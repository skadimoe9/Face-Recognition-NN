{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**FACE RECOGNITION**\n",
        "\n",
        "---\n",
        "BPNN Matrix 30x30 | Train-Testing-Validation </br>\n",
        "Ver. Fadhli"
      ],
      "metadata": {
        "id": "okLw9mtThmWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Import Libraries**\n"
      ],
      "metadata": {
        "id": "vauTZguNhiSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKfWaa1BBP1E",
        "outputId": "e241d31f-1535-434f-9f1d-12ede59c2c14"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "_7PI3eaeg4iz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0febfaf-875a-457d-9a1d-9fa3b8f6ff23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from PIL import Image\n",
        "\n",
        "!pip install tqdm\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Pemrosesan Gambar**"
      ],
      "metadata": {
        "id": "fY-Knf0sFMnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path ke dataset di Google Drive\n",
        "input_path = \"/content/drive/My Drive/FaceRec_NN/INVALID_data30x30\""
      ],
      "metadata": {
        "id": "8voDiZdwFZeD"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Flatten Data**"
      ],
      "metadata": {
        "id": "CA3pimjKFSbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_image(input_directory):\n",
        "    # List all folders in the input directory\n",
        "    folders = [f for f in os.listdir(input_directory) if os.path.isdir(os.path.join(input_directory, f))]\n",
        "    print(f\"Found folders: {folders}\")\n",
        "\n",
        "    # Initialize arrays for inputs and outputs\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    # Create a mapping from folder names to one-hot encoded labels\n",
        "    label_map = {folder: idx for idx, folder in enumerate(folders)}\n",
        "    num_classes = len(folders)\n",
        "\n",
        "    # Process each folder and photo\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(input_directory, folder)\n",
        "\n",
        "        # Sort the list of photos to ensure consistent order\n",
        "        photos = sorted([p for p in os.listdir(folder_path) if p.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "        for photo in photos:\n",
        "            photo_path = os.path.join(folder_path, photo)\n",
        "            image = Image.open(photo_path)\n",
        "\n",
        "            # Convert the image to a numpy array and flatten it\n",
        "            image_array = np.array(image).flatten()\n",
        "            X.append(image_array)\n",
        "\n",
        "            # Create a one-hot encoded label\n",
        "            label = np.zeros(num_classes)\n",
        "            label[label_map[folder]] = 1\n",
        "            y.append(label)\n",
        "\n",
        "    # Convert lists to numpy arrays\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "srd6uuk4FWCf"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalisasi Data**"
      ],
      "metadata": {
        "id": "8ne1YNQmG2tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NormalizeImage:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def transform(self):\n",
        "        #modified so the range of normalized data is [-1, 1]\n",
        "        return self.data/255\n",
        "\n",
        "    def inverse_transform(self):\n",
        "        return self.data*255"
      ],
      "metadata": {
        "id": "xJHEumWAG8-n"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Split Data**"
      ],
      "metadata": {
        "id": "VqEdXfnXCL8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_train_test(combined_array):\n",
        "    np.random.shuffle(combined_array)\n",
        "    # Calculate the split indices\n",
        "    num_samples = combined_array.shape[0]\n",
        "    train_end = int(0.7 * num_samples) # 70% of the data is used for training\n",
        "    test_end = int(0.85 * num_samples) # 15% of the data is used for testing\n",
        "\n",
        "    # Split the data into training, testing, and validation sets\n",
        "    train_data = combined_array[:train_end]\n",
        "    test_data = combined_array[train_end:test_end]\n",
        "    val_data = combined_array[test_end:]\n",
        "\n",
        "    return train_data, test_data, val_data\n",
        "\n",
        "def split_input_output(data, num_input_features):\n",
        "    X_data = data[:, :num_input_features]\n",
        "    y_data = data[:, num_input_features:]\n",
        "    return X_data, y_data"
      ],
      "metadata": {
        "id": "EQMGQF3RChz0"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = flatten_image(input_path)\n",
        "\n",
        "scalerinput = NormalizeImage(X)\n",
        "X_normalized = scalerinput.transform()\n",
        "combined_array = np.hstack((X_normalized, y))\n",
        "\n",
        "train_data, test_data, val_data = split_train_test(combined_array)\n",
        "num_input_features = X.shape[1]\n",
        "X_train, y_train = split_input_output(train_data, num_input_features)\n",
        "X_test, y_test = split_input_output(test_data, num_input_features)\n",
        "X_val, y_val = split_input_output(val_data, num_input_features)\n",
        "\n",
        "print(f\"Training data  : {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Testing data   : {X_test.shape}, {y_test.shape}\")\n",
        "print(f\"Validation data: {X_val.shape}, {y_val.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5bMG45QClYx",
        "outputId": "0d5dbed5-bd0f-44fb-ed35-40561977e4a5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found folders: ['Toni', 'Keiko', 'Fadhli', 'Fadlin', 'David', 'Azmira', 'Dimas', 'Hafidz', 'Haidar', 'Hanna', 'Khansa', 'Mikhael', 'Puti', 'Raesa', 'Satwika']\n",
            "Training data  : (968, 900), (968, 15)\n",
            "Testing data   : (208, 900), (208, 15)\n",
            "Validation data: (208, 900), (208, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Implementasi Kode**"
      ],
      "metadata": {
        "id": "8UDWoCXwC07n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "E_3aO-bmsAYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationFunction:\n",
        "    @staticmethod\n",
        "    def relu(y_feed):\n",
        "        return np.maximum(0, y_feed)\n",
        "\n",
        "    @staticmethod\n",
        "    def relu_derivative(y_feed):\n",
        "        return np.where(y_feed > 0, 1, 0)\n",
        "\n",
        "    @staticmethod\n",
        "    def leaky_relu(y_feed):\n",
        "        return np.where(y_feed > 0, y_feed, y_feed * 0.01)\n",
        "\n",
        "    @staticmethod\n",
        "    def leaky_relu_derivative(y_feed):\n",
        "        return np.where(y_feed > 0, 1, 0.01)\n",
        "\n",
        "    @staticmethod\n",
        "    def softmax(y_feed):\n",
        "        exps = np.exp(y_feed - np.max(y_feed, axis=1, keepdims=True))\n",
        "        return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "    def softmax_derivative(self, y_feed):\n",
        "        return ActivationFunction.softmax(y_feed) * (1 - ActivationFunction.softmax(y_feed))\n",
        "\n",
        "class WeightsInitialization:\n",
        "    @staticmethod\n",
        "    def xavier_initialization(n_input, n_output): # Bisa buat Sigmoid/Tanh\n",
        "        return np.random.randn(n_input, n_output) * np.sqrt(1 / n_input)\n",
        "\n",
        "    @staticmethod\n",
        "    def he_initialization(n_input, n_output): # Bisa buat Leaky ReLU/ReLU/Softmax\n",
        "        return np.random.randn(n_input, n_output) * np.sqrt(2 / n_input)\n",
        "\n",
        "    @staticmethod\n",
        "    def random_initialization(n_input, n_output):\n",
        "        return np.random.randn(n_input, n_output)\n",
        "\n",
        "class FaceRecognitionModel:\n",
        "    def __init__(self, input_size, hidden_layer_sizes, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_layer_sizes = hidden_layer_sizes\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = 0.05\n",
        "\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        self.activations = []\n",
        "        self.weights_gradients = []\n",
        "        self.biases_gradients = []\n",
        "\n",
        "        self.initialize_parameters()\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        input_size = self.input_size\n",
        "        for size in self.hidden_layer_sizes + [self.output_size]:\n",
        "            self.weights.append(WeightsInitialization.he_initialization(input_size, size))\n",
        "            self.weights_gradients.append(np.zeros((input_size, size)))\n",
        "            input_size = size\n",
        "\n",
        "    def initialize_biases(self):\n",
        "        for size in self.hidden_layer_sizes + [self.output_size]:\n",
        "            self.biases.append(np.zeros(size))\n",
        "            self.biases_gradients.append(np.zeros(size))\n",
        "\n",
        "    def initialize_activations(self):\n",
        "        for i in range(len(self.hidden_layer_sizes)):\n",
        "            self.activations.append(ActivationFunction.leaky_relu)\n",
        "        self.activations.append(ActivationFunction.softmax)\n",
        "\n",
        "    def initialize_parameters(self):\n",
        "        self.initialize_weights()\n",
        "        self.initialize_biases()\n",
        "        self.initialize_activations()\n",
        "\n",
        "    def forward_propagation(self, X):\n",
        "        self.z = []\n",
        "        self.a = [X]\n",
        "\n",
        "        for i in range(len(self.weights)):\n",
        "            z = np.dot(self.a[-1], self.weights[i]) + self.biases[i]\n",
        "            self.z.append(z)\n",
        "            a = self.activations[i](z)\n",
        "            self.a.append(a)\n",
        "\n",
        "        return self.a[-1]\n",
        "\n",
        "    def backward_propagation(self, X, y, y_pred):\n",
        "        m = X.shape[0]\n",
        "        self.weights_gradients = [np.zeros_like(w) for w in self.weights]\n",
        "        self.biases_gradients = [np.zeros_like(b) for b in self.biases]\n",
        "\n",
        "        dz = y_pred - y\n",
        "        for i in reversed(range(len(self.weights))):\n",
        "            self.weights_gradients[i] = np.dot(self.a[i].T, dz) / m\n",
        "            self.biases_gradients[i] = np.sum(dz, axis=0) / m\n",
        "            if i > 0:\n",
        "                if self.activations[i-1] == ActivationFunction.leaky_relu:\n",
        "                    dz = np.dot(dz, self.weights[i].T) * ActivationFunction.leaky_relu_derivative(self.z[i-1])\n",
        "                elif self.activations[i-1] == ActivationFunction.relu:\n",
        "                    dz = np.dot(dz, self.weights[i].T) * ActivationFunction.relu_derivative(self.z[i-1])\n",
        "                elif self.activations[i-1] == ActivationFunction.softmax:\n",
        "                    dz = np.dot(dz, self.weights[i].T) * ActivationFunction.softmax_derivative(self.z[i-1])\n",
        "\n",
        "    def initialize_adam(self):\n",
        "        self.m = [np.zeros_like(w) for w in self.weights]\n",
        "        self.v = [np.zeros_like(w) for w in self.weights]\n",
        "        self.m_b = [np.zeros_like(b) for b in self.biases]\n",
        "        self.v_b = [np.zeros_like(b) for b in self.biases]\n",
        "        self.t = 0\n",
        "\n",
        "    def update_weights(self, optimizer='sgd', beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "        if optimizer == 'adam':\n",
        "            if not hasattr(self, 'm'):\n",
        "                self.initialize_adam()\n",
        "\n",
        "            self.t += 1\n",
        "            lr_t = self.learning_rate\n",
        "\n",
        "            for i in range(len(self.weights)):\n",
        "                self.m[i] = beta1 * self.m[i] + (1 - beta1) * self.weights_gradients[i]\n",
        "                self.v[i] = beta2 * self.v[i] + (1 - beta2) * (self.weights_gradients[i] ** 2)\n",
        "                m_hat = self.m[i] / (1 - beta1 ** self.t)\n",
        "                v_hat = self.v[i] / (1 - beta2 ** self.t)\n",
        "                self.weights[i] -= lr_t * m_hat / (np.sqrt(v_hat) + epsilon)\n",
        "\n",
        "                self.m_b[i] = beta1 * self.m_b[i] + (1 - beta1) * self.biases_gradients[i]\n",
        "                self.v_b[i] = beta2 * self.v_b[i] + (1 - beta2) * (self.biases_gradients[i] ** 2)\n",
        "                m_hat_b = self.m_b[i] / (1 - beta1 ** self.t)\n",
        "                v_hat_b = self.v_b[i] / (1 - beta2 ** self.t)\n",
        "                self.biases[i] -= lr_t * m_hat_b / (np.sqrt(v_hat_b) + epsilon)\n",
        "        else:\n",
        "            for i in range(len(self.weights)):\n",
        "                self.weights[i] -= self.learning_rate * self.weights_gradients[i]\n",
        "                self.biases[i] -= self.learning_rate * self.biases_gradients[i]\n",
        "\n",
        "    def cross_entropy_loss(self, y_true, y_pred):\n",
        "        m = y_true.shape[0]\n",
        "        loss = -np.sum(y_true * np.log(y_pred + 1e-8)) / m\n",
        "        return loss\n",
        "\n",
        "    def save_weights(self, filename):\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump((self.weights, self.biases), f)\n",
        "\n",
        "    def load_weights(self, filename):\n",
        "        with open(filename, 'rb') as f:\n",
        "            self.weights, self.biases = pickle.load(f)\n",
        "\n",
        "    def train(self, X, y, X_val, y_val, epochs, learning_rate=0.1, optimizer='sgd', generate_new_params=True):\n",
        "        self.learning_rate = learning_rate\n",
        "        if generate_new_params:\n",
        "            self.weights, self.biases = [], []\n",
        "            self.initialize_parameters()\n",
        "            print('Params rewritten')\n",
        "\n",
        "        error_log = []\n",
        "        val_error_log = []\n",
        "        patience_counter = 0\n",
        "        patience = 10\n",
        "        flag = True\n",
        "\n",
        "        if optimizer == 'adam':\n",
        "            self.initialize_adam()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            y_pred = self.forward_propagation(X)\n",
        "            loss = self.cross_entropy_loss(y, y_pred)\n",
        "\n",
        "            self.backward_propagation(X, y, y_pred)\n",
        "            self.update_weights(optimizer)\n",
        "            error_log.append(loss)\n",
        "\n",
        "            # Early stopping break conditions\n",
        "            y_val_pred = self.forward_propagation(X_val)\n",
        "            val_loss = self.cross_entropy_loss(y_val, y_val_pred)\n",
        "            val_error_log.append(val_loss)\n",
        "\n",
        "            if epoch == 0:\n",
        "                prev_val_loss = val_loss\n",
        "            else:\n",
        "                if val_loss > prev_val_loss:\n",
        "                    if flag:\n",
        "                        self.save_weights('best_weights.pkl')\n",
        "                        flag = False\n",
        "                    patience_counter += 1\n",
        "                else:\n",
        "                    patience_counter = 0\n",
        "                    flag = True\n",
        "                prev_val_loss = val_loss\n",
        "\n",
        "            if patience_counter > patience:\n",
        "                print(f'Early stopping at Epoch: {epoch}, Patience: {patience_counter}')\n",
        "                break\n",
        "\n",
        "            print(f'Epoch {epoch}, Training Loss: {loss:.3e}, Validation Loss: {val_loss:.3e}, Patience: {patience_counter}, Learning Rate: {self.learning_rate}')\n",
        "\n",
        "        if epoch == epochs - 1 or patience_counter > patience:\n",
        "            print(f'Epoch {epoch}, Training Loss: {loss:.3e}, Validation Loss: {val_loss:.3e}, Patience: {patience_counter}')\n",
        "            if patience_counter > patience:\n",
        "                self.load_weights('best_weights.pkl')\n",
        "            return error_log, val_error_log\n",
        "        else:\n",
        "            self.weights, self.biases = [], []\n",
        "            self.initialize_parameters()\n",
        "            print('Reinitializing Param...')\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.forward_propagation(X)\n",
        "\n",
        "    def predict_label(self, X):\n",
        "        y_pred = self.predict(X)\n",
        "        predicted_labels = np.argmax(y_pred, axis=1)\n",
        "        return [self.labels[label] for label in predicted_labels]\n",
        "\n",
        "    def test(self, X_test, y_test):\n",
        "        y_pred = self.predict(X_test)\n",
        "        loss = self.cross_entropy_loss(y_test, y_pred)\n",
        "        print(f'Test Error : {loss}')\n",
        "        return y_pred\n",
        "\n",
        "    def plot_training_error(self, train_losses, val_losses=None):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(train_losses, label='Training Loss')\n",
        "        if val_losses is not None:\n",
        "            plt.plot(val_losses, label='Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def add_labels_from_folders(self, folder_path):\n",
        "        self.labels = []\n",
        "        for label in sorted(os.listdir(folder_path)):\n",
        "            if os.path.isdir(os.path.join(folder_path, label)):\n",
        "                self.labels.append(label)\n",
        "        self.output_size = len(self.labels)\n",
        "\n",
        "    def plot_confusion_matrix(self, X_test, y_test):\n",
        "        y_pred = np.argmax(self.predict(X_test), axis=1)\n",
        "        y_true = np.argmax(y_test, axis=1)\n",
        "        cm = np.zeros((self.output_size, self.output_size), dtype=int)\n",
        "        for t, p in zip(y_true, y_pred):\n",
        "            cm[t, p] += 1\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(self.output_size)\n",
        "        plt.xticks(tick_marks, self.labels, rotation=45)\n",
        "        plt.yticks(tick_marks, self.labels)\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        for i in range(cm.shape[0]):\n",
        "            for j in range(cm.shape[1]):\n",
        "                plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\")\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate_metrics(self, X_test, y_test):\n",
        "        y_pred = np.argmax(self.predict(X_test), axis=1)\n",
        "        y_true = np.argmax(y_test, axis=1)\n",
        "        accuracy = np.sum(y_pred == y_true) / len(y_true)\n",
        "        precision = np.zeros(self.output_size)\n",
        "        recall = np.zeros(self.output_size)\n",
        "        f1 = np.zeros(self.output_size)\n",
        "        for i in range(self.output_size):\n",
        "            tp = np.sum((y_pred == i) & (y_true == i))\n",
        "            fp = np.sum((y_pred == i) & (y_true != i))\n",
        "            fn = np.sum((y_pred != i) & (y_true == i))\n",
        "            precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "            recall[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            f1[i] = 2 * precision[i] * recall[i] / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n",
        "        print(f'Accuracy: {accuracy}')\n",
        "        for i, label in enumerate(self.labels):\n",
        "            print(f'{label} - Precision: {precision[i]}, Recall: {recall[i]}, F1 Score: {f1[i]}')\n",
        "        print(f'Mean Precision: {np.mean(precision)}')\n",
        "        print(f'Mean Recall: {np.mean(recall)}')\n",
        "        print(f'Mean F1 Score: {np.mean(f1)}')\n",
        "\n",
        "    def save_model(self, file_path):\n",
        "        with open(file_path, 'wb') as file:\n",
        "            pickle.dump(self, file)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_model(file_path):\n",
        "        with open(file_path, 'rb') as file:\n",
        "            return pickle.load(file)\n"
      ],
      "metadata": {
        "id": "8ze5_t8olrYg"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Data**"
      ],
      "metadata": {
        "id": "5gYTMeKBsFDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_30 = FaceRecognitionModel(X_train.shape[1], [64], y_train.shape[1])"
      ],
      "metadata": {
        "id": "jrwptS2tsHSs"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_train, error_val = model_30.train(X_train, y_train, X_val, y_val, epochs=10000, learning_rate=1e-2, optimizer='sgd', generate_new_params=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zdcHhNyuW6y",
        "outputId": "696454e4-7a45-490f-e5e6-a0156853a751"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming akan dipotong hingga 5000 baris terakhir.\u001b[0m\n",
            "Epoch 5001, Training Loss: 1.700e-01, Validation Loss: 4.505e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5002, Training Loss: 1.699e-01, Validation Loss: 4.505e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5003, Training Loss: 1.699e-01, Validation Loss: 4.505e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5004, Training Loss: 1.698e-01, Validation Loss: 4.504e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5005, Training Loss: 1.698e-01, Validation Loss: 4.504e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5006, Training Loss: 1.697e-01, Validation Loss: 4.504e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5007, Training Loss: 1.697e-01, Validation Loss: 4.503e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5008, Training Loss: 1.696e-01, Validation Loss: 4.503e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5009, Training Loss: 1.696e-01, Validation Loss: 4.502e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5010, Training Loss: 1.695e-01, Validation Loss: 4.502e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5011, Training Loss: 1.695e-01, Validation Loss: 4.502e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5012, Training Loss: 1.694e-01, Validation Loss: 4.502e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5013, Training Loss: 1.694e-01, Validation Loss: 4.501e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5014, Training Loss: 1.693e-01, Validation Loss: 4.501e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5015, Training Loss: 1.693e-01, Validation Loss: 4.501e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5016, Training Loss: 1.692e-01, Validation Loss: 4.500e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5017, Training Loss: 1.692e-01, Validation Loss: 4.500e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5018, Training Loss: 1.691e-01, Validation Loss: 4.500e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5019, Training Loss: 1.691e-01, Validation Loss: 4.500e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5020, Training Loss: 1.690e-01, Validation Loss: 4.499e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5021, Training Loss: 1.690e-01, Validation Loss: 4.499e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5022, Training Loss: 1.689e-01, Validation Loss: 4.498e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5023, Training Loss: 1.689e-01, Validation Loss: 4.498e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5024, Training Loss: 1.688e-01, Validation Loss: 4.498e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5025, Training Loss: 1.688e-01, Validation Loss: 4.498e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5026, Training Loss: 1.687e-01, Validation Loss: 4.498e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5027, Training Loss: 1.687e-01, Validation Loss: 4.497e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5028, Training Loss: 1.686e-01, Validation Loss: 4.497e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5029, Training Loss: 1.686e-01, Validation Loss: 4.496e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5030, Training Loss: 1.685e-01, Validation Loss: 4.496e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5031, Training Loss: 1.685e-01, Validation Loss: 4.496e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5032, Training Loss: 1.684e-01, Validation Loss: 4.495e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5033, Training Loss: 1.684e-01, Validation Loss: 4.495e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5034, Training Loss: 1.683e-01, Validation Loss: 4.495e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5035, Training Loss: 1.683e-01, Validation Loss: 4.494e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5036, Training Loss: 1.682e-01, Validation Loss: 4.494e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5037, Training Loss: 1.682e-01, Validation Loss: 4.494e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5038, Training Loss: 1.681e-01, Validation Loss: 4.493e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5039, Training Loss: 1.681e-01, Validation Loss: 4.493e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5040, Training Loss: 1.680e-01, Validation Loss: 4.493e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5041, Training Loss: 1.680e-01, Validation Loss: 4.492e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5042, Training Loss: 1.679e-01, Validation Loss: 4.492e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5043, Training Loss: 1.679e-01, Validation Loss: 4.492e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5044, Training Loss: 1.678e-01, Validation Loss: 4.492e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5045, Training Loss: 1.678e-01, Validation Loss: 4.491e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5046, Training Loss: 1.677e-01, Validation Loss: 4.491e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5047, Training Loss: 1.677e-01, Validation Loss: 4.491e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5048, Training Loss: 1.676e-01, Validation Loss: 4.490e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5049, Training Loss: 1.676e-01, Validation Loss: 4.490e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5050, Training Loss: 1.675e-01, Validation Loss: 4.490e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5051, Training Loss: 1.675e-01, Validation Loss: 4.489e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5052, Training Loss: 1.674e-01, Validation Loss: 4.489e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5053, Training Loss: 1.674e-01, Validation Loss: 4.489e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5054, Training Loss: 1.673e-01, Validation Loss: 4.488e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5055, Training Loss: 1.673e-01, Validation Loss: 4.488e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5056, Training Loss: 1.672e-01, Validation Loss: 4.488e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5057, Training Loss: 1.672e-01, Validation Loss: 4.488e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5058, Training Loss: 1.672e-01, Validation Loss: 4.487e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5059, Training Loss: 1.671e-01, Validation Loss: 4.487e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5060, Training Loss: 1.671e-01, Validation Loss: 4.487e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5061, Training Loss: 1.670e-01, Validation Loss: 4.486e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5062, Training Loss: 1.670e-01, Validation Loss: 4.486e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5063, Training Loss: 1.669e-01, Validation Loss: 4.486e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5064, Training Loss: 1.669e-01, Validation Loss: 4.485e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5065, Training Loss: 1.668e-01, Validation Loss: 4.485e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5066, Training Loss: 1.668e-01, Validation Loss: 4.485e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5067, Training Loss: 1.667e-01, Validation Loss: 4.484e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5068, Training Loss: 1.667e-01, Validation Loss: 4.484e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5069, Training Loss: 1.666e-01, Validation Loss: 4.484e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5070, Training Loss: 1.666e-01, Validation Loss: 4.484e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5071, Training Loss: 1.665e-01, Validation Loss: 4.483e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5072, Training Loss: 1.665e-01, Validation Loss: 4.483e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5073, Training Loss: 1.664e-01, Validation Loss: 4.482e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5074, Training Loss: 1.664e-01, Validation Loss: 4.482e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5075, Training Loss: 1.663e-01, Validation Loss: 4.482e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5076, Training Loss: 1.663e-01, Validation Loss: 4.482e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5077, Training Loss: 1.662e-01, Validation Loss: 4.482e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5078, Training Loss: 1.662e-01, Validation Loss: 4.481e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5079, Training Loss: 1.661e-01, Validation Loss: 4.481e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5080, Training Loss: 1.661e-01, Validation Loss: 4.480e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5081, Training Loss: 1.660e-01, Validation Loss: 4.480e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5082, Training Loss: 1.660e-01, Validation Loss: 4.480e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5083, Training Loss: 1.659e-01, Validation Loss: 4.479e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5084, Training Loss: 1.659e-01, Validation Loss: 4.479e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5085, Training Loss: 1.658e-01, Validation Loss: 4.479e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5086, Training Loss: 1.658e-01, Validation Loss: 4.479e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5087, Training Loss: 1.657e-01, Validation Loss: 4.478e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5088, Training Loss: 1.657e-01, Validation Loss: 4.478e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5089, Training Loss: 1.656e-01, Validation Loss: 4.478e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5090, Training Loss: 1.656e-01, Validation Loss: 4.477e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5091, Training Loss: 1.656e-01, Validation Loss: 4.477e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5092, Training Loss: 1.655e-01, Validation Loss: 4.477e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5093, Training Loss: 1.655e-01, Validation Loss: 4.477e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5094, Training Loss: 1.654e-01, Validation Loss: 4.476e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5095, Training Loss: 1.654e-01, Validation Loss: 4.476e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5096, Training Loss: 1.653e-01, Validation Loss: 4.475e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5097, Training Loss: 1.653e-01, Validation Loss: 4.475e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5098, Training Loss: 1.652e-01, Validation Loss: 4.475e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5099, Training Loss: 1.652e-01, Validation Loss: 4.474e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5100, Training Loss: 1.651e-01, Validation Loss: 4.474e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5101, Training Loss: 1.651e-01, Validation Loss: 4.474e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5102, Training Loss: 1.650e-01, Validation Loss: 4.473e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5103, Training Loss: 1.650e-01, Validation Loss: 4.473e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5104, Training Loss: 1.649e-01, Validation Loss: 4.473e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5105, Training Loss: 1.649e-01, Validation Loss: 4.473e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5106, Training Loss: 1.648e-01, Validation Loss: 4.472e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5107, Training Loss: 1.648e-01, Validation Loss: 4.472e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5108, Training Loss: 1.647e-01, Validation Loss: 4.472e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5109, Training Loss: 1.647e-01, Validation Loss: 4.472e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5110, Training Loss: 1.646e-01, Validation Loss: 4.471e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5111, Training Loss: 1.646e-01, Validation Loss: 4.471e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5112, Training Loss: 1.645e-01, Validation Loss: 4.470e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5113, Training Loss: 1.645e-01, Validation Loss: 4.470e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5114, Training Loss: 1.645e-01, Validation Loss: 4.470e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5115, Training Loss: 1.644e-01, Validation Loss: 4.470e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5116, Training Loss: 1.644e-01, Validation Loss: 4.469e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5117, Training Loss: 1.643e-01, Validation Loss: 4.469e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5118, Training Loss: 1.643e-01, Validation Loss: 4.469e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5119, Training Loss: 1.642e-01, Validation Loss: 4.468e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5120, Training Loss: 1.642e-01, Validation Loss: 4.468e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5121, Training Loss: 1.641e-01, Validation Loss: 4.468e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5122, Training Loss: 1.641e-01, Validation Loss: 4.467e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5123, Training Loss: 1.640e-01, Validation Loss: 4.467e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5124, Training Loss: 1.640e-01, Validation Loss: 4.467e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5125, Training Loss: 1.639e-01, Validation Loss: 4.467e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5126, Training Loss: 1.639e-01, Validation Loss: 4.466e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5127, Training Loss: 1.638e-01, Validation Loss: 4.466e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5128, Training Loss: 1.638e-01, Validation Loss: 4.466e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5129, Training Loss: 1.637e-01, Validation Loss: 4.465e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5130, Training Loss: 1.637e-01, Validation Loss: 4.465e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5131, Training Loss: 1.636e-01, Validation Loss: 4.465e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5132, Training Loss: 1.636e-01, Validation Loss: 4.464e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5133, Training Loss: 1.635e-01, Validation Loss: 4.464e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5134, Training Loss: 1.635e-01, Validation Loss: 4.464e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5135, Training Loss: 1.635e-01, Validation Loss: 4.464e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5136, Training Loss: 1.634e-01, Validation Loss: 4.463e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5137, Training Loss: 1.634e-01, Validation Loss: 4.463e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5138, Training Loss: 1.633e-01, Validation Loss: 4.462e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5139, Training Loss: 1.633e-01, Validation Loss: 4.462e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5140, Training Loss: 1.632e-01, Validation Loss: 4.462e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5141, Training Loss: 1.632e-01, Validation Loss: 4.462e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5142, Training Loss: 1.631e-01, Validation Loss: 4.462e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5143, Training Loss: 1.631e-01, Validation Loss: 4.461e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5144, Training Loss: 1.630e-01, Validation Loss: 4.460e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5145, Training Loss: 1.630e-01, Validation Loss: 4.461e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5146, Training Loss: 1.629e-01, Validation Loss: 4.460e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5147, Training Loss: 1.629e-01, Validation Loss: 4.460e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5148, Training Loss: 1.628e-01, Validation Loss: 4.460e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5149, Training Loss: 1.628e-01, Validation Loss: 4.459e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5150, Training Loss: 1.627e-01, Validation Loss: 4.459e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5151, Training Loss: 1.627e-01, Validation Loss: 4.459e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5152, Training Loss: 1.627e-01, Validation Loss: 4.458e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5153, Training Loss: 1.626e-01, Validation Loss: 4.458e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5154, Training Loss: 1.626e-01, Validation Loss: 4.458e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5155, Training Loss: 1.625e-01, Validation Loss: 4.458e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5156, Training Loss: 1.625e-01, Validation Loss: 4.457e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5157, Training Loss: 1.624e-01, Validation Loss: 4.457e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5158, Training Loss: 1.624e-01, Validation Loss: 4.457e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5159, Training Loss: 1.623e-01, Validation Loss: 4.456e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5160, Training Loss: 1.623e-01, Validation Loss: 4.456e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5161, Training Loss: 1.622e-01, Validation Loss: 4.456e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5162, Training Loss: 1.622e-01, Validation Loss: 4.455e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5163, Training Loss: 1.621e-01, Validation Loss: 4.455e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5164, Training Loss: 1.621e-01, Validation Loss: 4.455e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5165, Training Loss: 1.620e-01, Validation Loss: 4.454e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5166, Training Loss: 1.620e-01, Validation Loss: 4.454e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5167, Training Loss: 1.620e-01, Validation Loss: 4.454e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5168, Training Loss: 1.619e-01, Validation Loss: 4.454e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5169, Training Loss: 1.619e-01, Validation Loss: 4.453e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5170, Training Loss: 1.618e-01, Validation Loss: 4.453e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5171, Training Loss: 1.618e-01, Validation Loss: 4.453e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5172, Training Loss: 1.617e-01, Validation Loss: 4.453e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5173, Training Loss: 1.617e-01, Validation Loss: 4.452e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5174, Training Loss: 1.616e-01, Validation Loss: 4.452e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5175, Training Loss: 1.616e-01, Validation Loss: 4.452e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5176, Training Loss: 1.615e-01, Validation Loss: 4.451e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5177, Training Loss: 1.615e-01, Validation Loss: 4.451e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5178, Training Loss: 1.614e-01, Validation Loss: 4.451e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5179, Training Loss: 1.614e-01, Validation Loss: 4.450e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5180, Training Loss: 1.613e-01, Validation Loss: 4.450e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5181, Training Loss: 1.613e-01, Validation Loss: 4.450e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5182, Training Loss: 1.613e-01, Validation Loss: 4.449e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5183, Training Loss: 1.612e-01, Validation Loss: 4.449e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5184, Training Loss: 1.612e-01, Validation Loss: 4.449e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5185, Training Loss: 1.611e-01, Validation Loss: 4.449e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5186, Training Loss: 1.611e-01, Validation Loss: 4.448e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5187, Training Loss: 1.610e-01, Validation Loss: 4.448e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5188, Training Loss: 1.610e-01, Validation Loss: 4.448e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5189, Training Loss: 1.609e-01, Validation Loss: 4.447e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5190, Training Loss: 1.609e-01, Validation Loss: 4.447e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5191, Training Loss: 1.608e-01, Validation Loss: 4.447e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5192, Training Loss: 1.608e-01, Validation Loss: 4.446e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5193, Training Loss: 1.607e-01, Validation Loss: 4.447e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5194, Training Loss: 1.607e-01, Validation Loss: 4.446e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5195, Training Loss: 1.607e-01, Validation Loss: 4.446e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5196, Training Loss: 1.606e-01, Validation Loss: 4.445e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5197, Training Loss: 1.606e-01, Validation Loss: 4.445e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5198, Training Loss: 1.605e-01, Validation Loss: 4.445e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5199, Training Loss: 1.605e-01, Validation Loss: 4.445e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5200, Training Loss: 1.604e-01, Validation Loss: 4.444e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5201, Training Loss: 1.604e-01, Validation Loss: 4.444e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5202, Training Loss: 1.603e-01, Validation Loss: 4.444e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5203, Training Loss: 1.603e-01, Validation Loss: 4.443e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5204, Training Loss: 1.602e-01, Validation Loss: 4.443e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5205, Training Loss: 1.602e-01, Validation Loss: 4.443e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5206, Training Loss: 1.601e-01, Validation Loss: 4.442e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5207, Training Loss: 1.601e-01, Validation Loss: 4.442e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5208, Training Loss: 1.601e-01, Validation Loss: 4.442e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5209, Training Loss: 1.600e-01, Validation Loss: 4.442e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5210, Training Loss: 1.600e-01, Validation Loss: 4.441e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5211, Training Loss: 1.599e-01, Validation Loss: 4.441e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5212, Training Loss: 1.599e-01, Validation Loss: 4.441e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5213, Training Loss: 1.598e-01, Validation Loss: 4.440e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5214, Training Loss: 1.598e-01, Validation Loss: 4.440e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5215, Training Loss: 1.597e-01, Validation Loss: 4.440e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5216, Training Loss: 1.597e-01, Validation Loss: 4.439e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5217, Training Loss: 1.596e-01, Validation Loss: 4.439e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5218, Training Loss: 1.596e-01, Validation Loss: 4.439e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5219, Training Loss: 1.595e-01, Validation Loss: 4.438e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5220, Training Loss: 1.595e-01, Validation Loss: 4.438e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5221, Training Loss: 1.595e-01, Validation Loss: 4.438e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5222, Training Loss: 1.594e-01, Validation Loss: 4.438e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5223, Training Loss: 1.594e-01, Validation Loss: 4.437e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5224, Training Loss: 1.593e-01, Validation Loss: 4.437e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5225, Training Loss: 1.593e-01, Validation Loss: 4.437e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5226, Training Loss: 1.592e-01, Validation Loss: 4.437e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5227, Training Loss: 1.592e-01, Validation Loss: 4.436e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5228, Training Loss: 1.591e-01, Validation Loss: 4.436e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5229, Training Loss: 1.591e-01, Validation Loss: 4.436e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5230, Training Loss: 1.590e-01, Validation Loss: 4.435e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5231, Training Loss: 1.590e-01, Validation Loss: 4.435e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5232, Training Loss: 1.590e-01, Validation Loss: 4.435e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5233, Training Loss: 1.589e-01, Validation Loss: 4.434e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5234, Training Loss: 1.589e-01, Validation Loss: 4.434e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5235, Training Loss: 1.588e-01, Validation Loss: 4.434e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5236, Training Loss: 1.588e-01, Validation Loss: 4.434e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5237, Training Loss: 1.587e-01, Validation Loss: 4.434e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5238, Training Loss: 1.587e-01, Validation Loss: 4.433e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5239, Training Loss: 1.586e-01, Validation Loss: 4.433e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5240, Training Loss: 1.586e-01, Validation Loss: 4.432e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5241, Training Loss: 1.585e-01, Validation Loss: 4.432e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5242, Training Loss: 1.585e-01, Validation Loss: 4.432e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5243, Training Loss: 1.585e-01, Validation Loss: 4.432e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5244, Training Loss: 1.584e-01, Validation Loss: 4.431e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5245, Training Loss: 1.584e-01, Validation Loss: 4.431e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5246, Training Loss: 1.583e-01, Validation Loss: 4.431e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5247, Training Loss: 1.583e-01, Validation Loss: 4.430e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5248, Training Loss: 1.582e-01, Validation Loss: 4.430e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5249, Training Loss: 1.582e-01, Validation Loss: 4.430e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5250, Training Loss: 1.581e-01, Validation Loss: 4.430e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5251, Training Loss: 1.581e-01, Validation Loss: 4.429e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5252, Training Loss: 1.580e-01, Validation Loss: 4.429e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5253, Training Loss: 1.580e-01, Validation Loss: 4.429e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5254, Training Loss: 1.580e-01, Validation Loss: 4.429e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5255, Training Loss: 1.579e-01, Validation Loss: 4.428e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5256, Training Loss: 1.579e-01, Validation Loss: 4.428e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5257, Training Loss: 1.578e-01, Validation Loss: 4.427e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5258, Training Loss: 1.578e-01, Validation Loss: 4.427e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5259, Training Loss: 1.577e-01, Validation Loss: 4.427e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5260, Training Loss: 1.577e-01, Validation Loss: 4.427e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5261, Training Loss: 1.576e-01, Validation Loss: 4.426e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5262, Training Loss: 1.576e-01, Validation Loss: 4.426e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5263, Training Loss: 1.576e-01, Validation Loss: 4.426e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5264, Training Loss: 1.575e-01, Validation Loss: 4.426e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5265, Training Loss: 1.575e-01, Validation Loss: 4.425e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5266, Training Loss: 1.574e-01, Validation Loss: 4.425e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5267, Training Loss: 1.574e-01, Validation Loss: 4.425e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5268, Training Loss: 1.573e-01, Validation Loss: 4.424e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5269, Training Loss: 1.573e-01, Validation Loss: 4.424e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5270, Training Loss: 1.572e-01, Validation Loss: 4.424e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5271, Training Loss: 1.572e-01, Validation Loss: 4.424e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5272, Training Loss: 1.572e-01, Validation Loss: 4.423e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5273, Training Loss: 1.571e-01, Validation Loss: 4.423e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5274, Training Loss: 1.571e-01, Validation Loss: 4.423e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5275, Training Loss: 1.570e-01, Validation Loss: 4.422e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5276, Training Loss: 1.570e-01, Validation Loss: 4.422e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5277, Training Loss: 1.569e-01, Validation Loss: 4.422e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5278, Training Loss: 1.569e-01, Validation Loss: 4.422e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5279, Training Loss: 1.568e-01, Validation Loss: 4.421e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5280, Training Loss: 1.568e-01, Validation Loss: 4.421e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5281, Training Loss: 1.567e-01, Validation Loss: 4.421e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5282, Training Loss: 1.567e-01, Validation Loss: 4.420e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5283, Training Loss: 1.567e-01, Validation Loss: 4.420e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5284, Training Loss: 1.566e-01, Validation Loss: 4.420e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5285, Training Loss: 1.566e-01, Validation Loss: 4.419e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5286, Training Loss: 1.565e-01, Validation Loss: 4.420e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5287, Training Loss: 1.565e-01, Validation Loss: 4.419e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5288, Training Loss: 1.564e-01, Validation Loss: 4.419e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5289, Training Loss: 1.564e-01, Validation Loss: 4.418e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5290, Training Loss: 1.564e-01, Validation Loss: 4.418e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5291, Training Loss: 1.563e-01, Validation Loss: 4.418e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5292, Training Loss: 1.563e-01, Validation Loss: 4.418e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5293, Training Loss: 1.562e-01, Validation Loss: 4.417e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5294, Training Loss: 1.562e-01, Validation Loss: 4.417e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5295, Training Loss: 1.561e-01, Validation Loss: 4.417e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5296, Training Loss: 1.561e-01, Validation Loss: 4.416e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5297, Training Loss: 1.560e-01, Validation Loss: 4.416e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5298, Training Loss: 1.560e-01, Validation Loss: 4.416e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5299, Training Loss: 1.560e-01, Validation Loss: 4.416e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5300, Training Loss: 1.559e-01, Validation Loss: 4.415e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5301, Training Loss: 1.559e-01, Validation Loss: 4.415e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5302, Training Loss: 1.558e-01, Validation Loss: 4.415e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5303, Training Loss: 1.558e-01, Validation Loss: 4.415e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5304, Training Loss: 1.557e-01, Validation Loss: 4.414e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5305, Training Loss: 1.557e-01, Validation Loss: 4.414e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5306, Training Loss: 1.556e-01, Validation Loss: 4.414e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5307, Training Loss: 1.556e-01, Validation Loss: 4.413e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5308, Training Loss: 1.556e-01, Validation Loss: 4.413e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5309, Training Loss: 1.555e-01, Validation Loss: 4.413e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5310, Training Loss: 1.555e-01, Validation Loss: 4.413e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5311, Training Loss: 1.554e-01, Validation Loss: 4.412e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5312, Training Loss: 1.554e-01, Validation Loss: 4.412e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5313, Training Loss: 1.553e-01, Validation Loss: 4.412e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5314, Training Loss: 1.553e-01, Validation Loss: 4.412e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5315, Training Loss: 1.552e-01, Validation Loss: 4.411e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5316, Training Loss: 1.552e-01, Validation Loss: 4.411e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5317, Training Loss: 1.552e-01, Validation Loss: 4.411e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5318, Training Loss: 1.551e-01, Validation Loss: 4.411e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5319, Training Loss: 1.551e-01, Validation Loss: 4.410e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5320, Training Loss: 1.550e-01, Validation Loss: 4.410e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5321, Training Loss: 1.550e-01, Validation Loss: 4.409e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5322, Training Loss: 1.549e-01, Validation Loss: 4.409e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5323, Training Loss: 1.549e-01, Validation Loss: 4.409e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5324, Training Loss: 1.548e-01, Validation Loss: 4.409e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5325, Training Loss: 1.548e-01, Validation Loss: 4.409e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5326, Training Loss: 1.548e-01, Validation Loss: 4.408e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5327, Training Loss: 1.547e-01, Validation Loss: 4.408e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5328, Training Loss: 1.547e-01, Validation Loss: 4.408e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5329, Training Loss: 1.546e-01, Validation Loss: 4.407e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5330, Training Loss: 1.546e-01, Validation Loss: 4.407e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5331, Training Loss: 1.545e-01, Validation Loss: 4.407e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5332, Training Loss: 1.545e-01, Validation Loss: 4.407e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5333, Training Loss: 1.545e-01, Validation Loss: 4.406e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5334, Training Loss: 1.544e-01, Validation Loss: 4.406e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5335, Training Loss: 1.544e-01, Validation Loss: 4.406e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5336, Training Loss: 1.543e-01, Validation Loss: 4.406e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5337, Training Loss: 1.543e-01, Validation Loss: 4.405e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5338, Training Loss: 1.542e-01, Validation Loss: 4.405e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5339, Training Loss: 1.542e-01, Validation Loss: 4.405e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5340, Training Loss: 1.542e-01, Validation Loss: 4.405e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5341, Training Loss: 1.541e-01, Validation Loss: 4.404e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5342, Training Loss: 1.541e-01, Validation Loss: 4.404e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5343, Training Loss: 1.540e-01, Validation Loss: 4.404e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5344, Training Loss: 1.540e-01, Validation Loss: 4.403e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5345, Training Loss: 1.539e-01, Validation Loss: 4.403e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5346, Training Loss: 1.539e-01, Validation Loss: 4.403e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5347, Training Loss: 1.538e-01, Validation Loss: 4.403e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5348, Training Loss: 1.538e-01, Validation Loss: 4.402e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5349, Training Loss: 1.538e-01, Validation Loss: 4.402e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5350, Training Loss: 1.537e-01, Validation Loss: 4.402e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5351, Training Loss: 1.537e-01, Validation Loss: 4.401e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5352, Training Loss: 1.536e-01, Validation Loss: 4.401e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5353, Training Loss: 1.536e-01, Validation Loss: 4.401e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5354, Training Loss: 1.535e-01, Validation Loss: 4.401e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5355, Training Loss: 1.535e-01, Validation Loss: 4.400e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5356, Training Loss: 1.535e-01, Validation Loss: 4.400e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5357, Training Loss: 1.534e-01, Validation Loss: 4.400e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5358, Training Loss: 1.534e-01, Validation Loss: 4.399e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5359, Training Loss: 1.533e-01, Validation Loss: 4.399e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5360, Training Loss: 1.533e-01, Validation Loss: 4.399e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5361, Training Loss: 1.532e-01, Validation Loss: 4.399e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5362, Training Loss: 1.532e-01, Validation Loss: 4.398e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5363, Training Loss: 1.532e-01, Validation Loss: 4.398e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5364, Training Loss: 1.531e-01, Validation Loss: 4.398e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5365, Training Loss: 1.531e-01, Validation Loss: 4.397e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5366, Training Loss: 1.530e-01, Validation Loss: 4.397e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5367, Training Loss: 1.530e-01, Validation Loss: 4.397e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5368, Training Loss: 1.529e-01, Validation Loss: 4.397e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5369, Training Loss: 1.529e-01, Validation Loss: 4.396e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5370, Training Loss: 1.529e-01, Validation Loss: 4.396e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5371, Training Loss: 1.528e-01, Validation Loss: 4.396e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5372, Training Loss: 1.528e-01, Validation Loss: 4.396e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5373, Training Loss: 1.527e-01, Validation Loss: 4.396e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5374, Training Loss: 1.527e-01, Validation Loss: 4.395e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5375, Training Loss: 1.526e-01, Validation Loss: 4.395e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5376, Training Loss: 1.526e-01, Validation Loss: 4.395e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5377, Training Loss: 1.526e-01, Validation Loss: 4.394e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5378, Training Loss: 1.525e-01, Validation Loss: 4.394e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5379, Training Loss: 1.525e-01, Validation Loss: 4.394e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5380, Training Loss: 1.524e-01, Validation Loss: 4.394e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5381, Training Loss: 1.524e-01, Validation Loss: 4.393e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5382, Training Loss: 1.523e-01, Validation Loss: 4.393e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5383, Training Loss: 1.523e-01, Validation Loss: 4.393e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5384, Training Loss: 1.523e-01, Validation Loss: 4.393e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5385, Training Loss: 1.522e-01, Validation Loss: 4.392e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5386, Training Loss: 1.522e-01, Validation Loss: 4.392e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5387, Training Loss: 1.521e-01, Validation Loss: 4.392e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5388, Training Loss: 1.521e-01, Validation Loss: 4.391e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5389, Training Loss: 1.520e-01, Validation Loss: 4.391e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5390, Training Loss: 1.520e-01, Validation Loss: 4.391e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5391, Training Loss: 1.520e-01, Validation Loss: 4.391e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5392, Training Loss: 1.519e-01, Validation Loss: 4.390e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5393, Training Loss: 1.519e-01, Validation Loss: 4.390e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5394, Training Loss: 1.518e-01, Validation Loss: 4.390e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5395, Training Loss: 1.518e-01, Validation Loss: 4.390e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5396, Training Loss: 1.517e-01, Validation Loss: 4.389e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5397, Training Loss: 1.517e-01, Validation Loss: 4.389e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5398, Training Loss: 1.517e-01, Validation Loss: 4.389e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5399, Training Loss: 1.516e-01, Validation Loss: 4.388e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5400, Training Loss: 1.516e-01, Validation Loss: 4.388e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5401, Training Loss: 1.515e-01, Validation Loss: 4.388e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5402, Training Loss: 1.515e-01, Validation Loss: 4.388e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5403, Training Loss: 1.514e-01, Validation Loss: 4.387e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5404, Training Loss: 1.514e-01, Validation Loss: 4.387e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5405, Training Loss: 1.514e-01, Validation Loss: 4.387e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5406, Training Loss: 1.513e-01, Validation Loss: 4.386e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5407, Training Loss: 1.513e-01, Validation Loss: 4.387e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5408, Training Loss: 1.512e-01, Validation Loss: 4.386e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5409, Training Loss: 1.512e-01, Validation Loss: 4.386e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5410, Training Loss: 1.511e-01, Validation Loss: 4.386e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5411, Training Loss: 1.511e-01, Validation Loss: 4.385e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5412, Training Loss: 1.511e-01, Validation Loss: 4.385e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5413, Training Loss: 1.510e-01, Validation Loss: 4.385e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5414, Training Loss: 1.510e-01, Validation Loss: 4.385e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5415, Training Loss: 1.509e-01, Validation Loss: 4.384e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5416, Training Loss: 1.509e-01, Validation Loss: 4.384e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5417, Training Loss: 1.509e-01, Validation Loss: 4.384e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5418, Training Loss: 1.508e-01, Validation Loss: 4.383e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5419, Training Loss: 1.508e-01, Validation Loss: 4.383e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5420, Training Loss: 1.507e-01, Validation Loss: 4.383e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5421, Training Loss: 1.507e-01, Validation Loss: 4.383e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5422, Training Loss: 1.506e-01, Validation Loss: 4.382e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5423, Training Loss: 1.506e-01, Validation Loss: 4.382e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5424, Training Loss: 1.506e-01, Validation Loss: 4.382e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5425, Training Loss: 1.505e-01, Validation Loss: 4.382e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5426, Training Loss: 1.505e-01, Validation Loss: 4.381e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5427, Training Loss: 1.504e-01, Validation Loss: 4.381e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5428, Training Loss: 1.504e-01, Validation Loss: 4.381e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5429, Training Loss: 1.503e-01, Validation Loss: 4.380e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5430, Training Loss: 1.503e-01, Validation Loss: 4.380e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5431, Training Loss: 1.503e-01, Validation Loss: 4.380e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5432, Training Loss: 1.502e-01, Validation Loss: 4.380e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5433, Training Loss: 1.502e-01, Validation Loss: 4.380e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5434, Training Loss: 1.501e-01, Validation Loss: 4.379e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5435, Training Loss: 1.501e-01, Validation Loss: 4.379e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5436, Training Loss: 1.501e-01, Validation Loss: 4.379e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5437, Training Loss: 1.500e-01, Validation Loss: 4.379e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5438, Training Loss: 1.500e-01, Validation Loss: 4.378e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5439, Training Loss: 1.499e-01, Validation Loss: 4.378e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5440, Training Loss: 1.499e-01, Validation Loss: 4.378e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5441, Training Loss: 1.498e-01, Validation Loss: 4.377e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5442, Training Loss: 1.498e-01, Validation Loss: 4.377e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5443, Training Loss: 1.498e-01, Validation Loss: 4.377e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5444, Training Loss: 1.497e-01, Validation Loss: 4.377e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5445, Training Loss: 1.497e-01, Validation Loss: 4.376e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5446, Training Loss: 1.496e-01, Validation Loss: 4.376e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5447, Training Loss: 1.496e-01, Validation Loss: 4.376e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5448, Training Loss: 1.496e-01, Validation Loss: 4.376e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5449, Training Loss: 1.495e-01, Validation Loss: 4.375e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5450, Training Loss: 1.495e-01, Validation Loss: 4.375e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5451, Training Loss: 1.494e-01, Validation Loss: 4.375e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5452, Training Loss: 1.494e-01, Validation Loss: 4.375e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5453, Training Loss: 1.493e-01, Validation Loss: 4.374e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5454, Training Loss: 1.493e-01, Validation Loss: 4.374e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5455, Training Loss: 1.493e-01, Validation Loss: 4.374e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5456, Training Loss: 1.492e-01, Validation Loss: 4.374e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5457, Training Loss: 1.492e-01, Validation Loss: 4.373e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5458, Training Loss: 1.491e-01, Validation Loss: 4.373e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5459, Training Loss: 1.491e-01, Validation Loss: 4.373e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5460, Training Loss: 1.491e-01, Validation Loss: 4.373e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5461, Training Loss: 1.490e-01, Validation Loss: 4.372e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5462, Training Loss: 1.490e-01, Validation Loss: 4.372e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5463, Training Loss: 1.489e-01, Validation Loss: 4.372e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5464, Training Loss: 1.489e-01, Validation Loss: 4.372e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5465, Training Loss: 1.488e-01, Validation Loss: 4.371e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5466, Training Loss: 1.488e-01, Validation Loss: 4.371e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5467, Training Loss: 1.488e-01, Validation Loss: 4.371e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5468, Training Loss: 1.487e-01, Validation Loss: 4.371e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5469, Training Loss: 1.487e-01, Validation Loss: 4.370e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5470, Training Loss: 1.486e-01, Validation Loss: 4.370e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5471, Training Loss: 1.486e-01, Validation Loss: 4.370e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5472, Training Loss: 1.486e-01, Validation Loss: 4.370e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5473, Training Loss: 1.485e-01, Validation Loss: 4.369e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5474, Training Loss: 1.485e-01, Validation Loss: 4.369e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5475, Training Loss: 1.484e-01, Validation Loss: 4.369e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5476, Training Loss: 1.484e-01, Validation Loss: 4.369e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5477, Training Loss: 1.483e-01, Validation Loss: 4.368e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5478, Training Loss: 1.483e-01, Validation Loss: 4.368e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5479, Training Loss: 1.483e-01, Validation Loss: 4.368e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5480, Training Loss: 1.482e-01, Validation Loss: 4.368e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5481, Training Loss: 1.482e-01, Validation Loss: 4.367e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5482, Training Loss: 1.481e-01, Validation Loss: 4.367e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5483, Training Loss: 1.481e-01, Validation Loss: 4.367e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5484, Training Loss: 1.481e-01, Validation Loss: 4.367e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5485, Training Loss: 1.480e-01, Validation Loss: 4.366e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5486, Training Loss: 1.480e-01, Validation Loss: 4.366e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5487, Training Loss: 1.479e-01, Validation Loss: 4.366e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5488, Training Loss: 1.479e-01, Validation Loss: 4.366e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5489, Training Loss: 1.479e-01, Validation Loss: 4.365e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5490, Training Loss: 1.478e-01, Validation Loss: 4.365e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5491, Training Loss: 1.478e-01, Validation Loss: 4.365e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5492, Training Loss: 1.477e-01, Validation Loss: 4.365e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5493, Training Loss: 1.477e-01, Validation Loss: 4.364e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5494, Training Loss: 1.477e-01, Validation Loss: 4.364e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5495, Training Loss: 1.476e-01, Validation Loss: 4.364e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5496, Training Loss: 1.476e-01, Validation Loss: 4.363e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5497, Training Loss: 1.475e-01, Validation Loss: 4.363e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5498, Training Loss: 1.475e-01, Validation Loss: 4.363e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5499, Training Loss: 1.474e-01, Validation Loss: 4.363e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5500, Training Loss: 1.474e-01, Validation Loss: 4.363e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5501, Training Loss: 1.474e-01, Validation Loss: 4.362e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5502, Training Loss: 1.473e-01, Validation Loss: 4.362e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5503, Training Loss: 1.473e-01, Validation Loss: 4.362e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5504, Training Loss: 1.472e-01, Validation Loss: 4.362e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5505, Training Loss: 1.472e-01, Validation Loss: 4.361e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5506, Training Loss: 1.472e-01, Validation Loss: 4.361e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5507, Training Loss: 1.471e-01, Validation Loss: 4.361e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5508, Training Loss: 1.471e-01, Validation Loss: 4.360e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5509, Training Loss: 1.470e-01, Validation Loss: 4.360e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5510, Training Loss: 1.470e-01, Validation Loss: 4.360e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5511, Training Loss: 1.470e-01, Validation Loss: 4.360e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5512, Training Loss: 1.469e-01, Validation Loss: 4.360e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5513, Training Loss: 1.469e-01, Validation Loss: 4.359e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5514, Training Loss: 1.468e-01, Validation Loss: 4.359e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5515, Training Loss: 1.468e-01, Validation Loss: 4.358e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5516, Training Loss: 1.468e-01, Validation Loss: 4.358e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5517, Training Loss: 1.467e-01, Validation Loss: 4.358e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5518, Training Loss: 1.467e-01, Validation Loss: 4.358e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5519, Training Loss: 1.466e-01, Validation Loss: 4.358e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5520, Training Loss: 1.466e-01, Validation Loss: 4.358e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5521, Training Loss: 1.466e-01, Validation Loss: 4.357e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5522, Training Loss: 1.465e-01, Validation Loss: 4.357e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5523, Training Loss: 1.465e-01, Validation Loss: 4.357e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5524, Training Loss: 1.464e-01, Validation Loss: 4.357e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5525, Training Loss: 1.464e-01, Validation Loss: 4.356e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5526, Training Loss: 1.464e-01, Validation Loss: 4.356e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5527, Training Loss: 1.463e-01, Validation Loss: 4.356e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5528, Training Loss: 1.463e-01, Validation Loss: 4.356e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5529, Training Loss: 1.462e-01, Validation Loss: 4.355e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5530, Training Loss: 1.462e-01, Validation Loss: 4.355e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5531, Training Loss: 1.461e-01, Validation Loss: 4.355e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5532, Training Loss: 1.461e-01, Validation Loss: 4.355e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5533, Training Loss: 1.461e-01, Validation Loss: 4.354e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5534, Training Loss: 1.460e-01, Validation Loss: 4.354e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5535, Training Loss: 1.460e-01, Validation Loss: 4.354e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5536, Training Loss: 1.459e-01, Validation Loss: 4.353e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5537, Training Loss: 1.459e-01, Validation Loss: 4.354e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5538, Training Loss: 1.459e-01, Validation Loss: 4.353e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5539, Training Loss: 1.458e-01, Validation Loss: 4.353e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5540, Training Loss: 1.458e-01, Validation Loss: 4.353e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5541, Training Loss: 1.457e-01, Validation Loss: 4.352e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5542, Training Loss: 1.457e-01, Validation Loss: 4.352e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5543, Training Loss: 1.457e-01, Validation Loss: 4.352e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5544, Training Loss: 1.456e-01, Validation Loss: 4.352e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5545, Training Loss: 1.456e-01, Validation Loss: 4.352e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5546, Training Loss: 1.455e-01, Validation Loss: 4.351e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5547, Training Loss: 1.455e-01, Validation Loss: 4.351e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5548, Training Loss: 1.455e-01, Validation Loss: 4.351e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5549, Training Loss: 1.454e-01, Validation Loss: 4.350e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5550, Training Loss: 1.454e-01, Validation Loss: 4.350e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5551, Training Loss: 1.453e-01, Validation Loss: 4.350e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5552, Training Loss: 1.453e-01, Validation Loss: 4.350e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5553, Training Loss: 1.453e-01, Validation Loss: 4.349e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5554, Training Loss: 1.452e-01, Validation Loss: 4.349e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5555, Training Loss: 1.452e-01, Validation Loss: 4.349e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5556, Training Loss: 1.451e-01, Validation Loss: 4.349e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5557, Training Loss: 1.451e-01, Validation Loss: 4.349e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5558, Training Loss: 1.451e-01, Validation Loss: 4.348e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5559, Training Loss: 1.450e-01, Validation Loss: 4.348e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5560, Training Loss: 1.450e-01, Validation Loss: 4.348e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5561, Training Loss: 1.449e-01, Validation Loss: 4.347e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5562, Training Loss: 1.449e-01, Validation Loss: 4.347e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5563, Training Loss: 1.449e-01, Validation Loss: 4.347e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5564, Training Loss: 1.448e-01, Validation Loss: 4.347e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5565, Training Loss: 1.448e-01, Validation Loss: 4.346e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5566, Training Loss: 1.447e-01, Validation Loss: 4.346e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5567, Training Loss: 1.447e-01, Validation Loss: 4.346e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5568, Training Loss: 1.447e-01, Validation Loss: 4.346e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5569, Training Loss: 1.446e-01, Validation Loss: 4.345e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5570, Training Loss: 1.446e-01, Validation Loss: 4.345e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5571, Training Loss: 1.445e-01, Validation Loss: 4.345e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5572, Training Loss: 1.445e-01, Validation Loss: 4.345e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5573, Training Loss: 1.445e-01, Validation Loss: 4.344e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5574, Training Loss: 1.444e-01, Validation Loss: 4.345e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5575, Training Loss: 1.444e-01, Validation Loss: 4.344e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5576, Training Loss: 1.444e-01, Validation Loss: 4.344e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5577, Training Loss: 1.443e-01, Validation Loss: 4.344e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5578, Training Loss: 1.443e-01, Validation Loss: 4.343e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5579, Training Loss: 1.442e-01, Validation Loss: 4.343e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5580, Training Loss: 1.442e-01, Validation Loss: 4.343e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5581, Training Loss: 1.442e-01, Validation Loss: 4.343e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5582, Training Loss: 1.441e-01, Validation Loss: 4.342e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5583, Training Loss: 1.441e-01, Validation Loss: 4.342e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5584, Training Loss: 1.440e-01, Validation Loss: 4.342e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5585, Training Loss: 1.440e-01, Validation Loss: 4.342e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5586, Training Loss: 1.440e-01, Validation Loss: 4.341e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5587, Training Loss: 1.439e-01, Validation Loss: 4.341e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5588, Training Loss: 1.439e-01, Validation Loss: 4.341e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5589, Training Loss: 1.438e-01, Validation Loss: 4.341e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5590, Training Loss: 1.438e-01, Validation Loss: 4.340e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5591, Training Loss: 1.438e-01, Validation Loss: 4.340e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5592, Training Loss: 1.437e-01, Validation Loss: 4.340e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5593, Training Loss: 1.437e-01, Validation Loss: 4.340e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5594, Training Loss: 1.436e-01, Validation Loss: 4.339e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5595, Training Loss: 1.436e-01, Validation Loss: 4.339e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5596, Training Loss: 1.436e-01, Validation Loss: 4.339e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5597, Training Loss: 1.435e-01, Validation Loss: 4.339e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5598, Training Loss: 1.435e-01, Validation Loss: 4.339e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5599, Training Loss: 1.434e-01, Validation Loss: 4.338e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5600, Training Loss: 1.434e-01, Validation Loss: 4.338e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5601, Training Loss: 1.434e-01, Validation Loss: 4.338e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5602, Training Loss: 1.433e-01, Validation Loss: 4.338e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5603, Training Loss: 1.433e-01, Validation Loss: 4.337e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5604, Training Loss: 1.432e-01, Validation Loss: 4.337e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5605, Training Loss: 1.432e-01, Validation Loss: 4.337e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5606, Training Loss: 1.432e-01, Validation Loss: 4.337e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5607, Training Loss: 1.431e-01, Validation Loss: 4.336e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5608, Training Loss: 1.431e-01, Validation Loss: 4.336e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5609, Training Loss: 1.431e-01, Validation Loss: 4.336e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5610, Training Loss: 1.430e-01, Validation Loss: 4.336e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5611, Training Loss: 1.430e-01, Validation Loss: 4.335e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5612, Training Loss: 1.429e-01, Validation Loss: 4.335e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5613, Training Loss: 1.429e-01, Validation Loss: 4.335e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5614, Training Loss: 1.429e-01, Validation Loss: 4.335e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5615, Training Loss: 1.428e-01, Validation Loss: 4.334e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5616, Training Loss: 1.428e-01, Validation Loss: 4.334e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5617, Training Loss: 1.427e-01, Validation Loss: 4.334e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5618, Training Loss: 1.427e-01, Validation Loss: 4.334e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5619, Training Loss: 1.427e-01, Validation Loss: 4.334e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5620, Training Loss: 1.426e-01, Validation Loss: 4.333e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5621, Training Loss: 1.426e-01, Validation Loss: 4.333e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5622, Training Loss: 1.425e-01, Validation Loss: 4.333e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5623, Training Loss: 1.425e-01, Validation Loss: 4.333e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5624, Training Loss: 1.425e-01, Validation Loss: 4.332e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5625, Training Loss: 1.424e-01, Validation Loss: 4.332e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5626, Training Loss: 1.424e-01, Validation Loss: 4.332e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5627, Training Loss: 1.423e-01, Validation Loss: 4.332e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5628, Training Loss: 1.423e-01, Validation Loss: 4.332e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5629, Training Loss: 1.423e-01, Validation Loss: 4.331e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5630, Training Loss: 1.422e-01, Validation Loss: 4.331e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5631, Training Loss: 1.422e-01, Validation Loss: 4.331e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5632, Training Loss: 1.422e-01, Validation Loss: 4.331e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5633, Training Loss: 1.421e-01, Validation Loss: 4.330e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5634, Training Loss: 1.421e-01, Validation Loss: 4.330e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5635, Training Loss: 1.420e-01, Validation Loss: 4.330e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5636, Training Loss: 1.420e-01, Validation Loss: 4.330e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5637, Training Loss: 1.420e-01, Validation Loss: 4.329e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5638, Training Loss: 1.419e-01, Validation Loss: 4.329e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5639, Training Loss: 1.419e-01, Validation Loss: 4.329e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5640, Training Loss: 1.418e-01, Validation Loss: 4.329e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5641, Training Loss: 1.418e-01, Validation Loss: 4.329e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5642, Training Loss: 1.418e-01, Validation Loss: 4.328e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5643, Training Loss: 1.417e-01, Validation Loss: 4.328e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5644, Training Loss: 1.417e-01, Validation Loss: 4.328e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5645, Training Loss: 1.417e-01, Validation Loss: 4.327e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5646, Training Loss: 1.416e-01, Validation Loss: 4.327e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5647, Training Loss: 1.416e-01, Validation Loss: 4.327e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5648, Training Loss: 1.415e-01, Validation Loss: 4.326e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5649, Training Loss: 1.415e-01, Validation Loss: 4.327e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5650, Training Loss: 1.415e-01, Validation Loss: 4.326e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5651, Training Loss: 1.414e-01, Validation Loss: 4.326e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5652, Training Loss: 1.414e-01, Validation Loss: 4.326e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5653, Training Loss: 1.413e-01, Validation Loss: 4.326e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5654, Training Loss: 1.413e-01, Validation Loss: 4.326e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5655, Training Loss: 1.413e-01, Validation Loss: 4.325e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5656, Training Loss: 1.412e-01, Validation Loss: 4.325e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5657, Training Loss: 1.412e-01, Validation Loss: 4.325e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5658, Training Loss: 1.412e-01, Validation Loss: 4.324e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5659, Training Loss: 1.411e-01, Validation Loss: 4.324e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5660, Training Loss: 1.411e-01, Validation Loss: 4.324e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5661, Training Loss: 1.410e-01, Validation Loss: 4.324e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5662, Training Loss: 1.410e-01, Validation Loss: 4.323e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5663, Training Loss: 1.410e-01, Validation Loss: 4.324e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5664, Training Loss: 1.409e-01, Validation Loss: 4.323e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5665, Training Loss: 1.409e-01, Validation Loss: 4.323e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5666, Training Loss: 1.408e-01, Validation Loss: 4.322e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5667, Training Loss: 1.408e-01, Validation Loss: 4.322e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5668, Training Loss: 1.408e-01, Validation Loss: 4.322e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5669, Training Loss: 1.407e-01, Validation Loss: 4.322e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5670, Training Loss: 1.407e-01, Validation Loss: 4.322e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5671, Training Loss: 1.407e-01, Validation Loss: 4.321e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5672, Training Loss: 1.406e-01, Validation Loss: 4.321e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5673, Training Loss: 1.406e-01, Validation Loss: 4.321e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5674, Training Loss: 1.405e-01, Validation Loss: 4.321e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5675, Training Loss: 1.405e-01, Validation Loss: 4.321e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5676, Training Loss: 1.405e-01, Validation Loss: 4.320e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5677, Training Loss: 1.404e-01, Validation Loss: 4.320e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5678, Training Loss: 1.404e-01, Validation Loss: 4.320e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5679, Training Loss: 1.403e-01, Validation Loss: 4.320e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5680, Training Loss: 1.403e-01, Validation Loss: 4.319e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5681, Training Loss: 1.403e-01, Validation Loss: 4.319e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5682, Training Loss: 1.402e-01, Validation Loss: 4.319e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5683, Training Loss: 1.402e-01, Validation Loss: 4.319e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5684, Training Loss: 1.402e-01, Validation Loss: 4.319e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5685, Training Loss: 1.401e-01, Validation Loss: 4.318e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5686, Training Loss: 1.401e-01, Validation Loss: 4.318e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5687, Training Loss: 1.400e-01, Validation Loss: 4.318e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5688, Training Loss: 1.400e-01, Validation Loss: 4.317e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5689, Training Loss: 1.400e-01, Validation Loss: 4.317e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5690, Training Loss: 1.399e-01, Validation Loss: 4.317e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5691, Training Loss: 1.399e-01, Validation Loss: 4.317e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5692, Training Loss: 1.399e-01, Validation Loss: 4.317e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5693, Training Loss: 1.398e-01, Validation Loss: 4.316e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5694, Training Loss: 1.398e-01, Validation Loss: 4.316e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5695, Training Loss: 1.397e-01, Validation Loss: 4.316e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5696, Training Loss: 1.397e-01, Validation Loss: 4.316e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5697, Training Loss: 1.397e-01, Validation Loss: 4.316e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5698, Training Loss: 1.396e-01, Validation Loss: 4.315e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5699, Training Loss: 1.396e-01, Validation Loss: 4.315e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5700, Training Loss: 1.396e-01, Validation Loss: 4.315e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5701, Training Loss: 1.395e-01, Validation Loss: 4.315e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5702, Training Loss: 1.395e-01, Validation Loss: 4.314e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5703, Training Loss: 1.394e-01, Validation Loss: 4.314e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5704, Training Loss: 1.394e-01, Validation Loss: 4.314e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5705, Training Loss: 1.394e-01, Validation Loss: 4.314e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5706, Training Loss: 1.393e-01, Validation Loss: 4.313e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5707, Training Loss: 1.393e-01, Validation Loss: 4.313e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5708, Training Loss: 1.392e-01, Validation Loss: 4.313e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5709, Training Loss: 1.392e-01, Validation Loss: 4.313e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5710, Training Loss: 1.392e-01, Validation Loss: 4.313e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5711, Training Loss: 1.391e-01, Validation Loss: 4.312e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5712, Training Loss: 1.391e-01, Validation Loss: 4.312e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5713, Training Loss: 1.391e-01, Validation Loss: 4.312e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5714, Training Loss: 1.390e-01, Validation Loss: 4.312e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5715, Training Loss: 1.390e-01, Validation Loss: 4.311e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5716, Training Loss: 1.389e-01, Validation Loss: 4.311e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5717, Training Loss: 1.389e-01, Validation Loss: 4.311e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5718, Training Loss: 1.389e-01, Validation Loss: 4.311e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5719, Training Loss: 1.388e-01, Validation Loss: 4.310e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5720, Training Loss: 1.388e-01, Validation Loss: 4.310e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5721, Training Loss: 1.388e-01, Validation Loss: 4.310e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5722, Training Loss: 1.387e-01, Validation Loss: 4.310e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5723, Training Loss: 1.387e-01, Validation Loss: 4.309e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5724, Training Loss: 1.386e-01, Validation Loss: 4.309e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5725, Training Loss: 1.386e-01, Validation Loss: 4.309e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5726, Training Loss: 1.386e-01, Validation Loss: 4.309e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5727, Training Loss: 1.385e-01, Validation Loss: 4.308e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5728, Training Loss: 1.385e-01, Validation Loss: 4.308e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5729, Training Loss: 1.385e-01, Validation Loss: 4.308e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5730, Training Loss: 1.384e-01, Validation Loss: 4.308e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5731, Training Loss: 1.384e-01, Validation Loss: 4.308e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5732, Training Loss: 1.383e-01, Validation Loss: 4.308e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5733, Training Loss: 1.383e-01, Validation Loss: 4.307e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5734, Training Loss: 1.383e-01, Validation Loss: 4.307e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5735, Training Loss: 1.382e-01, Validation Loss: 4.307e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5736, Training Loss: 1.382e-01, Validation Loss: 4.307e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5737, Training Loss: 1.382e-01, Validation Loss: 4.306e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5738, Training Loss: 1.381e-01, Validation Loss: 4.306e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5739, Training Loss: 1.381e-01, Validation Loss: 4.306e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5740, Training Loss: 1.381e-01, Validation Loss: 4.306e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5741, Training Loss: 1.380e-01, Validation Loss: 4.305e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5742, Training Loss: 1.380e-01, Validation Loss: 4.305e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5743, Training Loss: 1.379e-01, Validation Loss: 4.305e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5744, Training Loss: 1.379e-01, Validation Loss: 4.305e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5745, Training Loss: 1.379e-01, Validation Loss: 4.304e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5746, Training Loss: 1.378e-01, Validation Loss: 4.304e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5747, Training Loss: 1.378e-01, Validation Loss: 4.304e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5748, Training Loss: 1.378e-01, Validation Loss: 4.304e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5749, Training Loss: 1.377e-01, Validation Loss: 4.303e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5750, Training Loss: 1.377e-01, Validation Loss: 4.303e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5751, Training Loss: 1.376e-01, Validation Loss: 4.303e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5752, Training Loss: 1.376e-01, Validation Loss: 4.303e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5753, Training Loss: 1.376e-01, Validation Loss: 4.303e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5754, Training Loss: 1.375e-01, Validation Loss: 4.302e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5755, Training Loss: 1.375e-01, Validation Loss: 4.302e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5756, Training Loss: 1.375e-01, Validation Loss: 4.302e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5757, Training Loss: 1.374e-01, Validation Loss: 4.302e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5758, Training Loss: 1.374e-01, Validation Loss: 4.302e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5759, Training Loss: 1.373e-01, Validation Loss: 4.301e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5760, Training Loss: 1.373e-01, Validation Loss: 4.301e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5761, Training Loss: 1.373e-01, Validation Loss: 4.301e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5762, Training Loss: 1.372e-01, Validation Loss: 4.301e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5763, Training Loss: 1.372e-01, Validation Loss: 4.300e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5764, Training Loss: 1.372e-01, Validation Loss: 4.300e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5765, Training Loss: 1.371e-01, Validation Loss: 4.300e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5766, Training Loss: 1.371e-01, Validation Loss: 4.300e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5767, Training Loss: 1.371e-01, Validation Loss: 4.300e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5768, Training Loss: 1.370e-01, Validation Loss: 4.299e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5769, Training Loss: 1.370e-01, Validation Loss: 4.299e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5770, Training Loss: 1.369e-01, Validation Loss: 4.299e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5771, Training Loss: 1.369e-01, Validation Loss: 4.299e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5772, Training Loss: 1.369e-01, Validation Loss: 4.298e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5773, Training Loss: 1.368e-01, Validation Loss: 4.298e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5774, Training Loss: 1.368e-01, Validation Loss: 4.298e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5775, Training Loss: 1.368e-01, Validation Loss: 4.298e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5776, Training Loss: 1.367e-01, Validation Loss: 4.298e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5777, Training Loss: 1.367e-01, Validation Loss: 4.297e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5778, Training Loss: 1.366e-01, Validation Loss: 4.297e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5779, Training Loss: 1.366e-01, Validation Loss: 4.297e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5780, Training Loss: 1.366e-01, Validation Loss: 4.297e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5781, Training Loss: 1.365e-01, Validation Loss: 4.296e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5782, Training Loss: 1.365e-01, Validation Loss: 4.296e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5783, Training Loss: 1.365e-01, Validation Loss: 4.296e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5784, Training Loss: 1.364e-01, Validation Loss: 4.296e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5785, Training Loss: 1.364e-01, Validation Loss: 4.295e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5786, Training Loss: 1.364e-01, Validation Loss: 4.295e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5787, Training Loss: 1.363e-01, Validation Loss: 4.295e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5788, Training Loss: 1.363e-01, Validation Loss: 4.295e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5789, Training Loss: 1.362e-01, Validation Loss: 4.295e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5790, Training Loss: 1.362e-01, Validation Loss: 4.295e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5791, Training Loss: 1.362e-01, Validation Loss: 4.294e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5792, Training Loss: 1.361e-01, Validation Loss: 4.294e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5793, Training Loss: 1.361e-01, Validation Loss: 4.294e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5794, Training Loss: 1.361e-01, Validation Loss: 4.294e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5795, Training Loss: 1.360e-01, Validation Loss: 4.293e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5796, Training Loss: 1.360e-01, Validation Loss: 4.293e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5797, Training Loss: 1.360e-01, Validation Loss: 4.293e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5798, Training Loss: 1.359e-01, Validation Loss: 4.293e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5799, Training Loss: 1.359e-01, Validation Loss: 4.293e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5800, Training Loss: 1.358e-01, Validation Loss: 4.292e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5801, Training Loss: 1.358e-01, Validation Loss: 4.292e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5802, Training Loss: 1.358e-01, Validation Loss: 4.292e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5803, Training Loss: 1.357e-01, Validation Loss: 4.292e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5804, Training Loss: 1.357e-01, Validation Loss: 4.291e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5805, Training Loss: 1.357e-01, Validation Loss: 4.291e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5806, Training Loss: 1.356e-01, Validation Loss: 4.291e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5807, Training Loss: 1.356e-01, Validation Loss: 4.291e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5808, Training Loss: 1.356e-01, Validation Loss: 4.291e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5809, Training Loss: 1.355e-01, Validation Loss: 4.291e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5810, Training Loss: 1.355e-01, Validation Loss: 4.290e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5811, Training Loss: 1.354e-01, Validation Loss: 4.290e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5812, Training Loss: 1.354e-01, Validation Loss: 4.290e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5813, Training Loss: 1.354e-01, Validation Loss: 4.289e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5814, Training Loss: 1.353e-01, Validation Loss: 4.289e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5815, Training Loss: 1.353e-01, Validation Loss: 4.289e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5816, Training Loss: 1.353e-01, Validation Loss: 4.289e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5817, Training Loss: 1.352e-01, Validation Loss: 4.289e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5818, Training Loss: 1.352e-01, Validation Loss: 4.289e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5819, Training Loss: 1.352e-01, Validation Loss: 4.288e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5820, Training Loss: 1.351e-01, Validation Loss: 4.288e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5821, Training Loss: 1.351e-01, Validation Loss: 4.288e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5822, Training Loss: 1.350e-01, Validation Loss: 4.288e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5823, Training Loss: 1.350e-01, Validation Loss: 4.287e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5824, Training Loss: 1.350e-01, Validation Loss: 4.287e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5825, Training Loss: 1.349e-01, Validation Loss: 4.287e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5826, Training Loss: 1.349e-01, Validation Loss: 4.287e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5827, Training Loss: 1.349e-01, Validation Loss: 4.287e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5828, Training Loss: 1.348e-01, Validation Loss: 4.286e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5829, Training Loss: 1.348e-01, Validation Loss: 4.286e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5830, Training Loss: 1.348e-01, Validation Loss: 4.286e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5831, Training Loss: 1.347e-01, Validation Loss: 4.286e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5832, Training Loss: 1.347e-01, Validation Loss: 4.286e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5833, Training Loss: 1.347e-01, Validation Loss: 4.285e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5834, Training Loss: 1.346e-01, Validation Loss: 4.285e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5835, Training Loss: 1.346e-01, Validation Loss: 4.285e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5836, Training Loss: 1.345e-01, Validation Loss: 4.285e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5837, Training Loss: 1.345e-01, Validation Loss: 4.284e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5838, Training Loss: 1.345e-01, Validation Loss: 4.284e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5839, Training Loss: 1.344e-01, Validation Loss: 4.284e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5840, Training Loss: 1.344e-01, Validation Loss: 4.284e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5841, Training Loss: 1.344e-01, Validation Loss: 4.284e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5842, Training Loss: 1.343e-01, Validation Loss: 4.283e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5843, Training Loss: 1.343e-01, Validation Loss: 4.283e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5844, Training Loss: 1.343e-01, Validation Loss: 4.283e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5845, Training Loss: 1.342e-01, Validation Loss: 4.283e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5846, Training Loss: 1.342e-01, Validation Loss: 4.283e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5847, Training Loss: 1.342e-01, Validation Loss: 4.282e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5848, Training Loss: 1.341e-01, Validation Loss: 4.282e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5849, Training Loss: 1.341e-01, Validation Loss: 4.282e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5850, Training Loss: 1.340e-01, Validation Loss: 4.282e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5851, Training Loss: 1.340e-01, Validation Loss: 4.281e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5852, Training Loss: 1.340e-01, Validation Loss: 4.281e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5853, Training Loss: 1.339e-01, Validation Loss: 4.281e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5854, Training Loss: 1.339e-01, Validation Loss: 4.281e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5855, Training Loss: 1.339e-01, Validation Loss: 4.281e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5856, Training Loss: 1.338e-01, Validation Loss: 4.280e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5857, Training Loss: 1.338e-01, Validation Loss: 4.280e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5858, Training Loss: 1.338e-01, Validation Loss: 4.280e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5859, Training Loss: 1.337e-01, Validation Loss: 4.280e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5860, Training Loss: 1.337e-01, Validation Loss: 4.279e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5861, Training Loss: 1.337e-01, Validation Loss: 4.279e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5862, Training Loss: 1.336e-01, Validation Loss: 4.279e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5863, Training Loss: 1.336e-01, Validation Loss: 4.279e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5864, Training Loss: 1.335e-01, Validation Loss: 4.279e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5865, Training Loss: 1.335e-01, Validation Loss: 4.279e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5866, Training Loss: 1.335e-01, Validation Loss: 4.278e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5867, Training Loss: 1.334e-01, Validation Loss: 4.278e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5868, Training Loss: 1.334e-01, Validation Loss: 4.278e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5869, Training Loss: 1.334e-01, Validation Loss: 4.277e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5870, Training Loss: 1.333e-01, Validation Loss: 4.277e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5871, Training Loss: 1.333e-01, Validation Loss: 4.277e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5872, Training Loss: 1.333e-01, Validation Loss: 4.277e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5873, Training Loss: 1.332e-01, Validation Loss: 4.277e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5874, Training Loss: 1.332e-01, Validation Loss: 4.277e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5875, Training Loss: 1.332e-01, Validation Loss: 4.276e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5876, Training Loss: 1.331e-01, Validation Loss: 4.276e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5877, Training Loss: 1.331e-01, Validation Loss: 4.276e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5878, Training Loss: 1.330e-01, Validation Loss: 4.276e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5879, Training Loss: 1.330e-01, Validation Loss: 4.276e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5880, Training Loss: 1.330e-01, Validation Loss: 4.275e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5881, Training Loss: 1.329e-01, Validation Loss: 4.275e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5882, Training Loss: 1.329e-01, Validation Loss: 4.275e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5883, Training Loss: 1.329e-01, Validation Loss: 4.275e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5884, Training Loss: 1.328e-01, Validation Loss: 4.274e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5885, Training Loss: 1.328e-01, Validation Loss: 4.274e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5886, Training Loss: 1.328e-01, Validation Loss: 4.274e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5887, Training Loss: 1.327e-01, Validation Loss: 4.274e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5888, Training Loss: 1.327e-01, Validation Loss: 4.274e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5889, Training Loss: 1.327e-01, Validation Loss: 4.273e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5890, Training Loss: 1.326e-01, Validation Loss: 4.273e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5891, Training Loss: 1.326e-01, Validation Loss: 4.273e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5892, Training Loss: 1.326e-01, Validation Loss: 4.273e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5893, Training Loss: 1.325e-01, Validation Loss: 4.272e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5894, Training Loss: 1.325e-01, Validation Loss: 4.273e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5895, Training Loss: 1.325e-01, Validation Loss: 4.272e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5896, Training Loss: 1.324e-01, Validation Loss: 4.272e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5897, Training Loss: 1.324e-01, Validation Loss: 4.272e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5898, Training Loss: 1.323e-01, Validation Loss: 4.272e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5899, Training Loss: 1.323e-01, Validation Loss: 4.271e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5900, Training Loss: 1.323e-01, Validation Loss: 4.271e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5901, Training Loss: 1.322e-01, Validation Loss: 4.271e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5902, Training Loss: 1.322e-01, Validation Loss: 4.271e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5903, Training Loss: 1.322e-01, Validation Loss: 4.270e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5904, Training Loss: 1.321e-01, Validation Loss: 4.270e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5905, Training Loss: 1.321e-01, Validation Loss: 4.270e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5906, Training Loss: 1.321e-01, Validation Loss: 4.270e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5907, Training Loss: 1.320e-01, Validation Loss: 4.270e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5908, Training Loss: 1.320e-01, Validation Loss: 4.270e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5909, Training Loss: 1.320e-01, Validation Loss: 4.269e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5910, Training Loss: 1.319e-01, Validation Loss: 4.269e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5911, Training Loss: 1.319e-01, Validation Loss: 4.269e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5912, Training Loss: 1.319e-01, Validation Loss: 4.269e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5913, Training Loss: 1.318e-01, Validation Loss: 4.268e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5914, Training Loss: 1.318e-01, Validation Loss: 4.268e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5915, Training Loss: 1.318e-01, Validation Loss: 4.268e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5916, Training Loss: 1.317e-01, Validation Loss: 4.268e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5917, Training Loss: 1.317e-01, Validation Loss: 4.268e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5918, Training Loss: 1.316e-01, Validation Loss: 4.268e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5919, Training Loss: 1.316e-01, Validation Loss: 4.267e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5920, Training Loss: 1.316e-01, Validation Loss: 4.267e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5921, Training Loss: 1.315e-01, Validation Loss: 4.267e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5922, Training Loss: 1.315e-01, Validation Loss: 4.267e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5923, Training Loss: 1.315e-01, Validation Loss: 4.267e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5924, Training Loss: 1.314e-01, Validation Loss: 4.266e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5925, Training Loss: 1.314e-01, Validation Loss: 4.266e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5926, Training Loss: 1.314e-01, Validation Loss: 4.266e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5927, Training Loss: 1.313e-01, Validation Loss: 4.266e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5928, Training Loss: 1.313e-01, Validation Loss: 4.265e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5929, Training Loss: 1.313e-01, Validation Loss: 4.265e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5930, Training Loss: 1.312e-01, Validation Loss: 4.265e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5931, Training Loss: 1.312e-01, Validation Loss: 4.265e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5932, Training Loss: 1.312e-01, Validation Loss: 4.265e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5933, Training Loss: 1.311e-01, Validation Loss: 4.265e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5934, Training Loss: 1.311e-01, Validation Loss: 4.264e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5935, Training Loss: 1.311e-01, Validation Loss: 4.264e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5936, Training Loss: 1.310e-01, Validation Loss: 4.264e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5937, Training Loss: 1.310e-01, Validation Loss: 4.264e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5938, Training Loss: 1.310e-01, Validation Loss: 4.263e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5939, Training Loss: 1.309e-01, Validation Loss: 4.263e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5940, Training Loss: 1.309e-01, Validation Loss: 4.263e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5941, Training Loss: 1.309e-01, Validation Loss: 4.263e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5942, Training Loss: 1.308e-01, Validation Loss: 4.263e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5943, Training Loss: 1.308e-01, Validation Loss: 4.262e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5944, Training Loss: 1.307e-01, Validation Loss: 4.262e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5945, Training Loss: 1.307e-01, Validation Loss: 4.262e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5946, Training Loss: 1.307e-01, Validation Loss: 4.262e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5947, Training Loss: 1.306e-01, Validation Loss: 4.262e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5948, Training Loss: 1.306e-01, Validation Loss: 4.261e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5949, Training Loss: 1.306e-01, Validation Loss: 4.261e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5950, Training Loss: 1.305e-01, Validation Loss: 4.261e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5951, Training Loss: 1.305e-01, Validation Loss: 4.261e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5952, Training Loss: 1.305e-01, Validation Loss: 4.261e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5953, Training Loss: 1.304e-01, Validation Loss: 4.260e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5954, Training Loss: 1.304e-01, Validation Loss: 4.260e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5955, Training Loss: 1.304e-01, Validation Loss: 4.260e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5956, Training Loss: 1.303e-01, Validation Loss: 4.260e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5957, Training Loss: 1.303e-01, Validation Loss: 4.260e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5958, Training Loss: 1.303e-01, Validation Loss: 4.259e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5959, Training Loss: 1.302e-01, Validation Loss: 4.259e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5960, Training Loss: 1.302e-01, Validation Loss: 4.259e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5961, Training Loss: 1.302e-01, Validation Loss: 4.259e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5962, Training Loss: 1.301e-01, Validation Loss: 4.258e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5963, Training Loss: 1.301e-01, Validation Loss: 4.258e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5964, Training Loss: 1.301e-01, Validation Loss: 4.258e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5965, Training Loss: 1.300e-01, Validation Loss: 4.258e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5966, Training Loss: 1.300e-01, Validation Loss: 4.258e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5967, Training Loss: 1.300e-01, Validation Loss: 4.257e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5968, Training Loss: 1.299e-01, Validation Loss: 4.257e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5969, Training Loss: 1.299e-01, Validation Loss: 4.257e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5970, Training Loss: 1.299e-01, Validation Loss: 4.257e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5971, Training Loss: 1.298e-01, Validation Loss: 4.257e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5972, Training Loss: 1.298e-01, Validation Loss: 4.257e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5973, Training Loss: 1.298e-01, Validation Loss: 4.256e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5974, Training Loss: 1.297e-01, Validation Loss: 4.256e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5975, Training Loss: 1.297e-01, Validation Loss: 4.256e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5976, Training Loss: 1.297e-01, Validation Loss: 4.256e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5977, Training Loss: 1.296e-01, Validation Loss: 4.256e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5978, Training Loss: 1.296e-01, Validation Loss: 4.255e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5979, Training Loss: 1.296e-01, Validation Loss: 4.255e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5980, Training Loss: 1.295e-01, Validation Loss: 4.255e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5981, Training Loss: 1.295e-01, Validation Loss: 4.255e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5982, Training Loss: 1.295e-01, Validation Loss: 4.254e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5983, Training Loss: 1.294e-01, Validation Loss: 4.255e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5984, Training Loss: 1.294e-01, Validation Loss: 4.254e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5985, Training Loss: 1.293e-01, Validation Loss: 4.254e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5986, Training Loss: 1.293e-01, Validation Loss: 4.254e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5987, Training Loss: 1.293e-01, Validation Loss: 4.254e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5988, Training Loss: 1.292e-01, Validation Loss: 4.253e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5989, Training Loss: 1.292e-01, Validation Loss: 4.253e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5990, Training Loss: 1.292e-01, Validation Loss: 4.253e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5991, Training Loss: 1.291e-01, Validation Loss: 4.253e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5992, Training Loss: 1.291e-01, Validation Loss: 4.252e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5993, Training Loss: 1.291e-01, Validation Loss: 4.253e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5994, Training Loss: 1.290e-01, Validation Loss: 4.252e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5995, Training Loss: 1.290e-01, Validation Loss: 4.252e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5996, Training Loss: 1.290e-01, Validation Loss: 4.252e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5997, Training Loss: 1.289e-01, Validation Loss: 4.252e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 5998, Training Loss: 1.289e-01, Validation Loss: 4.251e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 5999, Training Loss: 1.289e-01, Validation Loss: 4.251e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6000, Training Loss: 1.288e-01, Validation Loss: 4.251e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6001, Training Loss: 1.288e-01, Validation Loss: 4.251e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6002, Training Loss: 1.288e-01, Validation Loss: 4.251e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6003, Training Loss: 1.287e-01, Validation Loss: 4.250e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6004, Training Loss: 1.287e-01, Validation Loss: 4.250e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6005, Training Loss: 1.287e-01, Validation Loss: 4.250e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6006, Training Loss: 1.286e-01, Validation Loss: 4.250e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6007, Training Loss: 1.286e-01, Validation Loss: 4.250e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6008, Training Loss: 1.286e-01, Validation Loss: 4.249e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6009, Training Loss: 1.285e-01, Validation Loss: 4.249e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6010, Training Loss: 1.285e-01, Validation Loss: 4.249e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6011, Training Loss: 1.285e-01, Validation Loss: 4.249e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6012, Training Loss: 1.284e-01, Validation Loss: 4.249e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6013, Training Loss: 1.284e-01, Validation Loss: 4.249e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6014, Training Loss: 1.284e-01, Validation Loss: 4.248e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6015, Training Loss: 1.283e-01, Validation Loss: 4.248e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6016, Training Loss: 1.283e-01, Validation Loss: 4.248e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6017, Training Loss: 1.283e-01, Validation Loss: 4.248e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6018, Training Loss: 1.282e-01, Validation Loss: 4.248e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6019, Training Loss: 1.282e-01, Validation Loss: 4.247e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6020, Training Loss: 1.282e-01, Validation Loss: 4.247e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6021, Training Loss: 1.281e-01, Validation Loss: 4.247e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6022, Training Loss: 1.281e-01, Validation Loss: 4.247e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6023, Training Loss: 1.281e-01, Validation Loss: 4.246e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6024, Training Loss: 1.280e-01, Validation Loss: 4.246e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6025, Training Loss: 1.280e-01, Validation Loss: 4.246e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6026, Training Loss: 1.280e-01, Validation Loss: 4.246e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6027, Training Loss: 1.279e-01, Validation Loss: 4.246e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6028, Training Loss: 1.279e-01, Validation Loss: 4.246e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6029, Training Loss: 1.279e-01, Validation Loss: 4.245e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6030, Training Loss: 1.278e-01, Validation Loss: 4.245e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6031, Training Loss: 1.278e-01, Validation Loss: 4.245e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6032, Training Loss: 1.278e-01, Validation Loss: 4.245e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6033, Training Loss: 1.277e-01, Validation Loss: 4.245e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6034, Training Loss: 1.277e-01, Validation Loss: 4.244e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6035, Training Loss: 1.277e-01, Validation Loss: 4.244e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6036, Training Loss: 1.276e-01, Validation Loss: 4.244e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6037, Training Loss: 1.276e-01, Validation Loss: 4.244e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6038, Training Loss: 1.276e-01, Validation Loss: 4.243e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6039, Training Loss: 1.275e-01, Validation Loss: 4.243e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6040, Training Loss: 1.275e-01, Validation Loss: 4.243e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6041, Training Loss: 1.275e-01, Validation Loss: 4.243e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6042, Training Loss: 1.274e-01, Validation Loss: 4.243e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6043, Training Loss: 1.274e-01, Validation Loss: 4.243e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6044, Training Loss: 1.274e-01, Validation Loss: 4.242e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6045, Training Loss: 1.273e-01, Validation Loss: 4.242e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6046, Training Loss: 1.273e-01, Validation Loss: 4.242e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6047, Training Loss: 1.273e-01, Validation Loss: 4.242e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6048, Training Loss: 1.272e-01, Validation Loss: 4.242e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6049, Training Loss: 1.272e-01, Validation Loss: 4.242e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6050, Training Loss: 1.272e-01, Validation Loss: 4.241e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6051, Training Loss: 1.271e-01, Validation Loss: 4.241e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6052, Training Loss: 1.271e-01, Validation Loss: 4.241e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6053, Training Loss: 1.271e-01, Validation Loss: 4.241e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6054, Training Loss: 1.270e-01, Validation Loss: 4.240e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6055, Training Loss: 1.270e-01, Validation Loss: 4.240e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6056, Training Loss: 1.270e-01, Validation Loss: 4.240e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6057, Training Loss: 1.269e-01, Validation Loss: 4.240e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6058, Training Loss: 1.269e-01, Validation Loss: 4.240e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6059, Training Loss: 1.269e-01, Validation Loss: 4.240e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6060, Training Loss: 1.268e-01, Validation Loss: 4.239e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6061, Training Loss: 1.268e-01, Validation Loss: 4.239e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6062, Training Loss: 1.268e-01, Validation Loss: 4.239e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6063, Training Loss: 1.267e-01, Validation Loss: 4.239e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6064, Training Loss: 1.267e-01, Validation Loss: 4.239e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6065, Training Loss: 1.267e-01, Validation Loss: 4.238e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6066, Training Loss: 1.266e-01, Validation Loss: 4.238e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6067, Training Loss: 1.266e-01, Validation Loss: 4.238e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6068, Training Loss: 1.266e-01, Validation Loss: 4.238e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6069, Training Loss: 1.265e-01, Validation Loss: 4.238e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6070, Training Loss: 1.265e-01, Validation Loss: 4.237e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6071, Training Loss: 1.265e-01, Validation Loss: 4.237e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6072, Training Loss: 1.265e-01, Validation Loss: 4.237e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6073, Training Loss: 1.264e-01, Validation Loss: 4.237e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6074, Training Loss: 1.264e-01, Validation Loss: 4.236e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6075, Training Loss: 1.264e-01, Validation Loss: 4.236e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6076, Training Loss: 1.263e-01, Validation Loss: 4.236e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6077, Training Loss: 1.263e-01, Validation Loss: 4.236e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6078, Training Loss: 1.263e-01, Validation Loss: 4.236e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6079, Training Loss: 1.262e-01, Validation Loss: 4.236e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6080, Training Loss: 1.262e-01, Validation Loss: 4.235e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6081, Training Loss: 1.262e-01, Validation Loss: 4.235e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6082, Training Loss: 1.261e-01, Validation Loss: 4.235e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6083, Training Loss: 1.261e-01, Validation Loss: 4.235e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6084, Training Loss: 1.261e-01, Validation Loss: 4.235e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6085, Training Loss: 1.260e-01, Validation Loss: 4.235e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6086, Training Loss: 1.260e-01, Validation Loss: 4.234e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6087, Training Loss: 1.260e-01, Validation Loss: 4.234e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6088, Training Loss: 1.259e-01, Validation Loss: 4.234e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6089, Training Loss: 1.259e-01, Validation Loss: 4.234e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6090, Training Loss: 1.259e-01, Validation Loss: 4.234e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6091, Training Loss: 1.258e-01, Validation Loss: 4.233e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6092, Training Loss: 1.258e-01, Validation Loss: 4.233e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6093, Training Loss: 1.258e-01, Validation Loss: 4.233e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6094, Training Loss: 1.257e-01, Validation Loss: 4.233e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6095, Training Loss: 1.257e-01, Validation Loss: 4.233e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6096, Training Loss: 1.257e-01, Validation Loss: 4.233e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6097, Training Loss: 1.256e-01, Validation Loss: 4.232e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6098, Training Loss: 1.256e-01, Validation Loss: 4.232e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6099, Training Loss: 1.256e-01, Validation Loss: 4.232e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6100, Training Loss: 1.255e-01, Validation Loss: 4.232e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6101, Training Loss: 1.255e-01, Validation Loss: 4.231e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6102, Training Loss: 1.255e-01, Validation Loss: 4.231e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6103, Training Loss: 1.254e-01, Validation Loss: 4.231e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6104, Training Loss: 1.254e-01, Validation Loss: 4.231e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6105, Training Loss: 1.254e-01, Validation Loss: 4.231e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6106, Training Loss: 1.253e-01, Validation Loss: 4.231e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6107, Training Loss: 1.253e-01, Validation Loss: 4.230e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6108, Training Loss: 1.253e-01, Validation Loss: 4.230e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6109, Training Loss: 1.252e-01, Validation Loss: 4.230e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6110, Training Loss: 1.252e-01, Validation Loss: 4.230e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6111, Training Loss: 1.252e-01, Validation Loss: 4.229e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6112, Training Loss: 1.251e-01, Validation Loss: 4.230e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6113, Training Loss: 1.251e-01, Validation Loss: 4.229e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6114, Training Loss: 1.251e-01, Validation Loss: 4.229e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6115, Training Loss: 1.251e-01, Validation Loss: 4.229e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6116, Training Loss: 1.250e-01, Validation Loss: 4.229e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6117, Training Loss: 1.250e-01, Validation Loss: 4.228e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6118, Training Loss: 1.250e-01, Validation Loss: 4.228e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6119, Training Loss: 1.249e-01, Validation Loss: 4.228e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6120, Training Loss: 1.249e-01, Validation Loss: 4.228e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6121, Training Loss: 1.249e-01, Validation Loss: 4.228e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6122, Training Loss: 1.248e-01, Validation Loss: 4.227e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6123, Training Loss: 1.248e-01, Validation Loss: 4.228e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6124, Training Loss: 1.248e-01, Validation Loss: 4.227e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6125, Training Loss: 1.247e-01, Validation Loss: 4.227e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6126, Training Loss: 1.247e-01, Validation Loss: 4.227e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6127, Training Loss: 1.247e-01, Validation Loss: 4.227e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6128, Training Loss: 1.246e-01, Validation Loss: 4.226e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6129, Training Loss: 1.246e-01, Validation Loss: 4.226e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6130, Training Loss: 1.246e-01, Validation Loss: 4.226e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6131, Training Loss: 1.245e-01, Validation Loss: 4.226e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6132, Training Loss: 1.245e-01, Validation Loss: 4.225e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6133, Training Loss: 1.245e-01, Validation Loss: 4.225e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6134, Training Loss: 1.244e-01, Validation Loss: 4.225e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6135, Training Loss: 1.244e-01, Validation Loss: 4.225e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6136, Training Loss: 1.244e-01, Validation Loss: 4.225e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6137, Training Loss: 1.243e-01, Validation Loss: 4.225e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6138, Training Loss: 1.243e-01, Validation Loss: 4.224e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6139, Training Loss: 1.243e-01, Validation Loss: 4.224e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6140, Training Loss: 1.242e-01, Validation Loss: 4.224e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6141, Training Loss: 1.242e-01, Validation Loss: 4.224e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6142, Training Loss: 1.242e-01, Validation Loss: 4.224e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6143, Training Loss: 1.242e-01, Validation Loss: 4.223e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6144, Training Loss: 1.241e-01, Validation Loss: 4.223e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6145, Training Loss: 1.241e-01, Validation Loss: 4.223e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6146, Training Loss: 1.241e-01, Validation Loss: 4.223e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6147, Training Loss: 1.240e-01, Validation Loss: 4.223e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6148, Training Loss: 1.240e-01, Validation Loss: 4.223e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6149, Training Loss: 1.240e-01, Validation Loss: 4.222e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6150, Training Loss: 1.239e-01, Validation Loss: 4.222e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6151, Training Loss: 1.239e-01, Validation Loss: 4.222e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6152, Training Loss: 1.239e-01, Validation Loss: 4.222e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6153, Training Loss: 1.238e-01, Validation Loss: 4.222e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6154, Training Loss: 1.238e-01, Validation Loss: 4.222e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6155, Training Loss: 1.238e-01, Validation Loss: 4.221e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6156, Training Loss: 1.237e-01, Validation Loss: 4.221e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6157, Training Loss: 1.237e-01, Validation Loss: 4.221e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6158, Training Loss: 1.237e-01, Validation Loss: 4.221e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6159, Training Loss: 1.236e-01, Validation Loss: 4.221e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6160, Training Loss: 1.236e-01, Validation Loss: 4.220e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6161, Training Loss: 1.236e-01, Validation Loss: 4.220e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6162, Training Loss: 1.235e-01, Validation Loss: 4.220e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6163, Training Loss: 1.235e-01, Validation Loss: 4.220e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6164, Training Loss: 1.235e-01, Validation Loss: 4.220e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6165, Training Loss: 1.234e-01, Validation Loss: 4.219e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6166, Training Loss: 1.234e-01, Validation Loss: 4.219e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6167, Training Loss: 1.234e-01, Validation Loss: 4.219e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6168, Training Loss: 1.234e-01, Validation Loss: 4.219e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6169, Training Loss: 1.233e-01, Validation Loss: 4.219e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6170, Training Loss: 1.233e-01, Validation Loss: 4.219e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6171, Training Loss: 1.233e-01, Validation Loss: 4.218e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6172, Training Loss: 1.232e-01, Validation Loss: 4.218e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6173, Training Loss: 1.232e-01, Validation Loss: 4.218e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6174, Training Loss: 1.232e-01, Validation Loss: 4.218e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6175, Training Loss: 1.231e-01, Validation Loss: 4.218e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6176, Training Loss: 1.231e-01, Validation Loss: 4.218e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6177, Training Loss: 1.231e-01, Validation Loss: 4.217e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6178, Training Loss: 1.230e-01, Validation Loss: 4.217e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6179, Training Loss: 1.230e-01, Validation Loss: 4.217e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6180, Training Loss: 1.230e-01, Validation Loss: 4.217e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6181, Training Loss: 1.229e-01, Validation Loss: 4.217e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6182, Training Loss: 1.229e-01, Validation Loss: 4.217e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6183, Training Loss: 1.229e-01, Validation Loss: 4.216e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6184, Training Loss: 1.228e-01, Validation Loss: 4.216e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6185, Training Loss: 1.228e-01, Validation Loss: 4.216e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6186, Training Loss: 1.228e-01, Validation Loss: 4.216e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6187, Training Loss: 1.228e-01, Validation Loss: 4.216e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6188, Training Loss: 1.227e-01, Validation Loss: 4.215e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6189, Training Loss: 1.227e-01, Validation Loss: 4.215e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6190, Training Loss: 1.227e-01, Validation Loss: 4.215e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6191, Training Loss: 1.226e-01, Validation Loss: 4.215e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6192, Training Loss: 1.226e-01, Validation Loss: 4.215e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6193, Training Loss: 1.226e-01, Validation Loss: 4.214e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6194, Training Loss: 1.225e-01, Validation Loss: 4.214e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6195, Training Loss: 1.225e-01, Validation Loss: 4.214e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6196, Training Loss: 1.225e-01, Validation Loss: 4.214e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6197, Training Loss: 1.224e-01, Validation Loss: 4.214e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6198, Training Loss: 1.224e-01, Validation Loss: 4.214e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6199, Training Loss: 1.224e-01, Validation Loss: 4.213e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6200, Training Loss: 1.223e-01, Validation Loss: 4.213e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6201, Training Loss: 1.223e-01, Validation Loss: 4.213e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6202, Training Loss: 1.223e-01, Validation Loss: 4.213e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6203, Training Loss: 1.222e-01, Validation Loss: 4.213e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6204, Training Loss: 1.222e-01, Validation Loss: 4.213e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6205, Training Loss: 1.222e-01, Validation Loss: 4.212e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6206, Training Loss: 1.222e-01, Validation Loss: 4.212e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6207, Training Loss: 1.221e-01, Validation Loss: 4.212e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6208, Training Loss: 1.221e-01, Validation Loss: 4.212e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6209, Training Loss: 1.221e-01, Validation Loss: 4.212e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6210, Training Loss: 1.220e-01, Validation Loss: 4.212e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6211, Training Loss: 1.220e-01, Validation Loss: 4.211e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6212, Training Loss: 1.220e-01, Validation Loss: 4.211e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6213, Training Loss: 1.219e-01, Validation Loss: 4.211e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6214, Training Loss: 1.219e-01, Validation Loss: 4.211e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6215, Training Loss: 1.219e-01, Validation Loss: 4.211e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6216, Training Loss: 1.218e-01, Validation Loss: 4.210e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6217, Training Loss: 1.218e-01, Validation Loss: 4.210e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6218, Training Loss: 1.218e-01, Validation Loss: 4.210e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6219, Training Loss: 1.217e-01, Validation Loss: 4.210e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6220, Training Loss: 1.217e-01, Validation Loss: 4.210e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6221, Training Loss: 1.217e-01, Validation Loss: 4.209e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6222, Training Loss: 1.217e-01, Validation Loss: 4.209e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6223, Training Loss: 1.216e-01, Validation Loss: 4.209e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6224, Training Loss: 1.216e-01, Validation Loss: 4.209e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6225, Training Loss: 1.216e-01, Validation Loss: 4.209e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6226, Training Loss: 1.215e-01, Validation Loss: 4.209e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6227, Training Loss: 1.215e-01, Validation Loss: 4.208e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6228, Training Loss: 1.215e-01, Validation Loss: 4.208e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6229, Training Loss: 1.214e-01, Validation Loss: 4.208e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6230, Training Loss: 1.214e-01, Validation Loss: 4.208e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6231, Training Loss: 1.214e-01, Validation Loss: 4.208e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6232, Training Loss: 1.213e-01, Validation Loss: 4.208e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6233, Training Loss: 1.213e-01, Validation Loss: 4.208e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6234, Training Loss: 1.213e-01, Validation Loss: 4.207e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6235, Training Loss: 1.212e-01, Validation Loss: 4.207e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6236, Training Loss: 1.212e-01, Validation Loss: 4.207e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6237, Training Loss: 1.212e-01, Validation Loss: 4.207e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6238, Training Loss: 1.212e-01, Validation Loss: 4.207e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6239, Training Loss: 1.211e-01, Validation Loss: 4.206e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6240, Training Loss: 1.211e-01, Validation Loss: 4.206e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6241, Training Loss: 1.211e-01, Validation Loss: 4.206e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6242, Training Loss: 1.210e-01, Validation Loss: 4.206e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6243, Training Loss: 1.210e-01, Validation Loss: 4.206e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6244, Training Loss: 1.210e-01, Validation Loss: 4.206e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6245, Training Loss: 1.209e-01, Validation Loss: 4.205e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6246, Training Loss: 1.209e-01, Validation Loss: 4.205e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6247, Training Loss: 1.209e-01, Validation Loss: 4.205e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6248, Training Loss: 1.208e-01, Validation Loss: 4.205e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6249, Training Loss: 1.208e-01, Validation Loss: 4.205e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6250, Training Loss: 1.208e-01, Validation Loss: 4.205e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6251, Training Loss: 1.208e-01, Validation Loss: 4.204e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6252, Training Loss: 1.207e-01, Validation Loss: 4.204e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6253, Training Loss: 1.207e-01, Validation Loss: 4.204e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6254, Training Loss: 1.207e-01, Validation Loss: 4.204e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6255, Training Loss: 1.206e-01, Validation Loss: 4.204e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6256, Training Loss: 1.206e-01, Validation Loss: 4.203e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6257, Training Loss: 1.206e-01, Validation Loss: 4.203e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6258, Training Loss: 1.205e-01, Validation Loss: 4.203e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6259, Training Loss: 1.205e-01, Validation Loss: 4.203e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6260, Training Loss: 1.205e-01, Validation Loss: 4.203e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6261, Training Loss: 1.204e-01, Validation Loss: 4.203e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6262, Training Loss: 1.204e-01, Validation Loss: 4.202e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6263, Training Loss: 1.204e-01, Validation Loss: 4.202e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6264, Training Loss: 1.204e-01, Validation Loss: 4.202e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6265, Training Loss: 1.203e-01, Validation Loss: 4.202e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6266, Training Loss: 1.203e-01, Validation Loss: 4.202e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6267, Training Loss: 1.203e-01, Validation Loss: 4.202e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6268, Training Loss: 1.202e-01, Validation Loss: 4.201e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6269, Training Loss: 1.202e-01, Validation Loss: 4.201e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6270, Training Loss: 1.202e-01, Validation Loss: 4.201e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6271, Training Loss: 1.201e-01, Validation Loss: 4.201e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6272, Training Loss: 1.201e-01, Validation Loss: 4.201e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6273, Training Loss: 1.201e-01, Validation Loss: 4.201e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6274, Training Loss: 1.200e-01, Validation Loss: 4.200e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6275, Training Loss: 1.200e-01, Validation Loss: 4.200e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6276, Training Loss: 1.200e-01, Validation Loss: 4.200e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6277, Training Loss: 1.200e-01, Validation Loss: 4.200e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6278, Training Loss: 1.199e-01, Validation Loss: 4.200e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6279, Training Loss: 1.199e-01, Validation Loss: 4.199e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6280, Training Loss: 1.199e-01, Validation Loss: 4.200e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6281, Training Loss: 1.198e-01, Validation Loss: 4.199e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6282, Training Loss: 1.198e-01, Validation Loss: 4.199e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6283, Training Loss: 1.198e-01, Validation Loss: 4.199e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6284, Training Loss: 1.197e-01, Validation Loss: 4.199e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6285, Training Loss: 1.197e-01, Validation Loss: 4.199e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6286, Training Loss: 1.197e-01, Validation Loss: 4.198e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6287, Training Loss: 1.197e-01, Validation Loss: 4.198e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6288, Training Loss: 1.196e-01, Validation Loss: 4.198e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6289, Training Loss: 1.196e-01, Validation Loss: 4.198e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6290, Training Loss: 1.196e-01, Validation Loss: 4.198e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6291, Training Loss: 1.195e-01, Validation Loss: 4.197e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6292, Training Loss: 1.195e-01, Validation Loss: 4.197e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6293, Training Loss: 1.195e-01, Validation Loss: 4.197e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6294, Training Loss: 1.194e-01, Validation Loss: 4.197e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6295, Training Loss: 1.194e-01, Validation Loss: 4.197e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6296, Training Loss: 1.194e-01, Validation Loss: 4.197e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6297, Training Loss: 1.193e-01, Validation Loss: 4.196e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6298, Training Loss: 1.193e-01, Validation Loss: 4.196e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6299, Training Loss: 1.193e-01, Validation Loss: 4.196e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6300, Training Loss: 1.193e-01, Validation Loss: 4.196e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6301, Training Loss: 1.192e-01, Validation Loss: 4.196e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6302, Training Loss: 1.192e-01, Validation Loss: 4.196e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6303, Training Loss: 1.192e-01, Validation Loss: 4.195e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6304, Training Loss: 1.191e-01, Validation Loss: 4.195e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6305, Training Loss: 1.191e-01, Validation Loss: 4.195e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6306, Training Loss: 1.191e-01, Validation Loss: 4.195e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6307, Training Loss: 1.190e-01, Validation Loss: 4.195e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6308, Training Loss: 1.190e-01, Validation Loss: 4.195e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6309, Training Loss: 1.190e-01, Validation Loss: 4.194e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6310, Training Loss: 1.190e-01, Validation Loss: 4.194e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6311, Training Loss: 1.189e-01, Validation Loss: 4.194e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6312, Training Loss: 1.189e-01, Validation Loss: 4.194e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6313, Training Loss: 1.189e-01, Validation Loss: 4.194e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6314, Training Loss: 1.188e-01, Validation Loss: 4.194e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6315, Training Loss: 1.188e-01, Validation Loss: 4.194e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6316, Training Loss: 1.188e-01, Validation Loss: 4.193e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6317, Training Loss: 1.187e-01, Validation Loss: 4.193e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6318, Training Loss: 1.187e-01, Validation Loss: 4.193e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6319, Training Loss: 1.187e-01, Validation Loss: 4.193e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6320, Training Loss: 1.187e-01, Validation Loss: 4.193e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6321, Training Loss: 1.186e-01, Validation Loss: 4.192e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6322, Training Loss: 1.186e-01, Validation Loss: 4.192e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6323, Training Loss: 1.186e-01, Validation Loss: 4.192e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6324, Training Loss: 1.185e-01, Validation Loss: 4.192e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6325, Training Loss: 1.185e-01, Validation Loss: 4.192e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6326, Training Loss: 1.185e-01, Validation Loss: 4.191e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6327, Training Loss: 1.184e-01, Validation Loss: 4.191e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6328, Training Loss: 1.184e-01, Validation Loss: 4.191e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6329, Training Loss: 1.184e-01, Validation Loss: 4.191e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6330, Training Loss: 1.184e-01, Validation Loss: 4.191e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6331, Training Loss: 1.183e-01, Validation Loss: 4.191e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6332, Training Loss: 1.183e-01, Validation Loss: 4.191e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6333, Training Loss: 1.183e-01, Validation Loss: 4.191e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6334, Training Loss: 1.182e-01, Validation Loss: 4.190e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6335, Training Loss: 1.182e-01, Validation Loss: 4.190e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6336, Training Loss: 1.182e-01, Validation Loss: 4.190e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6337, Training Loss: 1.181e-01, Validation Loss: 4.190e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6338, Training Loss: 1.181e-01, Validation Loss: 4.190e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6339, Training Loss: 1.181e-01, Validation Loss: 4.190e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6340, Training Loss: 1.181e-01, Validation Loss: 4.189e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6341, Training Loss: 1.180e-01, Validation Loss: 4.189e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6342, Training Loss: 1.180e-01, Validation Loss: 4.189e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6343, Training Loss: 1.180e-01, Validation Loss: 4.189e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6344, Training Loss: 1.179e-01, Validation Loss: 4.189e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6345, Training Loss: 1.179e-01, Validation Loss: 4.189e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6346, Training Loss: 1.179e-01, Validation Loss: 4.188e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6347, Training Loss: 1.178e-01, Validation Loss: 4.188e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6348, Training Loss: 1.178e-01, Validation Loss: 4.188e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6349, Training Loss: 1.178e-01, Validation Loss: 4.188e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6350, Training Loss: 1.178e-01, Validation Loss: 4.188e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6351, Training Loss: 1.177e-01, Validation Loss: 4.187e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6352, Training Loss: 1.177e-01, Validation Loss: 4.187e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6353, Training Loss: 1.177e-01, Validation Loss: 4.187e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6354, Training Loss: 1.176e-01, Validation Loss: 4.187e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6355, Training Loss: 1.176e-01, Validation Loss: 4.187e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6356, Training Loss: 1.176e-01, Validation Loss: 4.187e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6357, Training Loss: 1.176e-01, Validation Loss: 4.186e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6358, Training Loss: 1.175e-01, Validation Loss: 4.186e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6359, Training Loss: 1.175e-01, Validation Loss: 4.186e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6360, Training Loss: 1.175e-01, Validation Loss: 4.186e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6361, Training Loss: 1.174e-01, Validation Loss: 4.186e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6362, Training Loss: 1.174e-01, Validation Loss: 4.186e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6363, Training Loss: 1.174e-01, Validation Loss: 4.186e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6364, Training Loss: 1.173e-01, Validation Loss: 4.185e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6365, Training Loss: 1.173e-01, Validation Loss: 4.185e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6366, Training Loss: 1.173e-01, Validation Loss: 4.185e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6367, Training Loss: 1.173e-01, Validation Loss: 4.185e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6368, Training Loss: 1.172e-01, Validation Loss: 4.185e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6369, Training Loss: 1.172e-01, Validation Loss: 4.184e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6370, Training Loss: 1.172e-01, Validation Loss: 4.184e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6371, Training Loss: 1.171e-01, Validation Loss: 4.184e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6372, Training Loss: 1.171e-01, Validation Loss: 4.184e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6373, Training Loss: 1.171e-01, Validation Loss: 4.184e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6374, Training Loss: 1.170e-01, Validation Loss: 4.184e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6375, Training Loss: 1.170e-01, Validation Loss: 4.184e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6376, Training Loss: 1.170e-01, Validation Loss: 4.183e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6377, Training Loss: 1.170e-01, Validation Loss: 4.183e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6378, Training Loss: 1.169e-01, Validation Loss: 4.183e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6379, Training Loss: 1.169e-01, Validation Loss: 4.183e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6380, Training Loss: 1.169e-01, Validation Loss: 4.183e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6381, Training Loss: 1.168e-01, Validation Loss: 4.183e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6382, Training Loss: 1.168e-01, Validation Loss: 4.182e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6383, Training Loss: 1.168e-01, Validation Loss: 4.182e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6384, Training Loss: 1.168e-01, Validation Loss: 4.182e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6385, Training Loss: 1.167e-01, Validation Loss: 4.182e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6386, Training Loss: 1.167e-01, Validation Loss: 4.182e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6387, Training Loss: 1.167e-01, Validation Loss: 4.182e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6388, Training Loss: 1.166e-01, Validation Loss: 4.181e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6389, Training Loss: 1.166e-01, Validation Loss: 4.182e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6390, Training Loss: 1.166e-01, Validation Loss: 4.181e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6391, Training Loss: 1.165e-01, Validation Loss: 4.181e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6392, Training Loss: 1.165e-01, Validation Loss: 4.181e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6393, Training Loss: 1.165e-01, Validation Loss: 4.181e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6394, Training Loss: 1.165e-01, Validation Loss: 4.180e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6395, Training Loss: 1.164e-01, Validation Loss: 4.180e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6396, Training Loss: 1.164e-01, Validation Loss: 4.180e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6397, Training Loss: 1.164e-01, Validation Loss: 4.180e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6398, Training Loss: 1.163e-01, Validation Loss: 4.180e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6399, Training Loss: 1.163e-01, Validation Loss: 4.180e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6400, Training Loss: 1.163e-01, Validation Loss: 4.179e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6401, Training Loss: 1.163e-01, Validation Loss: 4.180e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6402, Training Loss: 1.162e-01, Validation Loss: 4.179e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6403, Training Loss: 1.162e-01, Validation Loss: 4.179e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6404, Training Loss: 1.162e-01, Validation Loss: 4.179e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6405, Training Loss: 1.161e-01, Validation Loss: 4.179e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6406, Training Loss: 1.161e-01, Validation Loss: 4.178e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6407, Training Loss: 1.161e-01, Validation Loss: 4.178e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6408, Training Loss: 1.161e-01, Validation Loss: 4.178e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6409, Training Loss: 1.160e-01, Validation Loss: 4.178e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6410, Training Loss: 1.160e-01, Validation Loss: 4.178e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6411, Training Loss: 1.160e-01, Validation Loss: 4.178e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6412, Training Loss: 1.159e-01, Validation Loss: 4.178e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6413, Training Loss: 1.159e-01, Validation Loss: 4.177e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6414, Training Loss: 1.159e-01, Validation Loss: 4.177e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6415, Training Loss: 1.159e-01, Validation Loss: 4.177e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6416, Training Loss: 1.158e-01, Validation Loss: 4.177e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6417, Training Loss: 1.158e-01, Validation Loss: 4.177e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6418, Training Loss: 1.158e-01, Validation Loss: 4.177e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6419, Training Loss: 1.157e-01, Validation Loss: 4.176e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6420, Training Loss: 1.157e-01, Validation Loss: 4.176e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6421, Training Loss: 1.157e-01, Validation Loss: 4.176e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6422, Training Loss: 1.156e-01, Validation Loss: 4.176e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6423, Training Loss: 1.156e-01, Validation Loss: 4.176e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6424, Training Loss: 1.156e-01, Validation Loss: 4.176e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6425, Training Loss: 1.156e-01, Validation Loss: 4.176e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6426, Training Loss: 1.155e-01, Validation Loss: 4.176e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6427, Training Loss: 1.155e-01, Validation Loss: 4.175e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6428, Training Loss: 1.155e-01, Validation Loss: 4.175e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6429, Training Loss: 1.154e-01, Validation Loss: 4.175e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6430, Training Loss: 1.154e-01, Validation Loss: 4.175e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6431, Training Loss: 1.154e-01, Validation Loss: 4.175e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6432, Training Loss: 1.154e-01, Validation Loss: 4.175e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6433, Training Loss: 1.153e-01, Validation Loss: 4.174e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6434, Training Loss: 1.153e-01, Validation Loss: 4.174e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6435, Training Loss: 1.153e-01, Validation Loss: 4.174e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6436, Training Loss: 1.152e-01, Validation Loss: 4.174e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6437, Training Loss: 1.152e-01, Validation Loss: 4.174e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6438, Training Loss: 1.152e-01, Validation Loss: 4.174e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6439, Training Loss: 1.152e-01, Validation Loss: 4.173e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6440, Training Loss: 1.151e-01, Validation Loss: 4.173e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6441, Training Loss: 1.151e-01, Validation Loss: 4.173e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6442, Training Loss: 1.151e-01, Validation Loss: 4.173e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6443, Training Loss: 1.150e-01, Validation Loss: 4.173e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6444, Training Loss: 1.150e-01, Validation Loss: 4.173e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6445, Training Loss: 1.150e-01, Validation Loss: 4.172e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6446, Training Loss: 1.150e-01, Validation Loss: 4.172e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6447, Training Loss: 1.149e-01, Validation Loss: 4.172e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6448, Training Loss: 1.149e-01, Validation Loss: 4.172e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6449, Training Loss: 1.149e-01, Validation Loss: 4.172e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6450, Training Loss: 1.148e-01, Validation Loss: 4.172e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6451, Training Loss: 1.148e-01, Validation Loss: 4.171e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6452, Training Loss: 1.148e-01, Validation Loss: 4.171e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6453, Training Loss: 1.148e-01, Validation Loss: 4.171e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6454, Training Loss: 1.147e-01, Validation Loss: 4.171e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6455, Training Loss: 1.147e-01, Validation Loss: 4.171e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6456, Training Loss: 1.147e-01, Validation Loss: 4.171e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6457, Training Loss: 1.146e-01, Validation Loss: 4.170e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6458, Training Loss: 1.146e-01, Validation Loss: 4.171e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6459, Training Loss: 1.146e-01, Validation Loss: 4.170e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6460, Training Loss: 1.146e-01, Validation Loss: 4.170e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6461, Training Loss: 1.145e-01, Validation Loss: 4.170e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6462, Training Loss: 1.145e-01, Validation Loss: 4.170e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6463, Training Loss: 1.145e-01, Validation Loss: 4.170e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6464, Training Loss: 1.144e-01, Validation Loss: 4.170e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6465, Training Loss: 1.144e-01, Validation Loss: 4.169e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6466, Training Loss: 1.144e-01, Validation Loss: 4.169e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6467, Training Loss: 1.144e-01, Validation Loss: 4.169e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6468, Training Loss: 1.143e-01, Validation Loss: 4.169e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6469, Training Loss: 1.143e-01, Validation Loss: 4.169e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6470, Training Loss: 1.143e-01, Validation Loss: 4.169e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6471, Training Loss: 1.142e-01, Validation Loss: 4.168e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6472, Training Loss: 1.142e-01, Validation Loss: 4.168e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6473, Training Loss: 1.142e-01, Validation Loss: 4.168e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6474, Training Loss: 1.142e-01, Validation Loss: 4.168e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6475, Training Loss: 1.141e-01, Validation Loss: 4.168e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6476, Training Loss: 1.141e-01, Validation Loss: 4.168e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6477, Training Loss: 1.141e-01, Validation Loss: 4.168e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6478, Training Loss: 1.140e-01, Validation Loss: 4.167e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6479, Training Loss: 1.140e-01, Validation Loss: 4.167e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6480, Training Loss: 1.140e-01, Validation Loss: 4.167e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6481, Training Loss: 1.140e-01, Validation Loss: 4.167e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6482, Training Loss: 1.139e-01, Validation Loss: 4.167e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6483, Training Loss: 1.139e-01, Validation Loss: 4.167e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6484, Training Loss: 1.139e-01, Validation Loss: 4.167e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6485, Training Loss: 1.138e-01, Validation Loss: 4.166e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6486, Training Loss: 1.138e-01, Validation Loss: 4.166e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6487, Training Loss: 1.138e-01, Validation Loss: 4.166e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6488, Training Loss: 1.138e-01, Validation Loss: 4.166e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6489, Training Loss: 1.137e-01, Validation Loss: 4.166e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6490, Training Loss: 1.137e-01, Validation Loss: 4.166e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6491, Training Loss: 1.137e-01, Validation Loss: 4.165e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6492, Training Loss: 1.137e-01, Validation Loss: 4.165e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6493, Training Loss: 1.136e-01, Validation Loss: 4.165e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6494, Training Loss: 1.136e-01, Validation Loss: 4.165e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6495, Training Loss: 1.136e-01, Validation Loss: 4.165e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6496, Training Loss: 1.135e-01, Validation Loss: 4.165e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6497, Training Loss: 1.135e-01, Validation Loss: 4.165e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6498, Training Loss: 1.135e-01, Validation Loss: 4.164e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6499, Training Loss: 1.135e-01, Validation Loss: 4.164e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6500, Training Loss: 1.134e-01, Validation Loss: 4.164e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6501, Training Loss: 1.134e-01, Validation Loss: 4.164e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6502, Training Loss: 1.134e-01, Validation Loss: 4.164e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6503, Training Loss: 1.133e-01, Validation Loss: 4.163e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6504, Training Loss: 1.133e-01, Validation Loss: 4.164e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6505, Training Loss: 1.133e-01, Validation Loss: 4.163e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6506, Training Loss: 1.133e-01, Validation Loss: 4.163e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6507, Training Loss: 1.132e-01, Validation Loss: 4.163e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6508, Training Loss: 1.132e-01, Validation Loss: 4.163e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6509, Training Loss: 1.132e-01, Validation Loss: 4.163e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6510, Training Loss: 1.131e-01, Validation Loss: 4.162e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6511, Training Loss: 1.131e-01, Validation Loss: 4.162e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6512, Training Loss: 1.131e-01, Validation Loss: 4.162e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6513, Training Loss: 1.131e-01, Validation Loss: 4.162e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6514, Training Loss: 1.130e-01, Validation Loss: 4.162e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6515, Training Loss: 1.130e-01, Validation Loss: 4.162e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6516, Training Loss: 1.130e-01, Validation Loss: 4.162e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6517, Training Loss: 1.129e-01, Validation Loss: 4.161e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6518, Training Loss: 1.129e-01, Validation Loss: 4.161e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6519, Training Loss: 1.129e-01, Validation Loss: 4.161e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6520, Training Loss: 1.129e-01, Validation Loss: 4.161e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6521, Training Loss: 1.128e-01, Validation Loss: 4.161e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6522, Training Loss: 1.128e-01, Validation Loss: 4.161e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6523, Training Loss: 1.128e-01, Validation Loss: 4.160e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6524, Training Loss: 1.128e-01, Validation Loss: 4.160e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6525, Training Loss: 1.127e-01, Validation Loss: 4.160e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6526, Training Loss: 1.127e-01, Validation Loss: 4.160e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6527, Training Loss: 1.127e-01, Validation Loss: 4.160e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6528, Training Loss: 1.126e-01, Validation Loss: 4.160e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6529, Training Loss: 1.126e-01, Validation Loss: 4.160e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6530, Training Loss: 1.126e-01, Validation Loss: 4.159e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6531, Training Loss: 1.126e-01, Validation Loss: 4.159e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6532, Training Loss: 1.125e-01, Validation Loss: 4.159e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6533, Training Loss: 1.125e-01, Validation Loss: 4.159e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6534, Training Loss: 1.125e-01, Validation Loss: 4.159e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6535, Training Loss: 1.124e-01, Validation Loss: 4.159e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6536, Training Loss: 1.124e-01, Validation Loss: 4.158e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6537, Training Loss: 1.124e-01, Validation Loss: 4.158e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6538, Training Loss: 1.124e-01, Validation Loss: 4.158e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6539, Training Loss: 1.123e-01, Validation Loss: 4.158e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6540, Training Loss: 1.123e-01, Validation Loss: 4.158e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6541, Training Loss: 1.123e-01, Validation Loss: 4.158e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6542, Training Loss: 1.123e-01, Validation Loss: 4.158e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6543, Training Loss: 1.122e-01, Validation Loss: 4.158e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6544, Training Loss: 1.122e-01, Validation Loss: 4.157e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6545, Training Loss: 1.122e-01, Validation Loss: 4.157e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6546, Training Loss: 1.121e-01, Validation Loss: 4.157e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6547, Training Loss: 1.121e-01, Validation Loss: 4.157e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6548, Training Loss: 1.121e-01, Validation Loss: 4.157e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6549, Training Loss: 1.121e-01, Validation Loss: 4.157e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6550, Training Loss: 1.120e-01, Validation Loss: 4.156e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6551, Training Loss: 1.120e-01, Validation Loss: 4.156e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6552, Training Loss: 1.120e-01, Validation Loss: 4.156e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6553, Training Loss: 1.119e-01, Validation Loss: 4.156e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6554, Training Loss: 1.119e-01, Validation Loss: 4.156e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6555, Training Loss: 1.119e-01, Validation Loss: 4.156e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6556, Training Loss: 1.119e-01, Validation Loss: 4.155e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6557, Training Loss: 1.118e-01, Validation Loss: 4.156e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6558, Training Loss: 1.118e-01, Validation Loss: 4.155e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6559, Training Loss: 1.118e-01, Validation Loss: 4.155e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6560, Training Loss: 1.118e-01, Validation Loss: 4.155e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6561, Training Loss: 1.117e-01, Validation Loss: 4.155e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6562, Training Loss: 1.117e-01, Validation Loss: 4.155e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6563, Training Loss: 1.117e-01, Validation Loss: 4.155e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6564, Training Loss: 1.116e-01, Validation Loss: 4.154e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6565, Training Loss: 1.116e-01, Validation Loss: 4.154e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6566, Training Loss: 1.116e-01, Validation Loss: 4.154e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6567, Training Loss: 1.116e-01, Validation Loss: 4.154e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6568, Training Loss: 1.115e-01, Validation Loss: 4.154e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6569, Training Loss: 1.115e-01, Validation Loss: 4.154e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6570, Training Loss: 1.115e-01, Validation Loss: 4.153e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6571, Training Loss: 1.115e-01, Validation Loss: 4.153e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6572, Training Loss: 1.114e-01, Validation Loss: 4.153e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6573, Training Loss: 1.114e-01, Validation Loss: 4.153e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6574, Training Loss: 1.114e-01, Validation Loss: 4.153e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6575, Training Loss: 1.113e-01, Validation Loss: 4.153e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6576, Training Loss: 1.113e-01, Validation Loss: 4.153e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6577, Training Loss: 1.113e-01, Validation Loss: 4.152e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6578, Training Loss: 1.113e-01, Validation Loss: 4.152e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6579, Training Loss: 1.112e-01, Validation Loss: 4.152e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6580, Training Loss: 1.112e-01, Validation Loss: 4.152e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6581, Training Loss: 1.112e-01, Validation Loss: 4.152e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6582, Training Loss: 1.112e-01, Validation Loss: 4.152e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6583, Training Loss: 1.111e-01, Validation Loss: 4.152e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6584, Training Loss: 1.111e-01, Validation Loss: 4.152e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6585, Training Loss: 1.111e-01, Validation Loss: 4.151e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6586, Training Loss: 1.110e-01, Validation Loss: 4.151e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6587, Training Loss: 1.110e-01, Validation Loss: 4.151e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6588, Training Loss: 1.110e-01, Validation Loss: 4.151e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6589, Training Loss: 1.110e-01, Validation Loss: 4.151e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6590, Training Loss: 1.109e-01, Validation Loss: 4.151e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6591, Training Loss: 1.109e-01, Validation Loss: 4.150e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6592, Training Loss: 1.109e-01, Validation Loss: 4.150e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6593, Training Loss: 1.109e-01, Validation Loss: 4.150e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6594, Training Loss: 1.108e-01, Validation Loss: 4.150e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6595, Training Loss: 1.108e-01, Validation Loss: 4.150e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6596, Training Loss: 1.108e-01, Validation Loss: 4.150e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6597, Training Loss: 1.107e-01, Validation Loss: 4.150e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6598, Training Loss: 1.107e-01, Validation Loss: 4.149e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6599, Training Loss: 1.107e-01, Validation Loss: 4.149e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6600, Training Loss: 1.107e-01, Validation Loss: 4.149e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6601, Training Loss: 1.106e-01, Validation Loss: 4.149e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6602, Training Loss: 1.106e-01, Validation Loss: 4.149e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6603, Training Loss: 1.106e-01, Validation Loss: 4.149e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6604, Training Loss: 1.106e-01, Validation Loss: 4.149e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6605, Training Loss: 1.105e-01, Validation Loss: 4.148e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6606, Training Loss: 1.105e-01, Validation Loss: 4.148e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6607, Training Loss: 1.105e-01, Validation Loss: 4.148e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6608, Training Loss: 1.104e-01, Validation Loss: 4.148e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6609, Training Loss: 1.104e-01, Validation Loss: 4.148e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6610, Training Loss: 1.104e-01, Validation Loss: 4.148e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6611, Training Loss: 1.104e-01, Validation Loss: 4.147e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6612, Training Loss: 1.103e-01, Validation Loss: 4.147e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6613, Training Loss: 1.103e-01, Validation Loss: 4.147e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6614, Training Loss: 1.103e-01, Validation Loss: 4.147e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6615, Training Loss: 1.103e-01, Validation Loss: 4.147e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6616, Training Loss: 1.102e-01, Validation Loss: 4.147e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6617, Training Loss: 1.102e-01, Validation Loss: 4.147e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6618, Training Loss: 1.102e-01, Validation Loss: 4.146e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6619, Training Loss: 1.102e-01, Validation Loss: 4.146e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6620, Training Loss: 1.101e-01, Validation Loss: 4.146e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6621, Training Loss: 1.101e-01, Validation Loss: 4.146e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6622, Training Loss: 1.101e-01, Validation Loss: 4.146e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6623, Training Loss: 1.100e-01, Validation Loss: 4.146e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6624, Training Loss: 1.100e-01, Validation Loss: 4.146e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6625, Training Loss: 1.100e-01, Validation Loss: 4.145e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6626, Training Loss: 1.100e-01, Validation Loss: 4.145e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6627, Training Loss: 1.099e-01, Validation Loss: 4.145e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6628, Training Loss: 1.099e-01, Validation Loss: 4.145e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6629, Training Loss: 1.099e-01, Validation Loss: 4.145e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6630, Training Loss: 1.099e-01, Validation Loss: 4.145e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6631, Training Loss: 1.098e-01, Validation Loss: 4.145e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6632, Training Loss: 1.098e-01, Validation Loss: 4.144e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6633, Training Loss: 1.098e-01, Validation Loss: 4.144e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6634, Training Loss: 1.098e-01, Validation Loss: 4.144e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6635, Training Loss: 1.097e-01, Validation Loss: 4.144e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6636, Training Loss: 1.097e-01, Validation Loss: 4.144e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6637, Training Loss: 1.097e-01, Validation Loss: 4.144e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6638, Training Loss: 1.096e-01, Validation Loss: 4.144e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6639, Training Loss: 1.096e-01, Validation Loss: 4.144e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6640, Training Loss: 1.096e-01, Validation Loss: 4.143e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6641, Training Loss: 1.096e-01, Validation Loss: 4.143e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6642, Training Loss: 1.095e-01, Validation Loss: 4.143e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6643, Training Loss: 1.095e-01, Validation Loss: 4.143e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6644, Training Loss: 1.095e-01, Validation Loss: 4.143e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6645, Training Loss: 1.095e-01, Validation Loss: 4.143e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6646, Training Loss: 1.094e-01, Validation Loss: 4.142e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6647, Training Loss: 1.094e-01, Validation Loss: 4.142e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6648, Training Loss: 1.094e-01, Validation Loss: 4.142e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6649, Training Loss: 1.094e-01, Validation Loss: 4.142e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6650, Training Loss: 1.093e-01, Validation Loss: 4.142e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6651, Training Loss: 1.093e-01, Validation Loss: 4.142e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6652, Training Loss: 1.093e-01, Validation Loss: 4.141e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6653, Training Loss: 1.092e-01, Validation Loss: 4.142e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6654, Training Loss: 1.092e-01, Validation Loss: 4.141e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6655, Training Loss: 1.092e-01, Validation Loss: 4.141e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6656, Training Loss: 1.092e-01, Validation Loss: 4.141e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6657, Training Loss: 1.091e-01, Validation Loss: 4.141e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6658, Training Loss: 1.091e-01, Validation Loss: 4.141e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6659, Training Loss: 1.091e-01, Validation Loss: 4.140e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6660, Training Loss: 1.091e-01, Validation Loss: 4.140e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6661, Training Loss: 1.090e-01, Validation Loss: 4.140e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6662, Training Loss: 1.090e-01, Validation Loss: 4.140e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6663, Training Loss: 1.090e-01, Validation Loss: 4.140e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6664, Training Loss: 1.090e-01, Validation Loss: 4.140e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6665, Training Loss: 1.089e-01, Validation Loss: 4.140e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6666, Training Loss: 1.089e-01, Validation Loss: 4.139e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6667, Training Loss: 1.089e-01, Validation Loss: 4.140e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6668, Training Loss: 1.088e-01, Validation Loss: 4.139e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6669, Training Loss: 1.088e-01, Validation Loss: 4.139e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6670, Training Loss: 1.088e-01, Validation Loss: 4.139e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6671, Training Loss: 1.088e-01, Validation Loss: 4.139e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6672, Training Loss: 1.087e-01, Validation Loss: 4.139e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6673, Training Loss: 1.087e-01, Validation Loss: 4.139e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6674, Training Loss: 1.087e-01, Validation Loss: 4.138e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6675, Training Loss: 1.087e-01, Validation Loss: 4.138e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6676, Training Loss: 1.086e-01, Validation Loss: 4.138e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6677, Training Loss: 1.086e-01, Validation Loss: 4.138e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6678, Training Loss: 1.086e-01, Validation Loss: 4.138e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6679, Training Loss: 1.086e-01, Validation Loss: 4.138e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6680, Training Loss: 1.085e-01, Validation Loss: 4.138e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6681, Training Loss: 1.085e-01, Validation Loss: 4.137e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6682, Training Loss: 1.085e-01, Validation Loss: 4.137e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6683, Training Loss: 1.085e-01, Validation Loss: 4.137e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6684, Training Loss: 1.084e-01, Validation Loss: 4.137e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6685, Training Loss: 1.084e-01, Validation Loss: 4.137e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6686, Training Loss: 1.084e-01, Validation Loss: 4.137e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6687, Training Loss: 1.083e-01, Validation Loss: 4.137e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6688, Training Loss: 1.083e-01, Validation Loss: 4.137e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6689, Training Loss: 1.083e-01, Validation Loss: 4.136e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6690, Training Loss: 1.083e-01, Validation Loss: 4.136e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6691, Training Loss: 1.082e-01, Validation Loss: 4.136e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6692, Training Loss: 1.082e-01, Validation Loss: 4.136e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6693, Training Loss: 1.082e-01, Validation Loss: 4.136e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6694, Training Loss: 1.082e-01, Validation Loss: 4.136e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6695, Training Loss: 1.081e-01, Validation Loss: 4.136e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6696, Training Loss: 1.081e-01, Validation Loss: 4.135e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6697, Training Loss: 1.081e-01, Validation Loss: 4.135e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6698, Training Loss: 1.081e-01, Validation Loss: 4.135e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6699, Training Loss: 1.080e-01, Validation Loss: 4.135e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6700, Training Loss: 1.080e-01, Validation Loss: 4.135e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6701, Training Loss: 1.080e-01, Validation Loss: 4.135e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6702, Training Loss: 1.080e-01, Validation Loss: 4.134e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6703, Training Loss: 1.079e-01, Validation Loss: 4.134e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6704, Training Loss: 1.079e-01, Validation Loss: 4.134e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6705, Training Loss: 1.079e-01, Validation Loss: 4.134e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6706, Training Loss: 1.078e-01, Validation Loss: 4.134e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6707, Training Loss: 1.078e-01, Validation Loss: 4.134e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6708, Training Loss: 1.078e-01, Validation Loss: 4.134e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6709, Training Loss: 1.078e-01, Validation Loss: 4.133e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6710, Training Loss: 1.077e-01, Validation Loss: 4.133e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6711, Training Loss: 1.077e-01, Validation Loss: 4.133e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6712, Training Loss: 1.077e-01, Validation Loss: 4.133e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6713, Training Loss: 1.077e-01, Validation Loss: 4.133e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6714, Training Loss: 1.076e-01, Validation Loss: 4.133e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6715, Training Loss: 1.076e-01, Validation Loss: 4.132e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6716, Training Loss: 1.076e-01, Validation Loss: 4.133e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6717, Training Loss: 1.076e-01, Validation Loss: 4.132e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6718, Training Loss: 1.075e-01, Validation Loss: 4.132e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6719, Training Loss: 1.075e-01, Validation Loss: 4.132e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6720, Training Loss: 1.075e-01, Validation Loss: 4.132e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6721, Training Loss: 1.075e-01, Validation Loss: 4.132e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6722, Training Loss: 1.074e-01, Validation Loss: 4.132e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6723, Training Loss: 1.074e-01, Validation Loss: 4.132e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6724, Training Loss: 1.074e-01, Validation Loss: 4.132e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6725, Training Loss: 1.074e-01, Validation Loss: 4.131e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6726, Training Loss: 1.073e-01, Validation Loss: 4.131e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6727, Training Loss: 1.073e-01, Validation Loss: 4.131e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6728, Training Loss: 1.073e-01, Validation Loss: 4.131e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6729, Training Loss: 1.073e-01, Validation Loss: 4.131e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6730, Training Loss: 1.072e-01, Validation Loss: 4.131e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6731, Training Loss: 1.072e-01, Validation Loss: 4.130e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6732, Training Loss: 1.072e-01, Validation Loss: 4.131e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6733, Training Loss: 1.071e-01, Validation Loss: 4.130e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6734, Training Loss: 1.071e-01, Validation Loss: 4.130e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6735, Training Loss: 1.071e-01, Validation Loss: 4.130e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6736, Training Loss: 1.071e-01, Validation Loss: 4.130e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6737, Training Loss: 1.070e-01, Validation Loss: 4.130e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6738, Training Loss: 1.070e-01, Validation Loss: 4.130e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6739, Training Loss: 1.070e-01, Validation Loss: 4.129e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6740, Training Loss: 1.070e-01, Validation Loss: 4.129e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6741, Training Loss: 1.069e-01, Validation Loss: 4.129e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6742, Training Loss: 1.069e-01, Validation Loss: 4.129e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6743, Training Loss: 1.069e-01, Validation Loss: 4.129e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6744, Training Loss: 1.069e-01, Validation Loss: 4.129e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6745, Training Loss: 1.068e-01, Validation Loss: 4.129e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6746, Training Loss: 1.068e-01, Validation Loss: 4.128e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6747, Training Loss: 1.068e-01, Validation Loss: 4.128e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6748, Training Loss: 1.068e-01, Validation Loss: 4.128e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6749, Training Loss: 1.067e-01, Validation Loss: 4.128e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6750, Training Loss: 1.067e-01, Validation Loss: 4.128e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6751, Training Loss: 1.067e-01, Validation Loss: 4.128e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6752, Training Loss: 1.067e-01, Validation Loss: 4.128e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6753, Training Loss: 1.066e-01, Validation Loss: 4.127e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6754, Training Loss: 1.066e-01, Validation Loss: 4.127e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6755, Training Loss: 1.066e-01, Validation Loss: 4.127e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6756, Training Loss: 1.066e-01, Validation Loss: 4.127e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6757, Training Loss: 1.065e-01, Validation Loss: 4.127e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6758, Training Loss: 1.065e-01, Validation Loss: 4.127e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6759, Training Loss: 1.065e-01, Validation Loss: 4.127e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6760, Training Loss: 1.065e-01, Validation Loss: 4.126e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6761, Training Loss: 1.064e-01, Validation Loss: 4.126e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6762, Training Loss: 1.064e-01, Validation Loss: 4.126e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6763, Training Loss: 1.064e-01, Validation Loss: 4.126e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6764, Training Loss: 1.064e-01, Validation Loss: 4.126e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6765, Training Loss: 1.063e-01, Validation Loss: 4.126e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6766, Training Loss: 1.063e-01, Validation Loss: 4.126e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6767, Training Loss: 1.063e-01, Validation Loss: 4.126e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6768, Training Loss: 1.063e-01, Validation Loss: 4.125e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6769, Training Loss: 1.062e-01, Validation Loss: 4.125e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6770, Training Loss: 1.062e-01, Validation Loss: 4.125e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6771, Training Loss: 1.062e-01, Validation Loss: 4.125e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6772, Training Loss: 1.061e-01, Validation Loss: 4.125e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6773, Training Loss: 1.061e-01, Validation Loss: 4.125e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6774, Training Loss: 1.061e-01, Validation Loss: 4.125e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6775, Training Loss: 1.061e-01, Validation Loss: 4.124e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6776, Training Loss: 1.060e-01, Validation Loss: 4.124e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6777, Training Loss: 1.060e-01, Validation Loss: 4.124e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6778, Training Loss: 1.060e-01, Validation Loss: 4.124e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6779, Training Loss: 1.060e-01, Validation Loss: 4.124e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6780, Training Loss: 1.059e-01, Validation Loss: 4.124e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6781, Training Loss: 1.059e-01, Validation Loss: 4.124e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6782, Training Loss: 1.059e-01, Validation Loss: 4.123e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6783, Training Loss: 1.059e-01, Validation Loss: 4.123e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6784, Training Loss: 1.058e-01, Validation Loss: 4.123e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6785, Training Loss: 1.058e-01, Validation Loss: 4.123e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6786, Training Loss: 1.058e-01, Validation Loss: 4.123e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6787, Training Loss: 1.058e-01, Validation Loss: 4.123e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6788, Training Loss: 1.057e-01, Validation Loss: 4.123e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6789, Training Loss: 1.057e-01, Validation Loss: 4.122e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6790, Training Loss: 1.057e-01, Validation Loss: 4.122e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6791, Training Loss: 1.057e-01, Validation Loss: 4.122e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6792, Training Loss: 1.056e-01, Validation Loss: 4.122e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6793, Training Loss: 1.056e-01, Validation Loss: 4.122e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6794, Training Loss: 1.056e-01, Validation Loss: 4.122e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6795, Training Loss: 1.056e-01, Validation Loss: 4.122e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6796, Training Loss: 1.055e-01, Validation Loss: 4.122e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6797, Training Loss: 1.055e-01, Validation Loss: 4.121e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6798, Training Loss: 1.055e-01, Validation Loss: 4.122e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6799, Training Loss: 1.055e-01, Validation Loss: 4.121e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6800, Training Loss: 1.054e-01, Validation Loss: 4.121e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6801, Training Loss: 1.054e-01, Validation Loss: 4.121e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6802, Training Loss: 1.054e-01, Validation Loss: 4.121e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6803, Training Loss: 1.054e-01, Validation Loss: 4.121e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6804, Training Loss: 1.053e-01, Validation Loss: 4.121e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6805, Training Loss: 1.053e-01, Validation Loss: 4.120e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6806, Training Loss: 1.053e-01, Validation Loss: 4.120e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6807, Training Loss: 1.053e-01, Validation Loss: 4.120e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6808, Training Loss: 1.052e-01, Validation Loss: 4.120e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6809, Training Loss: 1.052e-01, Validation Loss: 4.120e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6810, Training Loss: 1.052e-01, Validation Loss: 4.120e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6811, Training Loss: 1.052e-01, Validation Loss: 4.120e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6812, Training Loss: 1.051e-01, Validation Loss: 4.119e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6813, Training Loss: 1.051e-01, Validation Loss: 4.119e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6814, Training Loss: 1.051e-01, Validation Loss: 4.119e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6815, Training Loss: 1.051e-01, Validation Loss: 4.119e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6816, Training Loss: 1.050e-01, Validation Loss: 4.119e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6817, Training Loss: 1.050e-01, Validation Loss: 4.119e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6818, Training Loss: 1.050e-01, Validation Loss: 4.119e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6819, Training Loss: 1.050e-01, Validation Loss: 4.119e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6820, Training Loss: 1.049e-01, Validation Loss: 4.119e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6821, Training Loss: 1.049e-01, Validation Loss: 4.118e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6822, Training Loss: 1.049e-01, Validation Loss: 4.118e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6823, Training Loss: 1.049e-01, Validation Loss: 4.118e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6824, Training Loss: 1.048e-01, Validation Loss: 4.118e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6825, Training Loss: 1.048e-01, Validation Loss: 4.118e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6826, Training Loss: 1.048e-01, Validation Loss: 4.118e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6827, Training Loss: 1.048e-01, Validation Loss: 4.118e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6828, Training Loss: 1.047e-01, Validation Loss: 4.117e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6829, Training Loss: 1.047e-01, Validation Loss: 4.117e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6830, Training Loss: 1.047e-01, Validation Loss: 4.117e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6831, Training Loss: 1.047e-01, Validation Loss: 4.117e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6832, Training Loss: 1.046e-01, Validation Loss: 4.117e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6833, Training Loss: 1.046e-01, Validation Loss: 4.117e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6834, Training Loss: 1.046e-01, Validation Loss: 4.117e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6835, Training Loss: 1.046e-01, Validation Loss: 4.117e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6836, Training Loss: 1.045e-01, Validation Loss: 4.116e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6837, Training Loss: 1.045e-01, Validation Loss: 4.116e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6838, Training Loss: 1.045e-01, Validation Loss: 4.116e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6839, Training Loss: 1.045e-01, Validation Loss: 4.116e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6840, Training Loss: 1.044e-01, Validation Loss: 4.116e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6841, Training Loss: 1.044e-01, Validation Loss: 4.116e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6842, Training Loss: 1.044e-01, Validation Loss: 4.116e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6843, Training Loss: 1.044e-01, Validation Loss: 4.115e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6844, Training Loss: 1.043e-01, Validation Loss: 4.115e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6845, Training Loss: 1.043e-01, Validation Loss: 4.115e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6846, Training Loss: 1.043e-01, Validation Loss: 4.115e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6847, Training Loss: 1.043e-01, Validation Loss: 4.115e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6848, Training Loss: 1.042e-01, Validation Loss: 4.115e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6849, Training Loss: 1.042e-01, Validation Loss: 4.115e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6850, Training Loss: 1.042e-01, Validation Loss: 4.115e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6851, Training Loss: 1.042e-01, Validation Loss: 4.114e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6852, Training Loss: 1.041e-01, Validation Loss: 4.114e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6853, Training Loss: 1.041e-01, Validation Loss: 4.114e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6854, Training Loss: 1.041e-01, Validation Loss: 4.114e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6855, Training Loss: 1.041e-01, Validation Loss: 4.114e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6856, Training Loss: 1.040e-01, Validation Loss: 4.114e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6857, Training Loss: 1.040e-01, Validation Loss: 4.114e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6858, Training Loss: 1.040e-01, Validation Loss: 4.114e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6859, Training Loss: 1.040e-01, Validation Loss: 4.113e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6860, Training Loss: 1.039e-01, Validation Loss: 4.113e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6861, Training Loss: 1.039e-01, Validation Loss: 4.113e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6862, Training Loss: 1.039e-01, Validation Loss: 4.113e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6863, Training Loss: 1.039e-01, Validation Loss: 4.113e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6864, Training Loss: 1.038e-01, Validation Loss: 4.113e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6865, Training Loss: 1.038e-01, Validation Loss: 4.113e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6866, Training Loss: 1.038e-01, Validation Loss: 4.113e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6867, Training Loss: 1.038e-01, Validation Loss: 4.112e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6868, Training Loss: 1.037e-01, Validation Loss: 4.112e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6869, Training Loss: 1.037e-01, Validation Loss: 4.112e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6870, Training Loss: 1.037e-01, Validation Loss: 4.112e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6871, Training Loss: 1.037e-01, Validation Loss: 4.112e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6872, Training Loss: 1.036e-01, Validation Loss: 4.112e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6873, Training Loss: 1.036e-01, Validation Loss: 4.112e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6874, Training Loss: 1.036e-01, Validation Loss: 4.112e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6875, Training Loss: 1.036e-01, Validation Loss: 4.111e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6876, Training Loss: 1.035e-01, Validation Loss: 4.111e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6877, Training Loss: 1.035e-01, Validation Loss: 4.111e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6878, Training Loss: 1.035e-01, Validation Loss: 4.111e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6879, Training Loss: 1.035e-01, Validation Loss: 4.111e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6880, Training Loss: 1.035e-01, Validation Loss: 4.111e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6881, Training Loss: 1.034e-01, Validation Loss: 4.111e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6882, Training Loss: 1.034e-01, Validation Loss: 4.110e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6883, Training Loss: 1.034e-01, Validation Loss: 4.110e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6884, Training Loss: 1.034e-01, Validation Loss: 4.110e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6885, Training Loss: 1.033e-01, Validation Loss: 4.110e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6886, Training Loss: 1.033e-01, Validation Loss: 4.110e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6887, Training Loss: 1.033e-01, Validation Loss: 4.110e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6888, Training Loss: 1.033e-01, Validation Loss: 4.110e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6889, Training Loss: 1.032e-01, Validation Loss: 4.109e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6890, Training Loss: 1.032e-01, Validation Loss: 4.110e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6891, Training Loss: 1.032e-01, Validation Loss: 4.109e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6892, Training Loss: 1.032e-01, Validation Loss: 4.109e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6893, Training Loss: 1.031e-01, Validation Loss: 4.109e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6894, Training Loss: 1.031e-01, Validation Loss: 4.109e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6895, Training Loss: 1.031e-01, Validation Loss: 4.109e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6896, Training Loss: 1.031e-01, Validation Loss: 4.109e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6897, Training Loss: 1.030e-01, Validation Loss: 4.108e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6898, Training Loss: 1.030e-01, Validation Loss: 4.108e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6899, Training Loss: 1.030e-01, Validation Loss: 4.108e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6900, Training Loss: 1.030e-01, Validation Loss: 4.108e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6901, Training Loss: 1.029e-01, Validation Loss: 4.108e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6902, Training Loss: 1.029e-01, Validation Loss: 4.108e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6903, Training Loss: 1.029e-01, Validation Loss: 4.108e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6904, Training Loss: 1.029e-01, Validation Loss: 4.108e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6905, Training Loss: 1.028e-01, Validation Loss: 4.108e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6906, Training Loss: 1.028e-01, Validation Loss: 4.107e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6907, Training Loss: 1.028e-01, Validation Loss: 4.107e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6908, Training Loss: 1.028e-01, Validation Loss: 4.107e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6909, Training Loss: 1.027e-01, Validation Loss: 4.107e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6910, Training Loss: 1.027e-01, Validation Loss: 4.107e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6911, Training Loss: 1.027e-01, Validation Loss: 4.107e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6912, Training Loss: 1.027e-01, Validation Loss: 4.107e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6913, Training Loss: 1.026e-01, Validation Loss: 4.107e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6914, Training Loss: 1.026e-01, Validation Loss: 4.106e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6915, Training Loss: 1.026e-01, Validation Loss: 4.106e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6916, Training Loss: 1.026e-01, Validation Loss: 4.106e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6917, Training Loss: 1.026e-01, Validation Loss: 4.106e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6918, Training Loss: 1.025e-01, Validation Loss: 4.106e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6919, Training Loss: 1.025e-01, Validation Loss: 4.106e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6920, Training Loss: 1.025e-01, Validation Loss: 4.106e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6921, Training Loss: 1.025e-01, Validation Loss: 4.106e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6922, Training Loss: 1.024e-01, Validation Loss: 4.105e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6923, Training Loss: 1.024e-01, Validation Loss: 4.105e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6924, Training Loss: 1.024e-01, Validation Loss: 4.105e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6925, Training Loss: 1.024e-01, Validation Loss: 4.105e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6926, Training Loss: 1.023e-01, Validation Loss: 4.105e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6927, Training Loss: 1.023e-01, Validation Loss: 4.105e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6928, Training Loss: 1.023e-01, Validation Loss: 4.105e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6929, Training Loss: 1.023e-01, Validation Loss: 4.105e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6930, Training Loss: 1.022e-01, Validation Loss: 4.104e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6931, Training Loss: 1.022e-01, Validation Loss: 4.104e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6932, Training Loss: 1.022e-01, Validation Loss: 4.104e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6933, Training Loss: 1.022e-01, Validation Loss: 4.104e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6934, Training Loss: 1.021e-01, Validation Loss: 4.104e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6935, Training Loss: 1.021e-01, Validation Loss: 4.104e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6936, Training Loss: 1.021e-01, Validation Loss: 4.104e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6937, Training Loss: 1.021e-01, Validation Loss: 4.104e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6938, Training Loss: 1.020e-01, Validation Loss: 4.103e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6939, Training Loss: 1.020e-01, Validation Loss: 4.103e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6940, Training Loss: 1.020e-01, Validation Loss: 4.103e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6941, Training Loss: 1.020e-01, Validation Loss: 4.103e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6942, Training Loss: 1.019e-01, Validation Loss: 4.103e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6943, Training Loss: 1.019e-01, Validation Loss: 4.103e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6944, Training Loss: 1.019e-01, Validation Loss: 4.103e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6945, Training Loss: 1.019e-01, Validation Loss: 4.102e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6946, Training Loss: 1.019e-01, Validation Loss: 4.102e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6947, Training Loss: 1.018e-01, Validation Loss: 4.102e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6948, Training Loss: 1.018e-01, Validation Loss: 4.102e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6949, Training Loss: 1.018e-01, Validation Loss: 4.102e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6950, Training Loss: 1.018e-01, Validation Loss: 4.102e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6951, Training Loss: 1.017e-01, Validation Loss: 4.102e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6952, Training Loss: 1.017e-01, Validation Loss: 4.101e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6953, Training Loss: 1.017e-01, Validation Loss: 4.102e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6954, Training Loss: 1.017e-01, Validation Loss: 4.101e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6955, Training Loss: 1.016e-01, Validation Loss: 4.101e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6956, Training Loss: 1.016e-01, Validation Loss: 4.101e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6957, Training Loss: 1.016e-01, Validation Loss: 4.101e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6958, Training Loss: 1.016e-01, Validation Loss: 4.101e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6959, Training Loss: 1.015e-01, Validation Loss: 4.101e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6960, Training Loss: 1.015e-01, Validation Loss: 4.100e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6961, Training Loss: 1.015e-01, Validation Loss: 4.101e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6962, Training Loss: 1.015e-01, Validation Loss: 4.100e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6963, Training Loss: 1.014e-01, Validation Loss: 4.101e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6964, Training Loss: 1.014e-01, Validation Loss: 4.100e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6965, Training Loss: 1.014e-01, Validation Loss: 4.100e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6966, Training Loss: 1.014e-01, Validation Loss: 4.100e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6967, Training Loss: 1.014e-01, Validation Loss: 4.100e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6968, Training Loss: 1.013e-01, Validation Loss: 4.100e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6969, Training Loss: 1.013e-01, Validation Loss: 4.099e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6970, Training Loss: 1.013e-01, Validation Loss: 4.099e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6971, Training Loss: 1.013e-01, Validation Loss: 4.099e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6972, Training Loss: 1.012e-01, Validation Loss: 4.099e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6973, Training Loss: 1.012e-01, Validation Loss: 4.099e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6974, Training Loss: 1.012e-01, Validation Loss: 4.099e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6975, Training Loss: 1.012e-01, Validation Loss: 4.099e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6976, Training Loss: 1.011e-01, Validation Loss: 4.099e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6977, Training Loss: 1.011e-01, Validation Loss: 4.099e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6978, Training Loss: 1.011e-01, Validation Loss: 4.098e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6979, Training Loss: 1.011e-01, Validation Loss: 4.098e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6980, Training Loss: 1.010e-01, Validation Loss: 4.098e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6981, Training Loss: 1.010e-01, Validation Loss: 4.098e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6982, Training Loss: 1.010e-01, Validation Loss: 4.098e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6983, Training Loss: 1.010e-01, Validation Loss: 4.098e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6984, Training Loss: 1.009e-01, Validation Loss: 4.098e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6985, Training Loss: 1.009e-01, Validation Loss: 4.098e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6986, Training Loss: 1.009e-01, Validation Loss: 4.097e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6987, Training Loss: 1.009e-01, Validation Loss: 4.097e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6988, Training Loss: 1.009e-01, Validation Loss: 4.097e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6989, Training Loss: 1.008e-01, Validation Loss: 4.097e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6990, Training Loss: 1.008e-01, Validation Loss: 4.097e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6991, Training Loss: 1.008e-01, Validation Loss: 4.097e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6992, Training Loss: 1.008e-01, Validation Loss: 4.097e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 6993, Training Loss: 1.007e-01, Validation Loss: 4.096e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6994, Training Loss: 1.007e-01, Validation Loss: 4.096e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6995, Training Loss: 1.007e-01, Validation Loss: 4.096e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6996, Training Loss: 1.007e-01, Validation Loss: 4.096e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6997, Training Loss: 1.006e-01, Validation Loss: 4.096e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6998, Training Loss: 1.006e-01, Validation Loss: 4.096e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 6999, Training Loss: 1.006e-01, Validation Loss: 4.096e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7000, Training Loss: 1.006e-01, Validation Loss: 4.096e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7001, Training Loss: 1.005e-01, Validation Loss: 4.095e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7002, Training Loss: 1.005e-01, Validation Loss: 4.095e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7003, Training Loss: 1.005e-01, Validation Loss: 4.095e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7004, Training Loss: 1.005e-01, Validation Loss: 4.095e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7005, Training Loss: 1.005e-01, Validation Loss: 4.095e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7006, Training Loss: 1.004e-01, Validation Loss: 4.095e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7007, Training Loss: 1.004e-01, Validation Loss: 4.095e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7008, Training Loss: 1.004e-01, Validation Loss: 4.095e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7009, Training Loss: 1.004e-01, Validation Loss: 4.094e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7010, Training Loss: 1.003e-01, Validation Loss: 4.094e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7011, Training Loss: 1.003e-01, Validation Loss: 4.094e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7012, Training Loss: 1.003e-01, Validation Loss: 4.094e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7013, Training Loss: 1.003e-01, Validation Loss: 4.094e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7014, Training Loss: 1.002e-01, Validation Loss: 4.094e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7015, Training Loss: 1.002e-01, Validation Loss: 4.094e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7016, Training Loss: 1.002e-01, Validation Loss: 4.093e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7017, Training Loss: 1.002e-01, Validation Loss: 4.094e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7018, Training Loss: 1.002e-01, Validation Loss: 4.093e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7019, Training Loss: 1.001e-01, Validation Loss: 4.093e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7020, Training Loss: 1.001e-01, Validation Loss: 4.093e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7021, Training Loss: 1.001e-01, Validation Loss: 4.093e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7022, Training Loss: 1.001e-01, Validation Loss: 4.093e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7023, Training Loss: 1.000e-01, Validation Loss: 4.093e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7024, Training Loss: 1.000e-01, Validation Loss: 4.093e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7025, Training Loss: 9.999e-02, Validation Loss: 4.093e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7026, Training Loss: 9.997e-02, Validation Loss: 4.092e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7027, Training Loss: 9.994e-02, Validation Loss: 4.092e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7028, Training Loss: 9.992e-02, Validation Loss: 4.092e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7029, Training Loss: 9.990e-02, Validation Loss: 4.092e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7030, Training Loss: 9.987e-02, Validation Loss: 4.092e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7031, Training Loss: 9.985e-02, Validation Loss: 4.092e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7032, Training Loss: 9.983e-02, Validation Loss: 4.092e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7033, Training Loss: 9.980e-02, Validation Loss: 4.092e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7034, Training Loss: 9.978e-02, Validation Loss: 4.091e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7035, Training Loss: 9.976e-02, Validation Loss: 4.091e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7036, Training Loss: 9.973e-02, Validation Loss: 4.091e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7037, Training Loss: 9.971e-02, Validation Loss: 4.091e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7038, Training Loss: 9.969e-02, Validation Loss: 4.091e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7039, Training Loss: 9.966e-02, Validation Loss: 4.091e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7040, Training Loss: 9.964e-02, Validation Loss: 4.091e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7041, Training Loss: 9.962e-02, Validation Loss: 4.090e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7042, Training Loss: 9.959e-02, Validation Loss: 4.091e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7043, Training Loss: 9.957e-02, Validation Loss: 4.090e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7044, Training Loss: 9.955e-02, Validation Loss: 4.090e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7045, Training Loss: 9.953e-02, Validation Loss: 4.090e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7046, Training Loss: 9.950e-02, Validation Loss: 4.090e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7047, Training Loss: 9.948e-02, Validation Loss: 4.090e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7048, Training Loss: 9.946e-02, Validation Loss: 4.090e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7049, Training Loss: 9.943e-02, Validation Loss: 4.090e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7050, Training Loss: 9.941e-02, Validation Loss: 4.090e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7051, Training Loss: 9.939e-02, Validation Loss: 4.089e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7052, Training Loss: 9.936e-02, Validation Loss: 4.089e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7053, Training Loss: 9.934e-02, Validation Loss: 4.089e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7054, Training Loss: 9.932e-02, Validation Loss: 4.089e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7055, Training Loss: 9.930e-02, Validation Loss: 4.089e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7056, Training Loss: 9.927e-02, Validation Loss: 4.089e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7057, Training Loss: 9.925e-02, Validation Loss: 4.089e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7058, Training Loss: 9.923e-02, Validation Loss: 4.089e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7059, Training Loss: 9.920e-02, Validation Loss: 4.088e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7060, Training Loss: 9.918e-02, Validation Loss: 4.088e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7061, Training Loss: 9.916e-02, Validation Loss: 4.088e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7062, Training Loss: 9.913e-02, Validation Loss: 4.088e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7063, Training Loss: 9.911e-02, Validation Loss: 4.088e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7064, Training Loss: 9.909e-02, Validation Loss: 4.088e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7065, Training Loss: 9.907e-02, Validation Loss: 4.088e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7066, Training Loss: 9.904e-02, Validation Loss: 4.088e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7067, Training Loss: 9.902e-02, Validation Loss: 4.087e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7068, Training Loss: 9.900e-02, Validation Loss: 4.088e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7069, Training Loss: 9.897e-02, Validation Loss: 4.087e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7070, Training Loss: 9.895e-02, Validation Loss: 4.087e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7071, Training Loss: 9.893e-02, Validation Loss: 4.087e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7072, Training Loss: 9.890e-02, Validation Loss: 4.087e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7073, Training Loss: 9.888e-02, Validation Loss: 4.087e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7074, Training Loss: 9.886e-02, Validation Loss: 4.087e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7075, Training Loss: 9.884e-02, Validation Loss: 4.086e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7076, Training Loss: 9.881e-02, Validation Loss: 4.086e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7077, Training Loss: 9.879e-02, Validation Loss: 4.086e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7078, Training Loss: 9.877e-02, Validation Loss: 4.086e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7079, Training Loss: 9.874e-02, Validation Loss: 4.086e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7080, Training Loss: 9.872e-02, Validation Loss: 4.086e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7081, Training Loss: 9.870e-02, Validation Loss: 4.086e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7082, Training Loss: 9.868e-02, Validation Loss: 4.086e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7083, Training Loss: 9.865e-02, Validation Loss: 4.085e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7084, Training Loss: 9.863e-02, Validation Loss: 4.085e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7085, Training Loss: 9.861e-02, Validation Loss: 4.085e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7086, Training Loss: 9.859e-02, Validation Loss: 4.085e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7087, Training Loss: 9.856e-02, Validation Loss: 4.085e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7088, Training Loss: 9.854e-02, Validation Loss: 4.085e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7089, Training Loss: 9.852e-02, Validation Loss: 4.085e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7090, Training Loss: 9.849e-02, Validation Loss: 4.085e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7091, Training Loss: 9.847e-02, Validation Loss: 4.085e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7092, Training Loss: 9.845e-02, Validation Loss: 4.084e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7093, Training Loss: 9.843e-02, Validation Loss: 4.084e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7094, Training Loss: 9.840e-02, Validation Loss: 4.084e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7095, Training Loss: 9.838e-02, Validation Loss: 4.084e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7096, Training Loss: 9.836e-02, Validation Loss: 4.084e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7097, Training Loss: 9.834e-02, Validation Loss: 4.084e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7098, Training Loss: 9.831e-02, Validation Loss: 4.084e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7099, Training Loss: 9.829e-02, Validation Loss: 4.084e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7100, Training Loss: 9.827e-02, Validation Loss: 4.084e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7101, Training Loss: 9.824e-02, Validation Loss: 4.083e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7102, Training Loss: 9.822e-02, Validation Loss: 4.084e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7103, Training Loss: 9.820e-02, Validation Loss: 4.083e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7104, Training Loss: 9.818e-02, Validation Loss: 4.083e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7105, Training Loss: 9.815e-02, Validation Loss: 4.083e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7106, Training Loss: 9.813e-02, Validation Loss: 4.083e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7107, Training Loss: 9.811e-02, Validation Loss: 4.083e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7108, Training Loss: 9.809e-02, Validation Loss: 4.083e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7109, Training Loss: 9.806e-02, Validation Loss: 4.083e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7110, Training Loss: 9.804e-02, Validation Loss: 4.082e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7111, Training Loss: 9.802e-02, Validation Loss: 4.083e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7112, Training Loss: 9.800e-02, Validation Loss: 4.082e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7113, Training Loss: 9.797e-02, Validation Loss: 4.082e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7114, Training Loss: 9.795e-02, Validation Loss: 4.082e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7115, Training Loss: 9.793e-02, Validation Loss: 4.082e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7116, Training Loss: 9.791e-02, Validation Loss: 4.082e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7117, Training Loss: 9.788e-02, Validation Loss: 4.082e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7118, Training Loss: 9.786e-02, Validation Loss: 4.081e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7119, Training Loss: 9.784e-02, Validation Loss: 4.081e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7120, Training Loss: 9.782e-02, Validation Loss: 4.081e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7121, Training Loss: 9.779e-02, Validation Loss: 4.081e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7122, Training Loss: 9.777e-02, Validation Loss: 4.081e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7123, Training Loss: 9.775e-02, Validation Loss: 4.081e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7124, Training Loss: 9.773e-02, Validation Loss: 4.081e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7125, Training Loss: 9.770e-02, Validation Loss: 4.081e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7126, Training Loss: 9.768e-02, Validation Loss: 4.080e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7127, Training Loss: 9.766e-02, Validation Loss: 4.081e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7128, Training Loss: 9.764e-02, Validation Loss: 4.080e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7129, Training Loss: 9.761e-02, Validation Loss: 4.080e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7130, Training Loss: 9.759e-02, Validation Loss: 4.080e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7131, Training Loss: 9.757e-02, Validation Loss: 4.080e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7132, Training Loss: 9.755e-02, Validation Loss: 4.080e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7133, Training Loss: 9.752e-02, Validation Loss: 4.080e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7134, Training Loss: 9.750e-02, Validation Loss: 4.079e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7135, Training Loss: 9.748e-02, Validation Loss: 4.080e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7136, Training Loss: 9.746e-02, Validation Loss: 4.079e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7137, Training Loss: 9.743e-02, Validation Loss: 4.079e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7138, Training Loss: 9.741e-02, Validation Loss: 4.079e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7139, Training Loss: 9.739e-02, Validation Loss: 4.079e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7140, Training Loss: 9.737e-02, Validation Loss: 4.079e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7141, Training Loss: 9.734e-02, Validation Loss: 4.079e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7142, Training Loss: 9.732e-02, Validation Loss: 4.079e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7143, Training Loss: 9.730e-02, Validation Loss: 4.079e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7144, Training Loss: 9.728e-02, Validation Loss: 4.079e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7145, Training Loss: 9.726e-02, Validation Loss: 4.078e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7146, Training Loss: 9.723e-02, Validation Loss: 4.078e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7147, Training Loss: 9.721e-02, Validation Loss: 4.078e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7148, Training Loss: 9.719e-02, Validation Loss: 4.078e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7149, Training Loss: 9.717e-02, Validation Loss: 4.078e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7150, Training Loss: 9.714e-02, Validation Loss: 4.078e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7151, Training Loss: 9.712e-02, Validation Loss: 4.078e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7152, Training Loss: 9.710e-02, Validation Loss: 4.077e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7153, Training Loss: 9.708e-02, Validation Loss: 4.078e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7154, Training Loss: 9.706e-02, Validation Loss: 4.077e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7155, Training Loss: 9.703e-02, Validation Loss: 4.077e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7156, Training Loss: 9.701e-02, Validation Loss: 4.077e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7157, Training Loss: 9.699e-02, Validation Loss: 4.077e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7158, Training Loss: 9.697e-02, Validation Loss: 4.077e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7159, Training Loss: 9.694e-02, Validation Loss: 4.077e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7160, Training Loss: 9.692e-02, Validation Loss: 4.077e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7161, Training Loss: 9.690e-02, Validation Loss: 4.076e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7162, Training Loss: 9.688e-02, Validation Loss: 4.077e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7163, Training Loss: 9.686e-02, Validation Loss: 4.076e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7164, Training Loss: 9.683e-02, Validation Loss: 4.076e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7165, Training Loss: 9.681e-02, Validation Loss: 4.076e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7166, Training Loss: 9.679e-02, Validation Loss: 4.076e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7167, Training Loss: 9.677e-02, Validation Loss: 4.076e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7168, Training Loss: 9.674e-02, Validation Loss: 4.076e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7169, Training Loss: 9.672e-02, Validation Loss: 4.076e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7170, Training Loss: 9.670e-02, Validation Loss: 4.076e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7171, Training Loss: 9.668e-02, Validation Loss: 4.075e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7172, Training Loss: 9.666e-02, Validation Loss: 4.075e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7173, Training Loss: 9.663e-02, Validation Loss: 4.075e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7174, Training Loss: 9.661e-02, Validation Loss: 4.075e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7175, Training Loss: 9.659e-02, Validation Loss: 4.075e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7176, Training Loss: 9.657e-02, Validation Loss: 4.075e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7177, Training Loss: 9.654e-02, Validation Loss: 4.075e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7178, Training Loss: 9.652e-02, Validation Loss: 4.075e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7179, Training Loss: 9.650e-02, Validation Loss: 4.074e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7180, Training Loss: 9.648e-02, Validation Loss: 4.074e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7181, Training Loss: 9.646e-02, Validation Loss: 4.074e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7182, Training Loss: 9.643e-02, Validation Loss: 4.074e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7183, Training Loss: 9.641e-02, Validation Loss: 4.074e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7184, Training Loss: 9.639e-02, Validation Loss: 4.074e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7185, Training Loss: 9.637e-02, Validation Loss: 4.074e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7186, Training Loss: 9.635e-02, Validation Loss: 4.073e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7187, Training Loss: 9.632e-02, Validation Loss: 4.074e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7188, Training Loss: 9.630e-02, Validation Loss: 4.073e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7189, Training Loss: 9.628e-02, Validation Loss: 4.073e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7190, Training Loss: 9.626e-02, Validation Loss: 4.073e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7191, Training Loss: 9.624e-02, Validation Loss: 4.073e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7192, Training Loss: 9.621e-02, Validation Loss: 4.073e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7193, Training Loss: 9.619e-02, Validation Loss: 4.073e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7194, Training Loss: 9.617e-02, Validation Loss: 4.073e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7195, Training Loss: 9.615e-02, Validation Loss: 4.073e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7196, Training Loss: 9.613e-02, Validation Loss: 4.073e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7197, Training Loss: 9.610e-02, Validation Loss: 4.072e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7198, Training Loss: 9.608e-02, Validation Loss: 4.072e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7199, Training Loss: 9.606e-02, Validation Loss: 4.072e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7200, Training Loss: 9.604e-02, Validation Loss: 4.072e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7201, Training Loss: 9.602e-02, Validation Loss: 4.072e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7202, Training Loss: 9.599e-02, Validation Loss: 4.072e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7203, Training Loss: 9.597e-02, Validation Loss: 4.072e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7204, Training Loss: 9.595e-02, Validation Loss: 4.072e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7205, Training Loss: 9.593e-02, Validation Loss: 4.072e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7206, Training Loss: 9.591e-02, Validation Loss: 4.071e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7207, Training Loss: 9.589e-02, Validation Loss: 4.071e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7208, Training Loss: 9.586e-02, Validation Loss: 4.071e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7209, Training Loss: 9.584e-02, Validation Loss: 4.071e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7210, Training Loss: 9.582e-02, Validation Loss: 4.071e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7211, Training Loss: 9.580e-02, Validation Loss: 4.071e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7212, Training Loss: 9.578e-02, Validation Loss: 4.071e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7213, Training Loss: 9.575e-02, Validation Loss: 4.071e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7214, Training Loss: 9.573e-02, Validation Loss: 4.071e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7215, Training Loss: 9.571e-02, Validation Loss: 4.070e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7216, Training Loss: 9.569e-02, Validation Loss: 4.070e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7217, Training Loss: 9.567e-02, Validation Loss: 4.070e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7218, Training Loss: 9.565e-02, Validation Loss: 4.070e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7219, Training Loss: 9.562e-02, Validation Loss: 4.070e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7220, Training Loss: 9.560e-02, Validation Loss: 4.070e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7221, Training Loss: 9.558e-02, Validation Loss: 4.070e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7222, Training Loss: 9.556e-02, Validation Loss: 4.070e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7223, Training Loss: 9.554e-02, Validation Loss: 4.069e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7224, Training Loss: 9.551e-02, Validation Loss: 4.070e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7225, Training Loss: 9.549e-02, Validation Loss: 4.069e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7226, Training Loss: 9.547e-02, Validation Loss: 4.069e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7227, Training Loss: 9.545e-02, Validation Loss: 4.069e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7228, Training Loss: 9.543e-02, Validation Loss: 4.069e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7229, Training Loss: 9.541e-02, Validation Loss: 4.069e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7230, Training Loss: 9.538e-02, Validation Loss: 4.069e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7231, Training Loss: 9.536e-02, Validation Loss: 4.069e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7232, Training Loss: 9.534e-02, Validation Loss: 4.069e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7233, Training Loss: 9.532e-02, Validation Loss: 4.069e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7234, Training Loss: 9.530e-02, Validation Loss: 4.068e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7235, Training Loss: 9.528e-02, Validation Loss: 4.069e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7236, Training Loss: 9.525e-02, Validation Loss: 4.068e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7237, Training Loss: 9.523e-02, Validation Loss: 4.068e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7238, Training Loss: 9.521e-02, Validation Loss: 4.068e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7239, Training Loss: 9.519e-02, Validation Loss: 4.068e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7240, Training Loss: 9.517e-02, Validation Loss: 4.068e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7241, Training Loss: 9.515e-02, Validation Loss: 4.068e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7242, Training Loss: 9.513e-02, Validation Loss: 4.068e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7243, Training Loss: 9.510e-02, Validation Loss: 4.068e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7244, Training Loss: 9.508e-02, Validation Loss: 4.067e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7245, Training Loss: 9.506e-02, Validation Loss: 4.067e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7246, Training Loss: 9.504e-02, Validation Loss: 4.067e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7247, Training Loss: 9.502e-02, Validation Loss: 4.067e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7248, Training Loss: 9.500e-02, Validation Loss: 4.067e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7249, Training Loss: 9.497e-02, Validation Loss: 4.067e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7250, Training Loss: 9.495e-02, Validation Loss: 4.067e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7251, Training Loss: 9.493e-02, Validation Loss: 4.067e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7252, Training Loss: 9.491e-02, Validation Loss: 4.067e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7253, Training Loss: 9.489e-02, Validation Loss: 4.066e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7254, Training Loss: 9.487e-02, Validation Loss: 4.067e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7255, Training Loss: 9.485e-02, Validation Loss: 4.066e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7256, Training Loss: 9.482e-02, Validation Loss: 4.066e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7257, Training Loss: 9.480e-02, Validation Loss: 4.066e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7258, Training Loss: 9.478e-02, Validation Loss: 4.066e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7259, Training Loss: 9.476e-02, Validation Loss: 4.066e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7260, Training Loss: 9.474e-02, Validation Loss: 4.066e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7261, Training Loss: 9.472e-02, Validation Loss: 4.066e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7262, Training Loss: 9.470e-02, Validation Loss: 4.066e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7263, Training Loss: 9.467e-02, Validation Loss: 4.065e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7264, Training Loss: 9.465e-02, Validation Loss: 4.065e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7265, Training Loss: 9.463e-02, Validation Loss: 4.065e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7266, Training Loss: 9.461e-02, Validation Loss: 4.065e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7267, Training Loss: 9.459e-02, Validation Loss: 4.065e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7268, Training Loss: 9.457e-02, Validation Loss: 4.065e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7269, Training Loss: 9.455e-02, Validation Loss: 4.065e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7270, Training Loss: 9.452e-02, Validation Loss: 4.065e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7271, Training Loss: 9.450e-02, Validation Loss: 4.065e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7272, Training Loss: 9.448e-02, Validation Loss: 4.065e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7273, Training Loss: 9.446e-02, Validation Loss: 4.064e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7274, Training Loss: 9.444e-02, Validation Loss: 4.065e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7275, Training Loss: 9.442e-02, Validation Loss: 4.064e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7276, Training Loss: 9.440e-02, Validation Loss: 4.064e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7277, Training Loss: 9.437e-02, Validation Loss: 4.064e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7278, Training Loss: 9.435e-02, Validation Loss: 4.064e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7279, Training Loss: 9.433e-02, Validation Loss: 4.064e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7280, Training Loss: 9.431e-02, Validation Loss: 4.064e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7281, Training Loss: 9.429e-02, Validation Loss: 4.064e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7282, Training Loss: 9.427e-02, Validation Loss: 4.064e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7283, Training Loss: 9.425e-02, Validation Loss: 4.063e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7284, Training Loss: 9.423e-02, Validation Loss: 4.063e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7285, Training Loss: 9.420e-02, Validation Loss: 4.063e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7286, Training Loss: 9.418e-02, Validation Loss: 4.063e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7287, Training Loss: 9.416e-02, Validation Loss: 4.063e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7288, Training Loss: 9.414e-02, Validation Loss: 4.063e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7289, Training Loss: 9.412e-02, Validation Loss: 4.063e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7290, Training Loss: 9.410e-02, Validation Loss: 4.063e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7291, Training Loss: 9.408e-02, Validation Loss: 4.063e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7292, Training Loss: 9.406e-02, Validation Loss: 4.062e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7293, Training Loss: 9.403e-02, Validation Loss: 4.062e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7294, Training Loss: 9.401e-02, Validation Loss: 4.062e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7295, Training Loss: 9.399e-02, Validation Loss: 4.062e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7296, Training Loss: 9.397e-02, Validation Loss: 4.062e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7297, Training Loss: 9.395e-02, Validation Loss: 4.062e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7298, Training Loss: 9.393e-02, Validation Loss: 4.062e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7299, Training Loss: 9.391e-02, Validation Loss: 4.062e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7300, Training Loss: 9.389e-02, Validation Loss: 4.062e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7301, Training Loss: 9.387e-02, Validation Loss: 4.062e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7302, Training Loss: 9.384e-02, Validation Loss: 4.062e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7303, Training Loss: 9.382e-02, Validation Loss: 4.061e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7304, Training Loss: 9.380e-02, Validation Loss: 4.061e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7305, Training Loss: 9.378e-02, Validation Loss: 4.061e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7306, Training Loss: 9.376e-02, Validation Loss: 4.061e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7307, Training Loss: 9.374e-02, Validation Loss: 4.061e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7308, Training Loss: 9.372e-02, Validation Loss: 4.061e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7309, Training Loss: 9.370e-02, Validation Loss: 4.061e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7310, Training Loss: 9.367e-02, Validation Loss: 4.061e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7311, Training Loss: 9.365e-02, Validation Loss: 4.061e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7312, Training Loss: 9.363e-02, Validation Loss: 4.060e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7313, Training Loss: 9.361e-02, Validation Loss: 4.061e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7314, Training Loss: 9.359e-02, Validation Loss: 4.060e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7315, Training Loss: 9.357e-02, Validation Loss: 4.060e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7316, Training Loss: 9.355e-02, Validation Loss: 4.060e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7317, Training Loss: 9.353e-02, Validation Loss: 4.060e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7318, Training Loss: 9.351e-02, Validation Loss: 4.060e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7319, Training Loss: 9.349e-02, Validation Loss: 4.060e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7320, Training Loss: 9.346e-02, Validation Loss: 4.060e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 7321, Training Loss: 9.344e-02, Validation Loss: 4.060e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7322, Training Loss: 9.342e-02, Validation Loss: 4.059e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7323, Training Loss: 9.340e-02, Validation Loss: 4.059e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7324, Training Loss: 9.338e-02, Validation Loss: 4.059e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7325, Training Loss: 9.336e-02, Validation Loss: 4.059e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7326, Training Loss: 9.334e-02, Validation Loss: 4.059e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7327, Training Loss: 9.332e-02, Validation Loss: 4.059e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7328, Training Loss: 9.330e-02, Validation Loss: 4.059e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7329, Training Loss: 9.328e-02, Validation Loss: 4.059e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7330, Training Loss: 9.325e-02, Validation Loss: 4.059e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7331, Training Loss: 9.323e-02, Validation Loss: 4.059e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7332, Training Loss: 9.321e-02, Validation Loss: 4.058e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7333, Training Loss: 9.319e-02, Validation Loss: 4.058e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7334, Training Loss: 9.317e-02, Validation Loss: 4.059e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7335, Training Loss: 9.315e-02, Validation Loss: 4.058e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7336, Training Loss: 9.313e-02, Validation Loss: 4.058e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7337, Training Loss: 9.311e-02, Validation Loss: 4.058e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7338, Training Loss: 9.309e-02, Validation Loss: 4.058e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7339, Training Loss: 9.307e-02, Validation Loss: 4.058e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7340, Training Loss: 9.305e-02, Validation Loss: 4.058e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7341, Training Loss: 9.303e-02, Validation Loss: 4.058e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7342, Training Loss: 9.300e-02, Validation Loss: 4.057e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7343, Training Loss: 9.298e-02, Validation Loss: 4.057e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7344, Training Loss: 9.296e-02, Validation Loss: 4.057e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7345, Training Loss: 9.294e-02, Validation Loss: 4.057e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7346, Training Loss: 9.292e-02, Validation Loss: 4.057e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7347, Training Loss: 9.290e-02, Validation Loss: 4.057e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7348, Training Loss: 9.288e-02, Validation Loss: 4.057e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7349, Training Loss: 9.286e-02, Validation Loss: 4.057e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7350, Training Loss: 9.284e-02, Validation Loss: 4.056e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7351, Training Loss: 9.282e-02, Validation Loss: 4.057e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7352, Training Loss: 9.280e-02, Validation Loss: 4.056e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7353, Training Loss: 9.278e-02, Validation Loss: 4.056e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7354, Training Loss: 9.275e-02, Validation Loss: 4.056e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7355, Training Loss: 9.273e-02, Validation Loss: 4.056e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7356, Training Loss: 9.271e-02, Validation Loss: 4.056e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7357, Training Loss: 9.269e-02, Validation Loss: 4.056e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7358, Training Loss: 9.267e-02, Validation Loss: 4.056e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7359, Training Loss: 9.265e-02, Validation Loss: 4.056e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7360, Training Loss: 9.263e-02, Validation Loss: 4.055e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7361, Training Loss: 9.261e-02, Validation Loss: 4.056e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7362, Training Loss: 9.259e-02, Validation Loss: 4.055e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7363, Training Loss: 9.257e-02, Validation Loss: 4.055e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7364, Training Loss: 9.255e-02, Validation Loss: 4.055e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7365, Training Loss: 9.253e-02, Validation Loss: 4.055e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7366, Training Loss: 9.251e-02, Validation Loss: 4.055e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7367, Training Loss: 9.249e-02, Validation Loss: 4.055e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7368, Training Loss: 9.246e-02, Validation Loss: 4.055e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7369, Training Loss: 9.244e-02, Validation Loss: 4.055e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7370, Training Loss: 9.242e-02, Validation Loss: 4.055e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7371, Training Loss: 9.240e-02, Validation Loss: 4.055e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7372, Training Loss: 9.238e-02, Validation Loss: 4.054e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7373, Training Loss: 9.236e-02, Validation Loss: 4.054e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7374, Training Loss: 9.234e-02, Validation Loss: 4.054e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7375, Training Loss: 9.232e-02, Validation Loss: 4.054e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7376, Training Loss: 9.230e-02, Validation Loss: 4.054e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7377, Training Loss: 9.228e-02, Validation Loss: 4.054e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7378, Training Loss: 9.226e-02, Validation Loss: 4.054e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7379, Training Loss: 9.224e-02, Validation Loss: 4.054e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7380, Training Loss: 9.222e-02, Validation Loss: 4.054e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7381, Training Loss: 9.220e-02, Validation Loss: 4.054e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7382, Training Loss: 9.218e-02, Validation Loss: 4.053e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7383, Training Loss: 9.216e-02, Validation Loss: 4.053e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7384, Training Loss: 9.213e-02, Validation Loss: 4.053e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7385, Training Loss: 9.211e-02, Validation Loss: 4.053e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7386, Training Loss: 9.209e-02, Validation Loss: 4.053e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7387, Training Loss: 9.207e-02, Validation Loss: 4.053e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7388, Training Loss: 9.205e-02, Validation Loss: 4.053e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7389, Training Loss: 9.203e-02, Validation Loss: 4.053e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7390, Training Loss: 9.201e-02, Validation Loss: 4.053e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7391, Training Loss: 9.199e-02, Validation Loss: 4.052e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7392, Training Loss: 9.197e-02, Validation Loss: 4.053e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7393, Training Loss: 9.195e-02, Validation Loss: 4.052e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7394, Training Loss: 9.193e-02, Validation Loss: 4.052e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7395, Training Loss: 9.191e-02, Validation Loss: 4.052e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7396, Training Loss: 9.189e-02, Validation Loss: 4.052e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7397, Training Loss: 9.187e-02, Validation Loss: 4.052e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7398, Training Loss: 9.185e-02, Validation Loss: 4.052e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7399, Training Loss: 9.183e-02, Validation Loss: 4.052e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7400, Training Loss: 9.181e-02, Validation Loss: 4.052e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7401, Training Loss: 9.179e-02, Validation Loss: 4.051e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7402, Training Loss: 9.177e-02, Validation Loss: 4.052e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7403, Training Loss: 9.175e-02, Validation Loss: 4.051e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7404, Training Loss: 9.173e-02, Validation Loss: 4.051e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7405, Training Loss: 9.170e-02, Validation Loss: 4.051e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7406, Training Loss: 9.168e-02, Validation Loss: 4.051e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7407, Training Loss: 9.166e-02, Validation Loss: 4.051e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7408, Training Loss: 9.164e-02, Validation Loss: 4.051e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7409, Training Loss: 9.162e-02, Validation Loss: 4.051e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7410, Training Loss: 9.160e-02, Validation Loss: 4.051e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7411, Training Loss: 9.158e-02, Validation Loss: 4.050e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7412, Training Loss: 9.156e-02, Validation Loss: 4.051e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7413, Training Loss: 9.154e-02, Validation Loss: 4.050e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7414, Training Loss: 9.152e-02, Validation Loss: 4.050e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7415, Training Loss: 9.150e-02, Validation Loss: 4.050e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 7416, Training Loss: 9.148e-02, Validation Loss: 4.050e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7417, Training Loss: 9.146e-02, Validation Loss: 4.050e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7418, Training Loss: 9.144e-02, Validation Loss: 4.050e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7419, Training Loss: 9.142e-02, Validation Loss: 4.050e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7420, Training Loss: 9.140e-02, Validation Loss: 4.050e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7421, Training Loss: 9.138e-02, Validation Loss: 4.049e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7422, Training Loss: 9.136e-02, Validation Loss: 4.050e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7423, Training Loss: 9.134e-02, Validation Loss: 4.049e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7424, Training Loss: 9.132e-02, Validation Loss: 4.050e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7425, Training Loss: 9.130e-02, Validation Loss: 4.049e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7426, Training Loss: 9.128e-02, Validation Loss: 4.049e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7427, Training Loss: 9.126e-02, Validation Loss: 4.049e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7428, Training Loss: 9.124e-02, Validation Loss: 4.049e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7429, Training Loss: 9.122e-02, Validation Loss: 4.049e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7430, Training Loss: 9.120e-02, Validation Loss: 4.049e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7431, Training Loss: 9.118e-02, Validation Loss: 4.049e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7432, Training Loss: 9.116e-02, Validation Loss: 4.049e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7433, Training Loss: 9.114e-02, Validation Loss: 4.049e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7434, Training Loss: 9.112e-02, Validation Loss: 4.048e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7435, Training Loss: 9.110e-02, Validation Loss: 4.048e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7436, Training Loss: 9.108e-02, Validation Loss: 4.048e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7437, Training Loss: 9.106e-02, Validation Loss: 4.048e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7438, Training Loss: 9.104e-02, Validation Loss: 4.048e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7439, Training Loss: 9.101e-02, Validation Loss: 4.048e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7440, Training Loss: 9.100e-02, Validation Loss: 4.048e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7441, Training Loss: 9.097e-02, Validation Loss: 4.048e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7442, Training Loss: 9.095e-02, Validation Loss: 4.048e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7443, Training Loss: 9.093e-02, Validation Loss: 4.048e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7444, Training Loss: 9.091e-02, Validation Loss: 4.047e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7445, Training Loss: 9.089e-02, Validation Loss: 4.047e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7446, Training Loss: 9.087e-02, Validation Loss: 4.047e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7447, Training Loss: 9.085e-02, Validation Loss: 4.047e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7448, Training Loss: 9.083e-02, Validation Loss: 4.047e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7449, Training Loss: 9.081e-02, Validation Loss: 4.047e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7450, Training Loss: 9.079e-02, Validation Loss: 4.047e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7451, Training Loss: 9.077e-02, Validation Loss: 4.047e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7452, Training Loss: 9.075e-02, Validation Loss: 4.047e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7453, Training Loss: 9.073e-02, Validation Loss: 4.047e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7454, Training Loss: 9.071e-02, Validation Loss: 4.046e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7455, Training Loss: 9.069e-02, Validation Loss: 4.046e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7456, Training Loss: 9.067e-02, Validation Loss: 4.046e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7457, Training Loss: 9.065e-02, Validation Loss: 4.046e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7458, Training Loss: 9.063e-02, Validation Loss: 4.046e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7459, Training Loss: 9.061e-02, Validation Loss: 4.046e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7460, Training Loss: 9.059e-02, Validation Loss: 4.046e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7461, Training Loss: 9.057e-02, Validation Loss: 4.046e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7462, Training Loss: 9.055e-02, Validation Loss: 4.046e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7463, Training Loss: 9.053e-02, Validation Loss: 4.046e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7464, Training Loss: 9.051e-02, Validation Loss: 4.046e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7465, Training Loss: 9.049e-02, Validation Loss: 4.045e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7466, Training Loss: 9.047e-02, Validation Loss: 4.045e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7467, Training Loss: 9.045e-02, Validation Loss: 4.045e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 7468, Training Loss: 9.043e-02, Validation Loss: 4.045e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7469, Training Loss: 9.041e-02, Validation Loss: 4.045e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7470, Training Loss: 9.039e-02, Validation Loss: 4.045e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7471, Training Loss: 9.037e-02, Validation Loss: 4.045e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7472, Training Loss: 9.035e-02, Validation Loss: 4.045e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7473, Training Loss: 9.033e-02, Validation Loss: 4.045e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7474, Training Loss: 9.031e-02, Validation Loss: 4.045e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7475, Training Loss: 9.029e-02, Validation Loss: 4.045e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7476, Training Loss: 9.027e-02, Validation Loss: 4.044e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7477, Training Loss: 9.025e-02, Validation Loss: 4.044e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7478, Training Loss: 9.023e-02, Validation Loss: 4.044e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7479, Training Loss: 9.021e-02, Validation Loss: 4.044e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7480, Training Loss: 9.019e-02, Validation Loss: 4.044e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7481, Training Loss: 9.017e-02, Validation Loss: 4.044e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7482, Training Loss: 9.015e-02, Validation Loss: 4.044e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7483, Training Loss: 9.013e-02, Validation Loss: 4.044e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7484, Training Loss: 9.011e-02, Validation Loss: 4.044e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7485, Training Loss: 9.009e-02, Validation Loss: 4.044e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7486, Training Loss: 9.007e-02, Validation Loss: 4.044e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7487, Training Loss: 9.005e-02, Validation Loss: 4.044e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7488, Training Loss: 9.003e-02, Validation Loss: 4.043e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7489, Training Loss: 9.001e-02, Validation Loss: 4.043e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7490, Training Loss: 8.999e-02, Validation Loss: 4.043e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7491, Training Loss: 8.998e-02, Validation Loss: 4.043e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7492, Training Loss: 8.996e-02, Validation Loss: 4.043e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7493, Training Loss: 8.994e-02, Validation Loss: 4.043e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7494, Training Loss: 8.992e-02, Validation Loss: 4.043e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7495, Training Loss: 8.990e-02, Validation Loss: 4.043e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7496, Training Loss: 8.988e-02, Validation Loss: 4.043e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7497, Training Loss: 8.986e-02, Validation Loss: 4.043e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7498, Training Loss: 8.984e-02, Validation Loss: 4.042e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7499, Training Loss: 8.982e-02, Validation Loss: 4.042e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7500, Training Loss: 8.980e-02, Validation Loss: 4.042e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7501, Training Loss: 8.978e-02, Validation Loss: 4.042e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7502, Training Loss: 8.976e-02, Validation Loss: 4.042e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7503, Training Loss: 8.974e-02, Validation Loss: 4.042e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7504, Training Loss: 8.972e-02, Validation Loss: 4.042e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7505, Training Loss: 8.970e-02, Validation Loss: 4.042e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7506, Training Loss: 8.968e-02, Validation Loss: 4.042e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7507, Training Loss: 8.966e-02, Validation Loss: 4.042e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7508, Training Loss: 8.964e-02, Validation Loss: 4.041e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7509, Training Loss: 8.962e-02, Validation Loss: 4.041e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7510, Training Loss: 8.960e-02, Validation Loss: 4.041e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7511, Training Loss: 8.958e-02, Validation Loss: 4.041e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7512, Training Loss: 8.956e-02, Validation Loss: 4.041e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7513, Training Loss: 8.954e-02, Validation Loss: 4.041e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7514, Training Loss: 8.952e-02, Validation Loss: 4.041e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7515, Training Loss: 8.950e-02, Validation Loss: 4.041e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7516, Training Loss: 8.948e-02, Validation Loss: 4.041e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7517, Training Loss: 8.946e-02, Validation Loss: 4.041e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7518, Training Loss: 8.944e-02, Validation Loss: 4.041e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7519, Training Loss: 8.942e-02, Validation Loss: 4.040e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7520, Training Loss: 8.940e-02, Validation Loss: 4.040e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7521, Training Loss: 8.938e-02, Validation Loss: 4.040e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7522, Training Loss: 8.936e-02, Validation Loss: 4.040e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7523, Training Loss: 8.934e-02, Validation Loss: 4.040e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7524, Training Loss: 8.932e-02, Validation Loss: 4.040e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7525, Training Loss: 8.930e-02, Validation Loss: 4.040e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 7526, Training Loss: 8.928e-02, Validation Loss: 4.040e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7527, Training Loss: 8.927e-02, Validation Loss: 4.040e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7528, Training Loss: 8.925e-02, Validation Loss: 4.039e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7529, Training Loss: 8.923e-02, Validation Loss: 4.040e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7530, Training Loss: 8.921e-02, Validation Loss: 4.039e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7531, Training Loss: 8.919e-02, Validation Loss: 4.039e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7532, Training Loss: 8.917e-02, Validation Loss: 4.039e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7533, Training Loss: 8.915e-02, Validation Loss: 4.039e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7534, Training Loss: 8.913e-02, Validation Loss: 4.039e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7535, Training Loss: 8.911e-02, Validation Loss: 4.039e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7536, Training Loss: 8.909e-02, Validation Loss: 4.039e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7537, Training Loss: 8.907e-02, Validation Loss: 4.039e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7538, Training Loss: 8.905e-02, Validation Loss: 4.039e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7539, Training Loss: 8.903e-02, Validation Loss: 4.039e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7540, Training Loss: 8.901e-02, Validation Loss: 4.038e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7541, Training Loss: 8.899e-02, Validation Loss: 4.039e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7542, Training Loss: 8.897e-02, Validation Loss: 4.038e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7543, Training Loss: 8.895e-02, Validation Loss: 4.038e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7544, Training Loss: 8.893e-02, Validation Loss: 4.038e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7545, Training Loss: 8.891e-02, Validation Loss: 4.038e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7546, Training Loss: 8.889e-02, Validation Loss: 4.038e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7547, Training Loss: 8.887e-02, Validation Loss: 4.038e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7548, Training Loss: 8.886e-02, Validation Loss: 4.038e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7549, Training Loss: 8.884e-02, Validation Loss: 4.038e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7550, Training Loss: 8.882e-02, Validation Loss: 4.037e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7551, Training Loss: 8.880e-02, Validation Loss: 4.038e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7552, Training Loss: 8.878e-02, Validation Loss: 4.037e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7553, Training Loss: 8.876e-02, Validation Loss: 4.037e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7554, Training Loss: 8.874e-02, Validation Loss: 4.037e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7555, Training Loss: 8.872e-02, Validation Loss: 4.037e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7556, Training Loss: 8.870e-02, Validation Loss: 4.037e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7557, Training Loss: 8.868e-02, Validation Loss: 4.037e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7558, Training Loss: 8.866e-02, Validation Loss: 4.037e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7559, Training Loss: 8.864e-02, Validation Loss: 4.037e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7560, Training Loss: 8.862e-02, Validation Loss: 4.037e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7561, Training Loss: 8.860e-02, Validation Loss: 4.037e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7562, Training Loss: 8.858e-02, Validation Loss: 4.037e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7563, Training Loss: 8.856e-02, Validation Loss: 4.037e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7564, Training Loss: 8.854e-02, Validation Loss: 4.036e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7565, Training Loss: 8.853e-02, Validation Loss: 4.036e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7566, Training Loss: 8.851e-02, Validation Loss: 4.036e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7567, Training Loss: 8.849e-02, Validation Loss: 4.036e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7568, Training Loss: 8.847e-02, Validation Loss: 4.036e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 7569, Training Loss: 8.845e-02, Validation Loss: 4.036e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7570, Training Loss: 8.843e-02, Validation Loss: 4.036e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7571, Training Loss: 8.841e-02, Validation Loss: 4.036e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7572, Training Loss: 8.839e-02, Validation Loss: 4.036e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7573, Training Loss: 8.837e-02, Validation Loss: 4.036e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7574, Training Loss: 8.835e-02, Validation Loss: 4.035e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7575, Training Loss: 8.833e-02, Validation Loss: 4.035e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7576, Training Loss: 8.831e-02, Validation Loss: 4.035e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7577, Training Loss: 8.829e-02, Validation Loss: 4.035e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7578, Training Loss: 8.827e-02, Validation Loss: 4.035e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7579, Training Loss: 8.826e-02, Validation Loss: 4.035e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7580, Training Loss: 8.824e-02, Validation Loss: 4.035e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7581, Training Loss: 8.822e-02, Validation Loss: 4.035e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7582, Training Loss: 8.820e-02, Validation Loss: 4.035e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7583, Training Loss: 8.818e-02, Validation Loss: 4.035e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7584, Training Loss: 8.816e-02, Validation Loss: 4.035e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7585, Training Loss: 8.814e-02, Validation Loss: 4.034e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7586, Training Loss: 8.812e-02, Validation Loss: 4.035e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7587, Training Loss: 8.810e-02, Validation Loss: 4.034e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7588, Training Loss: 8.808e-02, Validation Loss: 4.034e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7589, Training Loss: 8.806e-02, Validation Loss: 4.034e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7590, Training Loss: 8.804e-02, Validation Loss: 4.034e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7591, Training Loss: 8.802e-02, Validation Loss: 4.034e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7592, Training Loss: 8.801e-02, Validation Loss: 4.034e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7593, Training Loss: 8.799e-02, Validation Loss: 4.034e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7594, Training Loss: 8.797e-02, Validation Loss: 4.034e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7595, Training Loss: 8.795e-02, Validation Loss: 4.034e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7596, Training Loss: 8.793e-02, Validation Loss: 4.034e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7597, Training Loss: 8.791e-02, Validation Loss: 4.034e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7598, Training Loss: 8.789e-02, Validation Loss: 4.033e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7599, Training Loss: 8.787e-02, Validation Loss: 4.033e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7600, Training Loss: 8.785e-02, Validation Loss: 4.033e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7601, Training Loss: 8.783e-02, Validation Loss: 4.033e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7602, Training Loss: 8.781e-02, Validation Loss: 4.033e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7603, Training Loss: 8.780e-02, Validation Loss: 4.033e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7604, Training Loss: 8.778e-02, Validation Loss: 4.033e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7605, Training Loss: 8.776e-02, Validation Loss: 4.033e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7606, Training Loss: 8.774e-02, Validation Loss: 4.033e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7607, Training Loss: 8.772e-02, Validation Loss: 4.033e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7608, Training Loss: 8.770e-02, Validation Loss: 4.032e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7609, Training Loss: 8.768e-02, Validation Loss: 4.032e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7610, Training Loss: 8.766e-02, Validation Loss: 4.032e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7611, Training Loss: 8.764e-02, Validation Loss: 4.032e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7612, Training Loss: 8.762e-02, Validation Loss: 4.032e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7613, Training Loss: 8.760e-02, Validation Loss: 4.032e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7614, Training Loss: 8.759e-02, Validation Loss: 4.032e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7615, Training Loss: 8.757e-02, Validation Loss: 4.032e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7616, Training Loss: 8.755e-02, Validation Loss: 4.032e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7617, Training Loss: 8.753e-02, Validation Loss: 4.032e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7618, Training Loss: 8.751e-02, Validation Loss: 4.032e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7619, Training Loss: 8.749e-02, Validation Loss: 4.031e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7620, Training Loss: 8.747e-02, Validation Loss: 4.031e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7621, Training Loss: 8.745e-02, Validation Loss: 4.031e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7622, Training Loss: 8.743e-02, Validation Loss: 4.031e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7623, Training Loss: 8.741e-02, Validation Loss: 4.031e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7624, Training Loss: 8.740e-02, Validation Loss: 4.031e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7625, Training Loss: 8.738e-02, Validation Loss: 4.031e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7626, Training Loss: 8.736e-02, Validation Loss: 4.031e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7627, Training Loss: 8.734e-02, Validation Loss: 4.031e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7628, Training Loss: 8.732e-02, Validation Loss: 4.031e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7629, Training Loss: 8.730e-02, Validation Loss: 4.031e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7630, Training Loss: 8.728e-02, Validation Loss: 4.031e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7631, Training Loss: 8.726e-02, Validation Loss: 4.030e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7632, Training Loss: 8.724e-02, Validation Loss: 4.030e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7633, Training Loss: 8.723e-02, Validation Loss: 4.030e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7634, Training Loss: 8.721e-02, Validation Loss: 4.030e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7635, Training Loss: 8.719e-02, Validation Loss: 4.030e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7636, Training Loss: 8.717e-02, Validation Loss: 4.030e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7637, Training Loss: 8.715e-02, Validation Loss: 4.030e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7638, Training Loss: 8.713e-02, Validation Loss: 4.030e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7639, Training Loss: 8.711e-02, Validation Loss: 4.030e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7640, Training Loss: 8.709e-02, Validation Loss: 4.030e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7641, Training Loss: 8.707e-02, Validation Loss: 4.030e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7642, Training Loss: 8.705e-02, Validation Loss: 4.030e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7643, Training Loss: 8.704e-02, Validation Loss: 4.029e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7644, Training Loss: 8.702e-02, Validation Loss: 4.029e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7645, Training Loss: 8.700e-02, Validation Loss: 4.029e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7646, Training Loss: 8.698e-02, Validation Loss: 4.029e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7647, Training Loss: 8.696e-02, Validation Loss: 4.029e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 7648, Training Loss: 8.694e-02, Validation Loss: 4.029e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7649, Training Loss: 8.692e-02, Validation Loss: 4.029e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7650, Training Loss: 8.690e-02, Validation Loss: 4.029e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7651, Training Loss: 8.689e-02, Validation Loss: 4.029e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7652, Training Loss: 8.687e-02, Validation Loss: 4.029e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7653, Training Loss: 8.685e-02, Validation Loss: 4.029e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7654, Training Loss: 8.683e-02, Validation Loss: 4.028e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7655, Training Loss: 8.681e-02, Validation Loss: 4.029e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7656, Training Loss: 8.679e-02, Validation Loss: 4.028e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7657, Training Loss: 8.677e-02, Validation Loss: 4.028e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7658, Training Loss: 8.675e-02, Validation Loss: 4.028e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7659, Training Loss: 8.674e-02, Validation Loss: 4.028e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7660, Training Loss: 8.672e-02, Validation Loss: 4.028e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7661, Training Loss: 8.670e-02, Validation Loss: 4.028e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7662, Training Loss: 8.668e-02, Validation Loss: 4.028e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7663, Training Loss: 8.666e-02, Validation Loss: 4.028e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7664, Training Loss: 8.664e-02, Validation Loss: 4.028e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7665, Training Loss: 8.662e-02, Validation Loss: 4.028e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7666, Training Loss: 8.660e-02, Validation Loss: 4.027e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7667, Training Loss: 8.659e-02, Validation Loss: 4.027e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7668, Training Loss: 8.657e-02, Validation Loss: 4.027e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7669, Training Loss: 8.655e-02, Validation Loss: 4.027e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7670, Training Loss: 8.653e-02, Validation Loss: 4.027e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7671, Training Loss: 8.651e-02, Validation Loss: 4.027e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7672, Training Loss: 8.649e-02, Validation Loss: 4.027e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7673, Training Loss: 8.647e-02, Validation Loss: 4.027e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7674, Training Loss: 8.645e-02, Validation Loss: 4.027e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7675, Training Loss: 8.644e-02, Validation Loss: 4.027e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7676, Training Loss: 8.642e-02, Validation Loss: 4.027e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7677, Training Loss: 8.640e-02, Validation Loss: 4.027e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7678, Training Loss: 8.638e-02, Validation Loss: 4.026e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7679, Training Loss: 8.636e-02, Validation Loss: 4.026e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7680, Training Loss: 8.634e-02, Validation Loss: 4.026e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7681, Training Loss: 8.632e-02, Validation Loss: 4.026e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7682, Training Loss: 8.631e-02, Validation Loss: 4.026e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7683, Training Loss: 8.629e-02, Validation Loss: 4.026e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7684, Training Loss: 8.627e-02, Validation Loss: 4.026e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7685, Training Loss: 8.625e-02, Validation Loss: 4.026e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7686, Training Loss: 8.623e-02, Validation Loss: 4.026e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7687, Training Loss: 8.621e-02, Validation Loss: 4.026e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7688, Training Loss: 8.619e-02, Validation Loss: 4.026e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7689, Training Loss: 8.618e-02, Validation Loss: 4.025e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7690, Training Loss: 8.616e-02, Validation Loss: 4.025e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7691, Training Loss: 8.614e-02, Validation Loss: 4.025e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7692, Training Loss: 8.612e-02, Validation Loss: 4.025e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7693, Training Loss: 8.610e-02, Validation Loss: 4.025e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7694, Training Loss: 8.608e-02, Validation Loss: 4.025e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7695, Training Loss: 8.606e-02, Validation Loss: 4.025e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7696, Training Loss: 8.605e-02, Validation Loss: 4.025e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7697, Training Loss: 8.603e-02, Validation Loss: 4.025e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7698, Training Loss: 8.601e-02, Validation Loss: 4.025e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7699, Training Loss: 8.599e-02, Validation Loss: 4.025e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7700, Training Loss: 8.597e-02, Validation Loss: 4.025e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7701, Training Loss: 8.595e-02, Validation Loss: 4.025e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7702, Training Loss: 8.593e-02, Validation Loss: 4.024e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7703, Training Loss: 8.592e-02, Validation Loss: 4.024e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7704, Training Loss: 8.590e-02, Validation Loss: 4.024e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7705, Training Loss: 8.588e-02, Validation Loss: 4.024e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7706, Training Loss: 8.586e-02, Validation Loss: 4.024e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7707, Training Loss: 8.584e-02, Validation Loss: 4.024e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7708, Training Loss: 8.582e-02, Validation Loss: 4.024e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7709, Training Loss: 8.581e-02, Validation Loss: 4.024e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 7710, Training Loss: 8.579e-02, Validation Loss: 4.024e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7711, Training Loss: 8.577e-02, Validation Loss: 4.024e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7712, Training Loss: 8.575e-02, Validation Loss: 4.024e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7713, Training Loss: 8.573e-02, Validation Loss: 4.024e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7714, Training Loss: 8.571e-02, Validation Loss: 4.023e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7715, Training Loss: 8.569e-02, Validation Loss: 4.023e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7716, Training Loss: 8.568e-02, Validation Loss: 4.023e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7717, Training Loss: 8.566e-02, Validation Loss: 4.023e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7718, Training Loss: 8.564e-02, Validation Loss: 4.023e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7719, Training Loss: 8.562e-02, Validation Loss: 4.023e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7720, Training Loss: 8.560e-02, Validation Loss: 4.023e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 7721, Training Loss: 8.558e-02, Validation Loss: 4.023e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7722, Training Loss: 8.557e-02, Validation Loss: 4.023e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7723, Training Loss: 8.555e-02, Validation Loss: 4.023e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7724, Training Loss: 8.553e-02, Validation Loss: 4.023e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7725, Training Loss: 8.551e-02, Validation Loss: 4.023e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7726, Training Loss: 8.549e-02, Validation Loss: 4.022e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7727, Training Loss: 8.547e-02, Validation Loss: 4.023e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7728, Training Loss: 8.546e-02, Validation Loss: 4.022e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7729, Training Loss: 8.544e-02, Validation Loss: 4.022e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7730, Training Loss: 8.542e-02, Validation Loss: 4.022e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7731, Training Loss: 8.540e-02, Validation Loss: 4.022e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7732, Training Loss: 8.538e-02, Validation Loss: 4.022e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7733, Training Loss: 8.536e-02, Validation Loss: 4.022e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7734, Training Loss: 8.535e-02, Validation Loss: 4.022e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7735, Training Loss: 8.533e-02, Validation Loss: 4.021e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7736, Training Loss: 8.531e-02, Validation Loss: 4.022e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7737, Training Loss: 8.529e-02, Validation Loss: 4.021e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7738, Training Loss: 8.527e-02, Validation Loss: 4.022e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7739, Training Loss: 8.525e-02, Validation Loss: 4.021e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7740, Training Loss: 8.524e-02, Validation Loss: 4.022e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7741, Training Loss: 8.522e-02, Validation Loss: 4.021e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7742, Training Loss: 8.520e-02, Validation Loss: 4.021e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7743, Training Loss: 8.518e-02, Validation Loss: 4.021e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7744, Training Loss: 8.516e-02, Validation Loss: 4.021e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7745, Training Loss: 8.515e-02, Validation Loss: 4.021e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7746, Training Loss: 8.513e-02, Validation Loss: 4.021e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7747, Training Loss: 8.511e-02, Validation Loss: 4.021e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7748, Training Loss: 8.509e-02, Validation Loss: 4.020e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7749, Training Loss: 8.507e-02, Validation Loss: 4.021e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7750, Training Loss: 8.505e-02, Validation Loss: 4.020e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7751, Training Loss: 8.504e-02, Validation Loss: 4.020e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7752, Training Loss: 8.502e-02, Validation Loss: 4.020e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7753, Training Loss: 8.500e-02, Validation Loss: 4.020e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7754, Training Loss: 8.498e-02, Validation Loss: 4.020e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7755, Training Loss: 8.496e-02, Validation Loss: 4.020e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7756, Training Loss: 8.495e-02, Validation Loss: 4.020e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7757, Training Loss: 8.493e-02, Validation Loss: 4.020e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7758, Training Loss: 8.491e-02, Validation Loss: 4.020e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7759, Training Loss: 8.489e-02, Validation Loss: 4.020e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7760, Training Loss: 8.487e-02, Validation Loss: 4.020e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7761, Training Loss: 8.485e-02, Validation Loss: 4.020e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7762, Training Loss: 8.484e-02, Validation Loss: 4.020e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7763, Training Loss: 8.482e-02, Validation Loss: 4.019e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7764, Training Loss: 8.480e-02, Validation Loss: 4.019e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7765, Training Loss: 8.478e-02, Validation Loss: 4.019e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7766, Training Loss: 8.476e-02, Validation Loss: 4.019e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7767, Training Loss: 8.475e-02, Validation Loss: 4.019e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7768, Training Loss: 8.473e-02, Validation Loss: 4.019e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7769, Training Loss: 8.471e-02, Validation Loss: 4.019e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7770, Training Loss: 8.469e-02, Validation Loss: 4.019e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7771, Training Loss: 8.467e-02, Validation Loss: 4.019e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7772, Training Loss: 8.466e-02, Validation Loss: 4.019e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7773, Training Loss: 8.464e-02, Validation Loss: 4.019e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7774, Training Loss: 8.462e-02, Validation Loss: 4.019e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7775, Training Loss: 8.460e-02, Validation Loss: 4.019e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7776, Training Loss: 8.458e-02, Validation Loss: 4.018e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7777, Training Loss: 8.456e-02, Validation Loss: 4.018e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7778, Training Loss: 8.455e-02, Validation Loss: 4.018e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7779, Training Loss: 8.453e-02, Validation Loss: 4.018e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7780, Training Loss: 8.451e-02, Validation Loss: 4.018e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7781, Training Loss: 8.449e-02, Validation Loss: 4.018e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7782, Training Loss: 8.447e-02, Validation Loss: 4.018e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7783, Training Loss: 8.446e-02, Validation Loss: 4.018e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7784, Training Loss: 8.444e-02, Validation Loss: 4.018e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7785, Training Loss: 8.442e-02, Validation Loss: 4.018e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7786, Training Loss: 8.440e-02, Validation Loss: 4.018e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7787, Training Loss: 8.438e-02, Validation Loss: 4.018e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7788, Training Loss: 8.437e-02, Validation Loss: 4.017e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7789, Training Loss: 8.435e-02, Validation Loss: 4.018e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7790, Training Loss: 8.433e-02, Validation Loss: 4.017e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7791, Training Loss: 8.431e-02, Validation Loss: 4.017e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7792, Training Loss: 8.430e-02, Validation Loss: 4.017e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 7793, Training Loss: 8.428e-02, Validation Loss: 4.017e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7794, Training Loss: 8.426e-02, Validation Loss: 4.017e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7795, Training Loss: 8.424e-02, Validation Loss: 4.017e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7796, Training Loss: 8.422e-02, Validation Loss: 4.017e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7797, Training Loss: 8.421e-02, Validation Loss: 4.017e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7798, Training Loss: 8.419e-02, Validation Loss: 4.017e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7799, Training Loss: 8.417e-02, Validation Loss: 4.017e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7800, Training Loss: 8.415e-02, Validation Loss: 4.016e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7801, Training Loss: 8.413e-02, Validation Loss: 4.016e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7802, Training Loss: 8.412e-02, Validation Loss: 4.016e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7803, Training Loss: 8.410e-02, Validation Loss: 4.016e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7804, Training Loss: 8.408e-02, Validation Loss: 4.016e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7805, Training Loss: 8.406e-02, Validation Loss: 4.016e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7806, Training Loss: 8.404e-02, Validation Loss: 4.016e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7807, Training Loss: 8.403e-02, Validation Loss: 4.016e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7808, Training Loss: 8.401e-02, Validation Loss: 4.016e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7809, Training Loss: 8.399e-02, Validation Loss: 4.016e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7810, Training Loss: 8.397e-02, Validation Loss: 4.016e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7811, Training Loss: 8.396e-02, Validation Loss: 4.016e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7812, Training Loss: 8.394e-02, Validation Loss: 4.015e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7813, Training Loss: 8.392e-02, Validation Loss: 4.015e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7814, Training Loss: 8.390e-02, Validation Loss: 4.015e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7815, Training Loss: 8.388e-02, Validation Loss: 4.015e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7816, Training Loss: 8.387e-02, Validation Loss: 4.015e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7817, Training Loss: 8.385e-02, Validation Loss: 4.015e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7818, Training Loss: 8.383e-02, Validation Loss: 4.015e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7819, Training Loss: 8.381e-02, Validation Loss: 4.015e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7820, Training Loss: 8.380e-02, Validation Loss: 4.015e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7821, Training Loss: 8.378e-02, Validation Loss: 4.015e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7822, Training Loss: 8.376e-02, Validation Loss: 4.015e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7823, Training Loss: 8.374e-02, Validation Loss: 4.015e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7824, Training Loss: 8.372e-02, Validation Loss: 4.015e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7825, Training Loss: 8.371e-02, Validation Loss: 4.015e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7826, Training Loss: 8.369e-02, Validation Loss: 4.014e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7827, Training Loss: 8.367e-02, Validation Loss: 4.015e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7828, Training Loss: 8.365e-02, Validation Loss: 4.014e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7829, Training Loss: 8.363e-02, Validation Loss: 4.014e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7830, Training Loss: 8.362e-02, Validation Loss: 4.014e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7831, Training Loss: 8.360e-02, Validation Loss: 4.014e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7832, Training Loss: 8.358e-02, Validation Loss: 4.014e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7833, Training Loss: 8.356e-02, Validation Loss: 4.014e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7834, Training Loss: 8.355e-02, Validation Loss: 4.014e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7835, Training Loss: 8.353e-02, Validation Loss: 4.014e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7836, Training Loss: 8.351e-02, Validation Loss: 4.014e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7837, Training Loss: 8.349e-02, Validation Loss: 4.014e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7838, Training Loss: 8.348e-02, Validation Loss: 4.013e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7839, Training Loss: 8.346e-02, Validation Loss: 4.014e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7840, Training Loss: 8.344e-02, Validation Loss: 4.013e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7841, Training Loss: 8.342e-02, Validation Loss: 4.013e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7842, Training Loss: 8.340e-02, Validation Loss: 4.013e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7843, Training Loss: 8.339e-02, Validation Loss: 4.013e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7844, Training Loss: 8.337e-02, Validation Loss: 4.013e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7845, Training Loss: 8.335e-02, Validation Loss: 4.013e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7846, Training Loss: 8.333e-02, Validation Loss: 4.013e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7847, Training Loss: 8.332e-02, Validation Loss: 4.013e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7848, Training Loss: 8.330e-02, Validation Loss: 4.013e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7849, Training Loss: 8.328e-02, Validation Loss: 4.013e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7850, Training Loss: 8.326e-02, Validation Loss: 4.012e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7851, Training Loss: 8.325e-02, Validation Loss: 4.012e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7852, Training Loss: 8.323e-02, Validation Loss: 4.012e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7853, Training Loss: 8.321e-02, Validation Loss: 4.012e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7854, Training Loss: 8.319e-02, Validation Loss: 4.012e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7855, Training Loss: 8.318e-02, Validation Loss: 4.012e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7856, Training Loss: 8.316e-02, Validation Loss: 4.012e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7857, Training Loss: 8.314e-02, Validation Loss: 4.012e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7858, Training Loss: 8.312e-02, Validation Loss: 4.012e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7859, Training Loss: 8.311e-02, Validation Loss: 4.012e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7860, Training Loss: 8.309e-02, Validation Loss: 4.012e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7861, Training Loss: 8.307e-02, Validation Loss: 4.012e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7862, Training Loss: 8.305e-02, Validation Loss: 4.011e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7863, Training Loss: 8.304e-02, Validation Loss: 4.011e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7864, Training Loss: 8.302e-02, Validation Loss: 4.011e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7865, Training Loss: 8.300e-02, Validation Loss: 4.011e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7866, Training Loss: 8.298e-02, Validation Loss: 4.011e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7867, Training Loss: 8.297e-02, Validation Loss: 4.011e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7868, Training Loss: 8.295e-02, Validation Loss: 4.011e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7869, Training Loss: 8.293e-02, Validation Loss: 4.011e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7870, Training Loss: 8.291e-02, Validation Loss: 4.011e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7871, Training Loss: 8.290e-02, Validation Loss: 4.011e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7872, Training Loss: 8.288e-02, Validation Loss: 4.011e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7873, Training Loss: 8.286e-02, Validation Loss: 4.011e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7874, Training Loss: 8.284e-02, Validation Loss: 4.010e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7875, Training Loss: 8.283e-02, Validation Loss: 4.010e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7876, Training Loss: 8.281e-02, Validation Loss: 4.010e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7877, Training Loss: 8.279e-02, Validation Loss: 4.010e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7878, Training Loss: 8.277e-02, Validation Loss: 4.010e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7879, Training Loss: 8.276e-02, Validation Loss: 4.010e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7880, Training Loss: 8.274e-02, Validation Loss: 4.010e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7881, Training Loss: 8.272e-02, Validation Loss: 4.010e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7882, Training Loss: 8.270e-02, Validation Loss: 4.010e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7883, Training Loss: 8.269e-02, Validation Loss: 4.010e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7884, Training Loss: 8.267e-02, Validation Loss: 4.010e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7885, Training Loss: 8.265e-02, Validation Loss: 4.010e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7886, Training Loss: 8.263e-02, Validation Loss: 4.009e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7887, Training Loss: 8.262e-02, Validation Loss: 4.009e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7888, Training Loss: 8.260e-02, Validation Loss: 4.009e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7889, Training Loss: 8.258e-02, Validation Loss: 4.009e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7890, Training Loss: 8.256e-02, Validation Loss: 4.009e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7891, Training Loss: 8.255e-02, Validation Loss: 4.009e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7892, Training Loss: 8.253e-02, Validation Loss: 4.009e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7893, Training Loss: 8.251e-02, Validation Loss: 4.009e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7894, Training Loss: 8.249e-02, Validation Loss: 4.009e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7895, Training Loss: 8.248e-02, Validation Loss: 4.009e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7896, Training Loss: 8.246e-02, Validation Loss: 4.009e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7897, Training Loss: 8.244e-02, Validation Loss: 4.009e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7898, Training Loss: 8.243e-02, Validation Loss: 4.009e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7899, Training Loss: 8.241e-02, Validation Loss: 4.009e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7900, Training Loss: 8.239e-02, Validation Loss: 4.008e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7901, Training Loss: 8.237e-02, Validation Loss: 4.008e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7902, Training Loss: 8.236e-02, Validation Loss: 4.008e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7903, Training Loss: 8.234e-02, Validation Loss: 4.008e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7904, Training Loss: 8.232e-02, Validation Loss: 4.008e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7905, Training Loss: 8.230e-02, Validation Loss: 4.008e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7906, Training Loss: 8.229e-02, Validation Loss: 4.008e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7907, Training Loss: 8.227e-02, Validation Loss: 4.008e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7908, Training Loss: 8.225e-02, Validation Loss: 4.008e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 7909, Training Loss: 8.223e-02, Validation Loss: 4.008e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7910, Training Loss: 8.222e-02, Validation Loss: 4.008e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7911, Training Loss: 8.220e-02, Validation Loss: 4.008e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7912, Training Loss: 8.218e-02, Validation Loss: 4.008e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7913, Training Loss: 8.217e-02, Validation Loss: 4.008e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7914, Training Loss: 8.215e-02, Validation Loss: 4.007e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7915, Training Loss: 8.213e-02, Validation Loss: 4.008e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7916, Training Loss: 8.211e-02, Validation Loss: 4.007e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7917, Training Loss: 8.210e-02, Validation Loss: 4.007e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7918, Training Loss: 8.208e-02, Validation Loss: 4.007e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7919, Training Loss: 8.206e-02, Validation Loss: 4.007e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7920, Training Loss: 8.204e-02, Validation Loss: 4.007e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7921, Training Loss: 8.203e-02, Validation Loss: 4.007e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7922, Training Loss: 8.201e-02, Validation Loss: 4.007e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7923, Training Loss: 8.199e-02, Validation Loss: 4.007e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7924, Training Loss: 8.198e-02, Validation Loss: 4.007e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7925, Training Loss: 8.196e-02, Validation Loss: 4.006e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7926, Training Loss: 8.194e-02, Validation Loss: 4.007e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7927, Training Loss: 8.192e-02, Validation Loss: 4.006e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7928, Training Loss: 8.191e-02, Validation Loss: 4.006e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7929, Training Loss: 8.189e-02, Validation Loss: 4.006e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7930, Training Loss: 8.187e-02, Validation Loss: 4.006e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7931, Training Loss: 8.186e-02, Validation Loss: 4.006e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7932, Training Loss: 8.184e-02, Validation Loss: 4.006e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7933, Training Loss: 8.182e-02, Validation Loss: 4.006e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7934, Training Loss: 8.180e-02, Validation Loss: 4.006e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7935, Training Loss: 8.179e-02, Validation Loss: 4.006e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7936, Training Loss: 8.177e-02, Validation Loss: 4.006e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7937, Training Loss: 8.175e-02, Validation Loss: 4.006e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7938, Training Loss: 8.174e-02, Validation Loss: 4.006e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7939, Training Loss: 8.172e-02, Validation Loss: 4.006e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7940, Training Loss: 8.170e-02, Validation Loss: 4.005e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7941, Training Loss: 8.168e-02, Validation Loss: 4.005e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7942, Training Loss: 8.167e-02, Validation Loss: 4.005e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7943, Training Loss: 8.165e-02, Validation Loss: 4.005e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7944, Training Loss: 8.163e-02, Validation Loss: 4.005e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7945, Training Loss: 8.162e-02, Validation Loss: 4.005e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7946, Training Loss: 8.160e-02, Validation Loss: 4.005e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7947, Training Loss: 8.158e-02, Validation Loss: 4.005e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7948, Training Loss: 8.157e-02, Validation Loss: 4.005e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7949, Training Loss: 8.155e-02, Validation Loss: 4.005e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7950, Training Loss: 8.153e-02, Validation Loss: 4.005e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7951, Training Loss: 8.151e-02, Validation Loss: 4.005e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7952, Training Loss: 8.150e-02, Validation Loss: 4.005e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7953, Training Loss: 8.148e-02, Validation Loss: 4.005e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7954, Training Loss: 8.146e-02, Validation Loss: 4.005e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7955, Training Loss: 8.145e-02, Validation Loss: 4.004e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7956, Training Loss: 8.143e-02, Validation Loss: 4.004e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7957, Training Loss: 8.141e-02, Validation Loss: 4.004e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7958, Training Loss: 8.139e-02, Validation Loss: 4.004e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7959, Training Loss: 8.138e-02, Validation Loss: 4.004e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7960, Training Loss: 8.136e-02, Validation Loss: 4.004e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7961, Training Loss: 8.134e-02, Validation Loss: 4.004e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7962, Training Loss: 8.133e-02, Validation Loss: 4.004e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7963, Training Loss: 8.131e-02, Validation Loss: 4.004e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7964, Training Loss: 8.129e-02, Validation Loss: 4.004e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7965, Training Loss: 8.128e-02, Validation Loss: 4.004e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7966, Training Loss: 8.126e-02, Validation Loss: 4.004e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7967, Training Loss: 8.124e-02, Validation Loss: 4.004e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7968, Training Loss: 8.123e-02, Validation Loss: 4.004e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7969, Training Loss: 8.121e-02, Validation Loss: 4.003e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7970, Training Loss: 8.119e-02, Validation Loss: 4.003e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7971, Training Loss: 8.117e-02, Validation Loss: 4.003e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7972, Training Loss: 8.116e-02, Validation Loss: 4.003e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7973, Training Loss: 8.114e-02, Validation Loss: 4.003e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7974, Training Loss: 8.112e-02, Validation Loss: 4.003e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7975, Training Loss: 8.111e-02, Validation Loss: 4.003e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7976, Training Loss: 8.109e-02, Validation Loss: 4.003e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7977, Training Loss: 8.107e-02, Validation Loss: 4.003e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7978, Training Loss: 8.106e-02, Validation Loss: 4.003e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7979, Training Loss: 8.104e-02, Validation Loss: 4.003e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7980, Training Loss: 8.102e-02, Validation Loss: 4.002e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7981, Training Loss: 8.101e-02, Validation Loss: 4.003e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7982, Training Loss: 8.099e-02, Validation Loss: 4.002e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7983, Training Loss: 8.097e-02, Validation Loss: 4.002e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7984, Training Loss: 8.095e-02, Validation Loss: 4.002e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7985, Training Loss: 8.094e-02, Validation Loss: 4.002e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7986, Training Loss: 8.092e-02, Validation Loss: 4.002e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7987, Training Loss: 8.090e-02, Validation Loss: 4.002e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7988, Training Loss: 8.089e-02, Validation Loss: 4.002e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7989, Training Loss: 8.087e-02, Validation Loss: 4.002e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7990, Training Loss: 8.085e-02, Validation Loss: 4.002e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7991, Training Loss: 8.084e-02, Validation Loss: 4.002e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7992, Training Loss: 8.082e-02, Validation Loss: 4.002e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7993, Training Loss: 8.080e-02, Validation Loss: 4.002e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7994, Training Loss: 8.079e-02, Validation Loss: 4.001e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7995, Training Loss: 8.077e-02, Validation Loss: 4.002e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 7996, Training Loss: 8.075e-02, Validation Loss: 4.001e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7997, Training Loss: 8.074e-02, Validation Loss: 4.001e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7998, Training Loss: 8.072e-02, Validation Loss: 4.001e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 7999, Training Loss: 8.070e-02, Validation Loss: 4.001e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8000, Training Loss: 8.069e-02, Validation Loss: 4.001e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8001, Training Loss: 8.067e-02, Validation Loss: 4.001e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8002, Training Loss: 8.065e-02, Validation Loss: 4.001e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8003, Training Loss: 8.064e-02, Validation Loss: 4.001e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8004, Training Loss: 8.062e-02, Validation Loss: 4.001e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8005, Training Loss: 8.060e-02, Validation Loss: 4.001e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8006, Training Loss: 8.059e-02, Validation Loss: 4.001e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8007, Training Loss: 8.057e-02, Validation Loss: 4.001e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8008, Training Loss: 8.055e-02, Validation Loss: 4.001e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8009, Training Loss: 8.053e-02, Validation Loss: 4.001e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8010, Training Loss: 8.052e-02, Validation Loss: 4.000e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8011, Training Loss: 8.050e-02, Validation Loss: 4.000e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8012, Training Loss: 8.048e-02, Validation Loss: 4.000e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8013, Training Loss: 8.047e-02, Validation Loss: 4.000e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8014, Training Loss: 8.045e-02, Validation Loss: 4.000e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8015, Training Loss: 8.043e-02, Validation Loss: 4.000e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8016, Training Loss: 8.042e-02, Validation Loss: 4.000e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8017, Training Loss: 8.040e-02, Validation Loss: 4.000e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8018, Training Loss: 8.038e-02, Validation Loss: 4.000e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8019, Training Loss: 8.037e-02, Validation Loss: 4.000e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8020, Training Loss: 8.035e-02, Validation Loss: 4.000e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8021, Training Loss: 8.033e-02, Validation Loss: 4.000e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8022, Training Loss: 8.032e-02, Validation Loss: 4.000e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8023, Training Loss: 8.030e-02, Validation Loss: 4.000e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8024, Training Loss: 8.028e-02, Validation Loss: 4.000e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8025, Training Loss: 8.027e-02, Validation Loss: 3.999e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8026, Training Loss: 8.025e-02, Validation Loss: 3.999e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8027, Training Loss: 8.023e-02, Validation Loss: 3.999e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8028, Training Loss: 8.022e-02, Validation Loss: 3.999e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8029, Training Loss: 8.020e-02, Validation Loss: 3.999e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8030, Training Loss: 8.018e-02, Validation Loss: 3.999e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8031, Training Loss: 8.017e-02, Validation Loss: 3.999e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8032, Training Loss: 8.015e-02, Validation Loss: 3.999e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8033, Training Loss: 8.014e-02, Validation Loss: 3.999e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8034, Training Loss: 8.012e-02, Validation Loss: 3.999e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8035, Training Loss: 8.010e-02, Validation Loss: 3.999e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8036, Training Loss: 8.009e-02, Validation Loss: 3.999e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8037, Training Loss: 8.007e-02, Validation Loss: 3.999e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8038, Training Loss: 8.005e-02, Validation Loss: 3.998e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8039, Training Loss: 8.004e-02, Validation Loss: 3.999e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8040, Training Loss: 8.002e-02, Validation Loss: 3.998e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8041, Training Loss: 8.000e-02, Validation Loss: 3.998e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8042, Training Loss: 7.999e-02, Validation Loss: 3.998e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8043, Training Loss: 7.997e-02, Validation Loss: 3.998e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8044, Training Loss: 7.995e-02, Validation Loss: 3.998e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8045, Training Loss: 7.994e-02, Validation Loss: 3.998e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8046, Training Loss: 7.992e-02, Validation Loss: 3.998e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8047, Training Loss: 7.990e-02, Validation Loss: 3.998e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8048, Training Loss: 7.989e-02, Validation Loss: 3.998e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8049, Training Loss: 7.987e-02, Validation Loss: 3.998e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8050, Training Loss: 7.985e-02, Validation Loss: 3.998e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8051, Training Loss: 7.984e-02, Validation Loss: 3.998e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8052, Training Loss: 7.982e-02, Validation Loss: 3.998e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8053, Training Loss: 7.980e-02, Validation Loss: 3.997e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8054, Training Loss: 7.979e-02, Validation Loss: 3.997e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8055, Training Loss: 7.977e-02, Validation Loss: 3.997e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8056, Training Loss: 7.975e-02, Validation Loss: 3.997e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8057, Training Loss: 7.974e-02, Validation Loss: 3.997e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8058, Training Loss: 7.972e-02, Validation Loss: 3.997e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8059, Training Loss: 7.971e-02, Validation Loss: 3.997e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8060, Training Loss: 7.969e-02, Validation Loss: 3.997e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8061, Training Loss: 7.967e-02, Validation Loss: 3.997e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8062, Training Loss: 7.966e-02, Validation Loss: 3.997e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8063, Training Loss: 7.964e-02, Validation Loss: 3.997e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8064, Training Loss: 7.962e-02, Validation Loss: 3.997e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8065, Training Loss: 7.961e-02, Validation Loss: 3.997e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8066, Training Loss: 7.959e-02, Validation Loss: 3.997e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8067, Training Loss: 7.957e-02, Validation Loss: 3.997e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8068, Training Loss: 7.956e-02, Validation Loss: 3.996e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8069, Training Loss: 7.954e-02, Validation Loss: 3.996e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8070, Training Loss: 7.952e-02, Validation Loss: 3.996e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8071, Training Loss: 7.951e-02, Validation Loss: 3.996e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8072, Training Loss: 7.949e-02, Validation Loss: 3.996e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8073, Training Loss: 7.948e-02, Validation Loss: 3.996e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8074, Training Loss: 7.946e-02, Validation Loss: 3.996e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8075, Training Loss: 7.944e-02, Validation Loss: 3.996e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8076, Training Loss: 7.943e-02, Validation Loss: 3.996e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8077, Training Loss: 7.941e-02, Validation Loss: 3.996e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8078, Training Loss: 7.939e-02, Validation Loss: 3.996e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8079, Training Loss: 7.938e-02, Validation Loss: 3.996e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8080, Training Loss: 7.936e-02, Validation Loss: 3.996e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8081, Training Loss: 7.934e-02, Validation Loss: 3.996e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8082, Training Loss: 7.933e-02, Validation Loss: 3.995e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8083, Training Loss: 7.931e-02, Validation Loss: 3.995e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8084, Training Loss: 7.930e-02, Validation Loss: 3.996e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8085, Training Loss: 7.928e-02, Validation Loss: 3.995e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8086, Training Loss: 7.926e-02, Validation Loss: 3.995e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8087, Training Loss: 7.925e-02, Validation Loss: 3.995e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8088, Training Loss: 7.923e-02, Validation Loss: 3.995e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8089, Training Loss: 7.921e-02, Validation Loss: 3.995e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8090, Training Loss: 7.920e-02, Validation Loss: 3.995e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8091, Training Loss: 7.918e-02, Validation Loss: 3.995e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8092, Training Loss: 7.916e-02, Validation Loss: 3.995e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8093, Training Loss: 7.915e-02, Validation Loss: 3.995e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8094, Training Loss: 7.913e-02, Validation Loss: 3.995e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8095, Training Loss: 7.912e-02, Validation Loss: 3.995e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8096, Training Loss: 7.910e-02, Validation Loss: 3.994e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8097, Training Loss: 7.908e-02, Validation Loss: 3.994e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8098, Training Loss: 7.907e-02, Validation Loss: 3.994e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8099, Training Loss: 7.905e-02, Validation Loss: 3.994e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8100, Training Loss: 7.903e-02, Validation Loss: 3.994e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8101, Training Loss: 7.902e-02, Validation Loss: 3.994e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8102, Training Loss: 7.900e-02, Validation Loss: 3.994e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8103, Training Loss: 7.899e-02, Validation Loss: 3.994e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8104, Training Loss: 7.897e-02, Validation Loss: 3.994e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8105, Training Loss: 7.895e-02, Validation Loss: 3.994e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8106, Training Loss: 7.894e-02, Validation Loss: 3.994e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8107, Training Loss: 7.892e-02, Validation Loss: 3.994e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8108, Training Loss: 7.891e-02, Validation Loss: 3.994e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8109, Training Loss: 7.889e-02, Validation Loss: 3.994e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8110, Training Loss: 7.887e-02, Validation Loss: 3.994e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8111, Training Loss: 7.886e-02, Validation Loss: 3.994e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8112, Training Loss: 7.884e-02, Validation Loss: 3.993e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8113, Training Loss: 7.882e-02, Validation Loss: 3.993e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8114, Training Loss: 7.881e-02, Validation Loss: 3.993e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8115, Training Loss: 7.879e-02, Validation Loss: 3.993e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8116, Training Loss: 7.878e-02, Validation Loss: 3.993e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8117, Training Loss: 7.876e-02, Validation Loss: 3.993e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8118, Training Loss: 7.874e-02, Validation Loss: 3.993e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8119, Training Loss: 7.873e-02, Validation Loss: 3.993e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8120, Training Loss: 7.871e-02, Validation Loss: 3.993e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8121, Training Loss: 7.869e-02, Validation Loss: 3.993e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8122, Training Loss: 7.868e-02, Validation Loss: 3.993e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8123, Training Loss: 7.866e-02, Validation Loss: 3.993e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8124, Training Loss: 7.865e-02, Validation Loss: 3.993e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8125, Training Loss: 7.863e-02, Validation Loss: 3.993e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8126, Training Loss: 7.861e-02, Validation Loss: 3.992e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8127, Training Loss: 7.860e-02, Validation Loss: 3.993e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8128, Training Loss: 7.858e-02, Validation Loss: 3.992e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8129, Training Loss: 7.857e-02, Validation Loss: 3.992e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8130, Training Loss: 7.855e-02, Validation Loss: 3.992e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8131, Training Loss: 7.853e-02, Validation Loss: 3.992e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8132, Training Loss: 7.852e-02, Validation Loss: 3.992e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8133, Training Loss: 7.850e-02, Validation Loss: 3.992e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8134, Training Loss: 7.849e-02, Validation Loss: 3.992e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8135, Training Loss: 7.847e-02, Validation Loss: 3.992e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8136, Training Loss: 7.845e-02, Validation Loss: 3.992e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8137, Training Loss: 7.844e-02, Validation Loss: 3.992e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8138, Training Loss: 7.842e-02, Validation Loss: 3.992e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8139, Training Loss: 7.841e-02, Validation Loss: 3.992e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8140, Training Loss: 7.839e-02, Validation Loss: 3.992e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8141, Training Loss: 7.837e-02, Validation Loss: 3.992e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8142, Training Loss: 7.836e-02, Validation Loss: 3.991e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8143, Training Loss: 7.834e-02, Validation Loss: 3.991e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8144, Training Loss: 7.833e-02, Validation Loss: 3.992e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8145, Training Loss: 7.831e-02, Validation Loss: 3.991e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8146, Training Loss: 7.829e-02, Validation Loss: 3.991e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8147, Training Loss: 7.828e-02, Validation Loss: 3.991e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8148, Training Loss: 7.826e-02, Validation Loss: 3.991e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8149, Training Loss: 7.825e-02, Validation Loss: 3.991e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8150, Training Loss: 7.823e-02, Validation Loss: 3.991e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8151, Training Loss: 7.821e-02, Validation Loss: 3.991e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8152, Training Loss: 7.820e-02, Validation Loss: 3.991e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8153, Training Loss: 7.818e-02, Validation Loss: 3.991e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8154, Training Loss: 7.817e-02, Validation Loss: 3.991e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8155, Training Loss: 7.815e-02, Validation Loss: 3.991e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8156, Training Loss: 7.813e-02, Validation Loss: 3.991e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8157, Training Loss: 7.812e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8158, Training Loss: 7.810e-02, Validation Loss: 3.991e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8159, Training Loss: 7.809e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8160, Training Loss: 7.807e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8161, Training Loss: 7.805e-02, Validation Loss: 3.991e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8162, Training Loss: 7.804e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8163, Training Loss: 7.802e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8164, Training Loss: 7.801e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8165, Training Loss: 7.799e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8166, Training Loss: 7.797e-02, Validation Loss: 3.990e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8167, Training Loss: 7.796e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8168, Training Loss: 7.794e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8169, Training Loss: 7.793e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8170, Training Loss: 7.791e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8171, Training Loss: 7.789e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8172, Training Loss: 7.788e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8173, Training Loss: 7.786e-02, Validation Loss: 3.990e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8174, Training Loss: 7.785e-02, Validation Loss: 3.989e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8175, Training Loss: 7.783e-02, Validation Loss: 3.990e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8176, Training Loss: 7.782e-02, Validation Loss: 3.989e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8177, Training Loss: 7.780e-02, Validation Loss: 3.989e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8178, Training Loss: 7.778e-02, Validation Loss: 3.989e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8179, Training Loss: 7.777e-02, Validation Loss: 3.989e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8180, Training Loss: 7.775e-02, Validation Loss: 3.989e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8181, Training Loss: 7.774e-02, Validation Loss: 3.989e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8182, Training Loss: 7.772e-02, Validation Loss: 3.989e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8183, Training Loss: 7.770e-02, Validation Loss: 3.989e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8184, Training Loss: 7.769e-02, Validation Loss: 3.989e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8185, Training Loss: 7.767e-02, Validation Loss: 3.989e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8186, Training Loss: 7.766e-02, Validation Loss: 3.989e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8187, Training Loss: 7.764e-02, Validation Loss: 3.989e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8188, Training Loss: 7.763e-02, Validation Loss: 3.988e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8189, Training Loss: 7.761e-02, Validation Loss: 3.988e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8190, Training Loss: 7.759e-02, Validation Loss: 3.989e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8191, Training Loss: 7.758e-02, Validation Loss: 3.988e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8192, Training Loss: 7.756e-02, Validation Loss: 3.988e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8193, Training Loss: 7.755e-02, Validation Loss: 3.988e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8194, Training Loss: 7.753e-02, Validation Loss: 3.988e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8195, Training Loss: 7.751e-02, Validation Loss: 3.988e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8196, Training Loss: 7.750e-02, Validation Loss: 3.988e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8197, Training Loss: 7.748e-02, Validation Loss: 3.988e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8198, Training Loss: 7.747e-02, Validation Loss: 3.988e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8199, Training Loss: 7.745e-02, Validation Loss: 3.988e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8200, Training Loss: 7.744e-02, Validation Loss: 3.988e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8201, Training Loss: 7.742e-02, Validation Loss: 3.988e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8202, Training Loss: 7.740e-02, Validation Loss: 3.988e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8203, Training Loss: 7.739e-02, Validation Loss: 3.988e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8204, Training Loss: 7.737e-02, Validation Loss: 3.988e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8205, Training Loss: 7.736e-02, Validation Loss: 3.988e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8206, Training Loss: 7.734e-02, Validation Loss: 3.987e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8207, Training Loss: 7.733e-02, Validation Loss: 3.987e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8208, Training Loss: 7.731e-02, Validation Loss: 3.987e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8209, Training Loss: 7.729e-02, Validation Loss: 3.987e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8210, Training Loss: 7.728e-02, Validation Loss: 3.987e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8211, Training Loss: 7.726e-02, Validation Loss: 3.987e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8212, Training Loss: 7.725e-02, Validation Loss: 3.987e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8213, Training Loss: 7.723e-02, Validation Loss: 3.987e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8214, Training Loss: 7.722e-02, Validation Loss: 3.987e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8215, Training Loss: 7.720e-02, Validation Loss: 3.987e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8216, Training Loss: 7.718e-02, Validation Loss: 3.987e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8217, Training Loss: 7.717e-02, Validation Loss: 3.987e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8218, Training Loss: 7.715e-02, Validation Loss: 3.987e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8219, Training Loss: 7.714e-02, Validation Loss: 3.987e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8220, Training Loss: 7.712e-02, Validation Loss: 3.986e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8221, Training Loss: 7.711e-02, Validation Loss: 3.986e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8222, Training Loss: 7.709e-02, Validation Loss: 3.986e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8223, Training Loss: 7.708e-02, Validation Loss: 3.986e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8224, Training Loss: 7.706e-02, Validation Loss: 3.986e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8225, Training Loss: 7.704e-02, Validation Loss: 3.986e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8226, Training Loss: 7.703e-02, Validation Loss: 3.986e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8227, Training Loss: 7.701e-02, Validation Loss: 3.986e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8228, Training Loss: 7.700e-02, Validation Loss: 3.986e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8229, Training Loss: 7.698e-02, Validation Loss: 3.986e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8230, Training Loss: 7.697e-02, Validation Loss: 3.986e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8231, Training Loss: 7.695e-02, Validation Loss: 3.986e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8232, Training Loss: 7.693e-02, Validation Loss: 3.986e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8233, Training Loss: 7.692e-02, Validation Loss: 3.986e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8234, Training Loss: 7.690e-02, Validation Loss: 3.986e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8235, Training Loss: 7.689e-02, Validation Loss: 3.986e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8236, Training Loss: 7.687e-02, Validation Loss: 3.985e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8237, Training Loss: 7.686e-02, Validation Loss: 3.985e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8238, Training Loss: 7.684e-02, Validation Loss: 3.985e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8239, Training Loss: 7.683e-02, Validation Loss: 3.985e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8240, Training Loss: 7.681e-02, Validation Loss: 3.985e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8241, Training Loss: 7.679e-02, Validation Loss: 3.985e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8242, Training Loss: 7.678e-02, Validation Loss: 3.985e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8243, Training Loss: 7.676e-02, Validation Loss: 3.985e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8244, Training Loss: 7.675e-02, Validation Loss: 3.985e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8245, Training Loss: 7.673e-02, Validation Loss: 3.985e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8246, Training Loss: 7.672e-02, Validation Loss: 3.985e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8247, Training Loss: 7.670e-02, Validation Loss: 3.985e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8248, Training Loss: 7.669e-02, Validation Loss: 3.985e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8249, Training Loss: 7.667e-02, Validation Loss: 3.985e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8250, Training Loss: 7.666e-02, Validation Loss: 3.984e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8251, Training Loss: 7.664e-02, Validation Loss: 3.985e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8252, Training Loss: 7.662e-02, Validation Loss: 3.984e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8253, Training Loss: 7.661e-02, Validation Loss: 3.984e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8254, Training Loss: 7.659e-02, Validation Loss: 3.984e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8255, Training Loss: 7.658e-02, Validation Loss: 3.984e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8256, Training Loss: 7.656e-02, Validation Loss: 3.984e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8257, Training Loss: 7.655e-02, Validation Loss: 3.984e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8258, Training Loss: 7.653e-02, Validation Loss: 3.984e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8259, Training Loss: 7.652e-02, Validation Loss: 3.984e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8260, Training Loss: 7.650e-02, Validation Loss: 3.984e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8261, Training Loss: 7.648e-02, Validation Loss: 3.984e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8262, Training Loss: 7.647e-02, Validation Loss: 3.984e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8263, Training Loss: 7.645e-02, Validation Loss: 3.984e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8264, Training Loss: 7.644e-02, Validation Loss: 3.984e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8265, Training Loss: 7.642e-02, Validation Loss: 3.984e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8266, Training Loss: 7.641e-02, Validation Loss: 3.983e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8267, Training Loss: 7.639e-02, Validation Loss: 3.984e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8268, Training Loss: 7.638e-02, Validation Loss: 3.983e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8269, Training Loss: 7.636e-02, Validation Loss: 3.983e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8270, Training Loss: 7.635e-02, Validation Loss: 3.983e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8271, Training Loss: 7.633e-02, Validation Loss: 3.983e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8272, Training Loss: 7.632e-02, Validation Loss: 3.983e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8273, Training Loss: 7.630e-02, Validation Loss: 3.983e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8274, Training Loss: 7.628e-02, Validation Loss: 3.983e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8275, Training Loss: 7.627e-02, Validation Loss: 3.983e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8276, Training Loss: 7.625e-02, Validation Loss: 3.983e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8277, Training Loss: 7.624e-02, Validation Loss: 3.983e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8278, Training Loss: 7.622e-02, Validation Loss: 3.983e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8279, Training Loss: 7.621e-02, Validation Loss: 3.983e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8280, Training Loss: 7.619e-02, Validation Loss: 3.983e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8281, Training Loss: 7.618e-02, Validation Loss: 3.982e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8282, Training Loss: 7.616e-02, Validation Loss: 3.983e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8283, Training Loss: 7.615e-02, Validation Loss: 3.983e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8284, Training Loss: 7.613e-02, Validation Loss: 3.982e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8285, Training Loss: 7.611e-02, Validation Loss: 3.982e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8286, Training Loss: 7.610e-02, Validation Loss: 3.982e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8287, Training Loss: 7.608e-02, Validation Loss: 3.982e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8288, Training Loss: 7.607e-02, Validation Loss: 3.982e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8289, Training Loss: 7.605e-02, Validation Loss: 3.982e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8290, Training Loss: 7.604e-02, Validation Loss: 3.982e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8291, Training Loss: 7.602e-02, Validation Loss: 3.982e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8292, Training Loss: 7.601e-02, Validation Loss: 3.982e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8293, Training Loss: 7.599e-02, Validation Loss: 3.982e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8294, Training Loss: 7.598e-02, Validation Loss: 3.982e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8295, Training Loss: 7.596e-02, Validation Loss: 3.982e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8296, Training Loss: 7.595e-02, Validation Loss: 3.982e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8297, Training Loss: 7.593e-02, Validation Loss: 3.982e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8298, Training Loss: 7.592e-02, Validation Loss: 3.981e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8299, Training Loss: 7.590e-02, Validation Loss: 3.981e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8300, Training Loss: 7.589e-02, Validation Loss: 3.981e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8301, Training Loss: 7.587e-02, Validation Loss: 3.981e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8302, Training Loss: 7.585e-02, Validation Loss: 3.981e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8303, Training Loss: 7.584e-02, Validation Loss: 3.981e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8304, Training Loss: 7.582e-02, Validation Loss: 3.981e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8305, Training Loss: 7.581e-02, Validation Loss: 3.981e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8306, Training Loss: 7.579e-02, Validation Loss: 3.981e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8307, Training Loss: 7.578e-02, Validation Loss: 3.981e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8308, Training Loss: 7.576e-02, Validation Loss: 3.981e-01, Patience: 3, Learning Rate: 0.01\n",
            "Epoch 8309, Training Loss: 7.575e-02, Validation Loss: 3.981e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8310, Training Loss: 7.573e-02, Validation Loss: 3.981e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8311, Training Loss: 7.572e-02, Validation Loss: 3.981e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8312, Training Loss: 7.570e-02, Validation Loss: 3.981e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8313, Training Loss: 7.569e-02, Validation Loss: 3.980e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8314, Training Loss: 7.567e-02, Validation Loss: 3.980e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8315, Training Loss: 7.566e-02, Validation Loss: 3.980e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8316, Training Loss: 7.564e-02, Validation Loss: 3.980e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8317, Training Loss: 7.563e-02, Validation Loss: 3.980e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8318, Training Loss: 7.561e-02, Validation Loss: 3.980e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8319, Training Loss: 7.560e-02, Validation Loss: 3.980e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8320, Training Loss: 7.558e-02, Validation Loss: 3.980e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8321, Training Loss: 7.557e-02, Validation Loss: 3.980e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8322, Training Loss: 7.555e-02, Validation Loss: 3.980e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8323, Training Loss: 7.553e-02, Validation Loss: 3.980e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8324, Training Loss: 7.552e-02, Validation Loss: 3.980e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8325, Training Loss: 7.550e-02, Validation Loss: 3.980e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8326, Training Loss: 7.549e-02, Validation Loss: 3.980e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8327, Training Loss: 7.547e-02, Validation Loss: 3.980e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8328, Training Loss: 7.546e-02, Validation Loss: 3.980e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8329, Training Loss: 7.544e-02, Validation Loss: 3.979e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8330, Training Loss: 7.543e-02, Validation Loss: 3.980e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8331, Training Loss: 7.541e-02, Validation Loss: 3.979e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8332, Training Loss: 7.540e-02, Validation Loss: 3.980e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8333, Training Loss: 7.538e-02, Validation Loss: 3.979e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8334, Training Loss: 7.537e-02, Validation Loss: 3.979e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8335, Training Loss: 7.535e-02, Validation Loss: 3.979e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8336, Training Loss: 7.534e-02, Validation Loss: 3.979e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8337, Training Loss: 7.532e-02, Validation Loss: 3.979e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8338, Training Loss: 7.531e-02, Validation Loss: 3.979e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8339, Training Loss: 7.529e-02, Validation Loss: 3.979e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8340, Training Loss: 7.528e-02, Validation Loss: 3.979e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8341, Training Loss: 7.526e-02, Validation Loss: 3.979e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8342, Training Loss: 7.525e-02, Validation Loss: 3.979e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8343, Training Loss: 7.523e-02, Validation Loss: 3.979e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8344, Training Loss: 7.522e-02, Validation Loss: 3.979e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8345, Training Loss: 7.520e-02, Validation Loss: 3.979e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8346, Training Loss: 7.519e-02, Validation Loss: 3.978e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8347, Training Loss: 7.517e-02, Validation Loss: 3.978e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8348, Training Loss: 7.516e-02, Validation Loss: 3.978e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8349, Training Loss: 7.514e-02, Validation Loss: 3.978e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8350, Training Loss: 7.513e-02, Validation Loss: 3.978e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8351, Training Loss: 7.511e-02, Validation Loss: 3.978e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8352, Training Loss: 7.510e-02, Validation Loss: 3.978e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8353, Training Loss: 7.508e-02, Validation Loss: 3.978e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8354, Training Loss: 7.507e-02, Validation Loss: 3.978e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8355, Training Loss: 7.505e-02, Validation Loss: 3.978e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8356, Training Loss: 7.504e-02, Validation Loss: 3.978e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8357, Training Loss: 7.502e-02, Validation Loss: 3.978e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8358, Training Loss: 7.501e-02, Validation Loss: 3.978e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8359, Training Loss: 7.499e-02, Validation Loss: 3.978e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8360, Training Loss: 7.498e-02, Validation Loss: 3.978e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8361, Training Loss: 7.496e-02, Validation Loss: 3.977e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8362, Training Loss: 7.495e-02, Validation Loss: 3.978e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8363, Training Loss: 7.493e-02, Validation Loss: 3.977e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8364, Training Loss: 7.492e-02, Validation Loss: 3.978e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8365, Training Loss: 7.490e-02, Validation Loss: 3.977e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8366, Training Loss: 7.489e-02, Validation Loss: 3.977e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8367, Training Loss: 7.487e-02, Validation Loss: 3.977e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8368, Training Loss: 7.486e-02, Validation Loss: 3.977e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8369, Training Loss: 7.484e-02, Validation Loss: 3.977e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8370, Training Loss: 7.483e-02, Validation Loss: 3.977e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8371, Training Loss: 7.481e-02, Validation Loss: 3.977e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8372, Training Loss: 7.480e-02, Validation Loss: 3.977e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8373, Training Loss: 7.478e-02, Validation Loss: 3.977e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8374, Training Loss: 7.477e-02, Validation Loss: 3.977e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8375, Training Loss: 7.475e-02, Validation Loss: 3.977e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8376, Training Loss: 7.474e-02, Validation Loss: 3.977e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8377, Training Loss: 7.472e-02, Validation Loss: 3.977e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8378, Training Loss: 7.471e-02, Validation Loss: 3.977e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8379, Training Loss: 7.469e-02, Validation Loss: 3.977e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8380, Training Loss: 7.468e-02, Validation Loss: 3.976e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8381, Training Loss: 7.466e-02, Validation Loss: 3.976e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8382, Training Loss: 7.465e-02, Validation Loss: 3.976e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8383, Training Loss: 7.463e-02, Validation Loss: 3.976e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8384, Training Loss: 7.462e-02, Validation Loss: 3.976e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8385, Training Loss: 7.460e-02, Validation Loss: 3.976e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8386, Training Loss: 7.459e-02, Validation Loss: 3.976e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8387, Training Loss: 7.457e-02, Validation Loss: 3.976e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8388, Training Loss: 7.456e-02, Validation Loss: 3.976e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8389, Training Loss: 7.454e-02, Validation Loss: 3.976e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8390, Training Loss: 7.453e-02, Validation Loss: 3.976e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8391, Training Loss: 7.451e-02, Validation Loss: 3.976e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8392, Training Loss: 7.450e-02, Validation Loss: 3.976e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8393, Training Loss: 7.448e-02, Validation Loss: 3.976e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8394, Training Loss: 7.447e-02, Validation Loss: 3.976e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8395, Training Loss: 7.445e-02, Validation Loss: 3.975e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8396, Training Loss: 7.444e-02, Validation Loss: 3.975e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8397, Training Loss: 7.443e-02, Validation Loss: 3.975e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8398, Training Loss: 7.441e-02, Validation Loss: 3.975e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8399, Training Loss: 7.440e-02, Validation Loss: 3.975e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8400, Training Loss: 7.438e-02, Validation Loss: 3.975e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8401, Training Loss: 7.437e-02, Validation Loss: 3.975e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8402, Training Loss: 7.435e-02, Validation Loss: 3.975e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8403, Training Loss: 7.434e-02, Validation Loss: 3.975e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8404, Training Loss: 7.432e-02, Validation Loss: 3.975e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8405, Training Loss: 7.431e-02, Validation Loss: 3.975e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8406, Training Loss: 7.429e-02, Validation Loss: 3.975e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8407, Training Loss: 7.428e-02, Validation Loss: 3.975e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8408, Training Loss: 7.426e-02, Validation Loss: 3.975e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8409, Training Loss: 7.425e-02, Validation Loss: 3.975e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8410, Training Loss: 7.423e-02, Validation Loss: 3.975e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8411, Training Loss: 7.422e-02, Validation Loss: 3.975e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8412, Training Loss: 7.420e-02, Validation Loss: 3.975e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8413, Training Loss: 7.419e-02, Validation Loss: 3.974e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8414, Training Loss: 7.417e-02, Validation Loss: 3.974e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8415, Training Loss: 7.416e-02, Validation Loss: 3.974e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8416, Training Loss: 7.414e-02, Validation Loss: 3.974e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8417, Training Loss: 7.413e-02, Validation Loss: 3.974e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8418, Training Loss: 7.411e-02, Validation Loss: 3.974e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8419, Training Loss: 7.410e-02, Validation Loss: 3.974e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8420, Training Loss: 7.409e-02, Validation Loss: 3.974e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8421, Training Loss: 7.407e-02, Validation Loss: 3.974e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8422, Training Loss: 7.406e-02, Validation Loss: 3.974e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8423, Training Loss: 7.404e-02, Validation Loss: 3.974e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8424, Training Loss: 7.403e-02, Validation Loss: 3.974e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8425, Training Loss: 7.401e-02, Validation Loss: 3.974e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8426, Training Loss: 7.400e-02, Validation Loss: 3.974e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8427, Training Loss: 7.398e-02, Validation Loss: 3.974e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8428, Training Loss: 7.397e-02, Validation Loss: 3.974e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8429, Training Loss: 7.395e-02, Validation Loss: 3.974e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8430, Training Loss: 7.394e-02, Validation Loss: 3.973e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8431, Training Loss: 7.392e-02, Validation Loss: 3.973e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8432, Training Loss: 7.391e-02, Validation Loss: 3.973e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8433, Training Loss: 7.389e-02, Validation Loss: 3.973e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8434, Training Loss: 7.388e-02, Validation Loss: 3.973e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8435, Training Loss: 7.387e-02, Validation Loss: 3.973e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8436, Training Loss: 7.385e-02, Validation Loss: 3.973e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8437, Training Loss: 7.384e-02, Validation Loss: 3.973e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8438, Training Loss: 7.382e-02, Validation Loss: 3.973e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8439, Training Loss: 7.381e-02, Validation Loss: 3.973e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8440, Training Loss: 7.379e-02, Validation Loss: 3.973e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8441, Training Loss: 7.378e-02, Validation Loss: 3.973e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8442, Training Loss: 7.376e-02, Validation Loss: 3.973e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8443, Training Loss: 7.375e-02, Validation Loss: 3.973e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8444, Training Loss: 7.373e-02, Validation Loss: 3.973e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8445, Training Loss: 7.372e-02, Validation Loss: 3.973e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8446, Training Loss: 7.370e-02, Validation Loss: 3.972e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8447, Training Loss: 7.369e-02, Validation Loss: 3.973e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8448, Training Loss: 7.367e-02, Validation Loss: 3.972e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8449, Training Loss: 7.366e-02, Validation Loss: 3.972e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8450, Training Loss: 7.365e-02, Validation Loss: 3.972e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8451, Training Loss: 7.363e-02, Validation Loss: 3.972e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8452, Training Loss: 7.362e-02, Validation Loss: 3.972e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8453, Training Loss: 7.360e-02, Validation Loss: 3.972e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8454, Training Loss: 7.359e-02, Validation Loss: 3.972e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8455, Training Loss: 7.357e-02, Validation Loss: 3.972e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8456, Training Loss: 7.356e-02, Validation Loss: 3.972e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8457, Training Loss: 7.354e-02, Validation Loss: 3.972e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8458, Training Loss: 7.353e-02, Validation Loss: 3.972e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8459, Training Loss: 7.351e-02, Validation Loss: 3.972e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8460, Training Loss: 7.350e-02, Validation Loss: 3.972e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8461, Training Loss: 7.349e-02, Validation Loss: 3.971e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8462, Training Loss: 7.347e-02, Validation Loss: 3.972e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8463, Training Loss: 7.346e-02, Validation Loss: 3.972e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8464, Training Loss: 7.344e-02, Validation Loss: 3.972e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8465, Training Loss: 7.343e-02, Validation Loss: 3.971e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8466, Training Loss: 7.341e-02, Validation Loss: 3.971e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8467, Training Loss: 7.340e-02, Validation Loss: 3.971e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8468, Training Loss: 7.338e-02, Validation Loss: 3.971e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8469, Training Loss: 7.337e-02, Validation Loss: 3.971e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8470, Training Loss: 7.335e-02, Validation Loss: 3.971e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8471, Training Loss: 7.334e-02, Validation Loss: 3.971e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8472, Training Loss: 7.333e-02, Validation Loss: 3.971e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8473, Training Loss: 7.331e-02, Validation Loss: 3.971e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8474, Training Loss: 7.330e-02, Validation Loss: 3.971e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8475, Training Loss: 7.328e-02, Validation Loss: 3.971e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8476, Training Loss: 7.327e-02, Validation Loss: 3.971e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8477, Training Loss: 7.325e-02, Validation Loss: 3.971e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8478, Training Loss: 7.324e-02, Validation Loss: 3.971e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8479, Training Loss: 7.322e-02, Validation Loss: 3.971e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8480, Training Loss: 7.321e-02, Validation Loss: 3.971e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8481, Training Loss: 7.320e-02, Validation Loss: 3.971e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8482, Training Loss: 7.318e-02, Validation Loss: 3.970e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8483, Training Loss: 7.317e-02, Validation Loss: 3.970e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8484, Training Loss: 7.315e-02, Validation Loss: 3.970e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8485, Training Loss: 7.314e-02, Validation Loss: 3.970e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8486, Training Loss: 7.312e-02, Validation Loss: 3.970e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8487, Training Loss: 7.311e-02, Validation Loss: 3.970e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8488, Training Loss: 7.310e-02, Validation Loss: 3.970e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8489, Training Loss: 7.308e-02, Validation Loss: 3.970e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8490, Training Loss: 7.307e-02, Validation Loss: 3.970e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8491, Training Loss: 7.305e-02, Validation Loss: 3.970e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8492, Training Loss: 7.304e-02, Validation Loss: 3.970e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8493, Training Loss: 7.302e-02, Validation Loss: 3.970e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8494, Training Loss: 7.301e-02, Validation Loss: 3.970e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8495, Training Loss: 7.299e-02, Validation Loss: 3.970e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8496, Training Loss: 7.298e-02, Validation Loss: 3.970e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8497, Training Loss: 7.297e-02, Validation Loss: 3.970e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8498, Training Loss: 7.295e-02, Validation Loss: 3.969e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8499, Training Loss: 7.294e-02, Validation Loss: 3.969e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8500, Training Loss: 7.292e-02, Validation Loss: 3.969e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8501, Training Loss: 7.291e-02, Validation Loss: 3.969e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8502, Training Loss: 7.289e-02, Validation Loss: 3.969e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8503, Training Loss: 7.288e-02, Validation Loss: 3.969e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8504, Training Loss: 7.287e-02, Validation Loss: 3.969e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8505, Training Loss: 7.285e-02, Validation Loss: 3.969e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8506, Training Loss: 7.284e-02, Validation Loss: 3.969e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8507, Training Loss: 7.282e-02, Validation Loss: 3.969e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8508, Training Loss: 7.281e-02, Validation Loss: 3.969e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8509, Training Loss: 7.279e-02, Validation Loss: 3.969e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8510, Training Loss: 7.278e-02, Validation Loss: 3.969e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8511, Training Loss: 7.277e-02, Validation Loss: 3.969e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8512, Training Loss: 7.275e-02, Validation Loss: 3.969e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8513, Training Loss: 7.274e-02, Validation Loss: 3.969e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8514, Training Loss: 7.272e-02, Validation Loss: 3.969e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8515, Training Loss: 7.271e-02, Validation Loss: 3.969e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8516, Training Loss: 7.269e-02, Validation Loss: 3.969e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8517, Training Loss: 7.268e-02, Validation Loss: 3.968e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8518, Training Loss: 7.267e-02, Validation Loss: 3.968e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8519, Training Loss: 7.265e-02, Validation Loss: 3.968e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8520, Training Loss: 7.264e-02, Validation Loss: 3.968e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8521, Training Loss: 7.262e-02, Validation Loss: 3.968e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8522, Training Loss: 7.261e-02, Validation Loss: 3.968e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8523, Training Loss: 7.259e-02, Validation Loss: 3.968e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8524, Training Loss: 7.258e-02, Validation Loss: 3.968e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8525, Training Loss: 7.257e-02, Validation Loss: 3.968e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8526, Training Loss: 7.255e-02, Validation Loss: 3.968e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8527, Training Loss: 7.254e-02, Validation Loss: 3.968e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8528, Training Loss: 7.252e-02, Validation Loss: 3.968e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8529, Training Loss: 7.251e-02, Validation Loss: 3.968e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8530, Training Loss: 7.249e-02, Validation Loss: 3.968e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8531, Training Loss: 7.248e-02, Validation Loss: 3.968e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8532, Training Loss: 7.247e-02, Validation Loss: 3.968e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8533, Training Loss: 7.245e-02, Validation Loss: 3.968e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8534, Training Loss: 7.244e-02, Validation Loss: 3.967e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8535, Training Loss: 7.242e-02, Validation Loss: 3.968e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8536, Training Loss: 7.241e-02, Validation Loss: 3.967e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8537, Training Loss: 7.239e-02, Validation Loss: 3.967e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8538, Training Loss: 7.238e-02, Validation Loss: 3.967e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8539, Training Loss: 7.237e-02, Validation Loss: 3.967e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8540, Training Loss: 7.235e-02, Validation Loss: 3.967e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8541, Training Loss: 7.234e-02, Validation Loss: 3.967e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8542, Training Loss: 7.232e-02, Validation Loss: 3.967e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8543, Training Loss: 7.231e-02, Validation Loss: 3.967e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8544, Training Loss: 7.230e-02, Validation Loss: 3.967e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8545, Training Loss: 7.228e-02, Validation Loss: 3.967e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8546, Training Loss: 7.227e-02, Validation Loss: 3.967e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8547, Training Loss: 7.225e-02, Validation Loss: 3.967e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8548, Training Loss: 7.224e-02, Validation Loss: 3.967e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8549, Training Loss: 7.222e-02, Validation Loss: 3.967e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8550, Training Loss: 7.221e-02, Validation Loss: 3.967e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8551, Training Loss: 7.220e-02, Validation Loss: 3.966e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8552, Training Loss: 7.218e-02, Validation Loss: 3.967e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8553, Training Loss: 7.217e-02, Validation Loss: 3.966e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8554, Training Loss: 7.215e-02, Validation Loss: 3.966e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8555, Training Loss: 7.214e-02, Validation Loss: 3.966e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8556, Training Loss: 7.213e-02, Validation Loss: 3.966e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8557, Training Loss: 7.211e-02, Validation Loss: 3.966e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8558, Training Loss: 7.210e-02, Validation Loss: 3.966e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8559, Training Loss: 7.208e-02, Validation Loss: 3.966e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8560, Training Loss: 7.207e-02, Validation Loss: 3.966e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8561, Training Loss: 7.206e-02, Validation Loss: 3.966e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8562, Training Loss: 7.204e-02, Validation Loss: 3.966e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8563, Training Loss: 7.203e-02, Validation Loss: 3.966e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8564, Training Loss: 7.201e-02, Validation Loss: 3.966e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8565, Training Loss: 7.200e-02, Validation Loss: 3.965e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8566, Training Loss: 7.198e-02, Validation Loss: 3.966e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8567, Training Loss: 7.197e-02, Validation Loss: 3.966e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8568, Training Loss: 7.196e-02, Validation Loss: 3.966e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8569, Training Loss: 7.194e-02, Validation Loss: 3.966e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8570, Training Loss: 7.193e-02, Validation Loss: 3.966e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8571, Training Loss: 7.191e-02, Validation Loss: 3.965e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8572, Training Loss: 7.190e-02, Validation Loss: 3.965e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8573, Training Loss: 7.189e-02, Validation Loss: 3.965e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8574, Training Loss: 7.187e-02, Validation Loss: 3.965e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8575, Training Loss: 7.186e-02, Validation Loss: 3.965e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8576, Training Loss: 7.184e-02, Validation Loss: 3.965e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8577, Training Loss: 7.183e-02, Validation Loss: 3.965e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8578, Training Loss: 7.182e-02, Validation Loss: 3.965e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8579, Training Loss: 7.180e-02, Validation Loss: 3.965e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8580, Training Loss: 7.179e-02, Validation Loss: 3.965e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8581, Training Loss: 7.177e-02, Validation Loss: 3.965e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8582, Training Loss: 7.176e-02, Validation Loss: 3.965e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8583, Training Loss: 7.175e-02, Validation Loss: 3.965e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8584, Training Loss: 7.173e-02, Validation Loss: 3.964e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8585, Training Loss: 7.172e-02, Validation Loss: 3.965e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8586, Training Loss: 7.170e-02, Validation Loss: 3.965e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8587, Training Loss: 7.169e-02, Validation Loss: 3.964e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8588, Training Loss: 7.168e-02, Validation Loss: 3.965e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8589, Training Loss: 7.166e-02, Validation Loss: 3.964e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8590, Training Loss: 7.165e-02, Validation Loss: 3.964e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8591, Training Loss: 7.163e-02, Validation Loss: 3.964e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8592, Training Loss: 7.162e-02, Validation Loss: 3.964e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8593, Training Loss: 7.161e-02, Validation Loss: 3.964e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8594, Training Loss: 7.159e-02, Validation Loss: 3.964e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8595, Training Loss: 7.158e-02, Validation Loss: 3.964e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8596, Training Loss: 7.157e-02, Validation Loss: 3.964e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8597, Training Loss: 7.155e-02, Validation Loss: 3.964e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8598, Training Loss: 7.154e-02, Validation Loss: 3.964e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8599, Training Loss: 7.152e-02, Validation Loss: 3.964e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8600, Training Loss: 7.151e-02, Validation Loss: 3.964e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8601, Training Loss: 7.150e-02, Validation Loss: 3.964e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8602, Training Loss: 7.148e-02, Validation Loss: 3.964e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8603, Training Loss: 7.147e-02, Validation Loss: 3.964e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8604, Training Loss: 7.145e-02, Validation Loss: 3.964e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8605, Training Loss: 7.144e-02, Validation Loss: 3.964e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8606, Training Loss: 7.143e-02, Validation Loss: 3.963e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8607, Training Loss: 7.141e-02, Validation Loss: 3.963e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8608, Training Loss: 7.140e-02, Validation Loss: 3.963e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8609, Training Loss: 7.138e-02, Validation Loss: 3.963e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8610, Training Loss: 7.137e-02, Validation Loss: 3.963e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8611, Training Loss: 7.136e-02, Validation Loss: 3.963e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8612, Training Loss: 7.134e-02, Validation Loss: 3.963e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8613, Training Loss: 7.133e-02, Validation Loss: 3.963e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8614, Training Loss: 7.132e-02, Validation Loss: 3.963e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8615, Training Loss: 7.130e-02, Validation Loss: 3.963e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8616, Training Loss: 7.129e-02, Validation Loss: 3.963e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8617, Training Loss: 7.127e-02, Validation Loss: 3.963e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8618, Training Loss: 7.126e-02, Validation Loss: 3.963e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8619, Training Loss: 7.125e-02, Validation Loss: 3.963e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8620, Training Loss: 7.123e-02, Validation Loss: 3.963e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8621, Training Loss: 7.122e-02, Validation Loss: 3.963e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8622, Training Loss: 7.120e-02, Validation Loss: 3.963e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8623, Training Loss: 7.119e-02, Validation Loss: 3.963e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8624, Training Loss: 7.118e-02, Validation Loss: 3.963e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8625, Training Loss: 7.116e-02, Validation Loss: 3.962e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8626, Training Loss: 7.115e-02, Validation Loss: 3.962e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8627, Training Loss: 7.114e-02, Validation Loss: 3.962e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8628, Training Loss: 7.112e-02, Validation Loss: 3.962e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8629, Training Loss: 7.111e-02, Validation Loss: 3.962e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8630, Training Loss: 7.109e-02, Validation Loss: 3.962e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8631, Training Loss: 7.108e-02, Validation Loss: 3.962e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8632, Training Loss: 7.107e-02, Validation Loss: 3.962e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8633, Training Loss: 7.105e-02, Validation Loss: 3.962e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8634, Training Loss: 7.104e-02, Validation Loss: 3.962e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8635, Training Loss: 7.102e-02, Validation Loss: 3.962e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8636, Training Loss: 7.101e-02, Validation Loss: 3.962e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8637, Training Loss: 7.100e-02, Validation Loss: 3.962e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8638, Training Loss: 7.098e-02, Validation Loss: 3.962e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8639, Training Loss: 7.097e-02, Validation Loss: 3.962e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8640, Training Loss: 7.096e-02, Validation Loss: 3.962e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8641, Training Loss: 7.094e-02, Validation Loss: 3.962e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8642, Training Loss: 7.093e-02, Validation Loss: 3.961e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8643, Training Loss: 7.092e-02, Validation Loss: 3.962e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8644, Training Loss: 7.090e-02, Validation Loss: 3.962e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8645, Training Loss: 7.089e-02, Validation Loss: 3.961e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8646, Training Loss: 7.087e-02, Validation Loss: 3.961e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8647, Training Loss: 7.086e-02, Validation Loss: 3.961e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8648, Training Loss: 7.085e-02, Validation Loss: 3.961e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8649, Training Loss: 7.083e-02, Validation Loss: 3.961e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8650, Training Loss: 7.082e-02, Validation Loss: 3.961e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8651, Training Loss: 7.081e-02, Validation Loss: 3.961e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8652, Training Loss: 7.079e-02, Validation Loss: 3.961e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8653, Training Loss: 7.078e-02, Validation Loss: 3.961e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8654, Training Loss: 7.076e-02, Validation Loss: 3.961e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8655, Training Loss: 7.075e-02, Validation Loss: 3.961e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8656, Training Loss: 7.074e-02, Validation Loss: 3.961e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8657, Training Loss: 7.072e-02, Validation Loss: 3.961e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8658, Training Loss: 7.071e-02, Validation Loss: 3.961e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8659, Training Loss: 7.070e-02, Validation Loss: 3.961e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8660, Training Loss: 7.068e-02, Validation Loss: 3.961e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8661, Training Loss: 7.067e-02, Validation Loss: 3.960e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8662, Training Loss: 7.065e-02, Validation Loss: 3.961e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8663, Training Loss: 7.064e-02, Validation Loss: 3.960e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8664, Training Loss: 7.063e-02, Validation Loss: 3.961e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8665, Training Loss: 7.061e-02, Validation Loss: 3.960e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8666, Training Loss: 7.060e-02, Validation Loss: 3.960e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8667, Training Loss: 7.059e-02, Validation Loss: 3.960e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8668, Training Loss: 7.057e-02, Validation Loss: 3.960e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8669, Training Loss: 7.056e-02, Validation Loss: 3.960e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8670, Training Loss: 7.055e-02, Validation Loss: 3.960e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8671, Training Loss: 7.053e-02, Validation Loss: 3.960e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8672, Training Loss: 7.052e-02, Validation Loss: 3.960e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8673, Training Loss: 7.050e-02, Validation Loss: 3.960e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8674, Training Loss: 7.049e-02, Validation Loss: 3.960e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8675, Training Loss: 7.048e-02, Validation Loss: 3.960e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8676, Training Loss: 7.046e-02, Validation Loss: 3.960e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8677, Training Loss: 7.045e-02, Validation Loss: 3.960e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8678, Training Loss: 7.044e-02, Validation Loss: 3.960e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8679, Training Loss: 7.042e-02, Validation Loss: 3.960e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8680, Training Loss: 7.041e-02, Validation Loss: 3.960e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8681, Training Loss: 7.040e-02, Validation Loss: 3.959e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8682, Training Loss: 7.038e-02, Validation Loss: 3.959e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8683, Training Loss: 7.037e-02, Validation Loss: 3.959e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8684, Training Loss: 7.035e-02, Validation Loss: 3.959e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8685, Training Loss: 7.034e-02, Validation Loss: 3.959e-01, Patience: 3, Learning Rate: 0.01\n",
            "Epoch 8686, Training Loss: 7.033e-02, Validation Loss: 3.959e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8687, Training Loss: 7.031e-02, Validation Loss: 3.959e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8688, Training Loss: 7.030e-02, Validation Loss: 3.959e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8689, Training Loss: 7.029e-02, Validation Loss: 3.959e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8690, Training Loss: 7.027e-02, Validation Loss: 3.959e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8691, Training Loss: 7.026e-02, Validation Loss: 3.959e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8692, Training Loss: 7.025e-02, Validation Loss: 3.959e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8693, Training Loss: 7.023e-02, Validation Loss: 3.959e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8694, Training Loss: 7.022e-02, Validation Loss: 3.959e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8695, Training Loss: 7.021e-02, Validation Loss: 3.959e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8696, Training Loss: 7.019e-02, Validation Loss: 3.959e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8697, Training Loss: 7.018e-02, Validation Loss: 3.959e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8698, Training Loss: 7.017e-02, Validation Loss: 3.959e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8699, Training Loss: 7.015e-02, Validation Loss: 3.959e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8700, Training Loss: 7.014e-02, Validation Loss: 3.959e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8701, Training Loss: 7.013e-02, Validation Loss: 3.958e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8702, Training Loss: 7.011e-02, Validation Loss: 3.959e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8703, Training Loss: 7.010e-02, Validation Loss: 3.958e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8704, Training Loss: 7.008e-02, Validation Loss: 3.958e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8705, Training Loss: 7.007e-02, Validation Loss: 3.958e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8706, Training Loss: 7.006e-02, Validation Loss: 3.958e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8707, Training Loss: 7.004e-02, Validation Loss: 3.958e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8708, Training Loss: 7.003e-02, Validation Loss: 3.958e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8709, Training Loss: 7.002e-02, Validation Loss: 3.958e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8710, Training Loss: 7.000e-02, Validation Loss: 3.958e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8711, Training Loss: 6.999e-02, Validation Loss: 3.958e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8712, Training Loss: 6.998e-02, Validation Loss: 3.958e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8713, Training Loss: 6.996e-02, Validation Loss: 3.958e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8714, Training Loss: 6.995e-02, Validation Loss: 3.958e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8715, Training Loss: 6.994e-02, Validation Loss: 3.958e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8716, Training Loss: 6.992e-02, Validation Loss: 3.958e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8717, Training Loss: 6.991e-02, Validation Loss: 3.958e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8718, Training Loss: 6.990e-02, Validation Loss: 3.958e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8719, Training Loss: 6.988e-02, Validation Loss: 3.957e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8720, Training Loss: 6.987e-02, Validation Loss: 3.958e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8721, Training Loss: 6.986e-02, Validation Loss: 3.958e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8722, Training Loss: 6.984e-02, Validation Loss: 3.958e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8723, Training Loss: 6.983e-02, Validation Loss: 3.957e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8724, Training Loss: 6.982e-02, Validation Loss: 3.957e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8725, Training Loss: 6.980e-02, Validation Loss: 3.957e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8726, Training Loss: 6.979e-02, Validation Loss: 3.957e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8727, Training Loss: 6.978e-02, Validation Loss: 3.957e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8728, Training Loss: 6.976e-02, Validation Loss: 3.957e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8729, Training Loss: 6.975e-02, Validation Loss: 3.957e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8730, Training Loss: 6.974e-02, Validation Loss: 3.957e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8731, Training Loss: 6.972e-02, Validation Loss: 3.957e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8732, Training Loss: 6.971e-02, Validation Loss: 3.957e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8733, Training Loss: 6.970e-02, Validation Loss: 3.957e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8734, Training Loss: 6.968e-02, Validation Loss: 3.957e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8735, Training Loss: 6.967e-02, Validation Loss: 3.957e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8736, Training Loss: 6.966e-02, Validation Loss: 3.957e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8737, Training Loss: 6.964e-02, Validation Loss: 3.957e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8738, Training Loss: 6.963e-02, Validation Loss: 3.957e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8739, Training Loss: 6.962e-02, Validation Loss: 3.957e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8740, Training Loss: 6.960e-02, Validation Loss: 3.956e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8741, Training Loss: 6.959e-02, Validation Loss: 3.957e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8742, Training Loss: 6.957e-02, Validation Loss: 3.956e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8743, Training Loss: 6.956e-02, Validation Loss: 3.956e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8744, Training Loss: 6.955e-02, Validation Loss: 3.956e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8745, Training Loss: 6.953e-02, Validation Loss: 3.956e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8746, Training Loss: 6.952e-02, Validation Loss: 3.956e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8747, Training Loss: 6.951e-02, Validation Loss: 3.956e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8748, Training Loss: 6.949e-02, Validation Loss: 3.956e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8749, Training Loss: 6.948e-02, Validation Loss: 3.956e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8750, Training Loss: 6.947e-02, Validation Loss: 3.956e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8751, Training Loss: 6.946e-02, Validation Loss: 3.956e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8752, Training Loss: 6.944e-02, Validation Loss: 3.956e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8753, Training Loss: 6.943e-02, Validation Loss: 3.956e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8754, Training Loss: 6.942e-02, Validation Loss: 3.956e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8755, Training Loss: 6.940e-02, Validation Loss: 3.955e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8756, Training Loss: 6.939e-02, Validation Loss: 3.956e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8757, Training Loss: 6.938e-02, Validation Loss: 3.956e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8758, Training Loss: 6.936e-02, Validation Loss: 3.956e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8759, Training Loss: 6.935e-02, Validation Loss: 3.956e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8760, Training Loss: 6.934e-02, Validation Loss: 3.955e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8761, Training Loss: 6.932e-02, Validation Loss: 3.955e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8762, Training Loss: 6.931e-02, Validation Loss: 3.955e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8763, Training Loss: 6.930e-02, Validation Loss: 3.955e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8764, Training Loss: 6.928e-02, Validation Loss: 3.955e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8765, Training Loss: 6.927e-02, Validation Loss: 3.955e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8766, Training Loss: 6.926e-02, Validation Loss: 3.955e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8767, Training Loss: 6.924e-02, Validation Loss: 3.955e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8768, Training Loss: 6.923e-02, Validation Loss: 3.955e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8769, Training Loss: 6.922e-02, Validation Loss: 3.955e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8770, Training Loss: 6.920e-02, Validation Loss: 3.955e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8771, Training Loss: 6.919e-02, Validation Loss: 3.955e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8772, Training Loss: 6.918e-02, Validation Loss: 3.955e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8773, Training Loss: 6.916e-02, Validation Loss: 3.955e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8774, Training Loss: 6.915e-02, Validation Loss: 3.955e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8775, Training Loss: 6.914e-02, Validation Loss: 3.955e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8776, Training Loss: 6.912e-02, Validation Loss: 3.955e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8777, Training Loss: 6.911e-02, Validation Loss: 3.954e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8778, Training Loss: 6.910e-02, Validation Loss: 3.955e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8779, Training Loss: 6.908e-02, Validation Loss: 3.955e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8780, Training Loss: 6.907e-02, Validation Loss: 3.955e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8781, Training Loss: 6.906e-02, Validation Loss: 3.954e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8782, Training Loss: 6.904e-02, Validation Loss: 3.954e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8783, Training Loss: 6.903e-02, Validation Loss: 3.954e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8784, Training Loss: 6.902e-02, Validation Loss: 3.954e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8785, Training Loss: 6.900e-02, Validation Loss: 3.954e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8786, Training Loss: 6.899e-02, Validation Loss: 3.954e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8787, Training Loss: 6.898e-02, Validation Loss: 3.954e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8788, Training Loss: 6.897e-02, Validation Loss: 3.954e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8789, Training Loss: 6.895e-02, Validation Loss: 3.954e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8790, Training Loss: 6.894e-02, Validation Loss: 3.954e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8791, Training Loss: 6.893e-02, Validation Loss: 3.954e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8792, Training Loss: 6.891e-02, Validation Loss: 3.954e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8793, Training Loss: 6.890e-02, Validation Loss: 3.954e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8794, Training Loss: 6.889e-02, Validation Loss: 3.954e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8795, Training Loss: 6.887e-02, Validation Loss: 3.954e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8796, Training Loss: 6.886e-02, Validation Loss: 3.954e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8797, Training Loss: 6.885e-02, Validation Loss: 3.954e-01, Patience: 3, Learning Rate: 0.01\n",
            "Epoch 8798, Training Loss: 6.883e-02, Validation Loss: 3.954e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8799, Training Loss: 6.882e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8800, Training Loss: 6.881e-02, Validation Loss: 3.954e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8801, Training Loss: 6.879e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8802, Training Loss: 6.878e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8803, Training Loss: 6.877e-02, Validation Loss: 3.954e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8804, Training Loss: 6.876e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8805, Training Loss: 6.874e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8806, Training Loss: 6.873e-02, Validation Loss: 3.953e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8807, Training Loss: 6.872e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8808, Training Loss: 6.870e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8809, Training Loss: 6.869e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8810, Training Loss: 6.868e-02, Validation Loss: 3.953e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8811, Training Loss: 6.866e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8812, Training Loss: 6.865e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8813, Training Loss: 6.864e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8814, Training Loss: 6.862e-02, Validation Loss: 3.953e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8815, Training Loss: 6.861e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8816, Training Loss: 6.860e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8817, Training Loss: 6.859e-02, Validation Loss: 3.953e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8818, Training Loss: 6.857e-02, Validation Loss: 3.952e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8819, Training Loss: 6.856e-02, Validation Loss: 3.953e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8820, Training Loss: 6.855e-02, Validation Loss: 3.952e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8821, Training Loss: 6.853e-02, Validation Loss: 3.952e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8822, Training Loss: 6.852e-02, Validation Loss: 3.952e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8823, Training Loss: 6.851e-02, Validation Loss: 3.952e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8824, Training Loss: 6.849e-02, Validation Loss: 3.952e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8825, Training Loss: 6.848e-02, Validation Loss: 3.952e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8826, Training Loss: 6.847e-02, Validation Loss: 3.952e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8827, Training Loss: 6.846e-02, Validation Loss: 3.952e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8828, Training Loss: 6.844e-02, Validation Loss: 3.952e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8829, Training Loss: 6.843e-02, Validation Loss: 3.952e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8830, Training Loss: 6.842e-02, Validation Loss: 3.952e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8831, Training Loss: 6.840e-02, Validation Loss: 3.952e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8832, Training Loss: 6.839e-02, Validation Loss: 3.952e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8833, Training Loss: 6.838e-02, Validation Loss: 3.952e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8834, Training Loss: 6.836e-02, Validation Loss: 3.952e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8835, Training Loss: 6.835e-02, Validation Loss: 3.952e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8836, Training Loss: 6.834e-02, Validation Loss: 3.952e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8837, Training Loss: 6.833e-02, Validation Loss: 3.952e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8838, Training Loss: 6.831e-02, Validation Loss: 3.952e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8839, Training Loss: 6.830e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8840, Training Loss: 6.829e-02, Validation Loss: 3.952e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8841, Training Loss: 6.827e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8842, Training Loss: 6.826e-02, Validation Loss: 3.952e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8843, Training Loss: 6.825e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8844, Training Loss: 6.823e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8845, Training Loss: 6.822e-02, Validation Loss: 3.951e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8846, Training Loss: 6.821e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8847, Training Loss: 6.820e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8848, Training Loss: 6.818e-02, Validation Loss: 3.951e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8849, Training Loss: 6.817e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8850, Training Loss: 6.816e-02, Validation Loss: 3.951e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8851, Training Loss: 6.814e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8852, Training Loss: 6.813e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8853, Training Loss: 6.812e-02, Validation Loss: 3.951e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8854, Training Loss: 6.811e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8855, Training Loss: 6.809e-02, Validation Loss: 3.951e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8856, Training Loss: 6.808e-02, Validation Loss: 3.951e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8857, Training Loss: 6.807e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8858, Training Loss: 6.805e-02, Validation Loss: 3.951e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8859, Training Loss: 6.804e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8860, Training Loss: 6.803e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8861, Training Loss: 6.802e-02, Validation Loss: 3.951e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8862, Training Loss: 6.800e-02, Validation Loss: 3.951e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8863, Training Loss: 6.799e-02, Validation Loss: 3.950e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8864, Training Loss: 6.798e-02, Validation Loss: 3.950e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8865, Training Loss: 6.796e-02, Validation Loss: 3.950e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8866, Training Loss: 6.795e-02, Validation Loss: 3.950e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8867, Training Loss: 6.794e-02, Validation Loss: 3.950e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8868, Training Loss: 6.793e-02, Validation Loss: 3.950e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8869, Training Loss: 6.791e-02, Validation Loss: 3.950e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8870, Training Loss: 6.790e-02, Validation Loss: 3.950e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8871, Training Loss: 6.789e-02, Validation Loss: 3.950e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8872, Training Loss: 6.787e-02, Validation Loss: 3.950e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8873, Training Loss: 6.786e-02, Validation Loss: 3.950e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8874, Training Loss: 6.785e-02, Validation Loss: 3.950e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8875, Training Loss: 6.784e-02, Validation Loss: 3.950e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8876, Training Loss: 6.782e-02, Validation Loss: 3.950e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8877, Training Loss: 6.781e-02, Validation Loss: 3.950e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8878, Training Loss: 6.780e-02, Validation Loss: 3.950e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8879, Training Loss: 6.778e-02, Validation Loss: 3.950e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8880, Training Loss: 6.777e-02, Validation Loss: 3.950e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8881, Training Loss: 6.776e-02, Validation Loss: 3.949e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8882, Training Loss: 6.775e-02, Validation Loss: 3.950e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8883, Training Loss: 6.773e-02, Validation Loss: 3.949e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8884, Training Loss: 6.772e-02, Validation Loss: 3.950e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8885, Training Loss: 6.771e-02, Validation Loss: 3.949e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8886, Training Loss: 6.769e-02, Validation Loss: 3.949e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8887, Training Loss: 6.768e-02, Validation Loss: 3.949e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8888, Training Loss: 6.767e-02, Validation Loss: 3.949e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8889, Training Loss: 6.766e-02, Validation Loss: 3.949e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8890, Training Loss: 6.764e-02, Validation Loss: 3.949e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8891, Training Loss: 6.763e-02, Validation Loss: 3.949e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8892, Training Loss: 6.762e-02, Validation Loss: 3.949e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8893, Training Loss: 6.761e-02, Validation Loss: 3.949e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8894, Training Loss: 6.759e-02, Validation Loss: 3.949e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8895, Training Loss: 6.758e-02, Validation Loss: 3.949e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8896, Training Loss: 6.757e-02, Validation Loss: 3.949e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8897, Training Loss: 6.755e-02, Validation Loss: 3.949e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8898, Training Loss: 6.754e-02, Validation Loss: 3.949e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8899, Training Loss: 6.753e-02, Validation Loss: 3.949e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8900, Training Loss: 6.752e-02, Validation Loss: 3.949e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8901, Training Loss: 6.750e-02, Validation Loss: 3.949e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8902, Training Loss: 6.749e-02, Validation Loss: 3.948e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8903, Training Loss: 6.748e-02, Validation Loss: 3.949e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8904, Training Loss: 6.747e-02, Validation Loss: 3.948e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8905, Training Loss: 6.745e-02, Validation Loss: 3.949e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8906, Training Loss: 6.744e-02, Validation Loss: 3.948e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8907, Training Loss: 6.743e-02, Validation Loss: 3.948e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8908, Training Loss: 6.742e-02, Validation Loss: 3.948e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8909, Training Loss: 6.740e-02, Validation Loss: 3.948e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8910, Training Loss: 6.739e-02, Validation Loss: 3.948e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8911, Training Loss: 6.738e-02, Validation Loss: 3.948e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8912, Training Loss: 6.736e-02, Validation Loss: 3.948e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8913, Training Loss: 6.735e-02, Validation Loss: 3.948e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8914, Training Loss: 6.734e-02, Validation Loss: 3.948e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8915, Training Loss: 6.733e-02, Validation Loss: 3.948e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8916, Training Loss: 6.731e-02, Validation Loss: 3.948e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8917, Training Loss: 6.730e-02, Validation Loss: 3.948e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8918, Training Loss: 6.729e-02, Validation Loss: 3.948e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8919, Training Loss: 6.728e-02, Validation Loss: 3.948e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8920, Training Loss: 6.726e-02, Validation Loss: 3.948e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8921, Training Loss: 6.725e-02, Validation Loss: 3.948e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8922, Training Loss: 6.724e-02, Validation Loss: 3.948e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8923, Training Loss: 6.722e-02, Validation Loss: 3.948e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8924, Training Loss: 6.721e-02, Validation Loss: 3.948e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8925, Training Loss: 6.720e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8926, Training Loss: 6.719e-02, Validation Loss: 3.948e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8927, Training Loss: 6.717e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8928, Training Loss: 6.716e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8929, Training Loss: 6.715e-02, Validation Loss: 3.947e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8930, Training Loss: 6.714e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8931, Training Loss: 6.712e-02, Validation Loss: 3.947e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8932, Training Loss: 6.711e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8933, Training Loss: 6.710e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8934, Training Loss: 6.709e-02, Validation Loss: 3.947e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8935, Training Loss: 6.707e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8936, Training Loss: 6.706e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8937, Training Loss: 6.705e-02, Validation Loss: 3.947e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8938, Training Loss: 6.704e-02, Validation Loss: 3.947e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8939, Training Loss: 6.702e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8940, Training Loss: 6.701e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8941, Training Loss: 6.700e-02, Validation Loss: 3.947e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8942, Training Loss: 6.699e-02, Validation Loss: 3.947e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8943, Training Loss: 6.697e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8944, Training Loss: 6.696e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8945, Training Loss: 6.695e-02, Validation Loss: 3.947e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8946, Training Loss: 6.693e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8947, Training Loss: 6.692e-02, Validation Loss: 3.947e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8948, Training Loss: 6.691e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8949, Training Loss: 6.690e-02, Validation Loss: 3.947e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8950, Training Loss: 6.688e-02, Validation Loss: 3.947e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8951, Training Loss: 6.687e-02, Validation Loss: 3.946e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8952, Training Loss: 6.686e-02, Validation Loss: 3.947e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8953, Training Loss: 6.685e-02, Validation Loss: 3.946e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8954, Training Loss: 6.683e-02, Validation Loss: 3.946e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8955, Training Loss: 6.682e-02, Validation Loss: 3.946e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8956, Training Loss: 6.681e-02, Validation Loss: 3.946e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8957, Training Loss: 6.680e-02, Validation Loss: 3.946e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8958, Training Loss: 6.678e-02, Validation Loss: 3.946e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8959, Training Loss: 6.677e-02, Validation Loss: 3.946e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8960, Training Loss: 6.676e-02, Validation Loss: 3.946e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8961, Training Loss: 6.675e-02, Validation Loss: 3.946e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8962, Training Loss: 6.673e-02, Validation Loss: 3.946e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8963, Training Loss: 6.672e-02, Validation Loss: 3.946e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8964, Training Loss: 6.671e-02, Validation Loss: 3.946e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8965, Training Loss: 6.670e-02, Validation Loss: 3.946e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8966, Training Loss: 6.668e-02, Validation Loss: 3.946e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8967, Training Loss: 6.667e-02, Validation Loss: 3.946e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8968, Training Loss: 6.666e-02, Validation Loss: 3.946e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8969, Training Loss: 6.665e-02, Validation Loss: 3.946e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8970, Training Loss: 6.663e-02, Validation Loss: 3.946e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8971, Training Loss: 6.662e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8972, Training Loss: 6.661e-02, Validation Loss: 3.946e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8973, Training Loss: 6.660e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8974, Training Loss: 6.659e-02, Validation Loss: 3.946e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8975, Training Loss: 6.657e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8976, Training Loss: 6.656e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8977, Training Loss: 6.655e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8978, Training Loss: 6.654e-02, Validation Loss: 3.945e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8979, Training Loss: 6.652e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8980, Training Loss: 6.651e-02, Validation Loss: 3.945e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8981, Training Loss: 6.650e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8982, Training Loss: 6.649e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8983, Training Loss: 6.647e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8984, Training Loss: 6.646e-02, Validation Loss: 3.945e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8985, Training Loss: 6.645e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8986, Training Loss: 6.644e-02, Validation Loss: 3.945e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8987, Training Loss: 6.642e-02, Validation Loss: 3.945e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 8988, Training Loss: 6.641e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8989, Training Loss: 6.640e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8990, Training Loss: 6.639e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8991, Training Loss: 6.637e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8992, Training Loss: 6.636e-02, Validation Loss: 3.945e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8993, Training Loss: 6.635e-02, Validation Loss: 3.945e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8994, Training Loss: 6.634e-02, Validation Loss: 3.945e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8995, Training Loss: 6.632e-02, Validation Loss: 3.944e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8996, Training Loss: 6.631e-02, Validation Loss: 3.945e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8997, Training Loss: 6.630e-02, Validation Loss: 3.944e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 8998, Training Loss: 6.629e-02, Validation Loss: 3.945e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 8999, Training Loss: 6.627e-02, Validation Loss: 3.944e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9000, Training Loss: 6.626e-02, Validation Loss: 3.944e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9001, Training Loss: 6.625e-02, Validation Loss: 3.944e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9002, Training Loss: 6.624e-02, Validation Loss: 3.944e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9003, Training Loss: 6.623e-02, Validation Loss: 3.944e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9004, Training Loss: 6.621e-02, Validation Loss: 3.944e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9005, Training Loss: 6.620e-02, Validation Loss: 3.944e-01, Patience: 3, Learning Rate: 0.01\n",
            "Epoch 9006, Training Loss: 6.619e-02, Validation Loss: 3.944e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9007, Training Loss: 6.618e-02, Validation Loss: 3.944e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9008, Training Loss: 6.616e-02, Validation Loss: 3.944e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9009, Training Loss: 6.615e-02, Validation Loss: 3.944e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9010, Training Loss: 6.614e-02, Validation Loss: 3.944e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9011, Training Loss: 6.613e-02, Validation Loss: 3.944e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9012, Training Loss: 6.611e-02, Validation Loss: 3.944e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9013, Training Loss: 6.610e-02, Validation Loss: 3.944e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9014, Training Loss: 6.609e-02, Validation Loss: 3.944e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9015, Training Loss: 6.608e-02, Validation Loss: 3.944e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9016, Training Loss: 6.607e-02, Validation Loss: 3.944e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9017, Training Loss: 6.605e-02, Validation Loss: 3.944e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9018, Training Loss: 6.604e-02, Validation Loss: 3.944e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9019, Training Loss: 6.603e-02, Validation Loss: 3.944e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9020, Training Loss: 6.602e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9021, Training Loss: 6.600e-02, Validation Loss: 3.944e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9022, Training Loss: 6.599e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9023, Training Loss: 6.598e-02, Validation Loss: 3.944e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9024, Training Loss: 6.597e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9025, Training Loss: 6.595e-02, Validation Loss: 3.943e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9026, Training Loss: 6.594e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9027, Training Loss: 6.593e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9028, Training Loss: 6.592e-02, Validation Loss: 3.943e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9029, Training Loss: 6.591e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9030, Training Loss: 6.589e-02, Validation Loss: 3.943e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9031, Training Loss: 6.588e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9032, Training Loss: 6.587e-02, Validation Loss: 3.943e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9033, Training Loss: 6.586e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9034, Training Loss: 6.584e-02, Validation Loss: 3.943e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9035, Training Loss: 6.583e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9036, Training Loss: 6.582e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9037, Training Loss: 6.581e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9038, Training Loss: 6.580e-02, Validation Loss: 3.943e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9039, Training Loss: 6.578e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9040, Training Loss: 6.577e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9041, Training Loss: 6.576e-02, Validation Loss: 3.943e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9042, Training Loss: 6.575e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9043, Training Loss: 6.574e-02, Validation Loss: 3.943e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9044, Training Loss: 6.572e-02, Validation Loss: 3.943e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9045, Training Loss: 6.571e-02, Validation Loss: 3.943e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9046, Training Loss: 6.570e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9047, Training Loss: 6.569e-02, Validation Loss: 3.943e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9048, Training Loss: 6.567e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9049, Training Loss: 6.566e-02, Validation Loss: 3.942e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9050, Training Loss: 6.565e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9051, Training Loss: 6.564e-02, Validation Loss: 3.942e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9052, Training Loss: 6.563e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9053, Training Loss: 6.561e-02, Validation Loss: 3.942e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9054, Training Loss: 6.560e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9055, Training Loss: 6.559e-02, Validation Loss: 3.942e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9056, Training Loss: 6.558e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9057, Training Loss: 6.556e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9058, Training Loss: 6.555e-02, Validation Loss: 3.942e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9059, Training Loss: 6.554e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9060, Training Loss: 6.553e-02, Validation Loss: 3.942e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9061, Training Loss: 6.552e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9062, Training Loss: 6.550e-02, Validation Loss: 3.942e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9063, Training Loss: 6.549e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9064, Training Loss: 6.548e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9065, Training Loss: 6.547e-02, Validation Loss: 3.942e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9066, Training Loss: 6.546e-02, Validation Loss: 3.942e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9067, Training Loss: 6.544e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9068, Training Loss: 6.543e-02, Validation Loss: 3.942e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9069, Training Loss: 6.542e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9070, Training Loss: 6.541e-02, Validation Loss: 3.942e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9071, Training Loss: 6.539e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9072, Training Loss: 6.538e-02, Validation Loss: 3.941e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9073, Training Loss: 6.537e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9074, Training Loss: 6.536e-02, Validation Loss: 3.941e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9075, Training Loss: 6.535e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9076, Training Loss: 6.533e-02, Validation Loss: 3.941e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9077, Training Loss: 6.532e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9078, Training Loss: 6.531e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9079, Training Loss: 6.530e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9080, Training Loss: 6.529e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9081, Training Loss: 6.527e-02, Validation Loss: 3.941e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9082, Training Loss: 6.526e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9083, Training Loss: 6.525e-02, Validation Loss: 3.941e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9084, Training Loss: 6.524e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9085, Training Loss: 6.523e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9086, Training Loss: 6.521e-02, Validation Loss: 3.941e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9087, Training Loss: 6.520e-02, Validation Loss: 3.941e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9088, Training Loss: 6.519e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9089, Training Loss: 6.518e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9090, Training Loss: 6.517e-02, Validation Loss: 3.941e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9091, Training Loss: 6.515e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9092, Training Loss: 6.514e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9093, Training Loss: 6.513e-02, Validation Loss: 3.941e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9094, Training Loss: 6.512e-02, Validation Loss: 3.941e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9095, Training Loss: 6.511e-02, Validation Loss: 3.940e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9096, Training Loss: 6.509e-02, Validation Loss: 3.940e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9097, Training Loss: 6.508e-02, Validation Loss: 3.940e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9098, Training Loss: 6.507e-02, Validation Loss: 3.940e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9099, Training Loss: 6.506e-02, Validation Loss: 3.940e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9100, Training Loss: 6.505e-02, Validation Loss: 3.940e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9101, Training Loss: 6.503e-02, Validation Loss: 3.940e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9102, Training Loss: 6.502e-02, Validation Loss: 3.940e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9103, Training Loss: 6.501e-02, Validation Loss: 3.940e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9104, Training Loss: 6.500e-02, Validation Loss: 3.940e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9105, Training Loss: 6.499e-02, Validation Loss: 3.940e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9106, Training Loss: 6.497e-02, Validation Loss: 3.940e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9107, Training Loss: 6.496e-02, Validation Loss: 3.940e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9108, Training Loss: 6.495e-02, Validation Loss: 3.940e-01, Patience: 3, Learning Rate: 0.01\n",
            "Epoch 9109, Training Loss: 6.494e-02, Validation Loss: 3.940e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9110, Training Loss: 6.493e-02, Validation Loss: 3.940e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9111, Training Loss: 6.491e-02, Validation Loss: 3.940e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9112, Training Loss: 6.490e-02, Validation Loss: 3.940e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9113, Training Loss: 6.489e-02, Validation Loss: 3.940e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9114, Training Loss: 6.488e-02, Validation Loss: 3.940e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9115, Training Loss: 6.487e-02, Validation Loss: 3.940e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9116, Training Loss: 6.485e-02, Validation Loss: 3.940e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9117, Training Loss: 6.484e-02, Validation Loss: 3.940e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9118, Training Loss: 6.483e-02, Validation Loss: 3.940e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9119, Training Loss: 6.482e-02, Validation Loss: 3.940e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9120, Training Loss: 6.481e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9121, Training Loss: 6.479e-02, Validation Loss: 3.940e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9122, Training Loss: 6.478e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9123, Training Loss: 6.477e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9124, Training Loss: 6.476e-02, Validation Loss: 3.939e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9125, Training Loss: 6.475e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9126, Training Loss: 6.473e-02, Validation Loss: 3.939e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9127, Training Loss: 6.472e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9128, Training Loss: 6.471e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9129, Training Loss: 6.470e-02, Validation Loss: 3.939e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9130, Training Loss: 6.469e-02, Validation Loss: 3.939e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9131, Training Loss: 6.468e-02, Validation Loss: 3.939e-01, Patience: 3, Learning Rate: 0.01\n",
            "Epoch 9132, Training Loss: 6.466e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9133, Training Loss: 6.465e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9134, Training Loss: 6.464e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9135, Training Loss: 6.463e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9136, Training Loss: 6.462e-02, Validation Loss: 3.939e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9137, Training Loss: 6.460e-02, Validation Loss: 3.939e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9138, Training Loss: 6.459e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9139, Training Loss: 6.458e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9140, Training Loss: 6.457e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9141, Training Loss: 6.456e-02, Validation Loss: 3.939e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9142, Training Loss: 6.454e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9143, Training Loss: 6.453e-02, Validation Loss: 3.939e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9144, Training Loss: 6.452e-02, Validation Loss: 3.939e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9145, Training Loss: 6.451e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9146, Training Loss: 6.450e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9147, Training Loss: 6.449e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9148, Training Loss: 6.447e-02, Validation Loss: 3.939e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9149, Training Loss: 6.446e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9150, Training Loss: 6.445e-02, Validation Loss: 3.938e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9151, Training Loss: 6.444e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9152, Training Loss: 6.443e-02, Validation Loss: 3.938e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9153, Training Loss: 6.441e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9154, Training Loss: 6.440e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9155, Training Loss: 6.439e-02, Validation Loss: 3.938e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9156, Training Loss: 6.438e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9157, Training Loss: 6.437e-02, Validation Loss: 3.938e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9158, Training Loss: 6.436e-02, Validation Loss: 3.938e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9159, Training Loss: 6.434e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9160, Training Loss: 6.433e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9161, Training Loss: 6.432e-02, Validation Loss: 3.938e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9162, Training Loss: 6.431e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9163, Training Loss: 6.430e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9164, Training Loss: 6.429e-02, Validation Loss: 3.938e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9165, Training Loss: 6.427e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9166, Training Loss: 6.426e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9167, Training Loss: 6.425e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9168, Training Loss: 6.424e-02, Validation Loss: 3.938e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9169, Training Loss: 6.423e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9170, Training Loss: 6.421e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9171, Training Loss: 6.420e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9172, Training Loss: 6.419e-02, Validation Loss: 3.938e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9173, Training Loss: 6.418e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9174, Training Loss: 6.417e-02, Validation Loss: 3.938e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9175, Training Loss: 6.416e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9176, Training Loss: 6.414e-02, Validation Loss: 3.937e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9177, Training Loss: 6.413e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9178, Training Loss: 6.412e-02, Validation Loss: 3.937e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9179, Training Loss: 6.411e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9180, Training Loss: 6.410e-02, Validation Loss: 3.937e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9181, Training Loss: 6.409e-02, Validation Loss: 3.937e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9182, Training Loss: 6.407e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9183, Training Loss: 6.406e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9184, Training Loss: 6.405e-02, Validation Loss: 3.937e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9185, Training Loss: 6.404e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9186, Training Loss: 6.403e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9187, Training Loss: 6.402e-02, Validation Loss: 3.937e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9188, Training Loss: 6.400e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9189, Training Loss: 6.399e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9190, Training Loss: 6.398e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9191, Training Loss: 6.397e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9192, Training Loss: 6.396e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9193, Training Loss: 6.394e-02, Validation Loss: 3.937e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9194, Training Loss: 6.393e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9195, Training Loss: 6.392e-02, Validation Loss: 3.937e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9196, Training Loss: 6.391e-02, Validation Loss: 3.937e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9197, Training Loss: 6.390e-02, Validation Loss: 3.937e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9198, Training Loss: 6.389e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9199, Training Loss: 6.387e-02, Validation Loss: 3.937e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9200, Training Loss: 6.386e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9201, Training Loss: 6.385e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9202, Training Loss: 6.384e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9203, Training Loss: 6.383e-02, Validation Loss: 3.936e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9204, Training Loss: 6.382e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9205, Training Loss: 6.381e-02, Validation Loss: 3.936e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9206, Training Loss: 6.379e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9207, Training Loss: 6.378e-02, Validation Loss: 3.936e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9208, Training Loss: 6.377e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9209, Training Loss: 6.376e-02, Validation Loss: 3.936e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9210, Training Loss: 6.375e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9211, Training Loss: 6.374e-02, Validation Loss: 3.936e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9212, Training Loss: 6.372e-02, Validation Loss: 3.936e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9213, Training Loss: 6.371e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9214, Training Loss: 6.370e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9215, Training Loss: 6.369e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9216, Training Loss: 6.368e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9217, Training Loss: 6.367e-02, Validation Loss: 3.936e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9218, Training Loss: 6.365e-02, Validation Loss: 3.936e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9219, Training Loss: 6.364e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9220, Training Loss: 6.363e-02, Validation Loss: 3.936e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9221, Training Loss: 6.362e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9222, Training Loss: 6.361e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9223, Training Loss: 6.360e-02, Validation Loss: 3.936e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9224, Training Loss: 6.359e-02, Validation Loss: 3.936e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9225, Training Loss: 6.357e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9226, Training Loss: 6.356e-02, Validation Loss: 3.936e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9227, Training Loss: 6.355e-02, Validation Loss: 3.936e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9228, Training Loss: 6.354e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9229, Training Loss: 6.353e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9230, Training Loss: 6.352e-02, Validation Loss: 3.935e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9231, Training Loss: 6.350e-02, Validation Loss: 3.935e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9232, Training Loss: 6.349e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9233, Training Loss: 6.348e-02, Validation Loss: 3.935e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9234, Training Loss: 6.347e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9235, Training Loss: 6.346e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9236, Training Loss: 6.345e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9237, Training Loss: 6.343e-02, Validation Loss: 3.935e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9238, Training Loss: 6.342e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9239, Training Loss: 6.341e-02, Validation Loss: 3.935e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9240, Training Loss: 6.340e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9241, Training Loss: 6.339e-02, Validation Loss: 3.935e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9242, Training Loss: 6.338e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9243, Training Loss: 6.337e-02, Validation Loss: 3.935e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9244, Training Loss: 6.335e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9245, Training Loss: 6.334e-02, Validation Loss: 3.935e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9246, Training Loss: 6.333e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9247, Training Loss: 6.332e-02, Validation Loss: 3.935e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9248, Training Loss: 6.331e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9249, Training Loss: 6.330e-02, Validation Loss: 3.935e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9250, Training Loss: 6.329e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9251, Training Loss: 6.327e-02, Validation Loss: 3.935e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9252, Training Loss: 6.326e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9253, Training Loss: 6.325e-02, Validation Loss: 3.935e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9254, Training Loss: 6.324e-02, Validation Loss: 3.935e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9255, Training Loss: 6.323e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9256, Training Loss: 6.322e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9257, Training Loss: 6.320e-02, Validation Loss: 3.935e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9258, Training Loss: 6.319e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9259, Training Loss: 6.318e-02, Validation Loss: 3.934e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9260, Training Loss: 6.317e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9261, Training Loss: 6.316e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9262, Training Loss: 6.315e-02, Validation Loss: 3.934e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9263, Training Loss: 6.314e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9264, Training Loss: 6.312e-02, Validation Loss: 3.934e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9265, Training Loss: 6.311e-02, Validation Loss: 3.934e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9266, Training Loss: 6.310e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9267, Training Loss: 6.309e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9268, Training Loss: 6.308e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9269, Training Loss: 6.307e-02, Validation Loss: 3.934e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9270, Training Loss: 6.306e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9271, Training Loss: 6.304e-02, Validation Loss: 3.934e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9272, Training Loss: 6.303e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9273, Training Loss: 6.302e-02, Validation Loss: 3.934e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9274, Training Loss: 6.301e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9275, Training Loss: 6.300e-02, Validation Loss: 3.934e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9276, Training Loss: 6.299e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9277, Training Loss: 6.298e-02, Validation Loss: 3.934e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9278, Training Loss: 6.296e-02, Validation Loss: 3.934e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9279, Training Loss: 6.295e-02, Validation Loss: 3.934e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9280, Training Loss: 6.294e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9281, Training Loss: 6.293e-02, Validation Loss: 3.934e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9282, Training Loss: 6.292e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9283, Training Loss: 6.291e-02, Validation Loss: 3.934e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9284, Training Loss: 6.290e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9285, Training Loss: 6.289e-02, Validation Loss: 3.934e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9286, Training Loss: 6.287e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9287, Training Loss: 6.286e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9288, Training Loss: 6.285e-02, Validation Loss: 3.934e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9289, Training Loss: 6.284e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9290, Training Loss: 6.283e-02, Validation Loss: 3.933e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9291, Training Loss: 6.282e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9292, Training Loss: 6.281e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9293, Training Loss: 6.279e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9294, Training Loss: 6.278e-02, Validation Loss: 3.933e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9295, Training Loss: 6.277e-02, Validation Loss: 3.933e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9296, Training Loss: 6.276e-02, Validation Loss: 3.933e-01, Patience: 3, Learning Rate: 0.01\n",
            "Epoch 9297, Training Loss: 6.275e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9298, Training Loss: 6.274e-02, Validation Loss: 3.933e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9299, Training Loss: 6.273e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9300, Training Loss: 6.271e-02, Validation Loss: 3.933e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9301, Training Loss: 6.270e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9302, Training Loss: 6.269e-02, Validation Loss: 3.933e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9303, Training Loss: 6.268e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9304, Training Loss: 6.267e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9305, Training Loss: 6.266e-02, Validation Loss: 3.933e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9306, Training Loss: 6.265e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9307, Training Loss: 6.264e-02, Validation Loss: 3.933e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9308, Training Loss: 6.262e-02, Validation Loss: 3.932e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9309, Training Loss: 6.261e-02, Validation Loss: 3.932e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9310, Training Loss: 6.260e-02, Validation Loss: 3.932e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9311, Training Loss: 6.259e-02, Validation Loss: 3.933e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9312, Training Loss: 6.258e-02, Validation Loss: 3.932e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9313, Training Loss: 6.257e-02, Validation Loss: 3.932e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9314, Training Loss: 6.256e-02, Validation Loss: 3.932e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9315, Training Loss: 6.255e-02, Validation Loss: 3.932e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9316, Training Loss: 6.253e-02, Validation Loss: 3.932e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9317, Training Loss: 6.252e-02, Validation Loss: 3.932e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9318, Training Loss: 6.251e-02, Validation Loss: 3.932e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9319, Training Loss: 6.250e-02, Validation Loss: 3.932e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9320, Training Loss: 6.249e-02, Validation Loss: 3.932e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9321, Training Loss: 6.248e-02, Validation Loss: 3.932e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9322, Training Loss: 6.247e-02, Validation Loss: 3.932e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9323, Training Loss: 6.245e-02, Validation Loss: 3.932e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9324, Training Loss: 6.244e-02, Validation Loss: 3.932e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9325, Training Loss: 6.243e-02, Validation Loss: 3.932e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9326, Training Loss: 6.242e-02, Validation Loss: 3.932e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9327, Training Loss: 6.241e-02, Validation Loss: 3.932e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9328, Training Loss: 6.240e-02, Validation Loss: 3.932e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9329, Training Loss: 6.239e-02, Validation Loss: 3.932e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9330, Training Loss: 6.238e-02, Validation Loss: 3.932e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9331, Training Loss: 6.236e-02, Validation Loss: 3.932e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9332, Training Loss: 6.235e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9333, Training Loss: 6.234e-02, Validation Loss: 3.932e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9334, Training Loss: 6.233e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9335, Training Loss: 6.232e-02, Validation Loss: 3.932e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9336, Training Loss: 6.231e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9337, Training Loss: 6.230e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9338, Training Loss: 6.229e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9339, Training Loss: 6.227e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9340, Training Loss: 6.226e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9341, Training Loss: 6.225e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9342, Training Loss: 6.224e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9343, Training Loss: 6.223e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9344, Training Loss: 6.222e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9345, Training Loss: 6.221e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9346, Training Loss: 6.220e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9347, Training Loss: 6.219e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9348, Training Loss: 6.217e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9349, Training Loss: 6.216e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9350, Training Loss: 6.215e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9351, Training Loss: 6.214e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9352, Training Loss: 6.213e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9353, Training Loss: 6.212e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9354, Training Loss: 6.211e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9355, Training Loss: 6.210e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9356, Training Loss: 6.208e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9357, Training Loss: 6.207e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9358, Training Loss: 6.206e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9359, Training Loss: 6.205e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9360, Training Loss: 6.204e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9361, Training Loss: 6.203e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9362, Training Loss: 6.202e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9363, Training Loss: 6.201e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9364, Training Loss: 6.200e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9365, Training Loss: 6.198e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9366, Training Loss: 6.197e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9367, Training Loss: 6.196e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9368, Training Loss: 6.195e-02, Validation Loss: 3.931e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9369, Training Loss: 6.194e-02, Validation Loss: 3.931e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9370, Training Loss: 6.193e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9371, Training Loss: 6.192e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9372, Training Loss: 6.191e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9373, Training Loss: 6.190e-02, Validation Loss: 3.930e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9374, Training Loss: 6.188e-02, Validation Loss: 3.930e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9375, Training Loss: 6.187e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9376, Training Loss: 6.186e-02, Validation Loss: 3.930e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9377, Training Loss: 6.185e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9378, Training Loss: 6.184e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9379, Training Loss: 6.183e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9380, Training Loss: 6.182e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9381, Training Loss: 6.181e-02, Validation Loss: 3.930e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9382, Training Loss: 6.180e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9383, Training Loss: 6.178e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9384, Training Loss: 6.177e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9385, Training Loss: 6.176e-02, Validation Loss: 3.930e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9386, Training Loss: 6.175e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9387, Training Loss: 6.174e-02, Validation Loss: 3.930e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9388, Training Loss: 6.173e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9389, Training Loss: 6.172e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9390, Training Loss: 6.171e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9391, Training Loss: 6.170e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9392, Training Loss: 6.169e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9393, Training Loss: 6.167e-02, Validation Loss: 3.930e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9394, Training Loss: 6.166e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9395, Training Loss: 6.165e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9396, Training Loss: 6.164e-02, Validation Loss: 3.930e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9397, Training Loss: 6.163e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9398, Training Loss: 6.162e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9399, Training Loss: 6.161e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9400, Training Loss: 6.160e-02, Validation Loss: 3.930e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9401, Training Loss: 6.159e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9402, Training Loss: 6.158e-02, Validation Loss: 3.930e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9403, Training Loss: 6.156e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9404, Training Loss: 6.155e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9405, Training Loss: 6.154e-02, Validation Loss: 3.929e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9406, Training Loss: 6.153e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9407, Training Loss: 6.152e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9408, Training Loss: 6.151e-02, Validation Loss: 3.929e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9409, Training Loss: 6.150e-02, Validation Loss: 3.929e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9410, Training Loss: 6.149e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9411, Training Loss: 6.148e-02, Validation Loss: 3.929e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9412, Training Loss: 6.147e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9413, Training Loss: 6.145e-02, Validation Loss: 3.929e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9414, Training Loss: 6.144e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9415, Training Loss: 6.143e-02, Validation Loss: 3.929e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9416, Training Loss: 6.142e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9417, Training Loss: 6.141e-02, Validation Loss: 3.929e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9418, Training Loss: 6.140e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9419, Training Loss: 6.139e-02, Validation Loss: 3.929e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9420, Training Loss: 6.138e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9421, Training Loss: 6.137e-02, Validation Loss: 3.929e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9422, Training Loss: 6.136e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9423, Training Loss: 6.135e-02, Validation Loss: 3.929e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9424, Training Loss: 6.133e-02, Validation Loss: 3.929e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9425, Training Loss: 6.132e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9426, Training Loss: 6.131e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9427, Training Loss: 6.130e-02, Validation Loss: 3.929e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9428, Training Loss: 6.129e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9429, Training Loss: 6.128e-02, Validation Loss: 3.929e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9430, Training Loss: 6.127e-02, Validation Loss: 3.929e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9431, Training Loss: 6.126e-02, Validation Loss: 3.929e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9432, Training Loss: 6.125e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9433, Training Loss: 6.124e-02, Validation Loss: 3.929e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9434, Training Loss: 6.122e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9435, Training Loss: 6.121e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9436, Training Loss: 6.120e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9437, Training Loss: 6.119e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9438, Training Loss: 6.118e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9439, Training Loss: 6.117e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9440, Training Loss: 6.116e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9441, Training Loss: 6.115e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9442, Training Loss: 6.114e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9443, Training Loss: 6.113e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9444, Training Loss: 6.112e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9445, Training Loss: 6.111e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9446, Training Loss: 6.109e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9447, Training Loss: 6.108e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9448, Training Loss: 6.107e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9449, Training Loss: 6.106e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9450, Training Loss: 6.105e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9451, Training Loss: 6.104e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9452, Training Loss: 6.103e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9453, Training Loss: 6.102e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9454, Training Loss: 6.101e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9455, Training Loss: 6.100e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9456, Training Loss: 6.099e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9457, Training Loss: 6.098e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9458, Training Loss: 6.096e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9459, Training Loss: 6.095e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9460, Training Loss: 6.094e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9461, Training Loss: 6.093e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9462, Training Loss: 6.092e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9463, Training Loss: 6.091e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9464, Training Loss: 6.090e-02, Validation Loss: 3.928e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9465, Training Loss: 6.089e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9466, Training Loss: 6.088e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9467, Training Loss: 6.087e-02, Validation Loss: 3.928e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9468, Training Loss: 6.086e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9469, Training Loss: 6.085e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9470, Training Loss: 6.083e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9471, Training Loss: 6.082e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9472, Training Loss: 6.081e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9473, Training Loss: 6.080e-02, Validation Loss: 3.927e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9474, Training Loss: 6.079e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9475, Training Loss: 6.078e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9476, Training Loss: 6.077e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9477, Training Loss: 6.076e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9478, Training Loss: 6.075e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9479, Training Loss: 6.074e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9480, Training Loss: 6.073e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9481, Training Loss: 6.072e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9482, Training Loss: 6.071e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9483, Training Loss: 6.069e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9484, Training Loss: 6.068e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9485, Training Loss: 6.067e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9486, Training Loss: 6.066e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9487, Training Loss: 6.065e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9488, Training Loss: 6.064e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9489, Training Loss: 6.063e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9490, Training Loss: 6.062e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9491, Training Loss: 6.061e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9492, Training Loss: 6.060e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9493, Training Loss: 6.059e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9494, Training Loss: 6.058e-02, Validation Loss: 3.927e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9495, Training Loss: 6.057e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9496, Training Loss: 6.056e-02, Validation Loss: 3.927e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9497, Training Loss: 6.054e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9498, Training Loss: 6.053e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9499, Training Loss: 6.052e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9500, Training Loss: 6.051e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9501, Training Loss: 6.050e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9502, Training Loss: 6.049e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9503, Training Loss: 6.048e-02, Validation Loss: 3.927e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9504, Training Loss: 6.047e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9505, Training Loss: 6.046e-02, Validation Loss: 3.926e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9506, Training Loss: 6.045e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9507, Training Loss: 6.044e-02, Validation Loss: 3.926e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9508, Training Loss: 6.043e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9509, Training Loss: 6.042e-02, Validation Loss: 3.926e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9510, Training Loss: 6.041e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9511, Training Loss: 6.039e-02, Validation Loss: 3.926e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9512, Training Loss: 6.038e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9513, Training Loss: 6.037e-02, Validation Loss: 3.926e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9514, Training Loss: 6.036e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9515, Training Loss: 6.035e-02, Validation Loss: 3.926e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9516, Training Loss: 6.034e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9517, Training Loss: 6.033e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9518, Training Loss: 6.032e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9519, Training Loss: 6.031e-02, Validation Loss: 3.926e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9520, Training Loss: 6.030e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9521, Training Loss: 6.029e-02, Validation Loss: 3.926e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9522, Training Loss: 6.028e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9523, Training Loss: 6.027e-02, Validation Loss: 3.926e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9524, Training Loss: 6.026e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9525, Training Loss: 6.025e-02, Validation Loss: 3.926e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9526, Training Loss: 6.024e-02, Validation Loss: 3.926e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9527, Training Loss: 6.022e-02, Validation Loss: 3.926e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9528, Training Loss: 6.021e-02, Validation Loss: 3.926e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9529, Training Loss: 6.020e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9530, Training Loss: 6.019e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9531, Training Loss: 6.018e-02, Validation Loss: 3.926e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9532, Training Loss: 6.017e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9533, Training Loss: 6.016e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9534, Training Loss: 6.015e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9535, Training Loss: 6.014e-02, Validation Loss: 3.926e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9536, Training Loss: 6.013e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9537, Training Loss: 6.012e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9538, Training Loss: 6.011e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9539, Training Loss: 6.010e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9540, Training Loss: 6.009e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9541, Training Loss: 6.008e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9542, Training Loss: 6.007e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9543, Training Loss: 6.005e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9544, Training Loss: 6.004e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9545, Training Loss: 6.003e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9546, Training Loss: 6.002e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9547, Training Loss: 6.001e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9548, Training Loss: 6.000e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9549, Training Loss: 5.999e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9550, Training Loss: 5.998e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9551, Training Loss: 5.997e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9552, Training Loss: 5.996e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9553, Training Loss: 5.995e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9554, Training Loss: 5.994e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9555, Training Loss: 5.993e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9556, Training Loss: 5.992e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9557, Training Loss: 5.991e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9558, Training Loss: 5.990e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9559, Training Loss: 5.989e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9560, Training Loss: 5.988e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9561, Training Loss: 5.987e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9562, Training Loss: 5.985e-02, Validation Loss: 3.925e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9563, Training Loss: 5.984e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9564, Training Loss: 5.983e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9565, Training Loss: 5.982e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9566, Training Loss: 5.981e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9567, Training Loss: 5.980e-02, Validation Loss: 3.925e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9568, Training Loss: 5.979e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9569, Training Loss: 5.978e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9570, Training Loss: 5.977e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9571, Training Loss: 5.976e-02, Validation Loss: 3.924e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9572, Training Loss: 5.975e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9573, Training Loss: 5.974e-02, Validation Loss: 3.924e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9574, Training Loss: 5.973e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9575, Training Loss: 5.972e-02, Validation Loss: 3.924e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9576, Training Loss: 5.971e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9577, Training Loss: 5.970e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9578, Training Loss: 5.969e-02, Validation Loss: 3.924e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9579, Training Loss: 5.968e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9580, Training Loss: 5.967e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9581, Training Loss: 5.966e-02, Validation Loss: 3.924e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9582, Training Loss: 5.964e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9583, Training Loss: 5.963e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9584, Training Loss: 5.962e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9585, Training Loss: 5.961e-02, Validation Loss: 3.924e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9586, Training Loss: 5.960e-02, Validation Loss: 3.924e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9587, Training Loss: 5.959e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9588, Training Loss: 5.958e-02, Validation Loss: 3.924e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9589, Training Loss: 5.957e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9590, Training Loss: 5.956e-02, Validation Loss: 3.924e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9591, Training Loss: 5.955e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9592, Training Loss: 5.954e-02, Validation Loss: 3.924e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9593, Training Loss: 5.953e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9594, Training Loss: 5.952e-02, Validation Loss: 3.924e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9595, Training Loss: 5.951e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9596, Training Loss: 5.950e-02, Validation Loss: 3.924e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9597, Training Loss: 5.949e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9598, Training Loss: 5.948e-02, Validation Loss: 3.924e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9599, Training Loss: 5.947e-02, Validation Loss: 3.924e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9600, Training Loss: 5.946e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9601, Training Loss: 5.945e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9602, Training Loss: 5.944e-02, Validation Loss: 3.923e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9603, Training Loss: 5.943e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9604, Training Loss: 5.942e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9605, Training Loss: 5.940e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9606, Training Loss: 5.939e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9607, Training Loss: 5.938e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9608, Training Loss: 5.937e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9609, Training Loss: 5.936e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9610, Training Loss: 5.935e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9611, Training Loss: 5.934e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9612, Training Loss: 5.933e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9613, Training Loss: 5.932e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9614, Training Loss: 5.931e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9615, Training Loss: 5.930e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9616, Training Loss: 5.929e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9617, Training Loss: 5.928e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9618, Training Loss: 5.927e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9619, Training Loss: 5.926e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9620, Training Loss: 5.925e-02, Validation Loss: 3.923e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9621, Training Loss: 5.924e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9622, Training Loss: 5.923e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9623, Training Loss: 5.922e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9624, Training Loss: 5.921e-02, Validation Loss: 3.923e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9625, Training Loss: 5.920e-02, Validation Loss: 3.923e-01, Patience: 3, Learning Rate: 0.01\n",
            "Epoch 9626, Training Loss: 5.919e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9627, Training Loss: 5.918e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9628, Training Loss: 5.917e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9629, Training Loss: 5.916e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9630, Training Loss: 5.915e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9631, Training Loss: 5.914e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9632, Training Loss: 5.913e-02, Validation Loss: 3.923e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9633, Training Loss: 5.912e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9634, Training Loss: 5.911e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9635, Training Loss: 5.909e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9636, Training Loss: 5.908e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9637, Training Loss: 5.907e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9638, Training Loss: 5.906e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9639, Training Loss: 5.905e-02, Validation Loss: 3.923e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9640, Training Loss: 5.904e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9641, Training Loss: 5.903e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9642, Training Loss: 5.902e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9643, Training Loss: 5.901e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9644, Training Loss: 5.900e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9645, Training Loss: 5.899e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9646, Training Loss: 5.898e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9647, Training Loss: 5.897e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9648, Training Loss: 5.896e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9649, Training Loss: 5.895e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9650, Training Loss: 5.894e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9651, Training Loss: 5.893e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9652, Training Loss: 5.892e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9653, Training Loss: 5.891e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9654, Training Loss: 5.890e-02, Validation Loss: 3.922e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9655, Training Loss: 5.889e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9656, Training Loss: 5.888e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9657, Training Loss: 5.887e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9658, Training Loss: 5.886e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9659, Training Loss: 5.885e-02, Validation Loss: 3.922e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9660, Training Loss: 5.884e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9661, Training Loss: 5.883e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9662, Training Loss: 5.882e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9663, Training Loss: 5.881e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9664, Training Loss: 5.880e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9665, Training Loss: 5.879e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9666, Training Loss: 5.878e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9667, Training Loss: 5.877e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9668, Training Loss: 5.876e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9669, Training Loss: 5.875e-02, Validation Loss: 3.922e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9670, Training Loss: 5.874e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9671, Training Loss: 5.873e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9672, Training Loss: 5.872e-02, Validation Loss: 3.922e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9673, Training Loss: 5.871e-02, Validation Loss: 3.922e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9674, Training Loss: 5.869e-02, Validation Loss: 3.922e-01, Patience: 3, Learning Rate: 0.01\n",
            "Epoch 9675, Training Loss: 5.868e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9676, Training Loss: 5.867e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9677, Training Loss: 5.866e-02, Validation Loss: 3.921e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9678, Training Loss: 5.865e-02, Validation Loss: 3.922e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9679, Training Loss: 5.864e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9680, Training Loss: 5.863e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9681, Training Loss: 5.862e-02, Validation Loss: 3.921e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9682, Training Loss: 5.861e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9683, Training Loss: 5.860e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9684, Training Loss: 5.859e-02, Validation Loss: 3.921e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9685, Training Loss: 5.858e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9686, Training Loss: 5.857e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9687, Training Loss: 5.856e-02, Validation Loss: 3.921e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9688, Training Loss: 5.855e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9689, Training Loss: 5.854e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9690, Training Loss: 5.853e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9691, Training Loss: 5.852e-02, Validation Loss: 3.921e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9692, Training Loss: 5.851e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9693, Training Loss: 5.850e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9694, Training Loss: 5.849e-02, Validation Loss: 3.921e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9695, Training Loss: 5.848e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9696, Training Loss: 5.847e-02, Validation Loss: 3.921e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9697, Training Loss: 5.846e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9698, Training Loss: 5.845e-02, Validation Loss: 3.921e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9699, Training Loss: 5.844e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9700, Training Loss: 5.843e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9701, Training Loss: 5.842e-02, Validation Loss: 3.921e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9702, Training Loss: 5.841e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9703, Training Loss: 5.840e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9704, Training Loss: 5.839e-02, Validation Loss: 3.921e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9705, Training Loss: 5.838e-02, Validation Loss: 3.921e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9706, Training Loss: 5.837e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9707, Training Loss: 5.836e-02, Validation Loss: 3.921e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9708, Training Loss: 5.835e-02, Validation Loss: 3.921e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9709, Training Loss: 5.834e-02, Validation Loss: 3.921e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9710, Training Loss: 5.833e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9711, Training Loss: 5.832e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9712, Training Loss: 5.831e-02, Validation Loss: 3.920e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9713, Training Loss: 5.830e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9714, Training Loss: 5.829e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9715, Training Loss: 5.828e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9716, Training Loss: 5.827e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9717, Training Loss: 5.826e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9718, Training Loss: 5.825e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9719, Training Loss: 5.824e-02, Validation Loss: 3.920e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9720, Training Loss: 5.823e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9721, Training Loss: 5.822e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9722, Training Loss: 5.821e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9723, Training Loss: 5.820e-02, Validation Loss: 3.920e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9724, Training Loss: 5.819e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9725, Training Loss: 5.818e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9726, Training Loss: 5.817e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9727, Training Loss: 5.816e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9728, Training Loss: 5.815e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9729, Training Loss: 5.814e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9730, Training Loss: 5.813e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9731, Training Loss: 5.812e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9732, Training Loss: 5.811e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9733, Training Loss: 5.810e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9734, Training Loss: 5.809e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9735, Training Loss: 5.808e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9736, Training Loss: 5.807e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9737, Training Loss: 5.806e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9738, Training Loss: 5.805e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9739, Training Loss: 5.804e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9740, Training Loss: 5.803e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9741, Training Loss: 5.802e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9742, Training Loss: 5.801e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9743, Training Loss: 5.800e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9744, Training Loss: 5.799e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9745, Training Loss: 5.798e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9746, Training Loss: 5.797e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9747, Training Loss: 5.796e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9748, Training Loss: 5.795e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9749, Training Loss: 5.794e-02, Validation Loss: 3.920e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9750, Training Loss: 5.793e-02, Validation Loss: 3.920e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9751, Training Loss: 5.792e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9752, Training Loss: 5.791e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9753, Training Loss: 5.790e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9754, Training Loss: 5.789e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9755, Training Loss: 5.788e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9756, Training Loss: 5.787e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9757, Training Loss: 5.786e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9758, Training Loss: 5.785e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9759, Training Loss: 5.784e-02, Validation Loss: 3.919e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9760, Training Loss: 5.783e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9761, Training Loss: 5.782e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9762, Training Loss: 5.781e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9763, Training Loss: 5.780e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9764, Training Loss: 5.779e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9765, Training Loss: 5.778e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9766, Training Loss: 5.777e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9767, Training Loss: 5.776e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9768, Training Loss: 5.775e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9769, Training Loss: 5.774e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9770, Training Loss: 5.773e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9771, Training Loss: 5.772e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9772, Training Loss: 5.771e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9773, Training Loss: 5.770e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9774, Training Loss: 5.769e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9775, Training Loss: 5.768e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9776, Training Loss: 5.767e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9777, Training Loss: 5.766e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9778, Training Loss: 5.765e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9779, Training Loss: 5.764e-02, Validation Loss: 3.919e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9780, Training Loss: 5.763e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9781, Training Loss: 5.762e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9782, Training Loss: 5.761e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9783, Training Loss: 5.760e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9784, Training Loss: 5.759e-02, Validation Loss: 3.919e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9785, Training Loss: 5.758e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9786, Training Loss: 5.757e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9787, Training Loss: 5.756e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9788, Training Loss: 5.755e-02, Validation Loss: 3.919e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9789, Training Loss: 5.754e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9790, Training Loss: 5.753e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9791, Training Loss: 5.752e-02, Validation Loss: 3.919e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9792, Training Loss: 5.751e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9793, Training Loss: 5.750e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9794, Training Loss: 5.749e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9795, Training Loss: 5.748e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9796, Training Loss: 5.747e-02, Validation Loss: 3.918e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9797, Training Loss: 5.746e-02, Validation Loss: 3.918e-01, Patience: 3, Learning Rate: 0.01\n",
            "Epoch 9798, Training Loss: 5.745e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9799, Training Loss: 5.744e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9800, Training Loss: 5.743e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9801, Training Loss: 5.742e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9802, Training Loss: 5.741e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9803, Training Loss: 5.740e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9804, Training Loss: 5.739e-02, Validation Loss: 3.918e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9805, Training Loss: 5.738e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9806, Training Loss: 5.737e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9807, Training Loss: 5.736e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9808, Training Loss: 5.735e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9809, Training Loss: 5.734e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9810, Training Loss: 5.733e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9811, Training Loss: 5.732e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9812, Training Loss: 5.731e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9813, Training Loss: 5.730e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9814, Training Loss: 5.730e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9815, Training Loss: 5.729e-02, Validation Loss: 3.918e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9816, Training Loss: 5.728e-02, Validation Loss: 3.918e-01, Patience: 3, Learning Rate: 0.01\n",
            "Epoch 9817, Training Loss: 5.727e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9818, Training Loss: 5.726e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9819, Training Loss: 5.725e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9820, Training Loss: 5.724e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9821, Training Loss: 5.723e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9822, Training Loss: 5.722e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9823, Training Loss: 5.721e-02, Validation Loss: 3.918e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9824, Training Loss: 5.720e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9825, Training Loss: 5.719e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9826, Training Loss: 5.718e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9827, Training Loss: 5.717e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9828, Training Loss: 5.716e-02, Validation Loss: 3.918e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9829, Training Loss: 5.715e-02, Validation Loss: 3.918e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9830, Training Loss: 5.714e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9831, Training Loss: 5.713e-02, Validation Loss: 3.918e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9832, Training Loss: 5.712e-02, Validation Loss: 3.918e-01, Patience: 3, Learning Rate: 0.01\n",
            "Epoch 9833, Training Loss: 5.711e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9834, Training Loss: 5.710e-02, Validation Loss: 3.918e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9835, Training Loss: 5.709e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9836, Training Loss: 5.708e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9837, Training Loss: 5.707e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9838, Training Loss: 5.706e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9839, Training Loss: 5.705e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9840, Training Loss: 5.704e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9841, Training Loss: 5.703e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9842, Training Loss: 5.702e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9843, Training Loss: 5.701e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9844, Training Loss: 5.700e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9845, Training Loss: 5.699e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9846, Training Loss: 5.698e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9847, Training Loss: 5.697e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9848, Training Loss: 5.696e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9849, Training Loss: 5.695e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9850, Training Loss: 5.694e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9851, Training Loss: 5.693e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9852, Training Loss: 5.692e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9853, Training Loss: 5.691e-02, Validation Loss: 3.917e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9854, Training Loss: 5.690e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9855, Training Loss: 5.690e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9856, Training Loss: 5.689e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9857, Training Loss: 5.688e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9858, Training Loss: 5.687e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9859, Training Loss: 5.686e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9860, Training Loss: 5.685e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9861, Training Loss: 5.684e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9862, Training Loss: 5.683e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9863, Training Loss: 5.682e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9864, Training Loss: 5.681e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9865, Training Loss: 5.680e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9866, Training Loss: 5.679e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9867, Training Loss: 5.678e-02, Validation Loss: 3.917e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9868, Training Loss: 5.677e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9869, Training Loss: 5.676e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9870, Training Loss: 5.675e-02, Validation Loss: 3.917e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9871, Training Loss: 5.674e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9872, Training Loss: 5.673e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9873, Training Loss: 5.672e-02, Validation Loss: 3.916e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9874, Training Loss: 5.671e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9875, Training Loss: 5.670e-02, Validation Loss: 3.917e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9876, Training Loss: 5.669e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9877, Training Loss: 5.668e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9878, Training Loss: 5.667e-02, Validation Loss: 3.916e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9879, Training Loss: 5.666e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9880, Training Loss: 5.665e-02, Validation Loss: 3.916e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9881, Training Loss: 5.664e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9882, Training Loss: 5.663e-02, Validation Loss: 3.916e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9883, Training Loss: 5.662e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9884, Training Loss: 5.661e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9885, Training Loss: 5.661e-02, Validation Loss: 3.916e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9886, Training Loss: 5.660e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9887, Training Loss: 5.659e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9888, Training Loss: 5.658e-02, Validation Loss: 3.916e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9889, Training Loss: 5.657e-02, Validation Loss: 3.916e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9890, Training Loss: 5.656e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9891, Training Loss: 5.655e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9892, Training Loss: 5.654e-02, Validation Loss: 3.916e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9893, Training Loss: 5.653e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9894, Training Loss: 5.652e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9895, Training Loss: 5.651e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9896, Training Loss: 5.650e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9897, Training Loss: 5.649e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9898, Training Loss: 5.648e-02, Validation Loss: 3.916e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9899, Training Loss: 5.647e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9900, Training Loss: 5.646e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9901, Training Loss: 5.645e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9902, Training Loss: 5.644e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9903, Training Loss: 5.643e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9904, Training Loss: 5.642e-02, Validation Loss: 3.916e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9905, Training Loss: 5.641e-02, Validation Loss: 3.916e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9906, Training Loss: 5.640e-02, Validation Loss: 3.916e-01, Patience: 3, Learning Rate: 0.01\n",
            "Epoch 9907, Training Loss: 5.639e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9908, Training Loss: 5.638e-02, Validation Loss: 3.916e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9909, Training Loss: 5.638e-02, Validation Loss: 3.916e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9910, Training Loss: 5.637e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9911, Training Loss: 5.636e-02, Validation Loss: 3.916e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9912, Training Loss: 5.635e-02, Validation Loss: 3.916e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9913, Training Loss: 5.634e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9914, Training Loss: 5.633e-02, Validation Loss: 3.916e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9915, Training Loss: 5.632e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9916, Training Loss: 5.631e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9917, Training Loss: 5.630e-02, Validation Loss: 3.916e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9918, Training Loss: 5.629e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9919, Training Loss: 5.628e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9920, Training Loss: 5.627e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9921, Training Loss: 5.626e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9922, Training Loss: 5.625e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9923, Training Loss: 5.624e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9924, Training Loss: 5.623e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9925, Training Loss: 5.622e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9926, Training Loss: 5.621e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9927, Training Loss: 5.620e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9928, Training Loss: 5.619e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9929, Training Loss: 5.618e-02, Validation Loss: 3.915e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9930, Training Loss: 5.617e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9931, Training Loss: 5.617e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9932, Training Loss: 5.616e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9933, Training Loss: 5.615e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9934, Training Loss: 5.614e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9935, Training Loss: 5.613e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9936, Training Loss: 5.612e-02, Validation Loss: 3.915e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9937, Training Loss: 5.611e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9938, Training Loss: 5.610e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9939, Training Loss: 5.609e-02, Validation Loss: 3.915e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9940, Training Loss: 5.608e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9941, Training Loss: 5.607e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9942, Training Loss: 5.606e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9943, Training Loss: 5.605e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9944, Training Loss: 5.604e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9945, Training Loss: 5.603e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9946, Training Loss: 5.602e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9947, Training Loss: 5.601e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9948, Training Loss: 5.600e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9949, Training Loss: 5.599e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9950, Training Loss: 5.599e-02, Validation Loss: 3.915e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9951, Training Loss: 5.598e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9952, Training Loss: 5.597e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9953, Training Loss: 5.596e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9954, Training Loss: 5.595e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9955, Training Loss: 5.594e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9956, Training Loss: 5.593e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9957, Training Loss: 5.592e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9958, Training Loss: 5.591e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9959, Training Loss: 5.590e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9960, Training Loss: 5.589e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9961, Training Loss: 5.588e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9962, Training Loss: 5.587e-02, Validation Loss: 3.915e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9963, Training Loss: 5.586e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9964, Training Loss: 5.585e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9965, Training Loss: 5.584e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9966, Training Loss: 5.583e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9967, Training Loss: 5.582e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9968, Training Loss: 5.582e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9969, Training Loss: 5.581e-02, Validation Loss: 3.914e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9970, Training Loss: 5.580e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9971, Training Loss: 5.579e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9972, Training Loss: 5.578e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9973, Training Loss: 5.577e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9974, Training Loss: 5.576e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9975, Training Loss: 5.575e-02, Validation Loss: 3.914e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9976, Training Loss: 5.574e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9977, Training Loss: 5.573e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9978, Training Loss: 5.572e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9979, Training Loss: 5.571e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9980, Training Loss: 5.570e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9981, Training Loss: 5.569e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9982, Training Loss: 5.568e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9983, Training Loss: 5.567e-02, Validation Loss: 3.914e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9984, Training Loss: 5.567e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9985, Training Loss: 5.566e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9986, Training Loss: 5.565e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9987, Training Loss: 5.564e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9988, Training Loss: 5.563e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9989, Training Loss: 5.562e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9990, Training Loss: 5.561e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9991, Training Loss: 5.560e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9992, Training Loss: 5.559e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9993, Training Loss: 5.558e-02, Validation Loss: 3.913e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9994, Training Loss: 5.557e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9995, Training Loss: 5.556e-02, Validation Loss: 3.914e-01, Patience: 2, Learning Rate: 0.01\n",
            "Epoch 9996, Training Loss: 5.555e-02, Validation Loss: 3.913e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9997, Training Loss: 5.554e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9998, Training Loss: 5.553e-02, Validation Loss: 3.914e-01, Patience: 0, Learning Rate: 0.01\n",
            "Epoch 9999, Training Loss: 5.552e-02, Validation Loss: 3.914e-01, Patience: 1, Learning Rate: 0.01\n",
            "Epoch 9999, Training Loss: 5.552e-02, Validation Loss: 3.914e-01, Patience: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Evaluasi**"
      ],
      "metadata": {
        "id": "ejqliMsFzO3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_30.plot_training_error(error_train, error_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "xc9rp8xTzRG8",
        "outputId": "bd172ddc-8890-4d73-e742-1b82f03072c4"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_30.test(X_test, y_test)\n",
        "print(f'X_Test shape: {X_test.shape}')\n",
        "print(f'y_Test shape: {y_test.shape}')\n",
        "print(f'y_Pred shape: {y_pred.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM5hNn3NzUmj",
        "outputId": "67377deb-b0f1-45de-d9e3-94470864a709"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error : 0.4443280992620423\n",
            "X_Test shape: (208, 900)\n",
            "y_Test shape: (208, 15)\n",
            "y_Pred shape: (208, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_30.add_labels_from_folders(input_path)\n",
        "model_30.plot_confusion_matrix(X_test, y_test)\n",
        "model_30.evaluate_metrics(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g3VxAn__zolX",
        "outputId": "0ebf094d-de6f-4749-b33e-504d4a776fb8"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8942307692307693\n",
            "Azmira - Precision: 1.0, Recall: 0.9615384615384616, F1 Score: 0.9803921568627451\n",
            "David - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
            "Dimas - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
            "Fadhli - Precision: 1.0, Recall: 0.8260869565217391, F1 Score: 0.9047619047619047\n",
            "Fadlin - Precision: 0.9545454545454546, Recall: 1.0, F1 Score: 0.9767441860465117\n",
            "Hafidz - Precision: 1.0, Recall: 0.75, F1 Score: 0.8571428571428571\n",
            "Haidar - Precision: 0.7777777777777778, Recall: 1.0, F1 Score: 0.8750000000000001\n",
            "Hanna - Precision: 0.7333333333333333, Recall: 0.9166666666666666, F1 Score: 0.8148148148148148\n",
            "Keiko - Precision: 0.5384615384615384, Recall: 0.7, F1 Score: 0.608695652173913\n",
            "Khansa - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
            "Mikhael - Precision: 1.0, Recall: 0.4166666666666667, F1 Score: 0.5882352941176471\n",
            "Puti - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
            "Raesa - Precision: 0.9230769230769231, Recall: 0.9230769230769231, F1 Score: 0.9230769230769231\n",
            "Satwika - Precision: 0.5625, Recall: 0.8181818181818182, F1 Score: 0.6666666666666666\n",
            "Toni - Precision: 0.9230769230769231, Recall: 0.9230769230769231, F1 Score: 0.9230769230769231\n",
            "Mean Precision: 0.8941847966847968\n",
            "Mean Recall: 0.8823529610486133\n",
            "Mean F1 Score: 0.8745738252493938\n"
          ]
        }
      ]
    }
  ]
}