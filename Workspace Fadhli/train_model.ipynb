{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_image import *\n",
    "from model_nn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found folders: ['Azmira', 'David', 'Dimas', 'Fadhli', 'Fadlin', 'Hafidz', 'Haidar', 'Hanna', 'Keiko', 'Khansa', 'Mikhael', 'Puti', 'Raesa', 'Satwika', 'Toni']\n",
      "(968, 900) (968, 15) (208, 900) (208, 15) (208, 900) (208, 15)\n"
     ]
    }
   ],
   "source": [
    "input_directory = \"../Dataset/Foto_Resize_Rotate_70x70\" \n",
    "X_train, y_train, X_test, y_test, X_val, y_val, scalerinput = process_all(input_directory)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_50 = FaceRecognitionModel(X_train.shape[1], [64], y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params rewritten\n",
      "Epoch 0, Training Loss: 3.189e+00, Validation Loss: 3.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1, Training Loss: 3.157e+00, Validation Loss: 3.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2, Training Loss: 3.126e+00, Validation Loss: 3.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3, Training Loss: 3.098e+00, Validation Loss: 3.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4, Training Loss: 3.071e+00, Validation Loss: 3.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5, Training Loss: 3.047e+00, Validation Loss: 2.983e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6, Training Loss: 3.024e+00, Validation Loss: 2.966e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7, Training Loss: 3.003e+00, Validation Loss: 2.950e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8, Training Loss: 2.983e+00, Validation Loss: 2.935e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9, Training Loss: 2.965e+00, Validation Loss: 2.921e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10, Training Loss: 2.948e+00, Validation Loss: 2.908e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11, Training Loss: 2.932e+00, Validation Loss: 2.896e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12, Training Loss: 2.917e+00, Validation Loss: 2.885e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13, Training Loss: 2.903e+00, Validation Loss: 2.875e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14, Training Loss: 2.889e+00, Validation Loss: 2.866e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15, Training Loss: 2.877e+00, Validation Loss: 2.857e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16, Training Loss: 2.865e+00, Validation Loss: 2.848e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17, Training Loss: 2.855e+00, Validation Loss: 2.841e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18, Training Loss: 2.845e+00, Validation Loss: 2.834e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19, Training Loss: 2.835e+00, Validation Loss: 2.827e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 20, Training Loss: 2.826e+00, Validation Loss: 2.821e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 21, Training Loss: 2.818e+00, Validation Loss: 2.815e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 22, Training Loss: 2.810e+00, Validation Loss: 2.810e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 23, Training Loss: 2.803e+00, Validation Loss: 2.805e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 24, Training Loss: 2.796e+00, Validation Loss: 2.801e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 25, Training Loss: 2.790e+00, Validation Loss: 2.796e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 26, Training Loss: 2.784e+00, Validation Loss: 2.792e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 27, Training Loss: 2.778e+00, Validation Loss: 2.789e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 28, Training Loss: 2.773e+00, Validation Loss: 2.785e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 29, Training Loss: 2.768e+00, Validation Loss: 2.782e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 30, Training Loss: 2.763e+00, Validation Loss: 2.778e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 31, Training Loss: 2.758e+00, Validation Loss: 2.775e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 32, Training Loss: 2.754e+00, Validation Loss: 2.772e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 33, Training Loss: 2.750e+00, Validation Loss: 2.770e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 34, Training Loss: 2.746e+00, Validation Loss: 2.767e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 35, Training Loss: 2.742e+00, Validation Loss: 2.765e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 36, Training Loss: 2.739e+00, Validation Loss: 2.762e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 37, Training Loss: 2.735e+00, Validation Loss: 2.760e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 38, Training Loss: 2.732e+00, Validation Loss: 2.758e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 39, Training Loss: 2.729e+00, Validation Loss: 2.756e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 40, Training Loss: 2.726e+00, Validation Loss: 2.754e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 41, Training Loss: 2.723e+00, Validation Loss: 2.752e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 42, Training Loss: 2.721e+00, Validation Loss: 2.750e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 43, Training Loss: 2.718e+00, Validation Loss: 2.749e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 44, Training Loss: 2.715e+00, Validation Loss: 2.747e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 45, Training Loss: 2.713e+00, Validation Loss: 2.745e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 46, Training Loss: 2.711e+00, Validation Loss: 2.743e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 47, Training Loss: 2.708e+00, Validation Loss: 2.742e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 48, Training Loss: 2.706e+00, Validation Loss: 2.740e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 49, Training Loss: 2.704e+00, Validation Loss: 2.739e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 50, Training Loss: 2.702e+00, Validation Loss: 2.737e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 51, Training Loss: 2.700e+00, Validation Loss: 2.736e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 52, Training Loss: 2.698e+00, Validation Loss: 2.735e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 53, Training Loss: 2.696e+00, Validation Loss: 2.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 54, Training Loss: 2.694e+00, Validation Loss: 2.732e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 55, Training Loss: 2.693e+00, Validation Loss: 2.731e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 56, Training Loss: 2.691e+00, Validation Loss: 2.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 57, Training Loss: 2.689e+00, Validation Loss: 2.728e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 58, Training Loss: 2.688e+00, Validation Loss: 2.727e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 59, Training Loss: 2.686e+00, Validation Loss: 2.726e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 60, Training Loss: 2.685e+00, Validation Loss: 2.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 61, Training Loss: 2.683e+00, Validation Loss: 2.724e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 62, Training Loss: 2.682e+00, Validation Loss: 2.723e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 63, Training Loss: 2.680e+00, Validation Loss: 2.722e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 64, Training Loss: 2.679e+00, Validation Loss: 2.721e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 65, Training Loss: 2.678e+00, Validation Loss: 2.720e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 66, Training Loss: 2.677e+00, Validation Loss: 2.719e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 67, Training Loss: 2.675e+00, Validation Loss: 2.718e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 68, Training Loss: 2.674e+00, Validation Loss: 2.717e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 69, Training Loss: 2.673e+00, Validation Loss: 2.716e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 70, Training Loss: 2.672e+00, Validation Loss: 2.715e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 71, Training Loss: 2.671e+00, Validation Loss: 2.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 72, Training Loss: 2.669e+00, Validation Loss: 2.713e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 73, Training Loss: 2.668e+00, Validation Loss: 2.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 74, Training Loss: 2.667e+00, Validation Loss: 2.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 75, Training Loss: 2.666e+00, Validation Loss: 2.711e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 76, Training Loss: 2.665e+00, Validation Loss: 2.710e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 77, Training Loss: 2.664e+00, Validation Loss: 2.709e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 78, Training Loss: 2.663e+00, Validation Loss: 2.708e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 79, Training Loss: 2.663e+00, Validation Loss: 2.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 80, Training Loss: 2.662e+00, Validation Loss: 2.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 81, Training Loss: 2.661e+00, Validation Loss: 2.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 82, Training Loss: 2.660e+00, Validation Loss: 2.705e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 83, Training Loss: 2.659e+00, Validation Loss: 2.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 84, Training Loss: 2.658e+00, Validation Loss: 2.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 85, Training Loss: 2.657e+00, Validation Loss: 2.703e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 86, Training Loss: 2.656e+00, Validation Loss: 2.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 87, Training Loss: 2.655e+00, Validation Loss: 2.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 88, Training Loss: 2.655e+00, Validation Loss: 2.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 89, Training Loss: 2.654e+00, Validation Loss: 2.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 90, Training Loss: 2.653e+00, Validation Loss: 2.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 91, Training Loss: 2.652e+00, Validation Loss: 2.699e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 92, Training Loss: 2.651e+00, Validation Loss: 2.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 93, Training Loss: 2.651e+00, Validation Loss: 2.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 94, Training Loss: 2.650e+00, Validation Loss: 2.697e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 95, Training Loss: 2.649e+00, Validation Loss: 2.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 96, Training Loss: 2.648e+00, Validation Loss: 2.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 97, Training Loss: 2.648e+00, Validation Loss: 2.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 98, Training Loss: 2.647e+00, Validation Loss: 2.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 99, Training Loss: 2.646e+00, Validation Loss: 2.694e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 100, Training Loss: 2.645e+00, Validation Loss: 2.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 101, Training Loss: 2.645e+00, Validation Loss: 2.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 102, Training Loss: 2.644e+00, Validation Loss: 2.692e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 103, Training Loss: 2.643e+00, Validation Loss: 2.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 104, Training Loss: 2.642e+00, Validation Loss: 2.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 105, Training Loss: 2.642e+00, Validation Loss: 2.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 106, Training Loss: 2.641e+00, Validation Loss: 2.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 107, Training Loss: 2.640e+00, Validation Loss: 2.689e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 108, Training Loss: 2.640e+00, Validation Loss: 2.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 109, Training Loss: 2.639e+00, Validation Loss: 2.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 110, Training Loss: 2.638e+00, Validation Loss: 2.687e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 111, Training Loss: 2.638e+00, Validation Loss: 2.687e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 112, Training Loss: 2.637e+00, Validation Loss: 2.686e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 113, Training Loss: 2.636e+00, Validation Loss: 2.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 114, Training Loss: 2.636e+00, Validation Loss: 2.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 115, Training Loss: 2.635e+00, Validation Loss: 2.684e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 116, Training Loss: 2.634e+00, Validation Loss: 2.684e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 117, Training Loss: 2.634e+00, Validation Loss: 2.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 118, Training Loss: 2.633e+00, Validation Loss: 2.682e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 119, Training Loss: 2.632e+00, Validation Loss: 2.682e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 120, Training Loss: 2.632e+00, Validation Loss: 2.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 121, Training Loss: 2.631e+00, Validation Loss: 2.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 122, Training Loss: 2.631e+00, Validation Loss: 2.680e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 123, Training Loss: 2.630e+00, Validation Loss: 2.680e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 124, Training Loss: 2.629e+00, Validation Loss: 2.679e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 125, Training Loss: 2.629e+00, Validation Loss: 2.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 126, Training Loss: 2.628e+00, Validation Loss: 2.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 127, Training Loss: 2.628e+00, Validation Loss: 2.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 128, Training Loss: 2.627e+00, Validation Loss: 2.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 129, Training Loss: 2.627e+00, Validation Loss: 2.676e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 130, Training Loss: 2.626e+00, Validation Loss: 2.676e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 131, Training Loss: 2.626e+00, Validation Loss: 2.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 132, Training Loss: 2.625e+00, Validation Loss: 2.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 133, Training Loss: 2.625e+00, Validation Loss: 2.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 134, Training Loss: 2.624e+00, Validation Loss: 2.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 135, Training Loss: 2.623e+00, Validation Loss: 2.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 136, Training Loss: 2.623e+00, Validation Loss: 2.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 137, Training Loss: 2.622e+00, Validation Loss: 2.672e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 138, Training Loss: 2.622e+00, Validation Loss: 2.672e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 139, Training Loss: 2.621e+00, Validation Loss: 2.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 140, Training Loss: 2.621e+00, Validation Loss: 2.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 141, Training Loss: 2.620e+00, Validation Loss: 2.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 142, Training Loss: 2.620e+00, Validation Loss: 2.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 143, Training Loss: 2.619e+00, Validation Loss: 2.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 144, Training Loss: 2.619e+00, Validation Loss: 2.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 145, Training Loss: 2.618e+00, Validation Loss: 2.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 146, Training Loss: 2.618e+00, Validation Loss: 2.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 147, Training Loss: 2.617e+00, Validation Loss: 2.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 148, Training Loss: 2.617e+00, Validation Loss: 2.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 149, Training Loss: 2.616e+00, Validation Loss: 2.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 150, Training Loss: 2.616e+00, Validation Loss: 2.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 151, Training Loss: 2.616e+00, Validation Loss: 2.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 152, Training Loss: 2.615e+00, Validation Loss: 2.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 153, Training Loss: 2.615e+00, Validation Loss: 2.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 154, Training Loss: 2.614e+00, Validation Loss: 2.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 155, Training Loss: 2.614e+00, Validation Loss: 2.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 156, Training Loss: 2.613e+00, Validation Loss: 2.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 157, Training Loss: 2.613e+00, Validation Loss: 2.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 158, Training Loss: 2.612e+00, Validation Loss: 2.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 159, Training Loss: 2.612e+00, Validation Loss: 2.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 160, Training Loss: 2.612e+00, Validation Loss: 2.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 161, Training Loss: 2.611e+00, Validation Loss: 2.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 162, Training Loss: 2.611e+00, Validation Loss: 2.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 163, Training Loss: 2.610e+00, Validation Loss: 2.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 164, Training Loss: 2.610e+00, Validation Loss: 2.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 165, Training Loss: 2.609e+00, Validation Loss: 2.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 166, Training Loss: 2.609e+00, Validation Loss: 2.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 167, Training Loss: 2.608e+00, Validation Loss: 2.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 168, Training Loss: 2.608e+00, Validation Loss: 2.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 169, Training Loss: 2.608e+00, Validation Loss: 2.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 170, Training Loss: 2.607e+00, Validation Loss: 2.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 171, Training Loss: 2.607e+00, Validation Loss: 2.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 172, Training Loss: 2.606e+00, Validation Loss: 2.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 173, Training Loss: 2.606e+00, Validation Loss: 2.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 174, Training Loss: 2.605e+00, Validation Loss: 2.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 175, Training Loss: 2.605e+00, Validation Loss: 2.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 176, Training Loss: 2.605e+00, Validation Loss: 2.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 177, Training Loss: 2.604e+00, Validation Loss: 2.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 178, Training Loss: 2.604e+00, Validation Loss: 2.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 179, Training Loss: 2.604e+00, Validation Loss: 2.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 180, Training Loss: 2.603e+00, Validation Loss: 2.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 181, Training Loss: 2.603e+00, Validation Loss: 2.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 182, Training Loss: 2.602e+00, Validation Loss: 2.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 183, Training Loss: 2.602e+00, Validation Loss: 2.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 184, Training Loss: 2.602e+00, Validation Loss: 2.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 185, Training Loss: 2.601e+00, Validation Loss: 2.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 186, Training Loss: 2.601e+00, Validation Loss: 2.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 187, Training Loss: 2.601e+00, Validation Loss: 2.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 188, Training Loss: 2.600e+00, Validation Loss: 2.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 189, Training Loss: 2.600e+00, Validation Loss: 2.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 190, Training Loss: 2.600e+00, Validation Loss: 2.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 191, Training Loss: 2.599e+00, Validation Loss: 2.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 192, Training Loss: 2.599e+00, Validation Loss: 2.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 193, Training Loss: 2.599e+00, Validation Loss: 2.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 194, Training Loss: 2.598e+00, Validation Loss: 2.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 195, Training Loss: 2.598e+00, Validation Loss: 2.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 196, Training Loss: 2.598e+00, Validation Loss: 2.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 197, Training Loss: 2.597e+00, Validation Loss: 2.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 198, Training Loss: 2.597e+00, Validation Loss: 2.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 199, Training Loss: 2.597e+00, Validation Loss: 2.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 200, Training Loss: 2.596e+00, Validation Loss: 2.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 201, Training Loss: 2.596e+00, Validation Loss: 2.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 202, Training Loss: 2.596e+00, Validation Loss: 2.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 203, Training Loss: 2.595e+00, Validation Loss: 2.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 204, Training Loss: 2.595e+00, Validation Loss: 2.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 205, Training Loss: 2.595e+00, Validation Loss: 2.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 206, Training Loss: 2.594e+00, Validation Loss: 2.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 207, Training Loss: 2.594e+00, Validation Loss: 2.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 208, Training Loss: 2.594e+00, Validation Loss: 2.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 209, Training Loss: 2.593e+00, Validation Loss: 2.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 210, Training Loss: 2.593e+00, Validation Loss: 2.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 211, Training Loss: 2.593e+00, Validation Loss: 2.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 212, Training Loss: 2.592e+00, Validation Loss: 2.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 213, Training Loss: 2.592e+00, Validation Loss: 2.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 214, Training Loss: 2.592e+00, Validation Loss: 2.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 215, Training Loss: 2.592e+00, Validation Loss: 2.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 216, Training Loss: 2.591e+00, Validation Loss: 2.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 217, Training Loss: 2.591e+00, Validation Loss: 2.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 218, Training Loss: 2.591e+00, Validation Loss: 2.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 219, Training Loss: 2.590e+00, Validation Loss: 2.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 220, Training Loss: 2.590e+00, Validation Loss: 2.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 221, Training Loss: 2.590e+00, Validation Loss: 2.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 222, Training Loss: 2.589e+00, Validation Loss: 2.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 223, Training Loss: 2.589e+00, Validation Loss: 2.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 224, Training Loss: 2.589e+00, Validation Loss: 2.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 225, Training Loss: 2.589e+00, Validation Loss: 2.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 226, Training Loss: 2.588e+00, Validation Loss: 2.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 227, Training Loss: 2.588e+00, Validation Loss: 2.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 228, Training Loss: 2.588e+00, Validation Loss: 2.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 229, Training Loss: 2.587e+00, Validation Loss: 2.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 230, Training Loss: 2.587e+00, Validation Loss: 2.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 231, Training Loss: 2.587e+00, Validation Loss: 2.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 232, Training Loss: 2.587e+00, Validation Loss: 2.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 233, Training Loss: 2.586e+00, Validation Loss: 2.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 234, Training Loss: 2.586e+00, Validation Loss: 2.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 235, Training Loss: 2.586e+00, Validation Loss: 2.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 236, Training Loss: 2.585e+00, Validation Loss: 2.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 237, Training Loss: 2.585e+00, Validation Loss: 2.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 238, Training Loss: 2.585e+00, Validation Loss: 2.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 239, Training Loss: 2.585e+00, Validation Loss: 2.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 240, Training Loss: 2.584e+00, Validation Loss: 2.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 241, Training Loss: 2.584e+00, Validation Loss: 2.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 242, Training Loss: 2.584e+00, Validation Loss: 2.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 243, Training Loss: 2.583e+00, Validation Loss: 2.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 244, Training Loss: 2.583e+00, Validation Loss: 2.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 245, Training Loss: 2.583e+00, Validation Loss: 2.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 246, Training Loss: 2.583e+00, Validation Loss: 2.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 247, Training Loss: 2.582e+00, Validation Loss: 2.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 248, Training Loss: 2.582e+00, Validation Loss: 2.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 249, Training Loss: 2.582e+00, Validation Loss: 2.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 250, Training Loss: 2.581e+00, Validation Loss: 2.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 251, Training Loss: 2.581e+00, Validation Loss: 2.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 252, Training Loss: 2.581e+00, Validation Loss: 2.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 253, Training Loss: 2.581e+00, Validation Loss: 2.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 254, Training Loss: 2.580e+00, Validation Loss: 2.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 255, Training Loss: 2.580e+00, Validation Loss: 2.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 256, Training Loss: 2.580e+00, Validation Loss: 2.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 257, Training Loss: 2.580e+00, Validation Loss: 2.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 258, Training Loss: 2.579e+00, Validation Loss: 2.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 259, Training Loss: 2.579e+00, Validation Loss: 2.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 260, Training Loss: 2.579e+00, Validation Loss: 2.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 261, Training Loss: 2.578e+00, Validation Loss: 2.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 262, Training Loss: 2.578e+00, Validation Loss: 2.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 263, Training Loss: 2.578e+00, Validation Loss: 2.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 264, Training Loss: 2.578e+00, Validation Loss: 2.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 265, Training Loss: 2.577e+00, Validation Loss: 2.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 266, Training Loss: 2.577e+00, Validation Loss: 2.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 267, Training Loss: 2.577e+00, Validation Loss: 2.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 268, Training Loss: 2.577e+00, Validation Loss: 2.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 269, Training Loss: 2.576e+00, Validation Loss: 2.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 270, Training Loss: 2.576e+00, Validation Loss: 2.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 271, Training Loss: 2.576e+00, Validation Loss: 2.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 272, Training Loss: 2.576e+00, Validation Loss: 2.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 273, Training Loss: 2.575e+00, Validation Loss: 2.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 274, Training Loss: 2.575e+00, Validation Loss: 2.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 275, Training Loss: 2.575e+00, Validation Loss: 2.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 276, Training Loss: 2.574e+00, Validation Loss: 2.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 277, Training Loss: 2.574e+00, Validation Loss: 2.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 278, Training Loss: 2.574e+00, Validation Loss: 2.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 279, Training Loss: 2.574e+00, Validation Loss: 2.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 280, Training Loss: 2.573e+00, Validation Loss: 2.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 281, Training Loss: 2.573e+00, Validation Loss: 2.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 282, Training Loss: 2.573e+00, Validation Loss: 2.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 283, Training Loss: 2.573e+00, Validation Loss: 2.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 284, Training Loss: 2.572e+00, Validation Loss: 2.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 285, Training Loss: 2.572e+00, Validation Loss: 2.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 286, Training Loss: 2.572e+00, Validation Loss: 2.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 287, Training Loss: 2.572e+00, Validation Loss: 2.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 288, Training Loss: 2.571e+00, Validation Loss: 2.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 289, Training Loss: 2.571e+00, Validation Loss: 2.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 290, Training Loss: 2.571e+00, Validation Loss: 2.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 291, Training Loss: 2.571e+00, Validation Loss: 2.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 292, Training Loss: 2.570e+00, Validation Loss: 2.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 293, Training Loss: 2.570e+00, Validation Loss: 2.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 294, Training Loss: 2.570e+00, Validation Loss: 2.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 295, Training Loss: 2.570e+00, Validation Loss: 2.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 296, Training Loss: 2.569e+00, Validation Loss: 2.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 297, Training Loss: 2.569e+00, Validation Loss: 2.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 298, Training Loss: 2.569e+00, Validation Loss: 2.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 299, Training Loss: 2.568e+00, Validation Loss: 2.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 300, Training Loss: 2.568e+00, Validation Loss: 2.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 301, Training Loss: 2.568e+00, Validation Loss: 2.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 302, Training Loss: 2.568e+00, Validation Loss: 2.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 303, Training Loss: 2.567e+00, Validation Loss: 2.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 304, Training Loss: 2.567e+00, Validation Loss: 2.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 305, Training Loss: 2.567e+00, Validation Loss: 2.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 306, Training Loss: 2.567e+00, Validation Loss: 2.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 307, Training Loss: 2.566e+00, Validation Loss: 2.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 308, Training Loss: 2.566e+00, Validation Loss: 2.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 309, Training Loss: 2.566e+00, Validation Loss: 2.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 310, Training Loss: 2.566e+00, Validation Loss: 2.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 311, Training Loss: 2.565e+00, Validation Loss: 2.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 312, Training Loss: 2.565e+00, Validation Loss: 2.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 313, Training Loss: 2.565e+00, Validation Loss: 2.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 314, Training Loss: 2.565e+00, Validation Loss: 2.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 315, Training Loss: 2.564e+00, Validation Loss: 2.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 316, Training Loss: 2.564e+00, Validation Loss: 2.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 317, Training Loss: 2.564e+00, Validation Loss: 2.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 318, Training Loss: 2.564e+00, Validation Loss: 2.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 319, Training Loss: 2.563e+00, Validation Loss: 2.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 320, Training Loss: 2.563e+00, Validation Loss: 2.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 321, Training Loss: 2.563e+00, Validation Loss: 2.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 322, Training Loss: 2.562e+00, Validation Loss: 2.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 323, Training Loss: 2.562e+00, Validation Loss: 2.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 324, Training Loss: 2.562e+00, Validation Loss: 2.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 325, Training Loss: 2.562e+00, Validation Loss: 2.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 326, Training Loss: 2.561e+00, Validation Loss: 2.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 327, Training Loss: 2.561e+00, Validation Loss: 2.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 328, Training Loss: 2.561e+00, Validation Loss: 2.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 329, Training Loss: 2.561e+00, Validation Loss: 2.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 330, Training Loss: 2.560e+00, Validation Loss: 2.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 331, Training Loss: 2.560e+00, Validation Loss: 2.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 332, Training Loss: 2.560e+00, Validation Loss: 2.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 333, Training Loss: 2.560e+00, Validation Loss: 2.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 334, Training Loss: 2.559e+00, Validation Loss: 2.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 335, Training Loss: 2.559e+00, Validation Loss: 2.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 336, Training Loss: 2.559e+00, Validation Loss: 2.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 337, Training Loss: 2.559e+00, Validation Loss: 2.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 338, Training Loss: 2.558e+00, Validation Loss: 2.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 339, Training Loss: 2.558e+00, Validation Loss: 2.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 340, Training Loss: 2.558e+00, Validation Loss: 2.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 341, Training Loss: 2.558e+00, Validation Loss: 2.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 342, Training Loss: 2.557e+00, Validation Loss: 2.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 343, Training Loss: 2.557e+00, Validation Loss: 2.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 344, Training Loss: 2.557e+00, Validation Loss: 2.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 345, Training Loss: 2.557e+00, Validation Loss: 2.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 346, Training Loss: 2.556e+00, Validation Loss: 2.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 347, Training Loss: 2.556e+00, Validation Loss: 2.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 348, Training Loss: 2.556e+00, Validation Loss: 2.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 349, Training Loss: 2.556e+00, Validation Loss: 2.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 350, Training Loss: 2.555e+00, Validation Loss: 2.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 351, Training Loss: 2.555e+00, Validation Loss: 2.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 352, Training Loss: 2.555e+00, Validation Loss: 2.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 353, Training Loss: 2.554e+00, Validation Loss: 2.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 354, Training Loss: 2.554e+00, Validation Loss: 2.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 355, Training Loss: 2.554e+00, Validation Loss: 2.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 356, Training Loss: 2.554e+00, Validation Loss: 2.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 357, Training Loss: 2.553e+00, Validation Loss: 2.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 358, Training Loss: 2.553e+00, Validation Loss: 2.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 359, Training Loss: 2.553e+00, Validation Loss: 2.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 360, Training Loss: 2.553e+00, Validation Loss: 2.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 361, Training Loss: 2.552e+00, Validation Loss: 2.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 362, Training Loss: 2.552e+00, Validation Loss: 2.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 363, Training Loss: 2.552e+00, Validation Loss: 2.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 364, Training Loss: 2.552e+00, Validation Loss: 2.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 365, Training Loss: 2.551e+00, Validation Loss: 2.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 366, Training Loss: 2.551e+00, Validation Loss: 2.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 367, Training Loss: 2.551e+00, Validation Loss: 2.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 368, Training Loss: 2.551e+00, Validation Loss: 2.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 369, Training Loss: 2.550e+00, Validation Loss: 2.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 370, Training Loss: 2.550e+00, Validation Loss: 2.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 371, Training Loss: 2.550e+00, Validation Loss: 2.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 372, Training Loss: 2.550e+00, Validation Loss: 2.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 373, Training Loss: 2.549e+00, Validation Loss: 2.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 374, Training Loss: 2.549e+00, Validation Loss: 2.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 375, Training Loss: 2.549e+00, Validation Loss: 2.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 376, Training Loss: 2.549e+00, Validation Loss: 2.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 377, Training Loss: 2.548e+00, Validation Loss: 2.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 378, Training Loss: 2.548e+00, Validation Loss: 2.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 379, Training Loss: 2.548e+00, Validation Loss: 2.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 380, Training Loss: 2.548e+00, Validation Loss: 2.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 381, Training Loss: 2.547e+00, Validation Loss: 2.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 382, Training Loss: 2.547e+00, Validation Loss: 2.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 383, Training Loss: 2.547e+00, Validation Loss: 2.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 384, Training Loss: 2.547e+00, Validation Loss: 2.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 385, Training Loss: 2.546e+00, Validation Loss: 2.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 386, Training Loss: 2.546e+00, Validation Loss: 2.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 387, Training Loss: 2.546e+00, Validation Loss: 2.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 388, Training Loss: 2.546e+00, Validation Loss: 2.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 389, Training Loss: 2.545e+00, Validation Loss: 2.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 390, Training Loss: 2.545e+00, Validation Loss: 2.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 391, Training Loss: 2.545e+00, Validation Loss: 2.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 392, Training Loss: 2.545e+00, Validation Loss: 2.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 393, Training Loss: 2.544e+00, Validation Loss: 2.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 394, Training Loss: 2.544e+00, Validation Loss: 2.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 395, Training Loss: 2.544e+00, Validation Loss: 2.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 396, Training Loss: 2.544e+00, Validation Loss: 2.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 397, Training Loss: 2.543e+00, Validation Loss: 2.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 398, Training Loss: 2.543e+00, Validation Loss: 2.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 399, Training Loss: 2.543e+00, Validation Loss: 2.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 400, Training Loss: 2.543e+00, Validation Loss: 2.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 401, Training Loss: 2.542e+00, Validation Loss: 2.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 402, Training Loss: 2.542e+00, Validation Loss: 2.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 403, Training Loss: 2.542e+00, Validation Loss: 2.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 404, Training Loss: 2.542e+00, Validation Loss: 2.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 405, Training Loss: 2.541e+00, Validation Loss: 2.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 406, Training Loss: 2.541e+00, Validation Loss: 2.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 407, Training Loss: 2.541e+00, Validation Loss: 2.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 408, Training Loss: 2.540e+00, Validation Loss: 2.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 409, Training Loss: 2.540e+00, Validation Loss: 2.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 410, Training Loss: 2.540e+00, Validation Loss: 2.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 411, Training Loss: 2.540e+00, Validation Loss: 2.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 412, Training Loss: 2.539e+00, Validation Loss: 2.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 413, Training Loss: 2.539e+00, Validation Loss: 2.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 414, Training Loss: 2.539e+00, Validation Loss: 2.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 415, Training Loss: 2.539e+00, Validation Loss: 2.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 416, Training Loss: 2.538e+00, Validation Loss: 2.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 417, Training Loss: 2.538e+00, Validation Loss: 2.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 418, Training Loss: 2.538e+00, Validation Loss: 2.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 419, Training Loss: 2.538e+00, Validation Loss: 2.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 420, Training Loss: 2.537e+00, Validation Loss: 2.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 421, Training Loss: 2.537e+00, Validation Loss: 2.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 422, Training Loss: 2.537e+00, Validation Loss: 2.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 423, Training Loss: 2.537e+00, Validation Loss: 2.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 424, Training Loss: 2.536e+00, Validation Loss: 2.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 425, Training Loss: 2.536e+00, Validation Loss: 2.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 426, Training Loss: 2.536e+00, Validation Loss: 2.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 427, Training Loss: 2.536e+00, Validation Loss: 2.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 428, Training Loss: 2.535e+00, Validation Loss: 2.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 429, Training Loss: 2.535e+00, Validation Loss: 2.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 430, Training Loss: 2.535e+00, Validation Loss: 2.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 431, Training Loss: 2.535e+00, Validation Loss: 2.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 432, Training Loss: 2.534e+00, Validation Loss: 2.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 433, Training Loss: 2.534e+00, Validation Loss: 2.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 434, Training Loss: 2.534e+00, Validation Loss: 2.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 435, Training Loss: 2.534e+00, Validation Loss: 2.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 436, Training Loss: 2.533e+00, Validation Loss: 2.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 437, Training Loss: 2.533e+00, Validation Loss: 2.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 438, Training Loss: 2.533e+00, Validation Loss: 2.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 439, Training Loss: 2.533e+00, Validation Loss: 2.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 440, Training Loss: 2.532e+00, Validation Loss: 2.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 441, Training Loss: 2.532e+00, Validation Loss: 2.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 442, Training Loss: 2.532e+00, Validation Loss: 2.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 443, Training Loss: 2.532e+00, Validation Loss: 2.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 444, Training Loss: 2.532e+00, Validation Loss: 2.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 445, Training Loss: 2.531e+00, Validation Loss: 2.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 446, Training Loss: 2.531e+00, Validation Loss: 2.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 447, Training Loss: 2.531e+00, Validation Loss: 2.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 448, Training Loss: 2.531e+00, Validation Loss: 2.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 449, Training Loss: 2.530e+00, Validation Loss: 2.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 450, Training Loss: 2.530e+00, Validation Loss: 2.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 451, Training Loss: 2.530e+00, Validation Loss: 2.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 452, Training Loss: 2.530e+00, Validation Loss: 2.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 453, Training Loss: 2.529e+00, Validation Loss: 2.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 454, Training Loss: 2.529e+00, Validation Loss: 2.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 455, Training Loss: 2.529e+00, Validation Loss: 2.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 456, Training Loss: 2.529e+00, Validation Loss: 2.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 457, Training Loss: 2.528e+00, Validation Loss: 2.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 458, Training Loss: 2.528e+00, Validation Loss: 2.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 459, Training Loss: 2.528e+00, Validation Loss: 2.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 460, Training Loss: 2.528e+00, Validation Loss: 2.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 461, Training Loss: 2.527e+00, Validation Loss: 2.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 462, Training Loss: 2.527e+00, Validation Loss: 2.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 463, Training Loss: 2.527e+00, Validation Loss: 2.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 464, Training Loss: 2.527e+00, Validation Loss: 2.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 465, Training Loss: 2.527e+00, Validation Loss: 2.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 466, Training Loss: 2.526e+00, Validation Loss: 2.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 467, Training Loss: 2.526e+00, Validation Loss: 2.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 468, Training Loss: 2.526e+00, Validation Loss: 2.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 469, Training Loss: 2.526e+00, Validation Loss: 2.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 470, Training Loss: 2.525e+00, Validation Loss: 2.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 471, Training Loss: 2.525e+00, Validation Loss: 2.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 472, Training Loss: 2.525e+00, Validation Loss: 2.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 473, Training Loss: 2.525e+00, Validation Loss: 2.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 474, Training Loss: 2.524e+00, Validation Loss: 2.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 475, Training Loss: 2.524e+00, Validation Loss: 2.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 476, Training Loss: 2.524e+00, Validation Loss: 2.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 477, Training Loss: 2.524e+00, Validation Loss: 2.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 478, Training Loss: 2.524e+00, Validation Loss: 2.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 479, Training Loss: 2.523e+00, Validation Loss: 2.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 480, Training Loss: 2.523e+00, Validation Loss: 2.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 481, Training Loss: 2.523e+00, Validation Loss: 2.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 482, Training Loss: 2.523e+00, Validation Loss: 2.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 483, Training Loss: 2.522e+00, Validation Loss: 2.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 484, Training Loss: 2.522e+00, Validation Loss: 2.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 485, Training Loss: 2.522e+00, Validation Loss: 2.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 486, Training Loss: 2.522e+00, Validation Loss: 2.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 487, Training Loss: 2.521e+00, Validation Loss: 2.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 488, Training Loss: 2.521e+00, Validation Loss: 2.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 489, Training Loss: 2.521e+00, Validation Loss: 2.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 490, Training Loss: 2.521e+00, Validation Loss: 2.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 491, Training Loss: 2.521e+00, Validation Loss: 2.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 492, Training Loss: 2.520e+00, Validation Loss: 2.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 493, Training Loss: 2.520e+00, Validation Loss: 2.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 494, Training Loss: 2.520e+00, Validation Loss: 2.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 495, Training Loss: 2.520e+00, Validation Loss: 2.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 496, Training Loss: 2.519e+00, Validation Loss: 2.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 497, Training Loss: 2.519e+00, Validation Loss: 2.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 498, Training Loss: 2.519e+00, Validation Loss: 2.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 499, Training Loss: 2.519e+00, Validation Loss: 2.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 500, Training Loss: 2.518e+00, Validation Loss: 2.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 501, Training Loss: 2.518e+00, Validation Loss: 2.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 502, Training Loss: 2.518e+00, Validation Loss: 2.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 503, Training Loss: 2.518e+00, Validation Loss: 2.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 504, Training Loss: 2.518e+00, Validation Loss: 2.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 505, Training Loss: 2.517e+00, Validation Loss: 2.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 506, Training Loss: 2.517e+00, Validation Loss: 2.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 507, Training Loss: 2.517e+00, Validation Loss: 2.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 508, Training Loss: 2.517e+00, Validation Loss: 2.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 509, Training Loss: 2.516e+00, Validation Loss: 2.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 510, Training Loss: 2.516e+00, Validation Loss: 2.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 511, Training Loss: 2.516e+00, Validation Loss: 2.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 512, Training Loss: 2.516e+00, Validation Loss: 2.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 513, Training Loss: 2.515e+00, Validation Loss: 2.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 514, Training Loss: 2.515e+00, Validation Loss: 2.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 515, Training Loss: 2.515e+00, Validation Loss: 2.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 516, Training Loss: 2.515e+00, Validation Loss: 2.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 517, Training Loss: 2.515e+00, Validation Loss: 2.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 518, Training Loss: 2.514e+00, Validation Loss: 2.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 519, Training Loss: 2.514e+00, Validation Loss: 2.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 520, Training Loss: 2.514e+00, Validation Loss: 2.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 521, Training Loss: 2.514e+00, Validation Loss: 2.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 522, Training Loss: 2.513e+00, Validation Loss: 2.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 523, Training Loss: 2.513e+00, Validation Loss: 2.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 524, Training Loss: 2.513e+00, Validation Loss: 2.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 525, Training Loss: 2.513e+00, Validation Loss: 2.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 526, Training Loss: 2.513e+00, Validation Loss: 2.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 527, Training Loss: 2.512e+00, Validation Loss: 2.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 528, Training Loss: 2.512e+00, Validation Loss: 2.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 529, Training Loss: 2.512e+00, Validation Loss: 2.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 530, Training Loss: 2.512e+00, Validation Loss: 2.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 531, Training Loss: 2.511e+00, Validation Loss: 2.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 532, Training Loss: 2.511e+00, Validation Loss: 2.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 533, Training Loss: 2.511e+00, Validation Loss: 2.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 534, Training Loss: 2.511e+00, Validation Loss: 2.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 535, Training Loss: 2.510e+00, Validation Loss: 2.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 536, Training Loss: 2.510e+00, Validation Loss: 2.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 537, Training Loss: 2.510e+00, Validation Loss: 2.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 538, Training Loss: 2.510e+00, Validation Loss: 2.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 539, Training Loss: 2.510e+00, Validation Loss: 2.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 540, Training Loss: 2.509e+00, Validation Loss: 2.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 541, Training Loss: 2.509e+00, Validation Loss: 2.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 542, Training Loss: 2.509e+00, Validation Loss: 2.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 543, Training Loss: 2.509e+00, Validation Loss: 2.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 544, Training Loss: 2.508e+00, Validation Loss: 2.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 545, Training Loss: 2.508e+00, Validation Loss: 2.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 546, Training Loss: 2.508e+00, Validation Loss: 2.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 547, Training Loss: 2.508e+00, Validation Loss: 2.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 548, Training Loss: 2.508e+00, Validation Loss: 2.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 549, Training Loss: 2.507e+00, Validation Loss: 2.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 550, Training Loss: 2.507e+00, Validation Loss: 2.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 551, Training Loss: 2.507e+00, Validation Loss: 2.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 552, Training Loss: 2.507e+00, Validation Loss: 2.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 553, Training Loss: 2.506e+00, Validation Loss: 2.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 554, Training Loss: 2.506e+00, Validation Loss: 2.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 555, Training Loss: 2.506e+00, Validation Loss: 2.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 556, Training Loss: 2.506e+00, Validation Loss: 2.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 557, Training Loss: 2.505e+00, Validation Loss: 2.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 558, Training Loss: 2.505e+00, Validation Loss: 2.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 559, Training Loss: 2.505e+00, Validation Loss: 2.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 560, Training Loss: 2.505e+00, Validation Loss: 2.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 561, Training Loss: 2.505e+00, Validation Loss: 2.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 562, Training Loss: 2.504e+00, Validation Loss: 2.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 563, Training Loss: 2.504e+00, Validation Loss: 2.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 564, Training Loss: 2.504e+00, Validation Loss: 2.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 565, Training Loss: 2.504e+00, Validation Loss: 2.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 566, Training Loss: 2.503e+00, Validation Loss: 2.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 567, Training Loss: 2.503e+00, Validation Loss: 2.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 568, Training Loss: 2.503e+00, Validation Loss: 2.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 569, Training Loss: 2.503e+00, Validation Loss: 2.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 570, Training Loss: 2.503e+00, Validation Loss: 2.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 571, Training Loss: 2.502e+00, Validation Loss: 2.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 572, Training Loss: 2.502e+00, Validation Loss: 2.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 573, Training Loss: 2.502e+00, Validation Loss: 2.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 574, Training Loss: 2.502e+00, Validation Loss: 2.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 575, Training Loss: 2.501e+00, Validation Loss: 2.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 576, Training Loss: 2.501e+00, Validation Loss: 2.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 577, Training Loss: 2.501e+00, Validation Loss: 2.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 578, Training Loss: 2.501e+00, Validation Loss: 2.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 579, Training Loss: 2.500e+00, Validation Loss: 2.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 580, Training Loss: 2.500e+00, Validation Loss: 2.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 581, Training Loss: 2.500e+00, Validation Loss: 2.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 582, Training Loss: 2.500e+00, Validation Loss: 2.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 583, Training Loss: 2.500e+00, Validation Loss: 2.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 584, Training Loss: 2.499e+00, Validation Loss: 2.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 585, Training Loss: 2.499e+00, Validation Loss: 2.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 586, Training Loss: 2.499e+00, Validation Loss: 2.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 587, Training Loss: 2.499e+00, Validation Loss: 2.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 588, Training Loss: 2.498e+00, Validation Loss: 2.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 589, Training Loss: 2.498e+00, Validation Loss: 2.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 590, Training Loss: 2.498e+00, Validation Loss: 2.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 591, Training Loss: 2.498e+00, Validation Loss: 2.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 592, Training Loss: 2.498e+00, Validation Loss: 2.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 593, Training Loss: 2.497e+00, Validation Loss: 2.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 594, Training Loss: 2.497e+00, Validation Loss: 2.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 595, Training Loss: 2.497e+00, Validation Loss: 2.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 596, Training Loss: 2.497e+00, Validation Loss: 2.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 597, Training Loss: 2.496e+00, Validation Loss: 2.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 598, Training Loss: 2.496e+00, Validation Loss: 2.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 599, Training Loss: 2.496e+00, Validation Loss: 2.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 600, Training Loss: 2.496e+00, Validation Loss: 2.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 601, Training Loss: 2.496e+00, Validation Loss: 2.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 602, Training Loss: 2.495e+00, Validation Loss: 2.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 603, Training Loss: 2.495e+00, Validation Loss: 2.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 604, Training Loss: 2.495e+00, Validation Loss: 2.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 605, Training Loss: 2.495e+00, Validation Loss: 2.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 606, Training Loss: 2.494e+00, Validation Loss: 2.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 607, Training Loss: 2.494e+00, Validation Loss: 2.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 608, Training Loss: 2.494e+00, Validation Loss: 2.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 609, Training Loss: 2.494e+00, Validation Loss: 2.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 610, Training Loss: 2.494e+00, Validation Loss: 2.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 611, Training Loss: 2.493e+00, Validation Loss: 2.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 612, Training Loss: 2.493e+00, Validation Loss: 2.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 613, Training Loss: 2.493e+00, Validation Loss: 2.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 614, Training Loss: 2.493e+00, Validation Loss: 2.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 615, Training Loss: 2.492e+00, Validation Loss: 2.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 616, Training Loss: 2.492e+00, Validation Loss: 2.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 617, Training Loss: 2.492e+00, Validation Loss: 2.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 618, Training Loss: 2.492e+00, Validation Loss: 2.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 619, Training Loss: 2.492e+00, Validation Loss: 2.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 620, Training Loss: 2.491e+00, Validation Loss: 2.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 621, Training Loss: 2.491e+00, Validation Loss: 2.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 622, Training Loss: 2.491e+00, Validation Loss: 2.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 623, Training Loss: 2.491e+00, Validation Loss: 2.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 624, Training Loss: 2.490e+00, Validation Loss: 2.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 625, Training Loss: 2.490e+00, Validation Loss: 2.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 626, Training Loss: 2.490e+00, Validation Loss: 2.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 627, Training Loss: 2.490e+00, Validation Loss: 2.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 628, Training Loss: 2.490e+00, Validation Loss: 2.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 629, Training Loss: 2.489e+00, Validation Loss: 2.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 630, Training Loss: 2.489e+00, Validation Loss: 2.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 631, Training Loss: 2.489e+00, Validation Loss: 2.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 632, Training Loss: 2.489e+00, Validation Loss: 2.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 633, Training Loss: 2.488e+00, Validation Loss: 2.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 634, Training Loss: 2.488e+00, Validation Loss: 2.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 635, Training Loss: 2.488e+00, Validation Loss: 2.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 636, Training Loss: 2.488e+00, Validation Loss: 2.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 637, Training Loss: 2.488e+00, Validation Loss: 2.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 638, Training Loss: 2.487e+00, Validation Loss: 2.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 639, Training Loss: 2.487e+00, Validation Loss: 2.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 640, Training Loss: 2.487e+00, Validation Loss: 2.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 641, Training Loss: 2.487e+00, Validation Loss: 2.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 642, Training Loss: 2.486e+00, Validation Loss: 2.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 643, Training Loss: 2.486e+00, Validation Loss: 2.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 644, Training Loss: 2.486e+00, Validation Loss: 2.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 645, Training Loss: 2.486e+00, Validation Loss: 2.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 646, Training Loss: 2.486e+00, Validation Loss: 2.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 647, Training Loss: 2.485e+00, Validation Loss: 2.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 648, Training Loss: 2.485e+00, Validation Loss: 2.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 649, Training Loss: 2.485e+00, Validation Loss: 2.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 650, Training Loss: 2.485e+00, Validation Loss: 2.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 651, Training Loss: 2.484e+00, Validation Loss: 2.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 652, Training Loss: 2.484e+00, Validation Loss: 2.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 653, Training Loss: 2.484e+00, Validation Loss: 2.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 654, Training Loss: 2.484e+00, Validation Loss: 2.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 655, Training Loss: 2.484e+00, Validation Loss: 2.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 656, Training Loss: 2.483e+00, Validation Loss: 2.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 657, Training Loss: 2.483e+00, Validation Loss: 2.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 658, Training Loss: 2.483e+00, Validation Loss: 2.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 659, Training Loss: 2.483e+00, Validation Loss: 2.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 660, Training Loss: 2.483e+00, Validation Loss: 2.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 661, Training Loss: 2.482e+00, Validation Loss: 2.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 662, Training Loss: 2.482e+00, Validation Loss: 2.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 663, Training Loss: 2.482e+00, Validation Loss: 2.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 664, Training Loss: 2.482e+00, Validation Loss: 2.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 665, Training Loss: 2.481e+00, Validation Loss: 2.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 666, Training Loss: 2.481e+00, Validation Loss: 2.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 667, Training Loss: 2.481e+00, Validation Loss: 2.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 668, Training Loss: 2.481e+00, Validation Loss: 2.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 669, Training Loss: 2.481e+00, Validation Loss: 2.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 670, Training Loss: 2.480e+00, Validation Loss: 2.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 671, Training Loss: 2.480e+00, Validation Loss: 2.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 672, Training Loss: 2.480e+00, Validation Loss: 2.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 673, Training Loss: 2.480e+00, Validation Loss: 2.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 674, Training Loss: 2.479e+00, Validation Loss: 2.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 675, Training Loss: 2.479e+00, Validation Loss: 2.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 676, Training Loss: 2.479e+00, Validation Loss: 2.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 677, Training Loss: 2.479e+00, Validation Loss: 2.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 678, Training Loss: 2.479e+00, Validation Loss: 2.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 679, Training Loss: 2.478e+00, Validation Loss: 2.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 680, Training Loss: 2.478e+00, Validation Loss: 2.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 681, Training Loss: 2.478e+00, Validation Loss: 2.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 682, Training Loss: 2.478e+00, Validation Loss: 2.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 683, Training Loss: 2.478e+00, Validation Loss: 2.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 684, Training Loss: 2.477e+00, Validation Loss: 2.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 685, Training Loss: 2.477e+00, Validation Loss: 2.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 686, Training Loss: 2.477e+00, Validation Loss: 2.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 687, Training Loss: 2.477e+00, Validation Loss: 2.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 688, Training Loss: 2.476e+00, Validation Loss: 2.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 689, Training Loss: 2.476e+00, Validation Loss: 2.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 690, Training Loss: 2.476e+00, Validation Loss: 2.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 691, Training Loss: 2.476e+00, Validation Loss: 2.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 692, Training Loss: 2.476e+00, Validation Loss: 2.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 693, Training Loss: 2.475e+00, Validation Loss: 2.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 694, Training Loss: 2.475e+00, Validation Loss: 2.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 695, Training Loss: 2.475e+00, Validation Loss: 2.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 696, Training Loss: 2.475e+00, Validation Loss: 2.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 697, Training Loss: 2.475e+00, Validation Loss: 2.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 698, Training Loss: 2.474e+00, Validation Loss: 2.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 699, Training Loss: 2.474e+00, Validation Loss: 2.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 700, Training Loss: 2.474e+00, Validation Loss: 2.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 701, Training Loss: 2.474e+00, Validation Loss: 2.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 702, Training Loss: 2.473e+00, Validation Loss: 2.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 703, Training Loss: 2.473e+00, Validation Loss: 2.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 704, Training Loss: 2.473e+00, Validation Loss: 2.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 705, Training Loss: 2.473e+00, Validation Loss: 2.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 706, Training Loss: 2.473e+00, Validation Loss: 2.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 707, Training Loss: 2.472e+00, Validation Loss: 2.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 708, Training Loss: 2.472e+00, Validation Loss: 2.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 709, Training Loss: 2.472e+00, Validation Loss: 2.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 710, Training Loss: 2.472e+00, Validation Loss: 2.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 711, Training Loss: 2.471e+00, Validation Loss: 2.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 712, Training Loss: 2.471e+00, Validation Loss: 2.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 713, Training Loss: 2.471e+00, Validation Loss: 2.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 714, Training Loss: 2.471e+00, Validation Loss: 2.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 715, Training Loss: 2.471e+00, Validation Loss: 2.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 716, Training Loss: 2.470e+00, Validation Loss: 2.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 717, Training Loss: 2.470e+00, Validation Loss: 2.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 718, Training Loss: 2.470e+00, Validation Loss: 2.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 719, Training Loss: 2.470e+00, Validation Loss: 2.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 720, Training Loss: 2.470e+00, Validation Loss: 2.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 721, Training Loss: 2.469e+00, Validation Loss: 2.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 722, Training Loss: 2.469e+00, Validation Loss: 2.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 723, Training Loss: 2.469e+00, Validation Loss: 2.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 724, Training Loss: 2.469e+00, Validation Loss: 2.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 725, Training Loss: 2.468e+00, Validation Loss: 2.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 726, Training Loss: 2.468e+00, Validation Loss: 2.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 727, Training Loss: 2.468e+00, Validation Loss: 2.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 728, Training Loss: 2.468e+00, Validation Loss: 2.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 729, Training Loss: 2.468e+00, Validation Loss: 2.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 730, Training Loss: 2.467e+00, Validation Loss: 2.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 731, Training Loss: 2.467e+00, Validation Loss: 2.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 732, Training Loss: 2.467e+00, Validation Loss: 2.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 733, Training Loss: 2.467e+00, Validation Loss: 2.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 734, Training Loss: 2.466e+00, Validation Loss: 2.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 735, Training Loss: 2.466e+00, Validation Loss: 2.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 736, Training Loss: 2.466e+00, Validation Loss: 2.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 737, Training Loss: 2.466e+00, Validation Loss: 2.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 738, Training Loss: 2.466e+00, Validation Loss: 2.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 739, Training Loss: 2.465e+00, Validation Loss: 2.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 740, Training Loss: 2.465e+00, Validation Loss: 2.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 741, Training Loss: 2.465e+00, Validation Loss: 2.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 742, Training Loss: 2.465e+00, Validation Loss: 2.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 743, Training Loss: 2.465e+00, Validation Loss: 2.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 744, Training Loss: 2.464e+00, Validation Loss: 2.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 745, Training Loss: 2.464e+00, Validation Loss: 2.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 746, Training Loss: 2.464e+00, Validation Loss: 2.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 747, Training Loss: 2.464e+00, Validation Loss: 2.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 748, Training Loss: 2.463e+00, Validation Loss: 2.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 749, Training Loss: 2.463e+00, Validation Loss: 2.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 750, Training Loss: 2.463e+00, Validation Loss: 2.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 751, Training Loss: 2.463e+00, Validation Loss: 2.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 752, Training Loss: 2.463e+00, Validation Loss: 2.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 753, Training Loss: 2.462e+00, Validation Loss: 2.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 754, Training Loss: 2.462e+00, Validation Loss: 2.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 755, Training Loss: 2.462e+00, Validation Loss: 2.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 756, Training Loss: 2.462e+00, Validation Loss: 2.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 757, Training Loss: 2.461e+00, Validation Loss: 2.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 758, Training Loss: 2.461e+00, Validation Loss: 2.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 759, Training Loss: 2.461e+00, Validation Loss: 2.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 760, Training Loss: 2.461e+00, Validation Loss: 2.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 761, Training Loss: 2.461e+00, Validation Loss: 2.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 762, Training Loss: 2.460e+00, Validation Loss: 2.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 763, Training Loss: 2.460e+00, Validation Loss: 2.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 764, Training Loss: 2.460e+00, Validation Loss: 2.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 765, Training Loss: 2.460e+00, Validation Loss: 2.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 766, Training Loss: 2.459e+00, Validation Loss: 2.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 767, Training Loss: 2.459e+00, Validation Loss: 2.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 768, Training Loss: 2.459e+00, Validation Loss: 2.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 769, Training Loss: 2.459e+00, Validation Loss: 2.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 770, Training Loss: 2.459e+00, Validation Loss: 2.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 771, Training Loss: 2.458e+00, Validation Loss: 2.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 772, Training Loss: 2.458e+00, Validation Loss: 2.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 773, Training Loss: 2.458e+00, Validation Loss: 2.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 774, Training Loss: 2.458e+00, Validation Loss: 2.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 775, Training Loss: 2.457e+00, Validation Loss: 2.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 776, Training Loss: 2.457e+00, Validation Loss: 2.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 777, Training Loss: 2.457e+00, Validation Loss: 2.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 778, Training Loss: 2.457e+00, Validation Loss: 2.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 779, Training Loss: 2.457e+00, Validation Loss: 2.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 780, Training Loss: 2.456e+00, Validation Loss: 2.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 781, Training Loss: 2.456e+00, Validation Loss: 2.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 782, Training Loss: 2.456e+00, Validation Loss: 2.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 783, Training Loss: 2.456e+00, Validation Loss: 2.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 784, Training Loss: 2.456e+00, Validation Loss: 2.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 785, Training Loss: 2.455e+00, Validation Loss: 2.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 786, Training Loss: 2.455e+00, Validation Loss: 2.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 787, Training Loss: 2.455e+00, Validation Loss: 2.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 788, Training Loss: 2.455e+00, Validation Loss: 2.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 789, Training Loss: 2.454e+00, Validation Loss: 2.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 790, Training Loss: 2.454e+00, Validation Loss: 2.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 791, Training Loss: 2.454e+00, Validation Loss: 2.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 792, Training Loss: 2.454e+00, Validation Loss: 2.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 793, Training Loss: 2.454e+00, Validation Loss: 2.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 794, Training Loss: 2.453e+00, Validation Loss: 2.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 795, Training Loss: 2.453e+00, Validation Loss: 2.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 796, Training Loss: 2.453e+00, Validation Loss: 2.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 797, Training Loss: 2.453e+00, Validation Loss: 2.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 798, Training Loss: 2.452e+00, Validation Loss: 2.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 799, Training Loss: 2.452e+00, Validation Loss: 2.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 800, Training Loss: 2.452e+00, Validation Loss: 2.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 801, Training Loss: 2.452e+00, Validation Loss: 2.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 802, Training Loss: 2.452e+00, Validation Loss: 2.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 803, Training Loss: 2.451e+00, Validation Loss: 2.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 804, Training Loss: 2.451e+00, Validation Loss: 2.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 805, Training Loss: 2.451e+00, Validation Loss: 2.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 806, Training Loss: 2.451e+00, Validation Loss: 2.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 807, Training Loss: 2.450e+00, Validation Loss: 2.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 808, Training Loss: 2.450e+00, Validation Loss: 2.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 809, Training Loss: 2.450e+00, Validation Loss: 2.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 810, Training Loss: 2.450e+00, Validation Loss: 2.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 811, Training Loss: 2.450e+00, Validation Loss: 2.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 812, Training Loss: 2.449e+00, Validation Loss: 2.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 813, Training Loss: 2.449e+00, Validation Loss: 2.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 814, Training Loss: 2.449e+00, Validation Loss: 2.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 815, Training Loss: 2.449e+00, Validation Loss: 2.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 816, Training Loss: 2.448e+00, Validation Loss: 2.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 817, Training Loss: 2.448e+00, Validation Loss: 2.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 818, Training Loss: 2.448e+00, Validation Loss: 2.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 819, Training Loss: 2.448e+00, Validation Loss: 2.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 820, Training Loss: 2.447e+00, Validation Loss: 2.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 821, Training Loss: 2.447e+00, Validation Loss: 2.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 822, Training Loss: 2.447e+00, Validation Loss: 2.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 823, Training Loss: 2.447e+00, Validation Loss: 2.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 824, Training Loss: 2.447e+00, Validation Loss: 2.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 825, Training Loss: 2.446e+00, Validation Loss: 2.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 826, Training Loss: 2.446e+00, Validation Loss: 2.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 827, Training Loss: 2.446e+00, Validation Loss: 2.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 828, Training Loss: 2.446e+00, Validation Loss: 2.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 829, Training Loss: 2.445e+00, Validation Loss: 2.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 830, Training Loss: 2.445e+00, Validation Loss: 2.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 831, Training Loss: 2.445e+00, Validation Loss: 2.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 832, Training Loss: 2.445e+00, Validation Loss: 2.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 833, Training Loss: 2.445e+00, Validation Loss: 2.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 834, Training Loss: 2.444e+00, Validation Loss: 2.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 835, Training Loss: 2.444e+00, Validation Loss: 2.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 836, Training Loss: 2.444e+00, Validation Loss: 2.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 837, Training Loss: 2.444e+00, Validation Loss: 2.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 838, Training Loss: 2.443e+00, Validation Loss: 2.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 839, Training Loss: 2.443e+00, Validation Loss: 2.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 840, Training Loss: 2.443e+00, Validation Loss: 2.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 841, Training Loss: 2.443e+00, Validation Loss: 2.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 842, Training Loss: 2.442e+00, Validation Loss: 2.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 843, Training Loss: 2.442e+00, Validation Loss: 2.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 844, Training Loss: 2.442e+00, Validation Loss: 2.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 845, Training Loss: 2.442e+00, Validation Loss: 2.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 846, Training Loss: 2.442e+00, Validation Loss: 2.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 847, Training Loss: 2.441e+00, Validation Loss: 2.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 848, Training Loss: 2.441e+00, Validation Loss: 2.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 849, Training Loss: 2.441e+00, Validation Loss: 2.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 850, Training Loss: 2.441e+00, Validation Loss: 2.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 851, Training Loss: 2.440e+00, Validation Loss: 2.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 852, Training Loss: 2.440e+00, Validation Loss: 2.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 853, Training Loss: 2.440e+00, Validation Loss: 2.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 854, Training Loss: 2.440e+00, Validation Loss: 2.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 855, Training Loss: 2.439e+00, Validation Loss: 2.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 856, Training Loss: 2.439e+00, Validation Loss: 2.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 857, Training Loss: 2.439e+00, Validation Loss: 2.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 858, Training Loss: 2.439e+00, Validation Loss: 2.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 859, Training Loss: 2.439e+00, Validation Loss: 2.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 860, Training Loss: 2.438e+00, Validation Loss: 2.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 861, Training Loss: 2.438e+00, Validation Loss: 2.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 862, Training Loss: 2.438e+00, Validation Loss: 2.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 863, Training Loss: 2.438e+00, Validation Loss: 2.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 864, Training Loss: 2.437e+00, Validation Loss: 2.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 865, Training Loss: 2.437e+00, Validation Loss: 2.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 866, Training Loss: 2.437e+00, Validation Loss: 2.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 867, Training Loss: 2.437e+00, Validation Loss: 2.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 868, Training Loss: 2.436e+00, Validation Loss: 2.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 869, Training Loss: 2.436e+00, Validation Loss: 2.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 870, Training Loss: 2.436e+00, Validation Loss: 2.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 871, Training Loss: 2.436e+00, Validation Loss: 2.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 872, Training Loss: 2.435e+00, Validation Loss: 2.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 873, Training Loss: 2.435e+00, Validation Loss: 2.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 874, Training Loss: 2.435e+00, Validation Loss: 2.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 875, Training Loss: 2.435e+00, Validation Loss: 2.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 876, Training Loss: 2.435e+00, Validation Loss: 2.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 877, Training Loss: 2.434e+00, Validation Loss: 2.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 878, Training Loss: 2.434e+00, Validation Loss: 2.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 879, Training Loss: 2.434e+00, Validation Loss: 2.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 880, Training Loss: 2.434e+00, Validation Loss: 2.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 881, Training Loss: 2.433e+00, Validation Loss: 2.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 882, Training Loss: 2.433e+00, Validation Loss: 2.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 883, Training Loss: 2.433e+00, Validation Loss: 2.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 884, Training Loss: 2.433e+00, Validation Loss: 2.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 885, Training Loss: 2.432e+00, Validation Loss: 2.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 886, Training Loss: 2.432e+00, Validation Loss: 2.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 887, Training Loss: 2.432e+00, Validation Loss: 2.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 888, Training Loss: 2.432e+00, Validation Loss: 2.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 889, Training Loss: 2.431e+00, Validation Loss: 2.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 890, Training Loss: 2.431e+00, Validation Loss: 2.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 891, Training Loss: 2.431e+00, Validation Loss: 2.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 892, Training Loss: 2.431e+00, Validation Loss: 2.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 893, Training Loss: 2.430e+00, Validation Loss: 2.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 894, Training Loss: 2.430e+00, Validation Loss: 2.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 895, Training Loss: 2.430e+00, Validation Loss: 2.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 896, Training Loss: 2.430e+00, Validation Loss: 2.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 897, Training Loss: 2.429e+00, Validation Loss: 2.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 898, Training Loss: 2.429e+00, Validation Loss: 2.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 899, Training Loss: 2.429e+00, Validation Loss: 2.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 900, Training Loss: 2.429e+00, Validation Loss: 2.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 901, Training Loss: 2.429e+00, Validation Loss: 2.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 902, Training Loss: 2.428e+00, Validation Loss: 2.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 903, Training Loss: 2.428e+00, Validation Loss: 2.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 904, Training Loss: 2.428e+00, Validation Loss: 2.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 905, Training Loss: 2.428e+00, Validation Loss: 2.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 906, Training Loss: 2.427e+00, Validation Loss: 2.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 907, Training Loss: 2.427e+00, Validation Loss: 2.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 908, Training Loss: 2.427e+00, Validation Loss: 2.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 909, Training Loss: 2.427e+00, Validation Loss: 2.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 910, Training Loss: 2.426e+00, Validation Loss: 2.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 911, Training Loss: 2.426e+00, Validation Loss: 2.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 912, Training Loss: 2.426e+00, Validation Loss: 2.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 913, Training Loss: 2.426e+00, Validation Loss: 2.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 914, Training Loss: 2.425e+00, Validation Loss: 2.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 915, Training Loss: 2.425e+00, Validation Loss: 2.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 916, Training Loss: 2.425e+00, Validation Loss: 2.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 917, Training Loss: 2.425e+00, Validation Loss: 2.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 918, Training Loss: 2.424e+00, Validation Loss: 2.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 919, Training Loss: 2.424e+00, Validation Loss: 2.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 920, Training Loss: 2.424e+00, Validation Loss: 2.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 921, Training Loss: 2.424e+00, Validation Loss: 2.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 922, Training Loss: 2.423e+00, Validation Loss: 2.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 923, Training Loss: 2.423e+00, Validation Loss: 2.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 924, Training Loss: 2.423e+00, Validation Loss: 2.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 925, Training Loss: 2.423e+00, Validation Loss: 2.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 926, Training Loss: 2.422e+00, Validation Loss: 2.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 927, Training Loss: 2.422e+00, Validation Loss: 2.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 928, Training Loss: 2.422e+00, Validation Loss: 2.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 929, Training Loss: 2.422e+00, Validation Loss: 2.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 930, Training Loss: 2.422e+00, Validation Loss: 2.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 931, Training Loss: 2.421e+00, Validation Loss: 2.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 932, Training Loss: 2.421e+00, Validation Loss: 2.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 933, Training Loss: 2.421e+00, Validation Loss: 2.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 934, Training Loss: 2.421e+00, Validation Loss: 2.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 935, Training Loss: 2.420e+00, Validation Loss: 2.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 936, Training Loss: 2.420e+00, Validation Loss: 2.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 937, Training Loss: 2.420e+00, Validation Loss: 2.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 938, Training Loss: 2.420e+00, Validation Loss: 2.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 939, Training Loss: 2.420e+00, Validation Loss: 2.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 940, Training Loss: 2.419e+00, Validation Loss: 2.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 941, Training Loss: 2.419e+00, Validation Loss: 2.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 942, Training Loss: 2.419e+00, Validation Loss: 2.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 943, Training Loss: 2.419e+00, Validation Loss: 2.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 944, Training Loss: 2.418e+00, Validation Loss: 2.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 945, Training Loss: 2.418e+00, Validation Loss: 2.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 946, Training Loss: 2.418e+00, Validation Loss: 2.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 947, Training Loss: 2.418e+00, Validation Loss: 2.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 948, Training Loss: 2.417e+00, Validation Loss: 2.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 949, Training Loss: 2.417e+00, Validation Loss: 2.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 950, Training Loss: 2.417e+00, Validation Loss: 2.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 951, Training Loss: 2.417e+00, Validation Loss: 2.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 952, Training Loss: 2.417e+00, Validation Loss: 2.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 953, Training Loss: 2.416e+00, Validation Loss: 2.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 954, Training Loss: 2.416e+00, Validation Loss: 2.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 955, Training Loss: 2.416e+00, Validation Loss: 2.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 956, Training Loss: 2.416e+00, Validation Loss: 2.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 957, Training Loss: 2.415e+00, Validation Loss: 2.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 958, Training Loss: 2.415e+00, Validation Loss: 2.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 959, Training Loss: 2.415e+00, Validation Loss: 2.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 960, Training Loss: 2.415e+00, Validation Loss: 2.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 961, Training Loss: 2.415e+00, Validation Loss: 2.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 962, Training Loss: 2.414e+00, Validation Loss: 2.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 963, Training Loss: 2.414e+00, Validation Loss: 2.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 964, Training Loss: 2.414e+00, Validation Loss: 2.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 965, Training Loss: 2.414e+00, Validation Loss: 2.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 966, Training Loss: 2.413e+00, Validation Loss: 2.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 967, Training Loss: 2.413e+00, Validation Loss: 2.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 968, Training Loss: 2.413e+00, Validation Loss: 2.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 969, Training Loss: 2.413e+00, Validation Loss: 2.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 970, Training Loss: 2.413e+00, Validation Loss: 2.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 971, Training Loss: 2.412e+00, Validation Loss: 2.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 972, Training Loss: 2.412e+00, Validation Loss: 2.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 973, Training Loss: 2.412e+00, Validation Loss: 2.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 974, Training Loss: 2.412e+00, Validation Loss: 2.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 975, Training Loss: 2.411e+00, Validation Loss: 2.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 976, Training Loss: 2.411e+00, Validation Loss: 2.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 977, Training Loss: 2.411e+00, Validation Loss: 2.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 978, Training Loss: 2.411e+00, Validation Loss: 2.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 979, Training Loss: 2.411e+00, Validation Loss: 2.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 980, Training Loss: 2.410e+00, Validation Loss: 2.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 981, Training Loss: 2.410e+00, Validation Loss: 2.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 982, Training Loss: 2.410e+00, Validation Loss: 2.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 983, Training Loss: 2.410e+00, Validation Loss: 2.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 984, Training Loss: 2.410e+00, Validation Loss: 2.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 985, Training Loss: 2.409e+00, Validation Loss: 2.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 986, Training Loss: 2.409e+00, Validation Loss: 2.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 987, Training Loss: 2.409e+00, Validation Loss: 2.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 988, Training Loss: 2.409e+00, Validation Loss: 2.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 989, Training Loss: 2.408e+00, Validation Loss: 2.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 990, Training Loss: 2.408e+00, Validation Loss: 2.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 991, Training Loss: 2.408e+00, Validation Loss: 2.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 992, Training Loss: 2.408e+00, Validation Loss: 2.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 993, Training Loss: 2.408e+00, Validation Loss: 2.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 994, Training Loss: 2.407e+00, Validation Loss: 2.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 995, Training Loss: 2.407e+00, Validation Loss: 2.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 996, Training Loss: 2.407e+00, Validation Loss: 2.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 997, Training Loss: 2.407e+00, Validation Loss: 2.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 998, Training Loss: 2.406e+00, Validation Loss: 2.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 999, Training Loss: 2.406e+00, Validation Loss: 2.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1000, Training Loss: 2.406e+00, Validation Loss: 2.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1001, Training Loss: 2.406e+00, Validation Loss: 2.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1002, Training Loss: 2.406e+00, Validation Loss: 2.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1003, Training Loss: 2.405e+00, Validation Loss: 2.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1004, Training Loss: 2.405e+00, Validation Loss: 2.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1005, Training Loss: 2.405e+00, Validation Loss: 2.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1006, Training Loss: 2.405e+00, Validation Loss: 2.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1007, Training Loss: 2.405e+00, Validation Loss: 2.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1008, Training Loss: 2.404e+00, Validation Loss: 2.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1009, Training Loss: 2.404e+00, Validation Loss: 2.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1010, Training Loss: 2.404e+00, Validation Loss: 2.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1011, Training Loss: 2.404e+00, Validation Loss: 2.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1012, Training Loss: 2.403e+00, Validation Loss: 2.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1013, Training Loss: 2.403e+00, Validation Loss: 2.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1014, Training Loss: 2.403e+00, Validation Loss: 2.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1015, Training Loss: 2.403e+00, Validation Loss: 2.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1016, Training Loss: 2.403e+00, Validation Loss: 2.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1017, Training Loss: 2.402e+00, Validation Loss: 2.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1018, Training Loss: 2.402e+00, Validation Loss: 2.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1019, Training Loss: 2.402e+00, Validation Loss: 2.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1020, Training Loss: 2.402e+00, Validation Loss: 2.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1021, Training Loss: 2.402e+00, Validation Loss: 2.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1022, Training Loss: 2.401e+00, Validation Loss: 2.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1023, Training Loss: 2.401e+00, Validation Loss: 2.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1024, Training Loss: 2.401e+00, Validation Loss: 2.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1025, Training Loss: 2.401e+00, Validation Loss: 2.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1026, Training Loss: 2.401e+00, Validation Loss: 2.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1027, Training Loss: 2.400e+00, Validation Loss: 2.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1028, Training Loss: 2.400e+00, Validation Loss: 2.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1029, Training Loss: 2.400e+00, Validation Loss: 2.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1030, Training Loss: 2.400e+00, Validation Loss: 2.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1031, Training Loss: 2.399e+00, Validation Loss: 2.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1032, Training Loss: 2.399e+00, Validation Loss: 2.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1033, Training Loss: 2.399e+00, Validation Loss: 2.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1034, Training Loss: 2.399e+00, Validation Loss: 2.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1035, Training Loss: 2.399e+00, Validation Loss: 2.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1036, Training Loss: 2.398e+00, Validation Loss: 2.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1037, Training Loss: 2.398e+00, Validation Loss: 2.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1038, Training Loss: 2.398e+00, Validation Loss: 2.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1039, Training Loss: 2.398e+00, Validation Loss: 2.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1040, Training Loss: 2.398e+00, Validation Loss: 2.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1041, Training Loss: 2.397e+00, Validation Loss: 2.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1042, Training Loss: 2.397e+00, Validation Loss: 2.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1043, Training Loss: 2.397e+00, Validation Loss: 2.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1044, Training Loss: 2.397e+00, Validation Loss: 2.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1045, Training Loss: 2.397e+00, Validation Loss: 2.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1046, Training Loss: 2.396e+00, Validation Loss: 2.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1047, Training Loss: 2.396e+00, Validation Loss: 2.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1048, Training Loss: 2.396e+00, Validation Loss: 2.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1049, Training Loss: 2.396e+00, Validation Loss: 2.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1050, Training Loss: 2.396e+00, Validation Loss: 2.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1051, Training Loss: 2.395e+00, Validation Loss: 2.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1052, Training Loss: 2.395e+00, Validation Loss: 2.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1053, Training Loss: 2.395e+00, Validation Loss: 2.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1054, Training Loss: 2.395e+00, Validation Loss: 2.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1055, Training Loss: 2.394e+00, Validation Loss: 2.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1056, Training Loss: 2.394e+00, Validation Loss: 2.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1057, Training Loss: 2.394e+00, Validation Loss: 2.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1058, Training Loss: 2.394e+00, Validation Loss: 2.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1059, Training Loss: 2.394e+00, Validation Loss: 2.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1060, Training Loss: 2.393e+00, Validation Loss: 2.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1061, Training Loss: 2.393e+00, Validation Loss: 2.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1062, Training Loss: 2.393e+00, Validation Loss: 2.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1063, Training Loss: 2.393e+00, Validation Loss: 2.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1064, Training Loss: 2.393e+00, Validation Loss: 2.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1065, Training Loss: 2.392e+00, Validation Loss: 2.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1066, Training Loss: 2.392e+00, Validation Loss: 2.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1067, Training Loss: 2.392e+00, Validation Loss: 2.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1068, Training Loss: 2.392e+00, Validation Loss: 2.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1069, Training Loss: 2.392e+00, Validation Loss: 2.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1070, Training Loss: 2.391e+00, Validation Loss: 2.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1071, Training Loss: 2.391e+00, Validation Loss: 2.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1072, Training Loss: 2.391e+00, Validation Loss: 2.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1073, Training Loss: 2.391e+00, Validation Loss: 2.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1074, Training Loss: 2.391e+00, Validation Loss: 2.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1075, Training Loss: 2.390e+00, Validation Loss: 2.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1076, Training Loss: 2.390e+00, Validation Loss: 2.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1077, Training Loss: 2.390e+00, Validation Loss: 2.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1078, Training Loss: 2.390e+00, Validation Loss: 2.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1079, Training Loss: 2.390e+00, Validation Loss: 2.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1080, Training Loss: 2.389e+00, Validation Loss: 2.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1081, Training Loss: 2.389e+00, Validation Loss: 2.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1082, Training Loss: 2.389e+00, Validation Loss: 2.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1083, Training Loss: 2.389e+00, Validation Loss: 2.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1084, Training Loss: 2.388e+00, Validation Loss: 2.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1085, Training Loss: 2.388e+00, Validation Loss: 2.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1086, Training Loss: 2.388e+00, Validation Loss: 2.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1087, Training Loss: 2.388e+00, Validation Loss: 2.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1088, Training Loss: 2.388e+00, Validation Loss: 2.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1089, Training Loss: 2.387e+00, Validation Loss: 2.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1090, Training Loss: 2.387e+00, Validation Loss: 2.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1091, Training Loss: 2.387e+00, Validation Loss: 2.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1092, Training Loss: 2.387e+00, Validation Loss: 2.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1093, Training Loss: 2.387e+00, Validation Loss: 2.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1094, Training Loss: 2.386e+00, Validation Loss: 2.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1095, Training Loss: 2.386e+00, Validation Loss: 2.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1096, Training Loss: 2.386e+00, Validation Loss: 2.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1097, Training Loss: 2.386e+00, Validation Loss: 2.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1098, Training Loss: 2.386e+00, Validation Loss: 2.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1099, Training Loss: 2.385e+00, Validation Loss: 2.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1100, Training Loss: 2.385e+00, Validation Loss: 2.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1101, Training Loss: 2.385e+00, Validation Loss: 2.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1102, Training Loss: 2.385e+00, Validation Loss: 2.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1103, Training Loss: 2.385e+00, Validation Loss: 2.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1104, Training Loss: 2.384e+00, Validation Loss: 2.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1105, Training Loss: 2.384e+00, Validation Loss: 2.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1106, Training Loss: 2.384e+00, Validation Loss: 2.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1107, Training Loss: 2.384e+00, Validation Loss: 2.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1108, Training Loss: 2.383e+00, Validation Loss: 2.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1109, Training Loss: 2.383e+00, Validation Loss: 2.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1110, Training Loss: 2.383e+00, Validation Loss: 2.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1111, Training Loss: 2.383e+00, Validation Loss: 2.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1112, Training Loss: 2.383e+00, Validation Loss: 2.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1113, Training Loss: 2.382e+00, Validation Loss: 2.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1114, Training Loss: 2.382e+00, Validation Loss: 2.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1115, Training Loss: 2.382e+00, Validation Loss: 2.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1116, Training Loss: 2.382e+00, Validation Loss: 2.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1117, Training Loss: 2.382e+00, Validation Loss: 2.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1118, Training Loss: 2.381e+00, Validation Loss: 2.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1119, Training Loss: 2.381e+00, Validation Loss: 2.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1120, Training Loss: 2.381e+00, Validation Loss: 2.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1121, Training Loss: 2.381e+00, Validation Loss: 2.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1122, Training Loss: 2.381e+00, Validation Loss: 2.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1123, Training Loss: 2.380e+00, Validation Loss: 2.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1124, Training Loss: 2.380e+00, Validation Loss: 2.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1125, Training Loss: 2.380e+00, Validation Loss: 2.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1126, Training Loss: 2.380e+00, Validation Loss: 2.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1127, Training Loss: 2.379e+00, Validation Loss: 2.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1128, Training Loss: 2.379e+00, Validation Loss: 2.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1129, Training Loss: 2.379e+00, Validation Loss: 2.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1130, Training Loss: 2.379e+00, Validation Loss: 2.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1131, Training Loss: 2.379e+00, Validation Loss: 2.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1132, Training Loss: 2.378e+00, Validation Loss: 2.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1133, Training Loss: 2.378e+00, Validation Loss: 2.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1134, Training Loss: 2.378e+00, Validation Loss: 2.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1135, Training Loss: 2.378e+00, Validation Loss: 2.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1136, Training Loss: 2.378e+00, Validation Loss: 2.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1137, Training Loss: 2.377e+00, Validation Loss: 2.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1138, Training Loss: 2.377e+00, Validation Loss: 2.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1139, Training Loss: 2.377e+00, Validation Loss: 2.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1140, Training Loss: 2.377e+00, Validation Loss: 2.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1141, Training Loss: 2.377e+00, Validation Loss: 2.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1142, Training Loss: 2.376e+00, Validation Loss: 2.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1143, Training Loss: 2.376e+00, Validation Loss: 2.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1144, Training Loss: 2.376e+00, Validation Loss: 2.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1145, Training Loss: 2.376e+00, Validation Loss: 2.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1146, Training Loss: 2.376e+00, Validation Loss: 2.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1147, Training Loss: 2.375e+00, Validation Loss: 2.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1148, Training Loss: 2.375e+00, Validation Loss: 2.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1149, Training Loss: 2.375e+00, Validation Loss: 2.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1150, Training Loss: 2.375e+00, Validation Loss: 2.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1151, Training Loss: 2.375e+00, Validation Loss: 2.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1152, Training Loss: 2.374e+00, Validation Loss: 2.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1153, Training Loss: 2.374e+00, Validation Loss: 2.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1154, Training Loss: 2.374e+00, Validation Loss: 2.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1155, Training Loss: 2.374e+00, Validation Loss: 2.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1156, Training Loss: 2.373e+00, Validation Loss: 2.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1157, Training Loss: 2.373e+00, Validation Loss: 2.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1158, Training Loss: 2.373e+00, Validation Loss: 2.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1159, Training Loss: 2.373e+00, Validation Loss: 2.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1160, Training Loss: 2.373e+00, Validation Loss: 2.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1161, Training Loss: 2.372e+00, Validation Loss: 2.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1162, Training Loss: 2.372e+00, Validation Loss: 2.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1163, Training Loss: 2.372e+00, Validation Loss: 2.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1164, Training Loss: 2.372e+00, Validation Loss: 2.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1165, Training Loss: 2.372e+00, Validation Loss: 2.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1166, Training Loss: 2.371e+00, Validation Loss: 2.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1167, Training Loss: 2.371e+00, Validation Loss: 2.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1168, Training Loss: 2.371e+00, Validation Loss: 2.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1169, Training Loss: 2.371e+00, Validation Loss: 2.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1170, Training Loss: 2.371e+00, Validation Loss: 2.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1171, Training Loss: 2.370e+00, Validation Loss: 2.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1172, Training Loss: 2.370e+00, Validation Loss: 2.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1173, Training Loss: 2.370e+00, Validation Loss: 2.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1174, Training Loss: 2.370e+00, Validation Loss: 2.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1175, Training Loss: 2.370e+00, Validation Loss: 2.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1176, Training Loss: 2.369e+00, Validation Loss: 2.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1177, Training Loss: 2.369e+00, Validation Loss: 2.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1178, Training Loss: 2.369e+00, Validation Loss: 2.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1179, Training Loss: 2.369e+00, Validation Loss: 2.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1180, Training Loss: 2.369e+00, Validation Loss: 2.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1181, Training Loss: 2.368e+00, Validation Loss: 2.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1182, Training Loss: 2.368e+00, Validation Loss: 2.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1183, Training Loss: 2.368e+00, Validation Loss: 2.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1184, Training Loss: 2.368e+00, Validation Loss: 2.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1185, Training Loss: 2.368e+00, Validation Loss: 2.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1186, Training Loss: 2.367e+00, Validation Loss: 2.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1187, Training Loss: 2.367e+00, Validation Loss: 2.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1188, Training Loss: 2.367e+00, Validation Loss: 2.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1189, Training Loss: 2.367e+00, Validation Loss: 2.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1190, Training Loss: 2.366e+00, Validation Loss: 2.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1191, Training Loss: 2.366e+00, Validation Loss: 2.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1192, Training Loss: 2.366e+00, Validation Loss: 2.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1193, Training Loss: 2.366e+00, Validation Loss: 2.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1194, Training Loss: 2.366e+00, Validation Loss: 2.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1195, Training Loss: 2.365e+00, Validation Loss: 2.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1196, Training Loss: 2.365e+00, Validation Loss: 2.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1197, Training Loss: 2.365e+00, Validation Loss: 2.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1198, Training Loss: 2.365e+00, Validation Loss: 2.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1199, Training Loss: 2.365e+00, Validation Loss: 2.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1200, Training Loss: 2.364e+00, Validation Loss: 2.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1201, Training Loss: 2.364e+00, Validation Loss: 2.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1202, Training Loss: 2.364e+00, Validation Loss: 2.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1203, Training Loss: 2.364e+00, Validation Loss: 2.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1204, Training Loss: 2.364e+00, Validation Loss: 2.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1205, Training Loss: 2.363e+00, Validation Loss: 2.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1206, Training Loss: 2.363e+00, Validation Loss: 2.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1207, Training Loss: 2.363e+00, Validation Loss: 2.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1208, Training Loss: 2.363e+00, Validation Loss: 2.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1209, Training Loss: 2.363e+00, Validation Loss: 2.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1210, Training Loss: 2.362e+00, Validation Loss: 2.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1211, Training Loss: 2.362e+00, Validation Loss: 2.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1212, Training Loss: 2.362e+00, Validation Loss: 2.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1213, Training Loss: 2.362e+00, Validation Loss: 2.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1214, Training Loss: 2.362e+00, Validation Loss: 2.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1215, Training Loss: 2.361e+00, Validation Loss: 2.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1216, Training Loss: 2.361e+00, Validation Loss: 2.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1217, Training Loss: 2.361e+00, Validation Loss: 2.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1218, Training Loss: 2.361e+00, Validation Loss: 2.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1219, Training Loss: 2.361e+00, Validation Loss: 2.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1220, Training Loss: 2.360e+00, Validation Loss: 2.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1221, Training Loss: 2.360e+00, Validation Loss: 2.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1222, Training Loss: 2.360e+00, Validation Loss: 2.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1223, Training Loss: 2.360e+00, Validation Loss: 2.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1224, Training Loss: 2.360e+00, Validation Loss: 2.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1225, Training Loss: 2.359e+00, Validation Loss: 2.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1226, Training Loss: 2.359e+00, Validation Loss: 2.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1227, Training Loss: 2.359e+00, Validation Loss: 2.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1228, Training Loss: 2.359e+00, Validation Loss: 2.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1229, Training Loss: 2.359e+00, Validation Loss: 2.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1230, Training Loss: 2.358e+00, Validation Loss: 2.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1231, Training Loss: 2.358e+00, Validation Loss: 2.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1232, Training Loss: 2.358e+00, Validation Loss: 2.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1233, Training Loss: 2.358e+00, Validation Loss: 2.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1234, Training Loss: 2.358e+00, Validation Loss: 2.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1235, Training Loss: 2.357e+00, Validation Loss: 2.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1236, Training Loss: 2.357e+00, Validation Loss: 2.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1237, Training Loss: 2.357e+00, Validation Loss: 2.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1238, Training Loss: 2.357e+00, Validation Loss: 2.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1239, Training Loss: 2.356e+00, Validation Loss: 2.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1240, Training Loss: 2.356e+00, Validation Loss: 2.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1241, Training Loss: 2.356e+00, Validation Loss: 2.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1242, Training Loss: 2.356e+00, Validation Loss: 2.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1243, Training Loss: 2.356e+00, Validation Loss: 2.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1244, Training Loss: 2.355e+00, Validation Loss: 2.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1245, Training Loss: 2.355e+00, Validation Loss: 2.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1246, Training Loss: 2.355e+00, Validation Loss: 2.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1247, Training Loss: 2.355e+00, Validation Loss: 2.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1248, Training Loss: 2.355e+00, Validation Loss: 2.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1249, Training Loss: 2.354e+00, Validation Loss: 2.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1250, Training Loss: 2.354e+00, Validation Loss: 2.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1251, Training Loss: 2.354e+00, Validation Loss: 2.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1252, Training Loss: 2.354e+00, Validation Loss: 2.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1253, Training Loss: 2.354e+00, Validation Loss: 2.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1254, Training Loss: 2.353e+00, Validation Loss: 2.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1255, Training Loss: 2.353e+00, Validation Loss: 2.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1256, Training Loss: 2.353e+00, Validation Loss: 2.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1257, Training Loss: 2.353e+00, Validation Loss: 2.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1258, Training Loss: 2.353e+00, Validation Loss: 2.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1259, Training Loss: 2.352e+00, Validation Loss: 2.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1260, Training Loss: 2.352e+00, Validation Loss: 2.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1261, Training Loss: 2.352e+00, Validation Loss: 2.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1262, Training Loss: 2.352e+00, Validation Loss: 2.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1263, Training Loss: 2.352e+00, Validation Loss: 2.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1264, Training Loss: 2.351e+00, Validation Loss: 2.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1265, Training Loss: 2.351e+00, Validation Loss: 2.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1266, Training Loss: 2.351e+00, Validation Loss: 2.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1267, Training Loss: 2.351e+00, Validation Loss: 2.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1268, Training Loss: 2.351e+00, Validation Loss: 2.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1269, Training Loss: 2.350e+00, Validation Loss: 2.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1270, Training Loss: 2.350e+00, Validation Loss: 2.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1271, Training Loss: 2.350e+00, Validation Loss: 2.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1272, Training Loss: 2.350e+00, Validation Loss: 2.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1273, Training Loss: 2.350e+00, Validation Loss: 2.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1274, Training Loss: 2.349e+00, Validation Loss: 2.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1275, Training Loss: 2.349e+00, Validation Loss: 2.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1276, Training Loss: 2.349e+00, Validation Loss: 2.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1277, Training Loss: 2.349e+00, Validation Loss: 2.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1278, Training Loss: 2.349e+00, Validation Loss: 2.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1279, Training Loss: 2.348e+00, Validation Loss: 2.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1280, Training Loss: 2.348e+00, Validation Loss: 2.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1281, Training Loss: 2.348e+00, Validation Loss: 2.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1282, Training Loss: 2.348e+00, Validation Loss: 2.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1283, Training Loss: 2.348e+00, Validation Loss: 2.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1284, Training Loss: 2.347e+00, Validation Loss: 2.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1285, Training Loss: 2.347e+00, Validation Loss: 2.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1286, Training Loss: 2.347e+00, Validation Loss: 2.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1287, Training Loss: 2.347e+00, Validation Loss: 2.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1288, Training Loss: 2.347e+00, Validation Loss: 2.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1289, Training Loss: 2.346e+00, Validation Loss: 2.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1290, Training Loss: 2.346e+00, Validation Loss: 2.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1291, Training Loss: 2.346e+00, Validation Loss: 2.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1292, Training Loss: 2.346e+00, Validation Loss: 2.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1293, Training Loss: 2.346e+00, Validation Loss: 2.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1294, Training Loss: 2.345e+00, Validation Loss: 2.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1295, Training Loss: 2.345e+00, Validation Loss: 2.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1296, Training Loss: 2.345e+00, Validation Loss: 2.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1297, Training Loss: 2.345e+00, Validation Loss: 2.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1298, Training Loss: 2.345e+00, Validation Loss: 2.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1299, Training Loss: 2.344e+00, Validation Loss: 2.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1300, Training Loss: 2.344e+00, Validation Loss: 2.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1301, Training Loss: 2.344e+00, Validation Loss: 2.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1302, Training Loss: 2.344e+00, Validation Loss: 2.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1303, Training Loss: 2.343e+00, Validation Loss: 2.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1304, Training Loss: 2.343e+00, Validation Loss: 2.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1305, Training Loss: 2.343e+00, Validation Loss: 2.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1306, Training Loss: 2.343e+00, Validation Loss: 2.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1307, Training Loss: 2.343e+00, Validation Loss: 2.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1308, Training Loss: 2.342e+00, Validation Loss: 2.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1309, Training Loss: 2.342e+00, Validation Loss: 2.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1310, Training Loss: 2.342e+00, Validation Loss: 2.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1311, Training Loss: 2.342e+00, Validation Loss: 2.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1312, Training Loss: 2.342e+00, Validation Loss: 2.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1313, Training Loss: 2.341e+00, Validation Loss: 2.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1314, Training Loss: 2.341e+00, Validation Loss: 2.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1315, Training Loss: 2.341e+00, Validation Loss: 2.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1316, Training Loss: 2.341e+00, Validation Loss: 2.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1317, Training Loss: 2.341e+00, Validation Loss: 2.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1318, Training Loss: 2.340e+00, Validation Loss: 2.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1319, Training Loss: 2.340e+00, Validation Loss: 2.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1320, Training Loss: 2.340e+00, Validation Loss: 2.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1321, Training Loss: 2.340e+00, Validation Loss: 2.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1322, Training Loss: 2.340e+00, Validation Loss: 2.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1323, Training Loss: 2.339e+00, Validation Loss: 2.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1324, Training Loss: 2.339e+00, Validation Loss: 2.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1325, Training Loss: 2.339e+00, Validation Loss: 2.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1326, Training Loss: 2.339e+00, Validation Loss: 2.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1327, Training Loss: 2.339e+00, Validation Loss: 2.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1328, Training Loss: 2.338e+00, Validation Loss: 2.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1329, Training Loss: 2.338e+00, Validation Loss: 2.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1330, Training Loss: 2.338e+00, Validation Loss: 2.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1331, Training Loss: 2.338e+00, Validation Loss: 2.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1332, Training Loss: 2.338e+00, Validation Loss: 2.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1333, Training Loss: 2.337e+00, Validation Loss: 2.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1334, Training Loss: 2.337e+00, Validation Loss: 2.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1335, Training Loss: 2.337e+00, Validation Loss: 2.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1336, Training Loss: 2.337e+00, Validation Loss: 2.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1337, Training Loss: 2.337e+00, Validation Loss: 2.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1338, Training Loss: 2.336e+00, Validation Loss: 2.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1339, Training Loss: 2.336e+00, Validation Loss: 2.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1340, Training Loss: 2.336e+00, Validation Loss: 2.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1341, Training Loss: 2.336e+00, Validation Loss: 2.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1342, Training Loss: 2.336e+00, Validation Loss: 2.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1343, Training Loss: 2.335e+00, Validation Loss: 2.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1344, Training Loss: 2.335e+00, Validation Loss: 2.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1345, Training Loss: 2.335e+00, Validation Loss: 2.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1346, Training Loss: 2.335e+00, Validation Loss: 2.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1347, Training Loss: 2.335e+00, Validation Loss: 2.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1348, Training Loss: 2.334e+00, Validation Loss: 2.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1349, Training Loss: 2.334e+00, Validation Loss: 2.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1350, Training Loss: 2.334e+00, Validation Loss: 2.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1351, Training Loss: 2.334e+00, Validation Loss: 2.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1352, Training Loss: 2.334e+00, Validation Loss: 2.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1353, Training Loss: 2.333e+00, Validation Loss: 2.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1354, Training Loss: 2.333e+00, Validation Loss: 2.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1355, Training Loss: 2.333e+00, Validation Loss: 2.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1356, Training Loss: 2.333e+00, Validation Loss: 2.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1357, Training Loss: 2.333e+00, Validation Loss: 2.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1358, Training Loss: 2.332e+00, Validation Loss: 2.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1359, Training Loss: 2.332e+00, Validation Loss: 2.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1360, Training Loss: 2.332e+00, Validation Loss: 2.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1361, Training Loss: 2.332e+00, Validation Loss: 2.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1362, Training Loss: 2.332e+00, Validation Loss: 2.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1363, Training Loss: 2.331e+00, Validation Loss: 2.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1364, Training Loss: 2.331e+00, Validation Loss: 2.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1365, Training Loss: 2.331e+00, Validation Loss: 2.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1366, Training Loss: 2.331e+00, Validation Loss: 2.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1367, Training Loss: 2.331e+00, Validation Loss: 2.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1368, Training Loss: 2.330e+00, Validation Loss: 2.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1369, Training Loss: 2.330e+00, Validation Loss: 2.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1370, Training Loss: 2.330e+00, Validation Loss: 2.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1371, Training Loss: 2.330e+00, Validation Loss: 2.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1372, Training Loss: 2.329e+00, Validation Loss: 2.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1373, Training Loss: 2.329e+00, Validation Loss: 2.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1374, Training Loss: 2.329e+00, Validation Loss: 2.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1375, Training Loss: 2.329e+00, Validation Loss: 2.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1376, Training Loss: 2.329e+00, Validation Loss: 2.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1377, Training Loss: 2.328e+00, Validation Loss: 2.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1378, Training Loss: 2.328e+00, Validation Loss: 2.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1379, Training Loss: 2.328e+00, Validation Loss: 2.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1380, Training Loss: 2.328e+00, Validation Loss: 2.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1381, Training Loss: 2.328e+00, Validation Loss: 2.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1382, Training Loss: 2.327e+00, Validation Loss: 2.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1383, Training Loss: 2.327e+00, Validation Loss: 2.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1384, Training Loss: 2.327e+00, Validation Loss: 2.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1385, Training Loss: 2.327e+00, Validation Loss: 2.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1386, Training Loss: 2.327e+00, Validation Loss: 2.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1387, Training Loss: 2.326e+00, Validation Loss: 2.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1388, Training Loss: 2.326e+00, Validation Loss: 2.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1389, Training Loss: 2.326e+00, Validation Loss: 2.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1390, Training Loss: 2.326e+00, Validation Loss: 2.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1391, Training Loss: 2.326e+00, Validation Loss: 2.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1392, Training Loss: 2.325e+00, Validation Loss: 2.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1393, Training Loss: 2.325e+00, Validation Loss: 2.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1394, Training Loss: 2.325e+00, Validation Loss: 2.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1395, Training Loss: 2.325e+00, Validation Loss: 2.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1396, Training Loss: 2.325e+00, Validation Loss: 2.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1397, Training Loss: 2.324e+00, Validation Loss: 2.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1398, Training Loss: 2.324e+00, Validation Loss: 2.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1399, Training Loss: 2.324e+00, Validation Loss: 2.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1400, Training Loss: 2.324e+00, Validation Loss: 2.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1401, Training Loss: 2.324e+00, Validation Loss: 2.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1402, Training Loss: 2.323e+00, Validation Loss: 2.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1403, Training Loss: 2.323e+00, Validation Loss: 2.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1404, Training Loss: 2.323e+00, Validation Loss: 2.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1405, Training Loss: 2.323e+00, Validation Loss: 2.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1406, Training Loss: 2.323e+00, Validation Loss: 2.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1407, Training Loss: 2.322e+00, Validation Loss: 2.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1408, Training Loss: 2.322e+00, Validation Loss: 2.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1409, Training Loss: 2.322e+00, Validation Loss: 2.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1410, Training Loss: 2.322e+00, Validation Loss: 2.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1411, Training Loss: 2.322e+00, Validation Loss: 2.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1412, Training Loss: 2.321e+00, Validation Loss: 2.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1413, Training Loss: 2.321e+00, Validation Loss: 2.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1414, Training Loss: 2.321e+00, Validation Loss: 2.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1415, Training Loss: 2.321e+00, Validation Loss: 2.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1416, Training Loss: 2.321e+00, Validation Loss: 2.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1417, Training Loss: 2.320e+00, Validation Loss: 2.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1418, Training Loss: 2.320e+00, Validation Loss: 2.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1419, Training Loss: 2.320e+00, Validation Loss: 2.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1420, Training Loss: 2.320e+00, Validation Loss: 2.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1421, Training Loss: 2.320e+00, Validation Loss: 2.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1422, Training Loss: 2.319e+00, Validation Loss: 2.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1423, Training Loss: 2.319e+00, Validation Loss: 2.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1424, Training Loss: 2.319e+00, Validation Loss: 2.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1425, Training Loss: 2.319e+00, Validation Loss: 2.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1426, Training Loss: 2.319e+00, Validation Loss: 2.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1427, Training Loss: 2.318e+00, Validation Loss: 2.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1428, Training Loss: 2.318e+00, Validation Loss: 2.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1429, Training Loss: 2.318e+00, Validation Loss: 2.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1430, Training Loss: 2.318e+00, Validation Loss: 2.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1431, Training Loss: 2.318e+00, Validation Loss: 2.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1432, Training Loss: 2.317e+00, Validation Loss: 2.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1433, Training Loss: 2.317e+00, Validation Loss: 2.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1434, Training Loss: 2.317e+00, Validation Loss: 2.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1435, Training Loss: 2.317e+00, Validation Loss: 2.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1436, Training Loss: 2.317e+00, Validation Loss: 2.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1437, Training Loss: 2.316e+00, Validation Loss: 2.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1438, Training Loss: 2.316e+00, Validation Loss: 2.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1439, Training Loss: 2.316e+00, Validation Loss: 2.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1440, Training Loss: 2.316e+00, Validation Loss: 2.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1441, Training Loss: 2.316e+00, Validation Loss: 2.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1442, Training Loss: 2.315e+00, Validation Loss: 2.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1443, Training Loss: 2.315e+00, Validation Loss: 2.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1444, Training Loss: 2.315e+00, Validation Loss: 2.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1445, Training Loss: 2.315e+00, Validation Loss: 2.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1446, Training Loss: 2.314e+00, Validation Loss: 2.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1447, Training Loss: 2.314e+00, Validation Loss: 2.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1448, Training Loss: 2.314e+00, Validation Loss: 2.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1449, Training Loss: 2.314e+00, Validation Loss: 2.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1450, Training Loss: 2.314e+00, Validation Loss: 2.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1451, Training Loss: 2.313e+00, Validation Loss: 2.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1452, Training Loss: 2.313e+00, Validation Loss: 2.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1453, Training Loss: 2.313e+00, Validation Loss: 2.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1454, Training Loss: 2.313e+00, Validation Loss: 2.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1455, Training Loss: 2.313e+00, Validation Loss: 2.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1456, Training Loss: 2.312e+00, Validation Loss: 2.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1457, Training Loss: 2.312e+00, Validation Loss: 2.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1458, Training Loss: 2.312e+00, Validation Loss: 2.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1459, Training Loss: 2.312e+00, Validation Loss: 2.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1460, Training Loss: 2.312e+00, Validation Loss: 2.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1461, Training Loss: 2.311e+00, Validation Loss: 2.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1462, Training Loss: 2.311e+00, Validation Loss: 2.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1463, Training Loss: 2.311e+00, Validation Loss: 2.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1464, Training Loss: 2.311e+00, Validation Loss: 2.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1465, Training Loss: 2.311e+00, Validation Loss: 2.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1466, Training Loss: 2.310e+00, Validation Loss: 2.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1467, Training Loss: 2.310e+00, Validation Loss: 2.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1468, Training Loss: 2.310e+00, Validation Loss: 2.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1469, Training Loss: 2.310e+00, Validation Loss: 2.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1470, Training Loss: 2.310e+00, Validation Loss: 2.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1471, Training Loss: 2.309e+00, Validation Loss: 2.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1472, Training Loss: 2.309e+00, Validation Loss: 2.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1473, Training Loss: 2.309e+00, Validation Loss: 2.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1474, Training Loss: 2.309e+00, Validation Loss: 2.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1475, Training Loss: 2.309e+00, Validation Loss: 2.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1476, Training Loss: 2.308e+00, Validation Loss: 2.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1477, Training Loss: 2.308e+00, Validation Loss: 2.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1478, Training Loss: 2.308e+00, Validation Loss: 2.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1479, Training Loss: 2.308e+00, Validation Loss: 2.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1480, Training Loss: 2.308e+00, Validation Loss: 2.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1481, Training Loss: 2.307e+00, Validation Loss: 2.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1482, Training Loss: 2.307e+00, Validation Loss: 2.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1483, Training Loss: 2.307e+00, Validation Loss: 2.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1484, Training Loss: 2.307e+00, Validation Loss: 2.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1485, Training Loss: 2.307e+00, Validation Loss: 2.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1486, Training Loss: 2.306e+00, Validation Loss: 2.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1487, Training Loss: 2.306e+00, Validation Loss: 2.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1488, Training Loss: 2.306e+00, Validation Loss: 2.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1489, Training Loss: 2.306e+00, Validation Loss: 2.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1490, Training Loss: 2.306e+00, Validation Loss: 2.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1491, Training Loss: 2.305e+00, Validation Loss: 2.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1492, Training Loss: 2.305e+00, Validation Loss: 2.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1493, Training Loss: 2.305e+00, Validation Loss: 2.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1494, Training Loss: 2.305e+00, Validation Loss: 2.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1495, Training Loss: 2.305e+00, Validation Loss: 2.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1496, Training Loss: 2.304e+00, Validation Loss: 2.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1497, Training Loss: 2.304e+00, Validation Loss: 2.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1498, Training Loss: 2.304e+00, Validation Loss: 2.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1499, Training Loss: 2.304e+00, Validation Loss: 2.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1500, Training Loss: 2.304e+00, Validation Loss: 2.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1501, Training Loss: 2.303e+00, Validation Loss: 2.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1502, Training Loss: 2.303e+00, Validation Loss: 2.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1503, Training Loss: 2.303e+00, Validation Loss: 2.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1504, Training Loss: 2.303e+00, Validation Loss: 2.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1505, Training Loss: 2.303e+00, Validation Loss: 2.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1506, Training Loss: 2.302e+00, Validation Loss: 2.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1507, Training Loss: 2.302e+00, Validation Loss: 2.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1508, Training Loss: 2.302e+00, Validation Loss: 2.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1509, Training Loss: 2.302e+00, Validation Loss: 2.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1510, Training Loss: 2.302e+00, Validation Loss: 2.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1511, Training Loss: 2.301e+00, Validation Loss: 2.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1512, Training Loss: 2.301e+00, Validation Loss: 2.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1513, Training Loss: 2.301e+00, Validation Loss: 2.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1514, Training Loss: 2.301e+00, Validation Loss: 2.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1515, Training Loss: 2.301e+00, Validation Loss: 2.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1516, Training Loss: 2.300e+00, Validation Loss: 2.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1517, Training Loss: 2.300e+00, Validation Loss: 2.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1518, Training Loss: 2.300e+00, Validation Loss: 2.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1519, Training Loss: 2.300e+00, Validation Loss: 2.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1520, Training Loss: 2.300e+00, Validation Loss: 2.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1521, Training Loss: 2.299e+00, Validation Loss: 2.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1522, Training Loss: 2.299e+00, Validation Loss: 2.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1523, Training Loss: 2.299e+00, Validation Loss: 2.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1524, Training Loss: 2.299e+00, Validation Loss: 2.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1525, Training Loss: 2.298e+00, Validation Loss: 2.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1526, Training Loss: 2.298e+00, Validation Loss: 2.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1527, Training Loss: 2.298e+00, Validation Loss: 2.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1528, Training Loss: 2.298e+00, Validation Loss: 2.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1529, Training Loss: 2.298e+00, Validation Loss: 2.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1530, Training Loss: 2.297e+00, Validation Loss: 2.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1531, Training Loss: 2.297e+00, Validation Loss: 2.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1532, Training Loss: 2.297e+00, Validation Loss: 2.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1533, Training Loss: 2.297e+00, Validation Loss: 2.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1534, Training Loss: 2.297e+00, Validation Loss: 2.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1535, Training Loss: 2.296e+00, Validation Loss: 2.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1536, Training Loss: 2.296e+00, Validation Loss: 2.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1537, Training Loss: 2.296e+00, Validation Loss: 2.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1538, Training Loss: 2.296e+00, Validation Loss: 2.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1539, Training Loss: 2.296e+00, Validation Loss: 2.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1540, Training Loss: 2.295e+00, Validation Loss: 2.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1541, Training Loss: 2.295e+00, Validation Loss: 2.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1542, Training Loss: 2.295e+00, Validation Loss: 2.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1543, Training Loss: 2.295e+00, Validation Loss: 2.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1544, Training Loss: 2.295e+00, Validation Loss: 2.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1545, Training Loss: 2.294e+00, Validation Loss: 2.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1546, Training Loss: 2.294e+00, Validation Loss: 2.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1547, Training Loss: 2.294e+00, Validation Loss: 2.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1548, Training Loss: 2.294e+00, Validation Loss: 2.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1549, Training Loss: 2.294e+00, Validation Loss: 2.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1550, Training Loss: 2.293e+00, Validation Loss: 2.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1551, Training Loss: 2.293e+00, Validation Loss: 2.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1552, Training Loss: 2.293e+00, Validation Loss: 2.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1553, Training Loss: 2.293e+00, Validation Loss: 2.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1554, Training Loss: 2.293e+00, Validation Loss: 2.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1555, Training Loss: 2.292e+00, Validation Loss: 2.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1556, Training Loss: 2.292e+00, Validation Loss: 2.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1557, Training Loss: 2.292e+00, Validation Loss: 2.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1558, Training Loss: 2.292e+00, Validation Loss: 2.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1559, Training Loss: 2.292e+00, Validation Loss: 2.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1560, Training Loss: 2.291e+00, Validation Loss: 2.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1561, Training Loss: 2.291e+00, Validation Loss: 2.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1562, Training Loss: 2.291e+00, Validation Loss: 2.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1563, Training Loss: 2.291e+00, Validation Loss: 2.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1564, Training Loss: 2.291e+00, Validation Loss: 2.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1565, Training Loss: 2.290e+00, Validation Loss: 2.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1566, Training Loss: 2.290e+00, Validation Loss: 2.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1567, Training Loss: 2.290e+00, Validation Loss: 2.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1568, Training Loss: 2.290e+00, Validation Loss: 2.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1569, Training Loss: 2.290e+00, Validation Loss: 2.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1570, Training Loss: 2.289e+00, Validation Loss: 2.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1571, Training Loss: 2.289e+00, Validation Loss: 2.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1572, Training Loss: 2.289e+00, Validation Loss: 2.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1573, Training Loss: 2.289e+00, Validation Loss: 2.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1574, Training Loss: 2.289e+00, Validation Loss: 2.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1575, Training Loss: 2.288e+00, Validation Loss: 2.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1576, Training Loss: 2.288e+00, Validation Loss: 2.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1577, Training Loss: 2.288e+00, Validation Loss: 2.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1578, Training Loss: 2.288e+00, Validation Loss: 2.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1579, Training Loss: 2.288e+00, Validation Loss: 2.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1580, Training Loss: 2.287e+00, Validation Loss: 2.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1581, Training Loss: 2.287e+00, Validation Loss: 2.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1582, Training Loss: 2.287e+00, Validation Loss: 2.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1583, Training Loss: 2.287e+00, Validation Loss: 2.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1584, Training Loss: 2.287e+00, Validation Loss: 2.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1585, Training Loss: 2.286e+00, Validation Loss: 2.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1586, Training Loss: 2.286e+00, Validation Loss: 2.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1587, Training Loss: 2.286e+00, Validation Loss: 2.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1588, Training Loss: 2.286e+00, Validation Loss: 2.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1589, Training Loss: 2.286e+00, Validation Loss: 2.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1590, Training Loss: 2.285e+00, Validation Loss: 2.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1591, Training Loss: 2.285e+00, Validation Loss: 2.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1592, Training Loss: 2.285e+00, Validation Loss: 2.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1593, Training Loss: 2.285e+00, Validation Loss: 2.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1594, Training Loss: 2.285e+00, Validation Loss: 2.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1595, Training Loss: 2.284e+00, Validation Loss: 2.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1596, Training Loss: 2.284e+00, Validation Loss: 2.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1597, Training Loss: 2.284e+00, Validation Loss: 2.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1598, Training Loss: 2.284e+00, Validation Loss: 2.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1599, Training Loss: 2.284e+00, Validation Loss: 2.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1600, Training Loss: 2.283e+00, Validation Loss: 2.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1601, Training Loss: 2.283e+00, Validation Loss: 2.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1602, Training Loss: 2.283e+00, Validation Loss: 2.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1603, Training Loss: 2.283e+00, Validation Loss: 2.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1604, Training Loss: 2.283e+00, Validation Loss: 2.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1605, Training Loss: 2.282e+00, Validation Loss: 2.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1606, Training Loss: 2.282e+00, Validation Loss: 2.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1607, Training Loss: 2.282e+00, Validation Loss: 2.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1608, Training Loss: 2.282e+00, Validation Loss: 2.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1609, Training Loss: 2.282e+00, Validation Loss: 2.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1610, Training Loss: 2.281e+00, Validation Loss: 2.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1611, Training Loss: 2.281e+00, Validation Loss: 2.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1612, Training Loss: 2.281e+00, Validation Loss: 2.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1613, Training Loss: 2.281e+00, Validation Loss: 2.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1614, Training Loss: 2.280e+00, Validation Loss: 2.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1615, Training Loss: 2.280e+00, Validation Loss: 2.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1616, Training Loss: 2.280e+00, Validation Loss: 2.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1617, Training Loss: 2.280e+00, Validation Loss: 2.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1618, Training Loss: 2.280e+00, Validation Loss: 2.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1619, Training Loss: 2.279e+00, Validation Loss: 2.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1620, Training Loss: 2.279e+00, Validation Loss: 2.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1621, Training Loss: 2.279e+00, Validation Loss: 2.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1622, Training Loss: 2.279e+00, Validation Loss: 2.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1623, Training Loss: 2.279e+00, Validation Loss: 2.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1624, Training Loss: 2.278e+00, Validation Loss: 2.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1625, Training Loss: 2.278e+00, Validation Loss: 2.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1626, Training Loss: 2.278e+00, Validation Loss: 2.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1627, Training Loss: 2.278e+00, Validation Loss: 2.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1628, Training Loss: 2.278e+00, Validation Loss: 2.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1629, Training Loss: 2.277e+00, Validation Loss: 2.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1630, Training Loss: 2.277e+00, Validation Loss: 2.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1631, Training Loss: 2.277e+00, Validation Loss: 2.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1632, Training Loss: 2.277e+00, Validation Loss: 2.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1633, Training Loss: 2.277e+00, Validation Loss: 2.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1634, Training Loss: 2.276e+00, Validation Loss: 2.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1635, Training Loss: 2.276e+00, Validation Loss: 2.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1636, Training Loss: 2.276e+00, Validation Loss: 2.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1637, Training Loss: 2.276e+00, Validation Loss: 2.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1638, Training Loss: 2.276e+00, Validation Loss: 2.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1639, Training Loss: 2.275e+00, Validation Loss: 2.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1640, Training Loss: 2.275e+00, Validation Loss: 2.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1641, Training Loss: 2.275e+00, Validation Loss: 2.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1642, Training Loss: 2.275e+00, Validation Loss: 2.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1643, Training Loss: 2.275e+00, Validation Loss: 2.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1644, Training Loss: 2.274e+00, Validation Loss: 2.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1645, Training Loss: 2.274e+00, Validation Loss: 2.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1646, Training Loss: 2.274e+00, Validation Loss: 2.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1647, Training Loss: 2.274e+00, Validation Loss: 2.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1648, Training Loss: 2.274e+00, Validation Loss: 2.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1649, Training Loss: 2.273e+00, Validation Loss: 2.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1650, Training Loss: 2.273e+00, Validation Loss: 2.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1651, Training Loss: 2.273e+00, Validation Loss: 2.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1652, Training Loss: 2.273e+00, Validation Loss: 2.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1653, Training Loss: 2.273e+00, Validation Loss: 2.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1654, Training Loss: 2.272e+00, Validation Loss: 2.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1655, Training Loss: 2.272e+00, Validation Loss: 2.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1656, Training Loss: 2.272e+00, Validation Loss: 2.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1657, Training Loss: 2.272e+00, Validation Loss: 2.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1658, Training Loss: 2.272e+00, Validation Loss: 2.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1659, Training Loss: 2.271e+00, Validation Loss: 2.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1660, Training Loss: 2.271e+00, Validation Loss: 2.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1661, Training Loss: 2.271e+00, Validation Loss: 2.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1662, Training Loss: 2.271e+00, Validation Loss: 2.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1663, Training Loss: 2.271e+00, Validation Loss: 2.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1664, Training Loss: 2.270e+00, Validation Loss: 2.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1665, Training Loss: 2.270e+00, Validation Loss: 2.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1666, Training Loss: 2.270e+00, Validation Loss: 2.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1667, Training Loss: 2.270e+00, Validation Loss: 2.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1668, Training Loss: 2.270e+00, Validation Loss: 2.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1669, Training Loss: 2.269e+00, Validation Loss: 2.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1670, Training Loss: 2.269e+00, Validation Loss: 2.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1671, Training Loss: 2.269e+00, Validation Loss: 2.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1672, Training Loss: 2.269e+00, Validation Loss: 2.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1673, Training Loss: 2.269e+00, Validation Loss: 2.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1674, Training Loss: 2.268e+00, Validation Loss: 2.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1675, Training Loss: 2.268e+00, Validation Loss: 2.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1676, Training Loss: 2.268e+00, Validation Loss: 2.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1677, Training Loss: 2.268e+00, Validation Loss: 2.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1678, Training Loss: 2.268e+00, Validation Loss: 2.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1679, Training Loss: 2.267e+00, Validation Loss: 2.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1680, Training Loss: 2.267e+00, Validation Loss: 2.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1681, Training Loss: 2.267e+00, Validation Loss: 2.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1682, Training Loss: 2.267e+00, Validation Loss: 2.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1683, Training Loss: 2.267e+00, Validation Loss: 2.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1684, Training Loss: 2.266e+00, Validation Loss: 2.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1685, Training Loss: 2.266e+00, Validation Loss: 2.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1686, Training Loss: 2.266e+00, Validation Loss: 2.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1687, Training Loss: 2.266e+00, Validation Loss: 2.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1688, Training Loss: 2.266e+00, Validation Loss: 2.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1689, Training Loss: 2.265e+00, Validation Loss: 2.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1690, Training Loss: 2.265e+00, Validation Loss: 2.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1691, Training Loss: 2.265e+00, Validation Loss: 2.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1692, Training Loss: 2.265e+00, Validation Loss: 2.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1693, Training Loss: 2.265e+00, Validation Loss: 2.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1694, Training Loss: 2.264e+00, Validation Loss: 2.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1695, Training Loss: 2.264e+00, Validation Loss: 2.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1696, Training Loss: 2.264e+00, Validation Loss: 2.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1697, Training Loss: 2.264e+00, Validation Loss: 2.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1698, Training Loss: 2.264e+00, Validation Loss: 2.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1699, Training Loss: 2.263e+00, Validation Loss: 2.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1700, Training Loss: 2.263e+00, Validation Loss: 2.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1701, Training Loss: 2.263e+00, Validation Loss: 2.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1702, Training Loss: 2.263e+00, Validation Loss: 2.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1703, Training Loss: 2.262e+00, Validation Loss: 2.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1704, Training Loss: 2.262e+00, Validation Loss: 2.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1705, Training Loss: 2.262e+00, Validation Loss: 2.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1706, Training Loss: 2.262e+00, Validation Loss: 2.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1707, Training Loss: 2.262e+00, Validation Loss: 2.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1708, Training Loss: 2.261e+00, Validation Loss: 2.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1709, Training Loss: 2.261e+00, Validation Loss: 2.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1710, Training Loss: 2.261e+00, Validation Loss: 2.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1711, Training Loss: 2.261e+00, Validation Loss: 2.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1712, Training Loss: 2.261e+00, Validation Loss: 2.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1713, Training Loss: 2.260e+00, Validation Loss: 2.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1714, Training Loss: 2.260e+00, Validation Loss: 2.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1715, Training Loss: 2.260e+00, Validation Loss: 2.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1716, Training Loss: 2.260e+00, Validation Loss: 2.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1717, Training Loss: 2.260e+00, Validation Loss: 2.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1718, Training Loss: 2.259e+00, Validation Loss: 2.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1719, Training Loss: 2.259e+00, Validation Loss: 2.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1720, Training Loss: 2.259e+00, Validation Loss: 2.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1721, Training Loss: 2.259e+00, Validation Loss: 2.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1722, Training Loss: 2.259e+00, Validation Loss: 2.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1723, Training Loss: 2.258e+00, Validation Loss: 2.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1724, Training Loss: 2.258e+00, Validation Loss: 2.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1725, Training Loss: 2.258e+00, Validation Loss: 2.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1726, Training Loss: 2.258e+00, Validation Loss: 2.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1727, Training Loss: 2.258e+00, Validation Loss: 2.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1728, Training Loss: 2.257e+00, Validation Loss: 2.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1729, Training Loss: 2.257e+00, Validation Loss: 2.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1730, Training Loss: 2.257e+00, Validation Loss: 2.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1731, Training Loss: 2.257e+00, Validation Loss: 2.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1732, Training Loss: 2.257e+00, Validation Loss: 2.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1733, Training Loss: 2.256e+00, Validation Loss: 2.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1734, Training Loss: 2.256e+00, Validation Loss: 2.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1735, Training Loss: 2.256e+00, Validation Loss: 2.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1736, Training Loss: 2.256e+00, Validation Loss: 2.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1737, Training Loss: 2.256e+00, Validation Loss: 2.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1738, Training Loss: 2.255e+00, Validation Loss: 2.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1739, Training Loss: 2.255e+00, Validation Loss: 2.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1740, Training Loss: 2.255e+00, Validation Loss: 2.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1741, Training Loss: 2.255e+00, Validation Loss: 2.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1742, Training Loss: 2.255e+00, Validation Loss: 2.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1743, Training Loss: 2.254e+00, Validation Loss: 2.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1744, Training Loss: 2.254e+00, Validation Loss: 2.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1745, Training Loss: 2.254e+00, Validation Loss: 2.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1746, Training Loss: 2.254e+00, Validation Loss: 2.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1747, Training Loss: 2.254e+00, Validation Loss: 2.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1748, Training Loss: 2.253e+00, Validation Loss: 2.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1749, Training Loss: 2.253e+00, Validation Loss: 2.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1750, Training Loss: 2.253e+00, Validation Loss: 2.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1751, Training Loss: 2.253e+00, Validation Loss: 2.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1752, Training Loss: 2.253e+00, Validation Loss: 2.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1753, Training Loss: 2.252e+00, Validation Loss: 2.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1754, Training Loss: 2.252e+00, Validation Loss: 2.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1755, Training Loss: 2.252e+00, Validation Loss: 2.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1756, Training Loss: 2.252e+00, Validation Loss: 2.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1757, Training Loss: 2.252e+00, Validation Loss: 2.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1758, Training Loss: 2.251e+00, Validation Loss: 2.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1759, Training Loss: 2.251e+00, Validation Loss: 2.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1760, Training Loss: 2.251e+00, Validation Loss: 2.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1761, Training Loss: 2.251e+00, Validation Loss: 2.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1762, Training Loss: 2.251e+00, Validation Loss: 2.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1763, Training Loss: 2.250e+00, Validation Loss: 2.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1764, Training Loss: 2.250e+00, Validation Loss: 2.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1765, Training Loss: 2.250e+00, Validation Loss: 2.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1766, Training Loss: 2.250e+00, Validation Loss: 2.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1767, Training Loss: 2.250e+00, Validation Loss: 2.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1768, Training Loss: 2.249e+00, Validation Loss: 2.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1769, Training Loss: 2.249e+00, Validation Loss: 2.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1770, Training Loss: 2.249e+00, Validation Loss: 2.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1771, Training Loss: 2.249e+00, Validation Loss: 2.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1772, Training Loss: 2.249e+00, Validation Loss: 2.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1773, Training Loss: 2.248e+00, Validation Loss: 2.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1774, Training Loss: 2.248e+00, Validation Loss: 2.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1775, Training Loss: 2.248e+00, Validation Loss: 2.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1776, Training Loss: 2.248e+00, Validation Loss: 2.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1777, Training Loss: 2.247e+00, Validation Loss: 2.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1778, Training Loss: 2.247e+00, Validation Loss: 2.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1779, Training Loss: 2.247e+00, Validation Loss: 2.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1780, Training Loss: 2.247e+00, Validation Loss: 2.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1781, Training Loss: 2.247e+00, Validation Loss: 2.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1782, Training Loss: 2.246e+00, Validation Loss: 2.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1783, Training Loss: 2.246e+00, Validation Loss: 2.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1784, Training Loss: 2.246e+00, Validation Loss: 2.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1785, Training Loss: 2.246e+00, Validation Loss: 2.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1786, Training Loss: 2.246e+00, Validation Loss: 2.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1787, Training Loss: 2.245e+00, Validation Loss: 2.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1788, Training Loss: 2.245e+00, Validation Loss: 2.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1789, Training Loss: 2.245e+00, Validation Loss: 2.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1790, Training Loss: 2.245e+00, Validation Loss: 2.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1791, Training Loss: 2.245e+00, Validation Loss: 2.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1792, Training Loss: 2.244e+00, Validation Loss: 2.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1793, Training Loss: 2.244e+00, Validation Loss: 2.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1794, Training Loss: 2.244e+00, Validation Loss: 2.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1795, Training Loss: 2.244e+00, Validation Loss: 2.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1796, Training Loss: 2.244e+00, Validation Loss: 2.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1797, Training Loss: 2.243e+00, Validation Loss: 2.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1798, Training Loss: 2.243e+00, Validation Loss: 2.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1799, Training Loss: 2.243e+00, Validation Loss: 2.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1800, Training Loss: 2.243e+00, Validation Loss: 2.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1801, Training Loss: 2.243e+00, Validation Loss: 2.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1802, Training Loss: 2.242e+00, Validation Loss: 2.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1803, Training Loss: 2.242e+00, Validation Loss: 2.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1804, Training Loss: 2.242e+00, Validation Loss: 2.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1805, Training Loss: 2.242e+00, Validation Loss: 2.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1806, Training Loss: 2.242e+00, Validation Loss: 2.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1807, Training Loss: 2.241e+00, Validation Loss: 2.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1808, Training Loss: 2.241e+00, Validation Loss: 2.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1809, Training Loss: 2.241e+00, Validation Loss: 2.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1810, Training Loss: 2.241e+00, Validation Loss: 2.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1811, Training Loss: 2.241e+00, Validation Loss: 2.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1812, Training Loss: 2.240e+00, Validation Loss: 2.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1813, Training Loss: 2.240e+00, Validation Loss: 2.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1814, Training Loss: 2.240e+00, Validation Loss: 2.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1815, Training Loss: 2.240e+00, Validation Loss: 2.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1816, Training Loss: 2.240e+00, Validation Loss: 2.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1817, Training Loss: 2.239e+00, Validation Loss: 2.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1818, Training Loss: 2.239e+00, Validation Loss: 2.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1819, Training Loss: 2.239e+00, Validation Loss: 2.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1820, Training Loss: 2.239e+00, Validation Loss: 2.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1821, Training Loss: 2.239e+00, Validation Loss: 2.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1822, Training Loss: 2.238e+00, Validation Loss: 2.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1823, Training Loss: 2.238e+00, Validation Loss: 2.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1824, Training Loss: 2.238e+00, Validation Loss: 2.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1825, Training Loss: 2.238e+00, Validation Loss: 2.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1826, Training Loss: 2.238e+00, Validation Loss: 2.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1827, Training Loss: 2.237e+00, Validation Loss: 2.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1828, Training Loss: 2.237e+00, Validation Loss: 2.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1829, Training Loss: 2.237e+00, Validation Loss: 2.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1830, Training Loss: 2.237e+00, Validation Loss: 2.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1831, Training Loss: 2.237e+00, Validation Loss: 2.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1832, Training Loss: 2.236e+00, Validation Loss: 2.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1833, Training Loss: 2.236e+00, Validation Loss: 2.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1834, Training Loss: 2.236e+00, Validation Loss: 2.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1835, Training Loss: 2.236e+00, Validation Loss: 2.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1836, Training Loss: 2.235e+00, Validation Loss: 2.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1837, Training Loss: 2.235e+00, Validation Loss: 2.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1838, Training Loss: 2.235e+00, Validation Loss: 2.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1839, Training Loss: 2.235e+00, Validation Loss: 2.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1840, Training Loss: 2.235e+00, Validation Loss: 2.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1841, Training Loss: 2.234e+00, Validation Loss: 2.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1842, Training Loss: 2.234e+00, Validation Loss: 2.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1843, Training Loss: 2.234e+00, Validation Loss: 2.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1844, Training Loss: 2.234e+00, Validation Loss: 2.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1845, Training Loss: 2.234e+00, Validation Loss: 2.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1846, Training Loss: 2.233e+00, Validation Loss: 2.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1847, Training Loss: 2.233e+00, Validation Loss: 2.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1848, Training Loss: 2.233e+00, Validation Loss: 2.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1849, Training Loss: 2.233e+00, Validation Loss: 2.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1850, Training Loss: 2.233e+00, Validation Loss: 2.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1851, Training Loss: 2.232e+00, Validation Loss: 2.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1852, Training Loss: 2.232e+00, Validation Loss: 2.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1853, Training Loss: 2.232e+00, Validation Loss: 2.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1854, Training Loss: 2.232e+00, Validation Loss: 2.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1855, Training Loss: 2.232e+00, Validation Loss: 2.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1856, Training Loss: 2.231e+00, Validation Loss: 2.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1857, Training Loss: 2.231e+00, Validation Loss: 2.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1858, Training Loss: 2.231e+00, Validation Loss: 2.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1859, Training Loss: 2.231e+00, Validation Loss: 2.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1860, Training Loss: 2.231e+00, Validation Loss: 2.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1861, Training Loss: 2.230e+00, Validation Loss: 2.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1862, Training Loss: 2.230e+00, Validation Loss: 2.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1863, Training Loss: 2.230e+00, Validation Loss: 2.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1864, Training Loss: 2.230e+00, Validation Loss: 2.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1865, Training Loss: 2.230e+00, Validation Loss: 2.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1866, Training Loss: 2.229e+00, Validation Loss: 2.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1867, Training Loss: 2.229e+00, Validation Loss: 2.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1868, Training Loss: 2.229e+00, Validation Loss: 2.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1869, Training Loss: 2.229e+00, Validation Loss: 2.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1870, Training Loss: 2.229e+00, Validation Loss: 2.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1871, Training Loss: 2.228e+00, Validation Loss: 2.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1872, Training Loss: 2.228e+00, Validation Loss: 2.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1873, Training Loss: 2.228e+00, Validation Loss: 2.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1874, Training Loss: 2.228e+00, Validation Loss: 2.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1875, Training Loss: 2.227e+00, Validation Loss: 2.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1876, Training Loss: 2.227e+00, Validation Loss: 2.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1877, Training Loss: 2.227e+00, Validation Loss: 2.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1878, Training Loss: 2.227e+00, Validation Loss: 2.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1879, Training Loss: 2.227e+00, Validation Loss: 2.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1880, Training Loss: 2.226e+00, Validation Loss: 2.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1881, Training Loss: 2.226e+00, Validation Loss: 2.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1882, Training Loss: 2.226e+00, Validation Loss: 2.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1883, Training Loss: 2.226e+00, Validation Loss: 2.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1884, Training Loss: 2.226e+00, Validation Loss: 2.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1885, Training Loss: 2.225e+00, Validation Loss: 2.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1886, Training Loss: 2.225e+00, Validation Loss: 2.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1887, Training Loss: 2.225e+00, Validation Loss: 2.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1888, Training Loss: 2.225e+00, Validation Loss: 2.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1889, Training Loss: 2.225e+00, Validation Loss: 2.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1890, Training Loss: 2.224e+00, Validation Loss: 2.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1891, Training Loss: 2.224e+00, Validation Loss: 2.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1892, Training Loss: 2.224e+00, Validation Loss: 2.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1893, Training Loss: 2.224e+00, Validation Loss: 2.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1894, Training Loss: 2.224e+00, Validation Loss: 2.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1895, Training Loss: 2.223e+00, Validation Loss: 2.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1896, Training Loss: 2.223e+00, Validation Loss: 2.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1897, Training Loss: 2.223e+00, Validation Loss: 2.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1898, Training Loss: 2.223e+00, Validation Loss: 2.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1899, Training Loss: 2.223e+00, Validation Loss: 2.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1900, Training Loss: 2.222e+00, Validation Loss: 2.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1901, Training Loss: 2.222e+00, Validation Loss: 2.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1902, Training Loss: 2.222e+00, Validation Loss: 2.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1903, Training Loss: 2.222e+00, Validation Loss: 2.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1904, Training Loss: 2.222e+00, Validation Loss: 2.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1905, Training Loss: 2.221e+00, Validation Loss: 2.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1906, Training Loss: 2.221e+00, Validation Loss: 2.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1907, Training Loss: 2.221e+00, Validation Loss: 2.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1908, Training Loss: 2.221e+00, Validation Loss: 2.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1909, Training Loss: 2.221e+00, Validation Loss: 2.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1910, Training Loss: 2.220e+00, Validation Loss: 2.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1911, Training Loss: 2.220e+00, Validation Loss: 2.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1912, Training Loss: 2.220e+00, Validation Loss: 2.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1913, Training Loss: 2.220e+00, Validation Loss: 2.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1914, Training Loss: 2.220e+00, Validation Loss: 2.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1915, Training Loss: 2.219e+00, Validation Loss: 2.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1916, Training Loss: 2.219e+00, Validation Loss: 2.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1917, Training Loss: 2.219e+00, Validation Loss: 2.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1918, Training Loss: 2.219e+00, Validation Loss: 2.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1919, Training Loss: 2.219e+00, Validation Loss: 2.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1920, Training Loss: 2.218e+00, Validation Loss: 2.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1921, Training Loss: 2.218e+00, Validation Loss: 2.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1922, Training Loss: 2.218e+00, Validation Loss: 2.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1923, Training Loss: 2.218e+00, Validation Loss: 2.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1924, Training Loss: 2.218e+00, Validation Loss: 2.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1925, Training Loss: 2.217e+00, Validation Loss: 2.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1926, Training Loss: 2.217e+00, Validation Loss: 2.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1927, Training Loss: 2.217e+00, Validation Loss: 2.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1928, Training Loss: 2.217e+00, Validation Loss: 2.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1929, Training Loss: 2.217e+00, Validation Loss: 2.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1930, Training Loss: 2.216e+00, Validation Loss: 2.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1931, Training Loss: 2.216e+00, Validation Loss: 2.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1932, Training Loss: 2.216e+00, Validation Loss: 2.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1933, Training Loss: 2.216e+00, Validation Loss: 2.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1934, Training Loss: 2.216e+00, Validation Loss: 2.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1935, Training Loss: 2.215e+00, Validation Loss: 2.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1936, Training Loss: 2.215e+00, Validation Loss: 2.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1937, Training Loss: 2.215e+00, Validation Loss: 2.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1938, Training Loss: 2.215e+00, Validation Loss: 2.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1939, Training Loss: 2.214e+00, Validation Loss: 2.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1940, Training Loss: 2.214e+00, Validation Loss: 2.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1941, Training Loss: 2.214e+00, Validation Loss: 2.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1942, Training Loss: 2.214e+00, Validation Loss: 2.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1943, Training Loss: 2.214e+00, Validation Loss: 2.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1944, Training Loss: 2.213e+00, Validation Loss: 2.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1945, Training Loss: 2.213e+00, Validation Loss: 2.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1946, Training Loss: 2.213e+00, Validation Loss: 2.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1947, Training Loss: 2.213e+00, Validation Loss: 2.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1948, Training Loss: 2.213e+00, Validation Loss: 2.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1949, Training Loss: 2.212e+00, Validation Loss: 2.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1950, Training Loss: 2.212e+00, Validation Loss: 2.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1951, Training Loss: 2.212e+00, Validation Loss: 2.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1952, Training Loss: 2.212e+00, Validation Loss: 2.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1953, Training Loss: 2.212e+00, Validation Loss: 2.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1954, Training Loss: 2.211e+00, Validation Loss: 2.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1955, Training Loss: 2.211e+00, Validation Loss: 2.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1956, Training Loss: 2.211e+00, Validation Loss: 2.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1957, Training Loss: 2.211e+00, Validation Loss: 2.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1958, Training Loss: 2.211e+00, Validation Loss: 2.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1959, Training Loss: 2.210e+00, Validation Loss: 2.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1960, Training Loss: 2.210e+00, Validation Loss: 2.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1961, Training Loss: 2.210e+00, Validation Loss: 2.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1962, Training Loss: 2.210e+00, Validation Loss: 2.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1963, Training Loss: 2.210e+00, Validation Loss: 2.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1964, Training Loss: 2.209e+00, Validation Loss: 2.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1965, Training Loss: 2.209e+00, Validation Loss: 2.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1966, Training Loss: 2.209e+00, Validation Loss: 2.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1967, Training Loss: 2.209e+00, Validation Loss: 2.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1968, Training Loss: 2.209e+00, Validation Loss: 2.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1969, Training Loss: 2.208e+00, Validation Loss: 2.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1970, Training Loss: 2.208e+00, Validation Loss: 2.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1971, Training Loss: 2.208e+00, Validation Loss: 2.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1972, Training Loss: 2.208e+00, Validation Loss: 2.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1973, Training Loss: 2.207e+00, Validation Loss: 2.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1974, Training Loss: 2.207e+00, Validation Loss: 2.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1975, Training Loss: 2.207e+00, Validation Loss: 2.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1976, Training Loss: 2.207e+00, Validation Loss: 2.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1977, Training Loss: 2.207e+00, Validation Loss: 2.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1978, Training Loss: 2.206e+00, Validation Loss: 2.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1979, Training Loss: 2.206e+00, Validation Loss: 2.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1980, Training Loss: 2.206e+00, Validation Loss: 2.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1981, Training Loss: 2.206e+00, Validation Loss: 2.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1982, Training Loss: 2.206e+00, Validation Loss: 2.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1983, Training Loss: 2.205e+00, Validation Loss: 2.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1984, Training Loss: 2.205e+00, Validation Loss: 2.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1985, Training Loss: 2.205e+00, Validation Loss: 2.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1986, Training Loss: 2.205e+00, Validation Loss: 2.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1987, Training Loss: 2.205e+00, Validation Loss: 2.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1988, Training Loss: 2.204e+00, Validation Loss: 2.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1989, Training Loss: 2.204e+00, Validation Loss: 2.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1990, Training Loss: 2.204e+00, Validation Loss: 2.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1991, Training Loss: 2.204e+00, Validation Loss: 2.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1992, Training Loss: 2.204e+00, Validation Loss: 2.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1993, Training Loss: 2.203e+00, Validation Loss: 2.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1994, Training Loss: 2.203e+00, Validation Loss: 2.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1995, Training Loss: 2.203e+00, Validation Loss: 2.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1996, Training Loss: 2.203e+00, Validation Loss: 2.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1997, Training Loss: 2.203e+00, Validation Loss: 2.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1998, Training Loss: 2.202e+00, Validation Loss: 2.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1999, Training Loss: 2.202e+00, Validation Loss: 2.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2000, Training Loss: 2.202e+00, Validation Loss: 2.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2001, Training Loss: 2.202e+00, Validation Loss: 2.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2002, Training Loss: 2.202e+00, Validation Loss: 2.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2003, Training Loss: 2.201e+00, Validation Loss: 2.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2004, Training Loss: 2.201e+00, Validation Loss: 2.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2005, Training Loss: 2.201e+00, Validation Loss: 2.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2006, Training Loss: 2.201e+00, Validation Loss: 2.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2007, Training Loss: 2.201e+00, Validation Loss: 2.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2008, Training Loss: 2.200e+00, Validation Loss: 2.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2009, Training Loss: 2.200e+00, Validation Loss: 2.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2010, Training Loss: 2.200e+00, Validation Loss: 2.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2011, Training Loss: 2.200e+00, Validation Loss: 2.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2012, Training Loss: 2.200e+00, Validation Loss: 2.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2013, Training Loss: 2.199e+00, Validation Loss: 2.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2014, Training Loss: 2.199e+00, Validation Loss: 2.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2015, Training Loss: 2.199e+00, Validation Loss: 2.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2016, Training Loss: 2.199e+00, Validation Loss: 2.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2017, Training Loss: 2.198e+00, Validation Loss: 2.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2018, Training Loss: 2.198e+00, Validation Loss: 2.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2019, Training Loss: 2.198e+00, Validation Loss: 2.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2020, Training Loss: 2.198e+00, Validation Loss: 2.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2021, Training Loss: 2.198e+00, Validation Loss: 2.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2022, Training Loss: 2.197e+00, Validation Loss: 2.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2023, Training Loss: 2.197e+00, Validation Loss: 2.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2024, Training Loss: 2.197e+00, Validation Loss: 2.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2025, Training Loss: 2.197e+00, Validation Loss: 2.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2026, Training Loss: 2.197e+00, Validation Loss: 2.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2027, Training Loss: 2.196e+00, Validation Loss: 2.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2028, Training Loss: 2.196e+00, Validation Loss: 2.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2029, Training Loss: 2.196e+00, Validation Loss: 2.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2030, Training Loss: 2.196e+00, Validation Loss: 2.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2031, Training Loss: 2.196e+00, Validation Loss: 2.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2032, Training Loss: 2.195e+00, Validation Loss: 2.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2033, Training Loss: 2.195e+00, Validation Loss: 2.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2034, Training Loss: 2.195e+00, Validation Loss: 2.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2035, Training Loss: 2.195e+00, Validation Loss: 2.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2036, Training Loss: 2.195e+00, Validation Loss: 2.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2037, Training Loss: 2.194e+00, Validation Loss: 2.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2038, Training Loss: 2.194e+00, Validation Loss: 2.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2039, Training Loss: 2.194e+00, Validation Loss: 2.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2040, Training Loss: 2.194e+00, Validation Loss: 2.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2041, Training Loss: 2.194e+00, Validation Loss: 2.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2042, Training Loss: 2.193e+00, Validation Loss: 2.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2043, Training Loss: 2.193e+00, Validation Loss: 2.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2044, Training Loss: 2.193e+00, Validation Loss: 2.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2045, Training Loss: 2.193e+00, Validation Loss: 2.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2046, Training Loss: 2.193e+00, Validation Loss: 2.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2047, Training Loss: 2.192e+00, Validation Loss: 2.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2048, Training Loss: 2.192e+00, Validation Loss: 2.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2049, Training Loss: 2.192e+00, Validation Loss: 2.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2050, Training Loss: 2.192e+00, Validation Loss: 2.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2051, Training Loss: 2.192e+00, Validation Loss: 2.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2052, Training Loss: 2.191e+00, Validation Loss: 2.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2053, Training Loss: 2.191e+00, Validation Loss: 2.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2054, Training Loss: 2.191e+00, Validation Loss: 2.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2055, Training Loss: 2.191e+00, Validation Loss: 2.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2056, Training Loss: 2.191e+00, Validation Loss: 2.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2057, Training Loss: 2.190e+00, Validation Loss: 2.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2058, Training Loss: 2.190e+00, Validation Loss: 2.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2059, Training Loss: 2.190e+00, Validation Loss: 2.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2060, Training Loss: 2.190e+00, Validation Loss: 2.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2061, Training Loss: 2.189e+00, Validation Loss: 2.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2062, Training Loss: 2.189e+00, Validation Loss: 2.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2063, Training Loss: 2.189e+00, Validation Loss: 2.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2064, Training Loss: 2.189e+00, Validation Loss: 2.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2065, Training Loss: 2.189e+00, Validation Loss: 2.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2066, Training Loss: 2.188e+00, Validation Loss: 2.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2067, Training Loss: 2.188e+00, Validation Loss: 2.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2068, Training Loss: 2.188e+00, Validation Loss: 2.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2069, Training Loss: 2.188e+00, Validation Loss: 2.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2070, Training Loss: 2.188e+00, Validation Loss: 2.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2071, Training Loss: 2.187e+00, Validation Loss: 2.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2072, Training Loss: 2.187e+00, Validation Loss: 2.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2073, Training Loss: 2.187e+00, Validation Loss: 2.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2074, Training Loss: 2.187e+00, Validation Loss: 2.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2075, Training Loss: 2.187e+00, Validation Loss: 2.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2076, Training Loss: 2.186e+00, Validation Loss: 2.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2077, Training Loss: 2.186e+00, Validation Loss: 2.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2078, Training Loss: 2.186e+00, Validation Loss: 2.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2079, Training Loss: 2.186e+00, Validation Loss: 2.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2080, Training Loss: 2.186e+00, Validation Loss: 2.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2081, Training Loss: 2.185e+00, Validation Loss: 2.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2082, Training Loss: 2.185e+00, Validation Loss: 2.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2083, Training Loss: 2.185e+00, Validation Loss: 2.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2084, Training Loss: 2.185e+00, Validation Loss: 2.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2085, Training Loss: 2.185e+00, Validation Loss: 2.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2086, Training Loss: 2.184e+00, Validation Loss: 2.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2087, Training Loss: 2.184e+00, Validation Loss: 2.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2088, Training Loss: 2.184e+00, Validation Loss: 2.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2089, Training Loss: 2.184e+00, Validation Loss: 2.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2090, Training Loss: 2.184e+00, Validation Loss: 2.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2091, Training Loss: 2.183e+00, Validation Loss: 2.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2092, Training Loss: 2.183e+00, Validation Loss: 2.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2093, Training Loss: 2.183e+00, Validation Loss: 2.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2094, Training Loss: 2.183e+00, Validation Loss: 2.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2095, Training Loss: 2.183e+00, Validation Loss: 2.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2096, Training Loss: 2.182e+00, Validation Loss: 2.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2097, Training Loss: 2.182e+00, Validation Loss: 2.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2098, Training Loss: 2.182e+00, Validation Loss: 2.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2099, Training Loss: 2.182e+00, Validation Loss: 2.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2100, Training Loss: 2.182e+00, Validation Loss: 2.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2101, Training Loss: 2.181e+00, Validation Loss: 2.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2102, Training Loss: 2.181e+00, Validation Loss: 2.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2103, Training Loss: 2.181e+00, Validation Loss: 2.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2104, Training Loss: 2.181e+00, Validation Loss: 2.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2105, Training Loss: 2.181e+00, Validation Loss: 2.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2106, Training Loss: 2.180e+00, Validation Loss: 2.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2107, Training Loss: 2.180e+00, Validation Loss: 2.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2108, Training Loss: 2.180e+00, Validation Loss: 2.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2109, Training Loss: 2.180e+00, Validation Loss: 2.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2110, Training Loss: 2.179e+00, Validation Loss: 2.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2111, Training Loss: 2.179e+00, Validation Loss: 2.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2112, Training Loss: 2.179e+00, Validation Loss: 2.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2113, Training Loss: 2.179e+00, Validation Loss: 2.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2114, Training Loss: 2.179e+00, Validation Loss: 2.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2115, Training Loss: 2.178e+00, Validation Loss: 2.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2116, Training Loss: 2.178e+00, Validation Loss: 2.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2117, Training Loss: 2.178e+00, Validation Loss: 2.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2118, Training Loss: 2.178e+00, Validation Loss: 2.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2119, Training Loss: 2.178e+00, Validation Loss: 2.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2120, Training Loss: 2.177e+00, Validation Loss: 2.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2121, Training Loss: 2.177e+00, Validation Loss: 2.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2122, Training Loss: 2.177e+00, Validation Loss: 2.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2123, Training Loss: 2.177e+00, Validation Loss: 2.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2124, Training Loss: 2.177e+00, Validation Loss: 2.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2125, Training Loss: 2.176e+00, Validation Loss: 2.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2126, Training Loss: 2.176e+00, Validation Loss: 2.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2127, Training Loss: 2.176e+00, Validation Loss: 2.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2128, Training Loss: 2.176e+00, Validation Loss: 2.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2129, Training Loss: 2.176e+00, Validation Loss: 2.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2130, Training Loss: 2.175e+00, Validation Loss: 2.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2131, Training Loss: 2.175e+00, Validation Loss: 2.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2132, Training Loss: 2.175e+00, Validation Loss: 2.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2133, Training Loss: 2.175e+00, Validation Loss: 2.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2134, Training Loss: 2.175e+00, Validation Loss: 2.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2135, Training Loss: 2.174e+00, Validation Loss: 2.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2136, Training Loss: 2.174e+00, Validation Loss: 2.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2137, Training Loss: 2.174e+00, Validation Loss: 2.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2138, Training Loss: 2.174e+00, Validation Loss: 2.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2139, Training Loss: 2.174e+00, Validation Loss: 2.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2140, Training Loss: 2.173e+00, Validation Loss: 2.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2141, Training Loss: 2.173e+00, Validation Loss: 2.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2142, Training Loss: 2.173e+00, Validation Loss: 2.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2143, Training Loss: 2.173e+00, Validation Loss: 2.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2144, Training Loss: 2.173e+00, Validation Loss: 2.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2145, Training Loss: 2.172e+00, Validation Loss: 2.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2146, Training Loss: 2.172e+00, Validation Loss: 2.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2147, Training Loss: 2.172e+00, Validation Loss: 2.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2148, Training Loss: 2.172e+00, Validation Loss: 2.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2149, Training Loss: 2.171e+00, Validation Loss: 2.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2150, Training Loss: 2.171e+00, Validation Loss: 2.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2151, Training Loss: 2.171e+00, Validation Loss: 2.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2152, Training Loss: 2.171e+00, Validation Loss: 2.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2153, Training Loss: 2.171e+00, Validation Loss: 2.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2154, Training Loss: 2.170e+00, Validation Loss: 2.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2155, Training Loss: 2.170e+00, Validation Loss: 2.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2156, Training Loss: 2.170e+00, Validation Loss: 2.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2157, Training Loss: 2.170e+00, Validation Loss: 2.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2158, Training Loss: 2.170e+00, Validation Loss: 2.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2159, Training Loss: 2.169e+00, Validation Loss: 2.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2160, Training Loss: 2.169e+00, Validation Loss: 2.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2161, Training Loss: 2.169e+00, Validation Loss: 2.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2162, Training Loss: 2.169e+00, Validation Loss: 2.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2163, Training Loss: 2.169e+00, Validation Loss: 2.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2164, Training Loss: 2.168e+00, Validation Loss: 2.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2165, Training Loss: 2.168e+00, Validation Loss: 2.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2166, Training Loss: 2.168e+00, Validation Loss: 2.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2167, Training Loss: 2.168e+00, Validation Loss: 2.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2168, Training Loss: 2.168e+00, Validation Loss: 2.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2169, Training Loss: 2.167e+00, Validation Loss: 2.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2170, Training Loss: 2.167e+00, Validation Loss: 2.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2171, Training Loss: 2.167e+00, Validation Loss: 2.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2172, Training Loss: 2.167e+00, Validation Loss: 2.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2173, Training Loss: 2.167e+00, Validation Loss: 2.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2174, Training Loss: 2.166e+00, Validation Loss: 2.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2175, Training Loss: 2.166e+00, Validation Loss: 2.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2176, Training Loss: 2.166e+00, Validation Loss: 2.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2177, Training Loss: 2.166e+00, Validation Loss: 2.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2178, Training Loss: 2.166e+00, Validation Loss: 2.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2179, Training Loss: 2.165e+00, Validation Loss: 2.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2180, Training Loss: 2.165e+00, Validation Loss: 2.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2181, Training Loss: 2.165e+00, Validation Loss: 2.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2182, Training Loss: 2.165e+00, Validation Loss: 2.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2183, Training Loss: 2.165e+00, Validation Loss: 2.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2184, Training Loss: 2.164e+00, Validation Loss: 2.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2185, Training Loss: 2.164e+00, Validation Loss: 2.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2186, Training Loss: 2.164e+00, Validation Loss: 2.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2187, Training Loss: 2.164e+00, Validation Loss: 2.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2188, Training Loss: 2.164e+00, Validation Loss: 2.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2189, Training Loss: 2.163e+00, Validation Loss: 2.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2190, Training Loss: 2.163e+00, Validation Loss: 2.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2191, Training Loss: 2.163e+00, Validation Loss: 2.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2192, Training Loss: 2.163e+00, Validation Loss: 2.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2193, Training Loss: 2.163e+00, Validation Loss: 2.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2194, Training Loss: 2.162e+00, Validation Loss: 2.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2195, Training Loss: 2.162e+00, Validation Loss: 2.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2196, Training Loss: 2.162e+00, Validation Loss: 2.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2197, Training Loss: 2.162e+00, Validation Loss: 2.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2198, Training Loss: 2.162e+00, Validation Loss: 2.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2199, Training Loss: 2.161e+00, Validation Loss: 2.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2200, Training Loss: 2.161e+00, Validation Loss: 2.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2201, Training Loss: 2.161e+00, Validation Loss: 2.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2202, Training Loss: 2.161e+00, Validation Loss: 2.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2203, Training Loss: 2.160e+00, Validation Loss: 2.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2204, Training Loss: 2.160e+00, Validation Loss: 2.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2205, Training Loss: 2.160e+00, Validation Loss: 2.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2206, Training Loss: 2.160e+00, Validation Loss: 2.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2207, Training Loss: 2.160e+00, Validation Loss: 2.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2208, Training Loss: 2.159e+00, Validation Loss: 2.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2209, Training Loss: 2.159e+00, Validation Loss: 2.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2210, Training Loss: 2.159e+00, Validation Loss: 2.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2211, Training Loss: 2.159e+00, Validation Loss: 2.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2212, Training Loss: 2.159e+00, Validation Loss: 2.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2213, Training Loss: 2.158e+00, Validation Loss: 2.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2214, Training Loss: 2.158e+00, Validation Loss: 2.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2215, Training Loss: 2.158e+00, Validation Loss: 2.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2216, Training Loss: 2.158e+00, Validation Loss: 2.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2217, Training Loss: 2.158e+00, Validation Loss: 2.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2218, Training Loss: 2.157e+00, Validation Loss: 2.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2219, Training Loss: 2.157e+00, Validation Loss: 2.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2220, Training Loss: 2.157e+00, Validation Loss: 2.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2221, Training Loss: 2.157e+00, Validation Loss: 2.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2222, Training Loss: 2.157e+00, Validation Loss: 2.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2223, Training Loss: 2.156e+00, Validation Loss: 2.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2224, Training Loss: 2.156e+00, Validation Loss: 2.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2225, Training Loss: 2.156e+00, Validation Loss: 2.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2226, Training Loss: 2.156e+00, Validation Loss: 2.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2227, Training Loss: 2.156e+00, Validation Loss: 2.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2228, Training Loss: 2.155e+00, Validation Loss: 2.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2229, Training Loss: 2.155e+00, Validation Loss: 2.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2230, Training Loss: 2.155e+00, Validation Loss: 2.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2231, Training Loss: 2.155e+00, Validation Loss: 2.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2232, Training Loss: 2.155e+00, Validation Loss: 2.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2233, Training Loss: 2.154e+00, Validation Loss: 2.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2234, Training Loss: 2.154e+00, Validation Loss: 2.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2235, Training Loss: 2.154e+00, Validation Loss: 2.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2236, Training Loss: 2.154e+00, Validation Loss: 2.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2237, Training Loss: 2.154e+00, Validation Loss: 2.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2238, Training Loss: 2.153e+00, Validation Loss: 2.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2239, Training Loss: 2.153e+00, Validation Loss: 2.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2240, Training Loss: 2.153e+00, Validation Loss: 2.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2241, Training Loss: 2.153e+00, Validation Loss: 2.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2242, Training Loss: 2.153e+00, Validation Loss: 2.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2243, Training Loss: 2.152e+00, Validation Loss: 2.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2244, Training Loss: 2.152e+00, Validation Loss: 2.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2245, Training Loss: 2.152e+00, Validation Loss: 2.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2246, Training Loss: 2.152e+00, Validation Loss: 2.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2247, Training Loss: 2.152e+00, Validation Loss: 2.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2248, Training Loss: 2.151e+00, Validation Loss: 2.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2249, Training Loss: 2.151e+00, Validation Loss: 2.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2250, Training Loss: 2.151e+00, Validation Loss: 2.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2251, Training Loss: 2.151e+00, Validation Loss: 2.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2252, Training Loss: 2.151e+00, Validation Loss: 2.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2253, Training Loss: 2.150e+00, Validation Loss: 2.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2254, Training Loss: 2.150e+00, Validation Loss: 2.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2255, Training Loss: 2.150e+00, Validation Loss: 2.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2256, Training Loss: 2.150e+00, Validation Loss: 2.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2257, Training Loss: 2.150e+00, Validation Loss: 2.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2258, Training Loss: 2.149e+00, Validation Loss: 2.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2259, Training Loss: 2.149e+00, Validation Loss: 2.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2260, Training Loss: 2.149e+00, Validation Loss: 2.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2261, Training Loss: 2.149e+00, Validation Loss: 2.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2262, Training Loss: 2.149e+00, Validation Loss: 2.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2263, Training Loss: 2.148e+00, Validation Loss: 2.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2264, Training Loss: 2.148e+00, Validation Loss: 2.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2265, Training Loss: 2.148e+00, Validation Loss: 2.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2266, Training Loss: 2.148e+00, Validation Loss: 2.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2267, Training Loss: 2.147e+00, Validation Loss: 2.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2268, Training Loss: 2.147e+00, Validation Loss: 2.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2269, Training Loss: 2.147e+00, Validation Loss: 2.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2270, Training Loss: 2.147e+00, Validation Loss: 2.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2271, Training Loss: 2.147e+00, Validation Loss: 2.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2272, Training Loss: 2.146e+00, Validation Loss: 2.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2273, Training Loss: 2.146e+00, Validation Loss: 2.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2274, Training Loss: 2.146e+00, Validation Loss: 2.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2275, Training Loss: 2.146e+00, Validation Loss: 2.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2276, Training Loss: 2.146e+00, Validation Loss: 2.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2277, Training Loss: 2.145e+00, Validation Loss: 2.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2278, Training Loss: 2.145e+00, Validation Loss: 2.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2279, Training Loss: 2.145e+00, Validation Loss: 2.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2280, Training Loss: 2.145e+00, Validation Loss: 2.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2281, Training Loss: 2.145e+00, Validation Loss: 2.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2282, Training Loss: 2.144e+00, Validation Loss: 2.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2283, Training Loss: 2.144e+00, Validation Loss: 2.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2284, Training Loss: 2.144e+00, Validation Loss: 2.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2285, Training Loss: 2.144e+00, Validation Loss: 2.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2286, Training Loss: 2.144e+00, Validation Loss: 2.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2287, Training Loss: 2.143e+00, Validation Loss: 2.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2288, Training Loss: 2.143e+00, Validation Loss: 2.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2289, Training Loss: 2.143e+00, Validation Loss: 2.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2290, Training Loss: 2.143e+00, Validation Loss: 2.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2291, Training Loss: 2.143e+00, Validation Loss: 2.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2292, Training Loss: 2.142e+00, Validation Loss: 2.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2293, Training Loss: 2.142e+00, Validation Loss: 2.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2294, Training Loss: 2.142e+00, Validation Loss: 2.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2295, Training Loss: 2.142e+00, Validation Loss: 2.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2296, Training Loss: 2.142e+00, Validation Loss: 2.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2297, Training Loss: 2.141e+00, Validation Loss: 2.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2298, Training Loss: 2.141e+00, Validation Loss: 2.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2299, Training Loss: 2.141e+00, Validation Loss: 2.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2300, Training Loss: 2.141e+00, Validation Loss: 2.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2301, Training Loss: 2.141e+00, Validation Loss: 2.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2302, Training Loss: 2.140e+00, Validation Loss: 2.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2303, Training Loss: 2.140e+00, Validation Loss: 2.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2304, Training Loss: 2.140e+00, Validation Loss: 2.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2305, Training Loss: 2.140e+00, Validation Loss: 2.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2306, Training Loss: 2.140e+00, Validation Loss: 2.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2307, Training Loss: 2.139e+00, Validation Loss: 2.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2308, Training Loss: 2.139e+00, Validation Loss: 2.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2309, Training Loss: 2.139e+00, Validation Loss: 2.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2310, Training Loss: 2.139e+00, Validation Loss: 2.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2311, Training Loss: 2.139e+00, Validation Loss: 2.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2312, Training Loss: 2.138e+00, Validation Loss: 2.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2313, Training Loss: 2.138e+00, Validation Loss: 2.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2314, Training Loss: 2.138e+00, Validation Loss: 2.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2315, Training Loss: 2.138e+00, Validation Loss: 2.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2316, Training Loss: 2.138e+00, Validation Loss: 2.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2317, Training Loss: 2.137e+00, Validation Loss: 2.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2318, Training Loss: 2.137e+00, Validation Loss: 2.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2319, Training Loss: 2.137e+00, Validation Loss: 2.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2320, Training Loss: 2.137e+00, Validation Loss: 2.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2321, Training Loss: 2.137e+00, Validation Loss: 2.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2322, Training Loss: 2.136e+00, Validation Loss: 2.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2323, Training Loss: 2.136e+00, Validation Loss: 2.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2324, Training Loss: 2.136e+00, Validation Loss: 2.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2325, Training Loss: 2.136e+00, Validation Loss: 2.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2326, Training Loss: 2.136e+00, Validation Loss: 2.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2327, Training Loss: 2.135e+00, Validation Loss: 2.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2328, Training Loss: 2.135e+00, Validation Loss: 2.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2329, Training Loss: 2.135e+00, Validation Loss: 2.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2330, Training Loss: 2.135e+00, Validation Loss: 2.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2331, Training Loss: 2.135e+00, Validation Loss: 2.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2332, Training Loss: 2.134e+00, Validation Loss: 2.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2333, Training Loss: 2.134e+00, Validation Loss: 2.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2334, Training Loss: 2.134e+00, Validation Loss: 2.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2335, Training Loss: 2.134e+00, Validation Loss: 2.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2336, Training Loss: 2.134e+00, Validation Loss: 2.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2337, Training Loss: 2.133e+00, Validation Loss: 2.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2338, Training Loss: 2.133e+00, Validation Loss: 2.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2339, Training Loss: 2.133e+00, Validation Loss: 2.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2340, Training Loss: 2.133e+00, Validation Loss: 2.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2341, Training Loss: 2.133e+00, Validation Loss: 2.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2342, Training Loss: 2.132e+00, Validation Loss: 2.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2343, Training Loss: 2.132e+00, Validation Loss: 2.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2344, Training Loss: 2.132e+00, Validation Loss: 2.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2345, Training Loss: 2.132e+00, Validation Loss: 2.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2346, Training Loss: 2.132e+00, Validation Loss: 2.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2347, Training Loss: 2.131e+00, Validation Loss: 2.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2348, Training Loss: 2.131e+00, Validation Loss: 2.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2349, Training Loss: 2.131e+00, Validation Loss: 2.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2350, Training Loss: 2.131e+00, Validation Loss: 2.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2351, Training Loss: 2.131e+00, Validation Loss: 2.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2352, Training Loss: 2.130e+00, Validation Loss: 2.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2353, Training Loss: 2.130e+00, Validation Loss: 2.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2354, Training Loss: 2.130e+00, Validation Loss: 2.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2355, Training Loss: 2.130e+00, Validation Loss: 2.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2356, Training Loss: 2.130e+00, Validation Loss: 2.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2357, Training Loss: 2.129e+00, Validation Loss: 2.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2358, Training Loss: 2.129e+00, Validation Loss: 2.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2359, Training Loss: 2.129e+00, Validation Loss: 2.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2360, Training Loss: 2.129e+00, Validation Loss: 2.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2361, Training Loss: 2.129e+00, Validation Loss: 2.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2362, Training Loss: 2.128e+00, Validation Loss: 2.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2363, Training Loss: 2.128e+00, Validation Loss: 2.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2364, Training Loss: 2.128e+00, Validation Loss: 2.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2365, Training Loss: 2.128e+00, Validation Loss: 2.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2366, Training Loss: 2.128e+00, Validation Loss: 2.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2367, Training Loss: 2.127e+00, Validation Loss: 2.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2368, Training Loss: 2.127e+00, Validation Loss: 2.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2369, Training Loss: 2.127e+00, Validation Loss: 2.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2370, Training Loss: 2.127e+00, Validation Loss: 2.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2371, Training Loss: 2.126e+00, Validation Loss: 2.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2372, Training Loss: 2.126e+00, Validation Loss: 2.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2373, Training Loss: 2.126e+00, Validation Loss: 2.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2374, Training Loss: 2.126e+00, Validation Loss: 2.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2375, Training Loss: 2.126e+00, Validation Loss: 2.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2376, Training Loss: 2.125e+00, Validation Loss: 2.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2377, Training Loss: 2.125e+00, Validation Loss: 2.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2378, Training Loss: 2.125e+00, Validation Loss: 2.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2379, Training Loss: 2.125e+00, Validation Loss: 2.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2380, Training Loss: 2.125e+00, Validation Loss: 2.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2381, Training Loss: 2.124e+00, Validation Loss: 2.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2382, Training Loss: 2.124e+00, Validation Loss: 2.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2383, Training Loss: 2.124e+00, Validation Loss: 2.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2384, Training Loss: 2.124e+00, Validation Loss: 2.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2385, Training Loss: 2.124e+00, Validation Loss: 2.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2386, Training Loss: 2.123e+00, Validation Loss: 2.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2387, Training Loss: 2.123e+00, Validation Loss: 2.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2388, Training Loss: 2.123e+00, Validation Loss: 2.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2389, Training Loss: 2.123e+00, Validation Loss: 2.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2390, Training Loss: 2.123e+00, Validation Loss: 2.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2391, Training Loss: 2.122e+00, Validation Loss: 2.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2392, Training Loss: 2.122e+00, Validation Loss: 2.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2393, Training Loss: 2.122e+00, Validation Loss: 2.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2394, Training Loss: 2.122e+00, Validation Loss: 2.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2395, Training Loss: 2.122e+00, Validation Loss: 2.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2396, Training Loss: 2.121e+00, Validation Loss: 2.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2397, Training Loss: 2.121e+00, Validation Loss: 2.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2398, Training Loss: 2.121e+00, Validation Loss: 2.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2399, Training Loss: 2.121e+00, Validation Loss: 2.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2400, Training Loss: 2.121e+00, Validation Loss: 2.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2401, Training Loss: 2.120e+00, Validation Loss: 2.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2402, Training Loss: 2.120e+00, Validation Loss: 2.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2403, Training Loss: 2.120e+00, Validation Loss: 2.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2404, Training Loss: 2.120e+00, Validation Loss: 2.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2405, Training Loss: 2.120e+00, Validation Loss: 2.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2406, Training Loss: 2.119e+00, Validation Loss: 2.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2407, Training Loss: 2.119e+00, Validation Loss: 2.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2408, Training Loss: 2.119e+00, Validation Loss: 2.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2409, Training Loss: 2.119e+00, Validation Loss: 2.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2410, Training Loss: 2.119e+00, Validation Loss: 2.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2411, Training Loss: 2.118e+00, Validation Loss: 2.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2412, Training Loss: 2.118e+00, Validation Loss: 2.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2413, Training Loss: 2.118e+00, Validation Loss: 2.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2414, Training Loss: 2.118e+00, Validation Loss: 2.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2415, Training Loss: 2.118e+00, Validation Loss: 2.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2416, Training Loss: 2.117e+00, Validation Loss: 2.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2417, Training Loss: 2.117e+00, Validation Loss: 2.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2418, Training Loss: 2.117e+00, Validation Loss: 2.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2419, Training Loss: 2.117e+00, Validation Loss: 2.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2420, Training Loss: 2.117e+00, Validation Loss: 2.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2421, Training Loss: 2.116e+00, Validation Loss: 2.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2422, Training Loss: 2.116e+00, Validation Loss: 2.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2423, Training Loss: 2.116e+00, Validation Loss: 2.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2424, Training Loss: 2.116e+00, Validation Loss: 2.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2425, Training Loss: 2.116e+00, Validation Loss: 2.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2426, Training Loss: 2.115e+00, Validation Loss: 2.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2427, Training Loss: 2.115e+00, Validation Loss: 2.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2428, Training Loss: 2.115e+00, Validation Loss: 2.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2429, Training Loss: 2.115e+00, Validation Loss: 2.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2430, Training Loss: 2.115e+00, Validation Loss: 2.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2431, Training Loss: 2.114e+00, Validation Loss: 2.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2432, Training Loss: 2.114e+00, Validation Loss: 2.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2433, Training Loss: 2.114e+00, Validation Loss: 2.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2434, Training Loss: 2.114e+00, Validation Loss: 2.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2435, Training Loss: 2.114e+00, Validation Loss: 2.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2436, Training Loss: 2.113e+00, Validation Loss: 2.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2437, Training Loss: 2.113e+00, Validation Loss: 2.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2438, Training Loss: 2.113e+00, Validation Loss: 2.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2439, Training Loss: 2.113e+00, Validation Loss: 2.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2440, Training Loss: 2.113e+00, Validation Loss: 2.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2441, Training Loss: 2.112e+00, Validation Loss: 2.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2442, Training Loss: 2.112e+00, Validation Loss: 2.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2443, Training Loss: 2.112e+00, Validation Loss: 2.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2444, Training Loss: 2.112e+00, Validation Loss: 2.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2445, Training Loss: 2.112e+00, Validation Loss: 2.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2446, Training Loss: 2.111e+00, Validation Loss: 2.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2447, Training Loss: 2.111e+00, Validation Loss: 2.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2448, Training Loss: 2.111e+00, Validation Loss: 2.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2449, Training Loss: 2.111e+00, Validation Loss: 2.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2450, Training Loss: 2.111e+00, Validation Loss: 2.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2451, Training Loss: 2.110e+00, Validation Loss: 2.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2452, Training Loss: 2.110e+00, Validation Loss: 2.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2453, Training Loss: 2.110e+00, Validation Loss: 2.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2454, Training Loss: 2.110e+00, Validation Loss: 2.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2455, Training Loss: 2.110e+00, Validation Loss: 2.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2456, Training Loss: 2.109e+00, Validation Loss: 2.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2457, Training Loss: 2.109e+00, Validation Loss: 2.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2458, Training Loss: 2.109e+00, Validation Loss: 2.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2459, Training Loss: 2.109e+00, Validation Loss: 2.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2460, Training Loss: 2.109e+00, Validation Loss: 2.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2461, Training Loss: 2.108e+00, Validation Loss: 2.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2462, Training Loss: 2.108e+00, Validation Loss: 2.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2463, Training Loss: 2.108e+00, Validation Loss: 2.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2464, Training Loss: 2.108e+00, Validation Loss: 2.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2465, Training Loss: 2.108e+00, Validation Loss: 2.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2466, Training Loss: 2.107e+00, Validation Loss: 2.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2467, Training Loss: 2.107e+00, Validation Loss: 2.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2468, Training Loss: 2.107e+00, Validation Loss: 2.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2469, Training Loss: 2.107e+00, Validation Loss: 2.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2470, Training Loss: 2.107e+00, Validation Loss: 2.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2471, Training Loss: 2.106e+00, Validation Loss: 2.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2472, Training Loss: 2.106e+00, Validation Loss: 2.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2473, Training Loss: 2.106e+00, Validation Loss: 2.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2474, Training Loss: 2.106e+00, Validation Loss: 2.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2475, Training Loss: 2.106e+00, Validation Loss: 2.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2476, Training Loss: 2.105e+00, Validation Loss: 2.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2477, Training Loss: 2.105e+00, Validation Loss: 2.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2478, Training Loss: 2.105e+00, Validation Loss: 2.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2479, Training Loss: 2.105e+00, Validation Loss: 2.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2480, Training Loss: 2.105e+00, Validation Loss: 2.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2481, Training Loss: 2.104e+00, Validation Loss: 2.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2482, Training Loss: 2.104e+00, Validation Loss: 2.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2483, Training Loss: 2.104e+00, Validation Loss: 2.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2484, Training Loss: 2.104e+00, Validation Loss: 2.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2485, Training Loss: 2.104e+00, Validation Loss: 2.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2486, Training Loss: 2.103e+00, Validation Loss: 2.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2487, Training Loss: 2.103e+00, Validation Loss: 2.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2488, Training Loss: 2.103e+00, Validation Loss: 2.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2489, Training Loss: 2.103e+00, Validation Loss: 2.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2490, Training Loss: 2.103e+00, Validation Loss: 2.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2491, Training Loss: 2.102e+00, Validation Loss: 2.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2492, Training Loss: 2.102e+00, Validation Loss: 2.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2493, Training Loss: 2.102e+00, Validation Loss: 2.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2494, Training Loss: 2.102e+00, Validation Loss: 2.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2495, Training Loss: 2.102e+00, Validation Loss: 2.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2496, Training Loss: 2.101e+00, Validation Loss: 2.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2497, Training Loss: 2.101e+00, Validation Loss: 2.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2498, Training Loss: 2.101e+00, Validation Loss: 2.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2499, Training Loss: 2.101e+00, Validation Loss: 2.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2500, Training Loss: 2.101e+00, Validation Loss: 2.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2501, Training Loss: 2.100e+00, Validation Loss: 2.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2502, Training Loss: 2.100e+00, Validation Loss: 2.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2503, Training Loss: 2.100e+00, Validation Loss: 2.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2504, Training Loss: 2.100e+00, Validation Loss: 2.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2505, Training Loss: 2.100e+00, Validation Loss: 2.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2506, Training Loss: 2.099e+00, Validation Loss: 2.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2507, Training Loss: 2.099e+00, Validation Loss: 2.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2508, Training Loss: 2.099e+00, Validation Loss: 2.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2509, Training Loss: 2.099e+00, Validation Loss: 2.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2510, Training Loss: 2.099e+00, Validation Loss: 2.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2511, Training Loss: 2.098e+00, Validation Loss: 2.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2512, Training Loss: 2.098e+00, Validation Loss: 2.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2513, Training Loss: 2.098e+00, Validation Loss: 2.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2514, Training Loss: 2.098e+00, Validation Loss: 2.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2515, Training Loss: 2.098e+00, Validation Loss: 2.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2516, Training Loss: 2.097e+00, Validation Loss: 2.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2517, Training Loss: 2.097e+00, Validation Loss: 2.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2518, Training Loss: 2.097e+00, Validation Loss: 2.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2519, Training Loss: 2.097e+00, Validation Loss: 2.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2520, Training Loss: 2.097e+00, Validation Loss: 2.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2521, Training Loss: 2.096e+00, Validation Loss: 2.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2522, Training Loss: 2.096e+00, Validation Loss: 2.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2523, Training Loss: 2.096e+00, Validation Loss: 2.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2524, Training Loss: 2.096e+00, Validation Loss: 2.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2525, Training Loss: 2.096e+00, Validation Loss: 2.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2526, Training Loss: 2.095e+00, Validation Loss: 2.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2527, Training Loss: 2.095e+00, Validation Loss: 2.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2528, Training Loss: 2.095e+00, Validation Loss: 2.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2529, Training Loss: 2.095e+00, Validation Loss: 2.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2530, Training Loss: 2.095e+00, Validation Loss: 2.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2531, Training Loss: 2.094e+00, Validation Loss: 2.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2532, Training Loss: 2.094e+00, Validation Loss: 2.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2533, Training Loss: 2.094e+00, Validation Loss: 2.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2534, Training Loss: 2.094e+00, Validation Loss: 2.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2535, Training Loss: 2.094e+00, Validation Loss: 2.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2536, Training Loss: 2.093e+00, Validation Loss: 2.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2537, Training Loss: 2.093e+00, Validation Loss: 2.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2538, Training Loss: 2.093e+00, Validation Loss: 2.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2539, Training Loss: 2.093e+00, Validation Loss: 2.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2540, Training Loss: 2.093e+00, Validation Loss: 2.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2541, Training Loss: 2.092e+00, Validation Loss: 2.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2542, Training Loss: 2.092e+00, Validation Loss: 2.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2543, Training Loss: 2.092e+00, Validation Loss: 2.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2544, Training Loss: 2.092e+00, Validation Loss: 2.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2545, Training Loss: 2.092e+00, Validation Loss: 2.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2546, Training Loss: 2.091e+00, Validation Loss: 2.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2547, Training Loss: 2.091e+00, Validation Loss: 2.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2548, Training Loss: 2.091e+00, Validation Loss: 2.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2549, Training Loss: 2.091e+00, Validation Loss: 2.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2550, Training Loss: 2.091e+00, Validation Loss: 2.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2551, Training Loss: 2.090e+00, Validation Loss: 2.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2552, Training Loss: 2.090e+00, Validation Loss: 2.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2553, Training Loss: 2.090e+00, Validation Loss: 2.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2554, Training Loss: 2.090e+00, Validation Loss: 2.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2555, Training Loss: 2.090e+00, Validation Loss: 2.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2556, Training Loss: 2.089e+00, Validation Loss: 2.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2557, Training Loss: 2.089e+00, Validation Loss: 2.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2558, Training Loss: 2.089e+00, Validation Loss: 2.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2559, Training Loss: 2.089e+00, Validation Loss: 2.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2560, Training Loss: 2.089e+00, Validation Loss: 2.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2561, Training Loss: 2.088e+00, Validation Loss: 2.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2562, Training Loss: 2.088e+00, Validation Loss: 2.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2563, Training Loss: 2.088e+00, Validation Loss: 2.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2564, Training Loss: 2.088e+00, Validation Loss: 2.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2565, Training Loss: 2.088e+00, Validation Loss: 2.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2566, Training Loss: 2.087e+00, Validation Loss: 2.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2567, Training Loss: 2.087e+00, Validation Loss: 2.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2568, Training Loss: 2.087e+00, Validation Loss: 2.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2569, Training Loss: 2.087e+00, Validation Loss: 2.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2570, Training Loss: 2.087e+00, Validation Loss: 2.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2571, Training Loss: 2.086e+00, Validation Loss: 2.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2572, Training Loss: 2.086e+00, Validation Loss: 2.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2573, Training Loss: 2.086e+00, Validation Loss: 2.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2574, Training Loss: 2.086e+00, Validation Loss: 2.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2575, Training Loss: 2.086e+00, Validation Loss: 2.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2576, Training Loss: 2.085e+00, Validation Loss: 2.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2577, Training Loss: 2.085e+00, Validation Loss: 2.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2578, Training Loss: 2.085e+00, Validation Loss: 2.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2579, Training Loss: 2.085e+00, Validation Loss: 2.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2580, Training Loss: 2.085e+00, Validation Loss: 2.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2581, Training Loss: 2.084e+00, Validation Loss: 2.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2582, Training Loss: 2.084e+00, Validation Loss: 2.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2583, Training Loss: 2.084e+00, Validation Loss: 2.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2584, Training Loss: 2.084e+00, Validation Loss: 2.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2585, Training Loss: 2.084e+00, Validation Loss: 2.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2586, Training Loss: 2.083e+00, Validation Loss: 2.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2587, Training Loss: 2.083e+00, Validation Loss: 2.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2588, Training Loss: 2.083e+00, Validation Loss: 2.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2589, Training Loss: 2.083e+00, Validation Loss: 2.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2590, Training Loss: 2.083e+00, Validation Loss: 2.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2591, Training Loss: 2.082e+00, Validation Loss: 2.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2592, Training Loss: 2.082e+00, Validation Loss: 2.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2593, Training Loss: 2.082e+00, Validation Loss: 2.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2594, Training Loss: 2.082e+00, Validation Loss: 2.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2595, Training Loss: 2.082e+00, Validation Loss: 2.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2596, Training Loss: 2.081e+00, Validation Loss: 2.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2597, Training Loss: 2.081e+00, Validation Loss: 2.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2598, Training Loss: 2.081e+00, Validation Loss: 2.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2599, Training Loss: 2.081e+00, Validation Loss: 2.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2600, Training Loss: 2.081e+00, Validation Loss: 2.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2601, Training Loss: 2.080e+00, Validation Loss: 2.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2602, Training Loss: 2.080e+00, Validation Loss: 2.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2603, Training Loss: 2.080e+00, Validation Loss: 2.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2604, Training Loss: 2.080e+00, Validation Loss: 2.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2605, Training Loss: 2.080e+00, Validation Loss: 2.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2606, Training Loss: 2.079e+00, Validation Loss: 2.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2607, Training Loss: 2.079e+00, Validation Loss: 2.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2608, Training Loss: 2.079e+00, Validation Loss: 2.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2609, Training Loss: 2.079e+00, Validation Loss: 2.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2610, Training Loss: 2.079e+00, Validation Loss: 2.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2611, Training Loss: 2.079e+00, Validation Loss: 2.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2612, Training Loss: 2.078e+00, Validation Loss: 2.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2613, Training Loss: 2.078e+00, Validation Loss: 2.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2614, Training Loss: 2.078e+00, Validation Loss: 2.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2615, Training Loss: 2.078e+00, Validation Loss: 2.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2616, Training Loss: 2.078e+00, Validation Loss: 2.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2617, Training Loss: 2.077e+00, Validation Loss: 2.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2618, Training Loss: 2.077e+00, Validation Loss: 2.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2619, Training Loss: 2.077e+00, Validation Loss: 2.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2620, Training Loss: 2.077e+00, Validation Loss: 2.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2621, Training Loss: 2.077e+00, Validation Loss: 2.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2622, Training Loss: 2.076e+00, Validation Loss: 2.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2623, Training Loss: 2.076e+00, Validation Loss: 2.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2624, Training Loss: 2.076e+00, Validation Loss: 2.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2625, Training Loss: 2.076e+00, Validation Loss: 2.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2626, Training Loss: 2.076e+00, Validation Loss: 2.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2627, Training Loss: 2.075e+00, Validation Loss: 2.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2628, Training Loss: 2.075e+00, Validation Loss: 2.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2629, Training Loss: 2.075e+00, Validation Loss: 2.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2630, Training Loss: 2.075e+00, Validation Loss: 2.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2631, Training Loss: 2.075e+00, Validation Loss: 2.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2632, Training Loss: 2.074e+00, Validation Loss: 2.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2633, Training Loss: 2.074e+00, Validation Loss: 2.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2634, Training Loss: 2.074e+00, Validation Loss: 2.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2635, Training Loss: 2.074e+00, Validation Loss: 2.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2636, Training Loss: 2.074e+00, Validation Loss: 2.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2637, Training Loss: 2.073e+00, Validation Loss: 2.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2638, Training Loss: 2.073e+00, Validation Loss: 2.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2639, Training Loss: 2.073e+00, Validation Loss: 2.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2640, Training Loss: 2.073e+00, Validation Loss: 2.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2641, Training Loss: 2.073e+00, Validation Loss: 2.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2642, Training Loss: 2.072e+00, Validation Loss: 2.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2643, Training Loss: 2.072e+00, Validation Loss: 2.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2644, Training Loss: 2.072e+00, Validation Loss: 2.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2645, Training Loss: 2.072e+00, Validation Loss: 2.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2646, Training Loss: 2.072e+00, Validation Loss: 2.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2647, Training Loss: 2.071e+00, Validation Loss: 2.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2648, Training Loss: 2.071e+00, Validation Loss: 2.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2649, Training Loss: 2.071e+00, Validation Loss: 2.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2650, Training Loss: 2.071e+00, Validation Loss: 2.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2651, Training Loss: 2.071e+00, Validation Loss: 2.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2652, Training Loss: 2.070e+00, Validation Loss: 2.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2653, Training Loss: 2.070e+00, Validation Loss: 2.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2654, Training Loss: 2.070e+00, Validation Loss: 2.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2655, Training Loss: 2.070e+00, Validation Loss: 2.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2656, Training Loss: 2.070e+00, Validation Loss: 2.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2657, Training Loss: 2.069e+00, Validation Loss: 2.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2658, Training Loss: 2.069e+00, Validation Loss: 2.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2659, Training Loss: 2.069e+00, Validation Loss: 2.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2660, Training Loss: 2.069e+00, Validation Loss: 2.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2661, Training Loss: 2.069e+00, Validation Loss: 2.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2662, Training Loss: 2.068e+00, Validation Loss: 2.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2663, Training Loss: 2.068e+00, Validation Loss: 2.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2664, Training Loss: 2.068e+00, Validation Loss: 2.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2665, Training Loss: 2.068e+00, Validation Loss: 2.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2666, Training Loss: 2.068e+00, Validation Loss: 2.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2667, Training Loss: 2.067e+00, Validation Loss: 2.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2668, Training Loss: 2.067e+00, Validation Loss: 2.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2669, Training Loss: 2.067e+00, Validation Loss: 2.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2670, Training Loss: 2.067e+00, Validation Loss: 2.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2671, Training Loss: 2.067e+00, Validation Loss: 2.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2672, Training Loss: 2.066e+00, Validation Loss: 2.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2673, Training Loss: 2.066e+00, Validation Loss: 2.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2674, Training Loss: 2.066e+00, Validation Loss: 2.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2675, Training Loss: 2.066e+00, Validation Loss: 2.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2676, Training Loss: 2.066e+00, Validation Loss: 2.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2677, Training Loss: 2.065e+00, Validation Loss: 2.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2678, Training Loss: 2.065e+00, Validation Loss: 2.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2679, Training Loss: 2.065e+00, Validation Loss: 2.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2680, Training Loss: 2.065e+00, Validation Loss: 2.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2681, Training Loss: 2.065e+00, Validation Loss: 2.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2682, Training Loss: 2.064e+00, Validation Loss: 2.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2683, Training Loss: 2.064e+00, Validation Loss: 2.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2684, Training Loss: 2.064e+00, Validation Loss: 2.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2685, Training Loss: 2.064e+00, Validation Loss: 2.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2686, Training Loss: 2.064e+00, Validation Loss: 2.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2687, Training Loss: 2.063e+00, Validation Loss: 2.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2688, Training Loss: 2.063e+00, Validation Loss: 2.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2689, Training Loss: 2.063e+00, Validation Loss: 2.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2690, Training Loss: 2.063e+00, Validation Loss: 2.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2691, Training Loss: 2.063e+00, Validation Loss: 2.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2692, Training Loss: 2.062e+00, Validation Loss: 2.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2693, Training Loss: 2.062e+00, Validation Loss: 2.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2694, Training Loss: 2.062e+00, Validation Loss: 2.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2695, Training Loss: 2.062e+00, Validation Loss: 2.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2696, Training Loss: 2.062e+00, Validation Loss: 2.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2697, Training Loss: 2.061e+00, Validation Loss: 2.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2698, Training Loss: 2.061e+00, Validation Loss: 2.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2699, Training Loss: 2.061e+00, Validation Loss: 2.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2700, Training Loss: 2.061e+00, Validation Loss: 2.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2701, Training Loss: 2.061e+00, Validation Loss: 2.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2702, Training Loss: 2.060e+00, Validation Loss: 2.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2703, Training Loss: 2.060e+00, Validation Loss: 2.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2704, Training Loss: 2.060e+00, Validation Loss: 2.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2705, Training Loss: 2.060e+00, Validation Loss: 2.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2706, Training Loss: 2.060e+00, Validation Loss: 2.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2707, Training Loss: 2.059e+00, Validation Loss: 2.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2708, Training Loss: 2.059e+00, Validation Loss: 2.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2709, Training Loss: 2.059e+00, Validation Loss: 2.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2710, Training Loss: 2.059e+00, Validation Loss: 2.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2711, Training Loss: 2.059e+00, Validation Loss: 2.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2712, Training Loss: 2.058e+00, Validation Loss: 2.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2713, Training Loss: 2.058e+00, Validation Loss: 2.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2714, Training Loss: 2.058e+00, Validation Loss: 2.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2715, Training Loss: 2.058e+00, Validation Loss: 2.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2716, Training Loss: 2.058e+00, Validation Loss: 2.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2717, Training Loss: 2.058e+00, Validation Loss: 2.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2718, Training Loss: 2.057e+00, Validation Loss: 2.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2719, Training Loss: 2.057e+00, Validation Loss: 2.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2720, Training Loss: 2.057e+00, Validation Loss: 2.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2721, Training Loss: 2.057e+00, Validation Loss: 2.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2722, Training Loss: 2.057e+00, Validation Loss: 2.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2723, Training Loss: 2.056e+00, Validation Loss: 2.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2724, Training Loss: 2.056e+00, Validation Loss: 2.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2725, Training Loss: 2.056e+00, Validation Loss: 2.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2726, Training Loss: 2.056e+00, Validation Loss: 2.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2727, Training Loss: 2.056e+00, Validation Loss: 2.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2728, Training Loss: 2.055e+00, Validation Loss: 2.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2729, Training Loss: 2.055e+00, Validation Loss: 2.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2730, Training Loss: 2.055e+00, Validation Loss: 2.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2731, Training Loss: 2.055e+00, Validation Loss: 2.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2732, Training Loss: 2.055e+00, Validation Loss: 2.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2733, Training Loss: 2.054e+00, Validation Loss: 2.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2734, Training Loss: 2.054e+00, Validation Loss: 2.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2735, Training Loss: 2.054e+00, Validation Loss: 2.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2736, Training Loss: 2.054e+00, Validation Loss: 2.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2737, Training Loss: 2.054e+00, Validation Loss: 2.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2738, Training Loss: 2.053e+00, Validation Loss: 2.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2739, Training Loss: 2.053e+00, Validation Loss: 2.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2740, Training Loss: 2.053e+00, Validation Loss: 2.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2741, Training Loss: 2.053e+00, Validation Loss: 2.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2742, Training Loss: 2.053e+00, Validation Loss: 2.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2743, Training Loss: 2.052e+00, Validation Loss: 2.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2744, Training Loss: 2.052e+00, Validation Loss: 2.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2745, Training Loss: 2.052e+00, Validation Loss: 2.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2746, Training Loss: 2.052e+00, Validation Loss: 2.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2747, Training Loss: 2.052e+00, Validation Loss: 2.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2748, Training Loss: 2.051e+00, Validation Loss: 2.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2749, Training Loss: 2.051e+00, Validation Loss: 2.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2750, Training Loss: 2.051e+00, Validation Loss: 2.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2751, Training Loss: 2.051e+00, Validation Loss: 2.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2752, Training Loss: 2.051e+00, Validation Loss: 2.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2753, Training Loss: 2.050e+00, Validation Loss: 2.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2754, Training Loss: 2.050e+00, Validation Loss: 2.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2755, Training Loss: 2.050e+00, Validation Loss: 2.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2756, Training Loss: 2.050e+00, Validation Loss: 2.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2757, Training Loss: 2.050e+00, Validation Loss: 2.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2758, Training Loss: 2.049e+00, Validation Loss: 2.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2759, Training Loss: 2.049e+00, Validation Loss: 2.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2760, Training Loss: 2.049e+00, Validation Loss: 2.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2761, Training Loss: 2.049e+00, Validation Loss: 2.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2762, Training Loss: 2.049e+00, Validation Loss: 2.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2763, Training Loss: 2.048e+00, Validation Loss: 2.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2764, Training Loss: 2.048e+00, Validation Loss: 2.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2765, Training Loss: 2.048e+00, Validation Loss: 2.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2766, Training Loss: 2.048e+00, Validation Loss: 2.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2767, Training Loss: 2.048e+00, Validation Loss: 2.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2768, Training Loss: 2.047e+00, Validation Loss: 2.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2769, Training Loss: 2.047e+00, Validation Loss: 2.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2770, Training Loss: 2.047e+00, Validation Loss: 2.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2771, Training Loss: 2.047e+00, Validation Loss: 2.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2772, Training Loss: 2.047e+00, Validation Loss: 2.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2773, Training Loss: 2.046e+00, Validation Loss: 2.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2774, Training Loss: 2.046e+00, Validation Loss: 2.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2775, Training Loss: 2.046e+00, Validation Loss: 2.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2776, Training Loss: 2.046e+00, Validation Loss: 2.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2777, Training Loss: 2.046e+00, Validation Loss: 2.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2778, Training Loss: 2.045e+00, Validation Loss: 2.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2779, Training Loss: 2.045e+00, Validation Loss: 2.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2780, Training Loss: 2.045e+00, Validation Loss: 2.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2781, Training Loss: 2.045e+00, Validation Loss: 2.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2782, Training Loss: 2.045e+00, Validation Loss: 2.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2783, Training Loss: 2.045e+00, Validation Loss: 2.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2784, Training Loss: 2.044e+00, Validation Loss: 2.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2785, Training Loss: 2.044e+00, Validation Loss: 2.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2786, Training Loss: 2.044e+00, Validation Loss: 2.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2787, Training Loss: 2.044e+00, Validation Loss: 2.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2788, Training Loss: 2.044e+00, Validation Loss: 2.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2789, Training Loss: 2.043e+00, Validation Loss: 2.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2790, Training Loss: 2.043e+00, Validation Loss: 2.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2791, Training Loss: 2.043e+00, Validation Loss: 2.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2792, Training Loss: 2.043e+00, Validation Loss: 2.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2793, Training Loss: 2.043e+00, Validation Loss: 2.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2794, Training Loss: 2.042e+00, Validation Loss: 2.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2795, Training Loss: 2.042e+00, Validation Loss: 2.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2796, Training Loss: 2.042e+00, Validation Loss: 2.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2797, Training Loss: 2.042e+00, Validation Loss: 2.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2798, Training Loss: 2.042e+00, Validation Loss: 2.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2799, Training Loss: 2.041e+00, Validation Loss: 2.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2800, Training Loss: 2.041e+00, Validation Loss: 2.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2801, Training Loss: 2.041e+00, Validation Loss: 2.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2802, Training Loss: 2.041e+00, Validation Loss: 2.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2803, Training Loss: 2.041e+00, Validation Loss: 2.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2804, Training Loss: 2.040e+00, Validation Loss: 2.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2805, Training Loss: 2.040e+00, Validation Loss: 2.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2806, Training Loss: 2.040e+00, Validation Loss: 2.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2807, Training Loss: 2.040e+00, Validation Loss: 2.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2808, Training Loss: 2.040e+00, Validation Loss: 2.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2809, Training Loss: 2.039e+00, Validation Loss: 2.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2810, Training Loss: 2.039e+00, Validation Loss: 2.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2811, Training Loss: 2.039e+00, Validation Loss: 2.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2812, Training Loss: 2.039e+00, Validation Loss: 2.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2813, Training Loss: 2.039e+00, Validation Loss: 2.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2814, Training Loss: 2.038e+00, Validation Loss: 2.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2815, Training Loss: 2.038e+00, Validation Loss: 2.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2816, Training Loss: 2.038e+00, Validation Loss: 2.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2817, Training Loss: 2.038e+00, Validation Loss: 2.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2818, Training Loss: 2.038e+00, Validation Loss: 2.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2819, Training Loss: 2.037e+00, Validation Loss: 2.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2820, Training Loss: 2.037e+00, Validation Loss: 2.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2821, Training Loss: 2.037e+00, Validation Loss: 2.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2822, Training Loss: 2.037e+00, Validation Loss: 2.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2823, Training Loss: 2.037e+00, Validation Loss: 2.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2824, Training Loss: 2.036e+00, Validation Loss: 2.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2825, Training Loss: 2.036e+00, Validation Loss: 2.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2826, Training Loss: 2.036e+00, Validation Loss: 2.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2827, Training Loss: 2.036e+00, Validation Loss: 2.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2828, Training Loss: 2.036e+00, Validation Loss: 2.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2829, Training Loss: 2.035e+00, Validation Loss: 2.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2830, Training Loss: 2.035e+00, Validation Loss: 2.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2831, Training Loss: 2.035e+00, Validation Loss: 2.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2832, Training Loss: 2.035e+00, Validation Loss: 2.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2833, Training Loss: 2.035e+00, Validation Loss: 2.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2834, Training Loss: 2.034e+00, Validation Loss: 2.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2835, Training Loss: 2.034e+00, Validation Loss: 2.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2836, Training Loss: 2.034e+00, Validation Loss: 2.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2837, Training Loss: 2.034e+00, Validation Loss: 2.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2838, Training Loss: 2.034e+00, Validation Loss: 2.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2839, Training Loss: 2.034e+00, Validation Loss: 2.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2840, Training Loss: 2.033e+00, Validation Loss: 2.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2841, Training Loss: 2.033e+00, Validation Loss: 2.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2842, Training Loss: 2.033e+00, Validation Loss: 2.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2843, Training Loss: 2.033e+00, Validation Loss: 2.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2844, Training Loss: 2.033e+00, Validation Loss: 2.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2845, Training Loss: 2.032e+00, Validation Loss: 2.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2846, Training Loss: 2.032e+00, Validation Loss: 2.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2847, Training Loss: 2.032e+00, Validation Loss: 2.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2848, Training Loss: 2.032e+00, Validation Loss: 2.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2849, Training Loss: 2.032e+00, Validation Loss: 2.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2850, Training Loss: 2.031e+00, Validation Loss: 2.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2851, Training Loss: 2.031e+00, Validation Loss: 2.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2852, Training Loss: 2.031e+00, Validation Loss: 2.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2853, Training Loss: 2.031e+00, Validation Loss: 2.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2854, Training Loss: 2.031e+00, Validation Loss: 2.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2855, Training Loss: 2.030e+00, Validation Loss: 2.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2856, Training Loss: 2.030e+00, Validation Loss: 2.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2857, Training Loss: 2.030e+00, Validation Loss: 2.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2858, Training Loss: 2.030e+00, Validation Loss: 2.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2859, Training Loss: 2.030e+00, Validation Loss: 2.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2860, Training Loss: 2.029e+00, Validation Loss: 2.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2861, Training Loss: 2.029e+00, Validation Loss: 2.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2862, Training Loss: 2.029e+00, Validation Loss: 2.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2863, Training Loss: 2.029e+00, Validation Loss: 2.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2864, Training Loss: 2.029e+00, Validation Loss: 2.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2865, Training Loss: 2.028e+00, Validation Loss: 2.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2866, Training Loss: 2.028e+00, Validation Loss: 2.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2867, Training Loss: 2.028e+00, Validation Loss: 2.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2868, Training Loss: 2.028e+00, Validation Loss: 2.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2869, Training Loss: 2.028e+00, Validation Loss: 2.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2870, Training Loss: 2.027e+00, Validation Loss: 2.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2871, Training Loss: 2.027e+00, Validation Loss: 2.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2872, Training Loss: 2.027e+00, Validation Loss: 2.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2873, Training Loss: 2.027e+00, Validation Loss: 2.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2874, Training Loss: 2.027e+00, Validation Loss: 2.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2875, Training Loss: 2.026e+00, Validation Loss: 2.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2876, Training Loss: 2.026e+00, Validation Loss: 2.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2877, Training Loss: 2.026e+00, Validation Loss: 2.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2878, Training Loss: 2.026e+00, Validation Loss: 2.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2879, Training Loss: 2.026e+00, Validation Loss: 2.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2880, Training Loss: 2.025e+00, Validation Loss: 2.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2881, Training Loss: 2.025e+00, Validation Loss: 2.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2882, Training Loss: 2.025e+00, Validation Loss: 2.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2883, Training Loss: 2.025e+00, Validation Loss: 2.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2884, Training Loss: 2.025e+00, Validation Loss: 2.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2885, Training Loss: 2.025e+00, Validation Loss: 2.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2886, Training Loss: 2.024e+00, Validation Loss: 2.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2887, Training Loss: 2.024e+00, Validation Loss: 2.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2888, Training Loss: 2.024e+00, Validation Loss: 2.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2889, Training Loss: 2.024e+00, Validation Loss: 2.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2890, Training Loss: 2.024e+00, Validation Loss: 2.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2891, Training Loss: 2.023e+00, Validation Loss: 2.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2892, Training Loss: 2.023e+00, Validation Loss: 2.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2893, Training Loss: 2.023e+00, Validation Loss: 2.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2894, Training Loss: 2.023e+00, Validation Loss: 2.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2895, Training Loss: 2.023e+00, Validation Loss: 2.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2896, Training Loss: 2.022e+00, Validation Loss: 2.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2897, Training Loss: 2.022e+00, Validation Loss: 2.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2898, Training Loss: 2.022e+00, Validation Loss: 2.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2899, Training Loss: 2.022e+00, Validation Loss: 2.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2900, Training Loss: 2.022e+00, Validation Loss: 2.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2901, Training Loss: 2.021e+00, Validation Loss: 2.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2902, Training Loss: 2.021e+00, Validation Loss: 2.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2903, Training Loss: 2.021e+00, Validation Loss: 2.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2904, Training Loss: 2.021e+00, Validation Loss: 2.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2905, Training Loss: 2.021e+00, Validation Loss: 2.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2906, Training Loss: 2.020e+00, Validation Loss: 2.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2907, Training Loss: 2.020e+00, Validation Loss: 2.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2908, Training Loss: 2.020e+00, Validation Loss: 2.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2909, Training Loss: 2.020e+00, Validation Loss: 2.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2910, Training Loss: 2.020e+00, Validation Loss: 2.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2911, Training Loss: 2.019e+00, Validation Loss: 2.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2912, Training Loss: 2.019e+00, Validation Loss: 2.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2913, Training Loss: 2.019e+00, Validation Loss: 2.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2914, Training Loss: 2.019e+00, Validation Loss: 2.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2915, Training Loss: 2.019e+00, Validation Loss: 2.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2916, Training Loss: 2.018e+00, Validation Loss: 2.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2917, Training Loss: 2.018e+00, Validation Loss: 2.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2918, Training Loss: 2.018e+00, Validation Loss: 2.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2919, Training Loss: 2.018e+00, Validation Loss: 2.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2920, Training Loss: 2.018e+00, Validation Loss: 2.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2921, Training Loss: 2.017e+00, Validation Loss: 2.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2922, Training Loss: 2.017e+00, Validation Loss: 2.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2923, Training Loss: 2.017e+00, Validation Loss: 2.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2924, Training Loss: 2.017e+00, Validation Loss: 2.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2925, Training Loss: 2.017e+00, Validation Loss: 2.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2926, Training Loss: 2.017e+00, Validation Loss: 2.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2927, Training Loss: 2.016e+00, Validation Loss: 2.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2928, Training Loss: 2.016e+00, Validation Loss: 2.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2929, Training Loss: 2.016e+00, Validation Loss: 2.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2930, Training Loss: 2.016e+00, Validation Loss: 2.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2931, Training Loss: 2.016e+00, Validation Loss: 2.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2932, Training Loss: 2.015e+00, Validation Loss: 2.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2933, Training Loss: 2.015e+00, Validation Loss: 2.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2934, Training Loss: 2.015e+00, Validation Loss: 2.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2935, Training Loss: 2.015e+00, Validation Loss: 2.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2936, Training Loss: 2.015e+00, Validation Loss: 2.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2937, Training Loss: 2.014e+00, Validation Loss: 2.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2938, Training Loss: 2.014e+00, Validation Loss: 2.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2939, Training Loss: 2.014e+00, Validation Loss: 2.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2940, Training Loss: 2.014e+00, Validation Loss: 2.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2941, Training Loss: 2.014e+00, Validation Loss: 2.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2942, Training Loss: 2.013e+00, Validation Loss: 2.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2943, Training Loss: 2.013e+00, Validation Loss: 2.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2944, Training Loss: 2.013e+00, Validation Loss: 2.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2945, Training Loss: 2.013e+00, Validation Loss: 2.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2946, Training Loss: 2.013e+00, Validation Loss: 2.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2947, Training Loss: 2.012e+00, Validation Loss: 2.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2948, Training Loss: 2.012e+00, Validation Loss: 2.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2949, Training Loss: 2.012e+00, Validation Loss: 2.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2950, Training Loss: 2.012e+00, Validation Loss: 2.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2951, Training Loss: 2.012e+00, Validation Loss: 2.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2952, Training Loss: 2.011e+00, Validation Loss: 2.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2953, Training Loss: 2.011e+00, Validation Loss: 2.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2954, Training Loss: 2.011e+00, Validation Loss: 2.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2955, Training Loss: 2.011e+00, Validation Loss: 2.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2956, Training Loss: 2.011e+00, Validation Loss: 2.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2957, Training Loss: 2.010e+00, Validation Loss: 2.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2958, Training Loss: 2.010e+00, Validation Loss: 2.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2959, Training Loss: 2.010e+00, Validation Loss: 2.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2960, Training Loss: 2.010e+00, Validation Loss: 2.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2961, Training Loss: 2.010e+00, Validation Loss: 2.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2962, Training Loss: 2.010e+00, Validation Loss: 2.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2963, Training Loss: 2.009e+00, Validation Loss: 2.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2964, Training Loss: 2.009e+00, Validation Loss: 2.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2965, Training Loss: 2.009e+00, Validation Loss: 2.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2966, Training Loss: 2.009e+00, Validation Loss: 2.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2967, Training Loss: 2.009e+00, Validation Loss: 2.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2968, Training Loss: 2.008e+00, Validation Loss: 2.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2969, Training Loss: 2.008e+00, Validation Loss: 2.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2970, Training Loss: 2.008e+00, Validation Loss: 2.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2971, Training Loss: 2.008e+00, Validation Loss: 2.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2972, Training Loss: 2.008e+00, Validation Loss: 2.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2973, Training Loss: 2.007e+00, Validation Loss: 2.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2974, Training Loss: 2.007e+00, Validation Loss: 2.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2975, Training Loss: 2.007e+00, Validation Loss: 2.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2976, Training Loss: 2.007e+00, Validation Loss: 2.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2977, Training Loss: 2.007e+00, Validation Loss: 2.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2978, Training Loss: 2.006e+00, Validation Loss: 2.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2979, Training Loss: 2.006e+00, Validation Loss: 2.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2980, Training Loss: 2.006e+00, Validation Loss: 2.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2981, Training Loss: 2.006e+00, Validation Loss: 2.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2982, Training Loss: 2.006e+00, Validation Loss: 2.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2983, Training Loss: 2.005e+00, Validation Loss: 2.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2984, Training Loss: 2.005e+00, Validation Loss: 2.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2985, Training Loss: 2.005e+00, Validation Loss: 2.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2986, Training Loss: 2.005e+00, Validation Loss: 2.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2987, Training Loss: 2.005e+00, Validation Loss: 2.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2988, Training Loss: 2.004e+00, Validation Loss: 2.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2989, Training Loss: 2.004e+00, Validation Loss: 2.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2990, Training Loss: 2.004e+00, Validation Loss: 2.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2991, Training Loss: 2.004e+00, Validation Loss: 2.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2992, Training Loss: 2.004e+00, Validation Loss: 2.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2993, Training Loss: 2.003e+00, Validation Loss: 2.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2994, Training Loss: 2.003e+00, Validation Loss: 2.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2995, Training Loss: 2.003e+00, Validation Loss: 2.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2996, Training Loss: 2.003e+00, Validation Loss: 2.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2997, Training Loss: 2.003e+00, Validation Loss: 2.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2998, Training Loss: 2.003e+00, Validation Loss: 2.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2999, Training Loss: 2.002e+00, Validation Loss: 2.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3000, Training Loss: 2.002e+00, Validation Loss: 2.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3001, Training Loss: 2.002e+00, Validation Loss: 2.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3002, Training Loss: 2.002e+00, Validation Loss: 2.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3003, Training Loss: 2.002e+00, Validation Loss: 2.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3004, Training Loss: 2.001e+00, Validation Loss: 2.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3005, Training Loss: 2.001e+00, Validation Loss: 2.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3006, Training Loss: 2.001e+00, Validation Loss: 2.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3007, Training Loss: 2.001e+00, Validation Loss: 2.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3008, Training Loss: 2.001e+00, Validation Loss: 2.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3009, Training Loss: 2.000e+00, Validation Loss: 2.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3010, Training Loss: 2.000e+00, Validation Loss: 2.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3011, Training Loss: 2.000e+00, Validation Loss: 2.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3012, Training Loss: 2.000e+00, Validation Loss: 2.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3013, Training Loss: 2.000e+00, Validation Loss: 2.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3014, Training Loss: 1.999e+00, Validation Loss: 2.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3015, Training Loss: 1.999e+00, Validation Loss: 2.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3016, Training Loss: 1.999e+00, Validation Loss: 2.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3017, Training Loss: 1.999e+00, Validation Loss: 2.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3018, Training Loss: 1.999e+00, Validation Loss: 2.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3019, Training Loss: 1.998e+00, Validation Loss: 2.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3020, Training Loss: 1.998e+00, Validation Loss: 2.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3021, Training Loss: 1.998e+00, Validation Loss: 2.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3022, Training Loss: 1.998e+00, Validation Loss: 2.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3023, Training Loss: 1.998e+00, Validation Loss: 2.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3024, Training Loss: 1.997e+00, Validation Loss: 2.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3025, Training Loss: 1.997e+00, Validation Loss: 2.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3026, Training Loss: 1.997e+00, Validation Loss: 2.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3027, Training Loss: 1.997e+00, Validation Loss: 2.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3028, Training Loss: 1.997e+00, Validation Loss: 2.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3029, Training Loss: 1.997e+00, Validation Loss: 2.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3030, Training Loss: 1.996e+00, Validation Loss: 2.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3031, Training Loss: 1.996e+00, Validation Loss: 2.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3032, Training Loss: 1.996e+00, Validation Loss: 2.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3033, Training Loss: 1.996e+00, Validation Loss: 2.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3034, Training Loss: 1.996e+00, Validation Loss: 2.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3035, Training Loss: 1.995e+00, Validation Loss: 2.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3036, Training Loss: 1.995e+00, Validation Loss: 2.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3037, Training Loss: 1.995e+00, Validation Loss: 2.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3038, Training Loss: 1.995e+00, Validation Loss: 2.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3039, Training Loss: 1.995e+00, Validation Loss: 2.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3040, Training Loss: 1.994e+00, Validation Loss: 2.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3041, Training Loss: 1.994e+00, Validation Loss: 2.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3042, Training Loss: 1.994e+00, Validation Loss: 2.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3043, Training Loss: 1.994e+00, Validation Loss: 2.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3044, Training Loss: 1.994e+00, Validation Loss: 2.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3045, Training Loss: 1.993e+00, Validation Loss: 2.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3046, Training Loss: 1.993e+00, Validation Loss: 2.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3047, Training Loss: 1.993e+00, Validation Loss: 2.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3048, Training Loss: 1.993e+00, Validation Loss: 2.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3049, Training Loss: 1.993e+00, Validation Loss: 2.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3050, Training Loss: 1.992e+00, Validation Loss: 2.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3051, Training Loss: 1.992e+00, Validation Loss: 2.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3052, Training Loss: 1.992e+00, Validation Loss: 2.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3053, Training Loss: 1.992e+00, Validation Loss: 2.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3054, Training Loss: 1.992e+00, Validation Loss: 2.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3055, Training Loss: 1.992e+00, Validation Loss: 2.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3056, Training Loss: 1.991e+00, Validation Loss: 2.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3057, Training Loss: 1.991e+00, Validation Loss: 2.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3058, Training Loss: 1.991e+00, Validation Loss: 2.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3059, Training Loss: 1.991e+00, Validation Loss: 2.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3060, Training Loss: 1.991e+00, Validation Loss: 2.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3061, Training Loss: 1.990e+00, Validation Loss: 2.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3062, Training Loss: 1.990e+00, Validation Loss: 2.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3063, Training Loss: 1.990e+00, Validation Loss: 2.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3064, Training Loss: 1.990e+00, Validation Loss: 2.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3065, Training Loss: 1.990e+00, Validation Loss: 2.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3066, Training Loss: 1.989e+00, Validation Loss: 2.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3067, Training Loss: 1.989e+00, Validation Loss: 2.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3068, Training Loss: 1.989e+00, Validation Loss: 2.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3069, Training Loss: 1.989e+00, Validation Loss: 2.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3070, Training Loss: 1.989e+00, Validation Loss: 2.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3071, Training Loss: 1.988e+00, Validation Loss: 2.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3072, Training Loss: 1.988e+00, Validation Loss: 2.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3073, Training Loss: 1.988e+00, Validation Loss: 2.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3074, Training Loss: 1.988e+00, Validation Loss: 2.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3075, Training Loss: 1.988e+00, Validation Loss: 2.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3076, Training Loss: 1.987e+00, Validation Loss: 2.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3077, Training Loss: 1.987e+00, Validation Loss: 2.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3078, Training Loss: 1.987e+00, Validation Loss: 2.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3079, Training Loss: 1.987e+00, Validation Loss: 2.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3080, Training Loss: 1.987e+00, Validation Loss: 2.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3081, Training Loss: 1.986e+00, Validation Loss: 2.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3082, Training Loss: 1.986e+00, Validation Loss: 2.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3083, Training Loss: 1.986e+00, Validation Loss: 2.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3084, Training Loss: 1.986e+00, Validation Loss: 2.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3085, Training Loss: 1.986e+00, Validation Loss: 2.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3086, Training Loss: 1.986e+00, Validation Loss: 2.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3087, Training Loss: 1.985e+00, Validation Loss: 2.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3088, Training Loss: 1.985e+00, Validation Loss: 2.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3089, Training Loss: 1.985e+00, Validation Loss: 2.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3090, Training Loss: 1.985e+00, Validation Loss: 2.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3091, Training Loss: 1.985e+00, Validation Loss: 2.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3092, Training Loss: 1.984e+00, Validation Loss: 2.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3093, Training Loss: 1.984e+00, Validation Loss: 2.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3094, Training Loss: 1.984e+00, Validation Loss: 2.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3095, Training Loss: 1.984e+00, Validation Loss: 2.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3096, Training Loss: 1.984e+00, Validation Loss: 2.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3097, Training Loss: 1.983e+00, Validation Loss: 2.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3098, Training Loss: 1.983e+00, Validation Loss: 2.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3099, Training Loss: 1.983e+00, Validation Loss: 2.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3100, Training Loss: 1.983e+00, Validation Loss: 2.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3101, Training Loss: 1.983e+00, Validation Loss: 2.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3102, Training Loss: 1.982e+00, Validation Loss: 2.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3103, Training Loss: 1.982e+00, Validation Loss: 2.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3104, Training Loss: 1.982e+00, Validation Loss: 2.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3105, Training Loss: 1.982e+00, Validation Loss: 2.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3106, Training Loss: 1.982e+00, Validation Loss: 2.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3107, Training Loss: 1.981e+00, Validation Loss: 2.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3108, Training Loss: 1.981e+00, Validation Loss: 2.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3109, Training Loss: 1.981e+00, Validation Loss: 2.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3110, Training Loss: 1.981e+00, Validation Loss: 2.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3111, Training Loss: 1.981e+00, Validation Loss: 2.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3112, Training Loss: 1.981e+00, Validation Loss: 2.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3113, Training Loss: 1.980e+00, Validation Loss: 2.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3114, Training Loss: 1.980e+00, Validation Loss: 2.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3115, Training Loss: 1.980e+00, Validation Loss: 2.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3116, Training Loss: 1.980e+00, Validation Loss: 2.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3117, Training Loss: 1.980e+00, Validation Loss: 2.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3118, Training Loss: 1.979e+00, Validation Loss: 2.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3119, Training Loss: 1.979e+00, Validation Loss: 2.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3120, Training Loss: 1.979e+00, Validation Loss: 2.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3121, Training Loss: 1.979e+00, Validation Loss: 2.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3122, Training Loss: 1.979e+00, Validation Loss: 2.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3123, Training Loss: 1.978e+00, Validation Loss: 2.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3124, Training Loss: 1.978e+00, Validation Loss: 2.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3125, Training Loss: 1.978e+00, Validation Loss: 2.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3126, Training Loss: 1.978e+00, Validation Loss: 2.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3127, Training Loss: 1.978e+00, Validation Loss: 2.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3128, Training Loss: 1.977e+00, Validation Loss: 2.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3129, Training Loss: 1.977e+00, Validation Loss: 2.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3130, Training Loss: 1.977e+00, Validation Loss: 2.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3131, Training Loss: 1.977e+00, Validation Loss: 2.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3132, Training Loss: 1.977e+00, Validation Loss: 2.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3133, Training Loss: 1.976e+00, Validation Loss: 2.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3134, Training Loss: 1.976e+00, Validation Loss: 2.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3135, Training Loss: 1.976e+00, Validation Loss: 2.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3136, Training Loss: 1.976e+00, Validation Loss: 2.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3137, Training Loss: 1.976e+00, Validation Loss: 2.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3138, Training Loss: 1.976e+00, Validation Loss: 2.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3139, Training Loss: 1.975e+00, Validation Loss: 2.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3140, Training Loss: 1.975e+00, Validation Loss: 2.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3141, Training Loss: 1.975e+00, Validation Loss: 2.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3142, Training Loss: 1.975e+00, Validation Loss: 2.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3143, Training Loss: 1.975e+00, Validation Loss: 2.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3144, Training Loss: 1.974e+00, Validation Loss: 2.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3145, Training Loss: 1.974e+00, Validation Loss: 2.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3146, Training Loss: 1.974e+00, Validation Loss: 2.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3147, Training Loss: 1.974e+00, Validation Loss: 2.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3148, Training Loss: 1.974e+00, Validation Loss: 2.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3149, Training Loss: 1.973e+00, Validation Loss: 2.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3150, Training Loss: 1.973e+00, Validation Loss: 2.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3151, Training Loss: 1.973e+00, Validation Loss: 2.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3152, Training Loss: 1.973e+00, Validation Loss: 2.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3153, Training Loss: 1.973e+00, Validation Loss: 2.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3154, Training Loss: 1.972e+00, Validation Loss: 2.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3155, Training Loss: 1.972e+00, Validation Loss: 2.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3156, Training Loss: 1.972e+00, Validation Loss: 2.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3157, Training Loss: 1.972e+00, Validation Loss: 2.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3158, Training Loss: 1.972e+00, Validation Loss: 2.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3159, Training Loss: 1.972e+00, Validation Loss: 2.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3160, Training Loss: 1.971e+00, Validation Loss: 2.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3161, Training Loss: 1.971e+00, Validation Loss: 2.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3162, Training Loss: 1.971e+00, Validation Loss: 2.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3163, Training Loss: 1.971e+00, Validation Loss: 2.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3164, Training Loss: 1.971e+00, Validation Loss: 2.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3165, Training Loss: 1.970e+00, Validation Loss: 2.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3166, Training Loss: 1.970e+00, Validation Loss: 2.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3167, Training Loss: 1.970e+00, Validation Loss: 2.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3168, Training Loss: 1.970e+00, Validation Loss: 2.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3169, Training Loss: 1.970e+00, Validation Loss: 2.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3170, Training Loss: 1.969e+00, Validation Loss: 2.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3171, Training Loss: 1.969e+00, Validation Loss: 2.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3172, Training Loss: 1.969e+00, Validation Loss: 2.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3173, Training Loss: 1.969e+00, Validation Loss: 2.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3174, Training Loss: 1.969e+00, Validation Loss: 2.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3175, Training Loss: 1.968e+00, Validation Loss: 2.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3176, Training Loss: 1.968e+00, Validation Loss: 2.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3177, Training Loss: 1.968e+00, Validation Loss: 2.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3178, Training Loss: 1.968e+00, Validation Loss: 2.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3179, Training Loss: 1.968e+00, Validation Loss: 2.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3180, Training Loss: 1.967e+00, Validation Loss: 2.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3181, Training Loss: 1.967e+00, Validation Loss: 2.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3182, Training Loss: 1.967e+00, Validation Loss: 2.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3183, Training Loss: 1.967e+00, Validation Loss: 2.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3184, Training Loss: 1.967e+00, Validation Loss: 2.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3185, Training Loss: 1.967e+00, Validation Loss: 2.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3186, Training Loss: 1.966e+00, Validation Loss: 2.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3187, Training Loss: 1.966e+00, Validation Loss: 2.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3188, Training Loss: 1.966e+00, Validation Loss: 2.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3189, Training Loss: 1.966e+00, Validation Loss: 2.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3190, Training Loss: 1.966e+00, Validation Loss: 2.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3191, Training Loss: 1.965e+00, Validation Loss: 2.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3192, Training Loss: 1.965e+00, Validation Loss: 2.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3193, Training Loss: 1.965e+00, Validation Loss: 2.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3194, Training Loss: 1.965e+00, Validation Loss: 2.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3195, Training Loss: 1.965e+00, Validation Loss: 2.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3196, Training Loss: 1.964e+00, Validation Loss: 2.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3197, Training Loss: 1.964e+00, Validation Loss: 2.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3198, Training Loss: 1.964e+00, Validation Loss: 2.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3199, Training Loss: 1.964e+00, Validation Loss: 2.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3200, Training Loss: 1.964e+00, Validation Loss: 2.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3201, Training Loss: 1.963e+00, Validation Loss: 2.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3202, Training Loss: 1.963e+00, Validation Loss: 2.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3203, Training Loss: 1.963e+00, Validation Loss: 2.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3204, Training Loss: 1.963e+00, Validation Loss: 2.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3205, Training Loss: 1.963e+00, Validation Loss: 2.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3206, Training Loss: 1.962e+00, Validation Loss: 2.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3207, Training Loss: 1.962e+00, Validation Loss: 2.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3208, Training Loss: 1.962e+00, Validation Loss: 2.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3209, Training Loss: 1.962e+00, Validation Loss: 2.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3210, Training Loss: 1.962e+00, Validation Loss: 2.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3211, Training Loss: 1.962e+00, Validation Loss: 2.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3212, Training Loss: 1.961e+00, Validation Loss: 2.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3213, Training Loss: 1.961e+00, Validation Loss: 2.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3214, Training Loss: 1.961e+00, Validation Loss: 2.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3215, Training Loss: 1.961e+00, Validation Loss: 2.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3216, Training Loss: 1.961e+00, Validation Loss: 2.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3217, Training Loss: 1.960e+00, Validation Loss: 2.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3218, Training Loss: 1.960e+00, Validation Loss: 2.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3219, Training Loss: 1.960e+00, Validation Loss: 2.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3220, Training Loss: 1.960e+00, Validation Loss: 2.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3221, Training Loss: 1.960e+00, Validation Loss: 2.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3222, Training Loss: 1.959e+00, Validation Loss: 2.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3223, Training Loss: 1.959e+00, Validation Loss: 2.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3224, Training Loss: 1.959e+00, Validation Loss: 2.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3225, Training Loss: 1.959e+00, Validation Loss: 2.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3226, Training Loss: 1.959e+00, Validation Loss: 2.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3227, Training Loss: 1.958e+00, Validation Loss: 2.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3228, Training Loss: 1.958e+00, Validation Loss: 2.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3229, Training Loss: 1.958e+00, Validation Loss: 2.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3230, Training Loss: 1.958e+00, Validation Loss: 2.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3231, Training Loss: 1.958e+00, Validation Loss: 2.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3232, Training Loss: 1.958e+00, Validation Loss: 2.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3233, Training Loss: 1.957e+00, Validation Loss: 2.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3234, Training Loss: 1.957e+00, Validation Loss: 2.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3235, Training Loss: 1.957e+00, Validation Loss: 2.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3236, Training Loss: 1.957e+00, Validation Loss: 2.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3237, Training Loss: 1.957e+00, Validation Loss: 2.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3238, Training Loss: 1.956e+00, Validation Loss: 2.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3239, Training Loss: 1.956e+00, Validation Loss: 2.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3240, Training Loss: 1.956e+00, Validation Loss: 2.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3241, Training Loss: 1.956e+00, Validation Loss: 2.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3242, Training Loss: 1.956e+00, Validation Loss: 2.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3243, Training Loss: 1.955e+00, Validation Loss: 2.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3244, Training Loss: 1.955e+00, Validation Loss: 2.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3245, Training Loss: 1.955e+00, Validation Loss: 2.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3246, Training Loss: 1.955e+00, Validation Loss: 2.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3247, Training Loss: 1.955e+00, Validation Loss: 2.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3248, Training Loss: 1.954e+00, Validation Loss: 2.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3249, Training Loss: 1.954e+00, Validation Loss: 2.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3250, Training Loss: 1.954e+00, Validation Loss: 2.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3251, Training Loss: 1.954e+00, Validation Loss: 2.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3252, Training Loss: 1.954e+00, Validation Loss: 2.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3253, Training Loss: 1.954e+00, Validation Loss: 2.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3254, Training Loss: 1.953e+00, Validation Loss: 2.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3255, Training Loss: 1.953e+00, Validation Loss: 2.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3256, Training Loss: 1.953e+00, Validation Loss: 2.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3257, Training Loss: 1.953e+00, Validation Loss: 2.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3258, Training Loss: 1.953e+00, Validation Loss: 2.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3259, Training Loss: 1.952e+00, Validation Loss: 2.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3260, Training Loss: 1.952e+00, Validation Loss: 2.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3261, Training Loss: 1.952e+00, Validation Loss: 2.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3262, Training Loss: 1.952e+00, Validation Loss: 2.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3263, Training Loss: 1.952e+00, Validation Loss: 2.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3264, Training Loss: 1.951e+00, Validation Loss: 2.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3265, Training Loss: 1.951e+00, Validation Loss: 2.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3266, Training Loss: 1.951e+00, Validation Loss: 2.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3267, Training Loss: 1.951e+00, Validation Loss: 2.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3268, Training Loss: 1.951e+00, Validation Loss: 2.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3269, Training Loss: 1.950e+00, Validation Loss: 2.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3270, Training Loss: 1.950e+00, Validation Loss: 2.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3271, Training Loss: 1.950e+00, Validation Loss: 2.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3272, Training Loss: 1.950e+00, Validation Loss: 2.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3273, Training Loss: 1.950e+00, Validation Loss: 2.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3274, Training Loss: 1.950e+00, Validation Loss: 2.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3275, Training Loss: 1.949e+00, Validation Loss: 2.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3276, Training Loss: 1.949e+00, Validation Loss: 2.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3277, Training Loss: 1.949e+00, Validation Loss: 2.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3278, Training Loss: 1.949e+00, Validation Loss: 2.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3279, Training Loss: 1.949e+00, Validation Loss: 2.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3280, Training Loss: 1.948e+00, Validation Loss: 2.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3281, Training Loss: 1.948e+00, Validation Loss: 2.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3282, Training Loss: 1.948e+00, Validation Loss: 2.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3283, Training Loss: 1.948e+00, Validation Loss: 2.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3284, Training Loss: 1.948e+00, Validation Loss: 2.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3285, Training Loss: 1.947e+00, Validation Loss: 2.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3286, Training Loss: 1.947e+00, Validation Loss: 2.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3287, Training Loss: 1.947e+00, Validation Loss: 2.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3288, Training Loss: 1.947e+00, Validation Loss: 2.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3289, Training Loss: 1.947e+00, Validation Loss: 2.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3290, Training Loss: 1.946e+00, Validation Loss: 2.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3291, Training Loss: 1.946e+00, Validation Loss: 2.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3292, Training Loss: 1.946e+00, Validation Loss: 2.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3293, Training Loss: 1.946e+00, Validation Loss: 2.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3294, Training Loss: 1.946e+00, Validation Loss: 2.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3295, Training Loss: 1.946e+00, Validation Loss: 2.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3296, Training Loss: 1.945e+00, Validation Loss: 2.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3297, Training Loss: 1.945e+00, Validation Loss: 2.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3298, Training Loss: 1.945e+00, Validation Loss: 2.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3299, Training Loss: 1.945e+00, Validation Loss: 2.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3300, Training Loss: 1.945e+00, Validation Loss: 2.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3301, Training Loss: 1.944e+00, Validation Loss: 2.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3302, Training Loss: 1.944e+00, Validation Loss: 2.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3303, Training Loss: 1.944e+00, Validation Loss: 2.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3304, Training Loss: 1.944e+00, Validation Loss: 2.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3305, Training Loss: 1.944e+00, Validation Loss: 2.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3306, Training Loss: 1.943e+00, Validation Loss: 2.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3307, Training Loss: 1.943e+00, Validation Loss: 2.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3308, Training Loss: 1.943e+00, Validation Loss: 2.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3309, Training Loss: 1.943e+00, Validation Loss: 2.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3310, Training Loss: 1.943e+00, Validation Loss: 2.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3311, Training Loss: 1.942e+00, Validation Loss: 2.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3312, Training Loss: 1.942e+00, Validation Loss: 2.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3313, Training Loss: 1.942e+00, Validation Loss: 2.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3314, Training Loss: 1.942e+00, Validation Loss: 2.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3315, Training Loss: 1.942e+00, Validation Loss: 2.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3316, Training Loss: 1.942e+00, Validation Loss: 2.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3317, Training Loss: 1.941e+00, Validation Loss: 2.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3318, Training Loss: 1.941e+00, Validation Loss: 2.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3319, Training Loss: 1.941e+00, Validation Loss: 2.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3320, Training Loss: 1.941e+00, Validation Loss: 2.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3321, Training Loss: 1.941e+00, Validation Loss: 2.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3322, Training Loss: 1.940e+00, Validation Loss: 2.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3323, Training Loss: 1.940e+00, Validation Loss: 2.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3324, Training Loss: 1.940e+00, Validation Loss: 2.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3325, Training Loss: 1.940e+00, Validation Loss: 2.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3326, Training Loss: 1.940e+00, Validation Loss: 2.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3327, Training Loss: 1.939e+00, Validation Loss: 2.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3328, Training Loss: 1.939e+00, Validation Loss: 2.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3329, Training Loss: 1.939e+00, Validation Loss: 2.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3330, Training Loss: 1.939e+00, Validation Loss: 2.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3331, Training Loss: 1.939e+00, Validation Loss: 2.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3332, Training Loss: 1.938e+00, Validation Loss: 2.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3333, Training Loss: 1.938e+00, Validation Loss: 2.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3334, Training Loss: 1.938e+00, Validation Loss: 2.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3335, Training Loss: 1.938e+00, Validation Loss: 2.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3336, Training Loss: 1.938e+00, Validation Loss: 2.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3337, Training Loss: 1.938e+00, Validation Loss: 2.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3338, Training Loss: 1.937e+00, Validation Loss: 2.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3339, Training Loss: 1.937e+00, Validation Loss: 2.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3340, Training Loss: 1.937e+00, Validation Loss: 2.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3341, Training Loss: 1.937e+00, Validation Loss: 2.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3342, Training Loss: 1.937e+00, Validation Loss: 2.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3343, Training Loss: 1.936e+00, Validation Loss: 2.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3344, Training Loss: 1.936e+00, Validation Loss: 2.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3345, Training Loss: 1.936e+00, Validation Loss: 2.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3346, Training Loss: 1.936e+00, Validation Loss: 2.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3347, Training Loss: 1.936e+00, Validation Loss: 2.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3348, Training Loss: 1.935e+00, Validation Loss: 2.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3349, Training Loss: 1.935e+00, Validation Loss: 2.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3350, Training Loss: 1.935e+00, Validation Loss: 2.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3351, Training Loss: 1.935e+00, Validation Loss: 2.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3352, Training Loss: 1.935e+00, Validation Loss: 2.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3353, Training Loss: 1.935e+00, Validation Loss: 2.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3354, Training Loss: 1.934e+00, Validation Loss: 2.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3355, Training Loss: 1.934e+00, Validation Loss: 2.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3356, Training Loss: 1.934e+00, Validation Loss: 2.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3357, Training Loss: 1.934e+00, Validation Loss: 2.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3358, Training Loss: 1.934e+00, Validation Loss: 2.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3359, Training Loss: 1.933e+00, Validation Loss: 2.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3360, Training Loss: 1.933e+00, Validation Loss: 2.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3361, Training Loss: 1.933e+00, Validation Loss: 2.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3362, Training Loss: 1.933e+00, Validation Loss: 2.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3363, Training Loss: 1.933e+00, Validation Loss: 2.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3364, Training Loss: 1.932e+00, Validation Loss: 2.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3365, Training Loss: 1.932e+00, Validation Loss: 2.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3366, Training Loss: 1.932e+00, Validation Loss: 2.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3367, Training Loss: 1.932e+00, Validation Loss: 2.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3368, Training Loss: 1.932e+00, Validation Loss: 2.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3369, Training Loss: 1.931e+00, Validation Loss: 2.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3370, Training Loss: 1.931e+00, Validation Loss: 2.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3371, Training Loss: 1.931e+00, Validation Loss: 2.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3372, Training Loss: 1.931e+00, Validation Loss: 2.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3373, Training Loss: 1.931e+00, Validation Loss: 2.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3374, Training Loss: 1.931e+00, Validation Loss: 2.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3375, Training Loss: 1.930e+00, Validation Loss: 2.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3376, Training Loss: 1.930e+00, Validation Loss: 2.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3377, Training Loss: 1.930e+00, Validation Loss: 2.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3378, Training Loss: 1.930e+00, Validation Loss: 2.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3379, Training Loss: 1.930e+00, Validation Loss: 2.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3380, Training Loss: 1.929e+00, Validation Loss: 2.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3381, Training Loss: 1.929e+00, Validation Loss: 2.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3382, Training Loss: 1.929e+00, Validation Loss: 2.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3383, Training Loss: 1.929e+00, Validation Loss: 2.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3384, Training Loss: 1.929e+00, Validation Loss: 2.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3385, Training Loss: 1.928e+00, Validation Loss: 2.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3386, Training Loss: 1.928e+00, Validation Loss: 2.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3387, Training Loss: 1.928e+00, Validation Loss: 2.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3388, Training Loss: 1.928e+00, Validation Loss: 2.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3389, Training Loss: 1.928e+00, Validation Loss: 2.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3390, Training Loss: 1.928e+00, Validation Loss: 2.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3391, Training Loss: 1.927e+00, Validation Loss: 2.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3392, Training Loss: 1.927e+00, Validation Loss: 2.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3393, Training Loss: 1.927e+00, Validation Loss: 2.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3394, Training Loss: 1.927e+00, Validation Loss: 2.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3395, Training Loss: 1.927e+00, Validation Loss: 2.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3396, Training Loss: 1.926e+00, Validation Loss: 2.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3397, Training Loss: 1.926e+00, Validation Loss: 2.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3398, Training Loss: 1.926e+00, Validation Loss: 2.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3399, Training Loss: 1.926e+00, Validation Loss: 2.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3400, Training Loss: 1.926e+00, Validation Loss: 2.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3401, Training Loss: 1.925e+00, Validation Loss: 2.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3402, Training Loss: 1.925e+00, Validation Loss: 2.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3403, Training Loss: 1.925e+00, Validation Loss: 2.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3404, Training Loss: 1.925e+00, Validation Loss: 2.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3405, Training Loss: 1.925e+00, Validation Loss: 2.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3406, Training Loss: 1.925e+00, Validation Loss: 2.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3407, Training Loss: 1.924e+00, Validation Loss: 2.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3408, Training Loss: 1.924e+00, Validation Loss: 2.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3409, Training Loss: 1.924e+00, Validation Loss: 2.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3410, Training Loss: 1.924e+00, Validation Loss: 2.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3411, Training Loss: 1.924e+00, Validation Loss: 2.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3412, Training Loss: 1.923e+00, Validation Loss: 2.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3413, Training Loss: 1.923e+00, Validation Loss: 2.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3414, Training Loss: 1.923e+00, Validation Loss: 2.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3415, Training Loss: 1.923e+00, Validation Loss: 2.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3416, Training Loss: 1.923e+00, Validation Loss: 2.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3417, Training Loss: 1.922e+00, Validation Loss: 2.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3418, Training Loss: 1.922e+00, Validation Loss: 2.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3419, Training Loss: 1.922e+00, Validation Loss: 2.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3420, Training Loss: 1.922e+00, Validation Loss: 2.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3421, Training Loss: 1.922e+00, Validation Loss: 2.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3422, Training Loss: 1.921e+00, Validation Loss: 2.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3423, Training Loss: 1.921e+00, Validation Loss: 2.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3424, Training Loss: 1.921e+00, Validation Loss: 2.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3425, Training Loss: 1.921e+00, Validation Loss: 2.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3426, Training Loss: 1.921e+00, Validation Loss: 2.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3427, Training Loss: 1.921e+00, Validation Loss: 2.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3428, Training Loss: 1.920e+00, Validation Loss: 2.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3429, Training Loss: 1.920e+00, Validation Loss: 2.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3430, Training Loss: 1.920e+00, Validation Loss: 2.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3431, Training Loss: 1.920e+00, Validation Loss: 2.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3432, Training Loss: 1.920e+00, Validation Loss: 2.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3433, Training Loss: 1.919e+00, Validation Loss: 2.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3434, Training Loss: 1.919e+00, Validation Loss: 2.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3435, Training Loss: 1.919e+00, Validation Loss: 2.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3436, Training Loss: 1.919e+00, Validation Loss: 2.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3437, Training Loss: 1.919e+00, Validation Loss: 2.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3438, Training Loss: 1.918e+00, Validation Loss: 2.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3439, Training Loss: 1.918e+00, Validation Loss: 2.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3440, Training Loss: 1.918e+00, Validation Loss: 2.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3441, Training Loss: 1.918e+00, Validation Loss: 2.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3442, Training Loss: 1.918e+00, Validation Loss: 2.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3443, Training Loss: 1.918e+00, Validation Loss: 2.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3444, Training Loss: 1.917e+00, Validation Loss: 2.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3445, Training Loss: 1.917e+00, Validation Loss: 2.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3446, Training Loss: 1.917e+00, Validation Loss: 2.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3447, Training Loss: 1.917e+00, Validation Loss: 2.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3448, Training Loss: 1.917e+00, Validation Loss: 2.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3449, Training Loss: 1.916e+00, Validation Loss: 2.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3450, Training Loss: 1.916e+00, Validation Loss: 2.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3451, Training Loss: 1.916e+00, Validation Loss: 2.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3452, Training Loss: 1.916e+00, Validation Loss: 2.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3453, Training Loss: 1.916e+00, Validation Loss: 2.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3454, Training Loss: 1.915e+00, Validation Loss: 2.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3455, Training Loss: 1.915e+00, Validation Loss: 2.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3456, Training Loss: 1.915e+00, Validation Loss: 2.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3457, Training Loss: 1.915e+00, Validation Loss: 2.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3458, Training Loss: 1.915e+00, Validation Loss: 2.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3459, Training Loss: 1.915e+00, Validation Loss: 2.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3460, Training Loss: 1.914e+00, Validation Loss: 2.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3461, Training Loss: 1.914e+00, Validation Loss: 2.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3462, Training Loss: 1.914e+00, Validation Loss: 2.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3463, Training Loss: 1.914e+00, Validation Loss: 2.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3464, Training Loss: 1.914e+00, Validation Loss: 2.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3465, Training Loss: 1.913e+00, Validation Loss: 2.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3466, Training Loss: 1.913e+00, Validation Loss: 2.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3467, Training Loss: 1.913e+00, Validation Loss: 2.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3468, Training Loss: 1.913e+00, Validation Loss: 2.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3469, Training Loss: 1.913e+00, Validation Loss: 2.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3470, Training Loss: 1.912e+00, Validation Loss: 2.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3471, Training Loss: 1.912e+00, Validation Loss: 2.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3472, Training Loss: 1.912e+00, Validation Loss: 2.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3473, Training Loss: 1.912e+00, Validation Loss: 2.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3474, Training Loss: 1.912e+00, Validation Loss: 2.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3475, Training Loss: 1.912e+00, Validation Loss: 2.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3476, Training Loss: 1.911e+00, Validation Loss: 2.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3477, Training Loss: 1.911e+00, Validation Loss: 2.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3478, Training Loss: 1.911e+00, Validation Loss: 2.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3479, Training Loss: 1.911e+00, Validation Loss: 2.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3480, Training Loss: 1.911e+00, Validation Loss: 2.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3481, Training Loss: 1.910e+00, Validation Loss: 2.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3482, Training Loss: 1.910e+00, Validation Loss: 2.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3483, Training Loss: 1.910e+00, Validation Loss: 2.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3484, Training Loss: 1.910e+00, Validation Loss: 2.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3485, Training Loss: 1.910e+00, Validation Loss: 2.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3486, Training Loss: 1.909e+00, Validation Loss: 2.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3487, Training Loss: 1.909e+00, Validation Loss: 2.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3488, Training Loss: 1.909e+00, Validation Loss: 2.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3489, Training Loss: 1.909e+00, Validation Loss: 2.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3490, Training Loss: 1.909e+00, Validation Loss: 2.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3491, Training Loss: 1.909e+00, Validation Loss: 2.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3492, Training Loss: 1.908e+00, Validation Loss: 2.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3493, Training Loss: 1.908e+00, Validation Loss: 2.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3494, Training Loss: 1.908e+00, Validation Loss: 2.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3495, Training Loss: 1.908e+00, Validation Loss: 2.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3496, Training Loss: 1.908e+00, Validation Loss: 2.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3497, Training Loss: 1.907e+00, Validation Loss: 2.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3498, Training Loss: 1.907e+00, Validation Loss: 2.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3499, Training Loss: 1.907e+00, Validation Loss: 2.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3500, Training Loss: 1.907e+00, Validation Loss: 2.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3501, Training Loss: 1.907e+00, Validation Loss: 2.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3502, Training Loss: 1.906e+00, Validation Loss: 2.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3503, Training Loss: 1.906e+00, Validation Loss: 2.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3504, Training Loss: 1.906e+00, Validation Loss: 2.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3505, Training Loss: 1.906e+00, Validation Loss: 2.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3506, Training Loss: 1.906e+00, Validation Loss: 2.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3507, Training Loss: 1.906e+00, Validation Loss: 2.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3508, Training Loss: 1.905e+00, Validation Loss: 2.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3509, Training Loss: 1.905e+00, Validation Loss: 2.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3510, Training Loss: 1.905e+00, Validation Loss: 2.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3511, Training Loss: 1.905e+00, Validation Loss: 2.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3512, Training Loss: 1.905e+00, Validation Loss: 2.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3513, Training Loss: 1.904e+00, Validation Loss: 2.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3514, Training Loss: 1.904e+00, Validation Loss: 2.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3515, Training Loss: 1.904e+00, Validation Loss: 2.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3516, Training Loss: 1.904e+00, Validation Loss: 2.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3517, Training Loss: 1.904e+00, Validation Loss: 2.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3518, Training Loss: 1.903e+00, Validation Loss: 2.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3519, Training Loss: 1.903e+00, Validation Loss: 2.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3520, Training Loss: 1.903e+00, Validation Loss: 2.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3521, Training Loss: 1.903e+00, Validation Loss: 2.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3522, Training Loss: 1.903e+00, Validation Loss: 2.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3523, Training Loss: 1.903e+00, Validation Loss: 2.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3524, Training Loss: 1.902e+00, Validation Loss: 2.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3525, Training Loss: 1.902e+00, Validation Loss: 2.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3526, Training Loss: 1.902e+00, Validation Loss: 2.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3527, Training Loss: 1.902e+00, Validation Loss: 2.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3528, Training Loss: 1.902e+00, Validation Loss: 2.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3529, Training Loss: 1.901e+00, Validation Loss: 2.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3530, Training Loss: 1.901e+00, Validation Loss: 2.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3531, Training Loss: 1.901e+00, Validation Loss: 2.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3532, Training Loss: 1.901e+00, Validation Loss: 2.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3533, Training Loss: 1.901e+00, Validation Loss: 2.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3534, Training Loss: 1.900e+00, Validation Loss: 2.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3535, Training Loss: 1.900e+00, Validation Loss: 2.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3536, Training Loss: 1.900e+00, Validation Loss: 2.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3537, Training Loss: 1.900e+00, Validation Loss: 2.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3538, Training Loss: 1.900e+00, Validation Loss: 2.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3539, Training Loss: 1.900e+00, Validation Loss: 2.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3540, Training Loss: 1.899e+00, Validation Loss: 2.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3541, Training Loss: 1.899e+00, Validation Loss: 2.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3542, Training Loss: 1.899e+00, Validation Loss: 2.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3543, Training Loss: 1.899e+00, Validation Loss: 2.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3544, Training Loss: 1.899e+00, Validation Loss: 2.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3545, Training Loss: 1.898e+00, Validation Loss: 2.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3546, Training Loss: 1.898e+00, Validation Loss: 2.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3547, Training Loss: 1.898e+00, Validation Loss: 2.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3548, Training Loss: 1.898e+00, Validation Loss: 2.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3549, Training Loss: 1.898e+00, Validation Loss: 2.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3550, Training Loss: 1.898e+00, Validation Loss: 2.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3551, Training Loss: 1.897e+00, Validation Loss: 2.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3552, Training Loss: 1.897e+00, Validation Loss: 2.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3553, Training Loss: 1.897e+00, Validation Loss: 2.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3554, Training Loss: 1.897e+00, Validation Loss: 2.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3555, Training Loss: 1.897e+00, Validation Loss: 2.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3556, Training Loss: 1.896e+00, Validation Loss: 2.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3557, Training Loss: 1.896e+00, Validation Loss: 2.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3558, Training Loss: 1.896e+00, Validation Loss: 2.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3559, Training Loss: 1.896e+00, Validation Loss: 2.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3560, Training Loss: 1.896e+00, Validation Loss: 2.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3561, Training Loss: 1.895e+00, Validation Loss: 2.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3562, Training Loss: 1.895e+00, Validation Loss: 2.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3563, Training Loss: 1.895e+00, Validation Loss: 2.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3564, Training Loss: 1.895e+00, Validation Loss: 2.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3565, Training Loss: 1.895e+00, Validation Loss: 2.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3566, Training Loss: 1.895e+00, Validation Loss: 2.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3567, Training Loss: 1.894e+00, Validation Loss: 2.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3568, Training Loss: 1.894e+00, Validation Loss: 2.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3569, Training Loss: 1.894e+00, Validation Loss: 2.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3570, Training Loss: 1.894e+00, Validation Loss: 2.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3571, Training Loss: 1.894e+00, Validation Loss: 2.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3572, Training Loss: 1.893e+00, Validation Loss: 2.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3573, Training Loss: 1.893e+00, Validation Loss: 2.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3574, Training Loss: 1.893e+00, Validation Loss: 2.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3575, Training Loss: 1.893e+00, Validation Loss: 2.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3576, Training Loss: 1.893e+00, Validation Loss: 2.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3577, Training Loss: 1.892e+00, Validation Loss: 2.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3578, Training Loss: 1.892e+00, Validation Loss: 2.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3579, Training Loss: 1.892e+00, Validation Loss: 2.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3580, Training Loss: 1.892e+00, Validation Loss: 2.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3581, Training Loss: 1.892e+00, Validation Loss: 2.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3582, Training Loss: 1.892e+00, Validation Loss: 2.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3583, Training Loss: 1.891e+00, Validation Loss: 2.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3584, Training Loss: 1.891e+00, Validation Loss: 2.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3585, Training Loss: 1.891e+00, Validation Loss: 2.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3586, Training Loss: 1.891e+00, Validation Loss: 2.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3587, Training Loss: 1.891e+00, Validation Loss: 2.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3588, Training Loss: 1.890e+00, Validation Loss: 2.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3589, Training Loss: 1.890e+00, Validation Loss: 2.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3590, Training Loss: 1.890e+00, Validation Loss: 2.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3591, Training Loss: 1.890e+00, Validation Loss: 2.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3592, Training Loss: 1.890e+00, Validation Loss: 2.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3593, Training Loss: 1.889e+00, Validation Loss: 2.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3594, Training Loss: 1.889e+00, Validation Loss: 2.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3595, Training Loss: 1.889e+00, Validation Loss: 2.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3596, Training Loss: 1.889e+00, Validation Loss: 2.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3597, Training Loss: 1.889e+00, Validation Loss: 2.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3598, Training Loss: 1.889e+00, Validation Loss: 2.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3599, Training Loss: 1.888e+00, Validation Loss: 2.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3600, Training Loss: 1.888e+00, Validation Loss: 2.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3601, Training Loss: 1.888e+00, Validation Loss: 2.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3602, Training Loss: 1.888e+00, Validation Loss: 2.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3603, Training Loss: 1.888e+00, Validation Loss: 2.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3604, Training Loss: 1.887e+00, Validation Loss: 2.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3605, Training Loss: 1.887e+00, Validation Loss: 2.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3606, Training Loss: 1.887e+00, Validation Loss: 2.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3607, Training Loss: 1.887e+00, Validation Loss: 2.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3608, Training Loss: 1.887e+00, Validation Loss: 2.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3609, Training Loss: 1.886e+00, Validation Loss: 2.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3610, Training Loss: 1.886e+00, Validation Loss: 2.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3611, Training Loss: 1.886e+00, Validation Loss: 2.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3612, Training Loss: 1.886e+00, Validation Loss: 2.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3613, Training Loss: 1.886e+00, Validation Loss: 2.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3614, Training Loss: 1.886e+00, Validation Loss: 2.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3615, Training Loss: 1.885e+00, Validation Loss: 2.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3616, Training Loss: 1.885e+00, Validation Loss: 2.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3617, Training Loss: 1.885e+00, Validation Loss: 2.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3618, Training Loss: 1.885e+00, Validation Loss: 2.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3619, Training Loss: 1.885e+00, Validation Loss: 2.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3620, Training Loss: 1.884e+00, Validation Loss: 2.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3621, Training Loss: 1.884e+00, Validation Loss: 2.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3622, Training Loss: 1.884e+00, Validation Loss: 2.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3623, Training Loss: 1.884e+00, Validation Loss: 2.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3624, Training Loss: 1.884e+00, Validation Loss: 2.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3625, Training Loss: 1.884e+00, Validation Loss: 2.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3626, Training Loss: 1.883e+00, Validation Loss: 2.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3627, Training Loss: 1.883e+00, Validation Loss: 2.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3628, Training Loss: 1.883e+00, Validation Loss: 2.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3629, Training Loss: 1.883e+00, Validation Loss: 2.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3630, Training Loss: 1.883e+00, Validation Loss: 2.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3631, Training Loss: 1.882e+00, Validation Loss: 2.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3632, Training Loss: 1.882e+00, Validation Loss: 2.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3633, Training Loss: 1.882e+00, Validation Loss: 2.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3634, Training Loss: 1.882e+00, Validation Loss: 2.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3635, Training Loss: 1.882e+00, Validation Loss: 2.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3636, Training Loss: 1.881e+00, Validation Loss: 2.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3637, Training Loss: 1.881e+00, Validation Loss: 2.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3638, Training Loss: 1.881e+00, Validation Loss: 2.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3639, Training Loss: 1.881e+00, Validation Loss: 2.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3640, Training Loss: 1.881e+00, Validation Loss: 2.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3641, Training Loss: 1.881e+00, Validation Loss: 2.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3642, Training Loss: 1.880e+00, Validation Loss: 2.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3643, Training Loss: 1.880e+00, Validation Loss: 2.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3644, Training Loss: 1.880e+00, Validation Loss: 2.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3645, Training Loss: 1.880e+00, Validation Loss: 2.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3646, Training Loss: 1.880e+00, Validation Loss: 2.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3647, Training Loss: 1.879e+00, Validation Loss: 2.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3648, Training Loss: 1.879e+00, Validation Loss: 2.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3649, Training Loss: 1.879e+00, Validation Loss: 2.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3650, Training Loss: 1.879e+00, Validation Loss: 1.999e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3651, Training Loss: 1.879e+00, Validation Loss: 1.999e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3652, Training Loss: 1.878e+00, Validation Loss: 1.999e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3653, Training Loss: 1.878e+00, Validation Loss: 1.999e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3654, Training Loss: 1.878e+00, Validation Loss: 1.999e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3655, Training Loss: 1.878e+00, Validation Loss: 1.998e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3656, Training Loss: 1.878e+00, Validation Loss: 1.998e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3657, Training Loss: 1.878e+00, Validation Loss: 1.998e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3658, Training Loss: 1.877e+00, Validation Loss: 1.998e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3659, Training Loss: 1.877e+00, Validation Loss: 1.998e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3660, Training Loss: 1.877e+00, Validation Loss: 1.998e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3661, Training Loss: 1.877e+00, Validation Loss: 1.997e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3662, Training Loss: 1.877e+00, Validation Loss: 1.997e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3663, Training Loss: 1.876e+00, Validation Loss: 1.997e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3664, Training Loss: 1.876e+00, Validation Loss: 1.997e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3665, Training Loss: 1.876e+00, Validation Loss: 1.997e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3666, Training Loss: 1.876e+00, Validation Loss: 1.997e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3667, Training Loss: 1.876e+00, Validation Loss: 1.996e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3668, Training Loss: 1.876e+00, Validation Loss: 1.996e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3669, Training Loss: 1.875e+00, Validation Loss: 1.996e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3670, Training Loss: 1.875e+00, Validation Loss: 1.996e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3671, Training Loss: 1.875e+00, Validation Loss: 1.996e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3672, Training Loss: 1.875e+00, Validation Loss: 1.995e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3673, Training Loss: 1.875e+00, Validation Loss: 1.995e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3674, Training Loss: 1.874e+00, Validation Loss: 1.995e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3675, Training Loss: 1.874e+00, Validation Loss: 1.995e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3676, Training Loss: 1.874e+00, Validation Loss: 1.995e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3677, Training Loss: 1.874e+00, Validation Loss: 1.994e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3678, Training Loss: 1.874e+00, Validation Loss: 1.994e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3679, Training Loss: 1.873e+00, Validation Loss: 1.994e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3680, Training Loss: 1.873e+00, Validation Loss: 1.994e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3681, Training Loss: 1.873e+00, Validation Loss: 1.994e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3682, Training Loss: 1.873e+00, Validation Loss: 1.994e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3683, Training Loss: 1.873e+00, Validation Loss: 1.993e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3684, Training Loss: 1.873e+00, Validation Loss: 1.993e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3685, Training Loss: 1.872e+00, Validation Loss: 1.993e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3686, Training Loss: 1.872e+00, Validation Loss: 1.993e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3687, Training Loss: 1.872e+00, Validation Loss: 1.993e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3688, Training Loss: 1.872e+00, Validation Loss: 1.992e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3689, Training Loss: 1.872e+00, Validation Loss: 1.992e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3690, Training Loss: 1.871e+00, Validation Loss: 1.992e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3691, Training Loss: 1.871e+00, Validation Loss: 1.992e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3692, Training Loss: 1.871e+00, Validation Loss: 1.992e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3693, Training Loss: 1.871e+00, Validation Loss: 1.992e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3694, Training Loss: 1.871e+00, Validation Loss: 1.991e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3695, Training Loss: 1.871e+00, Validation Loss: 1.991e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3696, Training Loss: 1.870e+00, Validation Loss: 1.991e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3697, Training Loss: 1.870e+00, Validation Loss: 1.991e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3698, Training Loss: 1.870e+00, Validation Loss: 1.991e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3699, Training Loss: 1.870e+00, Validation Loss: 1.991e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3700, Training Loss: 1.870e+00, Validation Loss: 1.990e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3701, Training Loss: 1.869e+00, Validation Loss: 1.990e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3702, Training Loss: 1.869e+00, Validation Loss: 1.990e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3703, Training Loss: 1.869e+00, Validation Loss: 1.990e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3704, Training Loss: 1.869e+00, Validation Loss: 1.990e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3705, Training Loss: 1.869e+00, Validation Loss: 1.989e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3706, Training Loss: 1.868e+00, Validation Loss: 1.989e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3707, Training Loss: 1.868e+00, Validation Loss: 1.989e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3708, Training Loss: 1.868e+00, Validation Loss: 1.989e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3709, Training Loss: 1.868e+00, Validation Loss: 1.989e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3710, Training Loss: 1.868e+00, Validation Loss: 1.989e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3711, Training Loss: 1.868e+00, Validation Loss: 1.988e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3712, Training Loss: 1.867e+00, Validation Loss: 1.988e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3713, Training Loss: 1.867e+00, Validation Loss: 1.988e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3714, Training Loss: 1.867e+00, Validation Loss: 1.988e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3715, Training Loss: 1.867e+00, Validation Loss: 1.988e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3716, Training Loss: 1.867e+00, Validation Loss: 1.987e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3717, Training Loss: 1.866e+00, Validation Loss: 1.987e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3718, Training Loss: 1.866e+00, Validation Loss: 1.987e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3719, Training Loss: 1.866e+00, Validation Loss: 1.987e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3720, Training Loss: 1.866e+00, Validation Loss: 1.987e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3721, Training Loss: 1.866e+00, Validation Loss: 1.987e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3722, Training Loss: 1.866e+00, Validation Loss: 1.986e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3723, Training Loss: 1.865e+00, Validation Loss: 1.986e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3724, Training Loss: 1.865e+00, Validation Loss: 1.986e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3725, Training Loss: 1.865e+00, Validation Loss: 1.986e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3726, Training Loss: 1.865e+00, Validation Loss: 1.986e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3727, Training Loss: 1.865e+00, Validation Loss: 1.985e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3728, Training Loss: 1.864e+00, Validation Loss: 1.985e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3729, Training Loss: 1.864e+00, Validation Loss: 1.985e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3730, Training Loss: 1.864e+00, Validation Loss: 1.985e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3731, Training Loss: 1.864e+00, Validation Loss: 1.985e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3732, Training Loss: 1.864e+00, Validation Loss: 1.985e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3733, Training Loss: 1.864e+00, Validation Loss: 1.984e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3734, Training Loss: 1.863e+00, Validation Loss: 1.984e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3735, Training Loss: 1.863e+00, Validation Loss: 1.984e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3736, Training Loss: 1.863e+00, Validation Loss: 1.984e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3737, Training Loss: 1.863e+00, Validation Loss: 1.984e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3738, Training Loss: 1.863e+00, Validation Loss: 1.984e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3739, Training Loss: 1.862e+00, Validation Loss: 1.983e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3740, Training Loss: 1.862e+00, Validation Loss: 1.983e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3741, Training Loss: 1.862e+00, Validation Loss: 1.983e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3742, Training Loss: 1.862e+00, Validation Loss: 1.983e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3743, Training Loss: 1.862e+00, Validation Loss: 1.983e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3744, Training Loss: 1.861e+00, Validation Loss: 1.982e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3745, Training Loss: 1.861e+00, Validation Loss: 1.982e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3746, Training Loss: 1.861e+00, Validation Loss: 1.982e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3747, Training Loss: 1.861e+00, Validation Loss: 1.982e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3748, Training Loss: 1.861e+00, Validation Loss: 1.982e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3749, Training Loss: 1.861e+00, Validation Loss: 1.982e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3750, Training Loss: 1.860e+00, Validation Loss: 1.981e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3751, Training Loss: 1.860e+00, Validation Loss: 1.981e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3752, Training Loss: 1.860e+00, Validation Loss: 1.981e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3753, Training Loss: 1.860e+00, Validation Loss: 1.981e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3754, Training Loss: 1.860e+00, Validation Loss: 1.981e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3755, Training Loss: 1.859e+00, Validation Loss: 1.980e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3756, Training Loss: 1.859e+00, Validation Loss: 1.980e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3757, Training Loss: 1.859e+00, Validation Loss: 1.980e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3758, Training Loss: 1.859e+00, Validation Loss: 1.980e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3759, Training Loss: 1.859e+00, Validation Loss: 1.980e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3760, Training Loss: 1.859e+00, Validation Loss: 1.980e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3761, Training Loss: 1.858e+00, Validation Loss: 1.979e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3762, Training Loss: 1.858e+00, Validation Loss: 1.979e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3763, Training Loss: 1.858e+00, Validation Loss: 1.979e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3764, Training Loss: 1.858e+00, Validation Loss: 1.979e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3765, Training Loss: 1.858e+00, Validation Loss: 1.979e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3766, Training Loss: 1.857e+00, Validation Loss: 1.979e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3767, Training Loss: 1.857e+00, Validation Loss: 1.978e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3768, Training Loss: 1.857e+00, Validation Loss: 1.978e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3769, Training Loss: 1.857e+00, Validation Loss: 1.978e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3770, Training Loss: 1.857e+00, Validation Loss: 1.978e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3771, Training Loss: 1.857e+00, Validation Loss: 1.978e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3772, Training Loss: 1.856e+00, Validation Loss: 1.977e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3773, Training Loss: 1.856e+00, Validation Loss: 1.977e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3774, Training Loss: 1.856e+00, Validation Loss: 1.977e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3775, Training Loss: 1.856e+00, Validation Loss: 1.977e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3776, Training Loss: 1.856e+00, Validation Loss: 1.977e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3777, Training Loss: 1.855e+00, Validation Loss: 1.977e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3778, Training Loss: 1.855e+00, Validation Loss: 1.976e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3779, Training Loss: 1.855e+00, Validation Loss: 1.976e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3780, Training Loss: 1.855e+00, Validation Loss: 1.976e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3781, Training Loss: 1.855e+00, Validation Loss: 1.976e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3782, Training Loss: 1.854e+00, Validation Loss: 1.976e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3783, Training Loss: 1.854e+00, Validation Loss: 1.975e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3784, Training Loss: 1.854e+00, Validation Loss: 1.975e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3785, Training Loss: 1.854e+00, Validation Loss: 1.975e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3786, Training Loss: 1.854e+00, Validation Loss: 1.975e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3787, Training Loss: 1.854e+00, Validation Loss: 1.975e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3788, Training Loss: 1.853e+00, Validation Loss: 1.975e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3789, Training Loss: 1.853e+00, Validation Loss: 1.974e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3790, Training Loss: 1.853e+00, Validation Loss: 1.974e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3791, Training Loss: 1.853e+00, Validation Loss: 1.974e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3792, Training Loss: 1.853e+00, Validation Loss: 1.974e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3793, Training Loss: 1.852e+00, Validation Loss: 1.974e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3794, Training Loss: 1.852e+00, Validation Loss: 1.974e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3795, Training Loss: 1.852e+00, Validation Loss: 1.973e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3796, Training Loss: 1.852e+00, Validation Loss: 1.973e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3797, Training Loss: 1.852e+00, Validation Loss: 1.973e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3798, Training Loss: 1.852e+00, Validation Loss: 1.973e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3799, Training Loss: 1.851e+00, Validation Loss: 1.973e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3800, Training Loss: 1.851e+00, Validation Loss: 1.972e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3801, Training Loss: 1.851e+00, Validation Loss: 1.972e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3802, Training Loss: 1.851e+00, Validation Loss: 1.972e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3803, Training Loss: 1.851e+00, Validation Loss: 1.972e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3804, Training Loss: 1.850e+00, Validation Loss: 1.972e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3805, Training Loss: 1.850e+00, Validation Loss: 1.972e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3806, Training Loss: 1.850e+00, Validation Loss: 1.971e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3807, Training Loss: 1.850e+00, Validation Loss: 1.971e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3808, Training Loss: 1.850e+00, Validation Loss: 1.971e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3809, Training Loss: 1.850e+00, Validation Loss: 1.971e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3810, Training Loss: 1.849e+00, Validation Loss: 1.971e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3811, Training Loss: 1.849e+00, Validation Loss: 1.971e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3812, Training Loss: 1.849e+00, Validation Loss: 1.970e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3813, Training Loss: 1.849e+00, Validation Loss: 1.970e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3814, Training Loss: 1.849e+00, Validation Loss: 1.970e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3815, Training Loss: 1.848e+00, Validation Loss: 1.970e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3816, Training Loss: 1.848e+00, Validation Loss: 1.970e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3817, Training Loss: 1.848e+00, Validation Loss: 1.969e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3818, Training Loss: 1.848e+00, Validation Loss: 1.969e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3819, Training Loss: 1.848e+00, Validation Loss: 1.969e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3820, Training Loss: 1.848e+00, Validation Loss: 1.969e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3821, Training Loss: 1.847e+00, Validation Loss: 1.969e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3822, Training Loss: 1.847e+00, Validation Loss: 1.969e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3823, Training Loss: 1.847e+00, Validation Loss: 1.968e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3824, Training Loss: 1.847e+00, Validation Loss: 1.968e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3825, Training Loss: 1.847e+00, Validation Loss: 1.968e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3826, Training Loss: 1.846e+00, Validation Loss: 1.968e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3827, Training Loss: 1.846e+00, Validation Loss: 1.968e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3828, Training Loss: 1.846e+00, Validation Loss: 1.968e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3829, Training Loss: 1.846e+00, Validation Loss: 1.967e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3830, Training Loss: 1.846e+00, Validation Loss: 1.967e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3831, Training Loss: 1.845e+00, Validation Loss: 1.967e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3832, Training Loss: 1.845e+00, Validation Loss: 1.967e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3833, Training Loss: 1.845e+00, Validation Loss: 1.967e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3834, Training Loss: 1.845e+00, Validation Loss: 1.966e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3835, Training Loss: 1.845e+00, Validation Loss: 1.966e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3836, Training Loss: 1.845e+00, Validation Loss: 1.966e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3837, Training Loss: 1.844e+00, Validation Loss: 1.966e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3838, Training Loss: 1.844e+00, Validation Loss: 1.966e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3839, Training Loss: 1.844e+00, Validation Loss: 1.966e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3840, Training Loss: 1.844e+00, Validation Loss: 1.965e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3841, Training Loss: 1.844e+00, Validation Loss: 1.965e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3842, Training Loss: 1.843e+00, Validation Loss: 1.965e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3843, Training Loss: 1.843e+00, Validation Loss: 1.965e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3844, Training Loss: 1.843e+00, Validation Loss: 1.965e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3845, Training Loss: 1.843e+00, Validation Loss: 1.965e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3846, Training Loss: 1.843e+00, Validation Loss: 1.964e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3847, Training Loss: 1.843e+00, Validation Loss: 1.964e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3848, Training Loss: 1.842e+00, Validation Loss: 1.964e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3849, Training Loss: 1.842e+00, Validation Loss: 1.964e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3850, Training Loss: 1.842e+00, Validation Loss: 1.964e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3851, Training Loss: 1.842e+00, Validation Loss: 1.963e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3852, Training Loss: 1.842e+00, Validation Loss: 1.963e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3853, Training Loss: 1.841e+00, Validation Loss: 1.963e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3854, Training Loss: 1.841e+00, Validation Loss: 1.963e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3855, Training Loss: 1.841e+00, Validation Loss: 1.963e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3856, Training Loss: 1.841e+00, Validation Loss: 1.963e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3857, Training Loss: 1.841e+00, Validation Loss: 1.962e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3858, Training Loss: 1.841e+00, Validation Loss: 1.962e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3859, Training Loss: 1.840e+00, Validation Loss: 1.962e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3860, Training Loss: 1.840e+00, Validation Loss: 1.962e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3861, Training Loss: 1.840e+00, Validation Loss: 1.962e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3862, Training Loss: 1.840e+00, Validation Loss: 1.962e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3863, Training Loss: 1.840e+00, Validation Loss: 1.961e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3864, Training Loss: 1.839e+00, Validation Loss: 1.961e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3865, Training Loss: 1.839e+00, Validation Loss: 1.961e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3866, Training Loss: 1.839e+00, Validation Loss: 1.961e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3867, Training Loss: 1.839e+00, Validation Loss: 1.961e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3868, Training Loss: 1.839e+00, Validation Loss: 1.960e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3869, Training Loss: 1.839e+00, Validation Loss: 1.960e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3870, Training Loss: 1.838e+00, Validation Loss: 1.960e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3871, Training Loss: 1.838e+00, Validation Loss: 1.960e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3872, Training Loss: 1.838e+00, Validation Loss: 1.960e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3873, Training Loss: 1.838e+00, Validation Loss: 1.960e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3874, Training Loss: 1.838e+00, Validation Loss: 1.959e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3875, Training Loss: 1.837e+00, Validation Loss: 1.959e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3876, Training Loss: 1.837e+00, Validation Loss: 1.959e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3877, Training Loss: 1.837e+00, Validation Loss: 1.959e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3878, Training Loss: 1.837e+00, Validation Loss: 1.959e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3879, Training Loss: 1.837e+00, Validation Loss: 1.959e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3880, Training Loss: 1.837e+00, Validation Loss: 1.958e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3881, Training Loss: 1.836e+00, Validation Loss: 1.958e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3882, Training Loss: 1.836e+00, Validation Loss: 1.958e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3883, Training Loss: 1.836e+00, Validation Loss: 1.958e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3884, Training Loss: 1.836e+00, Validation Loss: 1.958e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3885, Training Loss: 1.836e+00, Validation Loss: 1.958e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3886, Training Loss: 1.835e+00, Validation Loss: 1.957e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3887, Training Loss: 1.835e+00, Validation Loss: 1.957e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3888, Training Loss: 1.835e+00, Validation Loss: 1.957e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3889, Training Loss: 1.835e+00, Validation Loss: 1.957e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3890, Training Loss: 1.835e+00, Validation Loss: 1.957e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3891, Training Loss: 1.835e+00, Validation Loss: 1.956e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3892, Training Loss: 1.834e+00, Validation Loss: 1.956e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3893, Training Loss: 1.834e+00, Validation Loss: 1.956e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3894, Training Loss: 1.834e+00, Validation Loss: 1.956e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3895, Training Loss: 1.834e+00, Validation Loss: 1.956e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3896, Training Loss: 1.834e+00, Validation Loss: 1.956e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3897, Training Loss: 1.833e+00, Validation Loss: 1.955e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3898, Training Loss: 1.833e+00, Validation Loss: 1.955e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3899, Training Loss: 1.833e+00, Validation Loss: 1.955e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3900, Training Loss: 1.833e+00, Validation Loss: 1.955e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3901, Training Loss: 1.833e+00, Validation Loss: 1.955e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3902, Training Loss: 1.833e+00, Validation Loss: 1.955e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3903, Training Loss: 1.832e+00, Validation Loss: 1.954e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3904, Training Loss: 1.832e+00, Validation Loss: 1.954e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3905, Training Loss: 1.832e+00, Validation Loss: 1.954e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3906, Training Loss: 1.832e+00, Validation Loss: 1.954e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3907, Training Loss: 1.832e+00, Validation Loss: 1.954e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3908, Training Loss: 1.831e+00, Validation Loss: 1.953e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3909, Training Loss: 1.831e+00, Validation Loss: 1.953e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3910, Training Loss: 1.831e+00, Validation Loss: 1.953e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3911, Training Loss: 1.831e+00, Validation Loss: 1.953e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3912, Training Loss: 1.831e+00, Validation Loss: 1.953e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3913, Training Loss: 1.831e+00, Validation Loss: 1.953e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3914, Training Loss: 1.830e+00, Validation Loss: 1.952e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3915, Training Loss: 1.830e+00, Validation Loss: 1.952e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3916, Training Loss: 1.830e+00, Validation Loss: 1.952e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3917, Training Loss: 1.830e+00, Validation Loss: 1.952e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3918, Training Loss: 1.830e+00, Validation Loss: 1.952e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3919, Training Loss: 1.829e+00, Validation Loss: 1.952e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3920, Training Loss: 1.829e+00, Validation Loss: 1.951e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3921, Training Loss: 1.829e+00, Validation Loss: 1.951e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3922, Training Loss: 1.829e+00, Validation Loss: 1.951e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3923, Training Loss: 1.829e+00, Validation Loss: 1.951e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3924, Training Loss: 1.829e+00, Validation Loss: 1.951e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3925, Training Loss: 1.828e+00, Validation Loss: 1.950e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3926, Training Loss: 1.828e+00, Validation Loss: 1.950e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3927, Training Loss: 1.828e+00, Validation Loss: 1.950e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3928, Training Loss: 1.828e+00, Validation Loss: 1.950e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3929, Training Loss: 1.828e+00, Validation Loss: 1.950e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3930, Training Loss: 1.827e+00, Validation Loss: 1.950e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3931, Training Loss: 1.827e+00, Validation Loss: 1.949e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3932, Training Loss: 1.827e+00, Validation Loss: 1.949e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3933, Training Loss: 1.827e+00, Validation Loss: 1.949e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3934, Training Loss: 1.827e+00, Validation Loss: 1.949e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3935, Training Loss: 1.827e+00, Validation Loss: 1.949e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3936, Training Loss: 1.826e+00, Validation Loss: 1.949e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3937, Training Loss: 1.826e+00, Validation Loss: 1.948e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3938, Training Loss: 1.826e+00, Validation Loss: 1.948e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3939, Training Loss: 1.826e+00, Validation Loss: 1.948e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3940, Training Loss: 1.826e+00, Validation Loss: 1.948e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3941, Training Loss: 1.825e+00, Validation Loss: 1.948e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3942, Training Loss: 1.825e+00, Validation Loss: 1.947e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3943, Training Loss: 1.825e+00, Validation Loss: 1.947e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3944, Training Loss: 1.825e+00, Validation Loss: 1.947e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3945, Training Loss: 1.825e+00, Validation Loss: 1.947e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3946, Training Loss: 1.825e+00, Validation Loss: 1.947e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3947, Training Loss: 1.824e+00, Validation Loss: 1.947e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3948, Training Loss: 1.824e+00, Validation Loss: 1.946e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3949, Training Loss: 1.824e+00, Validation Loss: 1.946e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3950, Training Loss: 1.824e+00, Validation Loss: 1.946e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3951, Training Loss: 1.824e+00, Validation Loss: 1.946e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3952, Training Loss: 1.823e+00, Validation Loss: 1.946e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3953, Training Loss: 1.823e+00, Validation Loss: 1.946e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3954, Training Loss: 1.823e+00, Validation Loss: 1.945e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3955, Training Loss: 1.823e+00, Validation Loss: 1.945e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3956, Training Loss: 1.823e+00, Validation Loss: 1.945e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3957, Training Loss: 1.823e+00, Validation Loss: 1.945e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3958, Training Loss: 1.822e+00, Validation Loss: 1.945e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3959, Training Loss: 1.822e+00, Validation Loss: 1.944e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3960, Training Loss: 1.822e+00, Validation Loss: 1.944e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3961, Training Loss: 1.822e+00, Validation Loss: 1.944e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3962, Training Loss: 1.822e+00, Validation Loss: 1.944e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3963, Training Loss: 1.821e+00, Validation Loss: 1.944e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3964, Training Loss: 1.821e+00, Validation Loss: 1.944e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3965, Training Loss: 1.821e+00, Validation Loss: 1.943e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3966, Training Loss: 1.821e+00, Validation Loss: 1.943e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3967, Training Loss: 1.821e+00, Validation Loss: 1.943e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3968, Training Loss: 1.821e+00, Validation Loss: 1.943e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3969, Training Loss: 1.820e+00, Validation Loss: 1.943e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3970, Training Loss: 1.820e+00, Validation Loss: 1.943e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3971, Training Loss: 1.820e+00, Validation Loss: 1.942e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3972, Training Loss: 1.820e+00, Validation Loss: 1.942e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3973, Training Loss: 1.820e+00, Validation Loss: 1.942e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3974, Training Loss: 1.819e+00, Validation Loss: 1.942e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3975, Training Loss: 1.819e+00, Validation Loss: 1.942e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3976, Training Loss: 1.819e+00, Validation Loss: 1.942e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3977, Training Loss: 1.819e+00, Validation Loss: 1.941e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3978, Training Loss: 1.819e+00, Validation Loss: 1.941e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3979, Training Loss: 1.819e+00, Validation Loss: 1.941e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3980, Training Loss: 1.818e+00, Validation Loss: 1.941e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3981, Training Loss: 1.818e+00, Validation Loss: 1.941e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3982, Training Loss: 1.818e+00, Validation Loss: 1.940e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3983, Training Loss: 1.818e+00, Validation Loss: 1.940e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3984, Training Loss: 1.818e+00, Validation Loss: 1.940e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3985, Training Loss: 1.817e+00, Validation Loss: 1.940e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3986, Training Loss: 1.817e+00, Validation Loss: 1.940e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3987, Training Loss: 1.817e+00, Validation Loss: 1.940e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3988, Training Loss: 1.817e+00, Validation Loss: 1.939e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3989, Training Loss: 1.817e+00, Validation Loss: 1.939e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3990, Training Loss: 1.817e+00, Validation Loss: 1.939e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3991, Training Loss: 1.816e+00, Validation Loss: 1.939e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3992, Training Loss: 1.816e+00, Validation Loss: 1.939e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3993, Training Loss: 1.816e+00, Validation Loss: 1.939e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3994, Training Loss: 1.816e+00, Validation Loss: 1.938e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3995, Training Loss: 1.816e+00, Validation Loss: 1.938e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3996, Training Loss: 1.815e+00, Validation Loss: 1.938e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3997, Training Loss: 1.815e+00, Validation Loss: 1.938e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3998, Training Loss: 1.815e+00, Validation Loss: 1.938e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3999, Training Loss: 1.815e+00, Validation Loss: 1.938e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4000, Training Loss: 1.815e+00, Validation Loss: 1.937e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4001, Training Loss: 1.815e+00, Validation Loss: 1.937e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4002, Training Loss: 1.814e+00, Validation Loss: 1.937e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4003, Training Loss: 1.814e+00, Validation Loss: 1.937e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4004, Training Loss: 1.814e+00, Validation Loss: 1.937e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4005, Training Loss: 1.814e+00, Validation Loss: 1.936e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4006, Training Loss: 1.814e+00, Validation Loss: 1.936e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4007, Training Loss: 1.813e+00, Validation Loss: 1.936e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4008, Training Loss: 1.813e+00, Validation Loss: 1.936e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4009, Training Loss: 1.813e+00, Validation Loss: 1.936e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4010, Training Loss: 1.813e+00, Validation Loss: 1.936e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4011, Training Loss: 1.813e+00, Validation Loss: 1.935e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4012, Training Loss: 1.813e+00, Validation Loss: 1.935e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4013, Training Loss: 1.812e+00, Validation Loss: 1.935e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4014, Training Loss: 1.812e+00, Validation Loss: 1.935e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4015, Training Loss: 1.812e+00, Validation Loss: 1.935e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4016, Training Loss: 1.812e+00, Validation Loss: 1.935e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4017, Training Loss: 1.812e+00, Validation Loss: 1.934e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4018, Training Loss: 1.811e+00, Validation Loss: 1.934e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4019, Training Loss: 1.811e+00, Validation Loss: 1.934e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4020, Training Loss: 1.811e+00, Validation Loss: 1.934e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4021, Training Loss: 1.811e+00, Validation Loss: 1.934e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4022, Training Loss: 1.811e+00, Validation Loss: 1.933e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4023, Training Loss: 1.811e+00, Validation Loss: 1.933e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4024, Training Loss: 1.810e+00, Validation Loss: 1.933e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4025, Training Loss: 1.810e+00, Validation Loss: 1.933e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4026, Training Loss: 1.810e+00, Validation Loss: 1.933e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4027, Training Loss: 1.810e+00, Validation Loss: 1.933e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4028, Training Loss: 1.810e+00, Validation Loss: 1.932e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4029, Training Loss: 1.809e+00, Validation Loss: 1.932e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4030, Training Loss: 1.809e+00, Validation Loss: 1.932e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4031, Training Loss: 1.809e+00, Validation Loss: 1.932e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4032, Training Loss: 1.809e+00, Validation Loss: 1.932e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4033, Training Loss: 1.809e+00, Validation Loss: 1.932e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4034, Training Loss: 1.809e+00, Validation Loss: 1.931e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4035, Training Loss: 1.808e+00, Validation Loss: 1.931e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4036, Training Loss: 1.808e+00, Validation Loss: 1.931e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4037, Training Loss: 1.808e+00, Validation Loss: 1.931e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4038, Training Loss: 1.808e+00, Validation Loss: 1.931e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4039, Training Loss: 1.808e+00, Validation Loss: 1.930e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4040, Training Loss: 1.807e+00, Validation Loss: 1.930e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4041, Training Loss: 1.807e+00, Validation Loss: 1.930e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4042, Training Loss: 1.807e+00, Validation Loss: 1.930e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4043, Training Loss: 1.807e+00, Validation Loss: 1.930e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4044, Training Loss: 1.807e+00, Validation Loss: 1.930e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4045, Training Loss: 1.807e+00, Validation Loss: 1.929e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4046, Training Loss: 1.806e+00, Validation Loss: 1.929e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4047, Training Loss: 1.806e+00, Validation Loss: 1.929e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4048, Training Loss: 1.806e+00, Validation Loss: 1.929e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4049, Training Loss: 1.806e+00, Validation Loss: 1.929e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4050, Training Loss: 1.806e+00, Validation Loss: 1.929e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4051, Training Loss: 1.805e+00, Validation Loss: 1.928e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4052, Training Loss: 1.805e+00, Validation Loss: 1.928e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4053, Training Loss: 1.805e+00, Validation Loss: 1.928e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4054, Training Loss: 1.805e+00, Validation Loss: 1.928e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4055, Training Loss: 1.805e+00, Validation Loss: 1.928e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4056, Training Loss: 1.805e+00, Validation Loss: 1.927e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4057, Training Loss: 1.804e+00, Validation Loss: 1.927e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4058, Training Loss: 1.804e+00, Validation Loss: 1.927e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4059, Training Loss: 1.804e+00, Validation Loss: 1.927e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4060, Training Loss: 1.804e+00, Validation Loss: 1.927e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4061, Training Loss: 1.804e+00, Validation Loss: 1.927e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4062, Training Loss: 1.803e+00, Validation Loss: 1.926e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4063, Training Loss: 1.803e+00, Validation Loss: 1.926e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4064, Training Loss: 1.803e+00, Validation Loss: 1.926e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4065, Training Loss: 1.803e+00, Validation Loss: 1.926e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4066, Training Loss: 1.803e+00, Validation Loss: 1.926e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4067, Training Loss: 1.803e+00, Validation Loss: 1.926e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4068, Training Loss: 1.802e+00, Validation Loss: 1.925e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4069, Training Loss: 1.802e+00, Validation Loss: 1.925e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4070, Training Loss: 1.802e+00, Validation Loss: 1.925e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4071, Training Loss: 1.802e+00, Validation Loss: 1.925e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4072, Training Loss: 1.802e+00, Validation Loss: 1.925e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4073, Training Loss: 1.801e+00, Validation Loss: 1.924e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4074, Training Loss: 1.801e+00, Validation Loss: 1.924e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4075, Training Loss: 1.801e+00, Validation Loss: 1.924e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4076, Training Loss: 1.801e+00, Validation Loss: 1.924e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4077, Training Loss: 1.801e+00, Validation Loss: 1.924e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4078, Training Loss: 1.801e+00, Validation Loss: 1.924e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4079, Training Loss: 1.800e+00, Validation Loss: 1.923e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4080, Training Loss: 1.800e+00, Validation Loss: 1.923e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4081, Training Loss: 1.800e+00, Validation Loss: 1.923e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4082, Training Loss: 1.800e+00, Validation Loss: 1.923e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4083, Training Loss: 1.800e+00, Validation Loss: 1.923e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4084, Training Loss: 1.800e+00, Validation Loss: 1.923e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4085, Training Loss: 1.799e+00, Validation Loss: 1.922e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4086, Training Loss: 1.799e+00, Validation Loss: 1.922e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4087, Training Loss: 1.799e+00, Validation Loss: 1.922e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4088, Training Loss: 1.799e+00, Validation Loss: 1.922e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4089, Training Loss: 1.799e+00, Validation Loss: 1.922e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4090, Training Loss: 1.798e+00, Validation Loss: 1.922e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4091, Training Loss: 1.798e+00, Validation Loss: 1.921e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4092, Training Loss: 1.798e+00, Validation Loss: 1.921e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4093, Training Loss: 1.798e+00, Validation Loss: 1.921e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4094, Training Loss: 1.798e+00, Validation Loss: 1.921e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4095, Training Loss: 1.798e+00, Validation Loss: 1.921e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4096, Training Loss: 1.797e+00, Validation Loss: 1.920e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4097, Training Loss: 1.797e+00, Validation Loss: 1.920e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4098, Training Loss: 1.797e+00, Validation Loss: 1.920e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4099, Training Loss: 1.797e+00, Validation Loss: 1.920e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4100, Training Loss: 1.797e+00, Validation Loss: 1.920e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4101, Training Loss: 1.796e+00, Validation Loss: 1.920e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4102, Training Loss: 1.796e+00, Validation Loss: 1.919e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4103, Training Loss: 1.796e+00, Validation Loss: 1.919e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4104, Training Loss: 1.796e+00, Validation Loss: 1.919e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4105, Training Loss: 1.796e+00, Validation Loss: 1.919e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4106, Training Loss: 1.796e+00, Validation Loss: 1.919e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4107, Training Loss: 1.795e+00, Validation Loss: 1.919e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4108, Training Loss: 1.795e+00, Validation Loss: 1.918e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4109, Training Loss: 1.795e+00, Validation Loss: 1.918e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4110, Training Loss: 1.795e+00, Validation Loss: 1.918e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4111, Training Loss: 1.795e+00, Validation Loss: 1.918e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4112, Training Loss: 1.794e+00, Validation Loss: 1.918e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4113, Training Loss: 1.794e+00, Validation Loss: 1.917e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4114, Training Loss: 1.794e+00, Validation Loss: 1.917e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4115, Training Loss: 1.794e+00, Validation Loss: 1.917e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4116, Training Loss: 1.794e+00, Validation Loss: 1.917e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4117, Training Loss: 1.794e+00, Validation Loss: 1.917e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4118, Training Loss: 1.793e+00, Validation Loss: 1.917e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4119, Training Loss: 1.793e+00, Validation Loss: 1.916e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4120, Training Loss: 1.793e+00, Validation Loss: 1.916e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4121, Training Loss: 1.793e+00, Validation Loss: 1.916e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4122, Training Loss: 1.793e+00, Validation Loss: 1.916e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4123, Training Loss: 1.792e+00, Validation Loss: 1.916e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4124, Training Loss: 1.792e+00, Validation Loss: 1.916e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4125, Training Loss: 1.792e+00, Validation Loss: 1.915e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4126, Training Loss: 1.792e+00, Validation Loss: 1.915e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4127, Training Loss: 1.792e+00, Validation Loss: 1.915e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4128, Training Loss: 1.792e+00, Validation Loss: 1.915e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4129, Training Loss: 1.791e+00, Validation Loss: 1.915e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4130, Training Loss: 1.791e+00, Validation Loss: 1.915e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4131, Training Loss: 1.791e+00, Validation Loss: 1.914e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4132, Training Loss: 1.791e+00, Validation Loss: 1.914e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4133, Training Loss: 1.791e+00, Validation Loss: 1.914e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4134, Training Loss: 1.791e+00, Validation Loss: 1.914e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4135, Training Loss: 1.790e+00, Validation Loss: 1.914e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4136, Training Loss: 1.790e+00, Validation Loss: 1.913e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4137, Training Loss: 1.790e+00, Validation Loss: 1.913e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4138, Training Loss: 1.790e+00, Validation Loss: 1.913e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4139, Training Loss: 1.790e+00, Validation Loss: 1.913e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4140, Training Loss: 1.789e+00, Validation Loss: 1.913e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4141, Training Loss: 1.789e+00, Validation Loss: 1.913e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4142, Training Loss: 1.789e+00, Validation Loss: 1.912e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4143, Training Loss: 1.789e+00, Validation Loss: 1.912e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4144, Training Loss: 1.789e+00, Validation Loss: 1.912e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4145, Training Loss: 1.789e+00, Validation Loss: 1.912e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4146, Training Loss: 1.788e+00, Validation Loss: 1.912e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4147, Training Loss: 1.788e+00, Validation Loss: 1.912e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4148, Training Loss: 1.788e+00, Validation Loss: 1.911e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4149, Training Loss: 1.788e+00, Validation Loss: 1.911e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4150, Training Loss: 1.788e+00, Validation Loss: 1.911e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4151, Training Loss: 1.787e+00, Validation Loss: 1.911e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4152, Training Loss: 1.787e+00, Validation Loss: 1.911e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4153, Training Loss: 1.787e+00, Validation Loss: 1.911e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4154, Training Loss: 1.787e+00, Validation Loss: 1.910e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4155, Training Loss: 1.787e+00, Validation Loss: 1.910e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4156, Training Loss: 1.787e+00, Validation Loss: 1.910e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4157, Training Loss: 1.786e+00, Validation Loss: 1.910e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4158, Training Loss: 1.786e+00, Validation Loss: 1.910e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4159, Training Loss: 1.786e+00, Validation Loss: 1.910e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4160, Training Loss: 1.786e+00, Validation Loss: 1.909e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4161, Training Loss: 1.786e+00, Validation Loss: 1.909e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4162, Training Loss: 1.785e+00, Validation Loss: 1.909e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4163, Training Loss: 1.785e+00, Validation Loss: 1.909e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4164, Training Loss: 1.785e+00, Validation Loss: 1.909e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4165, Training Loss: 1.785e+00, Validation Loss: 1.909e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4166, Training Loss: 1.785e+00, Validation Loss: 1.908e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4167, Training Loss: 1.785e+00, Validation Loss: 1.908e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4168, Training Loss: 1.784e+00, Validation Loss: 1.908e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4169, Training Loss: 1.784e+00, Validation Loss: 1.908e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4170, Training Loss: 1.784e+00, Validation Loss: 1.908e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4171, Training Loss: 1.784e+00, Validation Loss: 1.907e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4172, Training Loss: 1.784e+00, Validation Loss: 1.907e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4173, Training Loss: 1.784e+00, Validation Loss: 1.907e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4174, Training Loss: 1.783e+00, Validation Loss: 1.907e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4175, Training Loss: 1.783e+00, Validation Loss: 1.907e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4176, Training Loss: 1.783e+00, Validation Loss: 1.907e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4177, Training Loss: 1.783e+00, Validation Loss: 1.906e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4178, Training Loss: 1.783e+00, Validation Loss: 1.906e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4179, Training Loss: 1.782e+00, Validation Loss: 1.906e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4180, Training Loss: 1.782e+00, Validation Loss: 1.906e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4181, Training Loss: 1.782e+00, Validation Loss: 1.906e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4182, Training Loss: 1.782e+00, Validation Loss: 1.906e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4183, Training Loss: 1.782e+00, Validation Loss: 1.905e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4184, Training Loss: 1.782e+00, Validation Loss: 1.905e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4185, Training Loss: 1.781e+00, Validation Loss: 1.905e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4186, Training Loss: 1.781e+00, Validation Loss: 1.905e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4187, Training Loss: 1.781e+00, Validation Loss: 1.905e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4188, Training Loss: 1.781e+00, Validation Loss: 1.905e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4189, Training Loss: 1.781e+00, Validation Loss: 1.904e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4190, Training Loss: 1.780e+00, Validation Loss: 1.904e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4191, Training Loss: 1.780e+00, Validation Loss: 1.904e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4192, Training Loss: 1.780e+00, Validation Loss: 1.904e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4193, Training Loss: 1.780e+00, Validation Loss: 1.904e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4194, Training Loss: 1.780e+00, Validation Loss: 1.903e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4195, Training Loss: 1.780e+00, Validation Loss: 1.903e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4196, Training Loss: 1.779e+00, Validation Loss: 1.903e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4197, Training Loss: 1.779e+00, Validation Loss: 1.903e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4198, Training Loss: 1.779e+00, Validation Loss: 1.903e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4199, Training Loss: 1.779e+00, Validation Loss: 1.903e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4200, Training Loss: 1.779e+00, Validation Loss: 1.902e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4201, Training Loss: 1.779e+00, Validation Loss: 1.902e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4202, Training Loss: 1.778e+00, Validation Loss: 1.902e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4203, Training Loss: 1.778e+00, Validation Loss: 1.902e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4204, Training Loss: 1.778e+00, Validation Loss: 1.902e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4205, Training Loss: 1.778e+00, Validation Loss: 1.902e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4206, Training Loss: 1.778e+00, Validation Loss: 1.901e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4207, Training Loss: 1.777e+00, Validation Loss: 1.901e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4208, Training Loss: 1.777e+00, Validation Loss: 1.901e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4209, Training Loss: 1.777e+00, Validation Loss: 1.901e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4210, Training Loss: 1.777e+00, Validation Loss: 1.901e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4211, Training Loss: 1.777e+00, Validation Loss: 1.901e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4212, Training Loss: 1.777e+00, Validation Loss: 1.900e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4213, Training Loss: 1.776e+00, Validation Loss: 1.900e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4214, Training Loss: 1.776e+00, Validation Loss: 1.900e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4215, Training Loss: 1.776e+00, Validation Loss: 1.900e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4216, Training Loss: 1.776e+00, Validation Loss: 1.900e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4217, Training Loss: 1.776e+00, Validation Loss: 1.900e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4218, Training Loss: 1.776e+00, Validation Loss: 1.899e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4219, Training Loss: 1.775e+00, Validation Loss: 1.899e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4220, Training Loss: 1.775e+00, Validation Loss: 1.899e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4221, Training Loss: 1.775e+00, Validation Loss: 1.899e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4222, Training Loss: 1.775e+00, Validation Loss: 1.899e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4223, Training Loss: 1.775e+00, Validation Loss: 1.898e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4224, Training Loss: 1.774e+00, Validation Loss: 1.898e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4225, Training Loss: 1.774e+00, Validation Loss: 1.898e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4226, Training Loss: 1.774e+00, Validation Loss: 1.898e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4227, Training Loss: 1.774e+00, Validation Loss: 1.898e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4228, Training Loss: 1.774e+00, Validation Loss: 1.898e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4229, Training Loss: 1.774e+00, Validation Loss: 1.897e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4230, Training Loss: 1.773e+00, Validation Loss: 1.897e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4231, Training Loss: 1.773e+00, Validation Loss: 1.897e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4232, Training Loss: 1.773e+00, Validation Loss: 1.897e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4233, Training Loss: 1.773e+00, Validation Loss: 1.897e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4234, Training Loss: 1.773e+00, Validation Loss: 1.897e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4235, Training Loss: 1.772e+00, Validation Loss: 1.896e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4236, Training Loss: 1.772e+00, Validation Loss: 1.896e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4237, Training Loss: 1.772e+00, Validation Loss: 1.896e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4238, Training Loss: 1.772e+00, Validation Loss: 1.896e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4239, Training Loss: 1.772e+00, Validation Loss: 1.896e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4240, Training Loss: 1.772e+00, Validation Loss: 1.896e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4241, Training Loss: 1.771e+00, Validation Loss: 1.895e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4242, Training Loss: 1.771e+00, Validation Loss: 1.895e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4243, Training Loss: 1.771e+00, Validation Loss: 1.895e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4244, Training Loss: 1.771e+00, Validation Loss: 1.895e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4245, Training Loss: 1.771e+00, Validation Loss: 1.895e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4246, Training Loss: 1.771e+00, Validation Loss: 1.894e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4247, Training Loss: 1.770e+00, Validation Loss: 1.894e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4248, Training Loss: 1.770e+00, Validation Loss: 1.894e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4249, Training Loss: 1.770e+00, Validation Loss: 1.894e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4250, Training Loss: 1.770e+00, Validation Loss: 1.894e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4251, Training Loss: 1.770e+00, Validation Loss: 1.894e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4252, Training Loss: 1.769e+00, Validation Loss: 1.893e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4253, Training Loss: 1.769e+00, Validation Loss: 1.893e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4254, Training Loss: 1.769e+00, Validation Loss: 1.893e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4255, Training Loss: 1.769e+00, Validation Loss: 1.893e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4256, Training Loss: 1.769e+00, Validation Loss: 1.893e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4257, Training Loss: 1.769e+00, Validation Loss: 1.893e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4258, Training Loss: 1.768e+00, Validation Loss: 1.892e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4259, Training Loss: 1.768e+00, Validation Loss: 1.892e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4260, Training Loss: 1.768e+00, Validation Loss: 1.892e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4261, Training Loss: 1.768e+00, Validation Loss: 1.892e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4262, Training Loss: 1.768e+00, Validation Loss: 1.892e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4263, Training Loss: 1.768e+00, Validation Loss: 1.892e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4264, Training Loss: 1.767e+00, Validation Loss: 1.891e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4265, Training Loss: 1.767e+00, Validation Loss: 1.891e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4266, Training Loss: 1.767e+00, Validation Loss: 1.891e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4267, Training Loss: 1.767e+00, Validation Loss: 1.891e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4268, Training Loss: 1.767e+00, Validation Loss: 1.891e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4269, Training Loss: 1.766e+00, Validation Loss: 1.890e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4270, Training Loss: 1.766e+00, Validation Loss: 1.890e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4271, Training Loss: 1.766e+00, Validation Loss: 1.890e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4272, Training Loss: 1.766e+00, Validation Loss: 1.890e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4273, Training Loss: 1.766e+00, Validation Loss: 1.890e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4274, Training Loss: 1.766e+00, Validation Loss: 1.890e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4275, Training Loss: 1.765e+00, Validation Loss: 1.889e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4276, Training Loss: 1.765e+00, Validation Loss: 1.889e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4277, Training Loss: 1.765e+00, Validation Loss: 1.889e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4278, Training Loss: 1.765e+00, Validation Loss: 1.889e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4279, Training Loss: 1.765e+00, Validation Loss: 1.889e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4280, Training Loss: 1.765e+00, Validation Loss: 1.889e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4281, Training Loss: 1.764e+00, Validation Loss: 1.888e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4282, Training Loss: 1.764e+00, Validation Loss: 1.888e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4283, Training Loss: 1.764e+00, Validation Loss: 1.888e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4284, Training Loss: 1.764e+00, Validation Loss: 1.888e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4285, Training Loss: 1.764e+00, Validation Loss: 1.888e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4286, Training Loss: 1.763e+00, Validation Loss: 1.888e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4287, Training Loss: 1.763e+00, Validation Loss: 1.887e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4288, Training Loss: 1.763e+00, Validation Loss: 1.887e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4289, Training Loss: 1.763e+00, Validation Loss: 1.887e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4290, Training Loss: 1.763e+00, Validation Loss: 1.887e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4291, Training Loss: 1.763e+00, Validation Loss: 1.887e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4292, Training Loss: 1.762e+00, Validation Loss: 1.886e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4293, Training Loss: 1.762e+00, Validation Loss: 1.886e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4294, Training Loss: 1.762e+00, Validation Loss: 1.886e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4295, Training Loss: 1.762e+00, Validation Loss: 1.886e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4296, Training Loss: 1.762e+00, Validation Loss: 1.886e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4297, Training Loss: 1.762e+00, Validation Loss: 1.886e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4298, Training Loss: 1.761e+00, Validation Loss: 1.885e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4299, Training Loss: 1.761e+00, Validation Loss: 1.885e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4300, Training Loss: 1.761e+00, Validation Loss: 1.885e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4301, Training Loss: 1.761e+00, Validation Loss: 1.885e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4302, Training Loss: 1.761e+00, Validation Loss: 1.885e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4303, Training Loss: 1.760e+00, Validation Loss: 1.885e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4304, Training Loss: 1.760e+00, Validation Loss: 1.884e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4305, Training Loss: 1.760e+00, Validation Loss: 1.884e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4306, Training Loss: 1.760e+00, Validation Loss: 1.884e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4307, Training Loss: 1.760e+00, Validation Loss: 1.884e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4308, Training Loss: 1.760e+00, Validation Loss: 1.884e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4309, Training Loss: 1.759e+00, Validation Loss: 1.884e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4310, Training Loss: 1.759e+00, Validation Loss: 1.883e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4311, Training Loss: 1.759e+00, Validation Loss: 1.883e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4312, Training Loss: 1.759e+00, Validation Loss: 1.883e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4313, Training Loss: 1.759e+00, Validation Loss: 1.883e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4314, Training Loss: 1.759e+00, Validation Loss: 1.883e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4315, Training Loss: 1.758e+00, Validation Loss: 1.883e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4316, Training Loss: 1.758e+00, Validation Loss: 1.882e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4317, Training Loss: 1.758e+00, Validation Loss: 1.882e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4318, Training Loss: 1.758e+00, Validation Loss: 1.882e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4319, Training Loss: 1.758e+00, Validation Loss: 1.882e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4320, Training Loss: 1.757e+00, Validation Loss: 1.882e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4321, Training Loss: 1.757e+00, Validation Loss: 1.882e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4322, Training Loss: 1.757e+00, Validation Loss: 1.881e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4323, Training Loss: 1.757e+00, Validation Loss: 1.881e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4324, Training Loss: 1.757e+00, Validation Loss: 1.881e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4325, Training Loss: 1.757e+00, Validation Loss: 1.881e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4326, Training Loss: 1.756e+00, Validation Loss: 1.881e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4327, Training Loss: 1.756e+00, Validation Loss: 1.880e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4328, Training Loss: 1.756e+00, Validation Loss: 1.880e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4329, Training Loss: 1.756e+00, Validation Loss: 1.880e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4330, Training Loss: 1.756e+00, Validation Loss: 1.880e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4331, Training Loss: 1.756e+00, Validation Loss: 1.880e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4332, Training Loss: 1.755e+00, Validation Loss: 1.880e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4333, Training Loss: 1.755e+00, Validation Loss: 1.879e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4334, Training Loss: 1.755e+00, Validation Loss: 1.879e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4335, Training Loss: 1.755e+00, Validation Loss: 1.879e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4336, Training Loss: 1.755e+00, Validation Loss: 1.879e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4337, Training Loss: 1.754e+00, Validation Loss: 1.879e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4338, Training Loss: 1.754e+00, Validation Loss: 1.879e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4339, Training Loss: 1.754e+00, Validation Loss: 1.878e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4340, Training Loss: 1.754e+00, Validation Loss: 1.878e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4341, Training Loss: 1.754e+00, Validation Loss: 1.878e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4342, Training Loss: 1.754e+00, Validation Loss: 1.878e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4343, Training Loss: 1.753e+00, Validation Loss: 1.878e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4344, Training Loss: 1.753e+00, Validation Loss: 1.878e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4345, Training Loss: 1.753e+00, Validation Loss: 1.877e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4346, Training Loss: 1.753e+00, Validation Loss: 1.877e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4347, Training Loss: 1.753e+00, Validation Loss: 1.877e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4348, Training Loss: 1.753e+00, Validation Loss: 1.877e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4349, Training Loss: 1.752e+00, Validation Loss: 1.877e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4350, Training Loss: 1.752e+00, Validation Loss: 1.877e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4351, Training Loss: 1.752e+00, Validation Loss: 1.876e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4352, Training Loss: 1.752e+00, Validation Loss: 1.876e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4353, Training Loss: 1.752e+00, Validation Loss: 1.876e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4354, Training Loss: 1.751e+00, Validation Loss: 1.876e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4355, Training Loss: 1.751e+00, Validation Loss: 1.876e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4356, Training Loss: 1.751e+00, Validation Loss: 1.876e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4357, Training Loss: 1.751e+00, Validation Loss: 1.875e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4358, Training Loss: 1.751e+00, Validation Loss: 1.875e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4359, Training Loss: 1.751e+00, Validation Loss: 1.875e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4360, Training Loss: 1.750e+00, Validation Loss: 1.875e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4361, Training Loss: 1.750e+00, Validation Loss: 1.875e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4362, Training Loss: 1.750e+00, Validation Loss: 1.874e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4363, Training Loss: 1.750e+00, Validation Loss: 1.874e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4364, Training Loss: 1.750e+00, Validation Loss: 1.874e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4365, Training Loss: 1.750e+00, Validation Loss: 1.874e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4366, Training Loss: 1.749e+00, Validation Loss: 1.874e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4367, Training Loss: 1.749e+00, Validation Loss: 1.874e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4368, Training Loss: 1.749e+00, Validation Loss: 1.873e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4369, Training Loss: 1.749e+00, Validation Loss: 1.873e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4370, Training Loss: 1.749e+00, Validation Loss: 1.873e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4371, Training Loss: 1.749e+00, Validation Loss: 1.873e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4372, Training Loss: 1.748e+00, Validation Loss: 1.873e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4373, Training Loss: 1.748e+00, Validation Loss: 1.873e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4374, Training Loss: 1.748e+00, Validation Loss: 1.872e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4375, Training Loss: 1.748e+00, Validation Loss: 1.872e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4376, Training Loss: 1.748e+00, Validation Loss: 1.872e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4377, Training Loss: 1.747e+00, Validation Loss: 1.872e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4378, Training Loss: 1.747e+00, Validation Loss: 1.872e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4379, Training Loss: 1.747e+00, Validation Loss: 1.872e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4380, Training Loss: 1.747e+00, Validation Loss: 1.871e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4381, Training Loss: 1.747e+00, Validation Loss: 1.871e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4382, Training Loss: 1.747e+00, Validation Loss: 1.871e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4383, Training Loss: 1.746e+00, Validation Loss: 1.871e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4384, Training Loss: 1.746e+00, Validation Loss: 1.871e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4385, Training Loss: 1.746e+00, Validation Loss: 1.871e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4386, Training Loss: 1.746e+00, Validation Loss: 1.870e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4387, Training Loss: 1.746e+00, Validation Loss: 1.870e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4388, Training Loss: 1.746e+00, Validation Loss: 1.870e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4389, Training Loss: 1.745e+00, Validation Loss: 1.870e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4390, Training Loss: 1.745e+00, Validation Loss: 1.870e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4391, Training Loss: 1.745e+00, Validation Loss: 1.870e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4392, Training Loss: 1.745e+00, Validation Loss: 1.869e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4393, Training Loss: 1.745e+00, Validation Loss: 1.869e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4394, Training Loss: 1.744e+00, Validation Loss: 1.869e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4395, Training Loss: 1.744e+00, Validation Loss: 1.869e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4396, Training Loss: 1.744e+00, Validation Loss: 1.869e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4397, Training Loss: 1.744e+00, Validation Loss: 1.868e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4398, Training Loss: 1.744e+00, Validation Loss: 1.868e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4399, Training Loss: 1.744e+00, Validation Loss: 1.868e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4400, Training Loss: 1.743e+00, Validation Loss: 1.868e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4401, Training Loss: 1.743e+00, Validation Loss: 1.868e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4402, Training Loss: 1.743e+00, Validation Loss: 1.868e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4403, Training Loss: 1.743e+00, Validation Loss: 1.867e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4404, Training Loss: 1.743e+00, Validation Loss: 1.867e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4405, Training Loss: 1.743e+00, Validation Loss: 1.867e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4406, Training Loss: 1.742e+00, Validation Loss: 1.867e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4407, Training Loss: 1.742e+00, Validation Loss: 1.867e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4408, Training Loss: 1.742e+00, Validation Loss: 1.867e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4409, Training Loss: 1.742e+00, Validation Loss: 1.866e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4410, Training Loss: 1.742e+00, Validation Loss: 1.866e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4411, Training Loss: 1.742e+00, Validation Loss: 1.866e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4412, Training Loss: 1.741e+00, Validation Loss: 1.866e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4413, Training Loss: 1.741e+00, Validation Loss: 1.866e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4414, Training Loss: 1.741e+00, Validation Loss: 1.866e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4415, Training Loss: 1.741e+00, Validation Loss: 1.865e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4416, Training Loss: 1.741e+00, Validation Loss: 1.865e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4417, Training Loss: 1.740e+00, Validation Loss: 1.865e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4418, Training Loss: 1.740e+00, Validation Loss: 1.865e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4419, Training Loss: 1.740e+00, Validation Loss: 1.865e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4420, Training Loss: 1.740e+00, Validation Loss: 1.865e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4421, Training Loss: 1.740e+00, Validation Loss: 1.864e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4422, Training Loss: 1.740e+00, Validation Loss: 1.864e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4423, Training Loss: 1.739e+00, Validation Loss: 1.864e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4424, Training Loss: 1.739e+00, Validation Loss: 1.864e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4425, Training Loss: 1.739e+00, Validation Loss: 1.864e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4426, Training Loss: 1.739e+00, Validation Loss: 1.864e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4427, Training Loss: 1.739e+00, Validation Loss: 1.863e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4428, Training Loss: 1.739e+00, Validation Loss: 1.863e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4429, Training Loss: 1.738e+00, Validation Loss: 1.863e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4430, Training Loss: 1.738e+00, Validation Loss: 1.863e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4431, Training Loss: 1.738e+00, Validation Loss: 1.863e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4432, Training Loss: 1.738e+00, Validation Loss: 1.862e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4433, Training Loss: 1.738e+00, Validation Loss: 1.862e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4434, Training Loss: 1.738e+00, Validation Loss: 1.862e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4435, Training Loss: 1.737e+00, Validation Loss: 1.862e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4436, Training Loss: 1.737e+00, Validation Loss: 1.862e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4437, Training Loss: 1.737e+00, Validation Loss: 1.862e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4438, Training Loss: 1.737e+00, Validation Loss: 1.861e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4439, Training Loss: 1.737e+00, Validation Loss: 1.861e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4440, Training Loss: 1.736e+00, Validation Loss: 1.861e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4441, Training Loss: 1.736e+00, Validation Loss: 1.861e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4442, Training Loss: 1.736e+00, Validation Loss: 1.861e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4443, Training Loss: 1.736e+00, Validation Loss: 1.861e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4444, Training Loss: 1.736e+00, Validation Loss: 1.860e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4445, Training Loss: 1.736e+00, Validation Loss: 1.860e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4446, Training Loss: 1.735e+00, Validation Loss: 1.860e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4447, Training Loss: 1.735e+00, Validation Loss: 1.860e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4448, Training Loss: 1.735e+00, Validation Loss: 1.860e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4449, Training Loss: 1.735e+00, Validation Loss: 1.860e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4450, Training Loss: 1.735e+00, Validation Loss: 1.859e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4451, Training Loss: 1.735e+00, Validation Loss: 1.859e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4452, Training Loss: 1.734e+00, Validation Loss: 1.859e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4453, Training Loss: 1.734e+00, Validation Loss: 1.859e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4454, Training Loss: 1.734e+00, Validation Loss: 1.859e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4455, Training Loss: 1.734e+00, Validation Loss: 1.859e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4456, Training Loss: 1.734e+00, Validation Loss: 1.858e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4457, Training Loss: 1.734e+00, Validation Loss: 1.858e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4458, Training Loss: 1.733e+00, Validation Loss: 1.858e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4459, Training Loss: 1.733e+00, Validation Loss: 1.858e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4460, Training Loss: 1.733e+00, Validation Loss: 1.858e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4461, Training Loss: 1.733e+00, Validation Loss: 1.858e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4462, Training Loss: 1.733e+00, Validation Loss: 1.857e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4463, Training Loss: 1.732e+00, Validation Loss: 1.857e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4464, Training Loss: 1.732e+00, Validation Loss: 1.857e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4465, Training Loss: 1.732e+00, Validation Loss: 1.857e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4466, Training Loss: 1.732e+00, Validation Loss: 1.857e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4467, Training Loss: 1.732e+00, Validation Loss: 1.856e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4468, Training Loss: 1.732e+00, Validation Loss: 1.856e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4469, Training Loss: 1.731e+00, Validation Loss: 1.856e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4470, Training Loss: 1.731e+00, Validation Loss: 1.856e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4471, Training Loss: 1.731e+00, Validation Loss: 1.856e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4472, Training Loss: 1.731e+00, Validation Loss: 1.856e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4473, Training Loss: 1.731e+00, Validation Loss: 1.855e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4474, Training Loss: 1.731e+00, Validation Loss: 1.855e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4475, Training Loss: 1.730e+00, Validation Loss: 1.855e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4476, Training Loss: 1.730e+00, Validation Loss: 1.855e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4477, Training Loss: 1.730e+00, Validation Loss: 1.855e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4478, Training Loss: 1.730e+00, Validation Loss: 1.855e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4479, Training Loss: 1.730e+00, Validation Loss: 1.854e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4480, Training Loss: 1.730e+00, Validation Loss: 1.854e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4481, Training Loss: 1.729e+00, Validation Loss: 1.854e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4482, Training Loss: 1.729e+00, Validation Loss: 1.854e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4483, Training Loss: 1.729e+00, Validation Loss: 1.854e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4484, Training Loss: 1.729e+00, Validation Loss: 1.854e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4485, Training Loss: 1.729e+00, Validation Loss: 1.853e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4486, Training Loss: 1.728e+00, Validation Loss: 1.853e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4487, Training Loss: 1.728e+00, Validation Loss: 1.853e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4488, Training Loss: 1.728e+00, Validation Loss: 1.853e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4489, Training Loss: 1.728e+00, Validation Loss: 1.853e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4490, Training Loss: 1.728e+00, Validation Loss: 1.853e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4491, Training Loss: 1.728e+00, Validation Loss: 1.852e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4492, Training Loss: 1.727e+00, Validation Loss: 1.852e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4493, Training Loss: 1.727e+00, Validation Loss: 1.852e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4494, Training Loss: 1.727e+00, Validation Loss: 1.852e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4495, Training Loss: 1.727e+00, Validation Loss: 1.852e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4496, Training Loss: 1.727e+00, Validation Loss: 1.852e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4497, Training Loss: 1.727e+00, Validation Loss: 1.851e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4498, Training Loss: 1.726e+00, Validation Loss: 1.851e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4499, Training Loss: 1.726e+00, Validation Loss: 1.851e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4500, Training Loss: 1.726e+00, Validation Loss: 1.851e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4501, Training Loss: 1.726e+00, Validation Loss: 1.851e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4502, Training Loss: 1.726e+00, Validation Loss: 1.851e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4503, Training Loss: 1.726e+00, Validation Loss: 1.850e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4504, Training Loss: 1.725e+00, Validation Loss: 1.850e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4505, Training Loss: 1.725e+00, Validation Loss: 1.850e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4506, Training Loss: 1.725e+00, Validation Loss: 1.850e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4507, Training Loss: 1.725e+00, Validation Loss: 1.850e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4508, Training Loss: 1.725e+00, Validation Loss: 1.850e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4509, Training Loss: 1.725e+00, Validation Loss: 1.849e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4510, Training Loss: 1.724e+00, Validation Loss: 1.849e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4511, Training Loss: 1.724e+00, Validation Loss: 1.849e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4512, Training Loss: 1.724e+00, Validation Loss: 1.849e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4513, Training Loss: 1.724e+00, Validation Loss: 1.849e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4514, Training Loss: 1.724e+00, Validation Loss: 1.849e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4515, Training Loss: 1.723e+00, Validation Loss: 1.848e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4516, Training Loss: 1.723e+00, Validation Loss: 1.848e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4517, Training Loss: 1.723e+00, Validation Loss: 1.848e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4518, Training Loss: 1.723e+00, Validation Loss: 1.848e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4519, Training Loss: 1.723e+00, Validation Loss: 1.848e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4520, Training Loss: 1.723e+00, Validation Loss: 1.848e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4521, Training Loss: 1.722e+00, Validation Loss: 1.847e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4522, Training Loss: 1.722e+00, Validation Loss: 1.847e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4523, Training Loss: 1.722e+00, Validation Loss: 1.847e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4524, Training Loss: 1.722e+00, Validation Loss: 1.847e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4525, Training Loss: 1.722e+00, Validation Loss: 1.847e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4526, Training Loss: 1.722e+00, Validation Loss: 1.847e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4527, Training Loss: 1.721e+00, Validation Loss: 1.846e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4528, Training Loss: 1.721e+00, Validation Loss: 1.846e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4529, Training Loss: 1.721e+00, Validation Loss: 1.846e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4530, Training Loss: 1.721e+00, Validation Loss: 1.846e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4531, Training Loss: 1.721e+00, Validation Loss: 1.846e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4532, Training Loss: 1.721e+00, Validation Loss: 1.845e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4533, Training Loss: 1.720e+00, Validation Loss: 1.845e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4534, Training Loss: 1.720e+00, Validation Loss: 1.845e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4535, Training Loss: 1.720e+00, Validation Loss: 1.845e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4536, Training Loss: 1.720e+00, Validation Loss: 1.845e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4537, Training Loss: 1.720e+00, Validation Loss: 1.845e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4538, Training Loss: 1.720e+00, Validation Loss: 1.844e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4539, Training Loss: 1.719e+00, Validation Loss: 1.844e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4540, Training Loss: 1.719e+00, Validation Loss: 1.844e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4541, Training Loss: 1.719e+00, Validation Loss: 1.844e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4542, Training Loss: 1.719e+00, Validation Loss: 1.844e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4543, Training Loss: 1.719e+00, Validation Loss: 1.844e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4544, Training Loss: 1.718e+00, Validation Loss: 1.843e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4545, Training Loss: 1.718e+00, Validation Loss: 1.843e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4546, Training Loss: 1.718e+00, Validation Loss: 1.843e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4547, Training Loss: 1.718e+00, Validation Loss: 1.843e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4548, Training Loss: 1.718e+00, Validation Loss: 1.843e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4549, Training Loss: 1.718e+00, Validation Loss: 1.843e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4550, Training Loss: 1.717e+00, Validation Loss: 1.842e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4551, Training Loss: 1.717e+00, Validation Loss: 1.842e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4552, Training Loss: 1.717e+00, Validation Loss: 1.842e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4553, Training Loss: 1.717e+00, Validation Loss: 1.842e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4554, Training Loss: 1.717e+00, Validation Loss: 1.842e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4555, Training Loss: 1.717e+00, Validation Loss: 1.842e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4556, Training Loss: 1.716e+00, Validation Loss: 1.841e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4557, Training Loss: 1.716e+00, Validation Loss: 1.841e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4558, Training Loss: 1.716e+00, Validation Loss: 1.841e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4559, Training Loss: 1.716e+00, Validation Loss: 1.841e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4560, Training Loss: 1.716e+00, Validation Loss: 1.841e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4561, Training Loss: 1.716e+00, Validation Loss: 1.841e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4562, Training Loss: 1.715e+00, Validation Loss: 1.840e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4563, Training Loss: 1.715e+00, Validation Loss: 1.840e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4564, Training Loss: 1.715e+00, Validation Loss: 1.840e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4565, Training Loss: 1.715e+00, Validation Loss: 1.840e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4566, Training Loss: 1.715e+00, Validation Loss: 1.840e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4567, Training Loss: 1.715e+00, Validation Loss: 1.839e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4568, Training Loss: 1.714e+00, Validation Loss: 1.839e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4569, Training Loss: 1.714e+00, Validation Loss: 1.839e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4570, Training Loss: 1.714e+00, Validation Loss: 1.839e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4571, Training Loss: 1.714e+00, Validation Loss: 1.839e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4572, Training Loss: 1.714e+00, Validation Loss: 1.839e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4573, Training Loss: 1.713e+00, Validation Loss: 1.838e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4574, Training Loss: 1.713e+00, Validation Loss: 1.838e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4575, Training Loss: 1.713e+00, Validation Loss: 1.838e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4576, Training Loss: 1.713e+00, Validation Loss: 1.838e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4577, Training Loss: 1.713e+00, Validation Loss: 1.838e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4578, Training Loss: 1.713e+00, Validation Loss: 1.838e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4579, Training Loss: 1.712e+00, Validation Loss: 1.837e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4580, Training Loss: 1.712e+00, Validation Loss: 1.837e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4581, Training Loss: 1.712e+00, Validation Loss: 1.837e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4582, Training Loss: 1.712e+00, Validation Loss: 1.837e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4583, Training Loss: 1.712e+00, Validation Loss: 1.837e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4584, Training Loss: 1.712e+00, Validation Loss: 1.837e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4585, Training Loss: 1.711e+00, Validation Loss: 1.836e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4586, Training Loss: 1.711e+00, Validation Loss: 1.836e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4587, Training Loss: 1.711e+00, Validation Loss: 1.836e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4588, Training Loss: 1.711e+00, Validation Loss: 1.836e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4589, Training Loss: 1.711e+00, Validation Loss: 1.836e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4590, Training Loss: 1.711e+00, Validation Loss: 1.836e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4591, Training Loss: 1.710e+00, Validation Loss: 1.835e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4592, Training Loss: 1.710e+00, Validation Loss: 1.835e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4593, Training Loss: 1.710e+00, Validation Loss: 1.835e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4594, Training Loss: 1.710e+00, Validation Loss: 1.835e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4595, Training Loss: 1.710e+00, Validation Loss: 1.835e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4596, Training Loss: 1.710e+00, Validation Loss: 1.835e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4597, Training Loss: 1.709e+00, Validation Loss: 1.834e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4598, Training Loss: 1.709e+00, Validation Loss: 1.834e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4599, Training Loss: 1.709e+00, Validation Loss: 1.834e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4600, Training Loss: 1.709e+00, Validation Loss: 1.834e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4601, Training Loss: 1.709e+00, Validation Loss: 1.834e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4602, Training Loss: 1.708e+00, Validation Loss: 1.834e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4603, Training Loss: 1.708e+00, Validation Loss: 1.833e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4604, Training Loss: 1.708e+00, Validation Loss: 1.833e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4605, Training Loss: 1.708e+00, Validation Loss: 1.833e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4606, Training Loss: 1.708e+00, Validation Loss: 1.833e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4607, Training Loss: 1.708e+00, Validation Loss: 1.833e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4608, Training Loss: 1.707e+00, Validation Loss: 1.833e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4609, Training Loss: 1.707e+00, Validation Loss: 1.832e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4610, Training Loss: 1.707e+00, Validation Loss: 1.832e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4611, Training Loss: 1.707e+00, Validation Loss: 1.832e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4612, Training Loss: 1.707e+00, Validation Loss: 1.832e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4613, Training Loss: 1.707e+00, Validation Loss: 1.832e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4614, Training Loss: 1.706e+00, Validation Loss: 1.831e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4615, Training Loss: 1.706e+00, Validation Loss: 1.831e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4616, Training Loss: 1.706e+00, Validation Loss: 1.831e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4617, Training Loss: 1.706e+00, Validation Loss: 1.831e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4618, Training Loss: 1.706e+00, Validation Loss: 1.831e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4619, Training Loss: 1.706e+00, Validation Loss: 1.831e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4620, Training Loss: 1.705e+00, Validation Loss: 1.830e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4621, Training Loss: 1.705e+00, Validation Loss: 1.830e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4622, Training Loss: 1.705e+00, Validation Loss: 1.830e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4623, Training Loss: 1.705e+00, Validation Loss: 1.830e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4624, Training Loss: 1.705e+00, Validation Loss: 1.830e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4625, Training Loss: 1.705e+00, Validation Loss: 1.830e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4626, Training Loss: 1.704e+00, Validation Loss: 1.829e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4627, Training Loss: 1.704e+00, Validation Loss: 1.829e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4628, Training Loss: 1.704e+00, Validation Loss: 1.829e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4629, Training Loss: 1.704e+00, Validation Loss: 1.829e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4630, Training Loss: 1.704e+00, Validation Loss: 1.829e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4631, Training Loss: 1.704e+00, Validation Loss: 1.829e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4632, Training Loss: 1.703e+00, Validation Loss: 1.828e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4633, Training Loss: 1.703e+00, Validation Loss: 1.828e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4634, Training Loss: 1.703e+00, Validation Loss: 1.828e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4635, Training Loss: 1.703e+00, Validation Loss: 1.828e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4636, Training Loss: 1.703e+00, Validation Loss: 1.828e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4637, Training Loss: 1.702e+00, Validation Loss: 1.828e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4638, Training Loss: 1.702e+00, Validation Loss: 1.827e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4639, Training Loss: 1.702e+00, Validation Loss: 1.827e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4640, Training Loss: 1.702e+00, Validation Loss: 1.827e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4641, Training Loss: 1.702e+00, Validation Loss: 1.827e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4642, Training Loss: 1.702e+00, Validation Loss: 1.827e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4643, Training Loss: 1.701e+00, Validation Loss: 1.827e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4644, Training Loss: 1.701e+00, Validation Loss: 1.826e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4645, Training Loss: 1.701e+00, Validation Loss: 1.826e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4646, Training Loss: 1.701e+00, Validation Loss: 1.826e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4647, Training Loss: 1.701e+00, Validation Loss: 1.826e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4648, Training Loss: 1.701e+00, Validation Loss: 1.826e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4649, Training Loss: 1.700e+00, Validation Loss: 1.826e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4650, Training Loss: 1.700e+00, Validation Loss: 1.825e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4651, Training Loss: 1.700e+00, Validation Loss: 1.825e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4652, Training Loss: 1.700e+00, Validation Loss: 1.825e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4653, Training Loss: 1.700e+00, Validation Loss: 1.825e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4654, Training Loss: 1.700e+00, Validation Loss: 1.825e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4655, Training Loss: 1.699e+00, Validation Loss: 1.825e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4656, Training Loss: 1.699e+00, Validation Loss: 1.824e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4657, Training Loss: 1.699e+00, Validation Loss: 1.824e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4658, Training Loss: 1.699e+00, Validation Loss: 1.824e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4659, Training Loss: 1.699e+00, Validation Loss: 1.824e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4660, Training Loss: 1.699e+00, Validation Loss: 1.824e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4661, Training Loss: 1.698e+00, Validation Loss: 1.824e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4662, Training Loss: 1.698e+00, Validation Loss: 1.823e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4663, Training Loss: 1.698e+00, Validation Loss: 1.823e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4664, Training Loss: 1.698e+00, Validation Loss: 1.823e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4665, Training Loss: 1.698e+00, Validation Loss: 1.823e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4666, Training Loss: 1.698e+00, Validation Loss: 1.823e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4667, Training Loss: 1.697e+00, Validation Loss: 1.823e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4668, Training Loss: 1.697e+00, Validation Loss: 1.822e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4669, Training Loss: 1.697e+00, Validation Loss: 1.822e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4670, Training Loss: 1.697e+00, Validation Loss: 1.822e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4671, Training Loss: 1.697e+00, Validation Loss: 1.822e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4672, Training Loss: 1.697e+00, Validation Loss: 1.822e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4673, Training Loss: 1.696e+00, Validation Loss: 1.822e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4674, Training Loss: 1.696e+00, Validation Loss: 1.821e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4675, Training Loss: 1.696e+00, Validation Loss: 1.821e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4676, Training Loss: 1.696e+00, Validation Loss: 1.821e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4677, Training Loss: 1.696e+00, Validation Loss: 1.821e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4678, Training Loss: 1.696e+00, Validation Loss: 1.821e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4679, Training Loss: 1.695e+00, Validation Loss: 1.821e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4680, Training Loss: 1.695e+00, Validation Loss: 1.820e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4681, Training Loss: 1.695e+00, Validation Loss: 1.820e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4682, Training Loss: 1.695e+00, Validation Loss: 1.820e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4683, Training Loss: 1.695e+00, Validation Loss: 1.820e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4684, Training Loss: 1.694e+00, Validation Loss: 1.820e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4685, Training Loss: 1.694e+00, Validation Loss: 1.820e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4686, Training Loss: 1.694e+00, Validation Loss: 1.819e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4687, Training Loss: 1.694e+00, Validation Loss: 1.819e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4688, Training Loss: 1.694e+00, Validation Loss: 1.819e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4689, Training Loss: 1.694e+00, Validation Loss: 1.819e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4690, Training Loss: 1.693e+00, Validation Loss: 1.819e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4691, Training Loss: 1.693e+00, Validation Loss: 1.819e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4692, Training Loss: 1.693e+00, Validation Loss: 1.818e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4693, Training Loss: 1.693e+00, Validation Loss: 1.818e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4694, Training Loss: 1.693e+00, Validation Loss: 1.818e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4695, Training Loss: 1.693e+00, Validation Loss: 1.818e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4696, Training Loss: 1.692e+00, Validation Loss: 1.818e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4697, Training Loss: 1.692e+00, Validation Loss: 1.818e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4698, Training Loss: 1.692e+00, Validation Loss: 1.817e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4699, Training Loss: 1.692e+00, Validation Loss: 1.817e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4700, Training Loss: 1.692e+00, Validation Loss: 1.817e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4701, Training Loss: 1.692e+00, Validation Loss: 1.817e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4702, Training Loss: 1.691e+00, Validation Loss: 1.817e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4703, Training Loss: 1.691e+00, Validation Loss: 1.817e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4704, Training Loss: 1.691e+00, Validation Loss: 1.816e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4705, Training Loss: 1.691e+00, Validation Loss: 1.816e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4706, Training Loss: 1.691e+00, Validation Loss: 1.816e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4707, Training Loss: 1.691e+00, Validation Loss: 1.816e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4708, Training Loss: 1.690e+00, Validation Loss: 1.816e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4709, Training Loss: 1.690e+00, Validation Loss: 1.816e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4710, Training Loss: 1.690e+00, Validation Loss: 1.815e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4711, Training Loss: 1.690e+00, Validation Loss: 1.815e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4712, Training Loss: 1.690e+00, Validation Loss: 1.815e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4713, Training Loss: 1.690e+00, Validation Loss: 1.815e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4714, Training Loss: 1.689e+00, Validation Loss: 1.815e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4715, Training Loss: 1.689e+00, Validation Loss: 1.815e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4716, Training Loss: 1.689e+00, Validation Loss: 1.814e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4717, Training Loss: 1.689e+00, Validation Loss: 1.814e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4718, Training Loss: 1.689e+00, Validation Loss: 1.814e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4719, Training Loss: 1.689e+00, Validation Loss: 1.814e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4720, Training Loss: 1.688e+00, Validation Loss: 1.814e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4721, Training Loss: 1.688e+00, Validation Loss: 1.814e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4722, Training Loss: 1.688e+00, Validation Loss: 1.813e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4723, Training Loss: 1.688e+00, Validation Loss: 1.813e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4724, Training Loss: 1.688e+00, Validation Loss: 1.813e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4725, Training Loss: 1.688e+00, Validation Loss: 1.813e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4726, Training Loss: 1.687e+00, Validation Loss: 1.813e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4727, Training Loss: 1.687e+00, Validation Loss: 1.813e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4728, Training Loss: 1.687e+00, Validation Loss: 1.812e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4729, Training Loss: 1.687e+00, Validation Loss: 1.812e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4730, Training Loss: 1.687e+00, Validation Loss: 1.812e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4731, Training Loss: 1.687e+00, Validation Loss: 1.812e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4732, Training Loss: 1.686e+00, Validation Loss: 1.812e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4733, Training Loss: 1.686e+00, Validation Loss: 1.812e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4734, Training Loss: 1.686e+00, Validation Loss: 1.811e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4735, Training Loss: 1.686e+00, Validation Loss: 1.811e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4736, Training Loss: 1.686e+00, Validation Loss: 1.811e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4737, Training Loss: 1.685e+00, Validation Loss: 1.811e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4738, Training Loss: 1.685e+00, Validation Loss: 1.811e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4739, Training Loss: 1.685e+00, Validation Loss: 1.810e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4740, Training Loss: 1.685e+00, Validation Loss: 1.810e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4741, Training Loss: 1.685e+00, Validation Loss: 1.810e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4742, Training Loss: 1.685e+00, Validation Loss: 1.810e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4743, Training Loss: 1.684e+00, Validation Loss: 1.810e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4744, Training Loss: 1.684e+00, Validation Loss: 1.810e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4745, Training Loss: 1.684e+00, Validation Loss: 1.809e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4746, Training Loss: 1.684e+00, Validation Loss: 1.809e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4747, Training Loss: 1.684e+00, Validation Loss: 1.809e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4748, Training Loss: 1.684e+00, Validation Loss: 1.809e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4749, Training Loss: 1.683e+00, Validation Loss: 1.809e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4750, Training Loss: 1.683e+00, Validation Loss: 1.809e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4751, Training Loss: 1.683e+00, Validation Loss: 1.808e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4752, Training Loss: 1.683e+00, Validation Loss: 1.808e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4753, Training Loss: 1.683e+00, Validation Loss: 1.808e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4754, Training Loss: 1.683e+00, Validation Loss: 1.808e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4755, Training Loss: 1.682e+00, Validation Loss: 1.808e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4756, Training Loss: 1.682e+00, Validation Loss: 1.808e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4757, Training Loss: 1.682e+00, Validation Loss: 1.807e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4758, Training Loss: 1.682e+00, Validation Loss: 1.807e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4759, Training Loss: 1.682e+00, Validation Loss: 1.807e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4760, Training Loss: 1.682e+00, Validation Loss: 1.807e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4761, Training Loss: 1.681e+00, Validation Loss: 1.807e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4762, Training Loss: 1.681e+00, Validation Loss: 1.807e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4763, Training Loss: 1.681e+00, Validation Loss: 1.806e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4764, Training Loss: 1.681e+00, Validation Loss: 1.806e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4765, Training Loss: 1.681e+00, Validation Loss: 1.806e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4766, Training Loss: 1.681e+00, Validation Loss: 1.806e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4767, Training Loss: 1.680e+00, Validation Loss: 1.806e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4768, Training Loss: 1.680e+00, Validation Loss: 1.806e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4769, Training Loss: 1.680e+00, Validation Loss: 1.805e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4770, Training Loss: 1.680e+00, Validation Loss: 1.805e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4771, Training Loss: 1.680e+00, Validation Loss: 1.805e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4772, Training Loss: 1.680e+00, Validation Loss: 1.805e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4773, Training Loss: 1.679e+00, Validation Loss: 1.805e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4774, Training Loss: 1.679e+00, Validation Loss: 1.805e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4775, Training Loss: 1.679e+00, Validation Loss: 1.804e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4776, Training Loss: 1.679e+00, Validation Loss: 1.804e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4777, Training Loss: 1.679e+00, Validation Loss: 1.804e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4778, Training Loss: 1.679e+00, Validation Loss: 1.804e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4779, Training Loss: 1.678e+00, Validation Loss: 1.804e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4780, Training Loss: 1.678e+00, Validation Loss: 1.804e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4781, Training Loss: 1.678e+00, Validation Loss: 1.803e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4782, Training Loss: 1.678e+00, Validation Loss: 1.803e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4783, Training Loss: 1.678e+00, Validation Loss: 1.803e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4784, Training Loss: 1.678e+00, Validation Loss: 1.803e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4785, Training Loss: 1.677e+00, Validation Loss: 1.803e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4786, Training Loss: 1.677e+00, Validation Loss: 1.803e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4787, Training Loss: 1.677e+00, Validation Loss: 1.802e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4788, Training Loss: 1.677e+00, Validation Loss: 1.802e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4789, Training Loss: 1.677e+00, Validation Loss: 1.802e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4790, Training Loss: 1.677e+00, Validation Loss: 1.802e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4791, Training Loss: 1.676e+00, Validation Loss: 1.802e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4792, Training Loss: 1.676e+00, Validation Loss: 1.802e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4793, Training Loss: 1.676e+00, Validation Loss: 1.801e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4794, Training Loss: 1.676e+00, Validation Loss: 1.801e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4795, Training Loss: 1.676e+00, Validation Loss: 1.801e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4796, Training Loss: 1.676e+00, Validation Loss: 1.801e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4797, Training Loss: 1.675e+00, Validation Loss: 1.801e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4798, Training Loss: 1.675e+00, Validation Loss: 1.801e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4799, Training Loss: 1.675e+00, Validation Loss: 1.800e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4800, Training Loss: 1.675e+00, Validation Loss: 1.800e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4801, Training Loss: 1.675e+00, Validation Loss: 1.800e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4802, Training Loss: 1.675e+00, Validation Loss: 1.800e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4803, Training Loss: 1.674e+00, Validation Loss: 1.800e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4804, Training Loss: 1.674e+00, Validation Loss: 1.800e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4805, Training Loss: 1.674e+00, Validation Loss: 1.800e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4806, Training Loss: 1.674e+00, Validation Loss: 1.799e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4807, Training Loss: 1.674e+00, Validation Loss: 1.799e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4808, Training Loss: 1.674e+00, Validation Loss: 1.799e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4809, Training Loss: 1.673e+00, Validation Loss: 1.799e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4810, Training Loss: 1.673e+00, Validation Loss: 1.799e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4811, Training Loss: 1.673e+00, Validation Loss: 1.799e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4812, Training Loss: 1.673e+00, Validation Loss: 1.798e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4813, Training Loss: 1.673e+00, Validation Loss: 1.798e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4814, Training Loss: 1.673e+00, Validation Loss: 1.798e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4815, Training Loss: 1.672e+00, Validation Loss: 1.798e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4816, Training Loss: 1.672e+00, Validation Loss: 1.798e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4817, Training Loss: 1.672e+00, Validation Loss: 1.798e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4818, Training Loss: 1.672e+00, Validation Loss: 1.797e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4819, Training Loss: 1.672e+00, Validation Loss: 1.797e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4820, Training Loss: 1.672e+00, Validation Loss: 1.797e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4821, Training Loss: 1.671e+00, Validation Loss: 1.797e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4822, Training Loss: 1.671e+00, Validation Loss: 1.797e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4823, Training Loss: 1.671e+00, Validation Loss: 1.797e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4824, Training Loss: 1.671e+00, Validation Loss: 1.796e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4825, Training Loss: 1.671e+00, Validation Loss: 1.796e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4826, Training Loss: 1.671e+00, Validation Loss: 1.796e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4827, Training Loss: 1.670e+00, Validation Loss: 1.796e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4828, Training Loss: 1.670e+00, Validation Loss: 1.796e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4829, Training Loss: 1.670e+00, Validation Loss: 1.796e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4830, Training Loss: 1.670e+00, Validation Loss: 1.795e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4831, Training Loss: 1.670e+00, Validation Loss: 1.795e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4832, Training Loss: 1.670e+00, Validation Loss: 1.795e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4833, Training Loss: 1.669e+00, Validation Loss: 1.795e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4834, Training Loss: 1.669e+00, Validation Loss: 1.795e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4835, Training Loss: 1.669e+00, Validation Loss: 1.795e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4836, Training Loss: 1.669e+00, Validation Loss: 1.794e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4837, Training Loss: 1.669e+00, Validation Loss: 1.794e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4838, Training Loss: 1.669e+00, Validation Loss: 1.794e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4839, Training Loss: 1.668e+00, Validation Loss: 1.794e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4840, Training Loss: 1.668e+00, Validation Loss: 1.794e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4841, Training Loss: 1.668e+00, Validation Loss: 1.794e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4842, Training Loss: 1.668e+00, Validation Loss: 1.793e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4843, Training Loss: 1.668e+00, Validation Loss: 1.793e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4844, Training Loss: 1.668e+00, Validation Loss: 1.793e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4845, Training Loss: 1.667e+00, Validation Loss: 1.793e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4846, Training Loss: 1.667e+00, Validation Loss: 1.793e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4847, Training Loss: 1.667e+00, Validation Loss: 1.793e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4848, Training Loss: 1.667e+00, Validation Loss: 1.792e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4849, Training Loss: 1.667e+00, Validation Loss: 1.792e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4850, Training Loss: 1.666e+00, Validation Loss: 1.792e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4851, Training Loss: 1.666e+00, Validation Loss: 1.792e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4852, Training Loss: 1.666e+00, Validation Loss: 1.792e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4853, Training Loss: 1.666e+00, Validation Loss: 1.792e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4854, Training Loss: 1.666e+00, Validation Loss: 1.791e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4855, Training Loss: 1.666e+00, Validation Loss: 1.791e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4856, Training Loss: 1.665e+00, Validation Loss: 1.791e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4857, Training Loss: 1.665e+00, Validation Loss: 1.791e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4858, Training Loss: 1.665e+00, Validation Loss: 1.791e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4859, Training Loss: 1.665e+00, Validation Loss: 1.791e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4860, Training Loss: 1.665e+00, Validation Loss: 1.790e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4861, Training Loss: 1.665e+00, Validation Loss: 1.790e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4862, Training Loss: 1.664e+00, Validation Loss: 1.790e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4863, Training Loss: 1.664e+00, Validation Loss: 1.790e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4864, Training Loss: 1.664e+00, Validation Loss: 1.790e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4865, Training Loss: 1.664e+00, Validation Loss: 1.790e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4866, Training Loss: 1.664e+00, Validation Loss: 1.789e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4867, Training Loss: 1.664e+00, Validation Loss: 1.789e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4868, Training Loss: 1.663e+00, Validation Loss: 1.789e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4869, Training Loss: 1.663e+00, Validation Loss: 1.789e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4870, Training Loss: 1.663e+00, Validation Loss: 1.789e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4871, Training Loss: 1.663e+00, Validation Loss: 1.789e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4872, Training Loss: 1.663e+00, Validation Loss: 1.788e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4873, Training Loss: 1.663e+00, Validation Loss: 1.788e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4874, Training Loss: 1.662e+00, Validation Loss: 1.788e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4875, Training Loss: 1.662e+00, Validation Loss: 1.788e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4876, Training Loss: 1.662e+00, Validation Loss: 1.788e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4877, Training Loss: 1.662e+00, Validation Loss: 1.788e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4878, Training Loss: 1.662e+00, Validation Loss: 1.787e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4879, Training Loss: 1.662e+00, Validation Loss: 1.787e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4880, Training Loss: 1.661e+00, Validation Loss: 1.787e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4881, Training Loss: 1.661e+00, Validation Loss: 1.787e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4882, Training Loss: 1.661e+00, Validation Loss: 1.787e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4883, Training Loss: 1.661e+00, Validation Loss: 1.787e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4884, Training Loss: 1.661e+00, Validation Loss: 1.786e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4885, Training Loss: 1.661e+00, Validation Loss: 1.786e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4886, Training Loss: 1.660e+00, Validation Loss: 1.786e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4887, Training Loss: 1.660e+00, Validation Loss: 1.786e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4888, Training Loss: 1.660e+00, Validation Loss: 1.786e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4889, Training Loss: 1.660e+00, Validation Loss: 1.786e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4890, Training Loss: 1.660e+00, Validation Loss: 1.785e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4891, Training Loss: 1.660e+00, Validation Loss: 1.785e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4892, Training Loss: 1.659e+00, Validation Loss: 1.785e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4893, Training Loss: 1.659e+00, Validation Loss: 1.785e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4894, Training Loss: 1.659e+00, Validation Loss: 1.785e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4895, Training Loss: 1.659e+00, Validation Loss: 1.785e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4896, Training Loss: 1.659e+00, Validation Loss: 1.784e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4897, Training Loss: 1.659e+00, Validation Loss: 1.784e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4898, Training Loss: 1.658e+00, Validation Loss: 1.784e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4899, Training Loss: 1.658e+00, Validation Loss: 1.784e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4900, Training Loss: 1.658e+00, Validation Loss: 1.784e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4901, Training Loss: 1.658e+00, Validation Loss: 1.784e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4902, Training Loss: 1.658e+00, Validation Loss: 1.783e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4903, Training Loss: 1.658e+00, Validation Loss: 1.783e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4904, Training Loss: 1.658e+00, Validation Loss: 1.783e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4905, Training Loss: 1.657e+00, Validation Loss: 1.783e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4906, Training Loss: 1.657e+00, Validation Loss: 1.783e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4907, Training Loss: 1.657e+00, Validation Loss: 1.783e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4908, Training Loss: 1.657e+00, Validation Loss: 1.782e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4909, Training Loss: 1.657e+00, Validation Loss: 1.782e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4910, Training Loss: 1.657e+00, Validation Loss: 1.782e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4911, Training Loss: 1.656e+00, Validation Loss: 1.782e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4912, Training Loss: 1.656e+00, Validation Loss: 1.782e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4913, Training Loss: 1.656e+00, Validation Loss: 1.782e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4914, Training Loss: 1.656e+00, Validation Loss: 1.781e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4915, Training Loss: 1.656e+00, Validation Loss: 1.781e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4916, Training Loss: 1.656e+00, Validation Loss: 1.781e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4917, Training Loss: 1.655e+00, Validation Loss: 1.781e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4918, Training Loss: 1.655e+00, Validation Loss: 1.781e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4919, Training Loss: 1.655e+00, Validation Loss: 1.781e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4920, Training Loss: 1.655e+00, Validation Loss: 1.780e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4921, Training Loss: 1.655e+00, Validation Loss: 1.780e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4922, Training Loss: 1.655e+00, Validation Loss: 1.780e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4923, Training Loss: 1.654e+00, Validation Loss: 1.780e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4924, Training Loss: 1.654e+00, Validation Loss: 1.780e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4925, Training Loss: 1.654e+00, Validation Loss: 1.780e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4926, Training Loss: 1.654e+00, Validation Loss: 1.779e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4927, Training Loss: 1.654e+00, Validation Loss: 1.779e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4928, Training Loss: 1.654e+00, Validation Loss: 1.779e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4929, Training Loss: 1.653e+00, Validation Loss: 1.779e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4930, Training Loss: 1.653e+00, Validation Loss: 1.779e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4931, Training Loss: 1.653e+00, Validation Loss: 1.779e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4932, Training Loss: 1.653e+00, Validation Loss: 1.778e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4933, Training Loss: 1.653e+00, Validation Loss: 1.778e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4934, Training Loss: 1.653e+00, Validation Loss: 1.778e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4935, Training Loss: 1.652e+00, Validation Loss: 1.778e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4936, Training Loss: 1.652e+00, Validation Loss: 1.778e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4937, Training Loss: 1.652e+00, Validation Loss: 1.778e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4938, Training Loss: 1.652e+00, Validation Loss: 1.777e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4939, Training Loss: 1.652e+00, Validation Loss: 1.777e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4940, Training Loss: 1.652e+00, Validation Loss: 1.777e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4941, Training Loss: 1.651e+00, Validation Loss: 1.777e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4942, Training Loss: 1.651e+00, Validation Loss: 1.777e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4943, Training Loss: 1.651e+00, Validation Loss: 1.777e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4944, Training Loss: 1.651e+00, Validation Loss: 1.776e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4945, Training Loss: 1.651e+00, Validation Loss: 1.776e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4946, Training Loss: 1.651e+00, Validation Loss: 1.776e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4947, Training Loss: 1.650e+00, Validation Loss: 1.776e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4948, Training Loss: 1.650e+00, Validation Loss: 1.776e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4949, Training Loss: 1.650e+00, Validation Loss: 1.776e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4950, Training Loss: 1.650e+00, Validation Loss: 1.775e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4951, Training Loss: 1.650e+00, Validation Loss: 1.775e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4952, Training Loss: 1.650e+00, Validation Loss: 1.775e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4953, Training Loss: 1.649e+00, Validation Loss: 1.775e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4954, Training Loss: 1.649e+00, Validation Loss: 1.775e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4955, Training Loss: 1.649e+00, Validation Loss: 1.775e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4956, Training Loss: 1.649e+00, Validation Loss: 1.774e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4957, Training Loss: 1.649e+00, Validation Loss: 1.774e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4958, Training Loss: 1.649e+00, Validation Loss: 1.774e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4959, Training Loss: 1.648e+00, Validation Loss: 1.774e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4960, Training Loss: 1.648e+00, Validation Loss: 1.774e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4961, Training Loss: 1.648e+00, Validation Loss: 1.774e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4962, Training Loss: 1.648e+00, Validation Loss: 1.773e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4963, Training Loss: 1.648e+00, Validation Loss: 1.773e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4964, Training Loss: 1.648e+00, Validation Loss: 1.773e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4965, Training Loss: 1.647e+00, Validation Loss: 1.773e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4966, Training Loss: 1.647e+00, Validation Loss: 1.773e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4967, Training Loss: 1.647e+00, Validation Loss: 1.773e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4968, Training Loss: 1.647e+00, Validation Loss: 1.772e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4969, Training Loss: 1.647e+00, Validation Loss: 1.772e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4970, Training Loss: 1.647e+00, Validation Loss: 1.772e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4971, Training Loss: 1.646e+00, Validation Loss: 1.772e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4972, Training Loss: 1.646e+00, Validation Loss: 1.772e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4973, Training Loss: 1.646e+00, Validation Loss: 1.772e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4974, Training Loss: 1.646e+00, Validation Loss: 1.772e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4975, Training Loss: 1.646e+00, Validation Loss: 1.771e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4976, Training Loss: 1.646e+00, Validation Loss: 1.771e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4977, Training Loss: 1.645e+00, Validation Loss: 1.771e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4978, Training Loss: 1.645e+00, Validation Loss: 1.771e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4979, Training Loss: 1.645e+00, Validation Loss: 1.771e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4980, Training Loss: 1.645e+00, Validation Loss: 1.771e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4981, Training Loss: 1.645e+00, Validation Loss: 1.770e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4982, Training Loss: 1.645e+00, Validation Loss: 1.770e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4983, Training Loss: 1.644e+00, Validation Loss: 1.770e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4984, Training Loss: 1.644e+00, Validation Loss: 1.770e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4985, Training Loss: 1.644e+00, Validation Loss: 1.770e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4986, Training Loss: 1.644e+00, Validation Loss: 1.770e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4987, Training Loss: 1.644e+00, Validation Loss: 1.769e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4988, Training Loss: 1.644e+00, Validation Loss: 1.769e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4989, Training Loss: 1.643e+00, Validation Loss: 1.769e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4990, Training Loss: 1.643e+00, Validation Loss: 1.769e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4991, Training Loss: 1.643e+00, Validation Loss: 1.769e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4992, Training Loss: 1.643e+00, Validation Loss: 1.769e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4993, Training Loss: 1.643e+00, Validation Loss: 1.768e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4994, Training Loss: 1.643e+00, Validation Loss: 1.768e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4995, Training Loss: 1.642e+00, Validation Loss: 1.768e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4996, Training Loss: 1.642e+00, Validation Loss: 1.768e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4997, Training Loss: 1.642e+00, Validation Loss: 1.768e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4998, Training Loss: 1.642e+00, Validation Loss: 1.768e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4999, Training Loss: 1.642e+00, Validation Loss: 1.767e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5000, Training Loss: 1.642e+00, Validation Loss: 1.767e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5001, Training Loss: 1.641e+00, Validation Loss: 1.767e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5002, Training Loss: 1.641e+00, Validation Loss: 1.767e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5003, Training Loss: 1.641e+00, Validation Loss: 1.767e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5004, Training Loss: 1.641e+00, Validation Loss: 1.767e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5005, Training Loss: 1.641e+00, Validation Loss: 1.766e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5006, Training Loss: 1.641e+00, Validation Loss: 1.766e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5007, Training Loss: 1.640e+00, Validation Loss: 1.766e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5008, Training Loss: 1.640e+00, Validation Loss: 1.766e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5009, Training Loss: 1.640e+00, Validation Loss: 1.766e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5010, Training Loss: 1.640e+00, Validation Loss: 1.766e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5011, Training Loss: 1.640e+00, Validation Loss: 1.766e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5012, Training Loss: 1.640e+00, Validation Loss: 1.765e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5013, Training Loss: 1.639e+00, Validation Loss: 1.765e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5014, Training Loss: 1.639e+00, Validation Loss: 1.765e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5015, Training Loss: 1.639e+00, Validation Loss: 1.765e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5016, Training Loss: 1.639e+00, Validation Loss: 1.765e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5017, Training Loss: 1.639e+00, Validation Loss: 1.765e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5018, Training Loss: 1.639e+00, Validation Loss: 1.764e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5019, Training Loss: 1.639e+00, Validation Loss: 1.764e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5020, Training Loss: 1.638e+00, Validation Loss: 1.764e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5021, Training Loss: 1.638e+00, Validation Loss: 1.764e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5022, Training Loss: 1.638e+00, Validation Loss: 1.764e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5023, Training Loss: 1.638e+00, Validation Loss: 1.764e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5024, Training Loss: 1.638e+00, Validation Loss: 1.763e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5025, Training Loss: 1.638e+00, Validation Loss: 1.763e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5026, Training Loss: 1.637e+00, Validation Loss: 1.763e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5027, Training Loss: 1.637e+00, Validation Loss: 1.763e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5028, Training Loss: 1.637e+00, Validation Loss: 1.763e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5029, Training Loss: 1.637e+00, Validation Loss: 1.763e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5030, Training Loss: 1.637e+00, Validation Loss: 1.762e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5031, Training Loss: 1.637e+00, Validation Loss: 1.762e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5032, Training Loss: 1.636e+00, Validation Loss: 1.762e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5033, Training Loss: 1.636e+00, Validation Loss: 1.762e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5034, Training Loss: 1.636e+00, Validation Loss: 1.762e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5035, Training Loss: 1.636e+00, Validation Loss: 1.762e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5036, Training Loss: 1.636e+00, Validation Loss: 1.761e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5037, Training Loss: 1.636e+00, Validation Loss: 1.761e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5038, Training Loss: 1.635e+00, Validation Loss: 1.761e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5039, Training Loss: 1.635e+00, Validation Loss: 1.761e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5040, Training Loss: 1.635e+00, Validation Loss: 1.761e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5041, Training Loss: 1.635e+00, Validation Loss: 1.761e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5042, Training Loss: 1.635e+00, Validation Loss: 1.760e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5043, Training Loss: 1.635e+00, Validation Loss: 1.760e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5044, Training Loss: 1.634e+00, Validation Loss: 1.760e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5045, Training Loss: 1.634e+00, Validation Loss: 1.760e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5046, Training Loss: 1.634e+00, Validation Loss: 1.760e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5047, Training Loss: 1.634e+00, Validation Loss: 1.760e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5048, Training Loss: 1.634e+00, Validation Loss: 1.760e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5049, Training Loss: 1.634e+00, Validation Loss: 1.759e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5050, Training Loss: 1.633e+00, Validation Loss: 1.759e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5051, Training Loss: 1.633e+00, Validation Loss: 1.759e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5052, Training Loss: 1.633e+00, Validation Loss: 1.759e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5053, Training Loss: 1.633e+00, Validation Loss: 1.759e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5054, Training Loss: 1.633e+00, Validation Loss: 1.759e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5055, Training Loss: 1.633e+00, Validation Loss: 1.758e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5056, Training Loss: 1.632e+00, Validation Loss: 1.758e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5057, Training Loss: 1.632e+00, Validation Loss: 1.758e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5058, Training Loss: 1.632e+00, Validation Loss: 1.758e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5059, Training Loss: 1.632e+00, Validation Loss: 1.758e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5060, Training Loss: 1.632e+00, Validation Loss: 1.758e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5061, Training Loss: 1.632e+00, Validation Loss: 1.757e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5062, Training Loss: 1.631e+00, Validation Loss: 1.757e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5063, Training Loss: 1.631e+00, Validation Loss: 1.757e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5064, Training Loss: 1.631e+00, Validation Loss: 1.757e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5065, Training Loss: 1.631e+00, Validation Loss: 1.757e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5066, Training Loss: 1.631e+00, Validation Loss: 1.757e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5067, Training Loss: 1.631e+00, Validation Loss: 1.756e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5068, Training Loss: 1.630e+00, Validation Loss: 1.756e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5069, Training Loss: 1.630e+00, Validation Loss: 1.756e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5070, Training Loss: 1.630e+00, Validation Loss: 1.756e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5071, Training Loss: 1.630e+00, Validation Loss: 1.756e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5072, Training Loss: 1.630e+00, Validation Loss: 1.756e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5073, Training Loss: 1.630e+00, Validation Loss: 1.755e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5074, Training Loss: 1.630e+00, Validation Loss: 1.755e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5075, Training Loss: 1.629e+00, Validation Loss: 1.755e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5076, Training Loss: 1.629e+00, Validation Loss: 1.755e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5077, Training Loss: 1.629e+00, Validation Loss: 1.755e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5078, Training Loss: 1.629e+00, Validation Loss: 1.755e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5079, Training Loss: 1.629e+00, Validation Loss: 1.754e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5080, Training Loss: 1.629e+00, Validation Loss: 1.754e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5081, Training Loss: 1.628e+00, Validation Loss: 1.754e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5082, Training Loss: 1.628e+00, Validation Loss: 1.754e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5083, Training Loss: 1.628e+00, Validation Loss: 1.754e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5084, Training Loss: 1.628e+00, Validation Loss: 1.754e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5085, Training Loss: 1.628e+00, Validation Loss: 1.754e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5086, Training Loss: 1.628e+00, Validation Loss: 1.753e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5087, Training Loss: 1.627e+00, Validation Loss: 1.753e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5088, Training Loss: 1.627e+00, Validation Loss: 1.753e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5089, Training Loss: 1.627e+00, Validation Loss: 1.753e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5090, Training Loss: 1.627e+00, Validation Loss: 1.753e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5091, Training Loss: 1.627e+00, Validation Loss: 1.753e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5092, Training Loss: 1.627e+00, Validation Loss: 1.752e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5093, Training Loss: 1.626e+00, Validation Loss: 1.752e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5094, Training Loss: 1.626e+00, Validation Loss: 1.752e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5095, Training Loss: 1.626e+00, Validation Loss: 1.752e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5096, Training Loss: 1.626e+00, Validation Loss: 1.752e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5097, Training Loss: 1.626e+00, Validation Loss: 1.752e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5098, Training Loss: 1.626e+00, Validation Loss: 1.751e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5099, Training Loss: 1.625e+00, Validation Loss: 1.751e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5100, Training Loss: 1.625e+00, Validation Loss: 1.751e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5101, Training Loss: 1.625e+00, Validation Loss: 1.751e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5102, Training Loss: 1.625e+00, Validation Loss: 1.751e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5103, Training Loss: 1.625e+00, Validation Loss: 1.751e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5104, Training Loss: 1.625e+00, Validation Loss: 1.750e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5105, Training Loss: 1.624e+00, Validation Loss: 1.750e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5106, Training Loss: 1.624e+00, Validation Loss: 1.750e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5107, Training Loss: 1.624e+00, Validation Loss: 1.750e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5108, Training Loss: 1.624e+00, Validation Loss: 1.750e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5109, Training Loss: 1.624e+00, Validation Loss: 1.750e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5110, Training Loss: 1.624e+00, Validation Loss: 1.749e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5111, Training Loss: 1.623e+00, Validation Loss: 1.749e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5112, Training Loss: 1.623e+00, Validation Loss: 1.749e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5113, Training Loss: 1.623e+00, Validation Loss: 1.749e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5114, Training Loss: 1.623e+00, Validation Loss: 1.749e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5115, Training Loss: 1.623e+00, Validation Loss: 1.749e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5116, Training Loss: 1.623e+00, Validation Loss: 1.748e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5117, Training Loss: 1.623e+00, Validation Loss: 1.748e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5118, Training Loss: 1.622e+00, Validation Loss: 1.748e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5119, Training Loss: 1.622e+00, Validation Loss: 1.748e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5120, Training Loss: 1.622e+00, Validation Loss: 1.748e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5121, Training Loss: 1.622e+00, Validation Loss: 1.748e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5122, Training Loss: 1.622e+00, Validation Loss: 1.748e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5123, Training Loss: 1.622e+00, Validation Loss: 1.747e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5124, Training Loss: 1.621e+00, Validation Loss: 1.747e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5125, Training Loss: 1.621e+00, Validation Loss: 1.747e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5126, Training Loss: 1.621e+00, Validation Loss: 1.747e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5127, Training Loss: 1.621e+00, Validation Loss: 1.747e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5128, Training Loss: 1.621e+00, Validation Loss: 1.747e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5129, Training Loss: 1.621e+00, Validation Loss: 1.746e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5130, Training Loss: 1.620e+00, Validation Loss: 1.746e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5131, Training Loss: 1.620e+00, Validation Loss: 1.746e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5132, Training Loss: 1.620e+00, Validation Loss: 1.746e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5133, Training Loss: 1.620e+00, Validation Loss: 1.746e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5134, Training Loss: 1.620e+00, Validation Loss: 1.746e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5135, Training Loss: 1.620e+00, Validation Loss: 1.745e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5136, Training Loss: 1.619e+00, Validation Loss: 1.745e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5137, Training Loss: 1.619e+00, Validation Loss: 1.745e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5138, Training Loss: 1.619e+00, Validation Loss: 1.745e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5139, Training Loss: 1.619e+00, Validation Loss: 1.745e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5140, Training Loss: 1.619e+00, Validation Loss: 1.745e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5141, Training Loss: 1.619e+00, Validation Loss: 1.744e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5142, Training Loss: 1.618e+00, Validation Loss: 1.744e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5143, Training Loss: 1.618e+00, Validation Loss: 1.744e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5144, Training Loss: 1.618e+00, Validation Loss: 1.744e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5145, Training Loss: 1.618e+00, Validation Loss: 1.744e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5146, Training Loss: 1.618e+00, Validation Loss: 1.744e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5147, Training Loss: 1.618e+00, Validation Loss: 1.743e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5148, Training Loss: 1.617e+00, Validation Loss: 1.743e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5149, Training Loss: 1.617e+00, Validation Loss: 1.743e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5150, Training Loss: 1.617e+00, Validation Loss: 1.743e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5151, Training Loss: 1.617e+00, Validation Loss: 1.743e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5152, Training Loss: 1.617e+00, Validation Loss: 1.743e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5153, Training Loss: 1.617e+00, Validation Loss: 1.742e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5154, Training Loss: 1.617e+00, Validation Loss: 1.742e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5155, Training Loss: 1.616e+00, Validation Loss: 1.742e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5156, Training Loss: 1.616e+00, Validation Loss: 1.742e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5157, Training Loss: 1.616e+00, Validation Loss: 1.742e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5158, Training Loss: 1.616e+00, Validation Loss: 1.742e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5159, Training Loss: 1.616e+00, Validation Loss: 1.742e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5160, Training Loss: 1.616e+00, Validation Loss: 1.741e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5161, Training Loss: 1.615e+00, Validation Loss: 1.741e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5162, Training Loss: 1.615e+00, Validation Loss: 1.741e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5163, Training Loss: 1.615e+00, Validation Loss: 1.741e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5164, Training Loss: 1.615e+00, Validation Loss: 1.741e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5165, Training Loss: 1.615e+00, Validation Loss: 1.741e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5166, Training Loss: 1.615e+00, Validation Loss: 1.740e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5167, Training Loss: 1.614e+00, Validation Loss: 1.740e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5168, Training Loss: 1.614e+00, Validation Loss: 1.740e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5169, Training Loss: 1.614e+00, Validation Loss: 1.740e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5170, Training Loss: 1.614e+00, Validation Loss: 1.740e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5171, Training Loss: 1.614e+00, Validation Loss: 1.740e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5172, Training Loss: 1.614e+00, Validation Loss: 1.739e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5173, Training Loss: 1.613e+00, Validation Loss: 1.739e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5174, Training Loss: 1.613e+00, Validation Loss: 1.739e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5175, Training Loss: 1.613e+00, Validation Loss: 1.739e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5176, Training Loss: 1.613e+00, Validation Loss: 1.739e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5177, Training Loss: 1.613e+00, Validation Loss: 1.739e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5178, Training Loss: 1.613e+00, Validation Loss: 1.738e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5179, Training Loss: 1.612e+00, Validation Loss: 1.738e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5180, Training Loss: 1.612e+00, Validation Loss: 1.738e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5181, Training Loss: 1.612e+00, Validation Loss: 1.738e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5182, Training Loss: 1.612e+00, Validation Loss: 1.738e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5183, Training Loss: 1.612e+00, Validation Loss: 1.738e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5184, Training Loss: 1.612e+00, Validation Loss: 1.738e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5185, Training Loss: 1.612e+00, Validation Loss: 1.737e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5186, Training Loss: 1.611e+00, Validation Loss: 1.737e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5187, Training Loss: 1.611e+00, Validation Loss: 1.737e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5188, Training Loss: 1.611e+00, Validation Loss: 1.737e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5189, Training Loss: 1.611e+00, Validation Loss: 1.737e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5190, Training Loss: 1.611e+00, Validation Loss: 1.737e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5191, Training Loss: 1.611e+00, Validation Loss: 1.736e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5192, Training Loss: 1.610e+00, Validation Loss: 1.736e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5193, Training Loss: 1.610e+00, Validation Loss: 1.736e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5194, Training Loss: 1.610e+00, Validation Loss: 1.736e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5195, Training Loss: 1.610e+00, Validation Loss: 1.736e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5196, Training Loss: 1.610e+00, Validation Loss: 1.736e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5197, Training Loss: 1.610e+00, Validation Loss: 1.735e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5198, Training Loss: 1.609e+00, Validation Loss: 1.735e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5199, Training Loss: 1.609e+00, Validation Loss: 1.735e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5200, Training Loss: 1.609e+00, Validation Loss: 1.735e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5201, Training Loss: 1.609e+00, Validation Loss: 1.735e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5202, Training Loss: 1.609e+00, Validation Loss: 1.735e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5203, Training Loss: 1.609e+00, Validation Loss: 1.734e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5204, Training Loss: 1.608e+00, Validation Loss: 1.734e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5205, Training Loss: 1.608e+00, Validation Loss: 1.734e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5206, Training Loss: 1.608e+00, Validation Loss: 1.734e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5207, Training Loss: 1.608e+00, Validation Loss: 1.734e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5208, Training Loss: 1.608e+00, Validation Loss: 1.734e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5209, Training Loss: 1.608e+00, Validation Loss: 1.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5210, Training Loss: 1.607e+00, Validation Loss: 1.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5211, Training Loss: 1.607e+00, Validation Loss: 1.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5212, Training Loss: 1.607e+00, Validation Loss: 1.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5213, Training Loss: 1.607e+00, Validation Loss: 1.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5214, Training Loss: 1.607e+00, Validation Loss: 1.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5215, Training Loss: 1.607e+00, Validation Loss: 1.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5216, Training Loss: 1.607e+00, Validation Loss: 1.732e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5217, Training Loss: 1.606e+00, Validation Loss: 1.732e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5218, Training Loss: 1.606e+00, Validation Loss: 1.732e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5219, Training Loss: 1.606e+00, Validation Loss: 1.732e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5220, Training Loss: 1.606e+00, Validation Loss: 1.732e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5221, Training Loss: 1.606e+00, Validation Loss: 1.732e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5222, Training Loss: 1.606e+00, Validation Loss: 1.731e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5223, Training Loss: 1.605e+00, Validation Loss: 1.731e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5224, Training Loss: 1.605e+00, Validation Loss: 1.731e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5225, Training Loss: 1.605e+00, Validation Loss: 1.731e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5226, Training Loss: 1.605e+00, Validation Loss: 1.731e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5227, Training Loss: 1.605e+00, Validation Loss: 1.731e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5228, Training Loss: 1.605e+00, Validation Loss: 1.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5229, Training Loss: 1.604e+00, Validation Loss: 1.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5230, Training Loss: 1.604e+00, Validation Loss: 1.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5231, Training Loss: 1.604e+00, Validation Loss: 1.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5232, Training Loss: 1.604e+00, Validation Loss: 1.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5233, Training Loss: 1.604e+00, Validation Loss: 1.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5234, Training Loss: 1.604e+00, Validation Loss: 1.729e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5235, Training Loss: 1.603e+00, Validation Loss: 1.729e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5236, Training Loss: 1.603e+00, Validation Loss: 1.729e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5237, Training Loss: 1.603e+00, Validation Loss: 1.729e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5238, Training Loss: 1.603e+00, Validation Loss: 1.729e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5239, Training Loss: 1.603e+00, Validation Loss: 1.729e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5240, Training Loss: 1.603e+00, Validation Loss: 1.729e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5241, Training Loss: 1.603e+00, Validation Loss: 1.728e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5242, Training Loss: 1.602e+00, Validation Loss: 1.728e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5243, Training Loss: 1.602e+00, Validation Loss: 1.728e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5244, Training Loss: 1.602e+00, Validation Loss: 1.728e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5245, Training Loss: 1.602e+00, Validation Loss: 1.728e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5246, Training Loss: 1.602e+00, Validation Loss: 1.728e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5247, Training Loss: 1.602e+00, Validation Loss: 1.727e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5248, Training Loss: 1.601e+00, Validation Loss: 1.727e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5249, Training Loss: 1.601e+00, Validation Loss: 1.727e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5250, Training Loss: 1.601e+00, Validation Loss: 1.727e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5251, Training Loss: 1.601e+00, Validation Loss: 1.727e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5252, Training Loss: 1.601e+00, Validation Loss: 1.727e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5253, Training Loss: 1.601e+00, Validation Loss: 1.726e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5254, Training Loss: 1.600e+00, Validation Loss: 1.726e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5255, Training Loss: 1.600e+00, Validation Loss: 1.726e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5256, Training Loss: 1.600e+00, Validation Loss: 1.726e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5257, Training Loss: 1.600e+00, Validation Loss: 1.726e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5258, Training Loss: 1.600e+00, Validation Loss: 1.726e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5259, Training Loss: 1.600e+00, Validation Loss: 1.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5260, Training Loss: 1.599e+00, Validation Loss: 1.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5261, Training Loss: 1.599e+00, Validation Loss: 1.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5262, Training Loss: 1.599e+00, Validation Loss: 1.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5263, Training Loss: 1.599e+00, Validation Loss: 1.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5264, Training Loss: 1.599e+00, Validation Loss: 1.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5265, Training Loss: 1.599e+00, Validation Loss: 1.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5266, Training Loss: 1.599e+00, Validation Loss: 1.724e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5267, Training Loss: 1.598e+00, Validation Loss: 1.724e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5268, Training Loss: 1.598e+00, Validation Loss: 1.724e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5269, Training Loss: 1.598e+00, Validation Loss: 1.724e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5270, Training Loss: 1.598e+00, Validation Loss: 1.724e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5271, Training Loss: 1.598e+00, Validation Loss: 1.724e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5272, Training Loss: 1.598e+00, Validation Loss: 1.723e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5273, Training Loss: 1.597e+00, Validation Loss: 1.723e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5274, Training Loss: 1.597e+00, Validation Loss: 1.723e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5275, Training Loss: 1.597e+00, Validation Loss: 1.723e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5276, Training Loss: 1.597e+00, Validation Loss: 1.723e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5277, Training Loss: 1.597e+00, Validation Loss: 1.723e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5278, Training Loss: 1.597e+00, Validation Loss: 1.722e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5279, Training Loss: 1.596e+00, Validation Loss: 1.722e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5280, Training Loss: 1.596e+00, Validation Loss: 1.722e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5281, Training Loss: 1.596e+00, Validation Loss: 1.722e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5282, Training Loss: 1.596e+00, Validation Loss: 1.722e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5283, Training Loss: 1.596e+00, Validation Loss: 1.722e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5284, Training Loss: 1.596e+00, Validation Loss: 1.721e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5285, Training Loss: 1.595e+00, Validation Loss: 1.721e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5286, Training Loss: 1.595e+00, Validation Loss: 1.721e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5287, Training Loss: 1.595e+00, Validation Loss: 1.721e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5288, Training Loss: 1.595e+00, Validation Loss: 1.721e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5289, Training Loss: 1.595e+00, Validation Loss: 1.721e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5290, Training Loss: 1.595e+00, Validation Loss: 1.721e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5291, Training Loss: 1.595e+00, Validation Loss: 1.720e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5292, Training Loss: 1.594e+00, Validation Loss: 1.720e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5293, Training Loss: 1.594e+00, Validation Loss: 1.720e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5294, Training Loss: 1.594e+00, Validation Loss: 1.720e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5295, Training Loss: 1.594e+00, Validation Loss: 1.720e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5296, Training Loss: 1.594e+00, Validation Loss: 1.720e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5297, Training Loss: 1.594e+00, Validation Loss: 1.719e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5298, Training Loss: 1.593e+00, Validation Loss: 1.719e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5299, Training Loss: 1.593e+00, Validation Loss: 1.719e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5300, Training Loss: 1.593e+00, Validation Loss: 1.719e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5301, Training Loss: 1.593e+00, Validation Loss: 1.719e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5302, Training Loss: 1.593e+00, Validation Loss: 1.719e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5303, Training Loss: 1.593e+00, Validation Loss: 1.718e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5304, Training Loss: 1.592e+00, Validation Loss: 1.718e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5305, Training Loss: 1.592e+00, Validation Loss: 1.718e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5306, Training Loss: 1.592e+00, Validation Loss: 1.718e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5307, Training Loss: 1.592e+00, Validation Loss: 1.718e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5308, Training Loss: 1.592e+00, Validation Loss: 1.718e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5309, Training Loss: 1.592e+00, Validation Loss: 1.717e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5310, Training Loss: 1.591e+00, Validation Loss: 1.717e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5311, Training Loss: 1.591e+00, Validation Loss: 1.717e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5312, Training Loss: 1.591e+00, Validation Loss: 1.717e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5313, Training Loss: 1.591e+00, Validation Loss: 1.717e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5314, Training Loss: 1.591e+00, Validation Loss: 1.717e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5315, Training Loss: 1.591e+00, Validation Loss: 1.717e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5316, Training Loss: 1.591e+00, Validation Loss: 1.716e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5317, Training Loss: 1.590e+00, Validation Loss: 1.716e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5318, Training Loss: 1.590e+00, Validation Loss: 1.716e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5319, Training Loss: 1.590e+00, Validation Loss: 1.716e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5320, Training Loss: 1.590e+00, Validation Loss: 1.716e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5321, Training Loss: 1.590e+00, Validation Loss: 1.716e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5322, Training Loss: 1.590e+00, Validation Loss: 1.715e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5323, Training Loss: 1.589e+00, Validation Loss: 1.715e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5324, Training Loss: 1.589e+00, Validation Loss: 1.715e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5325, Training Loss: 1.589e+00, Validation Loss: 1.715e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5326, Training Loss: 1.589e+00, Validation Loss: 1.715e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5327, Training Loss: 1.589e+00, Validation Loss: 1.715e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5328, Training Loss: 1.589e+00, Validation Loss: 1.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5329, Training Loss: 1.588e+00, Validation Loss: 1.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5330, Training Loss: 1.588e+00, Validation Loss: 1.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5331, Training Loss: 1.588e+00, Validation Loss: 1.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5332, Training Loss: 1.588e+00, Validation Loss: 1.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5333, Training Loss: 1.588e+00, Validation Loss: 1.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5334, Training Loss: 1.588e+00, Validation Loss: 1.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5335, Training Loss: 1.588e+00, Validation Loss: 1.713e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5336, Training Loss: 1.587e+00, Validation Loss: 1.713e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5337, Training Loss: 1.587e+00, Validation Loss: 1.713e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5338, Training Loss: 1.587e+00, Validation Loss: 1.713e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5339, Training Loss: 1.587e+00, Validation Loss: 1.713e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5340, Training Loss: 1.587e+00, Validation Loss: 1.713e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5341, Training Loss: 1.587e+00, Validation Loss: 1.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5342, Training Loss: 1.586e+00, Validation Loss: 1.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5343, Training Loss: 1.586e+00, Validation Loss: 1.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5344, Training Loss: 1.586e+00, Validation Loss: 1.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5345, Training Loss: 1.586e+00, Validation Loss: 1.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5346, Training Loss: 1.586e+00, Validation Loss: 1.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5347, Training Loss: 1.586e+00, Validation Loss: 1.711e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5348, Training Loss: 1.585e+00, Validation Loss: 1.711e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5349, Training Loss: 1.585e+00, Validation Loss: 1.711e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5350, Training Loss: 1.585e+00, Validation Loss: 1.711e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5351, Training Loss: 1.585e+00, Validation Loss: 1.711e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5352, Training Loss: 1.585e+00, Validation Loss: 1.711e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5353, Training Loss: 1.585e+00, Validation Loss: 1.710e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5354, Training Loss: 1.585e+00, Validation Loss: 1.710e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5355, Training Loss: 1.584e+00, Validation Loss: 1.710e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5356, Training Loss: 1.584e+00, Validation Loss: 1.710e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5357, Training Loss: 1.584e+00, Validation Loss: 1.710e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5358, Training Loss: 1.584e+00, Validation Loss: 1.710e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5359, Training Loss: 1.584e+00, Validation Loss: 1.710e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5360, Training Loss: 1.584e+00, Validation Loss: 1.709e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5361, Training Loss: 1.583e+00, Validation Loss: 1.709e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5362, Training Loss: 1.583e+00, Validation Loss: 1.709e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5363, Training Loss: 1.583e+00, Validation Loss: 1.709e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5364, Training Loss: 1.583e+00, Validation Loss: 1.709e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5365, Training Loss: 1.583e+00, Validation Loss: 1.709e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5366, Training Loss: 1.583e+00, Validation Loss: 1.708e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5367, Training Loss: 1.582e+00, Validation Loss: 1.708e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5368, Training Loss: 1.582e+00, Validation Loss: 1.708e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5369, Training Loss: 1.582e+00, Validation Loss: 1.708e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5370, Training Loss: 1.582e+00, Validation Loss: 1.708e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5371, Training Loss: 1.582e+00, Validation Loss: 1.708e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5372, Training Loss: 1.582e+00, Validation Loss: 1.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5373, Training Loss: 1.582e+00, Validation Loss: 1.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5374, Training Loss: 1.581e+00, Validation Loss: 1.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5375, Training Loss: 1.581e+00, Validation Loss: 1.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5376, Training Loss: 1.581e+00, Validation Loss: 1.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5377, Training Loss: 1.581e+00, Validation Loss: 1.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5378, Training Loss: 1.581e+00, Validation Loss: 1.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5379, Training Loss: 1.581e+00, Validation Loss: 1.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5380, Training Loss: 1.580e+00, Validation Loss: 1.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5381, Training Loss: 1.580e+00, Validation Loss: 1.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5382, Training Loss: 1.580e+00, Validation Loss: 1.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5383, Training Loss: 1.580e+00, Validation Loss: 1.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5384, Training Loss: 1.580e+00, Validation Loss: 1.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5385, Training Loss: 1.580e+00, Validation Loss: 1.705e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5386, Training Loss: 1.579e+00, Validation Loss: 1.705e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5387, Training Loss: 1.579e+00, Validation Loss: 1.705e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5388, Training Loss: 1.579e+00, Validation Loss: 1.705e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5389, Training Loss: 1.579e+00, Validation Loss: 1.705e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5390, Training Loss: 1.579e+00, Validation Loss: 1.705e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5391, Training Loss: 1.579e+00, Validation Loss: 1.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5392, Training Loss: 1.579e+00, Validation Loss: 1.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5393, Training Loss: 1.578e+00, Validation Loss: 1.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5394, Training Loss: 1.578e+00, Validation Loss: 1.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5395, Training Loss: 1.578e+00, Validation Loss: 1.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5396, Training Loss: 1.578e+00, Validation Loss: 1.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5397, Training Loss: 1.578e+00, Validation Loss: 1.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5398, Training Loss: 1.578e+00, Validation Loss: 1.703e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5399, Training Loss: 1.577e+00, Validation Loss: 1.703e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5400, Training Loss: 1.577e+00, Validation Loss: 1.703e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5401, Training Loss: 1.577e+00, Validation Loss: 1.703e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5402, Training Loss: 1.577e+00, Validation Loss: 1.703e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5403, Training Loss: 1.577e+00, Validation Loss: 1.703e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5404, Training Loss: 1.577e+00, Validation Loss: 1.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5405, Training Loss: 1.576e+00, Validation Loss: 1.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5406, Training Loss: 1.576e+00, Validation Loss: 1.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5407, Training Loss: 1.576e+00, Validation Loss: 1.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5408, Training Loss: 1.576e+00, Validation Loss: 1.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5409, Training Loss: 1.576e+00, Validation Loss: 1.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5410, Training Loss: 1.576e+00, Validation Loss: 1.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5411, Training Loss: 1.576e+00, Validation Loss: 1.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5412, Training Loss: 1.575e+00, Validation Loss: 1.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5413, Training Loss: 1.575e+00, Validation Loss: 1.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5414, Training Loss: 1.575e+00, Validation Loss: 1.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5415, Training Loss: 1.575e+00, Validation Loss: 1.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5416, Training Loss: 1.575e+00, Validation Loss: 1.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5417, Training Loss: 1.575e+00, Validation Loss: 1.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5418, Training Loss: 1.574e+00, Validation Loss: 1.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5419, Training Loss: 1.574e+00, Validation Loss: 1.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5420, Training Loss: 1.574e+00, Validation Loss: 1.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5421, Training Loss: 1.574e+00, Validation Loss: 1.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5422, Training Loss: 1.574e+00, Validation Loss: 1.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5423, Training Loss: 1.574e+00, Validation Loss: 1.699e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5424, Training Loss: 1.573e+00, Validation Loss: 1.699e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5425, Training Loss: 1.573e+00, Validation Loss: 1.699e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5426, Training Loss: 1.573e+00, Validation Loss: 1.699e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5427, Training Loss: 1.573e+00, Validation Loss: 1.699e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5428, Training Loss: 1.573e+00, Validation Loss: 1.699e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5429, Training Loss: 1.573e+00, Validation Loss: 1.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5430, Training Loss: 1.573e+00, Validation Loss: 1.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5431, Training Loss: 1.572e+00, Validation Loss: 1.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5432, Training Loss: 1.572e+00, Validation Loss: 1.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5433, Training Loss: 1.572e+00, Validation Loss: 1.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5434, Training Loss: 1.572e+00, Validation Loss: 1.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5435, Training Loss: 1.572e+00, Validation Loss: 1.697e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5436, Training Loss: 1.572e+00, Validation Loss: 1.697e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5437, Training Loss: 1.571e+00, Validation Loss: 1.697e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5438, Training Loss: 1.571e+00, Validation Loss: 1.697e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5439, Training Loss: 1.571e+00, Validation Loss: 1.697e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5440, Training Loss: 1.571e+00, Validation Loss: 1.697e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5441, Training Loss: 1.571e+00, Validation Loss: 1.697e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5442, Training Loss: 1.571e+00, Validation Loss: 1.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5443, Training Loss: 1.570e+00, Validation Loss: 1.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5444, Training Loss: 1.570e+00, Validation Loss: 1.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5445, Training Loss: 1.570e+00, Validation Loss: 1.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5446, Training Loss: 1.570e+00, Validation Loss: 1.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5447, Training Loss: 1.570e+00, Validation Loss: 1.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5448, Training Loss: 1.570e+00, Validation Loss: 1.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5449, Training Loss: 1.570e+00, Validation Loss: 1.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5450, Training Loss: 1.569e+00, Validation Loss: 1.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5451, Training Loss: 1.569e+00, Validation Loss: 1.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5452, Training Loss: 1.569e+00, Validation Loss: 1.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5453, Training Loss: 1.569e+00, Validation Loss: 1.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5454, Training Loss: 1.569e+00, Validation Loss: 1.694e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5455, Training Loss: 1.569e+00, Validation Loss: 1.694e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5456, Training Loss: 1.568e+00, Validation Loss: 1.694e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5457, Training Loss: 1.568e+00, Validation Loss: 1.694e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5458, Training Loss: 1.568e+00, Validation Loss: 1.694e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5459, Training Loss: 1.568e+00, Validation Loss: 1.694e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5460, Training Loss: 1.568e+00, Validation Loss: 1.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5461, Training Loss: 1.568e+00, Validation Loss: 1.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5462, Training Loss: 1.567e+00, Validation Loss: 1.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5463, Training Loss: 1.567e+00, Validation Loss: 1.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5464, Training Loss: 1.567e+00, Validation Loss: 1.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5465, Training Loss: 1.567e+00, Validation Loss: 1.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5466, Training Loss: 1.567e+00, Validation Loss: 1.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5467, Training Loss: 1.567e+00, Validation Loss: 1.692e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5468, Training Loss: 1.567e+00, Validation Loss: 1.692e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5469, Training Loss: 1.566e+00, Validation Loss: 1.692e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5470, Training Loss: 1.566e+00, Validation Loss: 1.692e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5471, Training Loss: 1.566e+00, Validation Loss: 1.692e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5472, Training Loss: 1.566e+00, Validation Loss: 1.692e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5473, Training Loss: 1.566e+00, Validation Loss: 1.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5474, Training Loss: 1.566e+00, Validation Loss: 1.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5475, Training Loss: 1.565e+00, Validation Loss: 1.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5476, Training Loss: 1.565e+00, Validation Loss: 1.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5477, Training Loss: 1.565e+00, Validation Loss: 1.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5478, Training Loss: 1.565e+00, Validation Loss: 1.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5479, Training Loss: 1.565e+00, Validation Loss: 1.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5480, Training Loss: 1.565e+00, Validation Loss: 1.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5481, Training Loss: 1.565e+00, Validation Loss: 1.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5482, Training Loss: 1.564e+00, Validation Loss: 1.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5483, Training Loss: 1.564e+00, Validation Loss: 1.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5484, Training Loss: 1.564e+00, Validation Loss: 1.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5485, Training Loss: 1.564e+00, Validation Loss: 1.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5486, Training Loss: 1.564e+00, Validation Loss: 1.689e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5487, Training Loss: 1.564e+00, Validation Loss: 1.689e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5488, Training Loss: 1.563e+00, Validation Loss: 1.689e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5489, Training Loss: 1.563e+00, Validation Loss: 1.689e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5490, Training Loss: 1.563e+00, Validation Loss: 1.689e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5491, Training Loss: 1.563e+00, Validation Loss: 1.689e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5492, Training Loss: 1.563e+00, Validation Loss: 1.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5493, Training Loss: 1.563e+00, Validation Loss: 1.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5494, Training Loss: 1.562e+00, Validation Loss: 1.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5495, Training Loss: 1.562e+00, Validation Loss: 1.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5496, Training Loss: 1.562e+00, Validation Loss: 1.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5497, Training Loss: 1.562e+00, Validation Loss: 1.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5498, Training Loss: 1.562e+00, Validation Loss: 1.687e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5499, Training Loss: 1.562e+00, Validation Loss: 1.687e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5500, Training Loss: 1.562e+00, Validation Loss: 1.687e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5501, Training Loss: 1.561e+00, Validation Loss: 1.687e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5502, Training Loss: 1.561e+00, Validation Loss: 1.687e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5503, Training Loss: 1.561e+00, Validation Loss: 1.687e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5504, Training Loss: 1.561e+00, Validation Loss: 1.686e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5505, Training Loss: 1.561e+00, Validation Loss: 1.686e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5506, Training Loss: 1.561e+00, Validation Loss: 1.686e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5507, Training Loss: 1.560e+00, Validation Loss: 1.686e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5508, Training Loss: 1.560e+00, Validation Loss: 1.686e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5509, Training Loss: 1.560e+00, Validation Loss: 1.686e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5510, Training Loss: 1.560e+00, Validation Loss: 1.686e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5511, Training Loss: 1.560e+00, Validation Loss: 1.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5512, Training Loss: 1.560e+00, Validation Loss: 1.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5513, Training Loss: 1.560e+00, Validation Loss: 1.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5514, Training Loss: 1.559e+00, Validation Loss: 1.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5515, Training Loss: 1.559e+00, Validation Loss: 1.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5516, Training Loss: 1.559e+00, Validation Loss: 1.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5517, Training Loss: 1.559e+00, Validation Loss: 1.684e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5518, Training Loss: 1.559e+00, Validation Loss: 1.684e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5519, Training Loss: 1.559e+00, Validation Loss: 1.684e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5520, Training Loss: 1.558e+00, Validation Loss: 1.684e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5521, Training Loss: 1.558e+00, Validation Loss: 1.684e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5522, Training Loss: 1.558e+00, Validation Loss: 1.684e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5523, Training Loss: 1.558e+00, Validation Loss: 1.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5524, Training Loss: 1.558e+00, Validation Loss: 1.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5525, Training Loss: 1.558e+00, Validation Loss: 1.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5526, Training Loss: 1.557e+00, Validation Loss: 1.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5527, Training Loss: 1.557e+00, Validation Loss: 1.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5528, Training Loss: 1.557e+00, Validation Loss: 1.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5529, Training Loss: 1.557e+00, Validation Loss: 1.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5530, Training Loss: 1.557e+00, Validation Loss: 1.682e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5531, Training Loss: 1.557e+00, Validation Loss: 1.682e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5532, Training Loss: 1.557e+00, Validation Loss: 1.682e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5533, Training Loss: 1.556e+00, Validation Loss: 1.682e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5534, Training Loss: 1.556e+00, Validation Loss: 1.682e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5535, Training Loss: 1.556e+00, Validation Loss: 1.682e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5536, Training Loss: 1.556e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5537, Training Loss: 1.556e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5538, Training Loss: 1.556e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5539, Training Loss: 1.555e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5540, Training Loss: 1.555e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5541, Training Loss: 1.555e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5542, Training Loss: 1.555e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5543, Training Loss: 1.555e+00, Validation Loss: 1.680e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5544, Training Loss: 1.555e+00, Validation Loss: 1.680e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5545, Training Loss: 1.555e+00, Validation Loss: 1.680e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5546, Training Loss: 1.554e+00, Validation Loss: 1.680e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5547, Training Loss: 1.554e+00, Validation Loss: 1.680e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5548, Training Loss: 1.554e+00, Validation Loss: 1.680e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5549, Training Loss: 1.554e+00, Validation Loss: 1.679e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5550, Training Loss: 1.554e+00, Validation Loss: 1.679e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5551, Training Loss: 1.554e+00, Validation Loss: 1.679e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5552, Training Loss: 1.553e+00, Validation Loss: 1.679e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5553, Training Loss: 1.553e+00, Validation Loss: 1.679e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5554, Training Loss: 1.553e+00, Validation Loss: 1.679e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5555, Training Loss: 1.553e+00, Validation Loss: 1.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5556, Training Loss: 1.553e+00, Validation Loss: 1.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5557, Training Loss: 1.553e+00, Validation Loss: 1.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5558, Training Loss: 1.553e+00, Validation Loss: 1.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5559, Training Loss: 1.552e+00, Validation Loss: 1.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5560, Training Loss: 1.552e+00, Validation Loss: 1.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5561, Training Loss: 1.552e+00, Validation Loss: 1.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5562, Training Loss: 1.552e+00, Validation Loss: 1.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5563, Training Loss: 1.552e+00, Validation Loss: 1.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5564, Training Loss: 1.552e+00, Validation Loss: 1.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5565, Training Loss: 1.551e+00, Validation Loss: 1.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5566, Training Loss: 1.551e+00, Validation Loss: 1.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5567, Training Loss: 1.551e+00, Validation Loss: 1.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5568, Training Loss: 1.551e+00, Validation Loss: 1.676e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5569, Training Loss: 1.551e+00, Validation Loss: 1.676e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5570, Training Loss: 1.551e+00, Validation Loss: 1.676e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5571, Training Loss: 1.550e+00, Validation Loss: 1.676e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5572, Training Loss: 1.550e+00, Validation Loss: 1.676e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5573, Training Loss: 1.550e+00, Validation Loss: 1.676e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5574, Training Loss: 1.550e+00, Validation Loss: 1.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5575, Training Loss: 1.550e+00, Validation Loss: 1.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5576, Training Loss: 1.550e+00, Validation Loss: 1.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5577, Training Loss: 1.550e+00, Validation Loss: 1.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5578, Training Loss: 1.549e+00, Validation Loss: 1.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5579, Training Loss: 1.549e+00, Validation Loss: 1.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5580, Training Loss: 1.549e+00, Validation Loss: 1.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5581, Training Loss: 1.549e+00, Validation Loss: 1.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5582, Training Loss: 1.549e+00, Validation Loss: 1.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5583, Training Loss: 1.549e+00, Validation Loss: 1.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5584, Training Loss: 1.548e+00, Validation Loss: 1.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5585, Training Loss: 1.548e+00, Validation Loss: 1.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5586, Training Loss: 1.548e+00, Validation Loss: 1.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5587, Training Loss: 1.548e+00, Validation Loss: 1.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5588, Training Loss: 1.548e+00, Validation Loss: 1.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5589, Training Loss: 1.548e+00, Validation Loss: 1.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5590, Training Loss: 1.548e+00, Validation Loss: 1.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5591, Training Loss: 1.547e+00, Validation Loss: 1.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5592, Training Loss: 1.547e+00, Validation Loss: 1.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5593, Training Loss: 1.547e+00, Validation Loss: 1.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5594, Training Loss: 1.547e+00, Validation Loss: 1.672e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5595, Training Loss: 1.547e+00, Validation Loss: 1.672e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5596, Training Loss: 1.547e+00, Validation Loss: 1.672e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5597, Training Loss: 1.546e+00, Validation Loss: 1.672e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5598, Training Loss: 1.546e+00, Validation Loss: 1.672e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5599, Training Loss: 1.546e+00, Validation Loss: 1.672e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5600, Training Loss: 1.546e+00, Validation Loss: 1.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5601, Training Loss: 1.546e+00, Validation Loss: 1.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5602, Training Loss: 1.546e+00, Validation Loss: 1.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5603, Training Loss: 1.546e+00, Validation Loss: 1.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5604, Training Loss: 1.545e+00, Validation Loss: 1.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5605, Training Loss: 1.545e+00, Validation Loss: 1.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5606, Training Loss: 1.545e+00, Validation Loss: 1.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5607, Training Loss: 1.545e+00, Validation Loss: 1.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5608, Training Loss: 1.545e+00, Validation Loss: 1.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5609, Training Loss: 1.545e+00, Validation Loss: 1.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5610, Training Loss: 1.544e+00, Validation Loss: 1.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5611, Training Loss: 1.544e+00, Validation Loss: 1.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5612, Training Loss: 1.544e+00, Validation Loss: 1.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5613, Training Loss: 1.544e+00, Validation Loss: 1.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5614, Training Loss: 1.544e+00, Validation Loss: 1.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5615, Training Loss: 1.544e+00, Validation Loss: 1.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5616, Training Loss: 1.544e+00, Validation Loss: 1.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5617, Training Loss: 1.543e+00, Validation Loss: 1.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5618, Training Loss: 1.543e+00, Validation Loss: 1.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5619, Training Loss: 1.543e+00, Validation Loss: 1.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5620, Training Loss: 1.543e+00, Validation Loss: 1.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5621, Training Loss: 1.543e+00, Validation Loss: 1.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5622, Training Loss: 1.543e+00, Validation Loss: 1.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5623, Training Loss: 1.542e+00, Validation Loss: 1.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5624, Training Loss: 1.542e+00, Validation Loss: 1.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5625, Training Loss: 1.542e+00, Validation Loss: 1.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5626, Training Loss: 1.542e+00, Validation Loss: 1.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5627, Training Loss: 1.542e+00, Validation Loss: 1.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5628, Training Loss: 1.542e+00, Validation Loss: 1.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5629, Training Loss: 1.542e+00, Validation Loss: 1.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5630, Training Loss: 1.541e+00, Validation Loss: 1.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5631, Training Loss: 1.541e+00, Validation Loss: 1.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5632, Training Loss: 1.541e+00, Validation Loss: 1.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5633, Training Loss: 1.541e+00, Validation Loss: 1.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5634, Training Loss: 1.541e+00, Validation Loss: 1.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5635, Training Loss: 1.541e+00, Validation Loss: 1.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5636, Training Loss: 1.540e+00, Validation Loss: 1.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5637, Training Loss: 1.540e+00, Validation Loss: 1.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5638, Training Loss: 1.540e+00, Validation Loss: 1.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5639, Training Loss: 1.540e+00, Validation Loss: 1.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5640, Training Loss: 1.540e+00, Validation Loss: 1.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5641, Training Loss: 1.540e+00, Validation Loss: 1.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5642, Training Loss: 1.540e+00, Validation Loss: 1.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5643, Training Loss: 1.539e+00, Validation Loss: 1.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5644, Training Loss: 1.539e+00, Validation Loss: 1.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5645, Training Loss: 1.539e+00, Validation Loss: 1.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5646, Training Loss: 1.539e+00, Validation Loss: 1.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5647, Training Loss: 1.539e+00, Validation Loss: 1.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5648, Training Loss: 1.539e+00, Validation Loss: 1.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5649, Training Loss: 1.538e+00, Validation Loss: 1.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5650, Training Loss: 1.538e+00, Validation Loss: 1.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5651, Training Loss: 1.538e+00, Validation Loss: 1.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5652, Training Loss: 1.538e+00, Validation Loss: 1.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5653, Training Loss: 1.538e+00, Validation Loss: 1.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5654, Training Loss: 1.538e+00, Validation Loss: 1.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5655, Training Loss: 1.538e+00, Validation Loss: 1.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5656, Training Loss: 1.537e+00, Validation Loss: 1.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5657, Training Loss: 1.537e+00, Validation Loss: 1.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5658, Training Loss: 1.537e+00, Validation Loss: 1.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5659, Training Loss: 1.537e+00, Validation Loss: 1.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5660, Training Loss: 1.537e+00, Validation Loss: 1.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5661, Training Loss: 1.537e+00, Validation Loss: 1.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5662, Training Loss: 1.537e+00, Validation Loss: 1.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5663, Training Loss: 1.536e+00, Validation Loss: 1.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5664, Training Loss: 1.536e+00, Validation Loss: 1.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5665, Training Loss: 1.536e+00, Validation Loss: 1.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5666, Training Loss: 1.536e+00, Validation Loss: 1.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5667, Training Loss: 1.536e+00, Validation Loss: 1.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5668, Training Loss: 1.536e+00, Validation Loss: 1.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5669, Training Loss: 1.535e+00, Validation Loss: 1.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5670, Training Loss: 1.535e+00, Validation Loss: 1.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5671, Training Loss: 1.535e+00, Validation Loss: 1.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5672, Training Loss: 1.535e+00, Validation Loss: 1.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5673, Training Loss: 1.535e+00, Validation Loss: 1.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5674, Training Loss: 1.535e+00, Validation Loss: 1.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5675, Training Loss: 1.535e+00, Validation Loss: 1.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5676, Training Loss: 1.534e+00, Validation Loss: 1.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5677, Training Loss: 1.534e+00, Validation Loss: 1.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5678, Training Loss: 1.534e+00, Validation Loss: 1.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5679, Training Loss: 1.534e+00, Validation Loss: 1.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5680, Training Loss: 1.534e+00, Validation Loss: 1.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5681, Training Loss: 1.534e+00, Validation Loss: 1.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5682, Training Loss: 1.533e+00, Validation Loss: 1.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5683, Training Loss: 1.533e+00, Validation Loss: 1.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5684, Training Loss: 1.533e+00, Validation Loss: 1.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5685, Training Loss: 1.533e+00, Validation Loss: 1.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5686, Training Loss: 1.533e+00, Validation Loss: 1.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5687, Training Loss: 1.533e+00, Validation Loss: 1.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5688, Training Loss: 1.533e+00, Validation Loss: 1.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5689, Training Loss: 1.532e+00, Validation Loss: 1.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5690, Training Loss: 1.532e+00, Validation Loss: 1.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5691, Training Loss: 1.532e+00, Validation Loss: 1.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5692, Training Loss: 1.532e+00, Validation Loss: 1.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5693, Training Loss: 1.532e+00, Validation Loss: 1.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5694, Training Loss: 1.532e+00, Validation Loss: 1.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5695, Training Loss: 1.531e+00, Validation Loss: 1.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5696, Training Loss: 1.531e+00, Validation Loss: 1.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5697, Training Loss: 1.531e+00, Validation Loss: 1.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5698, Training Loss: 1.531e+00, Validation Loss: 1.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5699, Training Loss: 1.531e+00, Validation Loss: 1.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5700, Training Loss: 1.531e+00, Validation Loss: 1.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5701, Training Loss: 1.531e+00, Validation Loss: 1.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5702, Training Loss: 1.530e+00, Validation Loss: 1.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5703, Training Loss: 1.530e+00, Validation Loss: 1.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5704, Training Loss: 1.530e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5705, Training Loss: 1.530e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5706, Training Loss: 1.530e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5707, Training Loss: 1.530e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5708, Training Loss: 1.529e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5709, Training Loss: 1.529e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5710, Training Loss: 1.529e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5711, Training Loss: 1.529e+00, Validation Loss: 1.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5712, Training Loss: 1.529e+00, Validation Loss: 1.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5713, Training Loss: 1.529e+00, Validation Loss: 1.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5714, Training Loss: 1.529e+00, Validation Loss: 1.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5715, Training Loss: 1.528e+00, Validation Loss: 1.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5716, Training Loss: 1.528e+00, Validation Loss: 1.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5717, Training Loss: 1.528e+00, Validation Loss: 1.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5718, Training Loss: 1.528e+00, Validation Loss: 1.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5719, Training Loss: 1.528e+00, Validation Loss: 1.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5720, Training Loss: 1.528e+00, Validation Loss: 1.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5721, Training Loss: 1.528e+00, Validation Loss: 1.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5722, Training Loss: 1.527e+00, Validation Loss: 1.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5723, Training Loss: 1.527e+00, Validation Loss: 1.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5724, Training Loss: 1.527e+00, Validation Loss: 1.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5725, Training Loss: 1.527e+00, Validation Loss: 1.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5726, Training Loss: 1.527e+00, Validation Loss: 1.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5727, Training Loss: 1.527e+00, Validation Loss: 1.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5728, Training Loss: 1.526e+00, Validation Loss: 1.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5729, Training Loss: 1.526e+00, Validation Loss: 1.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5730, Training Loss: 1.526e+00, Validation Loss: 1.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5731, Training Loss: 1.526e+00, Validation Loss: 1.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5732, Training Loss: 1.526e+00, Validation Loss: 1.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5733, Training Loss: 1.526e+00, Validation Loss: 1.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5734, Training Loss: 1.526e+00, Validation Loss: 1.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5735, Training Loss: 1.525e+00, Validation Loss: 1.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5736, Training Loss: 1.525e+00, Validation Loss: 1.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5737, Training Loss: 1.525e+00, Validation Loss: 1.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5738, Training Loss: 1.525e+00, Validation Loss: 1.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5739, Training Loss: 1.525e+00, Validation Loss: 1.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5740, Training Loss: 1.525e+00, Validation Loss: 1.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5741, Training Loss: 1.524e+00, Validation Loss: 1.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5742, Training Loss: 1.524e+00, Validation Loss: 1.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5743, Training Loss: 1.524e+00, Validation Loss: 1.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5744, Training Loss: 1.524e+00, Validation Loss: 1.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5745, Training Loss: 1.524e+00, Validation Loss: 1.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5746, Training Loss: 1.524e+00, Validation Loss: 1.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5747, Training Loss: 1.524e+00, Validation Loss: 1.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5748, Training Loss: 1.523e+00, Validation Loss: 1.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5749, Training Loss: 1.523e+00, Validation Loss: 1.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5750, Training Loss: 1.523e+00, Validation Loss: 1.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5751, Training Loss: 1.523e+00, Validation Loss: 1.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5752, Training Loss: 1.523e+00, Validation Loss: 1.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5753, Training Loss: 1.523e+00, Validation Loss: 1.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5754, Training Loss: 1.523e+00, Validation Loss: 1.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5755, Training Loss: 1.522e+00, Validation Loss: 1.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5756, Training Loss: 1.522e+00, Validation Loss: 1.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5757, Training Loss: 1.522e+00, Validation Loss: 1.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5758, Training Loss: 1.522e+00, Validation Loss: 1.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5759, Training Loss: 1.522e+00, Validation Loss: 1.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5760, Training Loss: 1.522e+00, Validation Loss: 1.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5761, Training Loss: 1.521e+00, Validation Loss: 1.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5762, Training Loss: 1.521e+00, Validation Loss: 1.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5763, Training Loss: 1.521e+00, Validation Loss: 1.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5764, Training Loss: 1.521e+00, Validation Loss: 1.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5765, Training Loss: 1.521e+00, Validation Loss: 1.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5766, Training Loss: 1.521e+00, Validation Loss: 1.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5767, Training Loss: 1.521e+00, Validation Loss: 1.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5768, Training Loss: 1.520e+00, Validation Loss: 1.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5769, Training Loss: 1.520e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5770, Training Loss: 1.520e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5771, Training Loss: 1.520e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5772, Training Loss: 1.520e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5773, Training Loss: 1.520e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5774, Training Loss: 1.520e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5775, Training Loss: 1.519e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5776, Training Loss: 1.519e+00, Validation Loss: 1.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5777, Training Loss: 1.519e+00, Validation Loss: 1.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5778, Training Loss: 1.519e+00, Validation Loss: 1.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5779, Training Loss: 1.519e+00, Validation Loss: 1.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5780, Training Loss: 1.519e+00, Validation Loss: 1.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5781, Training Loss: 1.518e+00, Validation Loss: 1.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5782, Training Loss: 1.518e+00, Validation Loss: 1.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5783, Training Loss: 1.518e+00, Validation Loss: 1.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5784, Training Loss: 1.518e+00, Validation Loss: 1.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5785, Training Loss: 1.518e+00, Validation Loss: 1.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5786, Training Loss: 1.518e+00, Validation Loss: 1.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5787, Training Loss: 1.518e+00, Validation Loss: 1.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5788, Training Loss: 1.517e+00, Validation Loss: 1.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5789, Training Loss: 1.517e+00, Validation Loss: 1.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5790, Training Loss: 1.517e+00, Validation Loss: 1.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5791, Training Loss: 1.517e+00, Validation Loss: 1.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5792, Training Loss: 1.517e+00, Validation Loss: 1.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5793, Training Loss: 1.517e+00, Validation Loss: 1.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5794, Training Loss: 1.516e+00, Validation Loss: 1.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5795, Training Loss: 1.516e+00, Validation Loss: 1.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5796, Training Loss: 1.516e+00, Validation Loss: 1.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5797, Training Loss: 1.516e+00, Validation Loss: 1.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5798, Training Loss: 1.516e+00, Validation Loss: 1.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5799, Training Loss: 1.516e+00, Validation Loss: 1.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5800, Training Loss: 1.516e+00, Validation Loss: 1.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5801, Training Loss: 1.515e+00, Validation Loss: 1.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5802, Training Loss: 1.515e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5803, Training Loss: 1.515e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5804, Training Loss: 1.515e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5805, Training Loss: 1.515e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5806, Training Loss: 1.515e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5807, Training Loss: 1.515e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5808, Training Loss: 1.514e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5809, Training Loss: 1.514e+00, Validation Loss: 1.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5810, Training Loss: 1.514e+00, Validation Loss: 1.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5811, Training Loss: 1.514e+00, Validation Loss: 1.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5812, Training Loss: 1.514e+00, Validation Loss: 1.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5813, Training Loss: 1.514e+00, Validation Loss: 1.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5814, Training Loss: 1.513e+00, Validation Loss: 1.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5815, Training Loss: 1.513e+00, Validation Loss: 1.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5816, Training Loss: 1.513e+00, Validation Loss: 1.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5817, Training Loss: 1.513e+00, Validation Loss: 1.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5818, Training Loss: 1.513e+00, Validation Loss: 1.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5819, Training Loss: 1.513e+00, Validation Loss: 1.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5820, Training Loss: 1.513e+00, Validation Loss: 1.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5821, Training Loss: 1.512e+00, Validation Loss: 1.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5822, Training Loss: 1.512e+00, Validation Loss: 1.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5823, Training Loss: 1.512e+00, Validation Loss: 1.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5824, Training Loss: 1.512e+00, Validation Loss: 1.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5825, Training Loss: 1.512e+00, Validation Loss: 1.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5826, Training Loss: 1.512e+00, Validation Loss: 1.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5827, Training Loss: 1.512e+00, Validation Loss: 1.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5828, Training Loss: 1.511e+00, Validation Loss: 1.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5829, Training Loss: 1.511e+00, Validation Loss: 1.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5830, Training Loss: 1.511e+00, Validation Loss: 1.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5831, Training Loss: 1.511e+00, Validation Loss: 1.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5832, Training Loss: 1.511e+00, Validation Loss: 1.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5833, Training Loss: 1.511e+00, Validation Loss: 1.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5834, Training Loss: 1.510e+00, Validation Loss: 1.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5835, Training Loss: 1.510e+00, Validation Loss: 1.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5836, Training Loss: 1.510e+00, Validation Loss: 1.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5837, Training Loss: 1.510e+00, Validation Loss: 1.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5838, Training Loss: 1.510e+00, Validation Loss: 1.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5839, Training Loss: 1.510e+00, Validation Loss: 1.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5840, Training Loss: 1.510e+00, Validation Loss: 1.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5841, Training Loss: 1.509e+00, Validation Loss: 1.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5842, Training Loss: 1.509e+00, Validation Loss: 1.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5843, Training Loss: 1.509e+00, Validation Loss: 1.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5844, Training Loss: 1.509e+00, Validation Loss: 1.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5845, Training Loss: 1.509e+00, Validation Loss: 1.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5846, Training Loss: 1.509e+00, Validation Loss: 1.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5847, Training Loss: 1.509e+00, Validation Loss: 1.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5848, Training Loss: 1.508e+00, Validation Loss: 1.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5849, Training Loss: 1.508e+00, Validation Loss: 1.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5850, Training Loss: 1.508e+00, Validation Loss: 1.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5851, Training Loss: 1.508e+00, Validation Loss: 1.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5852, Training Loss: 1.508e+00, Validation Loss: 1.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5853, Training Loss: 1.508e+00, Validation Loss: 1.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5854, Training Loss: 1.508e+00, Validation Loss: 1.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5855, Training Loss: 1.507e+00, Validation Loss: 1.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5856, Training Loss: 1.507e+00, Validation Loss: 1.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5857, Training Loss: 1.507e+00, Validation Loss: 1.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5858, Training Loss: 1.507e+00, Validation Loss: 1.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5859, Training Loss: 1.507e+00, Validation Loss: 1.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5860, Training Loss: 1.507e+00, Validation Loss: 1.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5861, Training Loss: 1.506e+00, Validation Loss: 1.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5862, Training Loss: 1.506e+00, Validation Loss: 1.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5863, Training Loss: 1.506e+00, Validation Loss: 1.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5864, Training Loss: 1.506e+00, Validation Loss: 1.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5865, Training Loss: 1.506e+00, Validation Loss: 1.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5866, Training Loss: 1.506e+00, Validation Loss: 1.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5867, Training Loss: 1.506e+00, Validation Loss: 1.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5868, Training Loss: 1.505e+00, Validation Loss: 1.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5869, Training Loss: 1.505e+00, Validation Loss: 1.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5870, Training Loss: 1.505e+00, Validation Loss: 1.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5871, Training Loss: 1.505e+00, Validation Loss: 1.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5872, Training Loss: 1.505e+00, Validation Loss: 1.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5873, Training Loss: 1.505e+00, Validation Loss: 1.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5874, Training Loss: 1.505e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5875, Training Loss: 1.504e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5876, Training Loss: 1.504e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5877, Training Loss: 1.504e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5878, Training Loss: 1.504e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5879, Training Loss: 1.504e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5880, Training Loss: 1.504e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5881, Training Loss: 1.503e+00, Validation Loss: 1.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5882, Training Loss: 1.503e+00, Validation Loss: 1.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5883, Training Loss: 1.503e+00, Validation Loss: 1.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5884, Training Loss: 1.503e+00, Validation Loss: 1.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5885, Training Loss: 1.503e+00, Validation Loss: 1.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5886, Training Loss: 1.503e+00, Validation Loss: 1.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5887, Training Loss: 1.503e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5888, Training Loss: 1.502e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5889, Training Loss: 1.502e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5890, Training Loss: 1.502e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5891, Training Loss: 1.502e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5892, Training Loss: 1.502e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5893, Training Loss: 1.502e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5894, Training Loss: 1.502e+00, Validation Loss: 1.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5895, Training Loss: 1.501e+00, Validation Loss: 1.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5896, Training Loss: 1.501e+00, Validation Loss: 1.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5897, Training Loss: 1.501e+00, Validation Loss: 1.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5898, Training Loss: 1.501e+00, Validation Loss: 1.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5899, Training Loss: 1.501e+00, Validation Loss: 1.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5900, Training Loss: 1.501e+00, Validation Loss: 1.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5901, Training Loss: 1.501e+00, Validation Loss: 1.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5902, Training Loss: 1.500e+00, Validation Loss: 1.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5903, Training Loss: 1.500e+00, Validation Loss: 1.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5904, Training Loss: 1.500e+00, Validation Loss: 1.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5905, Training Loss: 1.500e+00, Validation Loss: 1.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5906, Training Loss: 1.500e+00, Validation Loss: 1.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5907, Training Loss: 1.500e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5908, Training Loss: 1.499e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5909, Training Loss: 1.499e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5910, Training Loss: 1.499e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5911, Training Loss: 1.499e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5912, Training Loss: 1.499e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5913, Training Loss: 1.499e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5914, Training Loss: 1.499e+00, Validation Loss: 1.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5915, Training Loss: 1.498e+00, Validation Loss: 1.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5916, Training Loss: 1.498e+00, Validation Loss: 1.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5917, Training Loss: 1.498e+00, Validation Loss: 1.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5918, Training Loss: 1.498e+00, Validation Loss: 1.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5919, Training Loss: 1.498e+00, Validation Loss: 1.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5920, Training Loss: 1.498e+00, Validation Loss: 1.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5921, Training Loss: 1.498e+00, Validation Loss: 1.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5922, Training Loss: 1.497e+00, Validation Loss: 1.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5923, Training Loss: 1.497e+00, Validation Loss: 1.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5924, Training Loss: 1.497e+00, Validation Loss: 1.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5925, Training Loss: 1.497e+00, Validation Loss: 1.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5926, Training Loss: 1.497e+00, Validation Loss: 1.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5927, Training Loss: 1.497e+00, Validation Loss: 1.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5928, Training Loss: 1.497e+00, Validation Loss: 1.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5929, Training Loss: 1.496e+00, Validation Loss: 1.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5930, Training Loss: 1.496e+00, Validation Loss: 1.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5931, Training Loss: 1.496e+00, Validation Loss: 1.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5932, Training Loss: 1.496e+00, Validation Loss: 1.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5933, Training Loss: 1.496e+00, Validation Loss: 1.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5934, Training Loss: 1.496e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5935, Training Loss: 1.495e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5936, Training Loss: 1.495e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5937, Training Loss: 1.495e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5938, Training Loss: 1.495e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5939, Training Loss: 1.495e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5940, Training Loss: 1.495e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5941, Training Loss: 1.495e+00, Validation Loss: 1.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5942, Training Loss: 1.494e+00, Validation Loss: 1.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5943, Training Loss: 1.494e+00, Validation Loss: 1.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5944, Training Loss: 1.494e+00, Validation Loss: 1.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5945, Training Loss: 1.494e+00, Validation Loss: 1.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5946, Training Loss: 1.494e+00, Validation Loss: 1.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5947, Training Loss: 1.494e+00, Validation Loss: 1.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5948, Training Loss: 1.494e+00, Validation Loss: 1.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5949, Training Loss: 1.493e+00, Validation Loss: 1.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5950, Training Loss: 1.493e+00, Validation Loss: 1.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5951, Training Loss: 1.493e+00, Validation Loss: 1.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5952, Training Loss: 1.493e+00, Validation Loss: 1.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5953, Training Loss: 1.493e+00, Validation Loss: 1.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5954, Training Loss: 1.493e+00, Validation Loss: 1.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5955, Training Loss: 1.493e+00, Validation Loss: 1.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5956, Training Loss: 1.492e+00, Validation Loss: 1.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5957, Training Loss: 1.492e+00, Validation Loss: 1.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5958, Training Loss: 1.492e+00, Validation Loss: 1.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5959, Training Loss: 1.492e+00, Validation Loss: 1.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5960, Training Loss: 1.492e+00, Validation Loss: 1.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5961, Training Loss: 1.492e+00, Validation Loss: 1.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5962, Training Loss: 1.491e+00, Validation Loss: 1.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5963, Training Loss: 1.491e+00, Validation Loss: 1.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5964, Training Loss: 1.491e+00, Validation Loss: 1.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5965, Training Loss: 1.491e+00, Validation Loss: 1.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5966, Training Loss: 1.491e+00, Validation Loss: 1.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5967, Training Loss: 1.491e+00, Validation Loss: 1.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5968, Training Loss: 1.491e+00, Validation Loss: 1.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5969, Training Loss: 1.490e+00, Validation Loss: 1.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5970, Training Loss: 1.490e+00, Validation Loss: 1.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5971, Training Loss: 1.490e+00, Validation Loss: 1.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5972, Training Loss: 1.490e+00, Validation Loss: 1.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5973, Training Loss: 1.490e+00, Validation Loss: 1.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5974, Training Loss: 1.490e+00, Validation Loss: 1.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5975, Training Loss: 1.490e+00, Validation Loss: 1.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5976, Training Loss: 1.489e+00, Validation Loss: 1.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5977, Training Loss: 1.489e+00, Validation Loss: 1.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5978, Training Loss: 1.489e+00, Validation Loss: 1.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5979, Training Loss: 1.489e+00, Validation Loss: 1.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5980, Training Loss: 1.489e+00, Validation Loss: 1.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5981, Training Loss: 1.489e+00, Validation Loss: 1.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5982, Training Loss: 1.489e+00, Validation Loss: 1.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5983, Training Loss: 1.488e+00, Validation Loss: 1.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5984, Training Loss: 1.488e+00, Validation Loss: 1.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5985, Training Loss: 1.488e+00, Validation Loss: 1.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5986, Training Loss: 1.488e+00, Validation Loss: 1.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5987, Training Loss: 1.488e+00, Validation Loss: 1.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5988, Training Loss: 1.488e+00, Validation Loss: 1.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5989, Training Loss: 1.488e+00, Validation Loss: 1.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5990, Training Loss: 1.487e+00, Validation Loss: 1.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5991, Training Loss: 1.487e+00, Validation Loss: 1.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5992, Training Loss: 1.487e+00, Validation Loss: 1.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5993, Training Loss: 1.487e+00, Validation Loss: 1.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5994, Training Loss: 1.487e+00, Validation Loss: 1.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5995, Training Loss: 1.487e+00, Validation Loss: 1.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5996, Training Loss: 1.486e+00, Validation Loss: 1.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5997, Training Loss: 1.486e+00, Validation Loss: 1.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5998, Training Loss: 1.486e+00, Validation Loss: 1.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5999, Training Loss: 1.486e+00, Validation Loss: 1.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6000, Training Loss: 1.486e+00, Validation Loss: 1.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6001, Training Loss: 1.486e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6002, Training Loss: 1.486e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6003, Training Loss: 1.485e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6004, Training Loss: 1.485e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6005, Training Loss: 1.485e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6006, Training Loss: 1.485e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6007, Training Loss: 1.485e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6008, Training Loss: 1.485e+00, Validation Loss: 1.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6009, Training Loss: 1.485e+00, Validation Loss: 1.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6010, Training Loss: 1.484e+00, Validation Loss: 1.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6011, Training Loss: 1.484e+00, Validation Loss: 1.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6012, Training Loss: 1.484e+00, Validation Loss: 1.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6013, Training Loss: 1.484e+00, Validation Loss: 1.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6014, Training Loss: 1.484e+00, Validation Loss: 1.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6015, Training Loss: 1.484e+00, Validation Loss: 1.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6016, Training Loss: 1.484e+00, Validation Loss: 1.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6017, Training Loss: 1.483e+00, Validation Loss: 1.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6018, Training Loss: 1.483e+00, Validation Loss: 1.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6019, Training Loss: 1.483e+00, Validation Loss: 1.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6020, Training Loss: 1.483e+00, Validation Loss: 1.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6021, Training Loss: 1.483e+00, Validation Loss: 1.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6022, Training Loss: 1.483e+00, Validation Loss: 1.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6023, Training Loss: 1.483e+00, Validation Loss: 1.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6024, Training Loss: 1.482e+00, Validation Loss: 1.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6025, Training Loss: 1.482e+00, Validation Loss: 1.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6026, Training Loss: 1.482e+00, Validation Loss: 1.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6027, Training Loss: 1.482e+00, Validation Loss: 1.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6028, Training Loss: 1.482e+00, Validation Loss: 1.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6029, Training Loss: 1.482e+00, Validation Loss: 1.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6030, Training Loss: 1.482e+00, Validation Loss: 1.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6031, Training Loss: 1.481e+00, Validation Loss: 1.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6032, Training Loss: 1.481e+00, Validation Loss: 1.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6033, Training Loss: 1.481e+00, Validation Loss: 1.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6034, Training Loss: 1.481e+00, Validation Loss: 1.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6035, Training Loss: 1.481e+00, Validation Loss: 1.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6036, Training Loss: 1.481e+00, Validation Loss: 1.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6037, Training Loss: 1.480e+00, Validation Loss: 1.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6038, Training Loss: 1.480e+00, Validation Loss: 1.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6039, Training Loss: 1.480e+00, Validation Loss: 1.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6040, Training Loss: 1.480e+00, Validation Loss: 1.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6041, Training Loss: 1.480e+00, Validation Loss: 1.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6042, Training Loss: 1.480e+00, Validation Loss: 1.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6043, Training Loss: 1.480e+00, Validation Loss: 1.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6044, Training Loss: 1.479e+00, Validation Loss: 1.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6045, Training Loss: 1.479e+00, Validation Loss: 1.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6046, Training Loss: 1.479e+00, Validation Loss: 1.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6047, Training Loss: 1.479e+00, Validation Loss: 1.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6048, Training Loss: 1.479e+00, Validation Loss: 1.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6049, Training Loss: 1.479e+00, Validation Loss: 1.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6050, Training Loss: 1.479e+00, Validation Loss: 1.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6051, Training Loss: 1.478e+00, Validation Loss: 1.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6052, Training Loss: 1.478e+00, Validation Loss: 1.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6053, Training Loss: 1.478e+00, Validation Loss: 1.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6054, Training Loss: 1.478e+00, Validation Loss: 1.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6055, Training Loss: 1.478e+00, Validation Loss: 1.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6056, Training Loss: 1.478e+00, Validation Loss: 1.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6057, Training Loss: 1.478e+00, Validation Loss: 1.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6058, Training Loss: 1.477e+00, Validation Loss: 1.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6059, Training Loss: 1.477e+00, Validation Loss: 1.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6060, Training Loss: 1.477e+00, Validation Loss: 1.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6061, Training Loss: 1.477e+00, Validation Loss: 1.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6062, Training Loss: 1.477e+00, Validation Loss: 1.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6063, Training Loss: 1.477e+00, Validation Loss: 1.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6064, Training Loss: 1.477e+00, Validation Loss: 1.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6065, Training Loss: 1.476e+00, Validation Loss: 1.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6066, Training Loss: 1.476e+00, Validation Loss: 1.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6067, Training Loss: 1.476e+00, Validation Loss: 1.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6068, Training Loss: 1.476e+00, Validation Loss: 1.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6069, Training Loss: 1.476e+00, Validation Loss: 1.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6070, Training Loss: 1.476e+00, Validation Loss: 1.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6071, Training Loss: 1.476e+00, Validation Loss: 1.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6072, Training Loss: 1.475e+00, Validation Loss: 1.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6073, Training Loss: 1.475e+00, Validation Loss: 1.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6074, Training Loss: 1.475e+00, Validation Loss: 1.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6075, Training Loss: 1.475e+00, Validation Loss: 1.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6076, Training Loss: 1.475e+00, Validation Loss: 1.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6077, Training Loss: 1.475e+00, Validation Loss: 1.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6078, Training Loss: 1.474e+00, Validation Loss: 1.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6079, Training Loss: 1.474e+00, Validation Loss: 1.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6080, Training Loss: 1.474e+00, Validation Loss: 1.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6081, Training Loss: 1.474e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6082, Training Loss: 1.474e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6083, Training Loss: 1.474e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6084, Training Loss: 1.474e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6085, Training Loss: 1.473e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6086, Training Loss: 1.473e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6087, Training Loss: 1.473e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6088, Training Loss: 1.473e+00, Validation Loss: 1.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6089, Training Loss: 1.473e+00, Validation Loss: 1.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6090, Training Loss: 1.473e+00, Validation Loss: 1.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6091, Training Loss: 1.473e+00, Validation Loss: 1.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6092, Training Loss: 1.472e+00, Validation Loss: 1.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6093, Training Loss: 1.472e+00, Validation Loss: 1.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6094, Training Loss: 1.472e+00, Validation Loss: 1.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6095, Training Loss: 1.472e+00, Validation Loss: 1.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6096, Training Loss: 1.472e+00, Validation Loss: 1.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6097, Training Loss: 1.472e+00, Validation Loss: 1.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6098, Training Loss: 1.472e+00, Validation Loss: 1.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6099, Training Loss: 1.471e+00, Validation Loss: 1.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6100, Training Loss: 1.471e+00, Validation Loss: 1.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6101, Training Loss: 1.471e+00, Validation Loss: 1.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6102, Training Loss: 1.471e+00, Validation Loss: 1.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6103, Training Loss: 1.471e+00, Validation Loss: 1.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6104, Training Loss: 1.471e+00, Validation Loss: 1.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6105, Training Loss: 1.471e+00, Validation Loss: 1.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6106, Training Loss: 1.470e+00, Validation Loss: 1.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6107, Training Loss: 1.470e+00, Validation Loss: 1.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6108, Training Loss: 1.470e+00, Validation Loss: 1.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6109, Training Loss: 1.470e+00, Validation Loss: 1.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6110, Training Loss: 1.470e+00, Validation Loss: 1.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6111, Training Loss: 1.470e+00, Validation Loss: 1.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6112, Training Loss: 1.470e+00, Validation Loss: 1.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6113, Training Loss: 1.469e+00, Validation Loss: 1.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6114, Training Loss: 1.469e+00, Validation Loss: 1.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6115, Training Loss: 1.469e+00, Validation Loss: 1.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6116, Training Loss: 1.469e+00, Validation Loss: 1.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6117, Training Loss: 1.469e+00, Validation Loss: 1.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6118, Training Loss: 1.469e+00, Validation Loss: 1.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6119, Training Loss: 1.469e+00, Validation Loss: 1.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6120, Training Loss: 1.468e+00, Validation Loss: 1.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6121, Training Loss: 1.468e+00, Validation Loss: 1.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6122, Training Loss: 1.468e+00, Validation Loss: 1.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6123, Training Loss: 1.468e+00, Validation Loss: 1.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6124, Training Loss: 1.468e+00, Validation Loss: 1.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6125, Training Loss: 1.468e+00, Validation Loss: 1.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6126, Training Loss: 1.468e+00, Validation Loss: 1.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6127, Training Loss: 1.467e+00, Validation Loss: 1.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6128, Training Loss: 1.467e+00, Validation Loss: 1.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6129, Training Loss: 1.467e+00, Validation Loss: 1.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6130, Training Loss: 1.467e+00, Validation Loss: 1.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6131, Training Loss: 1.467e+00, Validation Loss: 1.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6132, Training Loss: 1.467e+00, Validation Loss: 1.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6133, Training Loss: 1.466e+00, Validation Loss: 1.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6134, Training Loss: 1.466e+00, Validation Loss: 1.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6135, Training Loss: 1.466e+00, Validation Loss: 1.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6136, Training Loss: 1.466e+00, Validation Loss: 1.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6137, Training Loss: 1.466e+00, Validation Loss: 1.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6138, Training Loss: 1.466e+00, Validation Loss: 1.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6139, Training Loss: 1.466e+00, Validation Loss: 1.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6140, Training Loss: 1.465e+00, Validation Loss: 1.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6141, Training Loss: 1.465e+00, Validation Loss: 1.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6142, Training Loss: 1.465e+00, Validation Loss: 1.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6143, Training Loss: 1.465e+00, Validation Loss: 1.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6144, Training Loss: 1.465e+00, Validation Loss: 1.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6145, Training Loss: 1.465e+00, Validation Loss: 1.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6146, Training Loss: 1.465e+00, Validation Loss: 1.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6147, Training Loss: 1.464e+00, Validation Loss: 1.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6148, Training Loss: 1.464e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6149, Training Loss: 1.464e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6150, Training Loss: 1.464e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6151, Training Loss: 1.464e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6152, Training Loss: 1.464e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6153, Training Loss: 1.464e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6154, Training Loss: 1.463e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6155, Training Loss: 1.463e+00, Validation Loss: 1.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6156, Training Loss: 1.463e+00, Validation Loss: 1.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6157, Training Loss: 1.463e+00, Validation Loss: 1.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6158, Training Loss: 1.463e+00, Validation Loss: 1.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6159, Training Loss: 1.463e+00, Validation Loss: 1.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6160, Training Loss: 1.463e+00, Validation Loss: 1.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6161, Training Loss: 1.462e+00, Validation Loss: 1.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6162, Training Loss: 1.462e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6163, Training Loss: 1.462e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6164, Training Loss: 1.462e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6165, Training Loss: 1.462e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6166, Training Loss: 1.462e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6167, Training Loss: 1.462e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6168, Training Loss: 1.461e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6169, Training Loss: 1.461e+00, Validation Loss: 1.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6170, Training Loss: 1.461e+00, Validation Loss: 1.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6171, Training Loss: 1.461e+00, Validation Loss: 1.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6172, Training Loss: 1.461e+00, Validation Loss: 1.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6173, Training Loss: 1.461e+00, Validation Loss: 1.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6174, Training Loss: 1.461e+00, Validation Loss: 1.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6175, Training Loss: 1.460e+00, Validation Loss: 1.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6176, Training Loss: 1.460e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6177, Training Loss: 1.460e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6178, Training Loss: 1.460e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6179, Training Loss: 1.460e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6180, Training Loss: 1.460e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6181, Training Loss: 1.460e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6182, Training Loss: 1.459e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6183, Training Loss: 1.459e+00, Validation Loss: 1.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6184, Training Loss: 1.459e+00, Validation Loss: 1.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6185, Training Loss: 1.459e+00, Validation Loss: 1.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6186, Training Loss: 1.459e+00, Validation Loss: 1.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6187, Training Loss: 1.459e+00, Validation Loss: 1.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6188, Training Loss: 1.459e+00, Validation Loss: 1.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6189, Training Loss: 1.458e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6190, Training Loss: 1.458e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6191, Training Loss: 1.458e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6192, Training Loss: 1.458e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6193, Training Loss: 1.458e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6194, Training Loss: 1.458e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6195, Training Loss: 1.458e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6196, Training Loss: 1.457e+00, Validation Loss: 1.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6197, Training Loss: 1.457e+00, Validation Loss: 1.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6198, Training Loss: 1.457e+00, Validation Loss: 1.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6199, Training Loss: 1.457e+00, Validation Loss: 1.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6200, Training Loss: 1.457e+00, Validation Loss: 1.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6201, Training Loss: 1.457e+00, Validation Loss: 1.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6202, Training Loss: 1.457e+00, Validation Loss: 1.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6203, Training Loss: 1.456e+00, Validation Loss: 1.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6204, Training Loss: 1.456e+00, Validation Loss: 1.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6205, Training Loss: 1.456e+00, Validation Loss: 1.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6206, Training Loss: 1.456e+00, Validation Loss: 1.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6207, Training Loss: 1.456e+00, Validation Loss: 1.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6208, Training Loss: 1.456e+00, Validation Loss: 1.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6209, Training Loss: 1.456e+00, Validation Loss: 1.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6210, Training Loss: 1.455e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6211, Training Loss: 1.455e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6212, Training Loss: 1.455e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6213, Training Loss: 1.455e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6214, Training Loss: 1.455e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6215, Training Loss: 1.455e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6216, Training Loss: 1.455e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6217, Training Loss: 1.454e+00, Validation Loss: 1.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6218, Training Loss: 1.454e+00, Validation Loss: 1.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6219, Training Loss: 1.454e+00, Validation Loss: 1.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6220, Training Loss: 1.454e+00, Validation Loss: 1.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6221, Training Loss: 1.454e+00, Validation Loss: 1.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6222, Training Loss: 1.454e+00, Validation Loss: 1.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6223, Training Loss: 1.454e+00, Validation Loss: 1.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6224, Training Loss: 1.453e+00, Validation Loss: 1.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6225, Training Loss: 1.453e+00, Validation Loss: 1.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6226, Training Loss: 1.453e+00, Validation Loss: 1.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6227, Training Loss: 1.453e+00, Validation Loss: 1.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6228, Training Loss: 1.453e+00, Validation Loss: 1.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6229, Training Loss: 1.453e+00, Validation Loss: 1.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6230, Training Loss: 1.453e+00, Validation Loss: 1.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6231, Training Loss: 1.452e+00, Validation Loss: 1.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6232, Training Loss: 1.452e+00, Validation Loss: 1.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6233, Training Loss: 1.452e+00, Validation Loss: 1.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6234, Training Loss: 1.452e+00, Validation Loss: 1.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6235, Training Loss: 1.452e+00, Validation Loss: 1.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6236, Training Loss: 1.452e+00, Validation Loss: 1.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6237, Training Loss: 1.452e+00, Validation Loss: 1.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6238, Training Loss: 1.451e+00, Validation Loss: 1.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6239, Training Loss: 1.451e+00, Validation Loss: 1.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6240, Training Loss: 1.451e+00, Validation Loss: 1.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6241, Training Loss: 1.451e+00, Validation Loss: 1.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6242, Training Loss: 1.451e+00, Validation Loss: 1.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6243, Training Loss: 1.451e+00, Validation Loss: 1.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6244, Training Loss: 1.451e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6245, Training Loss: 1.450e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6246, Training Loss: 1.450e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6247, Training Loss: 1.450e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6248, Training Loss: 1.450e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6249, Training Loss: 1.450e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6250, Training Loss: 1.450e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6251, Training Loss: 1.450e+00, Validation Loss: 1.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6252, Training Loss: 1.449e+00, Validation Loss: 1.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6253, Training Loss: 1.449e+00, Validation Loss: 1.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6254, Training Loss: 1.449e+00, Validation Loss: 1.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6255, Training Loss: 1.449e+00, Validation Loss: 1.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6256, Training Loss: 1.449e+00, Validation Loss: 1.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6257, Training Loss: 1.449e+00, Validation Loss: 1.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6258, Training Loss: 1.449e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6259, Training Loss: 1.448e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6260, Training Loss: 1.448e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6261, Training Loss: 1.448e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6262, Training Loss: 1.448e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6263, Training Loss: 1.448e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6264, Training Loss: 1.448e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6265, Training Loss: 1.448e+00, Validation Loss: 1.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6266, Training Loss: 1.447e+00, Validation Loss: 1.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6267, Training Loss: 1.447e+00, Validation Loss: 1.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6268, Training Loss: 1.447e+00, Validation Loss: 1.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6269, Training Loss: 1.447e+00, Validation Loss: 1.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6270, Training Loss: 1.447e+00, Validation Loss: 1.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6271, Training Loss: 1.447e+00, Validation Loss: 1.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6272, Training Loss: 1.447e+00, Validation Loss: 1.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6273, Training Loss: 1.446e+00, Validation Loss: 1.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6274, Training Loss: 1.446e+00, Validation Loss: 1.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6275, Training Loss: 1.446e+00, Validation Loss: 1.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6276, Training Loss: 1.446e+00, Validation Loss: 1.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6277, Training Loss: 1.446e+00, Validation Loss: 1.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6278, Training Loss: 1.446e+00, Validation Loss: 1.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6279, Training Loss: 1.446e+00, Validation Loss: 1.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6280, Training Loss: 1.445e+00, Validation Loss: 1.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6281, Training Loss: 1.445e+00, Validation Loss: 1.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6282, Training Loss: 1.445e+00, Validation Loss: 1.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6283, Training Loss: 1.445e+00, Validation Loss: 1.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6284, Training Loss: 1.445e+00, Validation Loss: 1.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6285, Training Loss: 1.445e+00, Validation Loss: 1.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6286, Training Loss: 1.445e+00, Validation Loss: 1.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6287, Training Loss: 1.444e+00, Validation Loss: 1.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6288, Training Loss: 1.444e+00, Validation Loss: 1.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6289, Training Loss: 1.444e+00, Validation Loss: 1.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6290, Training Loss: 1.444e+00, Validation Loss: 1.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6291, Training Loss: 1.444e+00, Validation Loss: 1.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6292, Training Loss: 1.444e+00, Validation Loss: 1.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6293, Training Loss: 1.444e+00, Validation Loss: 1.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6294, Training Loss: 1.443e+00, Validation Loss: 1.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6295, Training Loss: 1.443e+00, Validation Loss: 1.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6296, Training Loss: 1.443e+00, Validation Loss: 1.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6297, Training Loss: 1.443e+00, Validation Loss: 1.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6298, Training Loss: 1.443e+00, Validation Loss: 1.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6299, Training Loss: 1.443e+00, Validation Loss: 1.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6300, Training Loss: 1.443e+00, Validation Loss: 1.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6301, Training Loss: 1.442e+00, Validation Loss: 1.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6302, Training Loss: 1.442e+00, Validation Loss: 1.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6303, Training Loss: 1.442e+00, Validation Loss: 1.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6304, Training Loss: 1.442e+00, Validation Loss: 1.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6305, Training Loss: 1.442e+00, Validation Loss: 1.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6306, Training Loss: 1.442e+00, Validation Loss: 1.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6307, Training Loss: 1.442e+00, Validation Loss: 1.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6308, Training Loss: 1.441e+00, Validation Loss: 1.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6309, Training Loss: 1.441e+00, Validation Loss: 1.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6310, Training Loss: 1.441e+00, Validation Loss: 1.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6311, Training Loss: 1.441e+00, Validation Loss: 1.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6312, Training Loss: 1.441e+00, Validation Loss: 1.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6313, Training Loss: 1.441e+00, Validation Loss: 1.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6314, Training Loss: 1.441e+00, Validation Loss: 1.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6315, Training Loss: 1.440e+00, Validation Loss: 1.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6316, Training Loss: 1.440e+00, Validation Loss: 1.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6317, Training Loss: 1.440e+00, Validation Loss: 1.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6318, Training Loss: 1.440e+00, Validation Loss: 1.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6319, Training Loss: 1.440e+00, Validation Loss: 1.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6320, Training Loss: 1.440e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6321, Training Loss: 1.440e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6322, Training Loss: 1.439e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6323, Training Loss: 1.439e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6324, Training Loss: 1.439e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6325, Training Loss: 1.439e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6326, Training Loss: 1.439e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6327, Training Loss: 1.439e+00, Validation Loss: 1.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6328, Training Loss: 1.439e+00, Validation Loss: 1.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6329, Training Loss: 1.439e+00, Validation Loss: 1.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6330, Training Loss: 1.438e+00, Validation Loss: 1.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6331, Training Loss: 1.438e+00, Validation Loss: 1.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6332, Training Loss: 1.438e+00, Validation Loss: 1.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6333, Training Loss: 1.438e+00, Validation Loss: 1.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6334, Training Loss: 1.438e+00, Validation Loss: 1.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6335, Training Loss: 1.438e+00, Validation Loss: 1.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6336, Training Loss: 1.438e+00, Validation Loss: 1.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6337, Training Loss: 1.437e+00, Validation Loss: 1.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6338, Training Loss: 1.437e+00, Validation Loss: 1.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6339, Training Loss: 1.437e+00, Validation Loss: 1.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6340, Training Loss: 1.437e+00, Validation Loss: 1.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6341, Training Loss: 1.437e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6342, Training Loss: 1.437e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6343, Training Loss: 1.437e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6344, Training Loss: 1.436e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6345, Training Loss: 1.436e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6346, Training Loss: 1.436e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6347, Training Loss: 1.436e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6348, Training Loss: 1.436e+00, Validation Loss: 1.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6349, Training Loss: 1.436e+00, Validation Loss: 1.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6350, Training Loss: 1.436e+00, Validation Loss: 1.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6351, Training Loss: 1.435e+00, Validation Loss: 1.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6352, Training Loss: 1.435e+00, Validation Loss: 1.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6353, Training Loss: 1.435e+00, Validation Loss: 1.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6354, Training Loss: 1.435e+00, Validation Loss: 1.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6355, Training Loss: 1.435e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6356, Training Loss: 1.435e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6357, Training Loss: 1.435e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6358, Training Loss: 1.434e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6359, Training Loss: 1.434e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6360, Training Loss: 1.434e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6361, Training Loss: 1.434e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6362, Training Loss: 1.434e+00, Validation Loss: 1.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6363, Training Loss: 1.434e+00, Validation Loss: 1.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6364, Training Loss: 1.434e+00, Validation Loss: 1.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6365, Training Loss: 1.433e+00, Validation Loss: 1.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6366, Training Loss: 1.433e+00, Validation Loss: 1.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6367, Training Loss: 1.433e+00, Validation Loss: 1.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6368, Training Loss: 1.433e+00, Validation Loss: 1.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6369, Training Loss: 1.433e+00, Validation Loss: 1.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6370, Training Loss: 1.433e+00, Validation Loss: 1.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6371, Training Loss: 1.433e+00, Validation Loss: 1.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6372, Training Loss: 1.432e+00, Validation Loss: 1.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6373, Training Loss: 1.432e+00, Validation Loss: 1.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6374, Training Loss: 1.432e+00, Validation Loss: 1.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6375, Training Loss: 1.432e+00, Validation Loss: 1.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6376, Training Loss: 1.432e+00, Validation Loss: 1.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6377, Training Loss: 1.432e+00, Validation Loss: 1.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6378, Training Loss: 1.432e+00, Validation Loss: 1.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6379, Training Loss: 1.431e+00, Validation Loss: 1.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6380, Training Loss: 1.431e+00, Validation Loss: 1.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6381, Training Loss: 1.431e+00, Validation Loss: 1.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6382, Training Loss: 1.431e+00, Validation Loss: 1.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6383, Training Loss: 1.431e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6384, Training Loss: 1.431e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6385, Training Loss: 1.431e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6386, Training Loss: 1.430e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6387, Training Loss: 1.430e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6388, Training Loss: 1.430e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6389, Training Loss: 1.430e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6390, Training Loss: 1.430e+00, Validation Loss: 1.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6391, Training Loss: 1.430e+00, Validation Loss: 1.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6392, Training Loss: 1.430e+00, Validation Loss: 1.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6393, Training Loss: 1.429e+00, Validation Loss: 1.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6394, Training Loss: 1.429e+00, Validation Loss: 1.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6395, Training Loss: 1.429e+00, Validation Loss: 1.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6396, Training Loss: 1.429e+00, Validation Loss: 1.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6397, Training Loss: 1.429e+00, Validation Loss: 1.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6398, Training Loss: 1.429e+00, Validation Loss: 1.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6399, Training Loss: 1.429e+00, Validation Loss: 1.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6400, Training Loss: 1.428e+00, Validation Loss: 1.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6401, Training Loss: 1.428e+00, Validation Loss: 1.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6402, Training Loss: 1.428e+00, Validation Loss: 1.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6403, Training Loss: 1.428e+00, Validation Loss: 1.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6404, Training Loss: 1.428e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6405, Training Loss: 1.428e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6406, Training Loss: 1.428e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6407, Training Loss: 1.427e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6408, Training Loss: 1.427e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6409, Training Loss: 1.427e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6410, Training Loss: 1.427e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6411, Training Loss: 1.427e+00, Validation Loss: 1.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6412, Training Loss: 1.427e+00, Validation Loss: 1.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6413, Training Loss: 1.427e+00, Validation Loss: 1.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6414, Training Loss: 1.426e+00, Validation Loss: 1.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6415, Training Loss: 1.426e+00, Validation Loss: 1.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6416, Training Loss: 1.426e+00, Validation Loss: 1.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6417, Training Loss: 1.426e+00, Validation Loss: 1.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6418, Training Loss: 1.426e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6419, Training Loss: 1.426e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6420, Training Loss: 1.426e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6421, Training Loss: 1.425e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6422, Training Loss: 1.425e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6423, Training Loss: 1.425e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6424, Training Loss: 1.425e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6425, Training Loss: 1.425e+00, Validation Loss: 1.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6426, Training Loss: 1.425e+00, Validation Loss: 1.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6427, Training Loss: 1.425e+00, Validation Loss: 1.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6428, Training Loss: 1.424e+00, Validation Loss: 1.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6429, Training Loss: 1.424e+00, Validation Loss: 1.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6430, Training Loss: 1.424e+00, Validation Loss: 1.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6431, Training Loss: 1.424e+00, Validation Loss: 1.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6432, Training Loss: 1.424e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6433, Training Loss: 1.424e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6434, Training Loss: 1.424e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6435, Training Loss: 1.424e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6436, Training Loss: 1.423e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6437, Training Loss: 1.423e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6438, Training Loss: 1.423e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6439, Training Loss: 1.423e+00, Validation Loss: 1.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6440, Training Loss: 1.423e+00, Validation Loss: 1.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6441, Training Loss: 1.423e+00, Validation Loss: 1.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6442, Training Loss: 1.423e+00, Validation Loss: 1.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6443, Training Loss: 1.422e+00, Validation Loss: 1.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6444, Training Loss: 1.422e+00, Validation Loss: 1.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6445, Training Loss: 1.422e+00, Validation Loss: 1.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6446, Training Loss: 1.422e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6447, Training Loss: 1.422e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6448, Training Loss: 1.422e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6449, Training Loss: 1.422e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6450, Training Loss: 1.421e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6451, Training Loss: 1.421e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6452, Training Loss: 1.421e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6453, Training Loss: 1.421e+00, Validation Loss: 1.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6454, Training Loss: 1.421e+00, Validation Loss: 1.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6455, Training Loss: 1.421e+00, Validation Loss: 1.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6456, Training Loss: 1.421e+00, Validation Loss: 1.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6457, Training Loss: 1.420e+00, Validation Loss: 1.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6458, Training Loss: 1.420e+00, Validation Loss: 1.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6459, Training Loss: 1.420e+00, Validation Loss: 1.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6460, Training Loss: 1.420e+00, Validation Loss: 1.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6461, Training Loss: 1.420e+00, Validation Loss: 1.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6462, Training Loss: 1.420e+00, Validation Loss: 1.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6463, Training Loss: 1.420e+00, Validation Loss: 1.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6464, Training Loss: 1.419e+00, Validation Loss: 1.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6465, Training Loss: 1.419e+00, Validation Loss: 1.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6466, Training Loss: 1.419e+00, Validation Loss: 1.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6467, Training Loss: 1.419e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6468, Training Loss: 1.419e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6469, Training Loss: 1.419e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6470, Training Loss: 1.419e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6471, Training Loss: 1.418e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6472, Training Loss: 1.418e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6473, Training Loss: 1.418e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6474, Training Loss: 1.418e+00, Validation Loss: 1.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6475, Training Loss: 1.418e+00, Validation Loss: 1.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6476, Training Loss: 1.418e+00, Validation Loss: 1.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6477, Training Loss: 1.418e+00, Validation Loss: 1.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6478, Training Loss: 1.418e+00, Validation Loss: 1.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6479, Training Loss: 1.417e+00, Validation Loss: 1.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6480, Training Loss: 1.417e+00, Validation Loss: 1.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6481, Training Loss: 1.417e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6482, Training Loss: 1.417e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6483, Training Loss: 1.417e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6484, Training Loss: 1.417e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6485, Training Loss: 1.417e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6486, Training Loss: 1.416e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6487, Training Loss: 1.416e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6488, Training Loss: 1.416e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6489, Training Loss: 1.416e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6490, Training Loss: 1.416e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6491, Training Loss: 1.416e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6492, Training Loss: 1.416e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6493, Training Loss: 1.415e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6494, Training Loss: 1.415e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6495, Training Loss: 1.415e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6496, Training Loss: 1.415e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6497, Training Loss: 1.415e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6498, Training Loss: 1.415e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6499, Training Loss: 1.415e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6500, Training Loss: 1.414e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6501, Training Loss: 1.414e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6502, Training Loss: 1.414e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6503, Training Loss: 1.414e+00, Validation Loss: 1.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6504, Training Loss: 1.414e+00, Validation Loss: 1.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6505, Training Loss: 1.414e+00, Validation Loss: 1.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6506, Training Loss: 1.414e+00, Validation Loss: 1.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6507, Training Loss: 1.414e+00, Validation Loss: 1.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6508, Training Loss: 1.413e+00, Validation Loss: 1.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6509, Training Loss: 1.413e+00, Validation Loss: 1.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6510, Training Loss: 1.413e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6511, Training Loss: 1.413e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6512, Training Loss: 1.413e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6513, Training Loss: 1.413e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6514, Training Loss: 1.413e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6515, Training Loss: 1.412e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6516, Training Loss: 1.412e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6517, Training Loss: 1.412e+00, Validation Loss: 1.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6518, Training Loss: 1.412e+00, Validation Loss: 1.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6519, Training Loss: 1.412e+00, Validation Loss: 1.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6520, Training Loss: 1.412e+00, Validation Loss: 1.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6521, Training Loss: 1.412e+00, Validation Loss: 1.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6522, Training Loss: 1.411e+00, Validation Loss: 1.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6523, Training Loss: 1.411e+00, Validation Loss: 1.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6524, Training Loss: 1.411e+00, Validation Loss: 1.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6525, Training Loss: 1.411e+00, Validation Loss: 1.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6526, Training Loss: 1.411e+00, Validation Loss: 1.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6527, Training Loss: 1.411e+00, Validation Loss: 1.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6528, Training Loss: 1.411e+00, Validation Loss: 1.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6529, Training Loss: 1.410e+00, Validation Loss: 1.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6530, Training Loss: 1.410e+00, Validation Loss: 1.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6531, Training Loss: 1.410e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6532, Training Loss: 1.410e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6533, Training Loss: 1.410e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6534, Training Loss: 1.410e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6535, Training Loss: 1.410e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6536, Training Loss: 1.410e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6537, Training Loss: 1.409e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6538, Training Loss: 1.409e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6539, Training Loss: 1.409e+00, Validation Loss: 1.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6540, Training Loss: 1.409e+00, Validation Loss: 1.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6541, Training Loss: 1.409e+00, Validation Loss: 1.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6542, Training Loss: 1.409e+00, Validation Loss: 1.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6543, Training Loss: 1.409e+00, Validation Loss: 1.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6544, Training Loss: 1.408e+00, Validation Loss: 1.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6545, Training Loss: 1.408e+00, Validation Loss: 1.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6546, Training Loss: 1.408e+00, Validation Loss: 1.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6547, Training Loss: 1.408e+00, Validation Loss: 1.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6548, Training Loss: 1.408e+00, Validation Loss: 1.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6549, Training Loss: 1.408e+00, Validation Loss: 1.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6550, Training Loss: 1.408e+00, Validation Loss: 1.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6551, Training Loss: 1.407e+00, Validation Loss: 1.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6552, Training Loss: 1.407e+00, Validation Loss: 1.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6553, Training Loss: 1.407e+00, Validation Loss: 1.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6554, Training Loss: 1.407e+00, Validation Loss: 1.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6555, Training Loss: 1.407e+00, Validation Loss: 1.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6556, Training Loss: 1.407e+00, Validation Loss: 1.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6557, Training Loss: 1.407e+00, Validation Loss: 1.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6558, Training Loss: 1.407e+00, Validation Loss: 1.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6559, Training Loss: 1.406e+00, Validation Loss: 1.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6560, Training Loss: 1.406e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6561, Training Loss: 1.406e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6562, Training Loss: 1.406e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6563, Training Loss: 1.406e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6564, Training Loss: 1.406e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6565, Training Loss: 1.406e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6566, Training Loss: 1.405e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6567, Training Loss: 1.405e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6568, Training Loss: 1.405e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6569, Training Loss: 1.405e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6570, Training Loss: 1.405e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6571, Training Loss: 1.405e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6572, Training Loss: 1.405e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6573, Training Loss: 1.404e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6574, Training Loss: 1.404e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6575, Training Loss: 1.404e+00, Validation Loss: 1.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6576, Training Loss: 1.404e+00, Validation Loss: 1.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6577, Training Loss: 1.404e+00, Validation Loss: 1.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6578, Training Loss: 1.404e+00, Validation Loss: 1.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6579, Training Loss: 1.404e+00, Validation Loss: 1.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6580, Training Loss: 1.404e+00, Validation Loss: 1.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6581, Training Loss: 1.403e+00, Validation Loss: 1.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6582, Training Loss: 1.403e+00, Validation Loss: 1.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6583, Training Loss: 1.403e+00, Validation Loss: 1.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6584, Training Loss: 1.403e+00, Validation Loss: 1.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6585, Training Loss: 1.403e+00, Validation Loss: 1.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6586, Training Loss: 1.403e+00, Validation Loss: 1.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6587, Training Loss: 1.403e+00, Validation Loss: 1.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6588, Training Loss: 1.402e+00, Validation Loss: 1.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6589, Training Loss: 1.402e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6590, Training Loss: 1.402e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6591, Training Loss: 1.402e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6592, Training Loss: 1.402e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6593, Training Loss: 1.402e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6594, Training Loss: 1.402e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6595, Training Loss: 1.401e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6596, Training Loss: 1.401e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6597, Training Loss: 1.401e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6598, Training Loss: 1.401e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6599, Training Loss: 1.401e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6600, Training Loss: 1.401e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6601, Training Loss: 1.401e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6602, Training Loss: 1.401e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6603, Training Loss: 1.400e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6604, Training Loss: 1.400e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6605, Training Loss: 1.400e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6606, Training Loss: 1.400e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6607, Training Loss: 1.400e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6608, Training Loss: 1.400e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6609, Training Loss: 1.400e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6610, Training Loss: 1.399e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6611, Training Loss: 1.399e+00, Validation Loss: 1.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6612, Training Loss: 1.399e+00, Validation Loss: 1.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6613, Training Loss: 1.399e+00, Validation Loss: 1.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6614, Training Loss: 1.399e+00, Validation Loss: 1.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6615, Training Loss: 1.399e+00, Validation Loss: 1.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6616, Training Loss: 1.399e+00, Validation Loss: 1.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6617, Training Loss: 1.398e+00, Validation Loss: 1.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6618, Training Loss: 1.398e+00, Validation Loss: 1.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6619, Training Loss: 1.398e+00, Validation Loss: 1.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6620, Training Loss: 1.398e+00, Validation Loss: 1.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6621, Training Loss: 1.398e+00, Validation Loss: 1.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6622, Training Loss: 1.398e+00, Validation Loss: 1.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6623, Training Loss: 1.398e+00, Validation Loss: 1.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6624, Training Loss: 1.398e+00, Validation Loss: 1.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6625, Training Loss: 1.397e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6626, Training Loss: 1.397e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6627, Training Loss: 1.397e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6628, Training Loss: 1.397e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6629, Training Loss: 1.397e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6630, Training Loss: 1.397e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6631, Training Loss: 1.397e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6632, Training Loss: 1.396e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6633, Training Loss: 1.396e+00, Validation Loss: 1.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6634, Training Loss: 1.396e+00, Validation Loss: 1.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6635, Training Loss: 1.396e+00, Validation Loss: 1.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6636, Training Loss: 1.396e+00, Validation Loss: 1.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6637, Training Loss: 1.396e+00, Validation Loss: 1.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6638, Training Loss: 1.396e+00, Validation Loss: 1.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6639, Training Loss: 1.395e+00, Validation Loss: 1.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6640, Training Loss: 1.395e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6641, Training Loss: 1.395e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6642, Training Loss: 1.395e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6643, Training Loss: 1.395e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6644, Training Loss: 1.395e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6645, Training Loss: 1.395e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6646, Training Loss: 1.395e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6647, Training Loss: 1.394e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6648, Training Loss: 1.394e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6649, Training Loss: 1.394e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6650, Training Loss: 1.394e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6651, Training Loss: 1.394e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6652, Training Loss: 1.394e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6653, Training Loss: 1.394e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6654, Training Loss: 1.393e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6655, Training Loss: 1.393e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6656, Training Loss: 1.393e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6657, Training Loss: 1.393e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6658, Training Loss: 1.393e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6659, Training Loss: 1.393e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6660, Training Loss: 1.393e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6661, Training Loss: 1.393e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6662, Training Loss: 1.392e+00, Validation Loss: 1.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6663, Training Loss: 1.392e+00, Validation Loss: 1.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6664, Training Loss: 1.392e+00, Validation Loss: 1.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6665, Training Loss: 1.392e+00, Validation Loss: 1.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6666, Training Loss: 1.392e+00, Validation Loss: 1.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6667, Training Loss: 1.392e+00, Validation Loss: 1.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6668, Training Loss: 1.392e+00, Validation Loss: 1.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6669, Training Loss: 1.391e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6670, Training Loss: 1.391e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6671, Training Loss: 1.391e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6672, Training Loss: 1.391e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6673, Training Loss: 1.391e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6674, Training Loss: 1.391e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6675, Training Loss: 1.391e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6676, Training Loss: 1.390e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6677, Training Loss: 1.390e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6678, Training Loss: 1.390e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6679, Training Loss: 1.390e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6680, Training Loss: 1.390e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6681, Training Loss: 1.390e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6682, Training Loss: 1.390e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6683, Training Loss: 1.390e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6684, Training Loss: 1.389e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6685, Training Loss: 1.389e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6686, Training Loss: 1.389e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6687, Training Loss: 1.389e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6688, Training Loss: 1.389e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6689, Training Loss: 1.389e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6690, Training Loss: 1.389e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6691, Training Loss: 1.388e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6692, Training Loss: 1.388e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6693, Training Loss: 1.388e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6694, Training Loss: 1.388e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6695, Training Loss: 1.388e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6696, Training Loss: 1.388e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6697, Training Loss: 1.388e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6698, Training Loss: 1.388e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6699, Training Loss: 1.387e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6700, Training Loss: 1.387e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6701, Training Loss: 1.387e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6702, Training Loss: 1.387e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6703, Training Loss: 1.387e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6704, Training Loss: 1.387e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6705, Training Loss: 1.387e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6706, Training Loss: 1.386e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6707, Training Loss: 1.386e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6708, Training Loss: 1.386e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6709, Training Loss: 1.386e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6710, Training Loss: 1.386e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6711, Training Loss: 1.386e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6712, Training Loss: 1.386e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6713, Training Loss: 1.386e+00, Validation Loss: 1.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6714, Training Loss: 1.385e+00, Validation Loss: 1.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6715, Training Loss: 1.385e+00, Validation Loss: 1.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6716, Training Loss: 1.385e+00, Validation Loss: 1.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6717, Training Loss: 1.385e+00, Validation Loss: 1.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6718, Training Loss: 1.385e+00, Validation Loss: 1.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6719, Training Loss: 1.385e+00, Validation Loss: 1.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6720, Training Loss: 1.385e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6721, Training Loss: 1.384e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6722, Training Loss: 1.384e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6723, Training Loss: 1.384e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6724, Training Loss: 1.384e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6725, Training Loss: 1.384e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6726, Training Loss: 1.384e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6727, Training Loss: 1.384e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6728, Training Loss: 1.384e+00, Validation Loss: 1.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6729, Training Loss: 1.383e+00, Validation Loss: 1.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6730, Training Loss: 1.383e+00, Validation Loss: 1.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6731, Training Loss: 1.383e+00, Validation Loss: 1.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6732, Training Loss: 1.383e+00, Validation Loss: 1.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6733, Training Loss: 1.383e+00, Validation Loss: 1.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6734, Training Loss: 1.383e+00, Validation Loss: 1.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6735, Training Loss: 1.383e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6736, Training Loss: 1.382e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6737, Training Loss: 1.382e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6738, Training Loss: 1.382e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6739, Training Loss: 1.382e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6740, Training Loss: 1.382e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6741, Training Loss: 1.382e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6742, Training Loss: 1.382e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6743, Training Loss: 1.382e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6744, Training Loss: 1.381e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6745, Training Loss: 1.381e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6746, Training Loss: 1.381e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6747, Training Loss: 1.381e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6748, Training Loss: 1.381e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6749, Training Loss: 1.381e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6750, Training Loss: 1.381e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6751, Training Loss: 1.380e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6752, Training Loss: 1.380e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6753, Training Loss: 1.380e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6754, Training Loss: 1.380e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6755, Training Loss: 1.380e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6756, Training Loss: 1.380e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6757, Training Loss: 1.380e+00, Validation Loss: 1.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6758, Training Loss: 1.380e+00, Validation Loss: 1.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6759, Training Loss: 1.379e+00, Validation Loss: 1.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6760, Training Loss: 1.379e+00, Validation Loss: 1.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6761, Training Loss: 1.379e+00, Validation Loss: 1.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6762, Training Loss: 1.379e+00, Validation Loss: 1.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6763, Training Loss: 1.379e+00, Validation Loss: 1.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6764, Training Loss: 1.379e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6765, Training Loss: 1.379e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6766, Training Loss: 1.378e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6767, Training Loss: 1.378e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6768, Training Loss: 1.378e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6769, Training Loss: 1.378e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6770, Training Loss: 1.378e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6771, Training Loss: 1.378e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6772, Training Loss: 1.378e+00, Validation Loss: 1.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6773, Training Loss: 1.378e+00, Validation Loss: 1.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6774, Training Loss: 1.377e+00, Validation Loss: 1.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6775, Training Loss: 1.377e+00, Validation Loss: 1.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6776, Training Loss: 1.377e+00, Validation Loss: 1.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6777, Training Loss: 1.377e+00, Validation Loss: 1.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6778, Training Loss: 1.377e+00, Validation Loss: 1.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6779, Training Loss: 1.377e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6780, Training Loss: 1.377e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6781, Training Loss: 1.376e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6782, Training Loss: 1.376e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6783, Training Loss: 1.376e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6784, Training Loss: 1.376e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6785, Training Loss: 1.376e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6786, Training Loss: 1.376e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6787, Training Loss: 1.376e+00, Validation Loss: 1.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6788, Training Loss: 1.376e+00, Validation Loss: 1.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6789, Training Loss: 1.375e+00, Validation Loss: 1.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6790, Training Loss: 1.375e+00, Validation Loss: 1.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6791, Training Loss: 1.375e+00, Validation Loss: 1.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6792, Training Loss: 1.375e+00, Validation Loss: 1.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6793, Training Loss: 1.375e+00, Validation Loss: 1.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6794, Training Loss: 1.375e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6795, Training Loss: 1.375e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6796, Training Loss: 1.374e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6797, Training Loss: 1.374e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6798, Training Loss: 1.374e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6799, Training Loss: 1.374e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6800, Training Loss: 1.374e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6801, Training Loss: 1.374e+00, Validation Loss: 1.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6802, Training Loss: 1.374e+00, Validation Loss: 1.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6803, Training Loss: 1.374e+00, Validation Loss: 1.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6804, Training Loss: 1.373e+00, Validation Loss: 1.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6805, Training Loss: 1.373e+00, Validation Loss: 1.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6806, Training Loss: 1.373e+00, Validation Loss: 1.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6807, Training Loss: 1.373e+00, Validation Loss: 1.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6808, Training Loss: 1.373e+00, Validation Loss: 1.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6809, Training Loss: 1.373e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6810, Training Loss: 1.373e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6811, Training Loss: 1.372e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6812, Training Loss: 1.372e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6813, Training Loss: 1.372e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6814, Training Loss: 1.372e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6815, Training Loss: 1.372e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6816, Training Loss: 1.372e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6817, Training Loss: 1.372e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6818, Training Loss: 1.372e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6819, Training Loss: 1.371e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6820, Training Loss: 1.371e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6821, Training Loss: 1.371e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6822, Training Loss: 1.371e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6823, Training Loss: 1.371e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6824, Training Loss: 1.371e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6825, Training Loss: 1.371e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6826, Training Loss: 1.370e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6827, Training Loss: 1.370e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6828, Training Loss: 1.370e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6829, Training Loss: 1.370e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6830, Training Loss: 1.370e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6831, Training Loss: 1.370e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6832, Training Loss: 1.370e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6833, Training Loss: 1.370e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6834, Training Loss: 1.369e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6835, Training Loss: 1.369e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6836, Training Loss: 1.369e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6837, Training Loss: 1.369e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6838, Training Loss: 1.369e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6839, Training Loss: 1.369e+00, Validation Loss: 1.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6840, Training Loss: 1.369e+00, Validation Loss: 1.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6841, Training Loss: 1.369e+00, Validation Loss: 1.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6842, Training Loss: 1.368e+00, Validation Loss: 1.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6843, Training Loss: 1.368e+00, Validation Loss: 1.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6844, Training Loss: 1.368e+00, Validation Loss: 1.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6845, Training Loss: 1.368e+00, Validation Loss: 1.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6846, Training Loss: 1.368e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6847, Training Loss: 1.368e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6848, Training Loss: 1.368e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6849, Training Loss: 1.367e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6850, Training Loss: 1.367e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6851, Training Loss: 1.367e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6852, Training Loss: 1.367e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6853, Training Loss: 1.367e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6854, Training Loss: 1.367e+00, Validation Loss: 1.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6855, Training Loss: 1.367e+00, Validation Loss: 1.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6856, Training Loss: 1.367e+00, Validation Loss: 1.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6857, Training Loss: 1.366e+00, Validation Loss: 1.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6858, Training Loss: 1.366e+00, Validation Loss: 1.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6859, Training Loss: 1.366e+00, Validation Loss: 1.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6860, Training Loss: 1.366e+00, Validation Loss: 1.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6861, Training Loss: 1.366e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6862, Training Loss: 1.366e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6863, Training Loss: 1.366e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6864, Training Loss: 1.366e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6865, Training Loss: 1.365e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6866, Training Loss: 1.365e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6867, Training Loss: 1.365e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6868, Training Loss: 1.365e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6869, Training Loss: 1.365e+00, Validation Loss: 1.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6870, Training Loss: 1.365e+00, Validation Loss: 1.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6871, Training Loss: 1.365e+00, Validation Loss: 1.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6872, Training Loss: 1.364e+00, Validation Loss: 1.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6873, Training Loss: 1.364e+00, Validation Loss: 1.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6874, Training Loss: 1.364e+00, Validation Loss: 1.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6875, Training Loss: 1.364e+00, Validation Loss: 1.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6876, Training Loss: 1.364e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6877, Training Loss: 1.364e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6878, Training Loss: 1.364e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6879, Training Loss: 1.364e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6880, Training Loss: 1.363e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6881, Training Loss: 1.363e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6882, Training Loss: 1.363e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6883, Training Loss: 1.363e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6884, Training Loss: 1.363e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6885, Training Loss: 1.363e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6886, Training Loss: 1.363e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6887, Training Loss: 1.362e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6888, Training Loss: 1.362e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6889, Training Loss: 1.362e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6890, Training Loss: 1.362e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6891, Training Loss: 1.362e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6892, Training Loss: 1.362e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6893, Training Loss: 1.362e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6894, Training Loss: 1.362e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6895, Training Loss: 1.361e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6896, Training Loss: 1.361e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6897, Training Loss: 1.361e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6898, Training Loss: 1.361e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6899, Training Loss: 1.361e+00, Validation Loss: 1.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6900, Training Loss: 1.361e+00, Validation Loss: 1.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6901, Training Loss: 1.361e+00, Validation Loss: 1.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6902, Training Loss: 1.361e+00, Validation Loss: 1.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6903, Training Loss: 1.360e+00, Validation Loss: 1.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6904, Training Loss: 1.360e+00, Validation Loss: 1.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6905, Training Loss: 1.360e+00, Validation Loss: 1.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6906, Training Loss: 1.360e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6907, Training Loss: 1.360e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6908, Training Loss: 1.360e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6909, Training Loss: 1.360e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6910, Training Loss: 1.359e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6911, Training Loss: 1.359e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6912, Training Loss: 1.359e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6913, Training Loss: 1.359e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6914, Training Loss: 1.359e+00, Validation Loss: 1.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6915, Training Loss: 1.359e+00, Validation Loss: 1.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6916, Training Loss: 1.359e+00, Validation Loss: 1.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6917, Training Loss: 1.359e+00, Validation Loss: 1.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6918, Training Loss: 1.358e+00, Validation Loss: 1.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6919, Training Loss: 1.358e+00, Validation Loss: 1.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6920, Training Loss: 1.358e+00, Validation Loss: 1.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6921, Training Loss: 1.358e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6922, Training Loss: 1.358e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6923, Training Loss: 1.358e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6924, Training Loss: 1.358e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6925, Training Loss: 1.358e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6926, Training Loss: 1.357e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6927, Training Loss: 1.357e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6928, Training Loss: 1.357e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6929, Training Loss: 1.357e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6930, Training Loss: 1.357e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6931, Training Loss: 1.357e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6932, Training Loss: 1.357e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6933, Training Loss: 1.356e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6934, Training Loss: 1.356e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6935, Training Loss: 1.356e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6936, Training Loss: 1.356e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6937, Training Loss: 1.356e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6938, Training Loss: 1.356e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6939, Training Loss: 1.356e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6940, Training Loss: 1.356e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6941, Training Loss: 1.355e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6942, Training Loss: 1.355e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6943, Training Loss: 1.355e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6944, Training Loss: 1.355e+00, Validation Loss: 1.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6945, Training Loss: 1.355e+00, Validation Loss: 1.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6946, Training Loss: 1.355e+00, Validation Loss: 1.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6947, Training Loss: 1.355e+00, Validation Loss: 1.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6948, Training Loss: 1.355e+00, Validation Loss: 1.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6949, Training Loss: 1.354e+00, Validation Loss: 1.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6950, Training Loss: 1.354e+00, Validation Loss: 1.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6951, Training Loss: 1.354e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6952, Training Loss: 1.354e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6953, Training Loss: 1.354e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6954, Training Loss: 1.354e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6955, Training Loss: 1.354e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6956, Training Loss: 1.354e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6957, Training Loss: 1.353e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6958, Training Loss: 1.353e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6959, Training Loss: 1.353e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6960, Training Loss: 1.353e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6961, Training Loss: 1.353e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6962, Training Loss: 1.353e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6963, Training Loss: 1.353e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6964, Training Loss: 1.352e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6965, Training Loss: 1.352e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6966, Training Loss: 1.352e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6967, Training Loss: 1.352e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6968, Training Loss: 1.352e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6969, Training Loss: 1.352e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6970, Training Loss: 1.352e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6971, Training Loss: 1.352e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6972, Training Loss: 1.351e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6973, Training Loss: 1.351e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6974, Training Loss: 1.351e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6975, Training Loss: 1.351e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6976, Training Loss: 1.351e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6977, Training Loss: 1.351e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6978, Training Loss: 1.351e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6979, Training Loss: 1.351e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6980, Training Loss: 1.350e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6981, Training Loss: 1.350e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6982, Training Loss: 1.350e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6983, Training Loss: 1.350e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6984, Training Loss: 1.350e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6985, Training Loss: 1.350e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6986, Training Loss: 1.350e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6987, Training Loss: 1.350e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6988, Training Loss: 1.349e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6989, Training Loss: 1.349e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6990, Training Loss: 1.349e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6991, Training Loss: 1.349e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6992, Training Loss: 1.349e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6993, Training Loss: 1.349e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6994, Training Loss: 1.349e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6995, Training Loss: 1.348e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6996, Training Loss: 1.348e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6997, Training Loss: 1.348e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6998, Training Loss: 1.348e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6999, Training Loss: 1.348e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7000, Training Loss: 1.348e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7001, Training Loss: 1.348e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7002, Training Loss: 1.348e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7003, Training Loss: 1.347e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7004, Training Loss: 1.347e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7005, Training Loss: 1.347e+00, Validation Loss: 1.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7006, Training Loss: 1.347e+00, Validation Loss: 1.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7007, Training Loss: 1.347e+00, Validation Loss: 1.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7008, Training Loss: 1.347e+00, Validation Loss: 1.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7009, Training Loss: 1.347e+00, Validation Loss: 1.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7010, Training Loss: 1.347e+00, Validation Loss: 1.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7011, Training Loss: 1.346e+00, Validation Loss: 1.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7012, Training Loss: 1.346e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7013, Training Loss: 1.346e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7014, Training Loss: 1.346e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7015, Training Loss: 1.346e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7016, Training Loss: 1.346e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7017, Training Loss: 1.346e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7018, Training Loss: 1.346e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7019, Training Loss: 1.345e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7020, Training Loss: 1.345e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7021, Training Loss: 1.345e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7022, Training Loss: 1.345e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7023, Training Loss: 1.345e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7024, Training Loss: 1.345e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7025, Training Loss: 1.345e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7026, Training Loss: 1.344e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7027, Training Loss: 1.344e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7028, Training Loss: 1.344e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7029, Training Loss: 1.344e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7030, Training Loss: 1.344e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7031, Training Loss: 1.344e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7032, Training Loss: 1.344e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7033, Training Loss: 1.344e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7034, Training Loss: 1.343e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7035, Training Loss: 1.343e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7036, Training Loss: 1.343e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7037, Training Loss: 1.343e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7038, Training Loss: 1.343e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7039, Training Loss: 1.343e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7040, Training Loss: 1.343e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7041, Training Loss: 1.343e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7042, Training Loss: 1.342e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7043, Training Loss: 1.342e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7044, Training Loss: 1.342e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7045, Training Loss: 1.342e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7046, Training Loss: 1.342e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7047, Training Loss: 1.342e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7048, Training Loss: 1.342e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7049, Training Loss: 1.342e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7050, Training Loss: 1.341e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7051, Training Loss: 1.341e+00, Validation Loss: 1.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7052, Training Loss: 1.341e+00, Validation Loss: 1.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7053, Training Loss: 1.341e+00, Validation Loss: 1.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7054, Training Loss: 1.341e+00, Validation Loss: 1.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7055, Training Loss: 1.341e+00, Validation Loss: 1.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7056, Training Loss: 1.341e+00, Validation Loss: 1.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7057, Training Loss: 1.341e+00, Validation Loss: 1.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7058, Training Loss: 1.340e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7059, Training Loss: 1.340e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7060, Training Loss: 1.340e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7061, Training Loss: 1.340e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7062, Training Loss: 1.340e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7063, Training Loss: 1.340e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7064, Training Loss: 1.340e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7065, Training Loss: 1.340e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7066, Training Loss: 1.339e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7067, Training Loss: 1.339e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7068, Training Loss: 1.339e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7069, Training Loss: 1.339e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7070, Training Loss: 1.339e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7071, Training Loss: 1.339e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7072, Training Loss: 1.339e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7073, Training Loss: 1.338e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7074, Training Loss: 1.338e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7075, Training Loss: 1.338e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7076, Training Loss: 1.338e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7077, Training Loss: 1.338e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7078, Training Loss: 1.338e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7079, Training Loss: 1.338e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7080, Training Loss: 1.338e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7081, Training Loss: 1.337e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7082, Training Loss: 1.337e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7083, Training Loss: 1.337e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7084, Training Loss: 1.337e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7085, Training Loss: 1.337e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7086, Training Loss: 1.337e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7087, Training Loss: 1.337e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7088, Training Loss: 1.337e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7089, Training Loss: 1.336e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7090, Training Loss: 1.336e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7091, Training Loss: 1.336e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7092, Training Loss: 1.336e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7093, Training Loss: 1.336e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7094, Training Loss: 1.336e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7095, Training Loss: 1.336e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7096, Training Loss: 1.336e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7097, Training Loss: 1.335e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7098, Training Loss: 1.335e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7099, Training Loss: 1.335e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7100, Training Loss: 1.335e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7101, Training Loss: 1.335e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7102, Training Loss: 1.335e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7103, Training Loss: 1.335e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7104, Training Loss: 1.335e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7105, Training Loss: 1.334e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7106, Training Loss: 1.334e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7107, Training Loss: 1.334e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7108, Training Loss: 1.334e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7109, Training Loss: 1.334e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7110, Training Loss: 1.334e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7111, Training Loss: 1.334e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7112, Training Loss: 1.334e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7113, Training Loss: 1.333e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7114, Training Loss: 1.333e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7115, Training Loss: 1.333e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7116, Training Loss: 1.333e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7117, Training Loss: 1.333e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7118, Training Loss: 1.333e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7119, Training Loss: 1.333e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7120, Training Loss: 1.333e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7121, Training Loss: 1.332e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7122, Training Loss: 1.332e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7123, Training Loss: 1.332e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7124, Training Loss: 1.332e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7125, Training Loss: 1.332e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7126, Training Loss: 1.332e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7127, Training Loss: 1.332e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7128, Training Loss: 1.332e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7129, Training Loss: 1.331e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7130, Training Loss: 1.331e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7131, Training Loss: 1.331e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7132, Training Loss: 1.331e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7133, Training Loss: 1.331e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7134, Training Loss: 1.331e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7135, Training Loss: 1.331e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7136, Training Loss: 1.330e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7137, Training Loss: 1.330e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7138, Training Loss: 1.330e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7139, Training Loss: 1.330e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7140, Training Loss: 1.330e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7141, Training Loss: 1.330e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7142, Training Loss: 1.330e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7143, Training Loss: 1.330e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7144, Training Loss: 1.329e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7145, Training Loss: 1.329e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7146, Training Loss: 1.329e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7147, Training Loss: 1.329e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7148, Training Loss: 1.329e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7149, Training Loss: 1.329e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7150, Training Loss: 1.329e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7151, Training Loss: 1.329e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7152, Training Loss: 1.328e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7153, Training Loss: 1.328e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7154, Training Loss: 1.328e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7155, Training Loss: 1.328e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7156, Training Loss: 1.328e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7157, Training Loss: 1.328e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7158, Training Loss: 1.328e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7159, Training Loss: 1.328e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7160, Training Loss: 1.327e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7161, Training Loss: 1.327e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7162, Training Loss: 1.327e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7163, Training Loss: 1.327e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7164, Training Loss: 1.327e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7165, Training Loss: 1.327e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7166, Training Loss: 1.327e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7167, Training Loss: 1.327e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7168, Training Loss: 1.326e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7169, Training Loss: 1.326e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7170, Training Loss: 1.326e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7171, Training Loss: 1.326e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7172, Training Loss: 1.326e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7173, Training Loss: 1.326e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7174, Training Loss: 1.326e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7175, Training Loss: 1.326e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7176, Training Loss: 1.325e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7177, Training Loss: 1.325e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7178, Training Loss: 1.325e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7179, Training Loss: 1.325e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7180, Training Loss: 1.325e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7181, Training Loss: 1.325e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7182, Training Loss: 1.325e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7183, Training Loss: 1.325e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7184, Training Loss: 1.324e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7185, Training Loss: 1.324e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7186, Training Loss: 1.324e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7187, Training Loss: 1.324e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7188, Training Loss: 1.324e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7189, Training Loss: 1.324e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7190, Training Loss: 1.324e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7191, Training Loss: 1.324e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7192, Training Loss: 1.323e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7193, Training Loss: 1.323e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7194, Training Loss: 1.323e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7195, Training Loss: 1.323e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7196, Training Loss: 1.323e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7197, Training Loss: 1.323e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7198, Training Loss: 1.323e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7199, Training Loss: 1.323e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7200, Training Loss: 1.322e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7201, Training Loss: 1.322e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7202, Training Loss: 1.322e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7203, Training Loss: 1.322e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7204, Training Loss: 1.322e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7205, Training Loss: 1.322e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7206, Training Loss: 1.322e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7207, Training Loss: 1.322e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7208, Training Loss: 1.321e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7209, Training Loss: 1.321e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7210, Training Loss: 1.321e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7211, Training Loss: 1.321e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7212, Training Loss: 1.321e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7213, Training Loss: 1.321e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7214, Training Loss: 1.321e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7215, Training Loss: 1.321e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7216, Training Loss: 1.320e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7217, Training Loss: 1.320e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7218, Training Loss: 1.320e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7219, Training Loss: 1.320e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7220, Training Loss: 1.320e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7221, Training Loss: 1.320e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7222, Training Loss: 1.320e+00, Validation Loss: 1.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7223, Training Loss: 1.320e+00, Validation Loss: 1.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7224, Training Loss: 1.319e+00, Validation Loss: 1.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7225, Training Loss: 1.319e+00, Validation Loss: 1.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7226, Training Loss: 1.319e+00, Validation Loss: 1.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7227, Training Loss: 1.319e+00, Validation Loss: 1.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7228, Training Loss: 1.319e+00, Validation Loss: 1.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7229, Training Loss: 1.319e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7230, Training Loss: 1.319e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7231, Training Loss: 1.319e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7232, Training Loss: 1.318e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7233, Training Loss: 1.318e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7234, Training Loss: 1.318e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7235, Training Loss: 1.318e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7236, Training Loss: 1.318e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7237, Training Loss: 1.318e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7238, Training Loss: 1.318e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7239, Training Loss: 1.318e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7240, Training Loss: 1.317e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7241, Training Loss: 1.317e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7242, Training Loss: 1.317e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7243, Training Loss: 1.317e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7244, Training Loss: 1.317e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7245, Training Loss: 1.317e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7246, Training Loss: 1.317e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7247, Training Loss: 1.317e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7248, Training Loss: 1.316e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7249, Training Loss: 1.316e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7250, Training Loss: 1.316e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7251, Training Loss: 1.316e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7252, Training Loss: 1.316e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7253, Training Loss: 1.316e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7254, Training Loss: 1.316e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7255, Training Loss: 1.316e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7256, Training Loss: 1.315e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7257, Training Loss: 1.315e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7258, Training Loss: 1.315e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7259, Training Loss: 1.315e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7260, Training Loss: 1.315e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7261, Training Loss: 1.315e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7262, Training Loss: 1.315e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7263, Training Loss: 1.315e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7264, Training Loss: 1.314e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7265, Training Loss: 1.314e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7266, Training Loss: 1.314e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7267, Training Loss: 1.314e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7268, Training Loss: 1.314e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7269, Training Loss: 1.314e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7270, Training Loss: 1.314e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7271, Training Loss: 1.314e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7272, Training Loss: 1.313e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7273, Training Loss: 1.313e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7274, Training Loss: 1.313e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7275, Training Loss: 1.313e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7276, Training Loss: 1.313e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7277, Training Loss: 1.313e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7278, Training Loss: 1.313e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7279, Training Loss: 1.313e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7280, Training Loss: 1.312e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7281, Training Loss: 1.312e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7282, Training Loss: 1.312e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7283, Training Loss: 1.312e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7284, Training Loss: 1.312e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7285, Training Loss: 1.312e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7286, Training Loss: 1.312e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7287, Training Loss: 1.312e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7288, Training Loss: 1.311e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7289, Training Loss: 1.311e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7290, Training Loss: 1.311e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7291, Training Loss: 1.311e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7292, Training Loss: 1.311e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7293, Training Loss: 1.311e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7294, Training Loss: 1.311e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7295, Training Loss: 1.311e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7296, Training Loss: 1.310e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7297, Training Loss: 1.310e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7298, Training Loss: 1.310e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7299, Training Loss: 1.310e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7300, Training Loss: 1.310e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7301, Training Loss: 1.310e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7302, Training Loss: 1.310e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7303, Training Loss: 1.310e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7304, Training Loss: 1.310e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7305, Training Loss: 1.309e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7306, Training Loss: 1.309e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7307, Training Loss: 1.309e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7308, Training Loss: 1.309e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7309, Training Loss: 1.309e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7310, Training Loss: 1.309e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7311, Training Loss: 1.309e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7312, Training Loss: 1.309e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7313, Training Loss: 1.308e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7314, Training Loss: 1.308e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7315, Training Loss: 1.308e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7316, Training Loss: 1.308e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7317, Training Loss: 1.308e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7318, Training Loss: 1.308e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7319, Training Loss: 1.308e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7320, Training Loss: 1.308e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7321, Training Loss: 1.307e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7322, Training Loss: 1.307e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7323, Training Loss: 1.307e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7324, Training Loss: 1.307e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7325, Training Loss: 1.307e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7326, Training Loss: 1.307e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7327, Training Loss: 1.307e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7328, Training Loss: 1.307e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7329, Training Loss: 1.306e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7330, Training Loss: 1.306e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7331, Training Loss: 1.306e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7332, Training Loss: 1.306e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7333, Training Loss: 1.306e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7334, Training Loss: 1.306e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7335, Training Loss: 1.306e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7336, Training Loss: 1.306e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7337, Training Loss: 1.305e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7338, Training Loss: 1.305e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7339, Training Loss: 1.305e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7340, Training Loss: 1.305e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7341, Training Loss: 1.305e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7342, Training Loss: 1.305e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7343, Training Loss: 1.305e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7344, Training Loss: 1.305e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7345, Training Loss: 1.304e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7346, Training Loss: 1.304e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7347, Training Loss: 1.304e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7348, Training Loss: 1.304e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7349, Training Loss: 1.304e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7350, Training Loss: 1.304e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7351, Training Loss: 1.304e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7352, Training Loss: 1.304e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7353, Training Loss: 1.303e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7354, Training Loss: 1.303e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7355, Training Loss: 1.303e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7356, Training Loss: 1.303e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7357, Training Loss: 1.303e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7358, Training Loss: 1.303e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7359, Training Loss: 1.303e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7360, Training Loss: 1.303e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7361, Training Loss: 1.303e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7362, Training Loss: 1.302e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7363, Training Loss: 1.302e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7364, Training Loss: 1.302e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7365, Training Loss: 1.302e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7366, Training Loss: 1.302e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7367, Training Loss: 1.302e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7368, Training Loss: 1.302e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7369, Training Loss: 1.302e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7370, Training Loss: 1.301e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7371, Training Loss: 1.301e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7372, Training Loss: 1.301e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7373, Training Loss: 1.301e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7374, Training Loss: 1.301e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7375, Training Loss: 1.301e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7376, Training Loss: 1.301e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7377, Training Loss: 1.301e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7378, Training Loss: 1.300e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7379, Training Loss: 1.300e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7380, Training Loss: 1.300e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7381, Training Loss: 1.300e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7382, Training Loss: 1.300e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7383, Training Loss: 1.300e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7384, Training Loss: 1.300e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7385, Training Loss: 1.300e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7386, Training Loss: 1.299e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7387, Training Loss: 1.299e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7388, Training Loss: 1.299e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7389, Training Loss: 1.299e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7390, Training Loss: 1.299e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7391, Training Loss: 1.299e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7392, Training Loss: 1.299e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7393, Training Loss: 1.299e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7394, Training Loss: 1.298e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7395, Training Loss: 1.298e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7396, Training Loss: 1.298e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7397, Training Loss: 1.298e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7398, Training Loss: 1.298e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7399, Training Loss: 1.298e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7400, Training Loss: 1.298e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7401, Training Loss: 1.298e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7402, Training Loss: 1.297e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7403, Training Loss: 1.297e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7404, Training Loss: 1.297e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7405, Training Loss: 1.297e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7406, Training Loss: 1.297e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7407, Training Loss: 1.297e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7408, Training Loss: 1.297e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7409, Training Loss: 1.297e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7410, Training Loss: 1.297e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7411, Training Loss: 1.296e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7412, Training Loss: 1.296e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7413, Training Loss: 1.296e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7414, Training Loss: 1.296e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7415, Training Loss: 1.296e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7416, Training Loss: 1.296e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7417, Training Loss: 1.296e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7418, Training Loss: 1.296e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7419, Training Loss: 1.295e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7420, Training Loss: 1.295e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7421, Training Loss: 1.295e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7422, Training Loss: 1.295e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7423, Training Loss: 1.295e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7424, Training Loss: 1.295e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7425, Training Loss: 1.295e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7426, Training Loss: 1.295e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7427, Training Loss: 1.294e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7428, Training Loss: 1.294e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7429, Training Loss: 1.294e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7430, Training Loss: 1.294e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7431, Training Loss: 1.294e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7432, Training Loss: 1.294e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7433, Training Loss: 1.294e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7434, Training Loss: 1.294e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7435, Training Loss: 1.293e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7436, Training Loss: 1.293e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7437, Training Loss: 1.293e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7438, Training Loss: 1.293e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7439, Training Loss: 1.293e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7440, Training Loss: 1.293e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7441, Training Loss: 1.293e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7442, Training Loss: 1.293e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7443, Training Loss: 1.293e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7444, Training Loss: 1.292e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7445, Training Loss: 1.292e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7446, Training Loss: 1.292e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7447, Training Loss: 1.292e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7448, Training Loss: 1.292e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7449, Training Loss: 1.292e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7450, Training Loss: 1.292e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7451, Training Loss: 1.292e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7452, Training Loss: 1.291e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7453, Training Loss: 1.291e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7454, Training Loss: 1.291e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7455, Training Loss: 1.291e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7456, Training Loss: 1.291e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7457, Training Loss: 1.291e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7458, Training Loss: 1.291e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7459, Training Loss: 1.291e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7460, Training Loss: 1.290e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7461, Training Loss: 1.290e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7462, Training Loss: 1.290e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7463, Training Loss: 1.290e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7464, Training Loss: 1.290e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7465, Training Loss: 1.290e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7466, Training Loss: 1.290e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7467, Training Loss: 1.290e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7468, Training Loss: 1.290e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7469, Training Loss: 1.289e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7470, Training Loss: 1.289e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7471, Training Loss: 1.289e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7472, Training Loss: 1.289e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7473, Training Loss: 1.289e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7474, Training Loss: 1.289e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7475, Training Loss: 1.289e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7476, Training Loss: 1.289e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7477, Training Loss: 1.288e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7478, Training Loss: 1.288e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7479, Training Loss: 1.288e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7480, Training Loss: 1.288e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7481, Training Loss: 1.288e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7482, Training Loss: 1.288e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7483, Training Loss: 1.288e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7484, Training Loss: 1.288e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7485, Training Loss: 1.287e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7486, Training Loss: 1.287e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7487, Training Loss: 1.287e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7488, Training Loss: 1.287e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7489, Training Loss: 1.287e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7490, Training Loss: 1.287e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7491, Training Loss: 1.287e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7492, Training Loss: 1.287e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7493, Training Loss: 1.286e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7494, Training Loss: 1.286e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7495, Training Loss: 1.286e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7496, Training Loss: 1.286e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7497, Training Loss: 1.286e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7498, Training Loss: 1.286e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7499, Training Loss: 1.286e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7500, Training Loss: 1.286e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7501, Training Loss: 1.286e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7502, Training Loss: 1.285e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7503, Training Loss: 1.285e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7504, Training Loss: 1.285e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7505, Training Loss: 1.285e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7506, Training Loss: 1.285e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7507, Training Loss: 1.285e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7508, Training Loss: 1.285e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7509, Training Loss: 1.285e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7510, Training Loss: 1.284e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7511, Training Loss: 1.284e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7512, Training Loss: 1.284e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7513, Training Loss: 1.284e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7514, Training Loss: 1.284e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7515, Training Loss: 1.284e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7516, Training Loss: 1.284e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7517, Training Loss: 1.284e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7518, Training Loss: 1.283e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7519, Training Loss: 1.283e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7520, Training Loss: 1.283e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7521, Training Loss: 1.283e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7522, Training Loss: 1.283e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7523, Training Loss: 1.283e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7524, Training Loss: 1.283e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7525, Training Loss: 1.283e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7526, Training Loss: 1.283e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7527, Training Loss: 1.282e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7528, Training Loss: 1.282e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7529, Training Loss: 1.282e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7530, Training Loss: 1.282e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7531, Training Loss: 1.282e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7532, Training Loss: 1.282e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7533, Training Loss: 1.282e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7534, Training Loss: 1.282e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7535, Training Loss: 1.281e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7536, Training Loss: 1.281e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7537, Training Loss: 1.281e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7538, Training Loss: 1.281e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7539, Training Loss: 1.281e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7540, Training Loss: 1.281e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7541, Training Loss: 1.281e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7542, Training Loss: 1.281e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7543, Training Loss: 1.281e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7544, Training Loss: 1.280e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7545, Training Loss: 1.280e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7546, Training Loss: 1.280e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7547, Training Loss: 1.280e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7548, Training Loss: 1.280e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7549, Training Loss: 1.280e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7550, Training Loss: 1.280e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7551, Training Loss: 1.280e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7552, Training Loss: 1.279e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7553, Training Loss: 1.279e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7554, Training Loss: 1.279e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7555, Training Loss: 1.279e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7556, Training Loss: 1.279e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7557, Training Loss: 1.279e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7558, Training Loss: 1.279e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7559, Training Loss: 1.279e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7560, Training Loss: 1.278e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7561, Training Loss: 1.278e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7562, Training Loss: 1.278e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7563, Training Loss: 1.278e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7564, Training Loss: 1.278e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7565, Training Loss: 1.278e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7566, Training Loss: 1.278e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7567, Training Loss: 1.278e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7568, Training Loss: 1.278e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7569, Training Loss: 1.277e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7570, Training Loss: 1.277e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7571, Training Loss: 1.277e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7572, Training Loss: 1.277e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7573, Training Loss: 1.277e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7574, Training Loss: 1.277e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7575, Training Loss: 1.277e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7576, Training Loss: 1.277e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7577, Training Loss: 1.276e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7578, Training Loss: 1.276e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7579, Training Loss: 1.276e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7580, Training Loss: 1.276e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7581, Training Loss: 1.276e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7582, Training Loss: 1.276e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7583, Training Loss: 1.276e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7584, Training Loss: 1.276e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7585, Training Loss: 1.276e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7586, Training Loss: 1.275e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7587, Training Loss: 1.275e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7588, Training Loss: 1.275e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7589, Training Loss: 1.275e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7590, Training Loss: 1.275e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7591, Training Loss: 1.275e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7592, Training Loss: 1.275e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7593, Training Loss: 1.275e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7594, Training Loss: 1.274e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7595, Training Loss: 1.274e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7596, Training Loss: 1.274e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7597, Training Loss: 1.274e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7598, Training Loss: 1.274e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7599, Training Loss: 1.274e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7600, Training Loss: 1.274e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7601, Training Loss: 1.274e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7602, Training Loss: 1.273e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7603, Training Loss: 1.273e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7604, Training Loss: 1.273e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7605, Training Loss: 1.273e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7606, Training Loss: 1.273e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7607, Training Loss: 1.273e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7608, Training Loss: 1.273e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7609, Training Loss: 1.273e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7610, Training Loss: 1.273e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7611, Training Loss: 1.272e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7612, Training Loss: 1.272e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7613, Training Loss: 1.272e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7614, Training Loss: 1.272e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7615, Training Loss: 1.272e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7616, Training Loss: 1.272e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7617, Training Loss: 1.272e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7618, Training Loss: 1.272e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7619, Training Loss: 1.271e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7620, Training Loss: 1.271e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7621, Training Loss: 1.271e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7622, Training Loss: 1.271e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7623, Training Loss: 1.271e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7624, Training Loss: 1.271e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7625, Training Loss: 1.271e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7626, Training Loss: 1.271e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7627, Training Loss: 1.271e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7628, Training Loss: 1.270e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7629, Training Loss: 1.270e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7630, Training Loss: 1.270e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7631, Training Loss: 1.270e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7632, Training Loss: 1.270e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7633, Training Loss: 1.270e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7634, Training Loss: 1.270e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7635, Training Loss: 1.270e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7636, Training Loss: 1.269e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7637, Training Loss: 1.269e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7638, Training Loss: 1.269e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7639, Training Loss: 1.269e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7640, Training Loss: 1.269e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7641, Training Loss: 1.269e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7642, Training Loss: 1.269e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7643, Training Loss: 1.269e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7644, Training Loss: 1.269e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7645, Training Loss: 1.268e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7646, Training Loss: 1.268e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7647, Training Loss: 1.268e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7648, Training Loss: 1.268e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7649, Training Loss: 1.268e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7650, Training Loss: 1.268e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7651, Training Loss: 1.268e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7652, Training Loss: 1.268e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7653, Training Loss: 1.267e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7654, Training Loss: 1.267e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7655, Training Loss: 1.267e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7656, Training Loss: 1.267e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7657, Training Loss: 1.267e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7658, Training Loss: 1.267e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7659, Training Loss: 1.267e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7660, Training Loss: 1.267e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7661, Training Loss: 1.267e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7662, Training Loss: 1.266e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7663, Training Loss: 1.266e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7664, Training Loss: 1.266e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7665, Training Loss: 1.266e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7666, Training Loss: 1.266e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7667, Training Loss: 1.266e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7668, Training Loss: 1.266e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7669, Training Loss: 1.266e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7670, Training Loss: 1.265e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7671, Training Loss: 1.265e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7672, Training Loss: 1.265e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7673, Training Loss: 1.265e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7674, Training Loss: 1.265e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7675, Training Loss: 1.265e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7676, Training Loss: 1.265e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7677, Training Loss: 1.265e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7678, Training Loss: 1.265e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7679, Training Loss: 1.264e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7680, Training Loss: 1.264e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7681, Training Loss: 1.264e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7682, Training Loss: 1.264e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7683, Training Loss: 1.264e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7684, Training Loss: 1.264e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7685, Training Loss: 1.264e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7686, Training Loss: 1.264e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7687, Training Loss: 1.263e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7688, Training Loss: 1.263e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7689, Training Loss: 1.263e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7690, Training Loss: 1.263e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7691, Training Loss: 1.263e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7692, Training Loss: 1.263e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7693, Training Loss: 1.263e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7694, Training Loss: 1.263e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7695, Training Loss: 1.263e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7696, Training Loss: 1.262e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7697, Training Loss: 1.262e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7698, Training Loss: 1.262e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7699, Training Loss: 1.262e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7700, Training Loss: 1.262e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7701, Training Loss: 1.262e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7702, Training Loss: 1.262e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7703, Training Loss: 1.262e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7704, Training Loss: 1.262e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7705, Training Loss: 1.261e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7706, Training Loss: 1.261e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7707, Training Loss: 1.261e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7708, Training Loss: 1.261e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7709, Training Loss: 1.261e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7710, Training Loss: 1.261e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7711, Training Loss: 1.261e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7712, Training Loss: 1.261e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7713, Training Loss: 1.260e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7714, Training Loss: 1.260e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7715, Training Loss: 1.260e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7716, Training Loss: 1.260e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7717, Training Loss: 1.260e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7718, Training Loss: 1.260e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7719, Training Loss: 1.260e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7720, Training Loss: 1.260e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7721, Training Loss: 1.260e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7722, Training Loss: 1.259e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7723, Training Loss: 1.259e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7724, Training Loss: 1.259e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7725, Training Loss: 1.259e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7726, Training Loss: 1.259e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7727, Training Loss: 1.259e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7728, Training Loss: 1.259e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7729, Training Loss: 1.259e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7730, Training Loss: 1.258e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7731, Training Loss: 1.258e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7732, Training Loss: 1.258e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7733, Training Loss: 1.258e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7734, Training Loss: 1.258e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7735, Training Loss: 1.258e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7736, Training Loss: 1.258e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7737, Training Loss: 1.258e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7738, Training Loss: 1.258e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7739, Training Loss: 1.257e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7740, Training Loss: 1.257e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7741, Training Loss: 1.257e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7742, Training Loss: 1.257e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7743, Training Loss: 1.257e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7744, Training Loss: 1.257e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7745, Training Loss: 1.257e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7746, Training Loss: 1.257e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7747, Training Loss: 1.257e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7748, Training Loss: 1.256e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7749, Training Loss: 1.256e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7750, Training Loss: 1.256e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7751, Training Loss: 1.256e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7752, Training Loss: 1.256e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7753, Training Loss: 1.256e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7754, Training Loss: 1.256e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7755, Training Loss: 1.256e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7756, Training Loss: 1.255e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7757, Training Loss: 1.255e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7758, Training Loss: 1.255e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7759, Training Loss: 1.255e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7760, Training Loss: 1.255e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7761, Training Loss: 1.255e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7762, Training Loss: 1.255e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7763, Training Loss: 1.255e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7764, Training Loss: 1.255e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7765, Training Loss: 1.254e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7766, Training Loss: 1.254e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7767, Training Loss: 1.254e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7768, Training Loss: 1.254e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7769, Training Loss: 1.254e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7770, Training Loss: 1.254e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7771, Training Loss: 1.254e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7772, Training Loss: 1.254e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7773, Training Loss: 1.254e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7774, Training Loss: 1.253e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7775, Training Loss: 1.253e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7776, Training Loss: 1.253e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7777, Training Loss: 1.253e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7778, Training Loss: 1.253e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7779, Training Loss: 1.253e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7780, Training Loss: 1.253e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7781, Training Loss: 1.253e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7782, Training Loss: 1.252e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7783, Training Loss: 1.252e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7784, Training Loss: 1.252e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7785, Training Loss: 1.252e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7786, Training Loss: 1.252e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7787, Training Loss: 1.252e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7788, Training Loss: 1.252e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7789, Training Loss: 1.252e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7790, Training Loss: 1.252e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7791, Training Loss: 1.251e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7792, Training Loss: 1.251e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7793, Training Loss: 1.251e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7794, Training Loss: 1.251e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7795, Training Loss: 1.251e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7796, Training Loss: 1.251e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7797, Training Loss: 1.251e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7798, Training Loss: 1.251e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7799, Training Loss: 1.251e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7800, Training Loss: 1.250e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7801, Training Loss: 1.250e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7802, Training Loss: 1.250e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7803, Training Loss: 1.250e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7804, Training Loss: 1.250e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7805, Training Loss: 1.250e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7806, Training Loss: 1.250e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7807, Training Loss: 1.250e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7808, Training Loss: 1.249e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7809, Training Loss: 1.249e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7810, Training Loss: 1.249e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7811, Training Loss: 1.249e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7812, Training Loss: 1.249e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7813, Training Loss: 1.249e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7814, Training Loss: 1.249e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7815, Training Loss: 1.249e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7816, Training Loss: 1.249e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7817, Training Loss: 1.248e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7818, Training Loss: 1.248e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7819, Training Loss: 1.248e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7820, Training Loss: 1.248e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7821, Training Loss: 1.248e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7822, Training Loss: 1.248e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7823, Training Loss: 1.248e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7824, Training Loss: 1.248e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7825, Training Loss: 1.248e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7826, Training Loss: 1.247e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7827, Training Loss: 1.247e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7828, Training Loss: 1.247e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7829, Training Loss: 1.247e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7830, Training Loss: 1.247e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7831, Training Loss: 1.247e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7832, Training Loss: 1.247e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7833, Training Loss: 1.247e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7834, Training Loss: 1.246e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7835, Training Loss: 1.246e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7836, Training Loss: 1.246e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7837, Training Loss: 1.246e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7838, Training Loss: 1.246e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7839, Training Loss: 1.246e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7840, Training Loss: 1.246e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7841, Training Loss: 1.246e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7842, Training Loss: 1.246e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7843, Training Loss: 1.245e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7844, Training Loss: 1.245e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7845, Training Loss: 1.245e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7846, Training Loss: 1.245e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7847, Training Loss: 1.245e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7848, Training Loss: 1.245e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7849, Training Loss: 1.245e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7850, Training Loss: 1.245e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7851, Training Loss: 1.245e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7852, Training Loss: 1.244e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7853, Training Loss: 1.244e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7854, Training Loss: 1.244e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7855, Training Loss: 1.244e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7856, Training Loss: 1.244e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7857, Training Loss: 1.244e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7858, Training Loss: 1.244e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7859, Training Loss: 1.244e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7860, Training Loss: 1.244e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7861, Training Loss: 1.243e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7862, Training Loss: 1.243e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7863, Training Loss: 1.243e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7864, Training Loss: 1.243e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7865, Training Loss: 1.243e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7866, Training Loss: 1.243e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7867, Training Loss: 1.243e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7868, Training Loss: 1.243e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7869, Training Loss: 1.242e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7870, Training Loss: 1.242e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7871, Training Loss: 1.242e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7872, Training Loss: 1.242e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7873, Training Loss: 1.242e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7874, Training Loss: 1.242e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7875, Training Loss: 1.242e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7876, Training Loss: 1.242e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7877, Training Loss: 1.242e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7878, Training Loss: 1.241e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7879, Training Loss: 1.241e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7880, Training Loss: 1.241e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7881, Training Loss: 1.241e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7882, Training Loss: 1.241e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7883, Training Loss: 1.241e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7884, Training Loss: 1.241e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7885, Training Loss: 1.241e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7886, Training Loss: 1.241e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7887, Training Loss: 1.240e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7888, Training Loss: 1.240e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7889, Training Loss: 1.240e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7890, Training Loss: 1.240e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7891, Training Loss: 1.240e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7892, Training Loss: 1.240e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7893, Training Loss: 1.240e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7894, Training Loss: 1.240e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7895, Training Loss: 1.240e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7896, Training Loss: 1.239e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7897, Training Loss: 1.239e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7898, Training Loss: 1.239e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7899, Training Loss: 1.239e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7900, Training Loss: 1.239e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7901, Training Loss: 1.239e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7902, Training Loss: 1.239e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7903, Training Loss: 1.239e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7904, Training Loss: 1.239e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7905, Training Loss: 1.238e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7906, Training Loss: 1.238e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7907, Training Loss: 1.238e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7908, Training Loss: 1.238e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7909, Training Loss: 1.238e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7910, Training Loss: 1.238e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7911, Training Loss: 1.238e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7912, Training Loss: 1.238e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7913, Training Loss: 1.238e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7914, Training Loss: 1.237e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7915, Training Loss: 1.237e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7916, Training Loss: 1.237e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7917, Training Loss: 1.237e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7918, Training Loss: 1.237e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7919, Training Loss: 1.237e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7920, Training Loss: 1.237e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7921, Training Loss: 1.237e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7922, Training Loss: 1.236e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7923, Training Loss: 1.236e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7924, Training Loss: 1.236e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7925, Training Loss: 1.236e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7926, Training Loss: 1.236e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7927, Training Loss: 1.236e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7928, Training Loss: 1.236e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7929, Training Loss: 1.236e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7930, Training Loss: 1.236e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7931, Training Loss: 1.235e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7932, Training Loss: 1.235e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7933, Training Loss: 1.235e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7934, Training Loss: 1.235e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7935, Training Loss: 1.235e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7936, Training Loss: 1.235e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7937, Training Loss: 1.235e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7938, Training Loss: 1.235e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7939, Training Loss: 1.235e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7940, Training Loss: 1.234e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7941, Training Loss: 1.234e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7942, Training Loss: 1.234e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7943, Training Loss: 1.234e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7944, Training Loss: 1.234e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7945, Training Loss: 1.234e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7946, Training Loss: 1.234e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7947, Training Loss: 1.234e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7948, Training Loss: 1.234e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7949, Training Loss: 1.233e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7950, Training Loss: 1.233e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7951, Training Loss: 1.233e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7952, Training Loss: 1.233e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7953, Training Loss: 1.233e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7954, Training Loss: 1.233e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7955, Training Loss: 1.233e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7956, Training Loss: 1.233e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7957, Training Loss: 1.233e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7958, Training Loss: 1.232e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7959, Training Loss: 1.232e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7960, Training Loss: 1.232e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7961, Training Loss: 1.232e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7962, Training Loss: 1.232e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7963, Training Loss: 1.232e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7964, Training Loss: 1.232e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7965, Training Loss: 1.232e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7966, Training Loss: 1.232e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7967, Training Loss: 1.231e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7968, Training Loss: 1.231e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7969, Training Loss: 1.231e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7970, Training Loss: 1.231e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7971, Training Loss: 1.231e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7972, Training Loss: 1.231e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7973, Training Loss: 1.231e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7974, Training Loss: 1.231e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7975, Training Loss: 1.231e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7976, Training Loss: 1.230e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7977, Training Loss: 1.230e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7978, Training Loss: 1.230e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7979, Training Loss: 1.230e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7980, Training Loss: 1.230e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7981, Training Loss: 1.230e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7982, Training Loss: 1.230e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7983, Training Loss: 1.230e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7984, Training Loss: 1.230e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7985, Training Loss: 1.229e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7986, Training Loss: 1.229e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7987, Training Loss: 1.229e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7988, Training Loss: 1.229e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7989, Training Loss: 1.229e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7990, Training Loss: 1.229e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7991, Training Loss: 1.229e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7992, Training Loss: 1.229e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7993, Training Loss: 1.229e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7994, Training Loss: 1.228e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7995, Training Loss: 1.228e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7996, Training Loss: 1.228e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7997, Training Loss: 1.228e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7998, Training Loss: 1.228e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7999, Training Loss: 1.228e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8000, Training Loss: 1.228e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8001, Training Loss: 1.228e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8002, Training Loss: 1.227e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8003, Training Loss: 1.227e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8004, Training Loss: 1.227e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8005, Training Loss: 1.227e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8006, Training Loss: 1.227e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8007, Training Loss: 1.227e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8008, Training Loss: 1.227e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8009, Training Loss: 1.227e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8010, Training Loss: 1.227e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8011, Training Loss: 1.226e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8012, Training Loss: 1.226e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8013, Training Loss: 1.226e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8014, Training Loss: 1.226e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8015, Training Loss: 1.226e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8016, Training Loss: 1.226e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8017, Training Loss: 1.226e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8018, Training Loss: 1.226e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8019, Training Loss: 1.226e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8020, Training Loss: 1.225e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8021, Training Loss: 1.225e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8022, Training Loss: 1.225e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8023, Training Loss: 1.225e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8024, Training Loss: 1.225e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8025, Training Loss: 1.225e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8026, Training Loss: 1.225e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8027, Training Loss: 1.225e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8028, Training Loss: 1.225e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8029, Training Loss: 1.224e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8030, Training Loss: 1.224e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8031, Training Loss: 1.224e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8032, Training Loss: 1.224e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8033, Training Loss: 1.224e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8034, Training Loss: 1.224e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8035, Training Loss: 1.224e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8036, Training Loss: 1.224e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8037, Training Loss: 1.224e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8038, Training Loss: 1.223e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8039, Training Loss: 1.223e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8040, Training Loss: 1.223e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8041, Training Loss: 1.223e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8042, Training Loss: 1.223e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8043, Training Loss: 1.223e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8044, Training Loss: 1.223e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8045, Training Loss: 1.223e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8046, Training Loss: 1.223e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8047, Training Loss: 1.222e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8048, Training Loss: 1.222e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8049, Training Loss: 1.222e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8050, Training Loss: 1.222e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8051, Training Loss: 1.222e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8052, Training Loss: 1.222e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8053, Training Loss: 1.222e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8054, Training Loss: 1.222e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8055, Training Loss: 1.222e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8056, Training Loss: 1.221e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8057, Training Loss: 1.221e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8058, Training Loss: 1.221e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8059, Training Loss: 1.221e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8060, Training Loss: 1.221e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8061, Training Loss: 1.221e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8062, Training Loss: 1.221e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8063, Training Loss: 1.221e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8064, Training Loss: 1.221e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8065, Training Loss: 1.220e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8066, Training Loss: 1.220e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8067, Training Loss: 1.220e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8068, Training Loss: 1.220e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8069, Training Loss: 1.220e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8070, Training Loss: 1.220e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8071, Training Loss: 1.220e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8072, Training Loss: 1.220e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8073, Training Loss: 1.220e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8074, Training Loss: 1.219e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8075, Training Loss: 1.219e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8076, Training Loss: 1.219e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8077, Training Loss: 1.219e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8078, Training Loss: 1.219e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8079, Training Loss: 1.219e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8080, Training Loss: 1.219e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8081, Training Loss: 1.219e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8082, Training Loss: 1.219e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8083, Training Loss: 1.218e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8084, Training Loss: 1.218e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8085, Training Loss: 1.218e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8086, Training Loss: 1.218e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8087, Training Loss: 1.218e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8088, Training Loss: 1.218e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8089, Training Loss: 1.218e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8090, Training Loss: 1.218e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8091, Training Loss: 1.218e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8092, Training Loss: 1.218e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8093, Training Loss: 1.217e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8094, Training Loss: 1.217e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8095, Training Loss: 1.217e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8096, Training Loss: 1.217e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8097, Training Loss: 1.217e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8098, Training Loss: 1.217e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8099, Training Loss: 1.217e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8100, Training Loss: 1.217e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8101, Training Loss: 1.217e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8102, Training Loss: 1.216e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8103, Training Loss: 1.216e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8104, Training Loss: 1.216e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8105, Training Loss: 1.216e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8106, Training Loss: 1.216e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8107, Training Loss: 1.216e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8108, Training Loss: 1.216e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8109, Training Loss: 1.216e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8110, Training Loss: 1.216e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8111, Training Loss: 1.215e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8112, Training Loss: 1.215e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8113, Training Loss: 1.215e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8114, Training Loss: 1.215e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8115, Training Loss: 1.215e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8116, Training Loss: 1.215e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8117, Training Loss: 1.215e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8118, Training Loss: 1.215e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8119, Training Loss: 1.215e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8120, Training Loss: 1.214e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8121, Training Loss: 1.214e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8122, Training Loss: 1.214e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8123, Training Loss: 1.214e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8124, Training Loss: 1.214e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8125, Training Loss: 1.214e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8126, Training Loss: 1.214e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8127, Training Loss: 1.214e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8128, Training Loss: 1.214e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8129, Training Loss: 1.213e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8130, Training Loss: 1.213e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8131, Training Loss: 1.213e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8132, Training Loss: 1.213e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8133, Training Loss: 1.213e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8134, Training Loss: 1.213e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8135, Training Loss: 1.213e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8136, Training Loss: 1.213e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8137, Training Loss: 1.213e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8138, Training Loss: 1.212e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8139, Training Loss: 1.212e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8140, Training Loss: 1.212e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8141, Training Loss: 1.212e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8142, Training Loss: 1.212e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8143, Training Loss: 1.212e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8144, Training Loss: 1.212e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8145, Training Loss: 1.212e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8146, Training Loss: 1.212e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8147, Training Loss: 1.211e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8148, Training Loss: 1.211e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8149, Training Loss: 1.211e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8150, Training Loss: 1.211e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8151, Training Loss: 1.211e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8152, Training Loss: 1.211e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8153, Training Loss: 1.211e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8154, Training Loss: 1.211e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8155, Training Loss: 1.211e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8156, Training Loss: 1.210e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8157, Training Loss: 1.210e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8158, Training Loss: 1.210e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8159, Training Loss: 1.210e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8160, Training Loss: 1.210e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8161, Training Loss: 1.210e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8162, Training Loss: 1.210e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8163, Training Loss: 1.210e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8164, Training Loss: 1.210e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8165, Training Loss: 1.209e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8166, Training Loss: 1.209e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8167, Training Loss: 1.209e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8168, Training Loss: 1.209e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8169, Training Loss: 1.209e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8170, Training Loss: 1.209e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8171, Training Loss: 1.209e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8172, Training Loss: 1.209e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8173, Training Loss: 1.209e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8174, Training Loss: 1.209e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8175, Training Loss: 1.208e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8176, Training Loss: 1.208e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8177, Training Loss: 1.208e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8178, Training Loss: 1.208e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8179, Training Loss: 1.208e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8180, Training Loss: 1.208e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8181, Training Loss: 1.208e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8182, Training Loss: 1.208e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8183, Training Loss: 1.208e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8184, Training Loss: 1.207e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8185, Training Loss: 1.207e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8186, Training Loss: 1.207e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8187, Training Loss: 1.207e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8188, Training Loss: 1.207e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8189, Training Loss: 1.207e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8190, Training Loss: 1.207e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8191, Training Loss: 1.207e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8192, Training Loss: 1.207e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8193, Training Loss: 1.206e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8194, Training Loss: 1.206e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8195, Training Loss: 1.206e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8196, Training Loss: 1.206e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8197, Training Loss: 1.206e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8198, Training Loss: 1.206e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8199, Training Loss: 1.206e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8200, Training Loss: 1.206e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8201, Training Loss: 1.206e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8202, Training Loss: 1.205e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8203, Training Loss: 1.205e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8204, Training Loss: 1.205e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8205, Training Loss: 1.205e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8206, Training Loss: 1.205e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8207, Training Loss: 1.205e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8208, Training Loss: 1.205e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8209, Training Loss: 1.205e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8210, Training Loss: 1.205e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8211, Training Loss: 1.204e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8212, Training Loss: 1.204e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8213, Training Loss: 1.204e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8214, Training Loss: 1.204e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8215, Training Loss: 1.204e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8216, Training Loss: 1.204e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8217, Training Loss: 1.204e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8218, Training Loss: 1.204e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8219, Training Loss: 1.204e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8220, Training Loss: 1.204e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8221, Training Loss: 1.203e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8222, Training Loss: 1.203e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8223, Training Loss: 1.203e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8224, Training Loss: 1.203e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8225, Training Loss: 1.203e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8226, Training Loss: 1.203e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8227, Training Loss: 1.203e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8228, Training Loss: 1.203e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8229, Training Loss: 1.203e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8230, Training Loss: 1.202e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8231, Training Loss: 1.202e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8232, Training Loss: 1.202e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8233, Training Loss: 1.202e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8234, Training Loss: 1.202e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8235, Training Loss: 1.202e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8236, Training Loss: 1.202e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8237, Training Loss: 1.202e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8238, Training Loss: 1.202e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8239, Training Loss: 1.201e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8240, Training Loss: 1.201e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8241, Training Loss: 1.201e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8242, Training Loss: 1.201e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8243, Training Loss: 1.201e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8244, Training Loss: 1.201e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8245, Training Loss: 1.201e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8246, Training Loss: 1.201e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8247, Training Loss: 1.201e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8248, Training Loss: 1.200e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8249, Training Loss: 1.200e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8250, Training Loss: 1.200e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8251, Training Loss: 1.200e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8252, Training Loss: 1.200e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8253, Training Loss: 1.200e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8254, Training Loss: 1.200e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8255, Training Loss: 1.200e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8256, Training Loss: 1.200e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8257, Training Loss: 1.200e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8258, Training Loss: 1.199e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8259, Training Loss: 1.199e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8260, Training Loss: 1.199e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8261, Training Loss: 1.199e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8262, Training Loss: 1.199e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8263, Training Loss: 1.199e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8264, Training Loss: 1.199e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8265, Training Loss: 1.199e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8266, Training Loss: 1.199e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8267, Training Loss: 1.198e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8268, Training Loss: 1.198e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8269, Training Loss: 1.198e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8270, Training Loss: 1.198e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8271, Training Loss: 1.198e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8272, Training Loss: 1.198e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8273, Training Loss: 1.198e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8274, Training Loss: 1.198e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8275, Training Loss: 1.198e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8276, Training Loss: 1.197e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8277, Training Loss: 1.197e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8278, Training Loss: 1.197e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8279, Training Loss: 1.197e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8280, Training Loss: 1.197e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8281, Training Loss: 1.197e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8282, Training Loss: 1.197e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8283, Training Loss: 1.197e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8284, Training Loss: 1.197e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8285, Training Loss: 1.196e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8286, Training Loss: 1.196e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8287, Training Loss: 1.196e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8288, Training Loss: 1.196e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8289, Training Loss: 1.196e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8290, Training Loss: 1.196e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8291, Training Loss: 1.196e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8292, Training Loss: 1.196e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8293, Training Loss: 1.196e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8294, Training Loss: 1.196e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8295, Training Loss: 1.195e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8296, Training Loss: 1.195e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8297, Training Loss: 1.195e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8298, Training Loss: 1.195e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8299, Training Loss: 1.195e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8300, Training Loss: 1.195e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8301, Training Loss: 1.195e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8302, Training Loss: 1.195e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8303, Training Loss: 1.195e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8304, Training Loss: 1.194e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8305, Training Loss: 1.194e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8306, Training Loss: 1.194e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8307, Training Loss: 1.194e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8308, Training Loss: 1.194e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8309, Training Loss: 1.194e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8310, Training Loss: 1.194e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8311, Training Loss: 1.194e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8312, Training Loss: 1.194e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8313, Training Loss: 1.193e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8314, Training Loss: 1.193e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8315, Training Loss: 1.193e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8316, Training Loss: 1.193e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8317, Training Loss: 1.193e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8318, Training Loss: 1.193e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8319, Training Loss: 1.193e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8320, Training Loss: 1.193e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8321, Training Loss: 1.193e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8322, Training Loss: 1.193e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8323, Training Loss: 1.192e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8324, Training Loss: 1.192e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8325, Training Loss: 1.192e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8326, Training Loss: 1.192e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8327, Training Loss: 1.192e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8328, Training Loss: 1.192e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8329, Training Loss: 1.192e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8330, Training Loss: 1.192e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8331, Training Loss: 1.192e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8332, Training Loss: 1.191e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8333, Training Loss: 1.191e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8334, Training Loss: 1.191e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8335, Training Loss: 1.191e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8336, Training Loss: 1.191e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8337, Training Loss: 1.191e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8338, Training Loss: 1.191e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8339, Training Loss: 1.191e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8340, Training Loss: 1.191e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8341, Training Loss: 1.191e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8342, Training Loss: 1.190e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8343, Training Loss: 1.190e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8344, Training Loss: 1.190e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8345, Training Loss: 1.190e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8346, Training Loss: 1.190e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8347, Training Loss: 1.190e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8348, Training Loss: 1.190e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8349, Training Loss: 1.190e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8350, Training Loss: 1.190e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8351, Training Loss: 1.189e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8352, Training Loss: 1.189e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8353, Training Loss: 1.189e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8354, Training Loss: 1.189e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8355, Training Loss: 1.189e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8356, Training Loss: 1.189e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8357, Training Loss: 1.189e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8358, Training Loss: 1.189e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8359, Training Loss: 1.189e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8360, Training Loss: 1.188e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8361, Training Loss: 1.188e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8362, Training Loss: 1.188e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8363, Training Loss: 1.188e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8364, Training Loss: 1.188e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8365, Training Loss: 1.188e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8366, Training Loss: 1.188e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8367, Training Loss: 1.188e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8368, Training Loss: 1.188e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8369, Training Loss: 1.188e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8370, Training Loss: 1.187e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8371, Training Loss: 1.187e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8372, Training Loss: 1.187e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8373, Training Loss: 1.187e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8374, Training Loss: 1.187e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8375, Training Loss: 1.187e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8376, Training Loss: 1.187e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8377, Training Loss: 1.187e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8378, Training Loss: 1.187e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8379, Training Loss: 1.186e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8380, Training Loss: 1.186e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8381, Training Loss: 1.186e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8382, Training Loss: 1.186e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8383, Training Loss: 1.186e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8384, Training Loss: 1.186e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8385, Training Loss: 1.186e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8386, Training Loss: 1.186e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8387, Training Loss: 1.186e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8388, Training Loss: 1.186e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8389, Training Loss: 1.185e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8390, Training Loss: 1.185e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8391, Training Loss: 1.185e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8392, Training Loss: 1.185e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8393, Training Loss: 1.185e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8394, Training Loss: 1.185e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8395, Training Loss: 1.185e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8396, Training Loss: 1.185e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8397, Training Loss: 1.185e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8398, Training Loss: 1.184e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8399, Training Loss: 1.184e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8400, Training Loss: 1.184e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8401, Training Loss: 1.184e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8402, Training Loss: 1.184e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8403, Training Loss: 1.184e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8404, Training Loss: 1.184e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8405, Training Loss: 1.184e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8406, Training Loss: 1.184e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8407, Training Loss: 1.184e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8408, Training Loss: 1.183e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8409, Training Loss: 1.183e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8410, Training Loss: 1.183e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8411, Training Loss: 1.183e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8412, Training Loss: 1.183e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8413, Training Loss: 1.183e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8414, Training Loss: 1.183e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8415, Training Loss: 1.183e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8416, Training Loss: 1.183e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8417, Training Loss: 1.182e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8418, Training Loss: 1.182e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8419, Training Loss: 1.182e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8420, Training Loss: 1.182e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8421, Training Loss: 1.182e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8422, Training Loss: 1.182e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8423, Training Loss: 1.182e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8424, Training Loss: 1.182e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8425, Training Loss: 1.182e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8426, Training Loss: 1.182e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8427, Training Loss: 1.181e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8428, Training Loss: 1.181e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8429, Training Loss: 1.181e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8430, Training Loss: 1.181e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8431, Training Loss: 1.181e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8432, Training Loss: 1.181e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8433, Training Loss: 1.181e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8434, Training Loss: 1.181e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8435, Training Loss: 1.181e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8436, Training Loss: 1.180e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8437, Training Loss: 1.180e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8438, Training Loss: 1.180e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8439, Training Loss: 1.180e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8440, Training Loss: 1.180e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8441, Training Loss: 1.180e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8442, Training Loss: 1.180e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8443, Training Loss: 1.180e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8444, Training Loss: 1.180e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8445, Training Loss: 1.180e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8446, Training Loss: 1.179e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8447, Training Loss: 1.179e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8448, Training Loss: 1.179e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8449, Training Loss: 1.179e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8450, Training Loss: 1.179e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8451, Training Loss: 1.179e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8452, Training Loss: 1.179e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8453, Training Loss: 1.179e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8454, Training Loss: 1.179e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8455, Training Loss: 1.178e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8456, Training Loss: 1.178e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8457, Training Loss: 1.178e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8458, Training Loss: 1.178e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8459, Training Loss: 1.178e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8460, Training Loss: 1.178e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8461, Training Loss: 1.178e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8462, Training Loss: 1.178e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8463, Training Loss: 1.178e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8464, Training Loss: 1.178e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8465, Training Loss: 1.177e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8466, Training Loss: 1.177e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8467, Training Loss: 1.177e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8468, Training Loss: 1.177e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8469, Training Loss: 1.177e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8470, Training Loss: 1.177e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8471, Training Loss: 1.177e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8472, Training Loss: 1.177e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8473, Training Loss: 1.177e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8474, Training Loss: 1.176e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8475, Training Loss: 1.176e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8476, Training Loss: 1.176e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8477, Training Loss: 1.176e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8478, Training Loss: 1.176e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8479, Training Loss: 1.176e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8480, Training Loss: 1.176e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8481, Training Loss: 1.176e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8482, Training Loss: 1.176e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8483, Training Loss: 1.176e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8484, Training Loss: 1.175e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8485, Training Loss: 1.175e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8486, Training Loss: 1.175e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8487, Training Loss: 1.175e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8488, Training Loss: 1.175e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8489, Training Loss: 1.175e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8490, Training Loss: 1.175e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8491, Training Loss: 1.175e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8492, Training Loss: 1.175e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8493, Training Loss: 1.174e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8494, Training Loss: 1.174e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8495, Training Loss: 1.174e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8496, Training Loss: 1.174e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8497, Training Loss: 1.174e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8498, Training Loss: 1.174e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8499, Training Loss: 1.174e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8500, Training Loss: 1.174e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8501, Training Loss: 1.174e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8502, Training Loss: 1.174e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8503, Training Loss: 1.173e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8504, Training Loss: 1.173e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8505, Training Loss: 1.173e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8506, Training Loss: 1.173e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8507, Training Loss: 1.173e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8508, Training Loss: 1.173e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8509, Training Loss: 1.173e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8510, Training Loss: 1.173e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8511, Training Loss: 1.173e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8512, Training Loss: 1.173e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8513, Training Loss: 1.172e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8514, Training Loss: 1.172e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8515, Training Loss: 1.172e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8516, Training Loss: 1.172e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8517, Training Loss: 1.172e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8518, Training Loss: 1.172e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8519, Training Loss: 1.172e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8520, Training Loss: 1.172e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8521, Training Loss: 1.172e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8522, Training Loss: 1.171e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8523, Training Loss: 1.171e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8524, Training Loss: 1.171e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8525, Training Loss: 1.171e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8526, Training Loss: 1.171e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8527, Training Loss: 1.171e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8528, Training Loss: 1.171e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8529, Training Loss: 1.171e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8530, Training Loss: 1.171e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8531, Training Loss: 1.171e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8532, Training Loss: 1.170e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8533, Training Loss: 1.170e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8534, Training Loss: 1.170e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8535, Training Loss: 1.170e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8536, Training Loss: 1.170e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8537, Training Loss: 1.170e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8538, Training Loss: 1.170e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8539, Training Loss: 1.170e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8540, Training Loss: 1.170e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8541, Training Loss: 1.170e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8542, Training Loss: 1.169e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8543, Training Loss: 1.169e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8544, Training Loss: 1.169e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8545, Training Loss: 1.169e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8546, Training Loss: 1.169e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8547, Training Loss: 1.169e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8548, Training Loss: 1.169e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8549, Training Loss: 1.169e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8550, Training Loss: 1.169e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8551, Training Loss: 1.168e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8552, Training Loss: 1.168e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8553, Training Loss: 1.168e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8554, Training Loss: 1.168e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8555, Training Loss: 1.168e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8556, Training Loss: 1.168e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8557, Training Loss: 1.168e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8558, Training Loss: 1.168e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8559, Training Loss: 1.168e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8560, Training Loss: 1.168e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8561, Training Loss: 1.167e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8562, Training Loss: 1.167e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8563, Training Loss: 1.167e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8564, Training Loss: 1.167e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8565, Training Loss: 1.167e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8566, Training Loss: 1.167e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8567, Training Loss: 1.167e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8568, Training Loss: 1.167e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8569, Training Loss: 1.167e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8570, Training Loss: 1.167e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8571, Training Loss: 1.166e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8572, Training Loss: 1.166e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8573, Training Loss: 1.166e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8574, Training Loss: 1.166e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8575, Training Loss: 1.166e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8576, Training Loss: 1.166e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8577, Training Loss: 1.166e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8578, Training Loss: 1.166e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8579, Training Loss: 1.166e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8580, Training Loss: 1.165e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8581, Training Loss: 1.165e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8582, Training Loss: 1.165e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8583, Training Loss: 1.165e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8584, Training Loss: 1.165e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8585, Training Loss: 1.165e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8586, Training Loss: 1.165e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8587, Training Loss: 1.165e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8588, Training Loss: 1.165e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8589, Training Loss: 1.165e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8590, Training Loss: 1.164e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8591, Training Loss: 1.164e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8592, Training Loss: 1.164e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8593, Training Loss: 1.164e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8594, Training Loss: 1.164e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8595, Training Loss: 1.164e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8596, Training Loss: 1.164e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8597, Training Loss: 1.164e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8598, Training Loss: 1.164e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8599, Training Loss: 1.164e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8600, Training Loss: 1.163e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8601, Training Loss: 1.163e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8602, Training Loss: 1.163e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8603, Training Loss: 1.163e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8604, Training Loss: 1.163e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8605, Training Loss: 1.163e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8606, Training Loss: 1.163e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8607, Training Loss: 1.163e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8608, Training Loss: 1.163e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8609, Training Loss: 1.163e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8610, Training Loss: 1.162e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8611, Training Loss: 1.162e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8612, Training Loss: 1.162e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8613, Training Loss: 1.162e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8614, Training Loss: 1.162e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8615, Training Loss: 1.162e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8616, Training Loss: 1.162e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8617, Training Loss: 1.162e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8618, Training Loss: 1.162e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8619, Training Loss: 1.161e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8620, Training Loss: 1.161e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8621, Training Loss: 1.161e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8622, Training Loss: 1.161e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8623, Training Loss: 1.161e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8624, Training Loss: 1.161e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8625, Training Loss: 1.161e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8626, Training Loss: 1.161e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8627, Training Loss: 1.161e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8628, Training Loss: 1.161e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8629, Training Loss: 1.160e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8630, Training Loss: 1.160e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8631, Training Loss: 1.160e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8632, Training Loss: 1.160e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8633, Training Loss: 1.160e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8634, Training Loss: 1.160e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8635, Training Loss: 1.160e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8636, Training Loss: 1.160e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8637, Training Loss: 1.160e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8638, Training Loss: 1.160e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8639, Training Loss: 1.159e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8640, Training Loss: 1.159e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8641, Training Loss: 1.159e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8642, Training Loss: 1.159e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8643, Training Loss: 1.159e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8644, Training Loss: 1.159e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8645, Training Loss: 1.159e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8646, Training Loss: 1.159e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8647, Training Loss: 1.159e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8648, Training Loss: 1.159e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8649, Training Loss: 1.158e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8650, Training Loss: 1.158e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8651, Training Loss: 1.158e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8652, Training Loss: 1.158e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8653, Training Loss: 1.158e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8654, Training Loss: 1.158e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8655, Training Loss: 1.158e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8656, Training Loss: 1.158e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8657, Training Loss: 1.158e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8658, Training Loss: 1.158e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8659, Training Loss: 1.157e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8660, Training Loss: 1.157e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8661, Training Loss: 1.157e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8662, Training Loss: 1.157e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8663, Training Loss: 1.157e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8664, Training Loss: 1.157e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8665, Training Loss: 1.157e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8666, Training Loss: 1.157e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8667, Training Loss: 1.157e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8668, Training Loss: 1.156e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8669, Training Loss: 1.156e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8670, Training Loss: 1.156e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8671, Training Loss: 1.156e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8672, Training Loss: 1.156e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8673, Training Loss: 1.156e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8674, Training Loss: 1.156e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8675, Training Loss: 1.156e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8676, Training Loss: 1.156e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8677, Training Loss: 1.156e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8678, Training Loss: 1.155e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8679, Training Loss: 1.155e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8680, Training Loss: 1.155e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8681, Training Loss: 1.155e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8682, Training Loss: 1.155e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8683, Training Loss: 1.155e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8684, Training Loss: 1.155e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8685, Training Loss: 1.155e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8686, Training Loss: 1.155e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8687, Training Loss: 1.155e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8688, Training Loss: 1.154e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8689, Training Loss: 1.154e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8690, Training Loss: 1.154e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8691, Training Loss: 1.154e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8692, Training Loss: 1.154e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8693, Training Loss: 1.154e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8694, Training Loss: 1.154e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8695, Training Loss: 1.154e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8696, Training Loss: 1.154e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8697, Training Loss: 1.154e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8698, Training Loss: 1.153e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8699, Training Loss: 1.153e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8700, Training Loss: 1.153e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8701, Training Loss: 1.153e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8702, Training Loss: 1.153e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8703, Training Loss: 1.153e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8704, Training Loss: 1.153e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8705, Training Loss: 1.153e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8706, Training Loss: 1.153e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8707, Training Loss: 1.153e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8708, Training Loss: 1.152e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8709, Training Loss: 1.152e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8710, Training Loss: 1.152e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8711, Training Loss: 1.152e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8712, Training Loss: 1.152e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8713, Training Loss: 1.152e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8714, Training Loss: 1.152e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8715, Training Loss: 1.152e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8716, Training Loss: 1.152e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8717, Training Loss: 1.152e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8718, Training Loss: 1.151e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8719, Training Loss: 1.151e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8720, Training Loss: 1.151e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8721, Training Loss: 1.151e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8722, Training Loss: 1.151e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8723, Training Loss: 1.151e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8724, Training Loss: 1.151e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8725, Training Loss: 1.151e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8726, Training Loss: 1.151e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8727, Training Loss: 1.151e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8728, Training Loss: 1.150e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8729, Training Loss: 1.150e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8730, Training Loss: 1.150e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8731, Training Loss: 1.150e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8732, Training Loss: 1.150e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8733, Training Loss: 1.150e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8734, Training Loss: 1.150e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8735, Training Loss: 1.150e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8736, Training Loss: 1.150e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8737, Training Loss: 1.150e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8738, Training Loss: 1.149e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8739, Training Loss: 1.149e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8740, Training Loss: 1.149e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8741, Training Loss: 1.149e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8742, Training Loss: 1.149e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8743, Training Loss: 1.149e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8744, Training Loss: 1.149e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8745, Training Loss: 1.149e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8746, Training Loss: 1.149e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8747, Training Loss: 1.149e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8748, Training Loss: 1.148e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8749, Training Loss: 1.148e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8750, Training Loss: 1.148e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8751, Training Loss: 1.148e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8752, Training Loss: 1.148e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8753, Training Loss: 1.148e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8754, Training Loss: 1.148e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8755, Training Loss: 1.148e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8756, Training Loss: 1.148e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8757, Training Loss: 1.148e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8758, Training Loss: 1.147e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8759, Training Loss: 1.147e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8760, Training Loss: 1.147e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8761, Training Loss: 1.147e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8762, Training Loss: 1.147e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8763, Training Loss: 1.147e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8764, Training Loss: 1.147e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8765, Training Loss: 1.147e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8766, Training Loss: 1.147e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8767, Training Loss: 1.147e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8768, Training Loss: 1.146e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8769, Training Loss: 1.146e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8770, Training Loss: 1.146e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8771, Training Loss: 1.146e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8772, Training Loss: 1.146e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8773, Training Loss: 1.146e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8774, Training Loss: 1.146e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8775, Training Loss: 1.146e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8776, Training Loss: 1.146e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8777, Training Loss: 1.146e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8778, Training Loss: 1.145e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8779, Training Loss: 1.145e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8780, Training Loss: 1.145e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8781, Training Loss: 1.145e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8782, Training Loss: 1.145e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8783, Training Loss: 1.145e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8784, Training Loss: 1.145e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8785, Training Loss: 1.145e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8786, Training Loss: 1.145e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8787, Training Loss: 1.145e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8788, Training Loss: 1.144e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8789, Training Loss: 1.144e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8790, Training Loss: 1.144e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8791, Training Loss: 1.144e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8792, Training Loss: 1.144e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8793, Training Loss: 1.144e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8794, Training Loss: 1.144e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8795, Training Loss: 1.144e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8796, Training Loss: 1.144e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8797, Training Loss: 1.144e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8798, Training Loss: 1.143e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8799, Training Loss: 1.143e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8800, Training Loss: 1.143e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8801, Training Loss: 1.143e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8802, Training Loss: 1.143e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8803, Training Loss: 1.143e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8804, Training Loss: 1.143e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8805, Training Loss: 1.143e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8806, Training Loss: 1.143e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8807, Training Loss: 1.143e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8808, Training Loss: 1.142e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8809, Training Loss: 1.142e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8810, Training Loss: 1.142e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8811, Training Loss: 1.142e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8812, Training Loss: 1.142e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8813, Training Loss: 1.142e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8814, Training Loss: 1.142e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8815, Training Loss: 1.142e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8816, Training Loss: 1.142e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8817, Training Loss: 1.142e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8818, Training Loss: 1.141e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8819, Training Loss: 1.141e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8820, Training Loss: 1.141e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8821, Training Loss: 1.141e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8822, Training Loss: 1.141e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8823, Training Loss: 1.141e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8824, Training Loss: 1.141e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8825, Training Loss: 1.141e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8826, Training Loss: 1.141e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8827, Training Loss: 1.141e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8828, Training Loss: 1.140e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8829, Training Loss: 1.140e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8830, Training Loss: 1.140e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8831, Training Loss: 1.140e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8832, Training Loss: 1.140e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8833, Training Loss: 1.140e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8834, Training Loss: 1.140e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8835, Training Loss: 1.140e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8836, Training Loss: 1.140e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8837, Training Loss: 1.140e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8838, Training Loss: 1.139e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8839, Training Loss: 1.139e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8840, Training Loss: 1.139e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8841, Training Loss: 1.139e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8842, Training Loss: 1.139e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8843, Training Loss: 1.139e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8844, Training Loss: 1.139e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8845, Training Loss: 1.139e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8846, Training Loss: 1.139e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8847, Training Loss: 1.139e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8848, Training Loss: 1.138e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8849, Training Loss: 1.138e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8850, Training Loss: 1.138e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8851, Training Loss: 1.138e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8852, Training Loss: 1.138e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8853, Training Loss: 1.138e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8854, Training Loss: 1.138e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8855, Training Loss: 1.138e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8856, Training Loss: 1.138e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8857, Training Loss: 1.138e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8858, Training Loss: 1.137e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8859, Training Loss: 1.137e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8860, Training Loss: 1.137e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8861, Training Loss: 1.137e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8862, Training Loss: 1.137e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8863, Training Loss: 1.137e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8864, Training Loss: 1.137e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8865, Training Loss: 1.137e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8866, Training Loss: 1.137e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8867, Training Loss: 1.137e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8868, Training Loss: 1.136e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8869, Training Loss: 1.136e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8870, Training Loss: 1.136e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8871, Training Loss: 1.136e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8872, Training Loss: 1.136e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8873, Training Loss: 1.136e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8874, Training Loss: 1.136e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8875, Training Loss: 1.136e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8876, Training Loss: 1.136e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8877, Training Loss: 1.136e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8878, Training Loss: 1.135e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8879, Training Loss: 1.135e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8880, Training Loss: 1.135e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8881, Training Loss: 1.135e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8882, Training Loss: 1.135e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8883, Training Loss: 1.135e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8884, Training Loss: 1.135e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8885, Training Loss: 1.135e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8886, Training Loss: 1.135e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8887, Training Loss: 1.135e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8888, Training Loss: 1.134e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8889, Training Loss: 1.134e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8890, Training Loss: 1.134e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8891, Training Loss: 1.134e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8892, Training Loss: 1.134e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8893, Training Loss: 1.134e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8894, Training Loss: 1.134e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8895, Training Loss: 1.134e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8896, Training Loss: 1.134e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8897, Training Loss: 1.134e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8898, Training Loss: 1.134e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8899, Training Loss: 1.133e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8900, Training Loss: 1.133e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8901, Training Loss: 1.133e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8902, Training Loss: 1.133e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8903, Training Loss: 1.133e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8904, Training Loss: 1.133e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8905, Training Loss: 1.133e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8906, Training Loss: 1.133e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8907, Training Loss: 1.133e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8908, Training Loss: 1.133e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8909, Training Loss: 1.132e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8910, Training Loss: 1.132e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8911, Training Loss: 1.132e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8912, Training Loss: 1.132e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8913, Training Loss: 1.132e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8914, Training Loss: 1.132e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8915, Training Loss: 1.132e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8916, Training Loss: 1.132e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8917, Training Loss: 1.132e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8918, Training Loss: 1.132e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8919, Training Loss: 1.131e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8920, Training Loss: 1.131e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8921, Training Loss: 1.131e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8922, Training Loss: 1.131e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8923, Training Loss: 1.131e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8924, Training Loss: 1.131e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8925, Training Loss: 1.131e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8926, Training Loss: 1.131e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8927, Training Loss: 1.131e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8928, Training Loss: 1.131e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8929, Training Loss: 1.130e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8930, Training Loss: 1.130e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8931, Training Loss: 1.130e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8932, Training Loss: 1.130e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8933, Training Loss: 1.130e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8934, Training Loss: 1.130e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8935, Training Loss: 1.130e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8936, Training Loss: 1.130e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8937, Training Loss: 1.130e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8938, Training Loss: 1.130e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8939, Training Loss: 1.129e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8940, Training Loss: 1.129e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8941, Training Loss: 1.129e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8942, Training Loss: 1.129e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8943, Training Loss: 1.129e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8944, Training Loss: 1.129e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8945, Training Loss: 1.129e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8946, Training Loss: 1.129e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8947, Training Loss: 1.129e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8948, Training Loss: 1.129e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8949, Training Loss: 1.129e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8950, Training Loss: 1.128e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8951, Training Loss: 1.128e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8952, Training Loss: 1.128e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8953, Training Loss: 1.128e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8954, Training Loss: 1.128e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8955, Training Loss: 1.128e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8956, Training Loss: 1.128e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8957, Training Loss: 1.128e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8958, Training Loss: 1.128e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8959, Training Loss: 1.128e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8960, Training Loss: 1.127e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8961, Training Loss: 1.127e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8962, Training Loss: 1.127e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8963, Training Loss: 1.127e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8964, Training Loss: 1.127e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8965, Training Loss: 1.127e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8966, Training Loss: 1.127e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8967, Training Loss: 1.127e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8968, Training Loss: 1.127e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8969, Training Loss: 1.127e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8970, Training Loss: 1.126e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8971, Training Loss: 1.126e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8972, Training Loss: 1.126e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8973, Training Loss: 1.126e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8974, Training Loss: 1.126e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8975, Training Loss: 1.126e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8976, Training Loss: 1.126e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8977, Training Loss: 1.126e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8978, Training Loss: 1.126e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8979, Training Loss: 1.126e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8980, Training Loss: 1.125e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8981, Training Loss: 1.125e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8982, Training Loss: 1.125e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8983, Training Loss: 1.125e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8984, Training Loss: 1.125e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8985, Training Loss: 1.125e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8986, Training Loss: 1.125e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8987, Training Loss: 1.125e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8988, Training Loss: 1.125e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8989, Training Loss: 1.125e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8990, Training Loss: 1.125e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8991, Training Loss: 1.124e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8992, Training Loss: 1.124e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8993, Training Loss: 1.124e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8994, Training Loss: 1.124e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8995, Training Loss: 1.124e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8996, Training Loss: 1.124e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8997, Training Loss: 1.124e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8998, Training Loss: 1.124e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8999, Training Loss: 1.124e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9000, Training Loss: 1.124e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9001, Training Loss: 1.123e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9002, Training Loss: 1.123e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9003, Training Loss: 1.123e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9004, Training Loss: 1.123e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9005, Training Loss: 1.123e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9006, Training Loss: 1.123e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9007, Training Loss: 1.123e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9008, Training Loss: 1.123e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9009, Training Loss: 1.123e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9010, Training Loss: 1.123e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9011, Training Loss: 1.122e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9012, Training Loss: 1.122e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9013, Training Loss: 1.122e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9014, Training Loss: 1.122e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9015, Training Loss: 1.122e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9016, Training Loss: 1.122e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9017, Training Loss: 1.122e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9018, Training Loss: 1.122e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9019, Training Loss: 1.122e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9020, Training Loss: 1.122e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9021, Training Loss: 1.122e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9022, Training Loss: 1.121e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9023, Training Loss: 1.121e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9024, Training Loss: 1.121e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9025, Training Loss: 1.121e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9026, Training Loss: 1.121e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9027, Training Loss: 1.121e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9028, Training Loss: 1.121e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9029, Training Loss: 1.121e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9030, Training Loss: 1.121e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9031, Training Loss: 1.121e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9032, Training Loss: 1.120e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9033, Training Loss: 1.120e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9034, Training Loss: 1.120e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9035, Training Loss: 1.120e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9036, Training Loss: 1.120e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9037, Training Loss: 1.120e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9038, Training Loss: 1.120e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9039, Training Loss: 1.120e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9040, Training Loss: 1.120e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9041, Training Loss: 1.120e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9042, Training Loss: 1.119e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9043, Training Loss: 1.119e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9044, Training Loss: 1.119e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9045, Training Loss: 1.119e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9046, Training Loss: 1.119e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9047, Training Loss: 1.119e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9048, Training Loss: 1.119e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9049, Training Loss: 1.119e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9050, Training Loss: 1.119e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9051, Training Loss: 1.119e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9052, Training Loss: 1.119e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9053, Training Loss: 1.118e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9054, Training Loss: 1.118e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9055, Training Loss: 1.118e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9056, Training Loss: 1.118e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9057, Training Loss: 1.118e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9058, Training Loss: 1.118e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9059, Training Loss: 1.118e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9060, Training Loss: 1.118e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9061, Training Loss: 1.118e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9062, Training Loss: 1.118e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9063, Training Loss: 1.117e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9064, Training Loss: 1.117e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9065, Training Loss: 1.117e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9066, Training Loss: 1.117e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9067, Training Loss: 1.117e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9068, Training Loss: 1.117e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9069, Training Loss: 1.117e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9070, Training Loss: 1.117e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9071, Training Loss: 1.117e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9072, Training Loss: 1.117e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9073, Training Loss: 1.117e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9074, Training Loss: 1.116e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9075, Training Loss: 1.116e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9076, Training Loss: 1.116e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9077, Training Loss: 1.116e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9078, Training Loss: 1.116e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9079, Training Loss: 1.116e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9080, Training Loss: 1.116e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9081, Training Loss: 1.116e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9082, Training Loss: 1.116e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9083, Training Loss: 1.116e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9084, Training Loss: 1.115e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9085, Training Loss: 1.115e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9086, Training Loss: 1.115e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9087, Training Loss: 1.115e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9088, Training Loss: 1.115e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9089, Training Loss: 1.115e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9090, Training Loss: 1.115e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9091, Training Loss: 1.115e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9092, Training Loss: 1.115e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9093, Training Loss: 1.115e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9094, Training Loss: 1.114e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9095, Training Loss: 1.114e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9096, Training Loss: 1.114e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9097, Training Loss: 1.114e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9098, Training Loss: 1.114e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9099, Training Loss: 1.114e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9100, Training Loss: 1.114e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9101, Training Loss: 1.114e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9102, Training Loss: 1.114e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9103, Training Loss: 1.114e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9104, Training Loss: 1.114e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9105, Training Loss: 1.113e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9106, Training Loss: 1.113e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9107, Training Loss: 1.113e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9108, Training Loss: 1.113e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9109, Training Loss: 1.113e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9110, Training Loss: 1.113e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9111, Training Loss: 1.113e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9112, Training Loss: 1.113e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9113, Training Loss: 1.113e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9114, Training Loss: 1.113e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9115, Training Loss: 1.112e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9116, Training Loss: 1.112e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9117, Training Loss: 1.112e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9118, Training Loss: 1.112e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9119, Training Loss: 1.112e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9120, Training Loss: 1.112e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9121, Training Loss: 1.112e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9122, Training Loss: 1.112e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9123, Training Loss: 1.112e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9124, Training Loss: 1.112e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9125, Training Loss: 1.112e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9126, Training Loss: 1.111e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9127, Training Loss: 1.111e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9128, Training Loss: 1.111e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9129, Training Loss: 1.111e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9130, Training Loss: 1.111e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9131, Training Loss: 1.111e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9132, Training Loss: 1.111e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9133, Training Loss: 1.111e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9134, Training Loss: 1.111e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9135, Training Loss: 1.111e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9136, Training Loss: 1.110e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9137, Training Loss: 1.110e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9138, Training Loss: 1.110e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9139, Training Loss: 1.110e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9140, Training Loss: 1.110e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9141, Training Loss: 1.110e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9142, Training Loss: 1.110e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9143, Training Loss: 1.110e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9144, Training Loss: 1.110e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9145, Training Loss: 1.110e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9146, Training Loss: 1.110e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9147, Training Loss: 1.109e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9148, Training Loss: 1.109e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9149, Training Loss: 1.109e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9150, Training Loss: 1.109e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9151, Training Loss: 1.109e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9152, Training Loss: 1.109e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9153, Training Loss: 1.109e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9154, Training Loss: 1.109e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9155, Training Loss: 1.109e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9156, Training Loss: 1.109e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9157, Training Loss: 1.108e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9158, Training Loss: 1.108e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9159, Training Loss: 1.108e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9160, Training Loss: 1.108e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9161, Training Loss: 1.108e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9162, Training Loss: 1.108e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9163, Training Loss: 1.108e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9164, Training Loss: 1.108e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9165, Training Loss: 1.108e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9166, Training Loss: 1.108e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9167, Training Loss: 1.108e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9168, Training Loss: 1.107e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9169, Training Loss: 1.107e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9170, Training Loss: 1.107e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9171, Training Loss: 1.107e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9172, Training Loss: 1.107e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9173, Training Loss: 1.107e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9174, Training Loss: 1.107e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9175, Training Loss: 1.107e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9176, Training Loss: 1.107e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9177, Training Loss: 1.107e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9178, Training Loss: 1.107e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9179, Training Loss: 1.106e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9180, Training Loss: 1.106e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9181, Training Loss: 1.106e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9182, Training Loss: 1.106e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9183, Training Loss: 1.106e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9184, Training Loss: 1.106e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9185, Training Loss: 1.106e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9186, Training Loss: 1.106e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9187, Training Loss: 1.106e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9188, Training Loss: 1.106e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9189, Training Loss: 1.105e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9190, Training Loss: 1.105e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9191, Training Loss: 1.105e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9192, Training Loss: 1.105e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9193, Training Loss: 1.105e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9194, Training Loss: 1.105e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9195, Training Loss: 1.105e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9196, Training Loss: 1.105e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9197, Training Loss: 1.105e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9198, Training Loss: 1.105e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9199, Training Loss: 1.105e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9200, Training Loss: 1.104e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9201, Training Loss: 1.104e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9202, Training Loss: 1.104e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9203, Training Loss: 1.104e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9204, Training Loss: 1.104e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9205, Training Loss: 1.104e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9206, Training Loss: 1.104e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9207, Training Loss: 1.104e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9208, Training Loss: 1.104e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9209, Training Loss: 1.104e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9210, Training Loss: 1.103e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9211, Training Loss: 1.103e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9212, Training Loss: 1.103e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9213, Training Loss: 1.103e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9214, Training Loss: 1.103e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9215, Training Loss: 1.103e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9216, Training Loss: 1.103e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9217, Training Loss: 1.103e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9218, Training Loss: 1.103e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9219, Training Loss: 1.103e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9220, Training Loss: 1.103e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9221, Training Loss: 1.102e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9222, Training Loss: 1.102e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9223, Training Loss: 1.102e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9224, Training Loss: 1.102e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9225, Training Loss: 1.102e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9226, Training Loss: 1.102e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9227, Training Loss: 1.102e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9228, Training Loss: 1.102e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9229, Training Loss: 1.102e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9230, Training Loss: 1.102e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9231, Training Loss: 1.102e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9232, Training Loss: 1.101e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9233, Training Loss: 1.101e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9234, Training Loss: 1.101e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9235, Training Loss: 1.101e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9236, Training Loss: 1.101e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9237, Training Loss: 1.101e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9238, Training Loss: 1.101e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9239, Training Loss: 1.101e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9240, Training Loss: 1.101e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9241, Training Loss: 1.101e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9242, Training Loss: 1.100e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9243, Training Loss: 1.100e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9244, Training Loss: 1.100e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9245, Training Loss: 1.100e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9246, Training Loss: 1.100e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9247, Training Loss: 1.100e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9248, Training Loss: 1.100e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9249, Training Loss: 1.100e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9250, Training Loss: 1.100e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9251, Training Loss: 1.100e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9252, Training Loss: 1.100e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9253, Training Loss: 1.099e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9254, Training Loss: 1.099e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9255, Training Loss: 1.099e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9256, Training Loss: 1.099e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9257, Training Loss: 1.099e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9258, Training Loss: 1.099e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9259, Training Loss: 1.099e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9260, Training Loss: 1.099e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9261, Training Loss: 1.099e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9262, Training Loss: 1.099e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9263, Training Loss: 1.099e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9264, Training Loss: 1.098e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9265, Training Loss: 1.098e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9266, Training Loss: 1.098e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9267, Training Loss: 1.098e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9268, Training Loss: 1.098e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9269, Training Loss: 1.098e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9270, Training Loss: 1.098e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9271, Training Loss: 1.098e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9272, Training Loss: 1.098e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9273, Training Loss: 1.098e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9274, Training Loss: 1.097e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9275, Training Loss: 1.097e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9276, Training Loss: 1.097e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9277, Training Loss: 1.097e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9278, Training Loss: 1.097e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9279, Training Loss: 1.097e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9280, Training Loss: 1.097e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9281, Training Loss: 1.097e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9282, Training Loss: 1.097e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9283, Training Loss: 1.097e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9284, Training Loss: 1.097e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9285, Training Loss: 1.096e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9286, Training Loss: 1.096e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9287, Training Loss: 1.096e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9288, Training Loss: 1.096e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9289, Training Loss: 1.096e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9290, Training Loss: 1.096e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9291, Training Loss: 1.096e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9292, Training Loss: 1.096e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9293, Training Loss: 1.096e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9294, Training Loss: 1.096e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9295, Training Loss: 1.096e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9296, Training Loss: 1.095e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9297, Training Loss: 1.095e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9298, Training Loss: 1.095e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9299, Training Loss: 1.095e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9300, Training Loss: 1.095e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9301, Training Loss: 1.095e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9302, Training Loss: 1.095e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9303, Training Loss: 1.095e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9304, Training Loss: 1.095e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9305, Training Loss: 1.095e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9306, Training Loss: 1.095e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9307, Training Loss: 1.094e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9308, Training Loss: 1.094e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9309, Training Loss: 1.094e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9310, Training Loss: 1.094e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9311, Training Loss: 1.094e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9312, Training Loss: 1.094e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9313, Training Loss: 1.094e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9314, Training Loss: 1.094e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9315, Training Loss: 1.094e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9316, Training Loss: 1.094e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9317, Training Loss: 1.093e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9318, Training Loss: 1.093e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9319, Training Loss: 1.093e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9320, Training Loss: 1.093e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9321, Training Loss: 1.093e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9322, Training Loss: 1.093e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9323, Training Loss: 1.093e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9324, Training Loss: 1.093e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9325, Training Loss: 1.093e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9326, Training Loss: 1.093e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9327, Training Loss: 1.093e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9328, Training Loss: 1.092e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9329, Training Loss: 1.092e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9330, Training Loss: 1.092e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9331, Training Loss: 1.092e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9332, Training Loss: 1.092e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9333, Training Loss: 1.092e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9334, Training Loss: 1.092e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9335, Training Loss: 1.092e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9336, Training Loss: 1.092e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9337, Training Loss: 1.092e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9338, Training Loss: 1.092e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9339, Training Loss: 1.091e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9340, Training Loss: 1.091e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9341, Training Loss: 1.091e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9342, Training Loss: 1.091e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9343, Training Loss: 1.091e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9344, Training Loss: 1.091e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9345, Training Loss: 1.091e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9346, Training Loss: 1.091e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9347, Training Loss: 1.091e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9348, Training Loss: 1.091e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9349, Training Loss: 1.091e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9350, Training Loss: 1.090e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9351, Training Loss: 1.090e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9352, Training Loss: 1.090e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9353, Training Loss: 1.090e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9354, Training Loss: 1.090e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9355, Training Loss: 1.090e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9356, Training Loss: 1.090e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9357, Training Loss: 1.090e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9358, Training Loss: 1.090e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9359, Training Loss: 1.090e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9360, Training Loss: 1.090e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9361, Training Loss: 1.089e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9362, Training Loss: 1.089e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9363, Training Loss: 1.089e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9364, Training Loss: 1.089e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9365, Training Loss: 1.089e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9366, Training Loss: 1.089e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9367, Training Loss: 1.089e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9368, Training Loss: 1.089e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9369, Training Loss: 1.089e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9370, Training Loss: 1.089e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9371, Training Loss: 1.088e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9372, Training Loss: 1.088e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9373, Training Loss: 1.088e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9374, Training Loss: 1.088e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9375, Training Loss: 1.088e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9376, Training Loss: 1.088e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9377, Training Loss: 1.088e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9378, Training Loss: 1.088e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9379, Training Loss: 1.088e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9380, Training Loss: 1.088e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9381, Training Loss: 1.088e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9382, Training Loss: 1.087e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9383, Training Loss: 1.087e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9384, Training Loss: 1.087e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9385, Training Loss: 1.087e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9386, Training Loss: 1.087e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9387, Training Loss: 1.087e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9388, Training Loss: 1.087e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9389, Training Loss: 1.087e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9390, Training Loss: 1.087e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9391, Training Loss: 1.087e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9392, Training Loss: 1.087e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9393, Training Loss: 1.086e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9394, Training Loss: 1.086e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9395, Training Loss: 1.086e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9396, Training Loss: 1.086e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9397, Training Loss: 1.086e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9398, Training Loss: 1.086e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9399, Training Loss: 1.086e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9400, Training Loss: 1.086e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9401, Training Loss: 1.086e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9402, Training Loss: 1.086e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9403, Training Loss: 1.086e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9404, Training Loss: 1.085e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9405, Training Loss: 1.085e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9406, Training Loss: 1.085e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9407, Training Loss: 1.085e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9408, Training Loss: 1.085e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9409, Training Loss: 1.085e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9410, Training Loss: 1.085e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9411, Training Loss: 1.085e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9412, Training Loss: 1.085e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9413, Training Loss: 1.085e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9414, Training Loss: 1.085e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9415, Training Loss: 1.084e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9416, Training Loss: 1.084e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9417, Training Loss: 1.084e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9418, Training Loss: 1.084e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9419, Training Loss: 1.084e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9420, Training Loss: 1.084e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9421, Training Loss: 1.084e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9422, Training Loss: 1.084e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9423, Training Loss: 1.084e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9424, Training Loss: 1.084e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9425, Training Loss: 1.084e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9426, Training Loss: 1.083e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9427, Training Loss: 1.083e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9428, Training Loss: 1.083e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9429, Training Loss: 1.083e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9430, Training Loss: 1.083e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9431, Training Loss: 1.083e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9432, Training Loss: 1.083e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9433, Training Loss: 1.083e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9434, Training Loss: 1.083e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9435, Training Loss: 1.083e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9436, Training Loss: 1.083e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9437, Training Loss: 1.082e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9438, Training Loss: 1.082e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9439, Training Loss: 1.082e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9440, Training Loss: 1.082e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9441, Training Loss: 1.082e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9442, Training Loss: 1.082e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9443, Training Loss: 1.082e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9444, Training Loss: 1.082e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9445, Training Loss: 1.082e+00, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9446, Training Loss: 1.082e+00, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9447, Training Loss: 1.082e+00, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9448, Training Loss: 1.081e+00, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9449, Training Loss: 1.081e+00, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9450, Training Loss: 1.081e+00, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9451, Training Loss: 1.081e+00, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9452, Training Loss: 1.081e+00, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9453, Training Loss: 1.081e+00, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9454, Training Loss: 1.081e+00, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9455, Training Loss: 1.081e+00, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9456, Training Loss: 1.081e+00, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9457, Training Loss: 1.081e+00, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9458, Training Loss: 1.081e+00, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9459, Training Loss: 1.080e+00, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9460, Training Loss: 1.080e+00, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9461, Training Loss: 1.080e+00, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9462, Training Loss: 1.080e+00, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9463, Training Loss: 1.080e+00, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9464, Training Loss: 1.080e+00, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9465, Training Loss: 1.080e+00, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9466, Training Loss: 1.080e+00, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9467, Training Loss: 1.080e+00, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9468, Training Loss: 1.080e+00, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9469, Training Loss: 1.080e+00, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9470, Training Loss: 1.079e+00, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9471, Training Loss: 1.079e+00, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9472, Training Loss: 1.079e+00, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9473, Training Loss: 1.079e+00, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9474, Training Loss: 1.079e+00, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9475, Training Loss: 1.079e+00, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9476, Training Loss: 1.079e+00, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9477, Training Loss: 1.079e+00, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9478, Training Loss: 1.079e+00, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9479, Training Loss: 1.079e+00, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9480, Training Loss: 1.079e+00, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9481, Training Loss: 1.078e+00, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9482, Training Loss: 1.078e+00, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9483, Training Loss: 1.078e+00, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9484, Training Loss: 1.078e+00, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9485, Training Loss: 1.078e+00, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9486, Training Loss: 1.078e+00, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9487, Training Loss: 1.078e+00, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9488, Training Loss: 1.078e+00, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9489, Training Loss: 1.078e+00, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9490, Training Loss: 1.078e+00, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9491, Training Loss: 1.078e+00, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9492, Training Loss: 1.077e+00, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9493, Training Loss: 1.077e+00, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9494, Training Loss: 1.077e+00, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9495, Training Loss: 1.077e+00, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9496, Training Loss: 1.077e+00, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9497, Training Loss: 1.077e+00, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9498, Training Loss: 1.077e+00, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9499, Training Loss: 1.077e+00, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9500, Training Loss: 1.077e+00, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9501, Training Loss: 1.077e+00, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9502, Training Loss: 1.077e+00, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9503, Training Loss: 1.076e+00, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9504, Training Loss: 1.076e+00, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9505, Training Loss: 1.076e+00, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9506, Training Loss: 1.076e+00, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9507, Training Loss: 1.076e+00, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9508, Training Loss: 1.076e+00, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9509, Training Loss: 1.076e+00, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9510, Training Loss: 1.076e+00, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9511, Training Loss: 1.076e+00, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9512, Training Loss: 1.076e+00, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9513, Training Loss: 1.076e+00, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9514, Training Loss: 1.075e+00, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9515, Training Loss: 1.075e+00, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9516, Training Loss: 1.075e+00, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9517, Training Loss: 1.075e+00, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9518, Training Loss: 1.075e+00, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9519, Training Loss: 1.075e+00, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9520, Training Loss: 1.075e+00, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9521, Training Loss: 1.075e+00, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9522, Training Loss: 1.075e+00, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9523, Training Loss: 1.075e+00, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9524, Training Loss: 1.075e+00, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9525, Training Loss: 1.074e+00, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9526, Training Loss: 1.074e+00, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9527, Training Loss: 1.074e+00, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9528, Training Loss: 1.074e+00, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9529, Training Loss: 1.074e+00, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9530, Training Loss: 1.074e+00, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9531, Training Loss: 1.074e+00, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9532, Training Loss: 1.074e+00, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9533, Training Loss: 1.074e+00, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9534, Training Loss: 1.074e+00, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9535, Training Loss: 1.074e+00, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9536, Training Loss: 1.073e+00, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9537, Training Loss: 1.073e+00, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9538, Training Loss: 1.073e+00, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9539, Training Loss: 1.073e+00, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9540, Training Loss: 1.073e+00, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9541, Training Loss: 1.073e+00, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9542, Training Loss: 1.073e+00, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9543, Training Loss: 1.073e+00, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9544, Training Loss: 1.073e+00, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9545, Training Loss: 1.073e+00, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9546, Training Loss: 1.073e+00, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9547, Training Loss: 1.072e+00, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9548, Training Loss: 1.072e+00, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9549, Training Loss: 1.072e+00, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9550, Training Loss: 1.072e+00, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9551, Training Loss: 1.072e+00, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9552, Training Loss: 1.072e+00, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9553, Training Loss: 1.072e+00, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9554, Training Loss: 1.072e+00, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9555, Training Loss: 1.072e+00, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9556, Training Loss: 1.072e+00, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9557, Training Loss: 1.072e+00, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9558, Training Loss: 1.071e+00, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9559, Training Loss: 1.071e+00, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9560, Training Loss: 1.071e+00, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9561, Training Loss: 1.071e+00, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9562, Training Loss: 1.071e+00, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9563, Training Loss: 1.071e+00, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9564, Training Loss: 1.071e+00, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9565, Training Loss: 1.071e+00, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9566, Training Loss: 1.071e+00, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9567, Training Loss: 1.071e+00, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9568, Training Loss: 1.071e+00, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9569, Training Loss: 1.071e+00, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9570, Training Loss: 1.070e+00, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9571, Training Loss: 1.070e+00, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9572, Training Loss: 1.070e+00, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9573, Training Loss: 1.070e+00, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9574, Training Loss: 1.070e+00, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9575, Training Loss: 1.070e+00, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9576, Training Loss: 1.070e+00, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9577, Training Loss: 1.070e+00, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9578, Training Loss: 1.070e+00, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9579, Training Loss: 1.070e+00, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9580, Training Loss: 1.070e+00, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9581, Training Loss: 1.069e+00, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9582, Training Loss: 1.069e+00, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9583, Training Loss: 1.069e+00, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9584, Training Loss: 1.069e+00, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9585, Training Loss: 1.069e+00, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9586, Training Loss: 1.069e+00, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9587, Training Loss: 1.069e+00, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9588, Training Loss: 1.069e+00, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9589, Training Loss: 1.069e+00, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9590, Training Loss: 1.069e+00, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9591, Training Loss: 1.069e+00, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9592, Training Loss: 1.068e+00, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9593, Training Loss: 1.068e+00, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9594, Training Loss: 1.068e+00, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9595, Training Loss: 1.068e+00, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9596, Training Loss: 1.068e+00, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9597, Training Loss: 1.068e+00, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9598, Training Loss: 1.068e+00, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9599, Training Loss: 1.068e+00, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9600, Training Loss: 1.068e+00, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9601, Training Loss: 1.068e+00, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9602, Training Loss: 1.068e+00, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9603, Training Loss: 1.067e+00, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9604, Training Loss: 1.067e+00, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9605, Training Loss: 1.067e+00, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9606, Training Loss: 1.067e+00, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9607, Training Loss: 1.067e+00, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9608, Training Loss: 1.067e+00, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9609, Training Loss: 1.067e+00, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9610, Training Loss: 1.067e+00, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9611, Training Loss: 1.067e+00, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9612, Training Loss: 1.067e+00, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9613, Training Loss: 1.067e+00, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9614, Training Loss: 1.066e+00, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9615, Training Loss: 1.066e+00, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9616, Training Loss: 1.066e+00, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9617, Training Loss: 1.066e+00, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9618, Training Loss: 1.066e+00, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9619, Training Loss: 1.066e+00, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9620, Training Loss: 1.066e+00, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9621, Training Loss: 1.066e+00, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9622, Training Loss: 1.066e+00, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9623, Training Loss: 1.066e+00, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9624, Training Loss: 1.066e+00, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9625, Training Loss: 1.066e+00, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9626, Training Loss: 1.065e+00, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9627, Training Loss: 1.065e+00, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9628, Training Loss: 1.065e+00, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9629, Training Loss: 1.065e+00, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9630, Training Loss: 1.065e+00, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9631, Training Loss: 1.065e+00, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9632, Training Loss: 1.065e+00, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9633, Training Loss: 1.065e+00, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9634, Training Loss: 1.065e+00, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9635, Training Loss: 1.065e+00, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9636, Training Loss: 1.065e+00, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9637, Training Loss: 1.064e+00, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9638, Training Loss: 1.064e+00, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9639, Training Loss: 1.064e+00, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9640, Training Loss: 1.064e+00, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9641, Training Loss: 1.064e+00, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9642, Training Loss: 1.064e+00, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9643, Training Loss: 1.064e+00, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9644, Training Loss: 1.064e+00, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9645, Training Loss: 1.064e+00, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9646, Training Loss: 1.064e+00, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9647, Training Loss: 1.064e+00, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9648, Training Loss: 1.063e+00, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9649, Training Loss: 1.063e+00, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9650, Training Loss: 1.063e+00, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9651, Training Loss: 1.063e+00, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9652, Training Loss: 1.063e+00, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9653, Training Loss: 1.063e+00, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9654, Training Loss: 1.063e+00, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9655, Training Loss: 1.063e+00, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9656, Training Loss: 1.063e+00, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9657, Training Loss: 1.063e+00, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9658, Training Loss: 1.063e+00, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9659, Training Loss: 1.062e+00, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9660, Training Loss: 1.062e+00, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9661, Training Loss: 1.062e+00, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9662, Training Loss: 1.062e+00, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9663, Training Loss: 1.062e+00, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9664, Training Loss: 1.062e+00, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9665, Training Loss: 1.062e+00, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9666, Training Loss: 1.062e+00, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9667, Training Loss: 1.062e+00, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9668, Training Loss: 1.062e+00, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9669, Training Loss: 1.062e+00, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9670, Training Loss: 1.062e+00, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9671, Training Loss: 1.061e+00, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9672, Training Loss: 1.061e+00, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9673, Training Loss: 1.061e+00, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9674, Training Loss: 1.061e+00, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9675, Training Loss: 1.061e+00, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9676, Training Loss: 1.061e+00, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9677, Training Loss: 1.061e+00, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9678, Training Loss: 1.061e+00, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9679, Training Loss: 1.061e+00, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9680, Training Loss: 1.061e+00, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9681, Training Loss: 1.061e+00, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9682, Training Loss: 1.060e+00, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9683, Training Loss: 1.060e+00, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9684, Training Loss: 1.060e+00, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9685, Training Loss: 1.060e+00, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9686, Training Loss: 1.060e+00, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9687, Training Loss: 1.060e+00, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9688, Training Loss: 1.060e+00, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9689, Training Loss: 1.060e+00, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9690, Training Loss: 1.060e+00, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9691, Training Loss: 1.060e+00, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9692, Training Loss: 1.060e+00, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9693, Training Loss: 1.059e+00, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9694, Training Loss: 1.059e+00, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9695, Training Loss: 1.059e+00, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9696, Training Loss: 1.059e+00, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9697, Training Loss: 1.059e+00, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9698, Training Loss: 1.059e+00, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9699, Training Loss: 1.059e+00, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9700, Training Loss: 1.059e+00, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9701, Training Loss: 1.059e+00, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9702, Training Loss: 1.059e+00, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9703, Training Loss: 1.059e+00, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9704, Training Loss: 1.059e+00, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9705, Training Loss: 1.058e+00, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9706, Training Loss: 1.058e+00, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9707, Training Loss: 1.058e+00, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9708, Training Loss: 1.058e+00, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9709, Training Loss: 1.058e+00, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9710, Training Loss: 1.058e+00, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9711, Training Loss: 1.058e+00, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9712, Training Loss: 1.058e+00, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9713, Training Loss: 1.058e+00, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9714, Training Loss: 1.058e+00, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9715, Training Loss: 1.058e+00, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9716, Training Loss: 1.057e+00, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9717, Training Loss: 1.057e+00, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9718, Training Loss: 1.057e+00, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9719, Training Loss: 1.057e+00, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9720, Training Loss: 1.057e+00, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9721, Training Loss: 1.057e+00, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9722, Training Loss: 1.057e+00, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9723, Training Loss: 1.057e+00, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9724, Training Loss: 1.057e+00, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9725, Training Loss: 1.057e+00, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9726, Training Loss: 1.057e+00, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9727, Training Loss: 1.057e+00, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9728, Training Loss: 1.056e+00, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9729, Training Loss: 1.056e+00, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9730, Training Loss: 1.056e+00, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9731, Training Loss: 1.056e+00, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9732, Training Loss: 1.056e+00, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9733, Training Loss: 1.056e+00, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9734, Training Loss: 1.056e+00, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9735, Training Loss: 1.056e+00, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9736, Training Loss: 1.056e+00, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9737, Training Loss: 1.056e+00, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9738, Training Loss: 1.056e+00, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9739, Training Loss: 1.055e+00, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9740, Training Loss: 1.055e+00, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9741, Training Loss: 1.055e+00, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9742, Training Loss: 1.055e+00, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9743, Training Loss: 1.055e+00, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9744, Training Loss: 1.055e+00, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9745, Training Loss: 1.055e+00, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9746, Training Loss: 1.055e+00, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9747, Training Loss: 1.055e+00, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9748, Training Loss: 1.055e+00, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9749, Training Loss: 1.055e+00, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9750, Training Loss: 1.054e+00, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9751, Training Loss: 1.054e+00, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9752, Training Loss: 1.054e+00, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9753, Training Loss: 1.054e+00, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9754, Training Loss: 1.054e+00, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9755, Training Loss: 1.054e+00, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9756, Training Loss: 1.054e+00, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9757, Training Loss: 1.054e+00, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9758, Training Loss: 1.054e+00, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9759, Training Loss: 1.054e+00, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9760, Training Loss: 1.054e+00, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9761, Training Loss: 1.054e+00, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9762, Training Loss: 1.053e+00, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9763, Training Loss: 1.053e+00, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9764, Training Loss: 1.053e+00, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9765, Training Loss: 1.053e+00, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9766, Training Loss: 1.053e+00, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9767, Training Loss: 1.053e+00, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9768, Training Loss: 1.053e+00, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9769, Training Loss: 1.053e+00, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9770, Training Loss: 1.053e+00, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9771, Training Loss: 1.053e+00, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9772, Training Loss: 1.053e+00, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9773, Training Loss: 1.052e+00, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9774, Training Loss: 1.052e+00, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9775, Training Loss: 1.052e+00, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9776, Training Loss: 1.052e+00, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9777, Training Loss: 1.052e+00, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9778, Training Loss: 1.052e+00, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9779, Training Loss: 1.052e+00, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9780, Training Loss: 1.052e+00, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9781, Training Loss: 1.052e+00, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9782, Training Loss: 1.052e+00, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9783, Training Loss: 1.052e+00, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9784, Training Loss: 1.052e+00, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9785, Training Loss: 1.051e+00, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9786, Training Loss: 1.051e+00, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9787, Training Loss: 1.051e+00, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9788, Training Loss: 1.051e+00, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9789, Training Loss: 1.051e+00, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9790, Training Loss: 1.051e+00, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9791, Training Loss: 1.051e+00, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9792, Training Loss: 1.051e+00, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9793, Training Loss: 1.051e+00, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9794, Training Loss: 1.051e+00, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9795, Training Loss: 1.051e+00, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9796, Training Loss: 1.050e+00, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9797, Training Loss: 1.050e+00, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9798, Training Loss: 1.050e+00, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9799, Training Loss: 1.050e+00, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9800, Training Loss: 1.050e+00, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9801, Training Loss: 1.050e+00, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9802, Training Loss: 1.050e+00, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9803, Training Loss: 1.050e+00, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9804, Training Loss: 1.050e+00, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9805, Training Loss: 1.050e+00, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9806, Training Loss: 1.050e+00, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9807, Training Loss: 1.050e+00, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9808, Training Loss: 1.049e+00, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9809, Training Loss: 1.049e+00, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9810, Training Loss: 1.049e+00, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9811, Training Loss: 1.049e+00, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9812, Training Loss: 1.049e+00, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9813, Training Loss: 1.049e+00, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9814, Training Loss: 1.049e+00, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9815, Training Loss: 1.049e+00, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9816, Training Loss: 1.049e+00, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9817, Training Loss: 1.049e+00, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9818, Training Loss: 1.049e+00, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9819, Training Loss: 1.048e+00, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9820, Training Loss: 1.048e+00, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9821, Training Loss: 1.048e+00, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9822, Training Loss: 1.048e+00, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9823, Training Loss: 1.048e+00, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9824, Training Loss: 1.048e+00, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9825, Training Loss: 1.048e+00, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9826, Training Loss: 1.048e+00, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9827, Training Loss: 1.048e+00, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9828, Training Loss: 1.048e+00, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9829, Training Loss: 1.048e+00, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9830, Training Loss: 1.048e+00, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9831, Training Loss: 1.047e+00, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9832, Training Loss: 1.047e+00, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9833, Training Loss: 1.047e+00, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9834, Training Loss: 1.047e+00, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9835, Training Loss: 1.047e+00, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9836, Training Loss: 1.047e+00, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9837, Training Loss: 1.047e+00, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9838, Training Loss: 1.047e+00, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9839, Training Loss: 1.047e+00, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9840, Training Loss: 1.047e+00, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9841, Training Loss: 1.047e+00, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9842, Training Loss: 1.047e+00, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9843, Training Loss: 1.046e+00, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9844, Training Loss: 1.046e+00, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9845, Training Loss: 1.046e+00, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9846, Training Loss: 1.046e+00, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9847, Training Loss: 1.046e+00, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9848, Training Loss: 1.046e+00, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9849, Training Loss: 1.046e+00, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9850, Training Loss: 1.046e+00, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9851, Training Loss: 1.046e+00, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9852, Training Loss: 1.046e+00, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9853, Training Loss: 1.046e+00, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9854, Training Loss: 1.045e+00, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9855, Training Loss: 1.045e+00, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9856, Training Loss: 1.045e+00, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9857, Training Loss: 1.045e+00, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9858, Training Loss: 1.045e+00, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9859, Training Loss: 1.045e+00, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9860, Training Loss: 1.045e+00, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9861, Training Loss: 1.045e+00, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9862, Training Loss: 1.045e+00, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9863, Training Loss: 1.045e+00, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9864, Training Loss: 1.045e+00, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9865, Training Loss: 1.045e+00, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9866, Training Loss: 1.044e+00, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9867, Training Loss: 1.044e+00, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9868, Training Loss: 1.044e+00, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9869, Training Loss: 1.044e+00, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9870, Training Loss: 1.044e+00, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9871, Training Loss: 1.044e+00, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9872, Training Loss: 1.044e+00, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9873, Training Loss: 1.044e+00, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9874, Training Loss: 1.044e+00, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9875, Training Loss: 1.044e+00, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9876, Training Loss: 1.044e+00, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9877, Training Loss: 1.043e+00, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9878, Training Loss: 1.043e+00, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9879, Training Loss: 1.043e+00, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9880, Training Loss: 1.043e+00, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9881, Training Loss: 1.043e+00, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9882, Training Loss: 1.043e+00, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9883, Training Loss: 1.043e+00, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9884, Training Loss: 1.043e+00, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9885, Training Loss: 1.043e+00, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9886, Training Loss: 1.043e+00, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9887, Training Loss: 1.043e+00, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9888, Training Loss: 1.043e+00, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9889, Training Loss: 1.042e+00, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9890, Training Loss: 1.042e+00, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9891, Training Loss: 1.042e+00, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9892, Training Loss: 1.042e+00, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9893, Training Loss: 1.042e+00, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9894, Training Loss: 1.042e+00, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9895, Training Loss: 1.042e+00, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9896, Training Loss: 1.042e+00, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9897, Training Loss: 1.042e+00, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9898, Training Loss: 1.042e+00, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9899, Training Loss: 1.042e+00, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9900, Training Loss: 1.042e+00, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9901, Training Loss: 1.041e+00, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9902, Training Loss: 1.041e+00, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9903, Training Loss: 1.041e+00, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9904, Training Loss: 1.041e+00, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9905, Training Loss: 1.041e+00, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9906, Training Loss: 1.041e+00, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9907, Training Loss: 1.041e+00, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9908, Training Loss: 1.041e+00, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9909, Training Loss: 1.041e+00, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9910, Training Loss: 1.041e+00, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9911, Training Loss: 1.041e+00, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9912, Training Loss: 1.040e+00, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9913, Training Loss: 1.040e+00, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9914, Training Loss: 1.040e+00, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9915, Training Loss: 1.040e+00, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9916, Training Loss: 1.040e+00, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9917, Training Loss: 1.040e+00, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9918, Training Loss: 1.040e+00, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9919, Training Loss: 1.040e+00, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9920, Training Loss: 1.040e+00, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9921, Training Loss: 1.040e+00, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9922, Training Loss: 1.040e+00, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9923, Training Loss: 1.040e+00, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9924, Training Loss: 1.039e+00, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9925, Training Loss: 1.039e+00, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9926, Training Loss: 1.039e+00, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9927, Training Loss: 1.039e+00, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9928, Training Loss: 1.039e+00, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9929, Training Loss: 1.039e+00, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9930, Training Loss: 1.039e+00, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9931, Training Loss: 1.039e+00, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9932, Training Loss: 1.039e+00, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9933, Training Loss: 1.039e+00, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9934, Training Loss: 1.039e+00, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9935, Training Loss: 1.039e+00, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9936, Training Loss: 1.038e+00, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9937, Training Loss: 1.038e+00, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9938, Training Loss: 1.038e+00, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9939, Training Loss: 1.038e+00, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9940, Training Loss: 1.038e+00, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9941, Training Loss: 1.038e+00, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9942, Training Loss: 1.038e+00, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9943, Training Loss: 1.038e+00, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9944, Training Loss: 1.038e+00, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9945, Training Loss: 1.038e+00, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9946, Training Loss: 1.038e+00, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9947, Training Loss: 1.038e+00, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9948, Training Loss: 1.037e+00, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9949, Training Loss: 1.037e+00, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9950, Training Loss: 1.037e+00, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9951, Training Loss: 1.037e+00, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9952, Training Loss: 1.037e+00, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9953, Training Loss: 1.037e+00, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9954, Training Loss: 1.037e+00, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9955, Training Loss: 1.037e+00, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9956, Training Loss: 1.037e+00, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9957, Training Loss: 1.037e+00, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9958, Training Loss: 1.037e+00, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9959, Training Loss: 1.036e+00, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9960, Training Loss: 1.036e+00, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9961, Training Loss: 1.036e+00, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9962, Training Loss: 1.036e+00, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9963, Training Loss: 1.036e+00, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9964, Training Loss: 1.036e+00, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9965, Training Loss: 1.036e+00, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9966, Training Loss: 1.036e+00, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9967, Training Loss: 1.036e+00, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9968, Training Loss: 1.036e+00, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9969, Training Loss: 1.036e+00, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9970, Training Loss: 1.036e+00, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9971, Training Loss: 1.035e+00, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9972, Training Loss: 1.035e+00, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9973, Training Loss: 1.035e+00, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9974, Training Loss: 1.035e+00, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9975, Training Loss: 1.035e+00, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9976, Training Loss: 1.035e+00, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9977, Training Loss: 1.035e+00, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9978, Training Loss: 1.035e+00, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9979, Training Loss: 1.035e+00, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9980, Training Loss: 1.035e+00, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9981, Training Loss: 1.035e+00, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9982, Training Loss: 1.035e+00, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9983, Training Loss: 1.034e+00, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9984, Training Loss: 1.034e+00, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9985, Training Loss: 1.034e+00, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9986, Training Loss: 1.034e+00, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9987, Training Loss: 1.034e+00, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9988, Training Loss: 1.034e+00, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9989, Training Loss: 1.034e+00, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9990, Training Loss: 1.034e+00, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9991, Training Loss: 1.034e+00, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9992, Training Loss: 1.034e+00, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9993, Training Loss: 1.034e+00, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9994, Training Loss: 1.034e+00, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9995, Training Loss: 1.033e+00, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9996, Training Loss: 1.033e+00, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9997, Training Loss: 1.033e+00, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9998, Training Loss: 1.033e+00, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9999, Training Loss: 1.033e+00, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10000, Training Loss: 1.033e+00, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10001, Training Loss: 1.033e+00, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10002, Training Loss: 1.033e+00, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10003, Training Loss: 1.033e+00, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10004, Training Loss: 1.033e+00, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10005, Training Loss: 1.033e+00, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10006, Training Loss: 1.033e+00, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10007, Training Loss: 1.032e+00, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10008, Training Loss: 1.032e+00, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10009, Training Loss: 1.032e+00, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10010, Training Loss: 1.032e+00, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10011, Training Loss: 1.032e+00, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10012, Training Loss: 1.032e+00, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10013, Training Loss: 1.032e+00, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10014, Training Loss: 1.032e+00, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10015, Training Loss: 1.032e+00, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10016, Training Loss: 1.032e+00, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10017, Training Loss: 1.032e+00, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10018, Training Loss: 1.031e+00, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10019, Training Loss: 1.031e+00, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10020, Training Loss: 1.031e+00, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10021, Training Loss: 1.031e+00, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10022, Training Loss: 1.031e+00, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10023, Training Loss: 1.031e+00, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10024, Training Loss: 1.031e+00, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10025, Training Loss: 1.031e+00, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10026, Training Loss: 1.031e+00, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10027, Training Loss: 1.031e+00, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10028, Training Loss: 1.031e+00, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10029, Training Loss: 1.031e+00, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10030, Training Loss: 1.030e+00, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10031, Training Loss: 1.030e+00, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10032, Training Loss: 1.030e+00, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10033, Training Loss: 1.030e+00, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10034, Training Loss: 1.030e+00, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10035, Training Loss: 1.030e+00, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10036, Training Loss: 1.030e+00, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10037, Training Loss: 1.030e+00, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10038, Training Loss: 1.030e+00, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10039, Training Loss: 1.030e+00, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10040, Training Loss: 1.030e+00, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10041, Training Loss: 1.030e+00, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10042, Training Loss: 1.029e+00, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10043, Training Loss: 1.029e+00, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10044, Training Loss: 1.029e+00, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10045, Training Loss: 1.029e+00, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10046, Training Loss: 1.029e+00, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10047, Training Loss: 1.029e+00, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10048, Training Loss: 1.029e+00, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10049, Training Loss: 1.029e+00, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10050, Training Loss: 1.029e+00, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10051, Training Loss: 1.029e+00, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10052, Training Loss: 1.029e+00, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10053, Training Loss: 1.029e+00, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10054, Training Loss: 1.028e+00, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10055, Training Loss: 1.028e+00, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10056, Training Loss: 1.028e+00, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10057, Training Loss: 1.028e+00, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10058, Training Loss: 1.028e+00, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10059, Training Loss: 1.028e+00, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10060, Training Loss: 1.028e+00, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10061, Training Loss: 1.028e+00, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10062, Training Loss: 1.028e+00, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10063, Training Loss: 1.028e+00, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10064, Training Loss: 1.028e+00, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10065, Training Loss: 1.028e+00, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10066, Training Loss: 1.027e+00, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10067, Training Loss: 1.027e+00, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10068, Training Loss: 1.027e+00, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10069, Training Loss: 1.027e+00, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10070, Training Loss: 1.027e+00, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10071, Training Loss: 1.027e+00, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10072, Training Loss: 1.027e+00, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10073, Training Loss: 1.027e+00, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10074, Training Loss: 1.027e+00, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10075, Training Loss: 1.027e+00, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10076, Training Loss: 1.027e+00, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10077, Training Loss: 1.027e+00, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10078, Training Loss: 1.026e+00, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10079, Training Loss: 1.026e+00, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10080, Training Loss: 1.026e+00, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10081, Training Loss: 1.026e+00, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10082, Training Loss: 1.026e+00, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10083, Training Loss: 1.026e+00, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10084, Training Loss: 1.026e+00, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10085, Training Loss: 1.026e+00, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10086, Training Loss: 1.026e+00, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10087, Training Loss: 1.026e+00, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10088, Training Loss: 1.026e+00, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10089, Training Loss: 1.026e+00, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10090, Training Loss: 1.025e+00, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10091, Training Loss: 1.025e+00, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10092, Training Loss: 1.025e+00, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10093, Training Loss: 1.025e+00, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10094, Training Loss: 1.025e+00, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10095, Training Loss: 1.025e+00, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10096, Training Loss: 1.025e+00, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10097, Training Loss: 1.025e+00, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10098, Training Loss: 1.025e+00, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10099, Training Loss: 1.025e+00, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10100, Training Loss: 1.025e+00, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10101, Training Loss: 1.025e+00, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10102, Training Loss: 1.024e+00, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10103, Training Loss: 1.024e+00, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10104, Training Loss: 1.024e+00, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10105, Training Loss: 1.024e+00, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10106, Training Loss: 1.024e+00, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10107, Training Loss: 1.024e+00, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10108, Training Loss: 1.024e+00, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10109, Training Loss: 1.024e+00, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10110, Training Loss: 1.024e+00, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10111, Training Loss: 1.024e+00, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10112, Training Loss: 1.024e+00, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10113, Training Loss: 1.024e+00, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10114, Training Loss: 1.023e+00, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10115, Training Loss: 1.023e+00, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10116, Training Loss: 1.023e+00, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10117, Training Loss: 1.023e+00, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10118, Training Loss: 1.023e+00, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10119, Training Loss: 1.023e+00, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10120, Training Loss: 1.023e+00, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10121, Training Loss: 1.023e+00, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10122, Training Loss: 1.023e+00, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10123, Training Loss: 1.023e+00, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10124, Training Loss: 1.023e+00, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10125, Training Loss: 1.023e+00, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10126, Training Loss: 1.022e+00, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10127, Training Loss: 1.022e+00, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10128, Training Loss: 1.022e+00, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10129, Training Loss: 1.022e+00, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10130, Training Loss: 1.022e+00, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10131, Training Loss: 1.022e+00, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10132, Training Loss: 1.022e+00, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10133, Training Loss: 1.022e+00, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10134, Training Loss: 1.022e+00, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10135, Training Loss: 1.022e+00, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10136, Training Loss: 1.022e+00, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10137, Training Loss: 1.022e+00, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10138, Training Loss: 1.021e+00, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10139, Training Loss: 1.021e+00, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10140, Training Loss: 1.021e+00, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10141, Training Loss: 1.021e+00, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10142, Training Loss: 1.021e+00, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10143, Training Loss: 1.021e+00, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10144, Training Loss: 1.021e+00, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10145, Training Loss: 1.021e+00, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10146, Training Loss: 1.021e+00, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10147, Training Loss: 1.021e+00, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10148, Training Loss: 1.021e+00, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10149, Training Loss: 1.021e+00, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10150, Training Loss: 1.020e+00, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10151, Training Loss: 1.020e+00, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10152, Training Loss: 1.020e+00, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10153, Training Loss: 1.020e+00, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10154, Training Loss: 1.020e+00, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10155, Training Loss: 1.020e+00, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10156, Training Loss: 1.020e+00, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10157, Training Loss: 1.020e+00, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10158, Training Loss: 1.020e+00, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10159, Training Loss: 1.020e+00, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10160, Training Loss: 1.020e+00, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10161, Training Loss: 1.020e+00, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10162, Training Loss: 1.019e+00, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10163, Training Loss: 1.019e+00, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10164, Training Loss: 1.019e+00, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10165, Training Loss: 1.019e+00, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10166, Training Loss: 1.019e+00, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10167, Training Loss: 1.019e+00, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10168, Training Loss: 1.019e+00, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10169, Training Loss: 1.019e+00, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10170, Training Loss: 1.019e+00, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10171, Training Loss: 1.019e+00, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10172, Training Loss: 1.019e+00, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10173, Training Loss: 1.019e+00, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10174, Training Loss: 1.018e+00, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10175, Training Loss: 1.018e+00, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10176, Training Loss: 1.018e+00, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10177, Training Loss: 1.018e+00, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10178, Training Loss: 1.018e+00, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10179, Training Loss: 1.018e+00, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10180, Training Loss: 1.018e+00, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10181, Training Loss: 1.018e+00, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10182, Training Loss: 1.018e+00, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10183, Training Loss: 1.018e+00, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10184, Training Loss: 1.018e+00, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10185, Training Loss: 1.018e+00, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10186, Training Loss: 1.017e+00, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10187, Training Loss: 1.017e+00, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10188, Training Loss: 1.017e+00, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10189, Training Loss: 1.017e+00, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10190, Training Loss: 1.017e+00, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10191, Training Loss: 1.017e+00, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10192, Training Loss: 1.017e+00, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10193, Training Loss: 1.017e+00, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10194, Training Loss: 1.017e+00, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10195, Training Loss: 1.017e+00, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10196, Training Loss: 1.017e+00, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10197, Training Loss: 1.017e+00, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10198, Training Loss: 1.016e+00, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10199, Training Loss: 1.016e+00, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10200, Training Loss: 1.016e+00, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10201, Training Loss: 1.016e+00, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10202, Training Loss: 1.016e+00, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10203, Training Loss: 1.016e+00, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10204, Training Loss: 1.016e+00, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10205, Training Loss: 1.016e+00, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10206, Training Loss: 1.016e+00, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10207, Training Loss: 1.016e+00, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10208, Training Loss: 1.016e+00, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10209, Training Loss: 1.016e+00, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10210, Training Loss: 1.016e+00, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10211, Training Loss: 1.015e+00, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10212, Training Loss: 1.015e+00, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10213, Training Loss: 1.015e+00, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10214, Training Loss: 1.015e+00, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10215, Training Loss: 1.015e+00, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10216, Training Loss: 1.015e+00, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10217, Training Loss: 1.015e+00, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10218, Training Loss: 1.015e+00, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10219, Training Loss: 1.015e+00, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10220, Training Loss: 1.015e+00, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10221, Training Loss: 1.015e+00, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10222, Training Loss: 1.015e+00, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10223, Training Loss: 1.014e+00, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10224, Training Loss: 1.014e+00, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10225, Training Loss: 1.014e+00, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10226, Training Loss: 1.014e+00, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10227, Training Loss: 1.014e+00, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10228, Training Loss: 1.014e+00, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10229, Training Loss: 1.014e+00, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10230, Training Loss: 1.014e+00, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10231, Training Loss: 1.014e+00, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10232, Training Loss: 1.014e+00, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10233, Training Loss: 1.014e+00, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10234, Training Loss: 1.014e+00, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10235, Training Loss: 1.013e+00, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10236, Training Loss: 1.013e+00, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10237, Training Loss: 1.013e+00, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10238, Training Loss: 1.013e+00, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10239, Training Loss: 1.013e+00, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10240, Training Loss: 1.013e+00, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10241, Training Loss: 1.013e+00, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10242, Training Loss: 1.013e+00, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10243, Training Loss: 1.013e+00, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10244, Training Loss: 1.013e+00, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10245, Training Loss: 1.013e+00, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10246, Training Loss: 1.013e+00, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10247, Training Loss: 1.012e+00, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10248, Training Loss: 1.012e+00, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10249, Training Loss: 1.012e+00, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10250, Training Loss: 1.012e+00, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10251, Training Loss: 1.012e+00, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10252, Training Loss: 1.012e+00, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10253, Training Loss: 1.012e+00, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10254, Training Loss: 1.012e+00, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10255, Training Loss: 1.012e+00, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10256, Training Loss: 1.012e+00, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10257, Training Loss: 1.012e+00, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10258, Training Loss: 1.012e+00, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10259, Training Loss: 1.011e+00, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10260, Training Loss: 1.011e+00, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10261, Training Loss: 1.011e+00, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10262, Training Loss: 1.011e+00, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10263, Training Loss: 1.011e+00, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10264, Training Loss: 1.011e+00, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10265, Training Loss: 1.011e+00, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10266, Training Loss: 1.011e+00, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10267, Training Loss: 1.011e+00, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10268, Training Loss: 1.011e+00, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10269, Training Loss: 1.011e+00, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10270, Training Loss: 1.011e+00, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10271, Training Loss: 1.011e+00, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10272, Training Loss: 1.010e+00, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10273, Training Loss: 1.010e+00, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10274, Training Loss: 1.010e+00, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10275, Training Loss: 1.010e+00, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10276, Training Loss: 1.010e+00, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10277, Training Loss: 1.010e+00, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10278, Training Loss: 1.010e+00, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10279, Training Loss: 1.010e+00, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10280, Training Loss: 1.010e+00, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10281, Training Loss: 1.010e+00, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10282, Training Loss: 1.010e+00, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10283, Training Loss: 1.010e+00, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10284, Training Loss: 1.009e+00, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10285, Training Loss: 1.009e+00, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10286, Training Loss: 1.009e+00, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10287, Training Loss: 1.009e+00, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10288, Training Loss: 1.009e+00, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10289, Training Loss: 1.009e+00, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10290, Training Loss: 1.009e+00, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10291, Training Loss: 1.009e+00, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10292, Training Loss: 1.009e+00, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10293, Training Loss: 1.009e+00, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10294, Training Loss: 1.009e+00, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10295, Training Loss: 1.009e+00, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10296, Training Loss: 1.008e+00, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10297, Training Loss: 1.008e+00, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10298, Training Loss: 1.008e+00, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10299, Training Loss: 1.008e+00, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10300, Training Loss: 1.008e+00, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10301, Training Loss: 1.008e+00, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10302, Training Loss: 1.008e+00, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10303, Training Loss: 1.008e+00, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10304, Training Loss: 1.008e+00, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10305, Training Loss: 1.008e+00, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10306, Training Loss: 1.008e+00, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10307, Training Loss: 1.008e+00, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10308, Training Loss: 1.008e+00, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10309, Training Loss: 1.007e+00, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10310, Training Loss: 1.007e+00, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10311, Training Loss: 1.007e+00, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10312, Training Loss: 1.007e+00, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10313, Training Loss: 1.007e+00, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10314, Training Loss: 1.007e+00, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10315, Training Loss: 1.007e+00, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10316, Training Loss: 1.007e+00, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10317, Training Loss: 1.007e+00, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10318, Training Loss: 1.007e+00, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10319, Training Loss: 1.007e+00, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10320, Training Loss: 1.007e+00, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10321, Training Loss: 1.006e+00, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10322, Training Loss: 1.006e+00, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10323, Training Loss: 1.006e+00, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10324, Training Loss: 1.006e+00, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10325, Training Loss: 1.006e+00, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10326, Training Loss: 1.006e+00, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10327, Training Loss: 1.006e+00, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10328, Training Loss: 1.006e+00, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10329, Training Loss: 1.006e+00, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10330, Training Loss: 1.006e+00, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10331, Training Loss: 1.006e+00, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10332, Training Loss: 1.006e+00, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10333, Training Loss: 1.005e+00, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10334, Training Loss: 1.005e+00, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10335, Training Loss: 1.005e+00, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10336, Training Loss: 1.005e+00, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10337, Training Loss: 1.005e+00, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10338, Training Loss: 1.005e+00, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10339, Training Loss: 1.005e+00, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10340, Training Loss: 1.005e+00, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10341, Training Loss: 1.005e+00, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10342, Training Loss: 1.005e+00, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10343, Training Loss: 1.005e+00, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10344, Training Loss: 1.005e+00, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10345, Training Loss: 1.005e+00, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10346, Training Loss: 1.004e+00, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10347, Training Loss: 1.004e+00, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10348, Training Loss: 1.004e+00, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10349, Training Loss: 1.004e+00, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10350, Training Loss: 1.004e+00, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10351, Training Loss: 1.004e+00, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10352, Training Loss: 1.004e+00, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10353, Training Loss: 1.004e+00, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10354, Training Loss: 1.004e+00, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10355, Training Loss: 1.004e+00, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10356, Training Loss: 1.004e+00, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10357, Training Loss: 1.004e+00, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10358, Training Loss: 1.003e+00, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10359, Training Loss: 1.003e+00, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10360, Training Loss: 1.003e+00, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10361, Training Loss: 1.003e+00, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10362, Training Loss: 1.003e+00, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10363, Training Loss: 1.003e+00, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10364, Training Loss: 1.003e+00, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10365, Training Loss: 1.003e+00, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10366, Training Loss: 1.003e+00, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10367, Training Loss: 1.003e+00, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10368, Training Loss: 1.003e+00, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10369, Training Loss: 1.003e+00, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10370, Training Loss: 1.003e+00, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10371, Training Loss: 1.002e+00, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10372, Training Loss: 1.002e+00, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10373, Training Loss: 1.002e+00, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10374, Training Loss: 1.002e+00, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10375, Training Loss: 1.002e+00, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10376, Training Loss: 1.002e+00, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10377, Training Loss: 1.002e+00, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10378, Training Loss: 1.002e+00, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10379, Training Loss: 1.002e+00, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10380, Training Loss: 1.002e+00, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10381, Training Loss: 1.002e+00, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10382, Training Loss: 1.002e+00, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10383, Training Loss: 1.001e+00, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10384, Training Loss: 1.001e+00, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10385, Training Loss: 1.001e+00, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10386, Training Loss: 1.001e+00, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10387, Training Loss: 1.001e+00, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10388, Training Loss: 1.001e+00, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10389, Training Loss: 1.001e+00, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10390, Training Loss: 1.001e+00, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10391, Training Loss: 1.001e+00, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10392, Training Loss: 1.001e+00, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10393, Training Loss: 1.001e+00, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10394, Training Loss: 1.001e+00, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10395, Training Loss: 1.001e+00, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10396, Training Loss: 1.000e+00, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10397, Training Loss: 1.000e+00, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10398, Training Loss: 1.000e+00, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10399, Training Loss: 1.000e+00, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10400, Training Loss: 1.000e+00, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10401, Training Loss: 1.000e+00, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10402, Training Loss: 9.999e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10403, Training Loss: 9.999e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10404, Training Loss: 9.998e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10405, Training Loss: 9.997e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10406, Training Loss: 9.996e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10407, Training Loss: 9.995e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10408, Training Loss: 9.995e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10409, Training Loss: 9.994e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10410, Training Loss: 9.993e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10411, Training Loss: 9.992e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10412, Training Loss: 9.991e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10413, Training Loss: 9.991e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10414, Training Loss: 9.990e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10415, Training Loss: 9.989e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10416, Training Loss: 9.988e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10417, Training Loss: 9.987e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10418, Training Loss: 9.987e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10419, Training Loss: 9.986e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10420, Training Loss: 9.985e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10421, Training Loss: 9.984e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10422, Training Loss: 9.983e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10423, Training Loss: 9.983e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10424, Training Loss: 9.982e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10425, Training Loss: 9.981e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10426, Training Loss: 9.980e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10427, Training Loss: 9.979e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10428, Training Loss: 9.979e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10429, Training Loss: 9.978e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10430, Training Loss: 9.977e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10431, Training Loss: 9.976e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10432, Training Loss: 9.975e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10433, Training Loss: 9.975e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10434, Training Loss: 9.974e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10435, Training Loss: 9.973e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10436, Training Loss: 9.972e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10437, Training Loss: 9.971e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10438, Training Loss: 9.971e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10439, Training Loss: 9.970e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10440, Training Loss: 9.969e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10441, Training Loss: 9.968e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10442, Training Loss: 9.967e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10443, Training Loss: 9.967e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10444, Training Loss: 9.966e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10445, Training Loss: 9.965e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10446, Training Loss: 9.964e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10447, Training Loss: 9.963e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10448, Training Loss: 9.963e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10449, Training Loss: 9.962e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10450, Training Loss: 9.961e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10451, Training Loss: 9.960e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10452, Training Loss: 9.959e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10453, Training Loss: 9.959e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10454, Training Loss: 9.958e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10455, Training Loss: 9.957e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10456, Training Loss: 9.956e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10457, Training Loss: 9.956e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10458, Training Loss: 9.955e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10459, Training Loss: 9.954e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10460, Training Loss: 9.953e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10461, Training Loss: 9.952e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10462, Training Loss: 9.952e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10463, Training Loss: 9.951e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10464, Training Loss: 9.950e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10465, Training Loss: 9.949e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10466, Training Loss: 9.948e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10467, Training Loss: 9.948e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10468, Training Loss: 9.947e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10469, Training Loss: 9.946e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10470, Training Loss: 9.945e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10471, Training Loss: 9.944e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10472, Training Loss: 9.944e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10473, Training Loss: 9.943e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10474, Training Loss: 9.942e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10475, Training Loss: 9.941e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10476, Training Loss: 9.940e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10477, Training Loss: 9.940e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10478, Training Loss: 9.939e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10479, Training Loss: 9.938e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10480, Training Loss: 9.937e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10481, Training Loss: 9.936e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10482, Training Loss: 9.936e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10483, Training Loss: 9.935e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10484, Training Loss: 9.934e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10485, Training Loss: 9.933e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10486, Training Loss: 9.933e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10487, Training Loss: 9.932e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10488, Training Loss: 9.931e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10489, Training Loss: 9.930e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10490, Training Loss: 9.929e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10491, Training Loss: 9.929e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10492, Training Loss: 9.928e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10493, Training Loss: 9.927e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10494, Training Loss: 9.926e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10495, Training Loss: 9.925e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10496, Training Loss: 9.925e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10497, Training Loss: 9.924e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10498, Training Loss: 9.923e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10499, Training Loss: 9.922e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10500, Training Loss: 9.921e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10501, Training Loss: 9.921e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10502, Training Loss: 9.920e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10503, Training Loss: 9.919e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10504, Training Loss: 9.918e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10505, Training Loss: 9.917e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10506, Training Loss: 9.917e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10507, Training Loss: 9.916e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10508, Training Loss: 9.915e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10509, Training Loss: 9.914e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10510, Training Loss: 9.914e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10511, Training Loss: 9.913e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10512, Training Loss: 9.912e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10513, Training Loss: 9.911e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10514, Training Loss: 9.910e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10515, Training Loss: 9.910e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10516, Training Loss: 9.909e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10517, Training Loss: 9.908e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10518, Training Loss: 9.907e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10519, Training Loss: 9.906e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10520, Training Loss: 9.906e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10521, Training Loss: 9.905e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10522, Training Loss: 9.904e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10523, Training Loss: 9.903e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10524, Training Loss: 9.902e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10525, Training Loss: 9.902e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10526, Training Loss: 9.901e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10527, Training Loss: 9.900e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10528, Training Loss: 9.899e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10529, Training Loss: 9.899e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10530, Training Loss: 9.898e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10531, Training Loss: 9.897e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10532, Training Loss: 9.896e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10533, Training Loss: 9.895e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10534, Training Loss: 9.895e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10535, Training Loss: 9.894e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10536, Training Loss: 9.893e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10537, Training Loss: 9.892e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10538, Training Loss: 9.891e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10539, Training Loss: 9.891e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10540, Training Loss: 9.890e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10541, Training Loss: 9.889e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10542, Training Loss: 9.888e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10543, Training Loss: 9.888e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10544, Training Loss: 9.887e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10545, Training Loss: 9.886e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10546, Training Loss: 9.885e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10547, Training Loss: 9.884e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10548, Training Loss: 9.884e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10549, Training Loss: 9.883e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10550, Training Loss: 9.882e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10551, Training Loss: 9.881e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10552, Training Loss: 9.880e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10553, Training Loss: 9.880e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10554, Training Loss: 9.879e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10555, Training Loss: 9.878e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10556, Training Loss: 9.877e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10557, Training Loss: 9.877e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10558, Training Loss: 9.876e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10559, Training Loss: 9.875e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10560, Training Loss: 9.874e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10561, Training Loss: 9.873e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10562, Training Loss: 9.873e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10563, Training Loss: 9.872e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10564, Training Loss: 9.871e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10565, Training Loss: 9.870e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10566, Training Loss: 9.869e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10567, Training Loss: 9.869e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10568, Training Loss: 9.868e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10569, Training Loss: 9.867e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10570, Training Loss: 9.866e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10571, Training Loss: 9.866e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10572, Training Loss: 9.865e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10573, Training Loss: 9.864e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10574, Training Loss: 9.863e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10575, Training Loss: 9.862e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10576, Training Loss: 9.862e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10577, Training Loss: 9.861e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10578, Training Loss: 9.860e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10579, Training Loss: 9.859e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10580, Training Loss: 9.859e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10581, Training Loss: 9.858e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10582, Training Loss: 9.857e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10583, Training Loss: 9.856e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10584, Training Loss: 9.855e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10585, Training Loss: 9.855e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10586, Training Loss: 9.854e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10587, Training Loss: 9.853e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10588, Training Loss: 9.852e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10589, Training Loss: 9.851e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10590, Training Loss: 9.851e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10591, Training Loss: 9.850e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10592, Training Loss: 9.849e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10593, Training Loss: 9.848e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10594, Training Loss: 9.848e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10595, Training Loss: 9.847e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10596, Training Loss: 9.846e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10597, Training Loss: 9.845e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10598, Training Loss: 9.844e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10599, Training Loss: 9.844e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10600, Training Loss: 9.843e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10601, Training Loss: 9.842e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10602, Training Loss: 9.841e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10603, Training Loss: 9.841e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10604, Training Loss: 9.840e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10605, Training Loss: 9.839e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10606, Training Loss: 9.838e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10607, Training Loss: 9.837e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10608, Training Loss: 9.837e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10609, Training Loss: 9.836e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10610, Training Loss: 9.835e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10611, Training Loss: 9.834e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10612, Training Loss: 9.834e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10613, Training Loss: 9.833e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10614, Training Loss: 9.832e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10615, Training Loss: 9.831e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10616, Training Loss: 9.830e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10617, Training Loss: 9.830e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10618, Training Loss: 9.829e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10619, Training Loss: 9.828e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10620, Training Loss: 9.827e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10621, Training Loss: 9.827e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10622, Training Loss: 9.826e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10623, Training Loss: 9.825e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10624, Training Loss: 9.824e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10625, Training Loss: 9.823e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10626, Training Loss: 9.823e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10627, Training Loss: 9.822e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10628, Training Loss: 9.821e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10629, Training Loss: 9.820e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10630, Training Loss: 9.820e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10631, Training Loss: 9.819e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10632, Training Loss: 9.818e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10633, Training Loss: 9.817e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10634, Training Loss: 9.816e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10635, Training Loss: 9.816e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10636, Training Loss: 9.815e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10637, Training Loss: 9.814e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10638, Training Loss: 9.813e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10639, Training Loss: 9.813e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10640, Training Loss: 9.812e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10641, Training Loss: 9.811e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10642, Training Loss: 9.810e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10643, Training Loss: 9.809e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10644, Training Loss: 9.809e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10645, Training Loss: 9.808e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10646, Training Loss: 9.807e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10647, Training Loss: 9.806e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10648, Training Loss: 9.806e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10649, Training Loss: 9.805e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10650, Training Loss: 9.804e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10651, Training Loss: 9.803e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10652, Training Loss: 9.802e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10653, Training Loss: 9.802e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10654, Training Loss: 9.801e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10655, Training Loss: 9.800e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10656, Training Loss: 9.799e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10657, Training Loss: 9.799e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10658, Training Loss: 9.798e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10659, Training Loss: 9.797e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10660, Training Loss: 9.796e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10661, Training Loss: 9.796e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10662, Training Loss: 9.795e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10663, Training Loss: 9.794e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10664, Training Loss: 9.793e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10665, Training Loss: 9.792e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10666, Training Loss: 9.792e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10667, Training Loss: 9.791e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10668, Training Loss: 9.790e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10669, Training Loss: 9.789e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10670, Training Loss: 9.789e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10671, Training Loss: 9.788e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10672, Training Loss: 9.787e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10673, Training Loss: 9.786e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10674, Training Loss: 9.785e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10675, Training Loss: 9.785e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10676, Training Loss: 9.784e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10677, Training Loss: 9.783e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10678, Training Loss: 9.782e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10679, Training Loss: 9.782e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10680, Training Loss: 9.781e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10681, Training Loss: 9.780e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10682, Training Loss: 9.779e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10683, Training Loss: 9.779e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10684, Training Loss: 9.778e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10685, Training Loss: 9.777e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10686, Training Loss: 9.776e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10687, Training Loss: 9.775e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10688, Training Loss: 9.775e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10689, Training Loss: 9.774e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10690, Training Loss: 9.773e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10691, Training Loss: 9.772e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10692, Training Loss: 9.772e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10693, Training Loss: 9.771e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10694, Training Loss: 9.770e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10695, Training Loss: 9.769e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10696, Training Loss: 9.768e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10697, Training Loss: 9.768e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10698, Training Loss: 9.767e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10699, Training Loss: 9.766e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10700, Training Loss: 9.765e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10701, Training Loss: 9.765e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10702, Training Loss: 9.764e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10703, Training Loss: 9.763e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10704, Training Loss: 9.762e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10705, Training Loss: 9.762e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10706, Training Loss: 9.761e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10707, Training Loss: 9.760e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10708, Training Loss: 9.759e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10709, Training Loss: 9.758e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10710, Training Loss: 9.758e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10711, Training Loss: 9.757e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10712, Training Loss: 9.756e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10713, Training Loss: 9.755e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10714, Training Loss: 9.755e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10715, Training Loss: 9.754e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10716, Training Loss: 9.753e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10717, Training Loss: 9.752e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10718, Training Loss: 9.752e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10719, Training Loss: 9.751e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10720, Training Loss: 9.750e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10721, Training Loss: 9.749e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10722, Training Loss: 9.748e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10723, Training Loss: 9.748e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10724, Training Loss: 9.747e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10725, Training Loss: 9.746e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10726, Training Loss: 9.745e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10727, Training Loss: 9.745e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10728, Training Loss: 9.744e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10729, Training Loss: 9.743e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10730, Training Loss: 9.742e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10731, Training Loss: 9.742e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10732, Training Loss: 9.741e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10733, Training Loss: 9.740e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10734, Training Loss: 9.739e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10735, Training Loss: 9.739e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10736, Training Loss: 9.738e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10737, Training Loss: 9.737e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10738, Training Loss: 9.736e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10739, Training Loss: 9.735e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10740, Training Loss: 9.735e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10741, Training Loss: 9.734e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10742, Training Loss: 9.733e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10743, Training Loss: 9.732e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10744, Training Loss: 9.732e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10745, Training Loss: 9.731e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10746, Training Loss: 9.730e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10747, Training Loss: 9.729e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10748, Training Loss: 9.729e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10749, Training Loss: 9.728e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10750, Training Loss: 9.727e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10751, Training Loss: 9.726e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10752, Training Loss: 9.726e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10753, Training Loss: 9.725e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10754, Training Loss: 9.724e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10755, Training Loss: 9.723e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10756, Training Loss: 9.722e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10757, Training Loss: 9.722e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10758, Training Loss: 9.721e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10759, Training Loss: 9.720e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10760, Training Loss: 9.719e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10761, Training Loss: 9.719e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10762, Training Loss: 9.718e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10763, Training Loss: 9.717e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10764, Training Loss: 9.716e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10765, Training Loss: 9.716e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10766, Training Loss: 9.715e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10767, Training Loss: 9.714e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10768, Training Loss: 9.713e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10769, Training Loss: 9.713e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10770, Training Loss: 9.712e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10771, Training Loss: 9.711e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10772, Training Loss: 9.710e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10773, Training Loss: 9.709e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10774, Training Loss: 9.709e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10775, Training Loss: 9.708e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10776, Training Loss: 9.707e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10777, Training Loss: 9.706e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10778, Training Loss: 9.706e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10779, Training Loss: 9.705e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10780, Training Loss: 9.704e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10781, Training Loss: 9.703e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10782, Training Loss: 9.703e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10783, Training Loss: 9.702e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10784, Training Loss: 9.701e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10785, Training Loss: 9.700e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10786, Training Loss: 9.700e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10787, Training Loss: 9.699e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10788, Training Loss: 9.698e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10789, Training Loss: 9.697e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10790, Training Loss: 9.697e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10791, Training Loss: 9.696e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10792, Training Loss: 9.695e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10793, Training Loss: 9.694e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10794, Training Loss: 9.694e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10795, Training Loss: 9.693e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10796, Training Loss: 9.692e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10797, Training Loss: 9.691e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10798, Training Loss: 9.690e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10799, Training Loss: 9.690e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10800, Training Loss: 9.689e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10801, Training Loss: 9.688e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10802, Training Loss: 9.687e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10803, Training Loss: 9.687e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10804, Training Loss: 9.686e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10805, Training Loss: 9.685e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10806, Training Loss: 9.684e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10807, Training Loss: 9.684e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10808, Training Loss: 9.683e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10809, Training Loss: 9.682e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10810, Training Loss: 9.681e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10811, Training Loss: 9.681e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10812, Training Loss: 9.680e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10813, Training Loss: 9.679e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10814, Training Loss: 9.678e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10815, Training Loss: 9.678e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10816, Training Loss: 9.677e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10817, Training Loss: 9.676e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10818, Training Loss: 9.675e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10819, Training Loss: 9.675e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10820, Training Loss: 9.674e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10821, Training Loss: 9.673e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10822, Training Loss: 9.672e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10823, Training Loss: 9.672e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10824, Training Loss: 9.671e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10825, Training Loss: 9.670e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10826, Training Loss: 9.669e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10827, Training Loss: 9.668e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10828, Training Loss: 9.668e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10829, Training Loss: 9.667e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10830, Training Loss: 9.666e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10831, Training Loss: 9.665e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10832, Training Loss: 9.665e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10833, Training Loss: 9.664e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10834, Training Loss: 9.663e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10835, Training Loss: 9.662e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10836, Training Loss: 9.662e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10837, Training Loss: 9.661e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10838, Training Loss: 9.660e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10839, Training Loss: 9.659e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10840, Training Loss: 9.659e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10841, Training Loss: 9.658e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10842, Training Loss: 9.657e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10843, Training Loss: 9.656e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10844, Training Loss: 9.656e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10845, Training Loss: 9.655e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10846, Training Loss: 9.654e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10847, Training Loss: 9.653e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10848, Training Loss: 9.653e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10849, Training Loss: 9.652e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10850, Training Loss: 9.651e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10851, Training Loss: 9.650e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10852, Training Loss: 9.650e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10853, Training Loss: 9.649e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10854, Training Loss: 9.648e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10855, Training Loss: 9.647e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10856, Training Loss: 9.647e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10857, Training Loss: 9.646e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10858, Training Loss: 9.645e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10859, Training Loss: 9.644e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10860, Training Loss: 9.644e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10861, Training Loss: 9.643e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10862, Training Loss: 9.642e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10863, Training Loss: 9.641e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10864, Training Loss: 9.641e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10865, Training Loss: 9.640e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10866, Training Loss: 9.639e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10867, Training Loss: 9.638e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10868, Training Loss: 9.638e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10869, Training Loss: 9.637e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10870, Training Loss: 9.636e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10871, Training Loss: 9.635e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10872, Training Loss: 9.635e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10873, Training Loss: 9.634e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10874, Training Loss: 9.633e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10875, Training Loss: 9.632e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10876, Training Loss: 9.632e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10877, Training Loss: 9.631e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10878, Training Loss: 9.630e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10879, Training Loss: 9.629e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10880, Training Loss: 9.629e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10881, Training Loss: 9.628e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10882, Training Loss: 9.627e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10883, Training Loss: 9.626e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10884, Training Loss: 9.626e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10885, Training Loss: 9.625e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10886, Training Loss: 9.624e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10887, Training Loss: 9.623e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10888, Training Loss: 9.623e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10889, Training Loss: 9.622e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10890, Training Loss: 9.621e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10891, Training Loss: 9.620e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10892, Training Loss: 9.620e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10893, Training Loss: 9.619e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10894, Training Loss: 9.618e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10895, Training Loss: 9.617e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10896, Training Loss: 9.617e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10897, Training Loss: 9.616e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10898, Training Loss: 9.615e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10899, Training Loss: 9.614e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10900, Training Loss: 9.614e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10901, Training Loss: 9.613e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10902, Training Loss: 9.612e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10903, Training Loss: 9.611e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10904, Training Loss: 9.611e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10905, Training Loss: 9.610e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10906, Training Loss: 9.609e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10907, Training Loss: 9.608e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10908, Training Loss: 9.608e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10909, Training Loss: 9.607e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10910, Training Loss: 9.606e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10911, Training Loss: 9.605e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10912, Training Loss: 9.605e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10913, Training Loss: 9.604e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10914, Training Loss: 9.603e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10915, Training Loss: 9.602e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10916, Training Loss: 9.602e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10917, Training Loss: 9.601e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10918, Training Loss: 9.600e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10919, Training Loss: 9.599e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10920, Training Loss: 9.599e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10921, Training Loss: 9.598e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10922, Training Loss: 9.597e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10923, Training Loss: 9.596e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10924, Training Loss: 9.596e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10925, Training Loss: 9.595e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10926, Training Loss: 9.594e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10927, Training Loss: 9.593e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10928, Training Loss: 9.593e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10929, Training Loss: 9.592e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10930, Training Loss: 9.591e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10931, Training Loss: 9.590e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10932, Training Loss: 9.590e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10933, Training Loss: 9.589e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10934, Training Loss: 9.588e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10935, Training Loss: 9.587e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10936, Training Loss: 9.587e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10937, Training Loss: 9.586e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10938, Training Loss: 9.585e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10939, Training Loss: 9.584e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10940, Training Loss: 9.584e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10941, Training Loss: 9.583e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10942, Training Loss: 9.582e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10943, Training Loss: 9.581e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10944, Training Loss: 9.581e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10945, Training Loss: 9.580e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10946, Training Loss: 9.579e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10947, Training Loss: 9.578e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10948, Training Loss: 9.578e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10949, Training Loss: 9.577e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10950, Training Loss: 9.576e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10951, Training Loss: 9.575e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10952, Training Loss: 9.575e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10953, Training Loss: 9.574e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10954, Training Loss: 9.573e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10955, Training Loss: 9.572e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10956, Training Loss: 9.572e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10957, Training Loss: 9.571e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10958, Training Loss: 9.570e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10959, Training Loss: 9.569e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10960, Training Loss: 9.569e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10961, Training Loss: 9.568e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10962, Training Loss: 9.567e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10963, Training Loss: 9.566e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10964, Training Loss: 9.566e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10965, Training Loss: 9.565e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10966, Training Loss: 9.564e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10967, Training Loss: 9.564e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10968, Training Loss: 9.563e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10969, Training Loss: 9.562e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10970, Training Loss: 9.561e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10971, Training Loss: 9.561e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10972, Training Loss: 9.560e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10973, Training Loss: 9.559e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10974, Training Loss: 9.558e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10975, Training Loss: 9.558e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10976, Training Loss: 9.557e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10977, Training Loss: 9.556e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10978, Training Loss: 9.555e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10979, Training Loss: 9.555e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10980, Training Loss: 9.554e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10981, Training Loss: 9.553e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10982, Training Loss: 9.552e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10983, Training Loss: 9.552e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10984, Training Loss: 9.551e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10985, Training Loss: 9.550e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10986, Training Loss: 9.549e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10987, Training Loss: 9.549e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10988, Training Loss: 9.548e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10989, Training Loss: 9.547e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10990, Training Loss: 9.546e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10991, Training Loss: 9.546e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10992, Training Loss: 9.545e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10993, Training Loss: 9.544e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10994, Training Loss: 9.544e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10995, Training Loss: 9.543e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10996, Training Loss: 9.542e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10997, Training Loss: 9.541e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10998, Training Loss: 9.541e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10999, Training Loss: 9.540e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11000, Training Loss: 9.539e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11001, Training Loss: 9.538e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11002, Training Loss: 9.538e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11003, Training Loss: 9.537e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11004, Training Loss: 9.536e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11005, Training Loss: 9.535e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11006, Training Loss: 9.535e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11007, Training Loss: 9.534e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11008, Training Loss: 9.533e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11009, Training Loss: 9.532e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11010, Training Loss: 9.532e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11011, Training Loss: 9.531e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11012, Training Loss: 9.530e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11013, Training Loss: 9.529e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11014, Training Loss: 9.529e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11015, Training Loss: 9.528e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11016, Training Loss: 9.527e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11017, Training Loss: 9.527e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11018, Training Loss: 9.526e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11019, Training Loss: 9.525e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11020, Training Loss: 9.524e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11021, Training Loss: 9.524e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11022, Training Loss: 9.523e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11023, Training Loss: 9.522e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11024, Training Loss: 9.521e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11025, Training Loss: 9.521e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11026, Training Loss: 9.520e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11027, Training Loss: 9.519e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11028, Training Loss: 9.518e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11029, Training Loss: 9.518e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11030, Training Loss: 9.517e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11031, Training Loss: 9.516e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11032, Training Loss: 9.515e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11033, Training Loss: 9.515e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11034, Training Loss: 9.514e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11035, Training Loss: 9.513e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11036, Training Loss: 9.512e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11037, Training Loss: 9.512e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11038, Training Loss: 9.511e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11039, Training Loss: 9.510e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11040, Training Loss: 9.510e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11041, Training Loss: 9.509e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11042, Training Loss: 9.508e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11043, Training Loss: 9.507e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11044, Training Loss: 9.507e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11045, Training Loss: 9.506e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11046, Training Loss: 9.505e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11047, Training Loss: 9.504e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11048, Training Loss: 9.504e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11049, Training Loss: 9.503e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11050, Training Loss: 9.502e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11051, Training Loss: 9.501e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11052, Training Loss: 9.501e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11053, Training Loss: 9.500e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11054, Training Loss: 9.499e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11055, Training Loss: 9.499e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11056, Training Loss: 9.498e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11057, Training Loss: 9.497e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11058, Training Loss: 9.496e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11059, Training Loss: 9.496e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11060, Training Loss: 9.495e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11061, Training Loss: 9.494e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11062, Training Loss: 9.493e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11063, Training Loss: 9.493e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11064, Training Loss: 9.492e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11065, Training Loss: 9.491e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11066, Training Loss: 9.490e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11067, Training Loss: 9.490e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11068, Training Loss: 9.489e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11069, Training Loss: 9.488e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11070, Training Loss: 9.488e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11071, Training Loss: 9.487e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11072, Training Loss: 9.486e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11073, Training Loss: 9.485e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11074, Training Loss: 9.485e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11075, Training Loss: 9.484e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11076, Training Loss: 9.483e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11077, Training Loss: 9.482e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11078, Training Loss: 9.482e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11079, Training Loss: 9.481e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11080, Training Loss: 9.480e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11081, Training Loss: 9.479e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11082, Training Loss: 9.479e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11083, Training Loss: 9.478e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11084, Training Loss: 9.477e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11085, Training Loss: 9.477e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11086, Training Loss: 9.476e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11087, Training Loss: 9.475e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11088, Training Loss: 9.474e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11089, Training Loss: 9.474e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11090, Training Loss: 9.473e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11091, Training Loss: 9.472e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11092, Training Loss: 9.471e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11093, Training Loss: 9.471e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11094, Training Loss: 9.470e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11095, Training Loss: 9.469e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11096, Training Loss: 9.468e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11097, Training Loss: 9.468e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11098, Training Loss: 9.467e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11099, Training Loss: 9.466e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11100, Training Loss: 9.466e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11101, Training Loss: 9.465e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11102, Training Loss: 9.464e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11103, Training Loss: 9.463e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11104, Training Loss: 9.463e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11105, Training Loss: 9.462e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11106, Training Loss: 9.461e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11107, Training Loss: 9.460e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11108, Training Loss: 9.460e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11109, Training Loss: 9.459e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11110, Training Loss: 9.458e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11111, Training Loss: 9.458e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11112, Training Loss: 9.457e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11113, Training Loss: 9.456e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11114, Training Loss: 9.455e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11115, Training Loss: 9.455e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11116, Training Loss: 9.454e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11117, Training Loss: 9.453e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11118, Training Loss: 9.452e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11119, Training Loss: 9.452e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11120, Training Loss: 9.451e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11121, Training Loss: 9.450e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11122, Training Loss: 9.450e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11123, Training Loss: 9.449e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11124, Training Loss: 9.448e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11125, Training Loss: 9.447e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11126, Training Loss: 9.447e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11127, Training Loss: 9.446e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11128, Training Loss: 9.445e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11129, Training Loss: 9.444e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11130, Training Loss: 9.444e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11131, Training Loss: 9.443e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11132, Training Loss: 9.442e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11133, Training Loss: 9.441e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11134, Training Loss: 9.441e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11135, Training Loss: 9.440e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11136, Training Loss: 9.439e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11137, Training Loss: 9.439e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11138, Training Loss: 9.438e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11139, Training Loss: 9.437e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11140, Training Loss: 9.436e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11141, Training Loss: 9.436e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11142, Training Loss: 9.435e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11143, Training Loss: 9.434e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11144, Training Loss: 9.433e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11145, Training Loss: 9.433e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11146, Training Loss: 9.432e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11147, Training Loss: 9.431e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11148, Training Loss: 9.431e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11149, Training Loss: 9.430e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11150, Training Loss: 9.429e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11151, Training Loss: 9.428e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11152, Training Loss: 9.428e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11153, Training Loss: 9.427e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11154, Training Loss: 9.426e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11155, Training Loss: 9.426e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11156, Training Loss: 9.425e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11157, Training Loss: 9.424e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11158, Training Loss: 9.423e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11159, Training Loss: 9.423e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11160, Training Loss: 9.422e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11161, Training Loss: 9.421e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11162, Training Loss: 9.420e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11163, Training Loss: 9.420e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11164, Training Loss: 9.419e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11165, Training Loss: 9.418e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11166, Training Loss: 9.418e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11167, Training Loss: 9.417e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11168, Training Loss: 9.416e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11169, Training Loss: 9.415e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11170, Training Loss: 9.415e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11171, Training Loss: 9.414e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11172, Training Loss: 9.413e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11173, Training Loss: 9.412e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11174, Training Loss: 9.412e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11175, Training Loss: 9.411e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11176, Training Loss: 9.410e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11177, Training Loss: 9.410e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11178, Training Loss: 9.409e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11179, Training Loss: 9.408e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11180, Training Loss: 9.407e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11181, Training Loss: 9.407e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11182, Training Loss: 9.406e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11183, Training Loss: 9.405e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11184, Training Loss: 9.405e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11185, Training Loss: 9.404e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11186, Training Loss: 9.403e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11187, Training Loss: 9.402e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11188, Training Loss: 9.402e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11189, Training Loss: 9.401e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11190, Training Loss: 9.400e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11191, Training Loss: 9.399e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11192, Training Loss: 9.399e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11193, Training Loss: 9.398e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11194, Training Loss: 9.397e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11195, Training Loss: 9.397e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11196, Training Loss: 9.396e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11197, Training Loss: 9.395e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11198, Training Loss: 9.394e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11199, Training Loss: 9.394e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11200, Training Loss: 9.393e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11201, Training Loss: 9.392e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11202, Training Loss: 9.392e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11203, Training Loss: 9.391e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11204, Training Loss: 9.390e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11205, Training Loss: 9.389e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11206, Training Loss: 9.389e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11207, Training Loss: 9.388e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11208, Training Loss: 9.387e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11209, Training Loss: 9.386e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11210, Training Loss: 9.386e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11211, Training Loss: 9.385e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11212, Training Loss: 9.384e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11213, Training Loss: 9.384e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11214, Training Loss: 9.383e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11215, Training Loss: 9.382e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11216, Training Loss: 9.381e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11217, Training Loss: 9.381e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11218, Training Loss: 9.380e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11219, Training Loss: 9.379e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11220, Training Loss: 9.379e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11221, Training Loss: 9.378e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11222, Training Loss: 9.377e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11223, Training Loss: 9.376e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11224, Training Loss: 9.376e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11225, Training Loss: 9.375e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11226, Training Loss: 9.374e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11227, Training Loss: 9.374e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11228, Training Loss: 9.373e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11229, Training Loss: 9.372e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11230, Training Loss: 9.371e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11231, Training Loss: 9.371e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11232, Training Loss: 9.370e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11233, Training Loss: 9.369e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11234, Training Loss: 9.368e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11235, Training Loss: 9.368e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11236, Training Loss: 9.367e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11237, Training Loss: 9.366e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11238, Training Loss: 9.366e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11239, Training Loss: 9.365e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11240, Training Loss: 9.364e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11241, Training Loss: 9.363e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11242, Training Loss: 9.363e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11243, Training Loss: 9.362e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11244, Training Loss: 9.361e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11245, Training Loss: 9.361e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11246, Training Loss: 9.360e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11247, Training Loss: 9.359e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11248, Training Loss: 9.358e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11249, Training Loss: 9.358e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11250, Training Loss: 9.357e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11251, Training Loss: 9.356e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11252, Training Loss: 9.356e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11253, Training Loss: 9.355e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11254, Training Loss: 9.354e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11255, Training Loss: 9.353e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11256, Training Loss: 9.353e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11257, Training Loss: 9.352e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11258, Training Loss: 9.351e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11259, Training Loss: 9.351e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11260, Training Loss: 9.350e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11261, Training Loss: 9.349e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11262, Training Loss: 9.348e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11263, Training Loss: 9.348e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11264, Training Loss: 9.347e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11265, Training Loss: 9.346e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11266, Training Loss: 9.346e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11267, Training Loss: 9.345e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11268, Training Loss: 9.344e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11269, Training Loss: 9.343e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11270, Training Loss: 9.343e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11271, Training Loss: 9.342e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11272, Training Loss: 9.341e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11273, Training Loss: 9.341e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11274, Training Loss: 9.340e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11275, Training Loss: 9.339e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11276, Training Loss: 9.338e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11277, Training Loss: 9.338e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11278, Training Loss: 9.337e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11279, Training Loss: 9.336e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11280, Training Loss: 9.336e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11281, Training Loss: 9.335e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11282, Training Loss: 9.334e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11283, Training Loss: 9.333e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11284, Training Loss: 9.333e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11285, Training Loss: 9.332e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11286, Training Loss: 9.331e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11287, Training Loss: 9.331e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11288, Training Loss: 9.330e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11289, Training Loss: 9.329e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11290, Training Loss: 9.328e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11291, Training Loss: 9.328e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11292, Training Loss: 9.327e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11293, Training Loss: 9.326e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11294, Training Loss: 9.326e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11295, Training Loss: 9.325e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11296, Training Loss: 9.324e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11297, Training Loss: 9.323e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11298, Training Loss: 9.323e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11299, Training Loss: 9.322e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11300, Training Loss: 9.321e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11301, Training Loss: 9.321e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11302, Training Loss: 9.320e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11303, Training Loss: 9.319e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11304, Training Loss: 9.318e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11305, Training Loss: 9.318e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11306, Training Loss: 9.317e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11307, Training Loss: 9.316e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11308, Training Loss: 9.316e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11309, Training Loss: 9.315e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11310, Training Loss: 9.314e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11311, Training Loss: 9.314e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11312, Training Loss: 9.313e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11313, Training Loss: 9.312e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11314, Training Loss: 9.311e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11315, Training Loss: 9.311e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11316, Training Loss: 9.310e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11317, Training Loss: 9.309e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11318, Training Loss: 9.309e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11319, Training Loss: 9.308e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11320, Training Loss: 9.307e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11321, Training Loss: 9.306e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11322, Training Loss: 9.306e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11323, Training Loss: 9.305e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11324, Training Loss: 9.304e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11325, Training Loss: 9.304e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11326, Training Loss: 9.303e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11327, Training Loss: 9.302e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11328, Training Loss: 9.301e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11329, Training Loss: 9.301e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11330, Training Loss: 9.300e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11331, Training Loss: 9.299e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11332, Training Loss: 9.299e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11333, Training Loss: 9.298e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11334, Training Loss: 9.297e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11335, Training Loss: 9.296e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11336, Training Loss: 9.296e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11337, Training Loss: 9.295e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11338, Training Loss: 9.294e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11339, Training Loss: 9.294e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11340, Training Loss: 9.293e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11341, Training Loss: 9.292e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11342, Training Loss: 9.292e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11343, Training Loss: 9.291e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11344, Training Loss: 9.290e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11345, Training Loss: 9.289e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11346, Training Loss: 9.289e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11347, Training Loss: 9.288e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11348, Training Loss: 9.287e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11349, Training Loss: 9.287e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11350, Training Loss: 9.286e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11351, Training Loss: 9.285e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11352, Training Loss: 9.284e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11353, Training Loss: 9.284e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11354, Training Loss: 9.283e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11355, Training Loss: 9.282e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11356, Training Loss: 9.282e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11357, Training Loss: 9.281e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11358, Training Loss: 9.280e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11359, Training Loss: 9.280e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11360, Training Loss: 9.279e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11361, Training Loss: 9.278e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11362, Training Loss: 9.277e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11363, Training Loss: 9.277e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11364, Training Loss: 9.276e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11365, Training Loss: 9.275e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11366, Training Loss: 9.275e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11367, Training Loss: 9.274e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11368, Training Loss: 9.273e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11369, Training Loss: 9.272e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11370, Training Loss: 9.272e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11371, Training Loss: 9.271e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11372, Training Loss: 9.270e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11373, Training Loss: 9.270e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11374, Training Loss: 9.269e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11375, Training Loss: 9.268e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11376, Training Loss: 9.268e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11377, Training Loss: 9.267e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11378, Training Loss: 9.266e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11379, Training Loss: 9.265e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11380, Training Loss: 9.265e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11381, Training Loss: 9.264e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11382, Training Loss: 9.263e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11383, Training Loss: 9.263e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11384, Training Loss: 9.262e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11385, Training Loss: 9.261e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11386, Training Loss: 9.260e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11387, Training Loss: 9.260e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11388, Training Loss: 9.259e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11389, Training Loss: 9.258e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11390, Training Loss: 9.258e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11391, Training Loss: 9.257e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11392, Training Loss: 9.256e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11393, Training Loss: 9.256e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11394, Training Loss: 9.255e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11395, Training Loss: 9.254e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11396, Training Loss: 9.253e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11397, Training Loss: 9.253e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11398, Training Loss: 9.252e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11399, Training Loss: 9.251e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11400, Training Loss: 9.251e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11401, Training Loss: 9.250e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11402, Training Loss: 9.249e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11403, Training Loss: 9.249e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11404, Training Loss: 9.248e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11405, Training Loss: 9.247e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11406, Training Loss: 9.246e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11407, Training Loss: 9.246e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11408, Training Loss: 9.245e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11409, Training Loss: 9.244e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11410, Training Loss: 9.244e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11411, Training Loss: 9.243e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11412, Training Loss: 9.242e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11413, Training Loss: 9.242e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11414, Training Loss: 9.241e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11415, Training Loss: 9.240e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11416, Training Loss: 9.239e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11417, Training Loss: 9.239e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11418, Training Loss: 9.238e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11419, Training Loss: 9.237e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11420, Training Loss: 9.237e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11421, Training Loss: 9.236e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11422, Training Loss: 9.235e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11423, Training Loss: 9.234e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11424, Training Loss: 9.234e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11425, Training Loss: 9.233e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11426, Training Loss: 9.232e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11427, Training Loss: 9.232e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11428, Training Loss: 9.231e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11429, Training Loss: 9.230e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11430, Training Loss: 9.230e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11431, Training Loss: 9.229e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11432, Training Loss: 9.228e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11433, Training Loss: 9.227e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11434, Training Loss: 9.227e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11435, Training Loss: 9.226e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11436, Training Loss: 9.225e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11437, Training Loss: 9.225e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11438, Training Loss: 9.224e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11439, Training Loss: 9.223e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11440, Training Loss: 9.223e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11441, Training Loss: 9.222e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11442, Training Loss: 9.221e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11443, Training Loss: 9.221e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11444, Training Loss: 9.220e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11445, Training Loss: 9.219e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11446, Training Loss: 9.218e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11447, Training Loss: 9.218e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11448, Training Loss: 9.217e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11449, Training Loss: 9.216e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11450, Training Loss: 9.216e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11451, Training Loss: 9.215e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11452, Training Loss: 9.214e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11453, Training Loss: 9.214e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11454, Training Loss: 9.213e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11455, Training Loss: 9.212e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11456, Training Loss: 9.211e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11457, Training Loss: 9.211e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11458, Training Loss: 9.210e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11459, Training Loss: 9.209e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11460, Training Loss: 9.209e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11461, Training Loss: 9.208e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11462, Training Loss: 9.207e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11463, Training Loss: 9.207e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11464, Training Loss: 9.206e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11465, Training Loss: 9.205e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11466, Training Loss: 9.204e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11467, Training Loss: 9.204e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11468, Training Loss: 9.203e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11469, Training Loss: 9.202e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11470, Training Loss: 9.202e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11471, Training Loss: 9.201e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11472, Training Loss: 9.200e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11473, Training Loss: 9.200e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11474, Training Loss: 9.199e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11475, Training Loss: 9.198e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11476, Training Loss: 9.197e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11477, Training Loss: 9.197e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11478, Training Loss: 9.196e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11479, Training Loss: 9.195e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11480, Training Loss: 9.195e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11481, Training Loss: 9.194e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11482, Training Loss: 9.193e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11483, Training Loss: 9.193e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11484, Training Loss: 9.192e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11485, Training Loss: 9.191e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11486, Training Loss: 9.191e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11487, Training Loss: 9.190e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11488, Training Loss: 9.189e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11489, Training Loss: 9.188e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11490, Training Loss: 9.188e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11491, Training Loss: 9.187e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11492, Training Loss: 9.186e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11493, Training Loss: 9.186e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11494, Training Loss: 9.185e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11495, Training Loss: 9.184e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11496, Training Loss: 9.184e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11497, Training Loss: 9.183e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11498, Training Loss: 9.182e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11499, Training Loss: 9.182e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11500, Training Loss: 9.181e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11501, Training Loss: 9.180e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11502, Training Loss: 9.179e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11503, Training Loss: 9.179e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11504, Training Loss: 9.178e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11505, Training Loss: 9.177e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11506, Training Loss: 9.177e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11507, Training Loss: 9.176e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11508, Training Loss: 9.175e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11509, Training Loss: 9.175e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11510, Training Loss: 9.174e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11511, Training Loss: 9.173e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11512, Training Loss: 9.172e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11513, Training Loss: 9.172e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11514, Training Loss: 9.171e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11515, Training Loss: 9.170e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11516, Training Loss: 9.170e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11517, Training Loss: 9.169e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11518, Training Loss: 9.168e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11519, Training Loss: 9.168e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11520, Training Loss: 9.167e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11521, Training Loss: 9.166e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11522, Training Loss: 9.166e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11523, Training Loss: 9.165e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11524, Training Loss: 9.164e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11525, Training Loss: 9.163e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11526, Training Loss: 9.163e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11527, Training Loss: 9.162e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11528, Training Loss: 9.161e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11529, Training Loss: 9.161e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11530, Training Loss: 9.160e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11531, Training Loss: 9.159e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11532, Training Loss: 9.159e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11533, Training Loss: 9.158e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11534, Training Loss: 9.157e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11535, Training Loss: 9.157e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11536, Training Loss: 9.156e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11537, Training Loss: 9.155e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11538, Training Loss: 9.154e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11539, Training Loss: 9.154e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11540, Training Loss: 9.153e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11541, Training Loss: 9.152e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11542, Training Loss: 9.152e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11543, Training Loss: 9.151e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11544, Training Loss: 9.150e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11545, Training Loss: 9.150e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11546, Training Loss: 9.149e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11547, Training Loss: 9.148e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11548, Training Loss: 9.148e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11549, Training Loss: 9.147e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11550, Training Loss: 9.146e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11551, Training Loss: 9.145e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11552, Training Loss: 9.145e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11553, Training Loss: 9.144e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11554, Training Loss: 9.143e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11555, Training Loss: 9.143e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11556, Training Loss: 9.142e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11557, Training Loss: 9.141e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11558, Training Loss: 9.141e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11559, Training Loss: 9.140e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11560, Training Loss: 9.139e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11561, Training Loss: 9.139e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11562, Training Loss: 9.138e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11563, Training Loss: 9.137e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11564, Training Loss: 9.136e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11565, Training Loss: 9.136e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11566, Training Loss: 9.135e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11567, Training Loss: 9.134e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11568, Training Loss: 9.134e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11569, Training Loss: 9.133e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11570, Training Loss: 9.132e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11571, Training Loss: 9.132e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11572, Training Loss: 9.131e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11573, Training Loss: 9.130e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11574, Training Loss: 9.130e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11575, Training Loss: 9.129e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11576, Training Loss: 9.128e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11577, Training Loss: 9.127e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11578, Training Loss: 9.127e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11579, Training Loss: 9.126e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11580, Training Loss: 9.125e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11581, Training Loss: 9.125e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11582, Training Loss: 9.124e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11583, Training Loss: 9.123e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11584, Training Loss: 9.123e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11585, Training Loss: 9.122e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11586, Training Loss: 9.121e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11587, Training Loss: 9.121e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11588, Training Loss: 9.120e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11589, Training Loss: 9.119e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11590, Training Loss: 9.118e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11591, Training Loss: 9.118e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11592, Training Loss: 9.117e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11593, Training Loss: 9.116e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11594, Training Loss: 9.116e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11595, Training Loss: 9.115e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11596, Training Loss: 9.114e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11597, Training Loss: 9.114e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11598, Training Loss: 9.113e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11599, Training Loss: 9.112e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11600, Training Loss: 9.112e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11601, Training Loss: 9.111e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11602, Training Loss: 9.110e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11603, Training Loss: 9.110e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11604, Training Loss: 9.109e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11605, Training Loss: 9.108e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11606, Training Loss: 9.107e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11607, Training Loss: 9.107e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11608, Training Loss: 9.106e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11609, Training Loss: 9.105e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11610, Training Loss: 9.105e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11611, Training Loss: 9.104e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11612, Training Loss: 9.103e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11613, Training Loss: 9.103e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11614, Training Loss: 9.102e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11615, Training Loss: 9.101e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11616, Training Loss: 9.101e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11617, Training Loss: 9.100e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11618, Training Loss: 9.099e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11619, Training Loss: 9.098e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11620, Training Loss: 9.098e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11621, Training Loss: 9.097e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11622, Training Loss: 9.096e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11623, Training Loss: 9.096e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11624, Training Loss: 9.095e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11625, Training Loss: 9.094e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11626, Training Loss: 9.094e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11627, Training Loss: 9.093e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11628, Training Loss: 9.092e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11629, Training Loss: 9.092e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11630, Training Loss: 9.091e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11631, Training Loss: 9.090e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11632, Training Loss: 9.090e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11633, Training Loss: 9.089e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11634, Training Loss: 9.088e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11635, Training Loss: 9.087e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11636, Training Loss: 9.087e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11637, Training Loss: 9.086e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11638, Training Loss: 9.085e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11639, Training Loss: 9.085e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11640, Training Loss: 9.084e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11641, Training Loss: 9.083e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11642, Training Loss: 9.083e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11643, Training Loss: 9.082e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11644, Training Loss: 9.081e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11645, Training Loss: 9.081e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11646, Training Loss: 9.080e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11647, Training Loss: 9.079e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11648, Training Loss: 9.078e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11649, Training Loss: 9.078e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11650, Training Loss: 9.077e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11651, Training Loss: 9.076e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11652, Training Loss: 9.076e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11653, Training Loss: 9.075e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11654, Training Loss: 9.074e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11655, Training Loss: 9.074e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11656, Training Loss: 9.073e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11657, Training Loss: 9.072e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11658, Training Loss: 9.071e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11659, Training Loss: 9.071e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11660, Training Loss: 9.070e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11661, Training Loss: 9.069e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11662, Training Loss: 9.069e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11663, Training Loss: 9.068e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11664, Training Loss: 9.067e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11665, Training Loss: 9.067e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11666, Training Loss: 9.066e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11667, Training Loss: 9.065e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11668, Training Loss: 9.064e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11669, Training Loss: 9.064e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11670, Training Loss: 9.063e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11671, Training Loss: 9.062e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11672, Training Loss: 9.062e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11673, Training Loss: 9.061e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11674, Training Loss: 9.060e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11675, Training Loss: 9.060e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11676, Training Loss: 9.059e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11677, Training Loss: 9.058e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11678, Training Loss: 9.057e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11679, Training Loss: 9.057e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11680, Training Loss: 9.056e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11681, Training Loss: 9.055e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11682, Training Loss: 9.055e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11683, Training Loss: 9.054e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11684, Training Loss: 9.053e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11685, Training Loss: 9.053e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11686, Training Loss: 9.052e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11687, Training Loss: 9.051e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11688, Training Loss: 9.051e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11689, Training Loss: 9.050e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11690, Training Loss: 9.049e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11691, Training Loss: 9.048e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11692, Training Loss: 9.048e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11693, Training Loss: 9.047e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11694, Training Loss: 9.046e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11695, Training Loss: 9.046e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11696, Training Loss: 9.045e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11697, Training Loss: 9.044e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11698, Training Loss: 9.044e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11699, Training Loss: 9.043e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11700, Training Loss: 9.042e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11701, Training Loss: 9.041e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11702, Training Loss: 9.041e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11703, Training Loss: 9.040e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11704, Training Loss: 9.039e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11705, Training Loss: 9.039e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11706, Training Loss: 9.038e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11707, Training Loss: 9.037e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11708, Training Loss: 9.037e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11709, Training Loss: 9.036e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11710, Training Loss: 9.035e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11711, Training Loss: 9.034e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11712, Training Loss: 9.034e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11713, Training Loss: 9.033e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11714, Training Loss: 9.032e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11715, Training Loss: 9.032e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11716, Training Loss: 9.031e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11717, Training Loss: 9.030e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11718, Training Loss: 9.030e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11719, Training Loss: 9.029e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11720, Training Loss: 9.028e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11721, Training Loss: 9.027e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11722, Training Loss: 9.027e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11723, Training Loss: 9.026e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11724, Training Loss: 9.025e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11725, Training Loss: 9.025e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11726, Training Loss: 9.024e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11727, Training Loss: 9.023e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11728, Training Loss: 9.023e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11729, Training Loss: 9.022e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11730, Training Loss: 9.021e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11731, Training Loss: 9.020e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11732, Training Loss: 9.020e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11733, Training Loss: 9.019e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11734, Training Loss: 9.018e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11735, Training Loss: 9.018e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11736, Training Loss: 9.017e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11737, Training Loss: 9.016e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11738, Training Loss: 9.015e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11739, Training Loss: 9.015e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11740, Training Loss: 9.014e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11741, Training Loss: 9.013e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11742, Training Loss: 9.013e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11743, Training Loss: 9.012e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11744, Training Loss: 9.011e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11745, Training Loss: 9.011e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11746, Training Loss: 9.010e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11747, Training Loss: 9.009e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11748, Training Loss: 9.008e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11749, Training Loss: 9.008e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11750, Training Loss: 9.007e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11751, Training Loss: 9.006e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11752, Training Loss: 9.006e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11753, Training Loss: 9.005e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11754, Training Loss: 9.004e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11755, Training Loss: 9.004e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11756, Training Loss: 9.003e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11757, Training Loss: 9.002e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11758, Training Loss: 9.001e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11759, Training Loss: 9.001e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11760, Training Loss: 9.000e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11761, Training Loss: 8.999e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11762, Training Loss: 8.999e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11763, Training Loss: 8.998e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11764, Training Loss: 8.997e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11765, Training Loss: 8.997e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11766, Training Loss: 8.996e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11767, Training Loss: 8.995e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11768, Training Loss: 8.994e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11769, Training Loss: 8.994e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11770, Training Loss: 8.993e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11771, Training Loss: 8.992e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11772, Training Loss: 8.992e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11773, Training Loss: 8.991e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11774, Training Loss: 8.990e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11775, Training Loss: 8.990e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11776, Training Loss: 8.989e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11777, Training Loss: 8.988e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11778, Training Loss: 8.988e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11779, Training Loss: 8.987e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11780, Training Loss: 8.986e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11781, Training Loss: 8.986e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11782, Training Loss: 8.985e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11783, Training Loss: 8.984e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11784, Training Loss: 8.984e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11785, Training Loss: 8.983e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11786, Training Loss: 8.982e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11787, Training Loss: 8.981e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11788, Training Loss: 8.981e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11789, Training Loss: 8.980e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11790, Training Loss: 8.979e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11791, Training Loss: 8.979e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11792, Training Loss: 8.978e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11793, Training Loss: 8.977e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11794, Training Loss: 8.977e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11795, Training Loss: 8.976e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11796, Training Loss: 8.975e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11797, Training Loss: 8.975e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11798, Training Loss: 8.974e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11799, Training Loss: 8.973e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11800, Training Loss: 8.973e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11801, Training Loss: 8.972e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11802, Training Loss: 8.971e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11803, Training Loss: 8.971e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11804, Training Loss: 8.970e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11805, Training Loss: 8.969e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11806, Training Loss: 8.969e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11807, Training Loss: 8.968e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11808, Training Loss: 8.967e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11809, Training Loss: 8.967e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11810, Training Loss: 8.966e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11811, Training Loss: 8.965e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11812, Training Loss: 8.965e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11813, Training Loss: 8.964e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11814, Training Loss: 8.963e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11815, Training Loss: 8.963e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11816, Training Loss: 8.962e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11817, Training Loss: 8.961e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11818, Training Loss: 8.961e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11819, Training Loss: 8.960e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11820, Training Loss: 8.959e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11821, Training Loss: 8.959e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11822, Training Loss: 8.958e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11823, Training Loss: 8.957e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11824, Training Loss: 8.957e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11825, Training Loss: 8.956e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11826, Training Loss: 8.955e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11827, Training Loss: 8.955e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11828, Training Loss: 8.954e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11829, Training Loss: 8.953e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11830, Training Loss: 8.953e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11831, Training Loss: 8.952e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11832, Training Loss: 8.951e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11833, Training Loss: 8.951e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11834, Training Loss: 8.950e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11835, Training Loss: 8.949e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11836, Training Loss: 8.949e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11837, Training Loss: 8.948e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11838, Training Loss: 8.947e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11839, Training Loss: 8.947e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11840, Training Loss: 8.946e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11841, Training Loss: 8.945e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11842, Training Loss: 8.945e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11843, Training Loss: 8.944e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11844, Training Loss: 8.943e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11845, Training Loss: 8.943e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11846, Training Loss: 8.942e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11847, Training Loss: 8.941e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11848, Training Loss: 8.941e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11849, Training Loss: 8.940e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11850, Training Loss: 8.939e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11851, Training Loss: 8.939e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11852, Training Loss: 8.938e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11853, Training Loss: 8.937e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11854, Training Loss: 8.937e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11855, Training Loss: 8.936e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11856, Training Loss: 8.935e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11857, Training Loss: 8.935e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11858, Training Loss: 8.934e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11859, Training Loss: 8.933e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11860, Training Loss: 8.933e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11861, Training Loss: 8.932e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11862, Training Loss: 8.931e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11863, Training Loss: 8.931e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11864, Training Loss: 8.930e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11865, Training Loss: 8.929e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11866, Training Loss: 8.929e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11867, Training Loss: 8.928e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11868, Training Loss: 8.927e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11869, Training Loss: 8.927e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11870, Training Loss: 8.926e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11871, Training Loss: 8.925e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11872, Training Loss: 8.925e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11873, Training Loss: 8.924e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11874, Training Loss: 8.923e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11875, Training Loss: 8.923e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11876, Training Loss: 8.922e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11877, Training Loss: 8.921e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11878, Training Loss: 8.921e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11879, Training Loss: 8.920e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11880, Training Loss: 8.919e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11881, Training Loss: 8.919e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11882, Training Loss: 8.918e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11883, Training Loss: 8.917e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11884, Training Loss: 8.917e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11885, Training Loss: 8.916e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11886, Training Loss: 8.915e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11887, Training Loss: 8.915e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11888, Training Loss: 8.914e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11889, Training Loss: 8.913e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11890, Training Loss: 8.913e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11891, Training Loss: 8.912e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11892, Training Loss: 8.911e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11893, Training Loss: 8.911e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11894, Training Loss: 8.910e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11895, Training Loss: 8.909e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11896, Training Loss: 8.909e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11897, Training Loss: 8.908e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11898, Training Loss: 8.907e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11899, Training Loss: 8.907e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11900, Training Loss: 8.906e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11901, Training Loss: 8.905e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11902, Training Loss: 8.905e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11903, Training Loss: 8.904e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11904, Training Loss: 8.903e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11905, Training Loss: 8.903e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11906, Training Loss: 8.902e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11907, Training Loss: 8.902e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11908, Training Loss: 8.901e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11909, Training Loss: 8.900e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11910, Training Loss: 8.900e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11911, Training Loss: 8.899e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11912, Training Loss: 8.898e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11913, Training Loss: 8.898e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11914, Training Loss: 8.897e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11915, Training Loss: 8.896e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11916, Training Loss: 8.896e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11917, Training Loss: 8.895e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11918, Training Loss: 8.894e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11919, Training Loss: 8.894e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11920, Training Loss: 8.893e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11921, Training Loss: 8.892e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11922, Training Loss: 8.892e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11923, Training Loss: 8.891e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11924, Training Loss: 8.890e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11925, Training Loss: 8.890e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11926, Training Loss: 8.889e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11927, Training Loss: 8.888e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11928, Training Loss: 8.888e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11929, Training Loss: 8.887e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11930, Training Loss: 8.886e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11931, Training Loss: 8.886e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11932, Training Loss: 8.885e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11933, Training Loss: 8.884e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11934, Training Loss: 8.884e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11935, Training Loss: 8.883e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11936, Training Loss: 8.882e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11937, Training Loss: 8.882e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11938, Training Loss: 8.881e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11939, Training Loss: 8.880e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11940, Training Loss: 8.880e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11941, Training Loss: 8.879e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11942, Training Loss: 8.879e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11943, Training Loss: 8.878e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11944, Training Loss: 8.877e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11945, Training Loss: 8.877e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11946, Training Loss: 8.876e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11947, Training Loss: 8.875e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11948, Training Loss: 8.875e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11949, Training Loss: 8.874e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11950, Training Loss: 8.873e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11951, Training Loss: 8.873e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11952, Training Loss: 8.872e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11953, Training Loss: 8.871e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11954, Training Loss: 8.871e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11955, Training Loss: 8.870e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11956, Training Loss: 8.869e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11957, Training Loss: 8.869e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11958, Training Loss: 8.868e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11959, Training Loss: 8.867e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11960, Training Loss: 8.867e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11961, Training Loss: 8.866e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11962, Training Loss: 8.865e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11963, Training Loss: 8.865e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11964, Training Loss: 8.864e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11965, Training Loss: 8.863e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11966, Training Loss: 8.863e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11967, Training Loss: 8.862e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11968, Training Loss: 8.861e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11969, Training Loss: 8.861e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11970, Training Loss: 8.860e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11971, Training Loss: 8.860e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11972, Training Loss: 8.859e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11973, Training Loss: 8.858e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11974, Training Loss: 8.858e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11975, Training Loss: 8.857e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11976, Training Loss: 8.856e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11977, Training Loss: 8.856e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11978, Training Loss: 8.855e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11979, Training Loss: 8.854e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11980, Training Loss: 8.854e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11981, Training Loss: 8.853e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11982, Training Loss: 8.852e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11983, Training Loss: 8.852e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11984, Training Loss: 8.851e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11985, Training Loss: 8.850e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11986, Training Loss: 8.850e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11987, Training Loss: 8.849e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11988, Training Loss: 8.848e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11989, Training Loss: 8.848e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11990, Training Loss: 8.847e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11991, Training Loss: 8.846e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11992, Training Loss: 8.846e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11993, Training Loss: 8.845e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11994, Training Loss: 8.845e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11995, Training Loss: 8.844e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11996, Training Loss: 8.843e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11997, Training Loss: 8.843e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11998, Training Loss: 8.842e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11999, Training Loss: 8.841e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12000, Training Loss: 8.841e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12001, Training Loss: 8.840e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12002, Training Loss: 8.839e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12003, Training Loss: 8.839e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12004, Training Loss: 8.838e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12005, Training Loss: 8.837e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12006, Training Loss: 8.837e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12007, Training Loss: 8.836e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12008, Training Loss: 8.835e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12009, Training Loss: 8.835e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12010, Training Loss: 8.834e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12011, Training Loss: 8.833e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12012, Training Loss: 8.833e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12013, Training Loss: 8.832e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12014, Training Loss: 8.832e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12015, Training Loss: 8.831e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12016, Training Loss: 8.830e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12017, Training Loss: 8.830e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12018, Training Loss: 8.829e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12019, Training Loss: 8.828e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12020, Training Loss: 8.828e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12021, Training Loss: 8.827e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12022, Training Loss: 8.826e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12023, Training Loss: 8.826e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12024, Training Loss: 8.825e-01, Validation Loss: 9.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12025, Training Loss: 8.824e-01, Validation Loss: 9.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12026, Training Loss: 8.824e-01, Validation Loss: 9.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12027, Training Loss: 8.823e-01, Validation Loss: 9.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12028, Training Loss: 8.822e-01, Validation Loss: 9.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12029, Training Loss: 8.822e-01, Validation Loss: 9.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12030, Training Loss: 8.821e-01, Validation Loss: 9.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12031, Training Loss: 8.820e-01, Validation Loss: 9.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12032, Training Loss: 8.820e-01, Validation Loss: 9.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12033, Training Loss: 8.819e-01, Validation Loss: 9.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12034, Training Loss: 8.819e-01, Validation Loss: 9.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12035, Training Loss: 8.818e-01, Validation Loss: 9.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12036, Training Loss: 8.817e-01, Validation Loss: 9.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12037, Training Loss: 8.817e-01, Validation Loss: 9.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12038, Training Loss: 8.816e-01, Validation Loss: 9.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12039, Training Loss: 8.815e-01, Validation Loss: 9.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12040, Training Loss: 8.815e-01, Validation Loss: 9.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12041, Training Loss: 8.814e-01, Validation Loss: 9.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12042, Training Loss: 8.813e-01, Validation Loss: 9.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12043, Training Loss: 8.813e-01, Validation Loss: 9.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12044, Training Loss: 8.812e-01, Validation Loss: 9.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12045, Training Loss: 8.811e-01, Validation Loss: 9.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12046, Training Loss: 8.811e-01, Validation Loss: 9.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12047, Training Loss: 8.810e-01, Validation Loss: 9.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12048, Training Loss: 8.809e-01, Validation Loss: 9.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12049, Training Loss: 8.809e-01, Validation Loss: 9.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12050, Training Loss: 8.808e-01, Validation Loss: 9.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12051, Training Loss: 8.808e-01, Validation Loss: 9.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12052, Training Loss: 8.807e-01, Validation Loss: 9.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12053, Training Loss: 8.806e-01, Validation Loss: 9.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12054, Training Loss: 8.806e-01, Validation Loss: 9.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12055, Training Loss: 8.805e-01, Validation Loss: 9.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12056, Training Loss: 8.804e-01, Validation Loss: 9.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12057, Training Loss: 8.804e-01, Validation Loss: 9.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12058, Training Loss: 8.803e-01, Validation Loss: 9.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12059, Training Loss: 8.802e-01, Validation Loss: 9.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12060, Training Loss: 8.802e-01, Validation Loss: 9.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12061, Training Loss: 8.801e-01, Validation Loss: 9.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12062, Training Loss: 8.800e-01, Validation Loss: 9.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12063, Training Loss: 8.800e-01, Validation Loss: 9.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12064, Training Loss: 8.799e-01, Validation Loss: 9.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12065, Training Loss: 8.798e-01, Validation Loss: 9.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12066, Training Loss: 8.798e-01, Validation Loss: 9.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12067, Training Loss: 8.797e-01, Validation Loss: 9.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12068, Training Loss: 8.797e-01, Validation Loss: 9.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12069, Training Loss: 8.796e-01, Validation Loss: 9.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12070, Training Loss: 8.795e-01, Validation Loss: 9.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12071, Training Loss: 8.795e-01, Validation Loss: 9.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12072, Training Loss: 8.794e-01, Validation Loss: 9.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12073, Training Loss: 8.793e-01, Validation Loss: 9.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12074, Training Loss: 8.793e-01, Validation Loss: 9.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12075, Training Loss: 8.792e-01, Validation Loss: 9.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12076, Training Loss: 8.791e-01, Validation Loss: 9.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12077, Training Loss: 8.791e-01, Validation Loss: 9.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12078, Training Loss: 8.790e-01, Validation Loss: 9.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12079, Training Loss: 8.789e-01, Validation Loss: 9.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12080, Training Loss: 8.789e-01, Validation Loss: 9.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12081, Training Loss: 8.788e-01, Validation Loss: 9.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12082, Training Loss: 8.788e-01, Validation Loss: 9.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12083, Training Loss: 8.787e-01, Validation Loss: 9.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12084, Training Loss: 8.786e-01, Validation Loss: 9.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12085, Training Loss: 8.786e-01, Validation Loss: 9.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12086, Training Loss: 8.785e-01, Validation Loss: 9.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12087, Training Loss: 8.784e-01, Validation Loss: 9.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12088, Training Loss: 8.784e-01, Validation Loss: 9.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12089, Training Loss: 8.783e-01, Validation Loss: 9.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12090, Training Loss: 8.782e-01, Validation Loss: 9.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12091, Training Loss: 8.782e-01, Validation Loss: 9.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12092, Training Loss: 8.781e-01, Validation Loss: 9.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12093, Training Loss: 8.780e-01, Validation Loss: 9.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12094, Training Loss: 8.780e-01, Validation Loss: 9.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12095, Training Loss: 8.779e-01, Validation Loss: 9.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12096, Training Loss: 8.779e-01, Validation Loss: 9.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12097, Training Loss: 8.778e-01, Validation Loss: 9.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12098, Training Loss: 8.777e-01, Validation Loss: 9.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12099, Training Loss: 8.777e-01, Validation Loss: 9.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12100, Training Loss: 8.776e-01, Validation Loss: 9.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12101, Training Loss: 8.775e-01, Validation Loss: 9.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12102, Training Loss: 8.775e-01, Validation Loss: 9.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12103, Training Loss: 8.774e-01, Validation Loss: 9.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12104, Training Loss: 8.773e-01, Validation Loss: 9.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12105, Training Loss: 8.773e-01, Validation Loss: 9.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12106, Training Loss: 8.772e-01, Validation Loss: 9.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12107, Training Loss: 8.771e-01, Validation Loss: 9.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12108, Training Loss: 8.771e-01, Validation Loss: 9.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12109, Training Loss: 8.770e-01, Validation Loss: 9.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12110, Training Loss: 8.770e-01, Validation Loss: 9.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12111, Training Loss: 8.769e-01, Validation Loss: 9.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12112, Training Loss: 8.768e-01, Validation Loss: 9.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12113, Training Loss: 8.768e-01, Validation Loss: 9.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12114, Training Loss: 8.767e-01, Validation Loss: 9.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12115, Training Loss: 8.766e-01, Validation Loss: 9.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12116, Training Loss: 8.766e-01, Validation Loss: 9.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12117, Training Loss: 8.765e-01, Validation Loss: 9.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12118, Training Loss: 8.764e-01, Validation Loss: 9.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12119, Training Loss: 8.764e-01, Validation Loss: 9.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12120, Training Loss: 8.763e-01, Validation Loss: 9.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12121, Training Loss: 8.762e-01, Validation Loss: 9.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12122, Training Loss: 8.762e-01, Validation Loss: 9.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12123, Training Loss: 8.761e-01, Validation Loss: 9.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12124, Training Loss: 8.761e-01, Validation Loss: 9.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12125, Training Loss: 8.760e-01, Validation Loss: 9.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12126, Training Loss: 8.759e-01, Validation Loss: 9.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12127, Training Loss: 8.759e-01, Validation Loss: 9.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12128, Training Loss: 8.758e-01, Validation Loss: 9.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12129, Training Loss: 8.757e-01, Validation Loss: 9.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12130, Training Loss: 8.757e-01, Validation Loss: 9.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12131, Training Loss: 8.756e-01, Validation Loss: 9.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12132, Training Loss: 8.755e-01, Validation Loss: 9.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12133, Training Loss: 8.755e-01, Validation Loss: 9.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12134, Training Loss: 8.754e-01, Validation Loss: 9.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12135, Training Loss: 8.754e-01, Validation Loss: 9.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12136, Training Loss: 8.753e-01, Validation Loss: 9.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12137, Training Loss: 8.752e-01, Validation Loss: 9.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12138, Training Loss: 8.752e-01, Validation Loss: 9.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12139, Training Loss: 8.751e-01, Validation Loss: 9.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12140, Training Loss: 8.750e-01, Validation Loss: 9.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12141, Training Loss: 8.750e-01, Validation Loss: 9.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12142, Training Loss: 8.749e-01, Validation Loss: 9.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12143, Training Loss: 8.748e-01, Validation Loss: 9.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12144, Training Loss: 8.748e-01, Validation Loss: 9.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12145, Training Loss: 8.747e-01, Validation Loss: 9.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12146, Training Loss: 8.747e-01, Validation Loss: 9.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12147, Training Loss: 8.746e-01, Validation Loss: 9.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12148, Training Loss: 8.745e-01, Validation Loss: 9.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12149, Training Loss: 8.745e-01, Validation Loss: 9.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12150, Training Loss: 8.744e-01, Validation Loss: 9.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12151, Training Loss: 8.743e-01, Validation Loss: 9.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12152, Training Loss: 8.743e-01, Validation Loss: 9.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12153, Training Loss: 8.742e-01, Validation Loss: 9.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12154, Training Loss: 8.741e-01, Validation Loss: 9.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12155, Training Loss: 8.741e-01, Validation Loss: 9.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12156, Training Loss: 8.740e-01, Validation Loss: 9.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12157, Training Loss: 8.739e-01, Validation Loss: 9.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12158, Training Loss: 8.739e-01, Validation Loss: 9.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12159, Training Loss: 8.738e-01, Validation Loss: 9.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12160, Training Loss: 8.738e-01, Validation Loss: 9.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12161, Training Loss: 8.737e-01, Validation Loss: 9.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12162, Training Loss: 8.736e-01, Validation Loss: 9.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12163, Training Loss: 8.736e-01, Validation Loss: 9.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12164, Training Loss: 8.735e-01, Validation Loss: 9.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12165, Training Loss: 8.734e-01, Validation Loss: 9.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12166, Training Loss: 8.734e-01, Validation Loss: 9.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12167, Training Loss: 8.733e-01, Validation Loss: 9.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12168, Training Loss: 8.732e-01, Validation Loss: 9.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12169, Training Loss: 8.732e-01, Validation Loss: 9.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12170, Training Loss: 8.731e-01, Validation Loss: 9.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12171, Training Loss: 8.731e-01, Validation Loss: 9.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12172, Training Loss: 8.730e-01, Validation Loss: 9.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12173, Training Loss: 8.729e-01, Validation Loss: 9.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12174, Training Loss: 8.729e-01, Validation Loss: 9.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12175, Training Loss: 8.728e-01, Validation Loss: 9.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12176, Training Loss: 8.727e-01, Validation Loss: 9.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12177, Training Loss: 8.727e-01, Validation Loss: 9.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12178, Training Loss: 8.726e-01, Validation Loss: 9.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12179, Training Loss: 8.725e-01, Validation Loss: 9.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12180, Training Loss: 8.725e-01, Validation Loss: 9.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12181, Training Loss: 8.724e-01, Validation Loss: 9.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12182, Training Loss: 8.724e-01, Validation Loss: 9.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12183, Training Loss: 8.723e-01, Validation Loss: 9.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12184, Training Loss: 8.722e-01, Validation Loss: 9.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12185, Training Loss: 8.722e-01, Validation Loss: 9.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12186, Training Loss: 8.721e-01, Validation Loss: 9.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12187, Training Loss: 8.720e-01, Validation Loss: 9.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12188, Training Loss: 8.720e-01, Validation Loss: 9.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12189, Training Loss: 8.719e-01, Validation Loss: 9.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12190, Training Loss: 8.718e-01, Validation Loss: 9.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12191, Training Loss: 8.718e-01, Validation Loss: 9.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12192, Training Loss: 8.717e-01, Validation Loss: 9.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12193, Training Loss: 8.717e-01, Validation Loss: 9.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12194, Training Loss: 8.716e-01, Validation Loss: 9.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12195, Training Loss: 8.715e-01, Validation Loss: 9.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12196, Training Loss: 8.715e-01, Validation Loss: 9.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12197, Training Loss: 8.714e-01, Validation Loss: 9.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12198, Training Loss: 8.713e-01, Validation Loss: 9.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12199, Training Loss: 8.713e-01, Validation Loss: 9.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12200, Training Loss: 8.712e-01, Validation Loss: 9.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12201, Training Loss: 8.711e-01, Validation Loss: 9.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12202, Training Loss: 8.711e-01, Validation Loss: 9.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12203, Training Loss: 8.710e-01, Validation Loss: 9.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12204, Training Loss: 8.710e-01, Validation Loss: 9.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12205, Training Loss: 8.709e-01, Validation Loss: 9.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12206, Training Loss: 8.708e-01, Validation Loss: 9.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12207, Training Loss: 8.708e-01, Validation Loss: 9.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12208, Training Loss: 8.707e-01, Validation Loss: 9.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12209, Training Loss: 8.706e-01, Validation Loss: 9.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12210, Training Loss: 8.706e-01, Validation Loss: 9.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12211, Training Loss: 8.705e-01, Validation Loss: 9.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12212, Training Loss: 8.705e-01, Validation Loss: 9.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12213, Training Loss: 8.704e-01, Validation Loss: 9.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12214, Training Loss: 8.703e-01, Validation Loss: 9.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12215, Training Loss: 8.703e-01, Validation Loss: 9.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12216, Training Loss: 8.702e-01, Validation Loss: 9.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12217, Training Loss: 8.701e-01, Validation Loss: 9.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12218, Training Loss: 8.701e-01, Validation Loss: 9.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12219, Training Loss: 8.700e-01, Validation Loss: 9.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12220, Training Loss: 8.699e-01, Validation Loss: 9.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12221, Training Loss: 8.699e-01, Validation Loss: 9.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12222, Training Loss: 8.698e-01, Validation Loss: 9.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12223, Training Loss: 8.698e-01, Validation Loss: 9.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12224, Training Loss: 8.697e-01, Validation Loss: 9.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12225, Training Loss: 8.696e-01, Validation Loss: 9.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12226, Training Loss: 8.696e-01, Validation Loss: 9.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12227, Training Loss: 8.695e-01, Validation Loss: 9.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12228, Training Loss: 8.694e-01, Validation Loss: 9.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12229, Training Loss: 8.694e-01, Validation Loss: 9.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12230, Training Loss: 8.693e-01, Validation Loss: 9.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12231, Training Loss: 8.692e-01, Validation Loss: 9.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12232, Training Loss: 8.692e-01, Validation Loss: 9.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12233, Training Loss: 8.691e-01, Validation Loss: 9.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12234, Training Loss: 8.691e-01, Validation Loss: 9.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12235, Training Loss: 8.690e-01, Validation Loss: 9.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12236, Training Loss: 8.689e-01, Validation Loss: 9.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12237, Training Loss: 8.689e-01, Validation Loss: 9.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12238, Training Loss: 8.688e-01, Validation Loss: 9.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12239, Training Loss: 8.687e-01, Validation Loss: 9.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12240, Training Loss: 8.687e-01, Validation Loss: 9.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12241, Training Loss: 8.686e-01, Validation Loss: 9.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12242, Training Loss: 8.686e-01, Validation Loss: 9.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12243, Training Loss: 8.685e-01, Validation Loss: 9.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12244, Training Loss: 8.684e-01, Validation Loss: 9.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12245, Training Loss: 8.684e-01, Validation Loss: 9.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12246, Training Loss: 8.683e-01, Validation Loss: 9.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12247, Training Loss: 8.682e-01, Validation Loss: 9.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12248, Training Loss: 8.682e-01, Validation Loss: 9.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12249, Training Loss: 8.681e-01, Validation Loss: 9.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12250, Training Loss: 8.681e-01, Validation Loss: 9.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12251, Training Loss: 8.680e-01, Validation Loss: 9.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12252, Training Loss: 8.679e-01, Validation Loss: 9.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12253, Training Loss: 8.679e-01, Validation Loss: 9.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12254, Training Loss: 8.678e-01, Validation Loss: 9.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12255, Training Loss: 8.677e-01, Validation Loss: 9.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12256, Training Loss: 8.677e-01, Validation Loss: 9.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12257, Training Loss: 8.676e-01, Validation Loss: 9.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12258, Training Loss: 8.675e-01, Validation Loss: 9.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12259, Training Loss: 8.675e-01, Validation Loss: 9.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12260, Training Loss: 8.674e-01, Validation Loss: 9.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12261, Training Loss: 8.674e-01, Validation Loss: 9.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12262, Training Loss: 8.673e-01, Validation Loss: 9.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12263, Training Loss: 8.672e-01, Validation Loss: 9.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12264, Training Loss: 8.672e-01, Validation Loss: 9.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12265, Training Loss: 8.671e-01, Validation Loss: 9.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12266, Training Loss: 8.670e-01, Validation Loss: 9.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12267, Training Loss: 8.670e-01, Validation Loss: 9.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12268, Training Loss: 8.669e-01, Validation Loss: 9.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12269, Training Loss: 8.669e-01, Validation Loss: 9.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12270, Training Loss: 8.668e-01, Validation Loss: 9.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12271, Training Loss: 8.667e-01, Validation Loss: 9.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12272, Training Loss: 8.667e-01, Validation Loss: 9.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12273, Training Loss: 8.666e-01, Validation Loss: 9.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12274, Training Loss: 8.665e-01, Validation Loss: 9.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12275, Training Loss: 8.665e-01, Validation Loss: 9.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12276, Training Loss: 8.664e-01, Validation Loss: 9.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12277, Training Loss: 8.663e-01, Validation Loss: 9.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12278, Training Loss: 8.663e-01, Validation Loss: 9.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12279, Training Loss: 8.662e-01, Validation Loss: 9.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12280, Training Loss: 8.662e-01, Validation Loss: 9.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12281, Training Loss: 8.661e-01, Validation Loss: 9.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12282, Training Loss: 8.660e-01, Validation Loss: 9.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12283, Training Loss: 8.660e-01, Validation Loss: 9.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12284, Training Loss: 8.659e-01, Validation Loss: 9.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12285, Training Loss: 8.658e-01, Validation Loss: 9.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12286, Training Loss: 8.658e-01, Validation Loss: 9.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12287, Training Loss: 8.657e-01, Validation Loss: 9.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12288, Training Loss: 8.657e-01, Validation Loss: 9.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12289, Training Loss: 8.656e-01, Validation Loss: 9.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12290, Training Loss: 8.655e-01, Validation Loss: 9.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12291, Training Loss: 8.655e-01, Validation Loss: 9.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12292, Training Loss: 8.654e-01, Validation Loss: 9.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12293, Training Loss: 8.653e-01, Validation Loss: 9.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12294, Training Loss: 8.653e-01, Validation Loss: 9.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12295, Training Loss: 8.652e-01, Validation Loss: 9.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12296, Training Loss: 8.652e-01, Validation Loss: 9.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12297, Training Loss: 8.651e-01, Validation Loss: 9.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12298, Training Loss: 8.650e-01, Validation Loss: 9.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12299, Training Loss: 8.650e-01, Validation Loss: 9.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12300, Training Loss: 8.649e-01, Validation Loss: 9.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12301, Training Loss: 8.648e-01, Validation Loss: 9.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12302, Training Loss: 8.648e-01, Validation Loss: 9.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12303, Training Loss: 8.647e-01, Validation Loss: 9.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12304, Training Loss: 8.647e-01, Validation Loss: 9.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12305, Training Loss: 8.646e-01, Validation Loss: 9.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12306, Training Loss: 8.645e-01, Validation Loss: 9.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12307, Training Loss: 8.645e-01, Validation Loss: 9.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12308, Training Loss: 8.644e-01, Validation Loss: 9.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12309, Training Loss: 8.643e-01, Validation Loss: 9.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12310, Training Loss: 8.643e-01, Validation Loss: 9.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12311, Training Loss: 8.642e-01, Validation Loss: 9.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12312, Training Loss: 8.642e-01, Validation Loss: 9.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12313, Training Loss: 8.641e-01, Validation Loss: 9.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12314, Training Loss: 8.640e-01, Validation Loss: 9.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12315, Training Loss: 8.640e-01, Validation Loss: 9.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12316, Training Loss: 8.639e-01, Validation Loss: 9.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12317, Training Loss: 8.638e-01, Validation Loss: 9.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12318, Training Loss: 8.638e-01, Validation Loss: 9.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12319, Training Loss: 8.637e-01, Validation Loss: 9.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12320, Training Loss: 8.637e-01, Validation Loss: 9.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12321, Training Loss: 8.636e-01, Validation Loss: 9.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12322, Training Loss: 8.635e-01, Validation Loss: 9.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12323, Training Loss: 8.635e-01, Validation Loss: 9.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12324, Training Loss: 8.634e-01, Validation Loss: 9.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12325, Training Loss: 8.633e-01, Validation Loss: 9.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12326, Training Loss: 8.633e-01, Validation Loss: 9.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12327, Training Loss: 8.632e-01, Validation Loss: 9.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12328, Training Loss: 8.632e-01, Validation Loss: 9.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12329, Training Loss: 8.631e-01, Validation Loss: 9.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12330, Training Loss: 8.630e-01, Validation Loss: 9.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12331, Training Loss: 8.630e-01, Validation Loss: 9.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12332, Training Loss: 8.629e-01, Validation Loss: 9.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12333, Training Loss: 8.628e-01, Validation Loss: 9.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12334, Training Loss: 8.628e-01, Validation Loss: 9.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12335, Training Loss: 8.627e-01, Validation Loss: 9.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12336, Training Loss: 8.627e-01, Validation Loss: 9.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12337, Training Loss: 8.626e-01, Validation Loss: 9.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12338, Training Loss: 8.625e-01, Validation Loss: 9.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12339, Training Loss: 8.625e-01, Validation Loss: 9.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12340, Training Loss: 8.624e-01, Validation Loss: 9.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12341, Training Loss: 8.623e-01, Validation Loss: 9.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12342, Training Loss: 8.623e-01, Validation Loss: 9.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12343, Training Loss: 8.622e-01, Validation Loss: 9.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12344, Training Loss: 8.622e-01, Validation Loss: 9.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12345, Training Loss: 8.621e-01, Validation Loss: 9.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12346, Training Loss: 8.620e-01, Validation Loss: 9.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12347, Training Loss: 8.620e-01, Validation Loss: 9.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12348, Training Loss: 8.619e-01, Validation Loss: 9.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12349, Training Loss: 8.618e-01, Validation Loss: 9.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12350, Training Loss: 8.618e-01, Validation Loss: 9.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12351, Training Loss: 8.617e-01, Validation Loss: 9.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12352, Training Loss: 8.617e-01, Validation Loss: 9.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12353, Training Loss: 8.616e-01, Validation Loss: 9.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12354, Training Loss: 8.615e-01, Validation Loss: 9.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12355, Training Loss: 8.615e-01, Validation Loss: 9.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12356, Training Loss: 8.614e-01, Validation Loss: 9.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12357, Training Loss: 8.613e-01, Validation Loss: 9.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12358, Training Loss: 8.613e-01, Validation Loss: 9.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12359, Training Loss: 8.612e-01, Validation Loss: 9.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12360, Training Loss: 8.612e-01, Validation Loss: 9.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12361, Training Loss: 8.611e-01, Validation Loss: 9.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12362, Training Loss: 8.610e-01, Validation Loss: 9.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12363, Training Loss: 8.610e-01, Validation Loss: 9.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12364, Training Loss: 8.609e-01, Validation Loss: 9.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12365, Training Loss: 8.608e-01, Validation Loss: 9.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12366, Training Loss: 8.608e-01, Validation Loss: 9.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12367, Training Loss: 8.607e-01, Validation Loss: 9.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12368, Training Loss: 8.607e-01, Validation Loss: 9.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12369, Training Loss: 8.606e-01, Validation Loss: 9.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12370, Training Loss: 8.605e-01, Validation Loss: 9.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12371, Training Loss: 8.605e-01, Validation Loss: 9.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12372, Training Loss: 8.604e-01, Validation Loss: 9.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12373, Training Loss: 8.604e-01, Validation Loss: 9.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12374, Training Loss: 8.603e-01, Validation Loss: 9.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12375, Training Loss: 8.602e-01, Validation Loss: 9.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12376, Training Loss: 8.602e-01, Validation Loss: 9.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12377, Training Loss: 8.601e-01, Validation Loss: 9.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12378, Training Loss: 8.600e-01, Validation Loss: 9.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12379, Training Loss: 8.600e-01, Validation Loss: 9.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12380, Training Loss: 8.599e-01, Validation Loss: 9.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12381, Training Loss: 8.599e-01, Validation Loss: 9.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12382, Training Loss: 8.598e-01, Validation Loss: 9.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12383, Training Loss: 8.597e-01, Validation Loss: 9.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12384, Training Loss: 8.597e-01, Validation Loss: 9.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12385, Training Loss: 8.596e-01, Validation Loss: 9.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12386, Training Loss: 8.595e-01, Validation Loss: 9.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12387, Training Loss: 8.595e-01, Validation Loss: 9.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12388, Training Loss: 8.594e-01, Validation Loss: 9.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12389, Training Loss: 8.594e-01, Validation Loss: 9.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12390, Training Loss: 8.593e-01, Validation Loss: 9.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12391, Training Loss: 8.592e-01, Validation Loss: 9.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12392, Training Loss: 8.592e-01, Validation Loss: 9.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12393, Training Loss: 8.591e-01, Validation Loss: 9.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12394, Training Loss: 8.590e-01, Validation Loss: 9.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12395, Training Loss: 8.590e-01, Validation Loss: 9.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12396, Training Loss: 8.589e-01, Validation Loss: 9.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12397, Training Loss: 8.589e-01, Validation Loss: 9.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12398, Training Loss: 8.588e-01, Validation Loss: 9.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12399, Training Loss: 8.587e-01, Validation Loss: 9.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12400, Training Loss: 8.587e-01, Validation Loss: 9.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12401, Training Loss: 8.586e-01, Validation Loss: 9.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12402, Training Loss: 8.586e-01, Validation Loss: 9.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12403, Training Loss: 8.585e-01, Validation Loss: 9.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12404, Training Loss: 8.584e-01, Validation Loss: 9.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12405, Training Loss: 8.584e-01, Validation Loss: 9.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12406, Training Loss: 8.583e-01, Validation Loss: 9.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12407, Training Loss: 8.582e-01, Validation Loss: 9.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12408, Training Loss: 8.582e-01, Validation Loss: 9.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12409, Training Loss: 8.581e-01, Validation Loss: 9.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12410, Training Loss: 8.581e-01, Validation Loss: 9.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12411, Training Loss: 8.580e-01, Validation Loss: 9.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12412, Training Loss: 8.579e-01, Validation Loss: 9.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12413, Training Loss: 8.579e-01, Validation Loss: 9.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12414, Training Loss: 8.578e-01, Validation Loss: 9.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12415, Training Loss: 8.577e-01, Validation Loss: 9.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12416, Training Loss: 8.577e-01, Validation Loss: 9.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12417, Training Loss: 8.576e-01, Validation Loss: 9.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12418, Training Loss: 8.576e-01, Validation Loss: 9.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12419, Training Loss: 8.575e-01, Validation Loss: 9.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12420, Training Loss: 8.574e-01, Validation Loss: 9.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12421, Training Loss: 8.574e-01, Validation Loss: 9.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12422, Training Loss: 8.573e-01, Validation Loss: 9.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12423, Training Loss: 8.573e-01, Validation Loss: 9.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12424, Training Loss: 8.572e-01, Validation Loss: 9.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12425, Training Loss: 8.571e-01, Validation Loss: 9.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12426, Training Loss: 8.571e-01, Validation Loss: 9.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12427, Training Loss: 8.570e-01, Validation Loss: 9.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12428, Training Loss: 8.569e-01, Validation Loss: 9.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12429, Training Loss: 8.569e-01, Validation Loss: 9.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12430, Training Loss: 8.568e-01, Validation Loss: 9.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12431, Training Loss: 8.568e-01, Validation Loss: 9.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12432, Training Loss: 8.567e-01, Validation Loss: 9.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12433, Training Loss: 8.566e-01, Validation Loss: 9.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12434, Training Loss: 8.566e-01, Validation Loss: 9.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12435, Training Loss: 8.565e-01, Validation Loss: 9.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12436, Training Loss: 8.565e-01, Validation Loss: 9.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12437, Training Loss: 8.564e-01, Validation Loss: 9.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12438, Training Loss: 8.563e-01, Validation Loss: 9.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12439, Training Loss: 8.563e-01, Validation Loss: 9.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12440, Training Loss: 8.562e-01, Validation Loss: 9.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12441, Training Loss: 8.561e-01, Validation Loss: 9.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12442, Training Loss: 8.561e-01, Validation Loss: 9.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12443, Training Loss: 8.560e-01, Validation Loss: 9.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12444, Training Loss: 8.560e-01, Validation Loss: 9.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12445, Training Loss: 8.559e-01, Validation Loss: 9.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12446, Training Loss: 8.558e-01, Validation Loss: 9.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12447, Training Loss: 8.558e-01, Validation Loss: 9.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12448, Training Loss: 8.557e-01, Validation Loss: 9.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12449, Training Loss: 8.557e-01, Validation Loss: 9.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12450, Training Loss: 8.556e-01, Validation Loss: 9.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12451, Training Loss: 8.555e-01, Validation Loss: 9.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12452, Training Loss: 8.555e-01, Validation Loss: 9.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12453, Training Loss: 8.554e-01, Validation Loss: 9.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12454, Training Loss: 8.553e-01, Validation Loss: 9.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12455, Training Loss: 8.553e-01, Validation Loss: 9.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12456, Training Loss: 8.552e-01, Validation Loss: 9.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12457, Training Loss: 8.552e-01, Validation Loss: 9.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12458, Training Loss: 8.551e-01, Validation Loss: 9.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12459, Training Loss: 8.550e-01, Validation Loss: 9.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12460, Training Loss: 8.550e-01, Validation Loss: 9.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12461, Training Loss: 8.549e-01, Validation Loss: 9.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12462, Training Loss: 8.549e-01, Validation Loss: 9.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12463, Training Loss: 8.548e-01, Validation Loss: 9.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12464, Training Loss: 8.547e-01, Validation Loss: 9.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12465, Training Loss: 8.547e-01, Validation Loss: 9.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12466, Training Loss: 8.546e-01, Validation Loss: 9.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12467, Training Loss: 8.545e-01, Validation Loss: 9.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12468, Training Loss: 8.545e-01, Validation Loss: 9.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12469, Training Loss: 8.544e-01, Validation Loss: 9.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12470, Training Loss: 8.544e-01, Validation Loss: 9.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12471, Training Loss: 8.543e-01, Validation Loss: 9.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12472, Training Loss: 8.542e-01, Validation Loss: 9.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12473, Training Loss: 8.542e-01, Validation Loss: 9.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12474, Training Loss: 8.541e-01, Validation Loss: 9.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12475, Training Loss: 8.541e-01, Validation Loss: 9.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12476, Training Loss: 8.540e-01, Validation Loss: 9.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12477, Training Loss: 8.539e-01, Validation Loss: 9.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12478, Training Loss: 8.539e-01, Validation Loss: 9.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12479, Training Loss: 8.538e-01, Validation Loss: 9.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12480, Training Loss: 8.537e-01, Validation Loss: 9.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12481, Training Loss: 8.537e-01, Validation Loss: 9.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12482, Training Loss: 8.536e-01, Validation Loss: 9.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12483, Training Loss: 8.536e-01, Validation Loss: 9.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12484, Training Loss: 8.535e-01, Validation Loss: 9.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12485, Training Loss: 8.534e-01, Validation Loss: 9.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12486, Training Loss: 8.534e-01, Validation Loss: 9.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12487, Training Loss: 8.533e-01, Validation Loss: 9.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12488, Training Loss: 8.533e-01, Validation Loss: 9.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12489, Training Loss: 8.532e-01, Validation Loss: 9.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12490, Training Loss: 8.531e-01, Validation Loss: 9.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12491, Training Loss: 8.531e-01, Validation Loss: 9.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12492, Training Loss: 8.530e-01, Validation Loss: 9.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12493, Training Loss: 8.530e-01, Validation Loss: 9.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12494, Training Loss: 8.529e-01, Validation Loss: 9.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12495, Training Loss: 8.528e-01, Validation Loss: 9.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12496, Training Loss: 8.528e-01, Validation Loss: 9.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12497, Training Loss: 8.527e-01, Validation Loss: 9.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12498, Training Loss: 8.526e-01, Validation Loss: 9.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12499, Training Loss: 8.526e-01, Validation Loss: 9.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12500, Training Loss: 8.525e-01, Validation Loss: 9.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12501, Training Loss: 8.525e-01, Validation Loss: 9.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12502, Training Loss: 8.524e-01, Validation Loss: 9.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12503, Training Loss: 8.523e-01, Validation Loss: 9.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12504, Training Loss: 8.523e-01, Validation Loss: 9.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12505, Training Loss: 8.522e-01, Validation Loss: 9.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12506, Training Loss: 8.522e-01, Validation Loss: 9.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12507, Training Loss: 8.521e-01, Validation Loss: 9.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12508, Training Loss: 8.520e-01, Validation Loss: 9.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12509, Training Loss: 8.520e-01, Validation Loss: 9.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12510, Training Loss: 8.519e-01, Validation Loss: 9.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12511, Training Loss: 8.519e-01, Validation Loss: 9.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12512, Training Loss: 8.518e-01, Validation Loss: 9.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12513, Training Loss: 8.517e-01, Validation Loss: 9.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12514, Training Loss: 8.517e-01, Validation Loss: 9.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12515, Training Loss: 8.516e-01, Validation Loss: 9.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12516, Training Loss: 8.515e-01, Validation Loss: 9.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12517, Training Loss: 8.515e-01, Validation Loss: 9.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12518, Training Loss: 8.514e-01, Validation Loss: 9.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12519, Training Loss: 8.514e-01, Validation Loss: 9.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12520, Training Loss: 8.513e-01, Validation Loss: 9.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12521, Training Loss: 8.512e-01, Validation Loss: 9.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12522, Training Loss: 8.512e-01, Validation Loss: 9.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12523, Training Loss: 8.511e-01, Validation Loss: 9.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12524, Training Loss: 8.511e-01, Validation Loss: 9.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12525, Training Loss: 8.510e-01, Validation Loss: 9.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12526, Training Loss: 8.509e-01, Validation Loss: 9.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12527, Training Loss: 8.509e-01, Validation Loss: 9.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12528, Training Loss: 8.508e-01, Validation Loss: 9.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12529, Training Loss: 8.508e-01, Validation Loss: 9.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12530, Training Loss: 8.507e-01, Validation Loss: 9.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12531, Training Loss: 8.506e-01, Validation Loss: 9.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12532, Training Loss: 8.506e-01, Validation Loss: 9.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12533, Training Loss: 8.505e-01, Validation Loss: 9.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12534, Training Loss: 8.504e-01, Validation Loss: 9.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12535, Training Loss: 8.504e-01, Validation Loss: 9.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12536, Training Loss: 8.503e-01, Validation Loss: 9.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12537, Training Loss: 8.503e-01, Validation Loss: 9.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12538, Training Loss: 8.502e-01, Validation Loss: 9.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12539, Training Loss: 8.501e-01, Validation Loss: 9.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12540, Training Loss: 8.501e-01, Validation Loss: 9.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12541, Training Loss: 8.500e-01, Validation Loss: 9.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12542, Training Loss: 8.500e-01, Validation Loss: 9.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12543, Training Loss: 8.499e-01, Validation Loss: 9.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12544, Training Loss: 8.498e-01, Validation Loss: 9.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12545, Training Loss: 8.498e-01, Validation Loss: 9.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12546, Training Loss: 8.497e-01, Validation Loss: 9.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12547, Training Loss: 8.497e-01, Validation Loss: 9.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12548, Training Loss: 8.496e-01, Validation Loss: 9.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12549, Training Loss: 8.495e-01, Validation Loss: 9.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12550, Training Loss: 8.495e-01, Validation Loss: 9.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12551, Training Loss: 8.494e-01, Validation Loss: 9.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12552, Training Loss: 8.494e-01, Validation Loss: 9.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12553, Training Loss: 8.493e-01, Validation Loss: 9.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12554, Training Loss: 8.492e-01, Validation Loss: 9.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12555, Training Loss: 8.492e-01, Validation Loss: 9.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12556, Training Loss: 8.491e-01, Validation Loss: 9.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12557, Training Loss: 8.490e-01, Validation Loss: 9.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12558, Training Loss: 8.490e-01, Validation Loss: 9.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12559, Training Loss: 8.489e-01, Validation Loss: 9.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12560, Training Loss: 8.489e-01, Validation Loss: 9.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12561, Training Loss: 8.488e-01, Validation Loss: 9.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12562, Training Loss: 8.487e-01, Validation Loss: 9.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12563, Training Loss: 8.487e-01, Validation Loss: 9.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12564, Training Loss: 8.486e-01, Validation Loss: 9.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12565, Training Loss: 8.486e-01, Validation Loss: 9.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12566, Training Loss: 8.485e-01, Validation Loss: 9.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12567, Training Loss: 8.484e-01, Validation Loss: 9.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12568, Training Loss: 8.484e-01, Validation Loss: 9.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12569, Training Loss: 8.483e-01, Validation Loss: 9.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12570, Training Loss: 8.483e-01, Validation Loss: 9.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12571, Training Loss: 8.482e-01, Validation Loss: 9.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12572, Training Loss: 8.481e-01, Validation Loss: 9.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12573, Training Loss: 8.481e-01, Validation Loss: 9.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12574, Training Loss: 8.480e-01, Validation Loss: 9.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12575, Training Loss: 8.480e-01, Validation Loss: 9.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12576, Training Loss: 8.479e-01, Validation Loss: 9.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12577, Training Loss: 8.478e-01, Validation Loss: 9.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12578, Training Loss: 8.478e-01, Validation Loss: 9.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12579, Training Loss: 8.477e-01, Validation Loss: 9.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12580, Training Loss: 8.477e-01, Validation Loss: 9.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12581, Training Loss: 8.476e-01, Validation Loss: 9.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12582, Training Loss: 8.475e-01, Validation Loss: 9.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12583, Training Loss: 8.475e-01, Validation Loss: 9.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12584, Training Loss: 8.474e-01, Validation Loss: 9.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12585, Training Loss: 8.473e-01, Validation Loss: 9.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12586, Training Loss: 8.473e-01, Validation Loss: 9.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12587, Training Loss: 8.472e-01, Validation Loss: 9.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12588, Training Loss: 8.472e-01, Validation Loss: 9.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12589, Training Loss: 8.471e-01, Validation Loss: 9.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12590, Training Loss: 8.470e-01, Validation Loss: 9.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12591, Training Loss: 8.470e-01, Validation Loss: 9.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12592, Training Loss: 8.469e-01, Validation Loss: 9.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12593, Training Loss: 8.469e-01, Validation Loss: 9.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12594, Training Loss: 8.468e-01, Validation Loss: 9.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12595, Training Loss: 8.467e-01, Validation Loss: 9.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12596, Training Loss: 8.467e-01, Validation Loss: 9.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12597, Training Loss: 8.466e-01, Validation Loss: 9.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12598, Training Loss: 8.466e-01, Validation Loss: 9.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12599, Training Loss: 8.465e-01, Validation Loss: 9.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12600, Training Loss: 8.464e-01, Validation Loss: 9.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12601, Training Loss: 8.464e-01, Validation Loss: 9.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12602, Training Loss: 8.463e-01, Validation Loss: 9.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12603, Training Loss: 8.463e-01, Validation Loss: 9.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12604, Training Loss: 8.462e-01, Validation Loss: 9.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12605, Training Loss: 8.461e-01, Validation Loss: 9.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12606, Training Loss: 8.461e-01, Validation Loss: 9.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12607, Training Loss: 8.460e-01, Validation Loss: 9.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12608, Training Loss: 8.460e-01, Validation Loss: 9.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12609, Training Loss: 8.459e-01, Validation Loss: 9.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12610, Training Loss: 8.458e-01, Validation Loss: 9.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12611, Training Loss: 8.458e-01, Validation Loss: 9.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12612, Training Loss: 8.457e-01, Validation Loss: 9.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12613, Training Loss: 8.457e-01, Validation Loss: 9.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12614, Training Loss: 8.456e-01, Validation Loss: 9.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12615, Training Loss: 8.455e-01, Validation Loss: 9.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12616, Training Loss: 8.455e-01, Validation Loss: 9.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12617, Training Loss: 8.454e-01, Validation Loss: 9.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12618, Training Loss: 8.454e-01, Validation Loss: 9.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12619, Training Loss: 8.453e-01, Validation Loss: 9.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12620, Training Loss: 8.452e-01, Validation Loss: 9.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12621, Training Loss: 8.452e-01, Validation Loss: 9.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12622, Training Loss: 8.451e-01, Validation Loss: 9.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12623, Training Loss: 8.451e-01, Validation Loss: 9.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12624, Training Loss: 8.450e-01, Validation Loss: 9.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12625, Training Loss: 8.449e-01, Validation Loss: 9.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12626, Training Loss: 8.449e-01, Validation Loss: 9.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12627, Training Loss: 8.448e-01, Validation Loss: 9.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12628, Training Loss: 8.448e-01, Validation Loss: 9.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12629, Training Loss: 8.447e-01, Validation Loss: 9.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12630, Training Loss: 8.446e-01, Validation Loss: 9.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12631, Training Loss: 8.446e-01, Validation Loss: 9.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12632, Training Loss: 8.445e-01, Validation Loss: 9.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12633, Training Loss: 8.445e-01, Validation Loss: 9.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12634, Training Loss: 8.444e-01, Validation Loss: 9.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12635, Training Loss: 8.443e-01, Validation Loss: 9.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12636, Training Loss: 8.443e-01, Validation Loss: 9.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12637, Training Loss: 8.442e-01, Validation Loss: 9.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12638, Training Loss: 8.442e-01, Validation Loss: 9.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12639, Training Loss: 8.441e-01, Validation Loss: 9.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12640, Training Loss: 8.440e-01, Validation Loss: 9.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12641, Training Loss: 8.440e-01, Validation Loss: 9.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12642, Training Loss: 8.439e-01, Validation Loss: 9.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12643, Training Loss: 8.438e-01, Validation Loss: 9.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12644, Training Loss: 8.438e-01, Validation Loss: 9.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12645, Training Loss: 8.437e-01, Validation Loss: 9.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12646, Training Loss: 8.437e-01, Validation Loss: 9.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12647, Training Loss: 8.436e-01, Validation Loss: 9.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12648, Training Loss: 8.435e-01, Validation Loss: 9.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12649, Training Loss: 8.435e-01, Validation Loss: 9.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12650, Training Loss: 8.434e-01, Validation Loss: 9.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12651, Training Loss: 8.434e-01, Validation Loss: 9.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12652, Training Loss: 8.433e-01, Validation Loss: 9.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12653, Training Loss: 8.432e-01, Validation Loss: 9.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12654, Training Loss: 8.432e-01, Validation Loss: 9.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12655, Training Loss: 8.431e-01, Validation Loss: 9.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12656, Training Loss: 8.431e-01, Validation Loss: 9.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12657, Training Loss: 8.430e-01, Validation Loss: 9.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12658, Training Loss: 8.429e-01, Validation Loss: 9.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12659, Training Loss: 8.429e-01, Validation Loss: 9.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12660, Training Loss: 8.428e-01, Validation Loss: 9.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12661, Training Loss: 8.428e-01, Validation Loss: 9.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12662, Training Loss: 8.427e-01, Validation Loss: 9.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12663, Training Loss: 8.426e-01, Validation Loss: 9.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12664, Training Loss: 8.426e-01, Validation Loss: 9.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12665, Training Loss: 8.425e-01, Validation Loss: 9.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12666, Training Loss: 8.425e-01, Validation Loss: 9.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12667, Training Loss: 8.424e-01, Validation Loss: 9.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12668, Training Loss: 8.423e-01, Validation Loss: 9.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12669, Training Loss: 8.423e-01, Validation Loss: 9.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12670, Training Loss: 8.422e-01, Validation Loss: 9.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12671, Training Loss: 8.422e-01, Validation Loss: 9.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12672, Training Loss: 8.421e-01, Validation Loss: 9.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12673, Training Loss: 8.420e-01, Validation Loss: 9.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12674, Training Loss: 8.420e-01, Validation Loss: 9.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12675, Training Loss: 8.419e-01, Validation Loss: 9.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12676, Training Loss: 8.419e-01, Validation Loss: 9.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12677, Training Loss: 8.418e-01, Validation Loss: 9.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12678, Training Loss: 8.417e-01, Validation Loss: 9.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12679, Training Loss: 8.417e-01, Validation Loss: 9.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12680, Training Loss: 8.416e-01, Validation Loss: 9.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12681, Training Loss: 8.416e-01, Validation Loss: 9.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12682, Training Loss: 8.415e-01, Validation Loss: 9.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12683, Training Loss: 8.414e-01, Validation Loss: 9.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12684, Training Loss: 8.414e-01, Validation Loss: 9.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12685, Training Loss: 8.413e-01, Validation Loss: 9.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12686, Training Loss: 8.413e-01, Validation Loss: 9.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12687, Training Loss: 8.412e-01, Validation Loss: 9.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12688, Training Loss: 8.412e-01, Validation Loss: 9.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12689, Training Loss: 8.411e-01, Validation Loss: 9.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12690, Training Loss: 8.410e-01, Validation Loss: 9.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12691, Training Loss: 8.410e-01, Validation Loss: 9.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12692, Training Loss: 8.409e-01, Validation Loss: 9.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12693, Training Loss: 8.409e-01, Validation Loss: 9.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12694, Training Loss: 8.408e-01, Validation Loss: 9.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12695, Training Loss: 8.407e-01, Validation Loss: 9.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12696, Training Loss: 8.407e-01, Validation Loss: 9.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12697, Training Loss: 8.406e-01, Validation Loss: 9.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12698, Training Loss: 8.406e-01, Validation Loss: 9.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12699, Training Loss: 8.405e-01, Validation Loss: 9.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12700, Training Loss: 8.404e-01, Validation Loss: 9.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12701, Training Loss: 8.404e-01, Validation Loss: 9.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12702, Training Loss: 8.403e-01, Validation Loss: 9.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12703, Training Loss: 8.403e-01, Validation Loss: 9.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12704, Training Loss: 8.402e-01, Validation Loss: 9.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12705, Training Loss: 8.401e-01, Validation Loss: 9.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12706, Training Loss: 8.401e-01, Validation Loss: 9.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12707, Training Loss: 8.400e-01, Validation Loss: 9.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12708, Training Loss: 8.400e-01, Validation Loss: 9.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12709, Training Loss: 8.399e-01, Validation Loss: 9.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12710, Training Loss: 8.398e-01, Validation Loss: 9.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12711, Training Loss: 8.398e-01, Validation Loss: 9.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12712, Training Loss: 8.397e-01, Validation Loss: 9.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12713, Training Loss: 8.397e-01, Validation Loss: 9.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12714, Training Loss: 8.396e-01, Validation Loss: 9.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12715, Training Loss: 8.395e-01, Validation Loss: 9.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12716, Training Loss: 8.395e-01, Validation Loss: 9.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12717, Training Loss: 8.394e-01, Validation Loss: 9.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12718, Training Loss: 8.394e-01, Validation Loss: 9.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12719, Training Loss: 8.393e-01, Validation Loss: 9.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12720, Training Loss: 8.392e-01, Validation Loss: 9.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12721, Training Loss: 8.392e-01, Validation Loss: 9.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12722, Training Loss: 8.391e-01, Validation Loss: 9.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12723, Training Loss: 8.391e-01, Validation Loss: 9.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12724, Training Loss: 8.390e-01, Validation Loss: 9.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12725, Training Loss: 8.389e-01, Validation Loss: 9.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12726, Training Loss: 8.389e-01, Validation Loss: 9.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12727, Training Loss: 8.388e-01, Validation Loss: 9.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12728, Training Loss: 8.388e-01, Validation Loss: 9.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12729, Training Loss: 8.387e-01, Validation Loss: 9.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12730, Training Loss: 8.386e-01, Validation Loss: 9.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12731, Training Loss: 8.386e-01, Validation Loss: 9.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12732, Training Loss: 8.385e-01, Validation Loss: 9.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12733, Training Loss: 8.385e-01, Validation Loss: 9.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12734, Training Loss: 8.384e-01, Validation Loss: 9.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12735, Training Loss: 8.383e-01, Validation Loss: 9.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12736, Training Loss: 8.383e-01, Validation Loss: 9.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12737, Training Loss: 8.382e-01, Validation Loss: 9.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12738, Training Loss: 8.382e-01, Validation Loss: 9.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12739, Training Loss: 8.381e-01, Validation Loss: 9.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12740, Training Loss: 8.380e-01, Validation Loss: 9.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12741, Training Loss: 8.380e-01, Validation Loss: 9.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12742, Training Loss: 8.379e-01, Validation Loss: 9.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12743, Training Loss: 8.379e-01, Validation Loss: 9.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12744, Training Loss: 8.378e-01, Validation Loss: 9.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12745, Training Loss: 8.377e-01, Validation Loss: 9.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12746, Training Loss: 8.377e-01, Validation Loss: 9.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12747, Training Loss: 8.376e-01, Validation Loss: 9.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12748, Training Loss: 8.376e-01, Validation Loss: 9.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12749, Training Loss: 8.375e-01, Validation Loss: 9.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12750, Training Loss: 8.374e-01, Validation Loss: 9.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12751, Training Loss: 8.374e-01, Validation Loss: 9.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12752, Training Loss: 8.373e-01, Validation Loss: 9.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12753, Training Loss: 8.373e-01, Validation Loss: 9.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12754, Training Loss: 8.372e-01, Validation Loss: 9.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12755, Training Loss: 8.371e-01, Validation Loss: 9.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12756, Training Loss: 8.371e-01, Validation Loss: 9.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12757, Training Loss: 8.370e-01, Validation Loss: 9.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12758, Training Loss: 8.370e-01, Validation Loss: 9.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12759, Training Loss: 8.369e-01, Validation Loss: 9.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12760, Training Loss: 8.369e-01, Validation Loss: 9.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12761, Training Loss: 8.368e-01, Validation Loss: 9.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12762, Training Loss: 8.367e-01, Validation Loss: 9.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12763, Training Loss: 8.367e-01, Validation Loss: 9.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12764, Training Loss: 8.366e-01, Validation Loss: 9.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12765, Training Loss: 8.366e-01, Validation Loss: 9.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12766, Training Loss: 8.365e-01, Validation Loss: 9.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12767, Training Loss: 8.364e-01, Validation Loss: 9.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12768, Training Loss: 8.364e-01, Validation Loss: 9.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12769, Training Loss: 8.363e-01, Validation Loss: 9.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12770, Training Loss: 8.363e-01, Validation Loss: 9.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12771, Training Loss: 8.362e-01, Validation Loss: 9.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12772, Training Loss: 8.361e-01, Validation Loss: 9.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12773, Training Loss: 8.361e-01, Validation Loss: 9.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12774, Training Loss: 8.360e-01, Validation Loss: 9.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12775, Training Loss: 8.360e-01, Validation Loss: 9.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12776, Training Loss: 8.359e-01, Validation Loss: 9.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12777, Training Loss: 8.358e-01, Validation Loss: 9.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12778, Training Loss: 8.358e-01, Validation Loss: 9.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12779, Training Loss: 8.357e-01, Validation Loss: 9.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12780, Training Loss: 8.357e-01, Validation Loss: 9.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12781, Training Loss: 8.356e-01, Validation Loss: 9.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12782, Training Loss: 8.355e-01, Validation Loss: 9.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12783, Training Loss: 8.355e-01, Validation Loss: 9.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12784, Training Loss: 8.354e-01, Validation Loss: 9.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12785, Training Loss: 8.354e-01, Validation Loss: 9.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12786, Training Loss: 8.353e-01, Validation Loss: 9.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12787, Training Loss: 8.352e-01, Validation Loss: 9.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12788, Training Loss: 8.352e-01, Validation Loss: 9.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12789, Training Loss: 8.351e-01, Validation Loss: 9.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12790, Training Loss: 8.351e-01, Validation Loss: 9.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12791, Training Loss: 8.350e-01, Validation Loss: 9.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12792, Training Loss: 8.349e-01, Validation Loss: 9.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12793, Training Loss: 8.349e-01, Validation Loss: 9.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12794, Training Loss: 8.348e-01, Validation Loss: 9.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12795, Training Loss: 8.348e-01, Validation Loss: 9.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12796, Training Loss: 8.347e-01, Validation Loss: 9.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12797, Training Loss: 8.346e-01, Validation Loss: 9.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12798, Training Loss: 8.346e-01, Validation Loss: 9.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12799, Training Loss: 8.345e-01, Validation Loss: 9.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12800, Training Loss: 8.345e-01, Validation Loss: 9.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12801, Training Loss: 8.344e-01, Validation Loss: 9.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12802, Training Loss: 8.343e-01, Validation Loss: 9.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12803, Training Loss: 8.343e-01, Validation Loss: 9.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12804, Training Loss: 8.342e-01, Validation Loss: 9.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12805, Training Loss: 8.342e-01, Validation Loss: 9.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12806, Training Loss: 8.341e-01, Validation Loss: 9.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12807, Training Loss: 8.340e-01, Validation Loss: 9.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12808, Training Loss: 8.340e-01, Validation Loss: 9.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12809, Training Loss: 8.339e-01, Validation Loss: 9.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12810, Training Loss: 8.339e-01, Validation Loss: 9.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12811, Training Loss: 8.338e-01, Validation Loss: 9.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12812, Training Loss: 8.338e-01, Validation Loss: 9.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12813, Training Loss: 8.337e-01, Validation Loss: 9.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12814, Training Loss: 8.336e-01, Validation Loss: 9.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12815, Training Loss: 8.336e-01, Validation Loss: 9.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12816, Training Loss: 8.335e-01, Validation Loss: 9.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12817, Training Loss: 8.335e-01, Validation Loss: 9.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12818, Training Loss: 8.334e-01, Validation Loss: 9.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12819, Training Loss: 8.333e-01, Validation Loss: 9.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12820, Training Loss: 8.333e-01, Validation Loss: 9.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12821, Training Loss: 8.332e-01, Validation Loss: 9.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12822, Training Loss: 8.332e-01, Validation Loss: 9.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12823, Training Loss: 8.331e-01, Validation Loss: 9.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12824, Training Loss: 8.330e-01, Validation Loss: 9.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12825, Training Loss: 8.330e-01, Validation Loss: 9.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12826, Training Loss: 8.329e-01, Validation Loss: 9.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12827, Training Loss: 8.329e-01, Validation Loss: 9.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12828, Training Loss: 8.328e-01, Validation Loss: 9.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12829, Training Loss: 8.327e-01, Validation Loss: 9.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12830, Training Loss: 8.327e-01, Validation Loss: 9.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12831, Training Loss: 8.326e-01, Validation Loss: 9.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12832, Training Loss: 8.326e-01, Validation Loss: 9.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12833, Training Loss: 8.325e-01, Validation Loss: 9.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12834, Training Loss: 8.324e-01, Validation Loss: 9.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12835, Training Loss: 8.324e-01, Validation Loss: 9.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12836, Training Loss: 8.323e-01, Validation Loss: 9.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12837, Training Loss: 8.323e-01, Validation Loss: 9.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12838, Training Loss: 8.322e-01, Validation Loss: 9.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12839, Training Loss: 8.322e-01, Validation Loss: 9.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12840, Training Loss: 8.321e-01, Validation Loss: 9.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12841, Training Loss: 8.320e-01, Validation Loss: 9.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12842, Training Loss: 8.320e-01, Validation Loss: 9.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12843, Training Loss: 8.319e-01, Validation Loss: 9.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12844, Training Loss: 8.319e-01, Validation Loss: 9.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12845, Training Loss: 8.318e-01, Validation Loss: 9.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12846, Training Loss: 8.317e-01, Validation Loss: 9.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12847, Training Loss: 8.317e-01, Validation Loss: 9.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12848, Training Loss: 8.316e-01, Validation Loss: 9.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12849, Training Loss: 8.316e-01, Validation Loss: 9.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12850, Training Loss: 8.315e-01, Validation Loss: 9.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12851, Training Loss: 8.314e-01, Validation Loss: 9.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12852, Training Loss: 8.314e-01, Validation Loss: 9.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12853, Training Loss: 8.313e-01, Validation Loss: 9.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12854, Training Loss: 8.313e-01, Validation Loss: 9.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12855, Training Loss: 8.312e-01, Validation Loss: 9.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12856, Training Loss: 8.311e-01, Validation Loss: 9.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12857, Training Loss: 8.311e-01, Validation Loss: 9.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12858, Training Loss: 8.310e-01, Validation Loss: 9.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12859, Training Loss: 8.310e-01, Validation Loss: 9.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12860, Training Loss: 8.309e-01, Validation Loss: 9.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12861, Training Loss: 8.308e-01, Validation Loss: 9.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12862, Training Loss: 8.308e-01, Validation Loss: 9.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12863, Training Loss: 8.307e-01, Validation Loss: 9.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12864, Training Loss: 8.307e-01, Validation Loss: 9.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12865, Training Loss: 8.306e-01, Validation Loss: 9.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12866, Training Loss: 8.306e-01, Validation Loss: 9.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12867, Training Loss: 8.305e-01, Validation Loss: 9.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12868, Training Loss: 8.304e-01, Validation Loss: 9.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12869, Training Loss: 8.304e-01, Validation Loss: 9.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12870, Training Loss: 8.303e-01, Validation Loss: 9.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12871, Training Loss: 8.303e-01, Validation Loss: 9.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12872, Training Loss: 8.302e-01, Validation Loss: 9.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12873, Training Loss: 8.301e-01, Validation Loss: 9.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12874, Training Loss: 8.301e-01, Validation Loss: 9.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12875, Training Loss: 8.300e-01, Validation Loss: 9.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12876, Training Loss: 8.300e-01, Validation Loss: 9.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12877, Training Loss: 8.299e-01, Validation Loss: 9.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12878, Training Loss: 8.298e-01, Validation Loss: 9.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12879, Training Loss: 8.298e-01, Validation Loss: 9.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12880, Training Loss: 8.297e-01, Validation Loss: 9.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12881, Training Loss: 8.297e-01, Validation Loss: 9.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12882, Training Loss: 8.296e-01, Validation Loss: 9.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12883, Training Loss: 8.295e-01, Validation Loss: 9.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12884, Training Loss: 8.295e-01, Validation Loss: 9.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12885, Training Loss: 8.294e-01, Validation Loss: 9.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12886, Training Loss: 8.294e-01, Validation Loss: 9.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12887, Training Loss: 8.293e-01, Validation Loss: 9.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12888, Training Loss: 8.292e-01, Validation Loss: 9.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12889, Training Loss: 8.292e-01, Validation Loss: 9.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12890, Training Loss: 8.291e-01, Validation Loss: 9.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12891, Training Loss: 8.291e-01, Validation Loss: 9.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12892, Training Loss: 8.290e-01, Validation Loss: 9.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12893, Training Loss: 8.290e-01, Validation Loss: 9.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12894, Training Loss: 8.289e-01, Validation Loss: 9.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12895, Training Loss: 8.288e-01, Validation Loss: 9.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12896, Training Loss: 8.288e-01, Validation Loss: 9.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12897, Training Loss: 8.287e-01, Validation Loss: 9.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12898, Training Loss: 8.287e-01, Validation Loss: 9.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12899, Training Loss: 8.286e-01, Validation Loss: 9.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12900, Training Loss: 8.285e-01, Validation Loss: 9.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12901, Training Loss: 8.285e-01, Validation Loss: 9.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12902, Training Loss: 8.284e-01, Validation Loss: 9.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12903, Training Loss: 8.284e-01, Validation Loss: 9.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12904, Training Loss: 8.283e-01, Validation Loss: 9.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12905, Training Loss: 8.282e-01, Validation Loss: 9.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12906, Training Loss: 8.282e-01, Validation Loss: 9.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12907, Training Loss: 8.281e-01, Validation Loss: 9.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12908, Training Loss: 8.281e-01, Validation Loss: 9.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12909, Training Loss: 8.280e-01, Validation Loss: 9.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12910, Training Loss: 8.279e-01, Validation Loss: 9.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12911, Training Loss: 8.279e-01, Validation Loss: 9.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12912, Training Loss: 8.278e-01, Validation Loss: 9.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12913, Training Loss: 8.278e-01, Validation Loss: 9.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12914, Training Loss: 8.277e-01, Validation Loss: 9.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12915, Training Loss: 8.276e-01, Validation Loss: 9.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12916, Training Loss: 8.276e-01, Validation Loss: 9.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12917, Training Loss: 8.275e-01, Validation Loss: 9.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12918, Training Loss: 8.275e-01, Validation Loss: 9.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12919, Training Loss: 8.274e-01, Validation Loss: 9.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12920, Training Loss: 8.273e-01, Validation Loss: 9.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12921, Training Loss: 8.273e-01, Validation Loss: 9.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12922, Training Loss: 8.272e-01, Validation Loss: 9.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12923, Training Loss: 8.272e-01, Validation Loss: 9.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12924, Training Loss: 8.271e-01, Validation Loss: 9.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12925, Training Loss: 8.271e-01, Validation Loss: 9.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12926, Training Loss: 8.270e-01, Validation Loss: 9.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12927, Training Loss: 8.269e-01, Validation Loss: 9.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12928, Training Loss: 8.269e-01, Validation Loss: 9.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12929, Training Loss: 8.268e-01, Validation Loss: 9.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12930, Training Loss: 8.268e-01, Validation Loss: 9.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12931, Training Loss: 8.267e-01, Validation Loss: 9.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12932, Training Loss: 8.266e-01, Validation Loss: 9.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12933, Training Loss: 8.266e-01, Validation Loss: 9.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12934, Training Loss: 8.265e-01, Validation Loss: 9.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12935, Training Loss: 8.264e-01, Validation Loss: 9.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12936, Training Loss: 8.264e-01, Validation Loss: 9.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12937, Training Loss: 8.263e-01, Validation Loss: 9.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12938, Training Loss: 8.263e-01, Validation Loss: 9.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12939, Training Loss: 8.262e-01, Validation Loss: 9.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12940, Training Loss: 8.261e-01, Validation Loss: 9.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12941, Training Loss: 8.261e-01, Validation Loss: 9.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12942, Training Loss: 8.260e-01, Validation Loss: 9.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12943, Training Loss: 8.260e-01, Validation Loss: 9.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12944, Training Loss: 8.259e-01, Validation Loss: 9.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12945, Training Loss: 8.258e-01, Validation Loss: 9.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12946, Training Loss: 8.258e-01, Validation Loss: 9.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12947, Training Loss: 8.257e-01, Validation Loss: 9.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12948, Training Loss: 8.257e-01, Validation Loss: 9.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12949, Training Loss: 8.256e-01, Validation Loss: 9.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12950, Training Loss: 8.255e-01, Validation Loss: 9.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12951, Training Loss: 8.255e-01, Validation Loss: 9.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12952, Training Loss: 8.254e-01, Validation Loss: 9.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12953, Training Loss: 8.253e-01, Validation Loss: 9.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12954, Training Loss: 8.253e-01, Validation Loss: 9.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12955, Training Loss: 8.252e-01, Validation Loss: 9.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12956, Training Loss: 8.251e-01, Validation Loss: 9.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12957, Training Loss: 8.251e-01, Validation Loss: 9.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12958, Training Loss: 8.250e-01, Validation Loss: 9.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12959, Training Loss: 8.250e-01, Validation Loss: 9.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12960, Training Loss: 8.249e-01, Validation Loss: 9.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12961, Training Loss: 8.248e-01, Validation Loss: 9.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12962, Training Loss: 8.248e-01, Validation Loss: 9.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12963, Training Loss: 8.247e-01, Validation Loss: 9.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12964, Training Loss: 8.246e-01, Validation Loss: 9.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12965, Training Loss: 8.246e-01, Validation Loss: 9.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12966, Training Loss: 8.245e-01, Validation Loss: 9.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12967, Training Loss: 8.244e-01, Validation Loss: 9.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12968, Training Loss: 8.244e-01, Validation Loss: 9.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12969, Training Loss: 8.243e-01, Validation Loss: 9.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12970, Training Loss: 8.242e-01, Validation Loss: 9.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12971, Training Loss: 8.242e-01, Validation Loss: 9.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12972, Training Loss: 8.241e-01, Validation Loss: 9.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12973, Training Loss: 8.240e-01, Validation Loss: 9.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12974, Training Loss: 8.240e-01, Validation Loss: 9.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12975, Training Loss: 8.239e-01, Validation Loss: 9.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12976, Training Loss: 8.238e-01, Validation Loss: 9.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12977, Training Loss: 8.238e-01, Validation Loss: 9.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12978, Training Loss: 8.237e-01, Validation Loss: 9.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12979, Training Loss: 8.236e-01, Validation Loss: 9.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12980, Training Loss: 8.236e-01, Validation Loss: 9.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12981, Training Loss: 8.235e-01, Validation Loss: 9.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12982, Training Loss: 8.234e-01, Validation Loss: 9.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12983, Training Loss: 8.234e-01, Validation Loss: 9.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12984, Training Loss: 8.233e-01, Validation Loss: 9.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12985, Training Loss: 8.233e-01, Validation Loss: 9.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12986, Training Loss: 8.232e-01, Validation Loss: 9.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12987, Training Loss: 8.231e-01, Validation Loss: 9.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12988, Training Loss: 8.231e-01, Validation Loss: 9.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12989, Training Loss: 8.230e-01, Validation Loss: 9.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12990, Training Loss: 8.229e-01, Validation Loss: 9.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12991, Training Loss: 8.229e-01, Validation Loss: 9.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12992, Training Loss: 8.228e-01, Validation Loss: 9.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12993, Training Loss: 8.227e-01, Validation Loss: 9.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12994, Training Loss: 8.227e-01, Validation Loss: 9.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12995, Training Loss: 8.226e-01, Validation Loss: 9.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12996, Training Loss: 8.225e-01, Validation Loss: 9.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12997, Training Loss: 8.225e-01, Validation Loss: 9.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12998, Training Loss: 8.224e-01, Validation Loss: 9.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12999, Training Loss: 8.223e-01, Validation Loss: 9.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13000, Training Loss: 8.223e-01, Validation Loss: 9.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13001, Training Loss: 8.222e-01, Validation Loss: 9.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13002, Training Loss: 8.221e-01, Validation Loss: 9.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13003, Training Loss: 8.221e-01, Validation Loss: 9.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13004, Training Loss: 8.220e-01, Validation Loss: 9.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13005, Training Loss: 8.219e-01, Validation Loss: 9.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13006, Training Loss: 8.219e-01, Validation Loss: 9.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13007, Training Loss: 8.218e-01, Validation Loss: 9.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13008, Training Loss: 8.217e-01, Validation Loss: 9.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13009, Training Loss: 8.217e-01, Validation Loss: 9.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13010, Training Loss: 8.216e-01, Validation Loss: 9.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13011, Training Loss: 8.215e-01, Validation Loss: 9.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13012, Training Loss: 8.215e-01, Validation Loss: 9.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13013, Training Loss: 8.214e-01, Validation Loss: 9.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13014, Training Loss: 8.213e-01, Validation Loss: 9.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13015, Training Loss: 8.213e-01, Validation Loss: 9.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13016, Training Loss: 8.212e-01, Validation Loss: 9.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13017, Training Loss: 8.211e-01, Validation Loss: 9.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13018, Training Loss: 8.211e-01, Validation Loss: 9.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13019, Training Loss: 8.210e-01, Validation Loss: 9.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13020, Training Loss: 8.209e-01, Validation Loss: 9.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13021, Training Loss: 8.208e-01, Validation Loss: 9.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13022, Training Loss: 8.208e-01, Validation Loss: 9.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13023, Training Loss: 8.207e-01, Validation Loss: 9.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13024, Training Loss: 8.206e-01, Validation Loss: 9.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13025, Training Loss: 8.206e-01, Validation Loss: 9.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13026, Training Loss: 8.205e-01, Validation Loss: 9.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13027, Training Loss: 8.205e-01, Validation Loss: 9.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13028, Training Loss: 8.204e-01, Validation Loss: 9.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13029, Training Loss: 8.203e-01, Validation Loss: 9.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13030, Training Loss: 8.203e-01, Validation Loss: 9.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13031, Training Loss: 8.202e-01, Validation Loss: 9.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13032, Training Loss: 8.201e-01, Validation Loss: 9.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13033, Training Loss: 8.201e-01, Validation Loss: 9.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13034, Training Loss: 8.200e-01, Validation Loss: 9.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13035, Training Loss: 8.199e-01, Validation Loss: 9.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13036, Training Loss: 8.199e-01, Validation Loss: 9.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13037, Training Loss: 8.198e-01, Validation Loss: 9.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13038, Training Loss: 8.197e-01, Validation Loss: 9.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13039, Training Loss: 8.197e-01, Validation Loss: 9.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13040, Training Loss: 8.196e-01, Validation Loss: 9.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13041, Training Loss: 8.196e-01, Validation Loss: 9.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13042, Training Loss: 8.195e-01, Validation Loss: 9.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13043, Training Loss: 8.194e-01, Validation Loss: 9.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13044, Training Loss: 8.194e-01, Validation Loss: 9.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13045, Training Loss: 8.193e-01, Validation Loss: 9.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13046, Training Loss: 8.192e-01, Validation Loss: 9.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13047, Training Loss: 8.192e-01, Validation Loss: 9.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13048, Training Loss: 8.191e-01, Validation Loss: 9.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13049, Training Loss: 8.190e-01, Validation Loss: 9.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13050, Training Loss: 8.190e-01, Validation Loss: 9.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13051, Training Loss: 8.189e-01, Validation Loss: 9.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13052, Training Loss: 8.189e-01, Validation Loss: 9.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13053, Training Loss: 8.188e-01, Validation Loss: 9.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13054, Training Loss: 8.187e-01, Validation Loss: 9.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13055, Training Loss: 8.187e-01, Validation Loss: 9.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13056, Training Loss: 8.186e-01, Validation Loss: 9.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13057, Training Loss: 8.186e-01, Validation Loss: 9.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13058, Training Loss: 8.185e-01, Validation Loss: 9.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13059, Training Loss: 8.184e-01, Validation Loss: 9.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13060, Training Loss: 8.184e-01, Validation Loss: 9.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13061, Training Loss: 8.183e-01, Validation Loss: 9.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13062, Training Loss: 8.182e-01, Validation Loss: 9.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13063, Training Loss: 8.182e-01, Validation Loss: 9.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13064, Training Loss: 8.181e-01, Validation Loss: 9.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13065, Training Loss: 8.181e-01, Validation Loss: 9.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13066, Training Loss: 8.180e-01, Validation Loss: 9.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13067, Training Loss: 8.179e-01, Validation Loss: 9.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13068, Training Loss: 8.179e-01, Validation Loss: 9.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13069, Training Loss: 8.178e-01, Validation Loss: 9.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13070, Training Loss: 8.178e-01, Validation Loss: 9.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13071, Training Loss: 8.177e-01, Validation Loss: 9.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13072, Training Loss: 8.176e-01, Validation Loss: 9.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13073, Training Loss: 8.176e-01, Validation Loss: 9.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13074, Training Loss: 8.175e-01, Validation Loss: 9.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13075, Training Loss: 8.175e-01, Validation Loss: 9.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13076, Training Loss: 8.174e-01, Validation Loss: 9.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13077, Training Loss: 8.174e-01, Validation Loss: 9.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13078, Training Loss: 8.173e-01, Validation Loss: 9.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13079, Training Loss: 8.172e-01, Validation Loss: 9.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13080, Training Loss: 8.172e-01, Validation Loss: 9.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13081, Training Loss: 8.171e-01, Validation Loss: 9.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13082, Training Loss: 8.171e-01, Validation Loss: 9.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13083, Training Loss: 8.170e-01, Validation Loss: 9.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13084, Training Loss: 8.169e-01, Validation Loss: 9.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13085, Training Loss: 8.169e-01, Validation Loss: 9.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13086, Training Loss: 8.168e-01, Validation Loss: 9.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13087, Training Loss: 8.168e-01, Validation Loss: 9.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13088, Training Loss: 8.167e-01, Validation Loss: 9.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13089, Training Loss: 8.166e-01, Validation Loss: 9.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13090, Training Loss: 8.166e-01, Validation Loss: 9.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13091, Training Loss: 8.165e-01, Validation Loss: 9.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13092, Training Loss: 8.165e-01, Validation Loss: 9.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13093, Training Loss: 8.164e-01, Validation Loss: 9.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13094, Training Loss: 8.164e-01, Validation Loss: 9.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13095, Training Loss: 8.163e-01, Validation Loss: 9.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13096, Training Loss: 8.162e-01, Validation Loss: 9.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13097, Training Loss: 8.162e-01, Validation Loss: 9.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13098, Training Loss: 8.161e-01, Validation Loss: 9.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13099, Training Loss: 8.161e-01, Validation Loss: 9.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13100, Training Loss: 8.160e-01, Validation Loss: 9.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13101, Training Loss: 8.160e-01, Validation Loss: 9.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13102, Training Loss: 8.159e-01, Validation Loss: 9.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13103, Training Loss: 8.158e-01, Validation Loss: 9.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13104, Training Loss: 8.158e-01, Validation Loss: 9.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13105, Training Loss: 8.157e-01, Validation Loss: 9.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13106, Training Loss: 8.157e-01, Validation Loss: 9.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13107, Training Loss: 8.156e-01, Validation Loss: 9.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13108, Training Loss: 8.155e-01, Validation Loss: 9.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13109, Training Loss: 8.155e-01, Validation Loss: 9.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13110, Training Loss: 8.154e-01, Validation Loss: 9.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13111, Training Loss: 8.154e-01, Validation Loss: 9.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13112, Training Loss: 8.153e-01, Validation Loss: 9.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13113, Training Loss: 8.153e-01, Validation Loss: 9.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13114, Training Loss: 8.152e-01, Validation Loss: 9.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13115, Training Loss: 8.151e-01, Validation Loss: 9.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13116, Training Loss: 8.151e-01, Validation Loss: 9.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13117, Training Loss: 8.150e-01, Validation Loss: 9.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13118, Training Loss: 8.150e-01, Validation Loss: 9.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13119, Training Loss: 8.149e-01, Validation Loss: 9.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13120, Training Loss: 8.149e-01, Validation Loss: 9.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13121, Training Loss: 8.148e-01, Validation Loss: 9.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13122, Training Loss: 8.147e-01, Validation Loss: 9.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13123, Training Loss: 8.147e-01, Validation Loss: 9.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13124, Training Loss: 8.146e-01, Validation Loss: 9.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13125, Training Loss: 8.146e-01, Validation Loss: 9.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13126, Training Loss: 8.145e-01, Validation Loss: 9.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13127, Training Loss: 8.145e-01, Validation Loss: 9.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13128, Training Loss: 8.144e-01, Validation Loss: 9.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13129, Training Loss: 8.143e-01, Validation Loss: 9.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13130, Training Loss: 8.143e-01, Validation Loss: 9.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13131, Training Loss: 8.142e-01, Validation Loss: 9.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13132, Training Loss: 8.142e-01, Validation Loss: 9.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13133, Training Loss: 8.141e-01, Validation Loss: 9.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13134, Training Loss: 8.141e-01, Validation Loss: 9.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13135, Training Loss: 8.140e-01, Validation Loss: 9.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13136, Training Loss: 8.139e-01, Validation Loss: 9.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13137, Training Loss: 8.139e-01, Validation Loss: 9.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13138, Training Loss: 8.138e-01, Validation Loss: 9.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13139, Training Loss: 8.138e-01, Validation Loss: 9.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13140, Training Loss: 8.137e-01, Validation Loss: 9.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13141, Training Loss: 8.137e-01, Validation Loss: 9.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13142, Training Loss: 8.136e-01, Validation Loss: 9.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13143, Training Loss: 8.135e-01, Validation Loss: 9.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13144, Training Loss: 8.135e-01, Validation Loss: 9.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13145, Training Loss: 8.134e-01, Validation Loss: 9.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13146, Training Loss: 8.134e-01, Validation Loss: 9.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13147, Training Loss: 8.133e-01, Validation Loss: 9.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13148, Training Loss: 8.133e-01, Validation Loss: 9.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13149, Training Loss: 8.132e-01, Validation Loss: 9.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13150, Training Loss: 8.131e-01, Validation Loss: 9.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13151, Training Loss: 8.131e-01, Validation Loss: 9.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13152, Training Loss: 8.130e-01, Validation Loss: 9.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13153, Training Loss: 8.130e-01, Validation Loss: 9.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13154, Training Loss: 8.129e-01, Validation Loss: 9.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13155, Training Loss: 8.129e-01, Validation Loss: 9.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13156, Training Loss: 8.128e-01, Validation Loss: 9.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13157, Training Loss: 8.127e-01, Validation Loss: 9.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13158, Training Loss: 8.127e-01, Validation Loss: 9.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13159, Training Loss: 8.126e-01, Validation Loss: 9.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13160, Training Loss: 8.126e-01, Validation Loss: 9.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13161, Training Loss: 8.125e-01, Validation Loss: 9.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13162, Training Loss: 8.125e-01, Validation Loss: 9.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13163, Training Loss: 8.124e-01, Validation Loss: 9.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13164, Training Loss: 8.123e-01, Validation Loss: 9.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13165, Training Loss: 8.123e-01, Validation Loss: 9.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13166, Training Loss: 8.122e-01, Validation Loss: 9.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13167, Training Loss: 8.122e-01, Validation Loss: 9.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13168, Training Loss: 8.121e-01, Validation Loss: 9.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13169, Training Loss: 8.121e-01, Validation Loss: 9.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13170, Training Loss: 8.120e-01, Validation Loss: 9.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13171, Training Loss: 8.119e-01, Validation Loss: 9.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13172, Training Loss: 8.119e-01, Validation Loss: 9.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13173, Training Loss: 8.118e-01, Validation Loss: 9.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13174, Training Loss: 8.118e-01, Validation Loss: 9.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13175, Training Loss: 8.117e-01, Validation Loss: 9.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13176, Training Loss: 8.117e-01, Validation Loss: 9.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13177, Training Loss: 8.116e-01, Validation Loss: 9.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13178, Training Loss: 8.115e-01, Validation Loss: 9.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13179, Training Loss: 8.115e-01, Validation Loss: 9.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13180, Training Loss: 8.114e-01, Validation Loss: 9.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13181, Training Loss: 8.114e-01, Validation Loss: 9.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13182, Training Loss: 8.113e-01, Validation Loss: 9.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13183, Training Loss: 8.113e-01, Validation Loss: 9.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13184, Training Loss: 8.112e-01, Validation Loss: 9.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13185, Training Loss: 8.111e-01, Validation Loss: 9.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13186, Training Loss: 8.111e-01, Validation Loss: 9.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13187, Training Loss: 8.110e-01, Validation Loss: 9.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13188, Training Loss: 8.110e-01, Validation Loss: 9.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13189, Training Loss: 8.109e-01, Validation Loss: 9.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13190, Training Loss: 8.109e-01, Validation Loss: 9.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13191, Training Loss: 8.108e-01, Validation Loss: 9.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13192, Training Loss: 8.108e-01, Validation Loss: 9.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13193, Training Loss: 8.107e-01, Validation Loss: 9.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13194, Training Loss: 8.106e-01, Validation Loss: 9.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13195, Training Loss: 8.106e-01, Validation Loss: 9.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13196, Training Loss: 8.105e-01, Validation Loss: 9.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13197, Training Loss: 8.105e-01, Validation Loss: 9.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13198, Training Loss: 8.104e-01, Validation Loss: 9.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13199, Training Loss: 8.104e-01, Validation Loss: 9.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13200, Training Loss: 8.103e-01, Validation Loss: 9.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13201, Training Loss: 8.102e-01, Validation Loss: 9.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13202, Training Loss: 8.102e-01, Validation Loss: 9.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13203, Training Loss: 8.101e-01, Validation Loss: 9.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13204, Training Loss: 8.101e-01, Validation Loss: 9.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13205, Training Loss: 8.100e-01, Validation Loss: 9.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13206, Training Loss: 8.100e-01, Validation Loss: 9.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13207, Training Loss: 8.099e-01, Validation Loss: 9.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13208, Training Loss: 8.098e-01, Validation Loss: 9.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13209, Training Loss: 8.098e-01, Validation Loss: 9.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13210, Training Loss: 8.097e-01, Validation Loss: 9.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13211, Training Loss: 8.097e-01, Validation Loss: 9.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13212, Training Loss: 8.096e-01, Validation Loss: 9.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13213, Training Loss: 8.096e-01, Validation Loss: 9.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13214, Training Loss: 8.095e-01, Validation Loss: 9.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13215, Training Loss: 8.094e-01, Validation Loss: 9.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13216, Training Loss: 8.094e-01, Validation Loss: 9.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13217, Training Loss: 8.093e-01, Validation Loss: 9.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13218, Training Loss: 8.093e-01, Validation Loss: 9.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13219, Training Loss: 8.092e-01, Validation Loss: 9.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13220, Training Loss: 8.092e-01, Validation Loss: 9.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13221, Training Loss: 8.091e-01, Validation Loss: 9.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13222, Training Loss: 8.091e-01, Validation Loss: 9.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13223, Training Loss: 8.090e-01, Validation Loss: 9.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13224, Training Loss: 8.089e-01, Validation Loss: 9.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13225, Training Loss: 8.089e-01, Validation Loss: 9.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13226, Training Loss: 8.088e-01, Validation Loss: 9.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13227, Training Loss: 8.088e-01, Validation Loss: 9.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13228, Training Loss: 8.087e-01, Validation Loss: 9.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13229, Training Loss: 8.087e-01, Validation Loss: 9.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13230, Training Loss: 8.086e-01, Validation Loss: 9.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13231, Training Loss: 8.085e-01, Validation Loss: 9.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13232, Training Loss: 8.085e-01, Validation Loss: 9.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13233, Training Loss: 8.084e-01, Validation Loss: 9.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13234, Training Loss: 8.084e-01, Validation Loss: 9.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13235, Training Loss: 8.083e-01, Validation Loss: 9.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13236, Training Loss: 8.083e-01, Validation Loss: 9.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13237, Training Loss: 8.082e-01, Validation Loss: 9.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13238, Training Loss: 8.082e-01, Validation Loss: 9.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13239, Training Loss: 8.081e-01, Validation Loss: 9.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13240, Training Loss: 8.080e-01, Validation Loss: 9.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13241, Training Loss: 8.080e-01, Validation Loss: 9.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13242, Training Loss: 8.079e-01, Validation Loss: 9.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13243, Training Loss: 8.079e-01, Validation Loss: 9.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13244, Training Loss: 8.078e-01, Validation Loss: 9.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13245, Training Loss: 8.078e-01, Validation Loss: 9.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13246, Training Loss: 8.077e-01, Validation Loss: 9.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13247, Training Loss: 8.076e-01, Validation Loss: 9.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13248, Training Loss: 8.076e-01, Validation Loss: 9.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13249, Training Loss: 8.075e-01, Validation Loss: 9.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13250, Training Loss: 8.075e-01, Validation Loss: 9.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13251, Training Loss: 8.074e-01, Validation Loss: 9.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13252, Training Loss: 8.074e-01, Validation Loss: 9.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13253, Training Loss: 8.073e-01, Validation Loss: 9.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13254, Training Loss: 8.073e-01, Validation Loss: 9.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13255, Training Loss: 8.072e-01, Validation Loss: 9.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13256, Training Loss: 8.071e-01, Validation Loss: 9.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13257, Training Loss: 8.071e-01, Validation Loss: 9.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13258, Training Loss: 8.070e-01, Validation Loss: 9.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13259, Training Loss: 8.070e-01, Validation Loss: 9.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13260, Training Loss: 8.069e-01, Validation Loss: 9.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13261, Training Loss: 8.069e-01, Validation Loss: 9.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13262, Training Loss: 8.068e-01, Validation Loss: 9.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13263, Training Loss: 8.067e-01, Validation Loss: 9.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13264, Training Loss: 8.067e-01, Validation Loss: 9.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13265, Training Loss: 8.066e-01, Validation Loss: 9.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13266, Training Loss: 8.066e-01, Validation Loss: 9.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13267, Training Loss: 8.065e-01, Validation Loss: 9.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13268, Training Loss: 8.065e-01, Validation Loss: 9.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13269, Training Loss: 8.064e-01, Validation Loss: 9.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13270, Training Loss: 8.064e-01, Validation Loss: 9.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13271, Training Loss: 8.063e-01, Validation Loss: 9.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13272, Training Loss: 8.062e-01, Validation Loss: 9.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13273, Training Loss: 8.062e-01, Validation Loss: 9.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13274, Training Loss: 8.061e-01, Validation Loss: 9.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13275, Training Loss: 8.061e-01, Validation Loss: 9.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13276, Training Loss: 8.060e-01, Validation Loss: 9.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13277, Training Loss: 8.060e-01, Validation Loss: 9.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13278, Training Loss: 8.059e-01, Validation Loss: 9.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13279, Training Loss: 8.058e-01, Validation Loss: 9.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13280, Training Loss: 8.058e-01, Validation Loss: 9.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13281, Training Loss: 8.057e-01, Validation Loss: 9.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13282, Training Loss: 8.057e-01, Validation Loss: 9.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13283, Training Loss: 8.056e-01, Validation Loss: 9.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13284, Training Loss: 8.056e-01, Validation Loss: 9.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13285, Training Loss: 8.055e-01, Validation Loss: 9.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13286, Training Loss: 8.055e-01, Validation Loss: 9.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13287, Training Loss: 8.054e-01, Validation Loss: 9.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13288, Training Loss: 8.053e-01, Validation Loss: 9.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13289, Training Loss: 8.053e-01, Validation Loss: 9.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13290, Training Loss: 8.052e-01, Validation Loss: 9.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13291, Training Loss: 8.052e-01, Validation Loss: 9.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13292, Training Loss: 8.051e-01, Validation Loss: 9.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13293, Training Loss: 8.051e-01, Validation Loss: 9.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13294, Training Loss: 8.050e-01, Validation Loss: 9.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13295, Training Loss: 8.050e-01, Validation Loss: 9.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13296, Training Loss: 8.049e-01, Validation Loss: 9.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13297, Training Loss: 8.048e-01, Validation Loss: 9.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13298, Training Loss: 8.048e-01, Validation Loss: 9.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13299, Training Loss: 8.047e-01, Validation Loss: 9.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13300, Training Loss: 8.047e-01, Validation Loss: 9.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13301, Training Loss: 8.046e-01, Validation Loss: 9.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13302, Training Loss: 8.046e-01, Validation Loss: 9.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13303, Training Loss: 8.045e-01, Validation Loss: 9.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13304, Training Loss: 8.044e-01, Validation Loss: 9.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13305, Training Loss: 8.044e-01, Validation Loss: 9.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13306, Training Loss: 8.043e-01, Validation Loss: 9.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13307, Training Loss: 8.043e-01, Validation Loss: 9.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13308, Training Loss: 8.042e-01, Validation Loss: 9.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13309, Training Loss: 8.042e-01, Validation Loss: 9.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13310, Training Loss: 8.041e-01, Validation Loss: 9.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13311, Training Loss: 8.041e-01, Validation Loss: 9.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13312, Training Loss: 8.040e-01, Validation Loss: 9.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13313, Training Loss: 8.039e-01, Validation Loss: 9.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13314, Training Loss: 8.039e-01, Validation Loss: 9.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13315, Training Loss: 8.038e-01, Validation Loss: 9.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13316, Training Loss: 8.038e-01, Validation Loss: 9.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13317, Training Loss: 8.037e-01, Validation Loss: 9.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13318, Training Loss: 8.037e-01, Validation Loss: 9.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13319, Training Loss: 8.036e-01, Validation Loss: 9.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13320, Training Loss: 8.036e-01, Validation Loss: 9.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13321, Training Loss: 8.035e-01, Validation Loss: 9.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13322, Training Loss: 8.034e-01, Validation Loss: 9.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13323, Training Loss: 8.034e-01, Validation Loss: 9.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13324, Training Loss: 8.033e-01, Validation Loss: 9.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13325, Training Loss: 8.033e-01, Validation Loss: 9.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13326, Training Loss: 8.032e-01, Validation Loss: 9.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13327, Training Loss: 8.032e-01, Validation Loss: 9.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13328, Training Loss: 8.031e-01, Validation Loss: 9.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13329, Training Loss: 8.031e-01, Validation Loss: 9.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13330, Training Loss: 8.030e-01, Validation Loss: 9.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13331, Training Loss: 8.029e-01, Validation Loss: 9.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13332, Training Loss: 8.029e-01, Validation Loss: 9.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13333, Training Loss: 8.028e-01, Validation Loss: 9.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13334, Training Loss: 8.028e-01, Validation Loss: 9.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13335, Training Loss: 8.027e-01, Validation Loss: 9.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13336, Training Loss: 8.027e-01, Validation Loss: 9.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13337, Training Loss: 8.026e-01, Validation Loss: 9.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13338, Training Loss: 8.026e-01, Validation Loss: 9.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13339, Training Loss: 8.025e-01, Validation Loss: 9.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13340, Training Loss: 8.024e-01, Validation Loss: 9.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13341, Training Loss: 8.024e-01, Validation Loss: 9.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13342, Training Loss: 8.023e-01, Validation Loss: 9.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13343, Training Loss: 8.023e-01, Validation Loss: 9.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13344, Training Loss: 8.022e-01, Validation Loss: 9.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13345, Training Loss: 8.022e-01, Validation Loss: 9.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13346, Training Loss: 8.021e-01, Validation Loss: 9.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13347, Training Loss: 8.021e-01, Validation Loss: 9.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13348, Training Loss: 8.020e-01, Validation Loss: 9.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13349, Training Loss: 8.019e-01, Validation Loss: 9.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13350, Training Loss: 8.019e-01, Validation Loss: 9.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13351, Training Loss: 8.018e-01, Validation Loss: 9.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13352, Training Loss: 8.018e-01, Validation Loss: 9.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13353, Training Loss: 8.017e-01, Validation Loss: 9.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13354, Training Loss: 8.017e-01, Validation Loss: 9.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13355, Training Loss: 8.016e-01, Validation Loss: 9.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13356, Training Loss: 8.016e-01, Validation Loss: 9.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13357, Training Loss: 8.015e-01, Validation Loss: 9.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13358, Training Loss: 8.014e-01, Validation Loss: 9.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13359, Training Loss: 8.014e-01, Validation Loss: 9.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13360, Training Loss: 8.013e-01, Validation Loss: 9.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13361, Training Loss: 8.013e-01, Validation Loss: 9.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13362, Training Loss: 8.012e-01, Validation Loss: 9.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13363, Training Loss: 8.012e-01, Validation Loss: 9.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13364, Training Loss: 8.011e-01, Validation Loss: 9.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13365, Training Loss: 8.011e-01, Validation Loss: 9.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13366, Training Loss: 8.010e-01, Validation Loss: 9.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13367, Training Loss: 8.009e-01, Validation Loss: 9.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13368, Training Loss: 8.009e-01, Validation Loss: 9.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13369, Training Loss: 8.008e-01, Validation Loss: 9.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13370, Training Loss: 8.008e-01, Validation Loss: 9.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13371, Training Loss: 8.007e-01, Validation Loss: 9.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13372, Training Loss: 8.007e-01, Validation Loss: 9.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13373, Training Loss: 8.006e-01, Validation Loss: 9.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13374, Training Loss: 8.006e-01, Validation Loss: 9.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13375, Training Loss: 8.005e-01, Validation Loss: 9.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13376, Training Loss: 8.004e-01, Validation Loss: 9.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13377, Training Loss: 8.004e-01, Validation Loss: 9.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13378, Training Loss: 8.003e-01, Validation Loss: 9.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13379, Training Loss: 8.003e-01, Validation Loss: 9.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13380, Training Loss: 8.002e-01, Validation Loss: 9.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13381, Training Loss: 8.002e-01, Validation Loss: 9.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13382, Training Loss: 8.001e-01, Validation Loss: 9.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13383, Training Loss: 8.001e-01, Validation Loss: 9.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13384, Training Loss: 8.000e-01, Validation Loss: 9.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13385, Training Loss: 7.999e-01, Validation Loss: 9.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13386, Training Loss: 7.999e-01, Validation Loss: 9.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13387, Training Loss: 7.998e-01, Validation Loss: 9.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13388, Training Loss: 7.998e-01, Validation Loss: 9.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13389, Training Loss: 7.997e-01, Validation Loss: 9.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13390, Training Loss: 7.997e-01, Validation Loss: 9.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13391, Training Loss: 7.996e-01, Validation Loss: 9.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13392, Training Loss: 7.996e-01, Validation Loss: 9.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13393, Training Loss: 7.995e-01, Validation Loss: 9.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13394, Training Loss: 7.994e-01, Validation Loss: 9.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13395, Training Loss: 7.994e-01, Validation Loss: 9.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13396, Training Loss: 7.993e-01, Validation Loss: 9.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13397, Training Loss: 7.993e-01, Validation Loss: 9.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13398, Training Loss: 7.992e-01, Validation Loss: 9.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13399, Training Loss: 7.992e-01, Validation Loss: 9.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13400, Training Loss: 7.991e-01, Validation Loss: 9.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13401, Training Loss: 7.991e-01, Validation Loss: 9.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13402, Training Loss: 7.990e-01, Validation Loss: 9.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13403, Training Loss: 7.989e-01, Validation Loss: 9.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13404, Training Loss: 7.989e-01, Validation Loss: 9.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13405, Training Loss: 7.988e-01, Validation Loss: 9.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13406, Training Loss: 7.988e-01, Validation Loss: 9.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13407, Training Loss: 7.987e-01, Validation Loss: 9.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13408, Training Loss: 7.987e-01, Validation Loss: 9.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13409, Training Loss: 7.986e-01, Validation Loss: 9.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13410, Training Loss: 7.986e-01, Validation Loss: 9.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13411, Training Loss: 7.985e-01, Validation Loss: 9.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13412, Training Loss: 7.985e-01, Validation Loss: 9.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13413, Training Loss: 7.984e-01, Validation Loss: 9.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13414, Training Loss: 7.983e-01, Validation Loss: 9.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13415, Training Loss: 7.983e-01, Validation Loss: 9.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13416, Training Loss: 7.982e-01, Validation Loss: 9.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13417, Training Loss: 7.982e-01, Validation Loss: 9.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13418, Training Loss: 7.981e-01, Validation Loss: 9.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13419, Training Loss: 7.981e-01, Validation Loss: 9.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13420, Training Loss: 7.980e-01, Validation Loss: 9.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13421, Training Loss: 7.980e-01, Validation Loss: 9.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13422, Training Loss: 7.979e-01, Validation Loss: 9.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13423, Training Loss: 7.978e-01, Validation Loss: 9.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13424, Training Loss: 7.978e-01, Validation Loss: 9.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13425, Training Loss: 7.977e-01, Validation Loss: 9.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13426, Training Loss: 7.977e-01, Validation Loss: 9.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13427, Training Loss: 7.976e-01, Validation Loss: 9.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13428, Training Loss: 7.976e-01, Validation Loss: 9.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13429, Training Loss: 7.975e-01, Validation Loss: 9.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13430, Training Loss: 7.975e-01, Validation Loss: 9.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13431, Training Loss: 7.974e-01, Validation Loss: 9.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13432, Training Loss: 7.974e-01, Validation Loss: 9.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13433, Training Loss: 7.973e-01, Validation Loss: 9.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13434, Training Loss: 7.972e-01, Validation Loss: 9.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13435, Training Loss: 7.972e-01, Validation Loss: 9.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13436, Training Loss: 7.971e-01, Validation Loss: 9.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13437, Training Loss: 7.971e-01, Validation Loss: 9.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13438, Training Loss: 7.970e-01, Validation Loss: 9.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13439, Training Loss: 7.970e-01, Validation Loss: 9.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13440, Training Loss: 7.969e-01, Validation Loss: 9.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13441, Training Loss: 7.969e-01, Validation Loss: 9.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13442, Training Loss: 7.968e-01, Validation Loss: 9.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13443, Training Loss: 7.967e-01, Validation Loss: 9.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13444, Training Loss: 7.967e-01, Validation Loss: 9.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13445, Training Loss: 7.966e-01, Validation Loss: 9.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13446, Training Loss: 7.966e-01, Validation Loss: 9.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13447, Training Loss: 7.965e-01, Validation Loss: 9.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13448, Training Loss: 7.965e-01, Validation Loss: 9.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13449, Training Loss: 7.964e-01, Validation Loss: 9.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13450, Training Loss: 7.964e-01, Validation Loss: 9.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13451, Training Loss: 7.963e-01, Validation Loss: 9.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13452, Training Loss: 7.963e-01, Validation Loss: 9.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13453, Training Loss: 7.962e-01, Validation Loss: 9.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13454, Training Loss: 7.961e-01, Validation Loss: 9.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13455, Training Loss: 7.961e-01, Validation Loss: 9.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13456, Training Loss: 7.960e-01, Validation Loss: 9.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13457, Training Loss: 7.960e-01, Validation Loss: 9.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13458, Training Loss: 7.959e-01, Validation Loss: 9.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13459, Training Loss: 7.959e-01, Validation Loss: 9.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13460, Training Loss: 7.958e-01, Validation Loss: 9.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13461, Training Loss: 7.958e-01, Validation Loss: 9.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13462, Training Loss: 7.957e-01, Validation Loss: 9.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13463, Training Loss: 7.956e-01, Validation Loss: 9.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13464, Training Loss: 7.956e-01, Validation Loss: 9.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13465, Training Loss: 7.955e-01, Validation Loss: 9.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13466, Training Loss: 7.955e-01, Validation Loss: 9.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13467, Training Loss: 7.954e-01, Validation Loss: 9.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13468, Training Loss: 7.954e-01, Validation Loss: 9.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13469, Training Loss: 7.953e-01, Validation Loss: 9.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13470, Training Loss: 7.953e-01, Validation Loss: 9.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13471, Training Loss: 7.952e-01, Validation Loss: 9.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13472, Training Loss: 7.952e-01, Validation Loss: 9.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13473, Training Loss: 7.951e-01, Validation Loss: 9.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13474, Training Loss: 7.950e-01, Validation Loss: 9.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13475, Training Loss: 7.950e-01, Validation Loss: 9.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13476, Training Loss: 7.949e-01, Validation Loss: 9.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13477, Training Loss: 7.949e-01, Validation Loss: 9.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13478, Training Loss: 7.948e-01, Validation Loss: 9.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13479, Training Loss: 7.948e-01, Validation Loss: 9.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13480, Training Loss: 7.947e-01, Validation Loss: 9.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13481, Training Loss: 7.947e-01, Validation Loss: 9.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13482, Training Loss: 7.946e-01, Validation Loss: 9.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13483, Training Loss: 7.946e-01, Validation Loss: 9.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13484, Training Loss: 7.945e-01, Validation Loss: 9.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13485, Training Loss: 7.944e-01, Validation Loss: 9.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13486, Training Loss: 7.944e-01, Validation Loss: 9.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13487, Training Loss: 7.943e-01, Validation Loss: 9.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13488, Training Loss: 7.943e-01, Validation Loss: 9.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13489, Training Loss: 7.942e-01, Validation Loss: 9.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13490, Training Loss: 7.942e-01, Validation Loss: 9.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13491, Training Loss: 7.941e-01, Validation Loss: 9.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13492, Training Loss: 7.941e-01, Validation Loss: 9.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13493, Training Loss: 7.940e-01, Validation Loss: 9.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13494, Training Loss: 7.939e-01, Validation Loss: 9.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13495, Training Loss: 7.939e-01, Validation Loss: 9.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13496, Training Loss: 7.938e-01, Validation Loss: 9.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13497, Training Loss: 7.938e-01, Validation Loss: 9.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13498, Training Loss: 7.937e-01, Validation Loss: 9.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13499, Training Loss: 7.937e-01, Validation Loss: 9.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13500, Training Loss: 7.936e-01, Validation Loss: 9.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13501, Training Loss: 7.936e-01, Validation Loss: 9.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13502, Training Loss: 7.935e-01, Validation Loss: 9.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13503, Training Loss: 7.935e-01, Validation Loss: 9.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13504, Training Loss: 7.934e-01, Validation Loss: 9.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13505, Training Loss: 7.933e-01, Validation Loss: 9.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13506, Training Loss: 7.933e-01, Validation Loss: 9.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13507, Training Loss: 7.932e-01, Validation Loss: 9.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13508, Training Loss: 7.932e-01, Validation Loss: 9.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13509, Training Loss: 7.931e-01, Validation Loss: 9.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13510, Training Loss: 7.931e-01, Validation Loss: 9.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13511, Training Loss: 7.930e-01, Validation Loss: 9.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13512, Training Loss: 7.930e-01, Validation Loss: 9.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13513, Training Loss: 7.929e-01, Validation Loss: 9.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13514, Training Loss: 7.929e-01, Validation Loss: 9.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13515, Training Loss: 7.928e-01, Validation Loss: 9.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13516, Training Loss: 7.927e-01, Validation Loss: 9.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13517, Training Loss: 7.927e-01, Validation Loss: 9.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13518, Training Loss: 7.926e-01, Validation Loss: 9.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13519, Training Loss: 7.926e-01, Validation Loss: 9.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13520, Training Loss: 7.925e-01, Validation Loss: 9.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13521, Training Loss: 7.925e-01, Validation Loss: 9.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13522, Training Loss: 7.924e-01, Validation Loss: 9.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13523, Training Loss: 7.924e-01, Validation Loss: 9.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13524, Training Loss: 7.923e-01, Validation Loss: 9.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13525, Training Loss: 7.923e-01, Validation Loss: 9.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13526, Training Loss: 7.922e-01, Validation Loss: 9.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13527, Training Loss: 7.921e-01, Validation Loss: 9.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13528, Training Loss: 7.921e-01, Validation Loss: 9.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13529, Training Loss: 7.920e-01, Validation Loss: 9.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13530, Training Loss: 7.920e-01, Validation Loss: 9.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13531, Training Loss: 7.919e-01, Validation Loss: 9.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13532, Training Loss: 7.919e-01, Validation Loss: 9.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13533, Training Loss: 7.918e-01, Validation Loss: 9.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13534, Training Loss: 7.918e-01, Validation Loss: 9.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13535, Training Loss: 7.917e-01, Validation Loss: 9.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13536, Training Loss: 7.917e-01, Validation Loss: 9.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13537, Training Loss: 7.916e-01, Validation Loss: 9.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13538, Training Loss: 7.916e-01, Validation Loss: 9.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13539, Training Loss: 7.915e-01, Validation Loss: 9.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13540, Training Loss: 7.914e-01, Validation Loss: 9.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13541, Training Loss: 7.914e-01, Validation Loss: 9.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13542, Training Loss: 7.913e-01, Validation Loss: 9.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13543, Training Loss: 7.913e-01, Validation Loss: 9.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13544, Training Loss: 7.912e-01, Validation Loss: 9.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13545, Training Loss: 7.912e-01, Validation Loss: 9.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13546, Training Loss: 7.911e-01, Validation Loss: 9.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13547, Training Loss: 7.911e-01, Validation Loss: 9.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13548, Training Loss: 7.910e-01, Validation Loss: 9.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13549, Training Loss: 7.910e-01, Validation Loss: 9.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13550, Training Loss: 7.909e-01, Validation Loss: 9.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13551, Training Loss: 7.908e-01, Validation Loss: 9.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13552, Training Loss: 7.908e-01, Validation Loss: 9.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13553, Training Loss: 7.907e-01, Validation Loss: 9.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13554, Training Loss: 7.907e-01, Validation Loss: 9.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13555, Training Loss: 7.906e-01, Validation Loss: 9.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13556, Training Loss: 7.906e-01, Validation Loss: 9.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13557, Training Loss: 7.905e-01, Validation Loss: 9.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13558, Training Loss: 7.905e-01, Validation Loss: 9.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13559, Training Loss: 7.904e-01, Validation Loss: 9.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13560, Training Loss: 7.904e-01, Validation Loss: 9.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13561, Training Loss: 7.903e-01, Validation Loss: 9.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13562, Training Loss: 7.902e-01, Validation Loss: 9.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13563, Training Loss: 7.902e-01, Validation Loss: 9.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13564, Training Loss: 7.901e-01, Validation Loss: 9.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13565, Training Loss: 7.901e-01, Validation Loss: 9.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13566, Training Loss: 7.900e-01, Validation Loss: 9.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13567, Training Loss: 7.900e-01, Validation Loss: 9.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13568, Training Loss: 7.899e-01, Validation Loss: 9.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13569, Training Loss: 7.899e-01, Validation Loss: 9.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13570, Training Loss: 7.898e-01, Validation Loss: 9.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13571, Training Loss: 7.898e-01, Validation Loss: 9.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13572, Training Loss: 7.897e-01, Validation Loss: 9.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13573, Training Loss: 7.897e-01, Validation Loss: 9.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13574, Training Loss: 7.896e-01, Validation Loss: 9.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13575, Training Loss: 7.895e-01, Validation Loss: 9.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13576, Training Loss: 7.895e-01, Validation Loss: 9.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13577, Training Loss: 7.894e-01, Validation Loss: 9.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13578, Training Loss: 7.894e-01, Validation Loss: 9.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13579, Training Loss: 7.893e-01, Validation Loss: 9.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13580, Training Loss: 7.893e-01, Validation Loss: 9.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13581, Training Loss: 7.892e-01, Validation Loss: 9.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13582, Training Loss: 7.892e-01, Validation Loss: 9.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13583, Training Loss: 7.891e-01, Validation Loss: 9.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13584, Training Loss: 7.891e-01, Validation Loss: 9.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13585, Training Loss: 7.890e-01, Validation Loss: 9.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13586, Training Loss: 7.890e-01, Validation Loss: 9.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13587, Training Loss: 7.889e-01, Validation Loss: 9.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13588, Training Loss: 7.888e-01, Validation Loss: 9.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13589, Training Loss: 7.888e-01, Validation Loss: 9.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13590, Training Loss: 7.887e-01, Validation Loss: 9.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13591, Training Loss: 7.887e-01, Validation Loss: 9.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13592, Training Loss: 7.886e-01, Validation Loss: 9.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13593, Training Loss: 7.886e-01, Validation Loss: 9.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13594, Training Loss: 7.885e-01, Validation Loss: 9.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13595, Training Loss: 7.885e-01, Validation Loss: 9.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13596, Training Loss: 7.884e-01, Validation Loss: 9.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13597, Training Loss: 7.884e-01, Validation Loss: 9.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13598, Training Loss: 7.883e-01, Validation Loss: 9.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13599, Training Loss: 7.882e-01, Validation Loss: 9.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13600, Training Loss: 7.882e-01, Validation Loss: 9.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13601, Training Loss: 7.881e-01, Validation Loss: 9.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13602, Training Loss: 7.881e-01, Validation Loss: 9.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13603, Training Loss: 7.880e-01, Validation Loss: 9.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13604, Training Loss: 7.880e-01, Validation Loss: 9.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13605, Training Loss: 7.879e-01, Validation Loss: 9.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13606, Training Loss: 7.879e-01, Validation Loss: 9.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13607, Training Loss: 7.878e-01, Validation Loss: 9.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13608, Training Loss: 7.878e-01, Validation Loss: 9.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13609, Training Loss: 7.877e-01, Validation Loss: 9.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13610, Training Loss: 7.877e-01, Validation Loss: 9.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13611, Training Loss: 7.876e-01, Validation Loss: 9.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13612, Training Loss: 7.875e-01, Validation Loss: 9.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13613, Training Loss: 7.875e-01, Validation Loss: 9.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13614, Training Loss: 7.874e-01, Validation Loss: 9.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13615, Training Loss: 7.874e-01, Validation Loss: 9.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13616, Training Loss: 7.873e-01, Validation Loss: 9.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13617, Training Loss: 7.873e-01, Validation Loss: 9.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13618, Training Loss: 7.872e-01, Validation Loss: 9.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13619, Training Loss: 7.872e-01, Validation Loss: 9.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13620, Training Loss: 7.871e-01, Validation Loss: 9.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13621, Training Loss: 7.871e-01, Validation Loss: 9.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13622, Training Loss: 7.870e-01, Validation Loss: 9.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13623, Training Loss: 7.870e-01, Validation Loss: 9.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13624, Training Loss: 7.869e-01, Validation Loss: 9.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13625, Training Loss: 7.869e-01, Validation Loss: 9.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13626, Training Loss: 7.868e-01, Validation Loss: 9.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13627, Training Loss: 7.867e-01, Validation Loss: 9.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13628, Training Loss: 7.867e-01, Validation Loss: 9.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13629, Training Loss: 7.866e-01, Validation Loss: 9.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13630, Training Loss: 7.866e-01, Validation Loss: 9.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13631, Training Loss: 7.865e-01, Validation Loss: 9.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13632, Training Loss: 7.865e-01, Validation Loss: 9.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13633, Training Loss: 7.864e-01, Validation Loss: 9.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13634, Training Loss: 7.864e-01, Validation Loss: 9.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13635, Training Loss: 7.863e-01, Validation Loss: 9.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13636, Training Loss: 7.863e-01, Validation Loss: 9.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13637, Training Loss: 7.862e-01, Validation Loss: 9.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13638, Training Loss: 7.862e-01, Validation Loss: 9.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13639, Training Loss: 7.861e-01, Validation Loss: 9.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13640, Training Loss: 7.860e-01, Validation Loss: 9.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13641, Training Loss: 7.860e-01, Validation Loss: 9.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13642, Training Loss: 7.859e-01, Validation Loss: 9.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13643, Training Loss: 7.859e-01, Validation Loss: 9.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13644, Training Loss: 7.858e-01, Validation Loss: 9.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13645, Training Loss: 7.858e-01, Validation Loss: 9.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13646, Training Loss: 7.857e-01, Validation Loss: 9.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13647, Training Loss: 7.857e-01, Validation Loss: 9.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13648, Training Loss: 7.856e-01, Validation Loss: 9.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13649, Training Loss: 7.856e-01, Validation Loss: 9.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13650, Training Loss: 7.855e-01, Validation Loss: 9.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13651, Training Loss: 7.855e-01, Validation Loss: 9.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13652, Training Loss: 7.854e-01, Validation Loss: 9.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13653, Training Loss: 7.853e-01, Validation Loss: 9.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13654, Training Loss: 7.853e-01, Validation Loss: 9.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13655, Training Loss: 7.852e-01, Validation Loss: 9.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13656, Training Loss: 7.852e-01, Validation Loss: 9.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13657, Training Loss: 7.851e-01, Validation Loss: 9.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13658, Training Loss: 7.851e-01, Validation Loss: 9.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13659, Training Loss: 7.850e-01, Validation Loss: 9.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13660, Training Loss: 7.850e-01, Validation Loss: 9.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13661, Training Loss: 7.849e-01, Validation Loss: 9.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13662, Training Loss: 7.849e-01, Validation Loss: 9.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13663, Training Loss: 7.848e-01, Validation Loss: 9.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13664, Training Loss: 7.848e-01, Validation Loss: 9.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13665, Training Loss: 7.847e-01, Validation Loss: 9.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13666, Training Loss: 7.847e-01, Validation Loss: 9.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13667, Training Loss: 7.846e-01, Validation Loss: 9.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13668, Training Loss: 7.845e-01, Validation Loss: 9.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13669, Training Loss: 7.845e-01, Validation Loss: 9.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13670, Training Loss: 7.844e-01, Validation Loss: 9.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13671, Training Loss: 7.844e-01, Validation Loss: 9.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13672, Training Loss: 7.843e-01, Validation Loss: 9.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13673, Training Loss: 7.843e-01, Validation Loss: 9.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13674, Training Loss: 7.842e-01, Validation Loss: 9.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13675, Training Loss: 7.842e-01, Validation Loss: 9.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13676, Training Loss: 7.841e-01, Validation Loss: 9.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13677, Training Loss: 7.841e-01, Validation Loss: 9.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13678, Training Loss: 7.840e-01, Validation Loss: 9.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13679, Training Loss: 7.840e-01, Validation Loss: 9.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13680, Training Loss: 7.839e-01, Validation Loss: 9.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13681, Training Loss: 7.838e-01, Validation Loss: 9.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13682, Training Loss: 7.838e-01, Validation Loss: 9.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13683, Training Loss: 7.837e-01, Validation Loss: 9.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13684, Training Loss: 7.837e-01, Validation Loss: 9.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13685, Training Loss: 7.836e-01, Validation Loss: 9.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13686, Training Loss: 7.836e-01, Validation Loss: 9.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13687, Training Loss: 7.835e-01, Validation Loss: 9.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13688, Training Loss: 7.835e-01, Validation Loss: 9.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13689, Training Loss: 7.834e-01, Validation Loss: 9.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13690, Training Loss: 7.834e-01, Validation Loss: 9.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13691, Training Loss: 7.833e-01, Validation Loss: 9.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13692, Training Loss: 7.833e-01, Validation Loss: 9.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13693, Training Loss: 7.832e-01, Validation Loss: 9.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13694, Training Loss: 7.832e-01, Validation Loss: 9.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13695, Training Loss: 7.831e-01, Validation Loss: 9.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13696, Training Loss: 7.830e-01, Validation Loss: 9.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13697, Training Loss: 7.830e-01, Validation Loss: 9.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13698, Training Loss: 7.829e-01, Validation Loss: 9.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13699, Training Loss: 7.829e-01, Validation Loss: 9.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13700, Training Loss: 7.828e-01, Validation Loss: 9.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13701, Training Loss: 7.828e-01, Validation Loss: 9.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13702, Training Loss: 7.827e-01, Validation Loss: 9.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13703, Training Loss: 7.827e-01, Validation Loss: 9.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13704, Training Loss: 7.826e-01, Validation Loss: 9.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13705, Training Loss: 7.826e-01, Validation Loss: 9.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13706, Training Loss: 7.825e-01, Validation Loss: 9.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13707, Training Loss: 7.825e-01, Validation Loss: 9.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13708, Training Loss: 7.824e-01, Validation Loss: 9.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13709, Training Loss: 7.824e-01, Validation Loss: 9.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13710, Training Loss: 7.823e-01, Validation Loss: 9.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13711, Training Loss: 7.822e-01, Validation Loss: 9.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13712, Training Loss: 7.822e-01, Validation Loss: 9.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13713, Training Loss: 7.821e-01, Validation Loss: 9.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13714, Training Loss: 7.821e-01, Validation Loss: 9.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13715, Training Loss: 7.820e-01, Validation Loss: 9.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13716, Training Loss: 7.820e-01, Validation Loss: 9.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13717, Training Loss: 7.819e-01, Validation Loss: 9.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13718, Training Loss: 7.819e-01, Validation Loss: 9.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13719, Training Loss: 7.818e-01, Validation Loss: 9.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13720, Training Loss: 7.818e-01, Validation Loss: 9.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13721, Training Loss: 7.817e-01, Validation Loss: 9.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13722, Training Loss: 7.817e-01, Validation Loss: 9.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13723, Training Loss: 7.816e-01, Validation Loss: 9.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13724, Training Loss: 7.816e-01, Validation Loss: 9.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13725, Training Loss: 7.815e-01, Validation Loss: 9.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13726, Training Loss: 7.815e-01, Validation Loss: 9.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13727, Training Loss: 7.814e-01, Validation Loss: 9.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13728, Training Loss: 7.813e-01, Validation Loss: 9.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13729, Training Loss: 7.813e-01, Validation Loss: 9.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13730, Training Loss: 7.812e-01, Validation Loss: 9.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13731, Training Loss: 7.812e-01, Validation Loss: 9.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13732, Training Loss: 7.811e-01, Validation Loss: 9.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13733, Training Loss: 7.811e-01, Validation Loss: 9.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13734, Training Loss: 7.810e-01, Validation Loss: 9.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13735, Training Loss: 7.810e-01, Validation Loss: 9.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13736, Training Loss: 7.809e-01, Validation Loss: 9.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13737, Training Loss: 7.809e-01, Validation Loss: 9.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13738, Training Loss: 7.808e-01, Validation Loss: 9.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13739, Training Loss: 7.808e-01, Validation Loss: 9.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13740, Training Loss: 7.807e-01, Validation Loss: 9.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13741, Training Loss: 7.807e-01, Validation Loss: 9.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13742, Training Loss: 7.806e-01, Validation Loss: 9.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13743, Training Loss: 7.805e-01, Validation Loss: 9.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13744, Training Loss: 7.805e-01, Validation Loss: 9.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13745, Training Loss: 7.804e-01, Validation Loss: 8.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13746, Training Loss: 7.804e-01, Validation Loss: 8.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13747, Training Loss: 7.803e-01, Validation Loss: 8.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13748, Training Loss: 7.803e-01, Validation Loss: 8.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13749, Training Loss: 7.802e-01, Validation Loss: 8.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13750, Training Loss: 7.802e-01, Validation Loss: 8.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13751, Training Loss: 7.801e-01, Validation Loss: 8.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13752, Training Loss: 7.801e-01, Validation Loss: 8.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13753, Training Loss: 7.800e-01, Validation Loss: 8.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13754, Training Loss: 7.800e-01, Validation Loss: 8.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13755, Training Loss: 7.799e-01, Validation Loss: 8.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13756, Training Loss: 7.799e-01, Validation Loss: 8.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13757, Training Loss: 7.798e-01, Validation Loss: 8.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13758, Training Loss: 7.798e-01, Validation Loss: 8.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13759, Training Loss: 7.797e-01, Validation Loss: 8.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13760, Training Loss: 7.796e-01, Validation Loss: 8.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13761, Training Loss: 7.796e-01, Validation Loss: 8.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13762, Training Loss: 7.795e-01, Validation Loss: 8.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13763, Training Loss: 7.795e-01, Validation Loss: 8.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13764, Training Loss: 7.794e-01, Validation Loss: 8.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13765, Training Loss: 7.794e-01, Validation Loss: 8.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13766, Training Loss: 7.793e-01, Validation Loss: 8.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13767, Training Loss: 7.793e-01, Validation Loss: 8.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13768, Training Loss: 7.792e-01, Validation Loss: 8.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13769, Training Loss: 7.792e-01, Validation Loss: 8.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13770, Training Loss: 7.791e-01, Validation Loss: 8.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13771, Training Loss: 7.791e-01, Validation Loss: 8.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13772, Training Loss: 7.790e-01, Validation Loss: 8.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13773, Training Loss: 7.790e-01, Validation Loss: 8.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13774, Training Loss: 7.789e-01, Validation Loss: 8.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13775, Training Loss: 7.788e-01, Validation Loss: 8.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13776, Training Loss: 7.788e-01, Validation Loss: 8.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13777, Training Loss: 7.787e-01, Validation Loss: 8.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13778, Training Loss: 7.787e-01, Validation Loss: 8.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13779, Training Loss: 7.786e-01, Validation Loss: 8.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13780, Training Loss: 7.786e-01, Validation Loss: 8.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13781, Training Loss: 7.785e-01, Validation Loss: 8.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13782, Training Loss: 7.785e-01, Validation Loss: 8.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13783, Training Loss: 7.784e-01, Validation Loss: 8.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13784, Training Loss: 7.784e-01, Validation Loss: 8.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13785, Training Loss: 7.783e-01, Validation Loss: 8.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13786, Training Loss: 7.783e-01, Validation Loss: 8.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13787, Training Loss: 7.782e-01, Validation Loss: 8.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13788, Training Loss: 7.782e-01, Validation Loss: 8.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13789, Training Loss: 7.781e-01, Validation Loss: 8.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13790, Training Loss: 7.781e-01, Validation Loss: 8.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13791, Training Loss: 7.780e-01, Validation Loss: 8.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13792, Training Loss: 7.779e-01, Validation Loss: 8.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13793, Training Loss: 7.779e-01, Validation Loss: 8.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13794, Training Loss: 7.778e-01, Validation Loss: 8.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13795, Training Loss: 7.778e-01, Validation Loss: 8.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13796, Training Loss: 7.777e-01, Validation Loss: 8.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13797, Training Loss: 7.777e-01, Validation Loss: 8.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13798, Training Loss: 7.776e-01, Validation Loss: 8.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13799, Training Loss: 7.776e-01, Validation Loss: 8.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13800, Training Loss: 7.775e-01, Validation Loss: 8.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13801, Training Loss: 7.775e-01, Validation Loss: 8.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13802, Training Loss: 7.774e-01, Validation Loss: 8.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13803, Training Loss: 7.774e-01, Validation Loss: 8.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13804, Training Loss: 7.773e-01, Validation Loss: 8.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13805, Training Loss: 7.773e-01, Validation Loss: 8.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13806, Training Loss: 7.772e-01, Validation Loss: 8.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13807, Training Loss: 7.772e-01, Validation Loss: 8.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13808, Training Loss: 7.771e-01, Validation Loss: 8.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13809, Training Loss: 7.771e-01, Validation Loss: 8.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13810, Training Loss: 7.770e-01, Validation Loss: 8.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13811, Training Loss: 7.769e-01, Validation Loss: 8.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13812, Training Loss: 7.769e-01, Validation Loss: 8.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13813, Training Loss: 7.768e-01, Validation Loss: 8.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13814, Training Loss: 7.768e-01, Validation Loss: 8.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13815, Training Loss: 7.767e-01, Validation Loss: 8.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13816, Training Loss: 7.767e-01, Validation Loss: 8.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13817, Training Loss: 7.766e-01, Validation Loss: 8.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13818, Training Loss: 7.766e-01, Validation Loss: 8.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13819, Training Loss: 7.765e-01, Validation Loss: 8.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13820, Training Loss: 7.765e-01, Validation Loss: 8.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13821, Training Loss: 7.764e-01, Validation Loss: 8.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13822, Training Loss: 7.764e-01, Validation Loss: 8.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13823, Training Loss: 7.763e-01, Validation Loss: 8.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13824, Training Loss: 7.763e-01, Validation Loss: 8.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13825, Training Loss: 7.762e-01, Validation Loss: 8.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13826, Training Loss: 7.762e-01, Validation Loss: 8.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13827, Training Loss: 7.761e-01, Validation Loss: 8.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13828, Training Loss: 7.760e-01, Validation Loss: 8.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13829, Training Loss: 7.760e-01, Validation Loss: 8.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13830, Training Loss: 7.759e-01, Validation Loss: 8.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13831, Training Loss: 7.759e-01, Validation Loss: 8.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13832, Training Loss: 7.758e-01, Validation Loss: 8.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13833, Training Loss: 7.758e-01, Validation Loss: 8.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13834, Training Loss: 7.757e-01, Validation Loss: 8.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13835, Training Loss: 7.757e-01, Validation Loss: 8.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13836, Training Loss: 7.756e-01, Validation Loss: 8.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13837, Training Loss: 7.756e-01, Validation Loss: 8.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13838, Training Loss: 7.755e-01, Validation Loss: 8.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13839, Training Loss: 7.755e-01, Validation Loss: 8.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13840, Training Loss: 7.754e-01, Validation Loss: 8.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13841, Training Loss: 7.754e-01, Validation Loss: 8.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13842, Training Loss: 7.753e-01, Validation Loss: 8.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13843, Training Loss: 7.753e-01, Validation Loss: 8.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13844, Training Loss: 7.752e-01, Validation Loss: 8.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13845, Training Loss: 7.752e-01, Validation Loss: 8.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13846, Training Loss: 7.751e-01, Validation Loss: 8.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13847, Training Loss: 7.750e-01, Validation Loss: 8.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13848, Training Loss: 7.750e-01, Validation Loss: 8.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13849, Training Loss: 7.749e-01, Validation Loss: 8.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13850, Training Loss: 7.749e-01, Validation Loss: 8.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13851, Training Loss: 7.748e-01, Validation Loss: 8.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13852, Training Loss: 7.748e-01, Validation Loss: 8.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13853, Training Loss: 7.747e-01, Validation Loss: 8.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13854, Training Loss: 7.747e-01, Validation Loss: 8.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13855, Training Loss: 7.746e-01, Validation Loss: 8.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13856, Training Loss: 7.746e-01, Validation Loss: 8.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13857, Training Loss: 7.745e-01, Validation Loss: 8.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13858, Training Loss: 7.745e-01, Validation Loss: 8.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13859, Training Loss: 7.744e-01, Validation Loss: 8.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13860, Training Loss: 7.744e-01, Validation Loss: 8.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13861, Training Loss: 7.743e-01, Validation Loss: 8.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13862, Training Loss: 7.743e-01, Validation Loss: 8.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13863, Training Loss: 7.742e-01, Validation Loss: 8.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13864, Training Loss: 7.742e-01, Validation Loss: 8.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13865, Training Loss: 7.741e-01, Validation Loss: 8.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13866, Training Loss: 7.740e-01, Validation Loss: 8.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13867, Training Loss: 7.740e-01, Validation Loss: 8.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13868, Training Loss: 7.739e-01, Validation Loss: 8.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13869, Training Loss: 7.739e-01, Validation Loss: 8.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13870, Training Loss: 7.738e-01, Validation Loss: 8.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13871, Training Loss: 7.738e-01, Validation Loss: 8.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13872, Training Loss: 7.737e-01, Validation Loss: 8.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13873, Training Loss: 7.737e-01, Validation Loss: 8.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13874, Training Loss: 7.736e-01, Validation Loss: 8.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13875, Training Loss: 7.736e-01, Validation Loss: 8.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13876, Training Loss: 7.735e-01, Validation Loss: 8.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13877, Training Loss: 7.735e-01, Validation Loss: 8.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13878, Training Loss: 7.734e-01, Validation Loss: 8.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13879, Training Loss: 7.734e-01, Validation Loss: 8.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13880, Training Loss: 7.733e-01, Validation Loss: 8.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13881, Training Loss: 7.733e-01, Validation Loss: 8.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13882, Training Loss: 7.732e-01, Validation Loss: 8.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13883, Training Loss: 7.732e-01, Validation Loss: 8.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13884, Training Loss: 7.731e-01, Validation Loss: 8.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13885, Training Loss: 7.730e-01, Validation Loss: 8.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13886, Training Loss: 7.730e-01, Validation Loss: 8.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13887, Training Loss: 7.729e-01, Validation Loss: 8.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13888, Training Loss: 7.729e-01, Validation Loss: 8.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13889, Training Loss: 7.728e-01, Validation Loss: 8.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13890, Training Loss: 7.728e-01, Validation Loss: 8.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13891, Training Loss: 7.727e-01, Validation Loss: 8.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13892, Training Loss: 7.727e-01, Validation Loss: 8.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13893, Training Loss: 7.726e-01, Validation Loss: 8.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13894, Training Loss: 7.726e-01, Validation Loss: 8.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13895, Training Loss: 7.725e-01, Validation Loss: 8.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13896, Training Loss: 7.725e-01, Validation Loss: 8.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13897, Training Loss: 7.724e-01, Validation Loss: 8.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13898, Training Loss: 7.724e-01, Validation Loss: 8.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13899, Training Loss: 7.723e-01, Validation Loss: 8.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13900, Training Loss: 7.723e-01, Validation Loss: 8.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13901, Training Loss: 7.722e-01, Validation Loss: 8.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13902, Training Loss: 7.722e-01, Validation Loss: 8.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13903, Training Loss: 7.721e-01, Validation Loss: 8.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13904, Training Loss: 7.721e-01, Validation Loss: 8.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13905, Training Loss: 7.720e-01, Validation Loss: 8.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13906, Training Loss: 7.720e-01, Validation Loss: 8.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13907, Training Loss: 7.719e-01, Validation Loss: 8.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13908, Training Loss: 7.718e-01, Validation Loss: 8.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13909, Training Loss: 7.718e-01, Validation Loss: 8.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13910, Training Loss: 7.717e-01, Validation Loss: 8.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13911, Training Loss: 7.717e-01, Validation Loss: 8.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13912, Training Loss: 7.716e-01, Validation Loss: 8.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13913, Training Loss: 7.716e-01, Validation Loss: 8.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13914, Training Loss: 7.715e-01, Validation Loss: 8.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13915, Training Loss: 7.715e-01, Validation Loss: 8.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13916, Training Loss: 7.714e-01, Validation Loss: 8.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13917, Training Loss: 7.714e-01, Validation Loss: 8.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13918, Training Loss: 7.713e-01, Validation Loss: 8.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13919, Training Loss: 7.713e-01, Validation Loss: 8.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13920, Training Loss: 7.712e-01, Validation Loss: 8.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13921, Training Loss: 7.712e-01, Validation Loss: 8.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13922, Training Loss: 7.711e-01, Validation Loss: 8.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13923, Training Loss: 7.711e-01, Validation Loss: 8.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13924, Training Loss: 7.710e-01, Validation Loss: 8.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13925, Training Loss: 7.710e-01, Validation Loss: 8.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13926, Training Loss: 7.709e-01, Validation Loss: 8.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13927, Training Loss: 7.709e-01, Validation Loss: 8.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13928, Training Loss: 7.708e-01, Validation Loss: 8.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13929, Training Loss: 7.708e-01, Validation Loss: 8.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13930, Training Loss: 7.707e-01, Validation Loss: 8.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13931, Training Loss: 7.706e-01, Validation Loss: 8.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13932, Training Loss: 7.706e-01, Validation Loss: 8.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13933, Training Loss: 7.705e-01, Validation Loss: 8.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13934, Training Loss: 7.705e-01, Validation Loss: 8.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13935, Training Loss: 7.704e-01, Validation Loss: 8.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13936, Training Loss: 7.704e-01, Validation Loss: 8.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13937, Training Loss: 7.703e-01, Validation Loss: 8.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13938, Training Loss: 7.703e-01, Validation Loss: 8.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13939, Training Loss: 7.702e-01, Validation Loss: 8.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13940, Training Loss: 7.702e-01, Validation Loss: 8.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13941, Training Loss: 7.701e-01, Validation Loss: 8.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13942, Training Loss: 7.701e-01, Validation Loss: 8.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13943, Training Loss: 7.700e-01, Validation Loss: 8.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13944, Training Loss: 7.700e-01, Validation Loss: 8.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13945, Training Loss: 7.699e-01, Validation Loss: 8.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13946, Training Loss: 7.699e-01, Validation Loss: 8.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13947, Training Loss: 7.698e-01, Validation Loss: 8.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13948, Training Loss: 7.698e-01, Validation Loss: 8.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13949, Training Loss: 7.697e-01, Validation Loss: 8.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13950, Training Loss: 7.697e-01, Validation Loss: 8.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13951, Training Loss: 7.696e-01, Validation Loss: 8.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13952, Training Loss: 7.696e-01, Validation Loss: 8.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13953, Training Loss: 7.695e-01, Validation Loss: 8.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13954, Training Loss: 7.694e-01, Validation Loss: 8.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13955, Training Loss: 7.694e-01, Validation Loss: 8.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13956, Training Loss: 7.693e-01, Validation Loss: 8.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13957, Training Loss: 7.693e-01, Validation Loss: 8.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13958, Training Loss: 7.692e-01, Validation Loss: 8.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13959, Training Loss: 7.692e-01, Validation Loss: 8.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13960, Training Loss: 7.691e-01, Validation Loss: 8.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13961, Training Loss: 7.691e-01, Validation Loss: 8.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13962, Training Loss: 7.690e-01, Validation Loss: 8.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13963, Training Loss: 7.690e-01, Validation Loss: 8.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13964, Training Loss: 7.689e-01, Validation Loss: 8.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13965, Training Loss: 7.689e-01, Validation Loss: 8.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13966, Training Loss: 7.688e-01, Validation Loss: 8.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13967, Training Loss: 7.688e-01, Validation Loss: 8.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13968, Training Loss: 7.687e-01, Validation Loss: 8.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13969, Training Loss: 7.687e-01, Validation Loss: 8.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13970, Training Loss: 7.686e-01, Validation Loss: 8.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13971, Training Loss: 7.686e-01, Validation Loss: 8.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13972, Training Loss: 7.685e-01, Validation Loss: 8.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13973, Training Loss: 7.685e-01, Validation Loss: 8.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13974, Training Loss: 7.684e-01, Validation Loss: 8.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13975, Training Loss: 7.684e-01, Validation Loss: 8.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13976, Training Loss: 7.683e-01, Validation Loss: 8.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13977, Training Loss: 7.683e-01, Validation Loss: 8.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13978, Training Loss: 7.682e-01, Validation Loss: 8.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13979, Training Loss: 7.682e-01, Validation Loss: 8.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13980, Training Loss: 7.681e-01, Validation Loss: 8.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13981, Training Loss: 7.680e-01, Validation Loss: 8.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13982, Training Loss: 7.680e-01, Validation Loss: 8.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13983, Training Loss: 7.679e-01, Validation Loss: 8.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13984, Training Loss: 7.679e-01, Validation Loss: 8.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13985, Training Loss: 7.678e-01, Validation Loss: 8.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13986, Training Loss: 7.678e-01, Validation Loss: 8.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13987, Training Loss: 7.677e-01, Validation Loss: 8.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13988, Training Loss: 7.677e-01, Validation Loss: 8.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13989, Training Loss: 7.676e-01, Validation Loss: 8.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13990, Training Loss: 7.676e-01, Validation Loss: 8.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13991, Training Loss: 7.675e-01, Validation Loss: 8.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13992, Training Loss: 7.675e-01, Validation Loss: 8.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13993, Training Loss: 7.674e-01, Validation Loss: 8.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13994, Training Loss: 7.674e-01, Validation Loss: 8.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13995, Training Loss: 7.673e-01, Validation Loss: 8.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13996, Training Loss: 7.673e-01, Validation Loss: 8.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13997, Training Loss: 7.672e-01, Validation Loss: 8.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13998, Training Loss: 7.672e-01, Validation Loss: 8.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13999, Training Loss: 7.671e-01, Validation Loss: 8.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14000, Training Loss: 7.671e-01, Validation Loss: 8.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14001, Training Loss: 7.670e-01, Validation Loss: 8.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14002, Training Loss: 7.670e-01, Validation Loss: 8.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14003, Training Loss: 7.669e-01, Validation Loss: 8.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14004, Training Loss: 7.669e-01, Validation Loss: 8.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14005, Training Loss: 7.668e-01, Validation Loss: 8.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14006, Training Loss: 7.668e-01, Validation Loss: 8.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14007, Training Loss: 7.667e-01, Validation Loss: 8.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14008, Training Loss: 7.667e-01, Validation Loss: 8.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14009, Training Loss: 7.666e-01, Validation Loss: 8.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14010, Training Loss: 7.665e-01, Validation Loss: 8.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14011, Training Loss: 7.665e-01, Validation Loss: 8.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14012, Training Loss: 7.664e-01, Validation Loss: 8.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14013, Training Loss: 7.664e-01, Validation Loss: 8.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14014, Training Loss: 7.663e-01, Validation Loss: 8.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14015, Training Loss: 7.663e-01, Validation Loss: 8.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14016, Training Loss: 7.662e-01, Validation Loss: 8.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14017, Training Loss: 7.662e-01, Validation Loss: 8.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14018, Training Loss: 7.661e-01, Validation Loss: 8.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14019, Training Loss: 7.661e-01, Validation Loss: 8.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14020, Training Loss: 7.660e-01, Validation Loss: 8.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14021, Training Loss: 7.660e-01, Validation Loss: 8.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14022, Training Loss: 7.659e-01, Validation Loss: 8.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14023, Training Loss: 7.659e-01, Validation Loss: 8.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14024, Training Loss: 7.658e-01, Validation Loss: 8.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14025, Training Loss: 7.658e-01, Validation Loss: 8.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14026, Training Loss: 7.657e-01, Validation Loss: 8.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14027, Training Loss: 7.657e-01, Validation Loss: 8.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14028, Training Loss: 7.656e-01, Validation Loss: 8.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14029, Training Loss: 7.656e-01, Validation Loss: 8.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14030, Training Loss: 7.655e-01, Validation Loss: 8.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14031, Training Loss: 7.655e-01, Validation Loss: 8.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14032, Training Loss: 7.654e-01, Validation Loss: 8.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14033, Training Loss: 7.654e-01, Validation Loss: 8.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14034, Training Loss: 7.653e-01, Validation Loss: 8.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14035, Training Loss: 7.653e-01, Validation Loss: 8.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14036, Training Loss: 7.652e-01, Validation Loss: 8.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14037, Training Loss: 7.652e-01, Validation Loss: 8.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14038, Training Loss: 7.651e-01, Validation Loss: 8.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14039, Training Loss: 7.651e-01, Validation Loss: 8.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14040, Training Loss: 7.650e-01, Validation Loss: 8.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14041, Training Loss: 7.650e-01, Validation Loss: 8.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14042, Training Loss: 7.649e-01, Validation Loss: 8.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14043, Training Loss: 7.648e-01, Validation Loss: 8.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14044, Training Loss: 7.648e-01, Validation Loss: 8.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14045, Training Loss: 7.647e-01, Validation Loss: 8.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14046, Training Loss: 7.647e-01, Validation Loss: 8.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14047, Training Loss: 7.646e-01, Validation Loss: 8.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14048, Training Loss: 7.646e-01, Validation Loss: 8.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14049, Training Loss: 7.645e-01, Validation Loss: 8.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14050, Training Loss: 7.645e-01, Validation Loss: 8.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14051, Training Loss: 7.644e-01, Validation Loss: 8.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14052, Training Loss: 7.644e-01, Validation Loss: 8.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14053, Training Loss: 7.643e-01, Validation Loss: 8.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14054, Training Loss: 7.643e-01, Validation Loss: 8.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14055, Training Loss: 7.642e-01, Validation Loss: 8.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14056, Training Loss: 7.642e-01, Validation Loss: 8.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14057, Training Loss: 7.641e-01, Validation Loss: 8.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14058, Training Loss: 7.641e-01, Validation Loss: 8.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14059, Training Loss: 7.640e-01, Validation Loss: 8.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14060, Training Loss: 7.640e-01, Validation Loss: 8.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14061, Training Loss: 7.639e-01, Validation Loss: 8.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14062, Training Loss: 7.639e-01, Validation Loss: 8.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14063, Training Loss: 7.638e-01, Validation Loss: 8.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14064, Training Loss: 7.638e-01, Validation Loss: 8.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14065, Training Loss: 7.637e-01, Validation Loss: 8.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14066, Training Loss: 7.637e-01, Validation Loss: 8.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14067, Training Loss: 7.636e-01, Validation Loss: 8.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14068, Training Loss: 7.636e-01, Validation Loss: 8.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14069, Training Loss: 7.635e-01, Validation Loss: 8.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14070, Training Loss: 7.635e-01, Validation Loss: 8.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14071, Training Loss: 7.634e-01, Validation Loss: 8.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14072, Training Loss: 7.634e-01, Validation Loss: 8.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14073, Training Loss: 7.633e-01, Validation Loss: 8.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14074, Training Loss: 7.633e-01, Validation Loss: 8.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14075, Training Loss: 7.632e-01, Validation Loss: 8.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14076, Training Loss: 7.632e-01, Validation Loss: 8.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14077, Training Loss: 7.631e-01, Validation Loss: 8.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14078, Training Loss: 7.631e-01, Validation Loss: 8.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14079, Training Loss: 7.630e-01, Validation Loss: 8.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14080, Training Loss: 7.630e-01, Validation Loss: 8.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14081, Training Loss: 7.629e-01, Validation Loss: 8.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14082, Training Loss: 7.629e-01, Validation Loss: 8.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14083, Training Loss: 7.628e-01, Validation Loss: 8.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14084, Training Loss: 7.627e-01, Validation Loss: 8.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14085, Training Loss: 7.627e-01, Validation Loss: 8.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14086, Training Loss: 7.626e-01, Validation Loss: 8.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14087, Training Loss: 7.626e-01, Validation Loss: 8.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14088, Training Loss: 7.625e-01, Validation Loss: 8.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14089, Training Loss: 7.625e-01, Validation Loss: 8.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14090, Training Loss: 7.624e-01, Validation Loss: 8.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14091, Training Loss: 7.624e-01, Validation Loss: 8.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14092, Training Loss: 7.623e-01, Validation Loss: 8.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14093, Training Loss: 7.623e-01, Validation Loss: 8.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14094, Training Loss: 7.622e-01, Validation Loss: 8.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14095, Training Loss: 7.622e-01, Validation Loss: 8.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14096, Training Loss: 7.621e-01, Validation Loss: 8.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14097, Training Loss: 7.621e-01, Validation Loss: 8.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14098, Training Loss: 7.620e-01, Validation Loss: 8.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14099, Training Loss: 7.620e-01, Validation Loss: 8.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14100, Training Loss: 7.619e-01, Validation Loss: 8.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14101, Training Loss: 7.619e-01, Validation Loss: 8.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14102, Training Loss: 7.618e-01, Validation Loss: 8.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14103, Training Loss: 7.618e-01, Validation Loss: 8.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14104, Training Loss: 7.617e-01, Validation Loss: 8.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14105, Training Loss: 7.617e-01, Validation Loss: 8.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14106, Training Loss: 7.616e-01, Validation Loss: 8.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14107, Training Loss: 7.616e-01, Validation Loss: 8.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14108, Training Loss: 7.615e-01, Validation Loss: 8.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14109, Training Loss: 7.615e-01, Validation Loss: 8.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14110, Training Loss: 7.614e-01, Validation Loss: 8.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14111, Training Loss: 7.614e-01, Validation Loss: 8.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14112, Training Loss: 7.613e-01, Validation Loss: 8.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14113, Training Loss: 7.613e-01, Validation Loss: 8.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14114, Training Loss: 7.612e-01, Validation Loss: 8.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14115, Training Loss: 7.612e-01, Validation Loss: 8.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14116, Training Loss: 7.611e-01, Validation Loss: 8.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14117, Training Loss: 7.611e-01, Validation Loss: 8.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14118, Training Loss: 7.610e-01, Validation Loss: 8.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14119, Training Loss: 7.610e-01, Validation Loss: 8.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14120, Training Loss: 7.609e-01, Validation Loss: 8.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14121, Training Loss: 7.609e-01, Validation Loss: 8.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14122, Training Loss: 7.608e-01, Validation Loss: 8.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14123, Training Loss: 7.608e-01, Validation Loss: 8.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14124, Training Loss: 7.607e-01, Validation Loss: 8.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14125, Training Loss: 7.607e-01, Validation Loss: 8.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14126, Training Loss: 7.606e-01, Validation Loss: 8.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14127, Training Loss: 7.606e-01, Validation Loss: 8.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14128, Training Loss: 7.605e-01, Validation Loss: 8.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14129, Training Loss: 7.605e-01, Validation Loss: 8.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14130, Training Loss: 7.604e-01, Validation Loss: 8.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14131, Training Loss: 7.604e-01, Validation Loss: 8.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14132, Training Loss: 7.603e-01, Validation Loss: 8.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14133, Training Loss: 7.603e-01, Validation Loss: 8.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14134, Training Loss: 7.602e-01, Validation Loss: 8.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14135, Training Loss: 7.602e-01, Validation Loss: 8.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14136, Training Loss: 7.601e-01, Validation Loss: 8.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14137, Training Loss: 7.600e-01, Validation Loss: 8.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14138, Training Loss: 7.600e-01, Validation Loss: 8.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14139, Training Loss: 7.599e-01, Validation Loss: 8.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14140, Training Loss: 7.599e-01, Validation Loss: 8.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14141, Training Loss: 7.598e-01, Validation Loss: 8.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14142, Training Loss: 7.598e-01, Validation Loss: 8.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14143, Training Loss: 7.597e-01, Validation Loss: 8.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14144, Training Loss: 7.597e-01, Validation Loss: 8.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14145, Training Loss: 7.596e-01, Validation Loss: 8.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14146, Training Loss: 7.596e-01, Validation Loss: 8.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14147, Training Loss: 7.595e-01, Validation Loss: 8.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14148, Training Loss: 7.595e-01, Validation Loss: 8.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14149, Training Loss: 7.594e-01, Validation Loss: 8.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14150, Training Loss: 7.594e-01, Validation Loss: 8.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14151, Training Loss: 7.593e-01, Validation Loss: 8.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14152, Training Loss: 7.593e-01, Validation Loss: 8.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14153, Training Loss: 7.592e-01, Validation Loss: 8.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14154, Training Loss: 7.592e-01, Validation Loss: 8.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14155, Training Loss: 7.591e-01, Validation Loss: 8.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14156, Training Loss: 7.591e-01, Validation Loss: 8.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14157, Training Loss: 7.590e-01, Validation Loss: 8.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14158, Training Loss: 7.590e-01, Validation Loss: 8.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14159, Training Loss: 7.589e-01, Validation Loss: 8.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14160, Training Loss: 7.589e-01, Validation Loss: 8.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14161, Training Loss: 7.588e-01, Validation Loss: 8.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14162, Training Loss: 7.588e-01, Validation Loss: 8.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14163, Training Loss: 7.587e-01, Validation Loss: 8.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14164, Training Loss: 7.587e-01, Validation Loss: 8.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14165, Training Loss: 7.586e-01, Validation Loss: 8.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14166, Training Loss: 7.586e-01, Validation Loss: 8.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14167, Training Loss: 7.585e-01, Validation Loss: 8.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14168, Training Loss: 7.585e-01, Validation Loss: 8.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14169, Training Loss: 7.584e-01, Validation Loss: 8.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14170, Training Loss: 7.584e-01, Validation Loss: 8.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14171, Training Loss: 7.583e-01, Validation Loss: 8.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14172, Training Loss: 7.583e-01, Validation Loss: 8.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14173, Training Loss: 7.582e-01, Validation Loss: 8.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14174, Training Loss: 7.582e-01, Validation Loss: 8.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14175, Training Loss: 7.581e-01, Validation Loss: 8.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14176, Training Loss: 7.581e-01, Validation Loss: 8.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14177, Training Loss: 7.580e-01, Validation Loss: 8.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14178, Training Loss: 7.580e-01, Validation Loss: 8.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14179, Training Loss: 7.579e-01, Validation Loss: 8.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14180, Training Loss: 7.579e-01, Validation Loss: 8.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14181, Training Loss: 7.578e-01, Validation Loss: 8.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14182, Training Loss: 7.578e-01, Validation Loss: 8.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14183, Training Loss: 7.577e-01, Validation Loss: 8.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14184, Training Loss: 7.577e-01, Validation Loss: 8.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14185, Training Loss: 7.576e-01, Validation Loss: 8.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14186, Training Loss: 7.576e-01, Validation Loss: 8.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14187, Training Loss: 7.575e-01, Validation Loss: 8.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14188, Training Loss: 7.575e-01, Validation Loss: 8.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14189, Training Loss: 7.574e-01, Validation Loss: 8.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14190, Training Loss: 7.574e-01, Validation Loss: 8.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14191, Training Loss: 7.573e-01, Validation Loss: 8.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14192, Training Loss: 7.573e-01, Validation Loss: 8.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14193, Training Loss: 7.572e-01, Validation Loss: 8.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14194, Training Loss: 7.572e-01, Validation Loss: 8.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14195, Training Loss: 7.571e-01, Validation Loss: 8.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14196, Training Loss: 7.571e-01, Validation Loss: 8.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14197, Training Loss: 7.570e-01, Validation Loss: 8.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14198, Training Loss: 7.570e-01, Validation Loss: 8.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14199, Training Loss: 7.569e-01, Validation Loss: 8.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14200, Training Loss: 7.569e-01, Validation Loss: 8.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14201, Training Loss: 7.568e-01, Validation Loss: 8.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14202, Training Loss: 7.568e-01, Validation Loss: 8.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14203, Training Loss: 7.567e-01, Validation Loss: 8.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14204, Training Loss: 7.567e-01, Validation Loss: 8.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14205, Training Loss: 7.566e-01, Validation Loss: 8.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14206, Training Loss: 7.566e-01, Validation Loss: 8.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14207, Training Loss: 7.565e-01, Validation Loss: 8.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14208, Training Loss: 7.565e-01, Validation Loss: 8.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14209, Training Loss: 7.564e-01, Validation Loss: 8.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14210, Training Loss: 7.564e-01, Validation Loss: 8.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14211, Training Loss: 7.563e-01, Validation Loss: 8.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14212, Training Loss: 7.563e-01, Validation Loss: 8.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14213, Training Loss: 7.562e-01, Validation Loss: 8.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14214, Training Loss: 7.562e-01, Validation Loss: 8.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14215, Training Loss: 7.561e-01, Validation Loss: 8.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14216, Training Loss: 7.561e-01, Validation Loss: 8.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14217, Training Loss: 7.560e-01, Validation Loss: 8.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14218, Training Loss: 7.560e-01, Validation Loss: 8.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14219, Training Loss: 7.559e-01, Validation Loss: 8.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14220, Training Loss: 7.559e-01, Validation Loss: 8.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14221, Training Loss: 7.558e-01, Validation Loss: 8.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14222, Training Loss: 7.558e-01, Validation Loss: 8.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14223, Training Loss: 7.557e-01, Validation Loss: 8.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14224, Training Loss: 7.557e-01, Validation Loss: 8.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14225, Training Loss: 7.556e-01, Validation Loss: 8.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14226, Training Loss: 7.556e-01, Validation Loss: 8.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14227, Training Loss: 7.555e-01, Validation Loss: 8.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14228, Training Loss: 7.555e-01, Validation Loss: 8.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14229, Training Loss: 7.554e-01, Validation Loss: 8.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14230, Training Loss: 7.554e-01, Validation Loss: 8.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14231, Training Loss: 7.553e-01, Validation Loss: 8.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14232, Training Loss: 7.553e-01, Validation Loss: 8.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14233, Training Loss: 7.552e-01, Validation Loss: 8.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14234, Training Loss: 7.551e-01, Validation Loss: 8.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14235, Training Loss: 7.551e-01, Validation Loss: 8.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14236, Training Loss: 7.550e-01, Validation Loss: 8.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14237, Training Loss: 7.550e-01, Validation Loss: 8.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14238, Training Loss: 7.549e-01, Validation Loss: 8.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14239, Training Loss: 7.549e-01, Validation Loss: 8.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14240, Training Loss: 7.548e-01, Validation Loss: 8.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14241, Training Loss: 7.548e-01, Validation Loss: 8.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14242, Training Loss: 7.547e-01, Validation Loss: 8.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14243, Training Loss: 7.547e-01, Validation Loss: 8.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14244, Training Loss: 7.546e-01, Validation Loss: 8.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14245, Training Loss: 7.546e-01, Validation Loss: 8.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14246, Training Loss: 7.545e-01, Validation Loss: 8.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14247, Training Loss: 7.545e-01, Validation Loss: 8.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14248, Training Loss: 7.544e-01, Validation Loss: 8.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14249, Training Loss: 7.544e-01, Validation Loss: 8.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14250, Training Loss: 7.543e-01, Validation Loss: 8.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14251, Training Loss: 7.543e-01, Validation Loss: 8.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14252, Training Loss: 7.542e-01, Validation Loss: 8.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14253, Training Loss: 7.542e-01, Validation Loss: 8.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14254, Training Loss: 7.541e-01, Validation Loss: 8.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14255, Training Loss: 7.541e-01, Validation Loss: 8.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14256, Training Loss: 7.540e-01, Validation Loss: 8.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14257, Training Loss: 7.540e-01, Validation Loss: 8.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14258, Training Loss: 7.539e-01, Validation Loss: 8.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14259, Training Loss: 7.539e-01, Validation Loss: 8.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14260, Training Loss: 7.538e-01, Validation Loss: 8.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14261, Training Loss: 7.538e-01, Validation Loss: 8.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14262, Training Loss: 7.537e-01, Validation Loss: 8.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14263, Training Loss: 7.537e-01, Validation Loss: 8.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14264, Training Loss: 7.536e-01, Validation Loss: 8.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14265, Training Loss: 7.536e-01, Validation Loss: 8.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14266, Training Loss: 7.535e-01, Validation Loss: 8.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14267, Training Loss: 7.535e-01, Validation Loss: 8.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14268, Training Loss: 7.534e-01, Validation Loss: 8.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14269, Training Loss: 7.534e-01, Validation Loss: 8.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14270, Training Loss: 7.533e-01, Validation Loss: 8.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14271, Training Loss: 7.533e-01, Validation Loss: 8.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14272, Training Loss: 7.532e-01, Validation Loss: 8.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14273, Training Loss: 7.532e-01, Validation Loss: 8.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14274, Training Loss: 7.531e-01, Validation Loss: 8.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14275, Training Loss: 7.531e-01, Validation Loss: 8.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14276, Training Loss: 7.530e-01, Validation Loss: 8.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14277, Training Loss: 7.530e-01, Validation Loss: 8.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14278, Training Loss: 7.529e-01, Validation Loss: 8.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14279, Training Loss: 7.529e-01, Validation Loss: 8.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14280, Training Loss: 7.528e-01, Validation Loss: 8.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14281, Training Loss: 7.528e-01, Validation Loss: 8.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14282, Training Loss: 7.527e-01, Validation Loss: 8.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14283, Training Loss: 7.527e-01, Validation Loss: 8.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14284, Training Loss: 7.526e-01, Validation Loss: 8.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14285, Training Loss: 7.526e-01, Validation Loss: 8.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14286, Training Loss: 7.525e-01, Validation Loss: 8.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14287, Training Loss: 7.525e-01, Validation Loss: 8.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14288, Training Loss: 7.524e-01, Validation Loss: 8.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14289, Training Loss: 7.524e-01, Validation Loss: 8.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14290, Training Loss: 7.523e-01, Validation Loss: 8.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14291, Training Loss: 7.523e-01, Validation Loss: 8.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14292, Training Loss: 7.522e-01, Validation Loss: 8.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14293, Training Loss: 7.522e-01, Validation Loss: 8.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14294, Training Loss: 7.521e-01, Validation Loss: 8.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14295, Training Loss: 7.521e-01, Validation Loss: 8.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14296, Training Loss: 7.520e-01, Validation Loss: 8.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14297, Training Loss: 7.520e-01, Validation Loss: 8.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14298, Training Loss: 7.519e-01, Validation Loss: 8.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14299, Training Loss: 7.519e-01, Validation Loss: 8.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14300, Training Loss: 7.518e-01, Validation Loss: 8.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14301, Training Loss: 7.518e-01, Validation Loss: 8.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14302, Training Loss: 7.517e-01, Validation Loss: 8.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14303, Training Loss: 7.517e-01, Validation Loss: 8.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14304, Training Loss: 7.516e-01, Validation Loss: 8.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14305, Training Loss: 7.516e-01, Validation Loss: 8.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14306, Training Loss: 7.515e-01, Validation Loss: 8.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14307, Training Loss: 7.515e-01, Validation Loss: 8.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14308, Training Loss: 7.514e-01, Validation Loss: 8.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14309, Training Loss: 7.514e-01, Validation Loss: 8.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14310, Training Loss: 7.513e-01, Validation Loss: 8.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14311, Training Loss: 7.513e-01, Validation Loss: 8.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14312, Training Loss: 7.512e-01, Validation Loss: 8.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14313, Training Loss: 7.512e-01, Validation Loss: 8.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14314, Training Loss: 7.511e-01, Validation Loss: 8.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14315, Training Loss: 7.511e-01, Validation Loss: 8.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14316, Training Loss: 7.510e-01, Validation Loss: 8.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14317, Training Loss: 7.510e-01, Validation Loss: 8.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14318, Training Loss: 7.509e-01, Validation Loss: 8.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14319, Training Loss: 7.509e-01, Validation Loss: 8.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14320, Training Loss: 7.508e-01, Validation Loss: 8.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14321, Training Loss: 7.508e-01, Validation Loss: 8.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14322, Training Loss: 7.507e-01, Validation Loss: 8.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14323, Training Loss: 7.507e-01, Validation Loss: 8.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14324, Training Loss: 7.506e-01, Validation Loss: 8.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14325, Training Loss: 7.506e-01, Validation Loss: 8.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14326, Training Loss: 7.506e-01, Validation Loss: 8.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14327, Training Loss: 7.505e-01, Validation Loss: 8.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14328, Training Loss: 7.505e-01, Validation Loss: 8.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14329, Training Loss: 7.504e-01, Validation Loss: 8.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14330, Training Loss: 7.504e-01, Validation Loss: 8.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14331, Training Loss: 7.503e-01, Validation Loss: 8.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14332, Training Loss: 7.503e-01, Validation Loss: 8.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14333, Training Loss: 7.502e-01, Validation Loss: 8.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14334, Training Loss: 7.502e-01, Validation Loss: 8.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14335, Training Loss: 7.501e-01, Validation Loss: 8.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14336, Training Loss: 7.501e-01, Validation Loss: 8.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14337, Training Loss: 7.500e-01, Validation Loss: 8.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14338, Training Loss: 7.500e-01, Validation Loss: 8.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14339, Training Loss: 7.499e-01, Validation Loss: 8.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14340, Training Loss: 7.499e-01, Validation Loss: 8.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14341, Training Loss: 7.498e-01, Validation Loss: 8.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14342, Training Loss: 7.498e-01, Validation Loss: 8.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14343, Training Loss: 7.497e-01, Validation Loss: 8.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14344, Training Loss: 7.497e-01, Validation Loss: 8.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14345, Training Loss: 7.496e-01, Validation Loss: 8.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14346, Training Loss: 7.496e-01, Validation Loss: 8.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14347, Training Loss: 7.495e-01, Validation Loss: 8.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14348, Training Loss: 7.495e-01, Validation Loss: 8.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14349, Training Loss: 7.494e-01, Validation Loss: 8.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14350, Training Loss: 7.494e-01, Validation Loss: 8.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14351, Training Loss: 7.493e-01, Validation Loss: 8.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14352, Training Loss: 7.493e-01, Validation Loss: 8.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14353, Training Loss: 7.492e-01, Validation Loss: 8.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14354, Training Loss: 7.492e-01, Validation Loss: 8.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14355, Training Loss: 7.491e-01, Validation Loss: 8.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14356, Training Loss: 7.491e-01, Validation Loss: 8.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14357, Training Loss: 7.490e-01, Validation Loss: 8.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14358, Training Loss: 7.490e-01, Validation Loss: 8.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14359, Training Loss: 7.489e-01, Validation Loss: 8.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14360, Training Loss: 7.489e-01, Validation Loss: 8.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14361, Training Loss: 7.488e-01, Validation Loss: 8.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14362, Training Loss: 7.488e-01, Validation Loss: 8.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14363, Training Loss: 7.487e-01, Validation Loss: 8.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14364, Training Loss: 7.487e-01, Validation Loss: 8.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14365, Training Loss: 7.486e-01, Validation Loss: 8.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14366, Training Loss: 7.486e-01, Validation Loss: 8.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14367, Training Loss: 7.485e-01, Validation Loss: 8.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14368, Training Loss: 7.485e-01, Validation Loss: 8.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14369, Training Loss: 7.484e-01, Validation Loss: 8.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14370, Training Loss: 7.484e-01, Validation Loss: 8.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14371, Training Loss: 7.483e-01, Validation Loss: 8.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14372, Training Loss: 7.483e-01, Validation Loss: 8.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14373, Training Loss: 7.482e-01, Validation Loss: 8.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14374, Training Loss: 7.482e-01, Validation Loss: 8.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14375, Training Loss: 7.481e-01, Validation Loss: 8.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14376, Training Loss: 7.481e-01, Validation Loss: 8.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14377, Training Loss: 7.480e-01, Validation Loss: 8.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14378, Training Loss: 7.480e-01, Validation Loss: 8.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14379, Training Loss: 7.479e-01, Validation Loss: 8.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14380, Training Loss: 7.479e-01, Validation Loss: 8.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14381, Training Loss: 7.478e-01, Validation Loss: 8.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14382, Training Loss: 7.478e-01, Validation Loss: 8.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14383, Training Loss: 7.477e-01, Validation Loss: 8.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14384, Training Loss: 7.477e-01, Validation Loss: 8.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14385, Training Loss: 7.476e-01, Validation Loss: 8.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14386, Training Loss: 7.476e-01, Validation Loss: 8.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14387, Training Loss: 7.475e-01, Validation Loss: 8.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14388, Training Loss: 7.475e-01, Validation Loss: 8.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14389, Training Loss: 7.474e-01, Validation Loss: 8.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14390, Training Loss: 7.474e-01, Validation Loss: 8.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14391, Training Loss: 7.473e-01, Validation Loss: 8.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14392, Training Loss: 7.473e-01, Validation Loss: 8.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14393, Training Loss: 7.472e-01, Validation Loss: 8.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14394, Training Loss: 7.472e-01, Validation Loss: 8.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14395, Training Loss: 7.471e-01, Validation Loss: 8.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14396, Training Loss: 7.471e-01, Validation Loss: 8.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14397, Training Loss: 7.470e-01, Validation Loss: 8.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14398, Training Loss: 7.470e-01, Validation Loss: 8.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14399, Training Loss: 7.469e-01, Validation Loss: 8.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14400, Training Loss: 7.469e-01, Validation Loss: 8.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14401, Training Loss: 7.468e-01, Validation Loss: 8.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14402, Training Loss: 7.468e-01, Validation Loss: 8.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14403, Training Loss: 7.467e-01, Validation Loss: 8.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14404, Training Loss: 7.467e-01, Validation Loss: 8.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14405, Training Loss: 7.466e-01, Validation Loss: 8.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14406, Training Loss: 7.466e-01, Validation Loss: 8.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14407, Training Loss: 7.465e-01, Validation Loss: 8.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14408, Training Loss: 7.465e-01, Validation Loss: 8.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14409, Training Loss: 7.464e-01, Validation Loss: 8.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14410, Training Loss: 7.464e-01, Validation Loss: 8.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14411, Training Loss: 7.463e-01, Validation Loss: 8.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14412, Training Loss: 7.463e-01, Validation Loss: 8.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14413, Training Loss: 7.462e-01, Validation Loss: 8.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14414, Training Loss: 7.462e-01, Validation Loss: 8.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14415, Training Loss: 7.462e-01, Validation Loss: 8.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14416, Training Loss: 7.461e-01, Validation Loss: 8.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14417, Training Loss: 7.461e-01, Validation Loss: 8.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14418, Training Loss: 7.460e-01, Validation Loss: 8.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14419, Training Loss: 7.460e-01, Validation Loss: 8.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14420, Training Loss: 7.459e-01, Validation Loss: 8.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14421, Training Loss: 7.459e-01, Validation Loss: 8.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14422, Training Loss: 7.458e-01, Validation Loss: 8.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14423, Training Loss: 7.458e-01, Validation Loss: 8.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14424, Training Loss: 7.457e-01, Validation Loss: 8.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14425, Training Loss: 7.457e-01, Validation Loss: 8.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14426, Training Loss: 7.456e-01, Validation Loss: 8.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14427, Training Loss: 7.456e-01, Validation Loss: 8.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14428, Training Loss: 7.455e-01, Validation Loss: 8.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14429, Training Loss: 7.455e-01, Validation Loss: 8.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14430, Training Loss: 7.454e-01, Validation Loss: 8.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14431, Training Loss: 7.454e-01, Validation Loss: 8.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14432, Training Loss: 7.453e-01, Validation Loss: 8.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14433, Training Loss: 7.453e-01, Validation Loss: 8.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14434, Training Loss: 7.452e-01, Validation Loss: 8.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14435, Training Loss: 7.452e-01, Validation Loss: 8.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14436, Training Loss: 7.451e-01, Validation Loss: 8.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14437, Training Loss: 7.451e-01, Validation Loss: 8.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14438, Training Loss: 7.450e-01, Validation Loss: 8.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14439, Training Loss: 7.450e-01, Validation Loss: 8.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14440, Training Loss: 7.449e-01, Validation Loss: 8.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14441, Training Loss: 7.449e-01, Validation Loss: 8.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14442, Training Loss: 7.448e-01, Validation Loss: 8.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14443, Training Loss: 7.448e-01, Validation Loss: 8.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14444, Training Loss: 7.447e-01, Validation Loss: 8.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14445, Training Loss: 7.447e-01, Validation Loss: 8.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14446, Training Loss: 7.446e-01, Validation Loss: 8.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14447, Training Loss: 7.446e-01, Validation Loss: 8.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14448, Training Loss: 7.445e-01, Validation Loss: 8.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14449, Training Loss: 7.445e-01, Validation Loss: 8.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14450, Training Loss: 7.444e-01, Validation Loss: 8.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14451, Training Loss: 7.444e-01, Validation Loss: 8.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14452, Training Loss: 7.443e-01, Validation Loss: 8.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14453, Training Loss: 7.443e-01, Validation Loss: 8.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14454, Training Loss: 7.442e-01, Validation Loss: 8.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14455, Training Loss: 7.442e-01, Validation Loss: 8.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14456, Training Loss: 7.441e-01, Validation Loss: 8.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14457, Training Loss: 7.441e-01, Validation Loss: 8.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14458, Training Loss: 7.440e-01, Validation Loss: 8.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14459, Training Loss: 7.440e-01, Validation Loss: 8.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14460, Training Loss: 7.439e-01, Validation Loss: 8.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14461, Training Loss: 7.439e-01, Validation Loss: 8.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14462, Training Loss: 7.438e-01, Validation Loss: 8.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14463, Training Loss: 7.438e-01, Validation Loss: 8.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14464, Training Loss: 7.437e-01, Validation Loss: 8.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14465, Training Loss: 7.437e-01, Validation Loss: 8.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14466, Training Loss: 7.436e-01, Validation Loss: 8.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14467, Training Loss: 7.436e-01, Validation Loss: 8.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14468, Training Loss: 7.436e-01, Validation Loss: 8.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14469, Training Loss: 7.435e-01, Validation Loss: 8.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14470, Training Loss: 7.435e-01, Validation Loss: 8.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14471, Training Loss: 7.434e-01, Validation Loss: 8.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14472, Training Loss: 7.434e-01, Validation Loss: 8.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14473, Training Loss: 7.433e-01, Validation Loss: 8.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14474, Training Loss: 7.433e-01, Validation Loss: 8.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14475, Training Loss: 7.432e-01, Validation Loss: 8.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14476, Training Loss: 7.432e-01, Validation Loss: 8.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14477, Training Loss: 7.431e-01, Validation Loss: 8.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14478, Training Loss: 7.431e-01, Validation Loss: 8.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14479, Training Loss: 7.430e-01, Validation Loss: 8.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14480, Training Loss: 7.430e-01, Validation Loss: 8.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14481, Training Loss: 7.429e-01, Validation Loss: 8.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14482, Training Loss: 7.429e-01, Validation Loss: 8.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14483, Training Loss: 7.428e-01, Validation Loss: 8.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14484, Training Loss: 7.428e-01, Validation Loss: 8.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14485, Training Loss: 7.427e-01, Validation Loss: 8.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14486, Training Loss: 7.427e-01, Validation Loss: 8.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14487, Training Loss: 7.426e-01, Validation Loss: 8.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14488, Training Loss: 7.426e-01, Validation Loss: 8.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14489, Training Loss: 7.425e-01, Validation Loss: 8.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14490, Training Loss: 7.425e-01, Validation Loss: 8.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14491, Training Loss: 7.424e-01, Validation Loss: 8.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14492, Training Loss: 7.424e-01, Validation Loss: 8.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14493, Training Loss: 7.423e-01, Validation Loss: 8.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14494, Training Loss: 7.423e-01, Validation Loss: 8.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14495, Training Loss: 7.422e-01, Validation Loss: 8.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14496, Training Loss: 7.422e-01, Validation Loss: 8.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14497, Training Loss: 7.421e-01, Validation Loss: 8.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14498, Training Loss: 7.421e-01, Validation Loss: 8.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14499, Training Loss: 7.420e-01, Validation Loss: 8.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14500, Training Loss: 7.420e-01, Validation Loss: 8.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14501, Training Loss: 7.419e-01, Validation Loss: 8.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14502, Training Loss: 7.419e-01, Validation Loss: 8.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14503, Training Loss: 7.418e-01, Validation Loss: 8.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14504, Training Loss: 7.418e-01, Validation Loss: 8.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14505, Training Loss: 7.417e-01, Validation Loss: 8.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14506, Training Loss: 7.417e-01, Validation Loss: 8.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14507, Training Loss: 7.416e-01, Validation Loss: 8.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14508, Training Loss: 7.416e-01, Validation Loss: 8.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14509, Training Loss: 7.416e-01, Validation Loss: 8.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14510, Training Loss: 7.415e-01, Validation Loss: 8.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14511, Training Loss: 7.415e-01, Validation Loss: 8.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14512, Training Loss: 7.414e-01, Validation Loss: 8.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14513, Training Loss: 7.414e-01, Validation Loss: 8.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14514, Training Loss: 7.413e-01, Validation Loss: 8.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14515, Training Loss: 7.413e-01, Validation Loss: 8.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14516, Training Loss: 7.412e-01, Validation Loss: 8.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14517, Training Loss: 7.412e-01, Validation Loss: 8.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14518, Training Loss: 7.411e-01, Validation Loss: 8.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14519, Training Loss: 7.411e-01, Validation Loss: 8.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14520, Training Loss: 7.410e-01, Validation Loss: 8.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14521, Training Loss: 7.410e-01, Validation Loss: 8.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14522, Training Loss: 7.409e-01, Validation Loss: 8.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14523, Training Loss: 7.409e-01, Validation Loss: 8.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14524, Training Loss: 7.408e-01, Validation Loss: 8.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14525, Training Loss: 7.408e-01, Validation Loss: 8.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14526, Training Loss: 7.407e-01, Validation Loss: 8.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14527, Training Loss: 7.407e-01, Validation Loss: 8.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14528, Training Loss: 7.406e-01, Validation Loss: 8.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14529, Training Loss: 7.406e-01, Validation Loss: 8.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14530, Training Loss: 7.405e-01, Validation Loss: 8.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14531, Training Loss: 7.405e-01, Validation Loss: 8.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14532, Training Loss: 7.404e-01, Validation Loss: 8.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14533, Training Loss: 7.404e-01, Validation Loss: 8.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14534, Training Loss: 7.403e-01, Validation Loss: 8.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14535, Training Loss: 7.403e-01, Validation Loss: 8.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14536, Training Loss: 7.402e-01, Validation Loss: 8.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14537, Training Loss: 7.402e-01, Validation Loss: 8.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14538, Training Loss: 7.401e-01, Validation Loss: 8.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14539, Training Loss: 7.401e-01, Validation Loss: 8.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14540, Training Loss: 7.400e-01, Validation Loss: 8.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14541, Training Loss: 7.400e-01, Validation Loss: 8.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14542, Training Loss: 7.399e-01, Validation Loss: 8.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14543, Training Loss: 7.399e-01, Validation Loss: 8.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14544, Training Loss: 7.399e-01, Validation Loss: 8.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14545, Training Loss: 7.398e-01, Validation Loss: 8.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14546, Training Loss: 7.398e-01, Validation Loss: 8.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14547, Training Loss: 7.397e-01, Validation Loss: 8.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14548, Training Loss: 7.397e-01, Validation Loss: 8.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14549, Training Loss: 7.396e-01, Validation Loss: 8.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14550, Training Loss: 7.396e-01, Validation Loss: 8.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14551, Training Loss: 7.395e-01, Validation Loss: 8.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14552, Training Loss: 7.395e-01, Validation Loss: 8.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14553, Training Loss: 7.394e-01, Validation Loss: 8.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14554, Training Loss: 7.394e-01, Validation Loss: 8.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14555, Training Loss: 7.393e-01, Validation Loss: 8.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14556, Training Loss: 7.393e-01, Validation Loss: 8.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14557, Training Loss: 7.392e-01, Validation Loss: 8.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14558, Training Loss: 7.392e-01, Validation Loss: 8.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14559, Training Loss: 7.391e-01, Validation Loss: 8.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14560, Training Loss: 7.391e-01, Validation Loss: 8.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14561, Training Loss: 7.390e-01, Validation Loss: 8.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14562, Training Loss: 7.390e-01, Validation Loss: 8.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14563, Training Loss: 7.389e-01, Validation Loss: 8.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14564, Training Loss: 7.389e-01, Validation Loss: 8.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14565, Training Loss: 7.388e-01, Validation Loss: 8.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14566, Training Loss: 7.388e-01, Validation Loss: 8.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14567, Training Loss: 7.387e-01, Validation Loss: 8.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14568, Training Loss: 7.387e-01, Validation Loss: 8.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14569, Training Loss: 7.386e-01, Validation Loss: 8.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14570, Training Loss: 7.386e-01, Validation Loss: 8.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14571, Training Loss: 7.385e-01, Validation Loss: 8.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14572, Training Loss: 7.385e-01, Validation Loss: 8.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14573, Training Loss: 7.384e-01, Validation Loss: 8.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14574, Training Loss: 7.384e-01, Validation Loss: 8.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14575, Training Loss: 7.384e-01, Validation Loss: 8.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14576, Training Loss: 7.383e-01, Validation Loss: 8.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14577, Training Loss: 7.383e-01, Validation Loss: 8.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14578, Training Loss: 7.382e-01, Validation Loss: 8.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14579, Training Loss: 7.382e-01, Validation Loss: 8.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14580, Training Loss: 7.381e-01, Validation Loss: 8.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14581, Training Loss: 7.381e-01, Validation Loss: 8.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14582, Training Loss: 7.380e-01, Validation Loss: 8.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14583, Training Loss: 7.380e-01, Validation Loss: 8.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14584, Training Loss: 7.379e-01, Validation Loss: 8.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14585, Training Loss: 7.379e-01, Validation Loss: 8.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14586, Training Loss: 7.378e-01, Validation Loss: 8.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14587, Training Loss: 7.378e-01, Validation Loss: 8.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14588, Training Loss: 7.377e-01, Validation Loss: 8.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14589, Training Loss: 7.377e-01, Validation Loss: 8.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14590, Training Loss: 7.376e-01, Validation Loss: 8.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14591, Training Loss: 7.376e-01, Validation Loss: 8.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14592, Training Loss: 7.375e-01, Validation Loss: 8.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14593, Training Loss: 7.375e-01, Validation Loss: 8.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14594, Training Loss: 7.374e-01, Validation Loss: 8.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14595, Training Loss: 7.374e-01, Validation Loss: 8.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14596, Training Loss: 7.373e-01, Validation Loss: 8.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14597, Training Loss: 7.373e-01, Validation Loss: 8.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14598, Training Loss: 7.372e-01, Validation Loss: 8.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14599, Training Loss: 7.372e-01, Validation Loss: 8.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14600, Training Loss: 7.371e-01, Validation Loss: 8.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14601, Training Loss: 7.371e-01, Validation Loss: 8.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14602, Training Loss: 7.370e-01, Validation Loss: 8.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14603, Training Loss: 7.370e-01, Validation Loss: 8.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14604, Training Loss: 7.370e-01, Validation Loss: 8.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14605, Training Loss: 7.369e-01, Validation Loss: 8.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14606, Training Loss: 7.369e-01, Validation Loss: 8.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14607, Training Loss: 7.368e-01, Validation Loss: 8.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14608, Training Loss: 7.368e-01, Validation Loss: 8.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14609, Training Loss: 7.367e-01, Validation Loss: 8.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14610, Training Loss: 7.367e-01, Validation Loss: 8.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14611, Training Loss: 7.366e-01, Validation Loss: 8.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14612, Training Loss: 7.366e-01, Validation Loss: 8.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14613, Training Loss: 7.365e-01, Validation Loss: 8.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14614, Training Loss: 7.365e-01, Validation Loss: 8.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14615, Training Loss: 7.364e-01, Validation Loss: 8.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14616, Training Loss: 7.364e-01, Validation Loss: 8.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14617, Training Loss: 7.363e-01, Validation Loss: 8.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14618, Training Loss: 7.363e-01, Validation Loss: 8.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14619, Training Loss: 7.362e-01, Validation Loss: 8.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14620, Training Loss: 7.362e-01, Validation Loss: 8.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14621, Training Loss: 7.361e-01, Validation Loss: 8.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14622, Training Loss: 7.361e-01, Validation Loss: 8.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14623, Training Loss: 7.360e-01, Validation Loss: 8.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14624, Training Loss: 7.360e-01, Validation Loss: 8.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14625, Training Loss: 7.359e-01, Validation Loss: 8.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14626, Training Loss: 7.359e-01, Validation Loss: 8.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14627, Training Loss: 7.358e-01, Validation Loss: 8.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14628, Training Loss: 7.358e-01, Validation Loss: 8.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14629, Training Loss: 7.358e-01, Validation Loss: 8.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14630, Training Loss: 7.357e-01, Validation Loss: 8.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14631, Training Loss: 7.357e-01, Validation Loss: 8.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14632, Training Loss: 7.356e-01, Validation Loss: 8.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14633, Training Loss: 7.356e-01, Validation Loss: 8.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14634, Training Loss: 7.355e-01, Validation Loss: 8.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14635, Training Loss: 7.355e-01, Validation Loss: 8.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14636, Training Loss: 7.354e-01, Validation Loss: 8.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14637, Training Loss: 7.354e-01, Validation Loss: 8.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14638, Training Loss: 7.353e-01, Validation Loss: 8.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14639, Training Loss: 7.353e-01, Validation Loss: 8.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14640, Training Loss: 7.352e-01, Validation Loss: 8.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14641, Training Loss: 7.352e-01, Validation Loss: 8.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14642, Training Loss: 7.351e-01, Validation Loss: 8.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14643, Training Loss: 7.351e-01, Validation Loss: 8.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14644, Training Loss: 7.350e-01, Validation Loss: 8.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14645, Training Loss: 7.350e-01, Validation Loss: 8.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14646, Training Loss: 7.349e-01, Validation Loss: 8.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14647, Training Loss: 7.349e-01, Validation Loss: 8.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14648, Training Loss: 7.348e-01, Validation Loss: 8.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14649, Training Loss: 7.348e-01, Validation Loss: 8.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14650, Training Loss: 7.347e-01, Validation Loss: 8.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14651, Training Loss: 7.347e-01, Validation Loss: 8.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14652, Training Loss: 7.346e-01, Validation Loss: 8.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14653, Training Loss: 7.346e-01, Validation Loss: 8.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14654, Training Loss: 7.346e-01, Validation Loss: 8.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14655, Training Loss: 7.345e-01, Validation Loss: 8.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14656, Training Loss: 7.345e-01, Validation Loss: 8.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14657, Training Loss: 7.344e-01, Validation Loss: 8.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14658, Training Loss: 7.344e-01, Validation Loss: 8.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14659, Training Loss: 7.343e-01, Validation Loss: 8.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14660, Training Loss: 7.343e-01, Validation Loss: 8.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14661, Training Loss: 7.342e-01, Validation Loss: 8.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14662, Training Loss: 7.342e-01, Validation Loss: 8.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14663, Training Loss: 7.341e-01, Validation Loss: 8.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14664, Training Loss: 7.341e-01, Validation Loss: 8.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14665, Training Loss: 7.340e-01, Validation Loss: 8.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14666, Training Loss: 7.340e-01, Validation Loss: 8.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14667, Training Loss: 7.339e-01, Validation Loss: 8.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14668, Training Loss: 7.339e-01, Validation Loss: 8.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14669, Training Loss: 7.338e-01, Validation Loss: 8.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14670, Training Loss: 7.338e-01, Validation Loss: 8.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14671, Training Loss: 7.337e-01, Validation Loss: 8.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14672, Training Loss: 7.337e-01, Validation Loss: 8.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14673, Training Loss: 7.336e-01, Validation Loss: 8.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14674, Training Loss: 7.336e-01, Validation Loss: 8.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14675, Training Loss: 7.335e-01, Validation Loss: 8.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14676, Training Loss: 7.335e-01, Validation Loss: 8.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14677, Training Loss: 7.335e-01, Validation Loss: 8.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14678, Training Loss: 7.334e-01, Validation Loss: 8.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14679, Training Loss: 7.334e-01, Validation Loss: 8.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14680, Training Loss: 7.333e-01, Validation Loss: 8.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14681, Training Loss: 7.333e-01, Validation Loss: 8.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14682, Training Loss: 7.332e-01, Validation Loss: 8.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14683, Training Loss: 7.332e-01, Validation Loss: 8.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14684, Training Loss: 7.331e-01, Validation Loss: 8.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14685, Training Loss: 7.331e-01, Validation Loss: 8.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14686, Training Loss: 7.330e-01, Validation Loss: 8.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14687, Training Loss: 7.330e-01, Validation Loss: 8.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14688, Training Loss: 7.329e-01, Validation Loss: 8.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14689, Training Loss: 7.329e-01, Validation Loss: 8.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14690, Training Loss: 7.328e-01, Validation Loss: 8.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14691, Training Loss: 7.328e-01, Validation Loss: 8.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14692, Training Loss: 7.327e-01, Validation Loss: 8.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14693, Training Loss: 7.327e-01, Validation Loss: 8.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14694, Training Loss: 7.326e-01, Validation Loss: 8.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14695, Training Loss: 7.326e-01, Validation Loss: 8.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14696, Training Loss: 7.325e-01, Validation Loss: 8.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14697, Training Loss: 7.325e-01, Validation Loss: 8.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14698, Training Loss: 7.324e-01, Validation Loss: 8.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14699, Training Loss: 7.324e-01, Validation Loss: 8.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14700, Training Loss: 7.324e-01, Validation Loss: 8.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14701, Training Loss: 7.323e-01, Validation Loss: 8.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14702, Training Loss: 7.323e-01, Validation Loss: 8.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14703, Training Loss: 7.322e-01, Validation Loss: 8.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14704, Training Loss: 7.322e-01, Validation Loss: 8.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14705, Training Loss: 7.321e-01, Validation Loss: 8.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14706, Training Loss: 7.321e-01, Validation Loss: 8.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14707, Training Loss: 7.320e-01, Validation Loss: 8.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14708, Training Loss: 7.320e-01, Validation Loss: 8.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14709, Training Loss: 7.319e-01, Validation Loss: 8.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14710, Training Loss: 7.319e-01, Validation Loss: 8.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14711, Training Loss: 7.318e-01, Validation Loss: 8.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14712, Training Loss: 7.318e-01, Validation Loss: 8.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14713, Training Loss: 7.317e-01, Validation Loss: 8.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14714, Training Loss: 7.317e-01, Validation Loss: 8.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14715, Training Loss: 7.316e-01, Validation Loss: 8.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14716, Training Loss: 7.316e-01, Validation Loss: 8.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14717, Training Loss: 7.315e-01, Validation Loss: 8.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14718, Training Loss: 7.315e-01, Validation Loss: 8.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14719, Training Loss: 7.314e-01, Validation Loss: 8.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14720, Training Loss: 7.314e-01, Validation Loss: 8.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14721, Training Loss: 7.314e-01, Validation Loss: 8.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14722, Training Loss: 7.313e-01, Validation Loss: 8.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14723, Training Loss: 7.313e-01, Validation Loss: 8.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14724, Training Loss: 7.312e-01, Validation Loss: 8.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14725, Training Loss: 7.312e-01, Validation Loss: 8.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14726, Training Loss: 7.311e-01, Validation Loss: 8.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14727, Training Loss: 7.311e-01, Validation Loss: 8.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14728, Training Loss: 7.310e-01, Validation Loss: 8.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14729, Training Loss: 7.310e-01, Validation Loss: 8.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14730, Training Loss: 7.309e-01, Validation Loss: 8.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14731, Training Loss: 7.309e-01, Validation Loss: 8.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14732, Training Loss: 7.308e-01, Validation Loss: 8.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14733, Training Loss: 7.308e-01, Validation Loss: 8.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14734, Training Loss: 7.307e-01, Validation Loss: 8.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14735, Training Loss: 7.307e-01, Validation Loss: 8.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14736, Training Loss: 7.306e-01, Validation Loss: 8.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14737, Training Loss: 7.306e-01, Validation Loss: 8.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14738, Training Loss: 7.305e-01, Validation Loss: 8.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14739, Training Loss: 7.305e-01, Validation Loss: 8.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14740, Training Loss: 7.304e-01, Validation Loss: 8.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14741, Training Loss: 7.304e-01, Validation Loss: 8.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14742, Training Loss: 7.304e-01, Validation Loss: 8.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14743, Training Loss: 7.303e-01, Validation Loss: 8.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14744, Training Loss: 7.303e-01, Validation Loss: 8.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14745, Training Loss: 7.302e-01, Validation Loss: 8.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14746, Training Loss: 7.302e-01, Validation Loss: 8.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14747, Training Loss: 7.301e-01, Validation Loss: 8.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14748, Training Loss: 7.301e-01, Validation Loss: 8.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14749, Training Loss: 7.300e-01, Validation Loss: 8.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14750, Training Loss: 7.300e-01, Validation Loss: 8.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14751, Training Loss: 7.299e-01, Validation Loss: 8.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14752, Training Loss: 7.299e-01, Validation Loss: 8.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14753, Training Loss: 7.298e-01, Validation Loss: 8.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14754, Training Loss: 7.298e-01, Validation Loss: 8.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14755, Training Loss: 7.297e-01, Validation Loss: 8.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14756, Training Loss: 7.297e-01, Validation Loss: 8.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14757, Training Loss: 7.296e-01, Validation Loss: 8.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14758, Training Loss: 7.296e-01, Validation Loss: 8.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14759, Training Loss: 7.295e-01, Validation Loss: 8.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14760, Training Loss: 7.295e-01, Validation Loss: 8.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14761, Training Loss: 7.295e-01, Validation Loss: 8.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14762, Training Loss: 7.294e-01, Validation Loss: 8.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14763, Training Loss: 7.294e-01, Validation Loss: 8.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14764, Training Loss: 7.293e-01, Validation Loss: 8.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14765, Training Loss: 7.293e-01, Validation Loss: 8.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14766, Training Loss: 7.292e-01, Validation Loss: 8.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14767, Training Loss: 7.292e-01, Validation Loss: 8.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14768, Training Loss: 7.291e-01, Validation Loss: 8.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14769, Training Loss: 7.291e-01, Validation Loss: 8.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14770, Training Loss: 7.290e-01, Validation Loss: 8.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14771, Training Loss: 7.290e-01, Validation Loss: 8.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14772, Training Loss: 7.289e-01, Validation Loss: 8.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14773, Training Loss: 7.289e-01, Validation Loss: 8.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14774, Training Loss: 7.288e-01, Validation Loss: 8.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14775, Training Loss: 7.288e-01, Validation Loss: 8.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14776, Training Loss: 7.287e-01, Validation Loss: 8.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14777, Training Loss: 7.287e-01, Validation Loss: 8.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14778, Training Loss: 7.286e-01, Validation Loss: 8.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14779, Training Loss: 7.286e-01, Validation Loss: 8.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14780, Training Loss: 7.285e-01, Validation Loss: 8.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14781, Training Loss: 7.285e-01, Validation Loss: 8.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14782, Training Loss: 7.285e-01, Validation Loss: 8.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14783, Training Loss: 7.284e-01, Validation Loss: 8.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14784, Training Loss: 7.284e-01, Validation Loss: 8.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14785, Training Loss: 7.283e-01, Validation Loss: 8.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14786, Training Loss: 7.283e-01, Validation Loss: 8.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14787, Training Loss: 7.282e-01, Validation Loss: 8.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14788, Training Loss: 7.282e-01, Validation Loss: 8.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14789, Training Loss: 7.281e-01, Validation Loss: 8.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14790, Training Loss: 7.281e-01, Validation Loss: 8.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14791, Training Loss: 7.280e-01, Validation Loss: 8.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14792, Training Loss: 7.280e-01, Validation Loss: 8.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14793, Training Loss: 7.279e-01, Validation Loss: 8.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14794, Training Loss: 7.279e-01, Validation Loss: 8.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14795, Training Loss: 7.278e-01, Validation Loss: 8.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14796, Training Loss: 7.278e-01, Validation Loss: 8.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14797, Training Loss: 7.277e-01, Validation Loss: 8.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14798, Training Loss: 7.277e-01, Validation Loss: 8.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14799, Training Loss: 7.276e-01, Validation Loss: 8.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14800, Training Loss: 7.276e-01, Validation Loss: 8.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14801, Training Loss: 7.276e-01, Validation Loss: 8.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14802, Training Loss: 7.275e-01, Validation Loss: 8.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14803, Training Loss: 7.275e-01, Validation Loss: 8.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14804, Training Loss: 7.274e-01, Validation Loss: 8.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14805, Training Loss: 7.274e-01, Validation Loss: 8.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14806, Training Loss: 7.273e-01, Validation Loss: 8.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14807, Training Loss: 7.273e-01, Validation Loss: 8.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14808, Training Loss: 7.272e-01, Validation Loss: 8.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14809, Training Loss: 7.272e-01, Validation Loss: 8.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14810, Training Loss: 7.271e-01, Validation Loss: 8.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14811, Training Loss: 7.271e-01, Validation Loss: 8.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14812, Training Loss: 7.270e-01, Validation Loss: 8.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14813, Training Loss: 7.270e-01, Validation Loss: 8.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14814, Training Loss: 7.269e-01, Validation Loss: 8.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14815, Training Loss: 7.269e-01, Validation Loss: 8.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14816, Training Loss: 7.268e-01, Validation Loss: 8.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14817, Training Loss: 7.268e-01, Validation Loss: 8.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14818, Training Loss: 7.267e-01, Validation Loss: 8.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14819, Training Loss: 7.267e-01, Validation Loss: 8.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14820, Training Loss: 7.267e-01, Validation Loss: 8.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14821, Training Loss: 7.266e-01, Validation Loss: 8.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14822, Training Loss: 7.266e-01, Validation Loss: 8.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14823, Training Loss: 7.265e-01, Validation Loss: 8.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14824, Training Loss: 7.265e-01, Validation Loss: 8.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14825, Training Loss: 7.264e-01, Validation Loss: 8.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14826, Training Loss: 7.264e-01, Validation Loss: 8.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14827, Training Loss: 7.263e-01, Validation Loss: 8.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14828, Training Loss: 7.263e-01, Validation Loss: 8.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14829, Training Loss: 7.262e-01, Validation Loss: 8.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14830, Training Loss: 7.262e-01, Validation Loss: 8.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14831, Training Loss: 7.261e-01, Validation Loss: 8.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14832, Training Loss: 7.261e-01, Validation Loss: 8.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14833, Training Loss: 7.260e-01, Validation Loss: 8.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14834, Training Loss: 7.260e-01, Validation Loss: 8.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14835, Training Loss: 7.259e-01, Validation Loss: 8.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14836, Training Loss: 7.259e-01, Validation Loss: 8.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14837, Training Loss: 7.258e-01, Validation Loss: 8.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14838, Training Loss: 7.258e-01, Validation Loss: 8.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14839, Training Loss: 7.258e-01, Validation Loss: 8.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14840, Training Loss: 7.257e-01, Validation Loss: 8.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14841, Training Loss: 7.257e-01, Validation Loss: 8.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14842, Training Loss: 7.256e-01, Validation Loss: 8.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14843, Training Loss: 7.256e-01, Validation Loss: 8.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14844, Training Loss: 7.255e-01, Validation Loss: 8.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14845, Training Loss: 7.255e-01, Validation Loss: 8.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14846, Training Loss: 7.254e-01, Validation Loss: 8.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14847, Training Loss: 7.254e-01, Validation Loss: 8.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14848, Training Loss: 7.253e-01, Validation Loss: 8.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14849, Training Loss: 7.253e-01, Validation Loss: 8.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14850, Training Loss: 7.252e-01, Validation Loss: 8.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14851, Training Loss: 7.252e-01, Validation Loss: 8.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14852, Training Loss: 7.251e-01, Validation Loss: 8.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14853, Training Loss: 7.251e-01, Validation Loss: 8.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14854, Training Loss: 7.250e-01, Validation Loss: 8.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14855, Training Loss: 7.250e-01, Validation Loss: 8.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14856, Training Loss: 7.250e-01, Validation Loss: 8.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14857, Training Loss: 7.249e-01, Validation Loss: 8.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14858, Training Loss: 7.249e-01, Validation Loss: 8.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14859, Training Loss: 7.248e-01, Validation Loss: 8.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14860, Training Loss: 7.248e-01, Validation Loss: 8.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14861, Training Loss: 7.247e-01, Validation Loss: 8.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14862, Training Loss: 7.247e-01, Validation Loss: 8.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14863, Training Loss: 7.246e-01, Validation Loss: 8.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14864, Training Loss: 7.246e-01, Validation Loss: 8.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14865, Training Loss: 7.245e-01, Validation Loss: 8.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14866, Training Loss: 7.245e-01, Validation Loss: 8.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14867, Training Loss: 7.244e-01, Validation Loss: 8.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14868, Training Loss: 7.244e-01, Validation Loss: 8.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14869, Training Loss: 7.243e-01, Validation Loss: 8.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14870, Training Loss: 7.243e-01, Validation Loss: 8.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14871, Training Loss: 7.242e-01, Validation Loss: 8.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14872, Training Loss: 7.242e-01, Validation Loss: 8.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14873, Training Loss: 7.241e-01, Validation Loss: 8.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14874, Training Loss: 7.241e-01, Validation Loss: 8.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14875, Training Loss: 7.241e-01, Validation Loss: 8.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14876, Training Loss: 7.240e-01, Validation Loss: 8.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14877, Training Loss: 7.240e-01, Validation Loss: 8.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14878, Training Loss: 7.239e-01, Validation Loss: 8.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14879, Training Loss: 7.239e-01, Validation Loss: 8.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14880, Training Loss: 7.238e-01, Validation Loss: 8.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14881, Training Loss: 7.238e-01, Validation Loss: 8.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14882, Training Loss: 7.237e-01, Validation Loss: 8.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14883, Training Loss: 7.237e-01, Validation Loss: 8.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14884, Training Loss: 7.236e-01, Validation Loss: 8.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14885, Training Loss: 7.236e-01, Validation Loss: 8.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14886, Training Loss: 7.235e-01, Validation Loss: 8.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14887, Training Loss: 7.235e-01, Validation Loss: 8.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14888, Training Loss: 7.234e-01, Validation Loss: 8.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14889, Training Loss: 7.234e-01, Validation Loss: 8.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14890, Training Loss: 7.233e-01, Validation Loss: 8.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14891, Training Loss: 7.233e-01, Validation Loss: 8.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14892, Training Loss: 7.232e-01, Validation Loss: 8.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14893, Training Loss: 7.232e-01, Validation Loss: 8.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14894, Training Loss: 7.232e-01, Validation Loss: 8.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14895, Training Loss: 7.231e-01, Validation Loss: 8.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14896, Training Loss: 7.231e-01, Validation Loss: 8.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14897, Training Loss: 7.230e-01, Validation Loss: 8.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14898, Training Loss: 7.230e-01, Validation Loss: 8.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14899, Training Loss: 7.229e-01, Validation Loss: 8.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14900, Training Loss: 7.229e-01, Validation Loss: 8.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14901, Training Loss: 7.228e-01, Validation Loss: 8.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14902, Training Loss: 7.228e-01, Validation Loss: 8.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14903, Training Loss: 7.227e-01, Validation Loss: 8.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14904, Training Loss: 7.227e-01, Validation Loss: 8.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14905, Training Loss: 7.226e-01, Validation Loss: 8.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14906, Training Loss: 7.226e-01, Validation Loss: 8.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14907, Training Loss: 7.225e-01, Validation Loss: 8.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14908, Training Loss: 7.225e-01, Validation Loss: 8.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14909, Training Loss: 7.224e-01, Validation Loss: 8.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14910, Training Loss: 7.224e-01, Validation Loss: 8.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14911, Training Loss: 7.223e-01, Validation Loss: 8.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14912, Training Loss: 7.223e-01, Validation Loss: 8.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14913, Training Loss: 7.223e-01, Validation Loss: 8.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14914, Training Loss: 7.222e-01, Validation Loss: 8.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14915, Training Loss: 7.222e-01, Validation Loss: 8.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14916, Training Loss: 7.221e-01, Validation Loss: 8.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14917, Training Loss: 7.221e-01, Validation Loss: 8.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14918, Training Loss: 7.220e-01, Validation Loss: 8.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14919, Training Loss: 7.220e-01, Validation Loss: 8.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14920, Training Loss: 7.219e-01, Validation Loss: 8.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14921, Training Loss: 7.219e-01, Validation Loss: 8.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14922, Training Loss: 7.218e-01, Validation Loss: 8.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14923, Training Loss: 7.218e-01, Validation Loss: 8.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14924, Training Loss: 7.217e-01, Validation Loss: 8.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14925, Training Loss: 7.217e-01, Validation Loss: 8.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14926, Training Loss: 7.216e-01, Validation Loss: 8.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14927, Training Loss: 7.216e-01, Validation Loss: 8.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14928, Training Loss: 7.215e-01, Validation Loss: 8.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14929, Training Loss: 7.215e-01, Validation Loss: 8.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14930, Training Loss: 7.214e-01, Validation Loss: 8.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14931, Training Loss: 7.214e-01, Validation Loss: 8.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14932, Training Loss: 7.213e-01, Validation Loss: 8.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14933, Training Loss: 7.213e-01, Validation Loss: 8.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14934, Training Loss: 7.213e-01, Validation Loss: 8.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14935, Training Loss: 7.212e-01, Validation Loss: 8.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14936, Training Loss: 7.212e-01, Validation Loss: 8.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14937, Training Loss: 7.211e-01, Validation Loss: 8.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14938, Training Loss: 7.211e-01, Validation Loss: 8.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14939, Training Loss: 7.210e-01, Validation Loss: 8.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14940, Training Loss: 7.210e-01, Validation Loss: 8.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14941, Training Loss: 7.209e-01, Validation Loss: 8.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14942, Training Loss: 7.209e-01, Validation Loss: 8.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14943, Training Loss: 7.208e-01, Validation Loss: 8.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14944, Training Loss: 7.208e-01, Validation Loss: 8.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14945, Training Loss: 7.207e-01, Validation Loss: 8.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14946, Training Loss: 7.207e-01, Validation Loss: 8.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14947, Training Loss: 7.206e-01, Validation Loss: 8.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14948, Training Loss: 7.206e-01, Validation Loss: 8.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14949, Training Loss: 7.205e-01, Validation Loss: 8.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14950, Training Loss: 7.205e-01, Validation Loss: 8.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14951, Training Loss: 7.204e-01, Validation Loss: 8.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14952, Training Loss: 7.204e-01, Validation Loss: 8.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14953, Training Loss: 7.203e-01, Validation Loss: 8.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14954, Training Loss: 7.203e-01, Validation Loss: 8.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14955, Training Loss: 7.203e-01, Validation Loss: 8.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14956, Training Loss: 7.202e-01, Validation Loss: 8.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14957, Training Loss: 7.202e-01, Validation Loss: 8.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14958, Training Loss: 7.201e-01, Validation Loss: 8.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14959, Training Loss: 7.201e-01, Validation Loss: 8.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14960, Training Loss: 7.200e-01, Validation Loss: 8.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14961, Training Loss: 7.200e-01, Validation Loss: 8.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14962, Training Loss: 7.199e-01, Validation Loss: 8.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14963, Training Loss: 7.199e-01, Validation Loss: 8.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14964, Training Loss: 7.198e-01, Validation Loss: 8.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14965, Training Loss: 7.198e-01, Validation Loss: 8.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14966, Training Loss: 7.197e-01, Validation Loss: 8.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14967, Training Loss: 7.197e-01, Validation Loss: 8.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14968, Training Loss: 7.196e-01, Validation Loss: 8.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14969, Training Loss: 7.196e-01, Validation Loss: 8.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14970, Training Loss: 7.195e-01, Validation Loss: 8.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14971, Training Loss: 7.195e-01, Validation Loss: 8.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14972, Training Loss: 7.195e-01, Validation Loss: 8.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14973, Training Loss: 7.194e-01, Validation Loss: 8.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14974, Training Loss: 7.194e-01, Validation Loss: 8.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14975, Training Loss: 7.193e-01, Validation Loss: 8.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14976, Training Loss: 7.193e-01, Validation Loss: 8.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14977, Training Loss: 7.192e-01, Validation Loss: 8.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14978, Training Loss: 7.192e-01, Validation Loss: 8.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14979, Training Loss: 7.191e-01, Validation Loss: 8.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14980, Training Loss: 7.191e-01, Validation Loss: 8.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14981, Training Loss: 7.190e-01, Validation Loss: 8.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14982, Training Loss: 7.190e-01, Validation Loss: 8.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14983, Training Loss: 7.189e-01, Validation Loss: 8.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14984, Training Loss: 7.189e-01, Validation Loss: 8.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14985, Training Loss: 7.188e-01, Validation Loss: 8.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14986, Training Loss: 7.188e-01, Validation Loss: 8.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14987, Training Loss: 7.187e-01, Validation Loss: 8.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14988, Training Loss: 7.187e-01, Validation Loss: 8.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14989, Training Loss: 7.187e-01, Validation Loss: 8.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14990, Training Loss: 7.186e-01, Validation Loss: 8.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14991, Training Loss: 7.186e-01, Validation Loss: 8.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14992, Training Loss: 7.185e-01, Validation Loss: 8.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14993, Training Loss: 7.185e-01, Validation Loss: 8.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14994, Training Loss: 7.184e-01, Validation Loss: 8.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14995, Training Loss: 7.184e-01, Validation Loss: 8.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14996, Training Loss: 7.183e-01, Validation Loss: 8.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14997, Training Loss: 7.183e-01, Validation Loss: 8.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14998, Training Loss: 7.182e-01, Validation Loss: 8.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14999, Training Loss: 7.182e-01, Validation Loss: 8.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15000, Training Loss: 7.181e-01, Validation Loss: 8.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15001, Training Loss: 7.181e-01, Validation Loss: 8.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15002, Training Loss: 7.180e-01, Validation Loss: 8.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15003, Training Loss: 7.180e-01, Validation Loss: 8.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15004, Training Loss: 7.180e-01, Validation Loss: 8.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15005, Training Loss: 7.179e-01, Validation Loss: 8.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15006, Training Loss: 7.179e-01, Validation Loss: 8.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15007, Training Loss: 7.178e-01, Validation Loss: 8.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15008, Training Loss: 7.178e-01, Validation Loss: 8.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15009, Training Loss: 7.177e-01, Validation Loss: 8.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15010, Training Loss: 7.177e-01, Validation Loss: 8.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15011, Training Loss: 7.176e-01, Validation Loss: 8.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15012, Training Loss: 7.176e-01, Validation Loss: 8.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15013, Training Loss: 7.175e-01, Validation Loss: 8.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15014, Training Loss: 7.175e-01, Validation Loss: 8.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15015, Training Loss: 7.174e-01, Validation Loss: 8.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15016, Training Loss: 7.174e-01, Validation Loss: 8.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15017, Training Loss: 7.174e-01, Validation Loss: 8.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15018, Training Loss: 7.173e-01, Validation Loss: 8.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15019, Training Loss: 7.173e-01, Validation Loss: 8.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15020, Training Loss: 7.172e-01, Validation Loss: 8.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15021, Training Loss: 7.172e-01, Validation Loss: 8.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15022, Training Loss: 7.171e-01, Validation Loss: 8.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15023, Training Loss: 7.171e-01, Validation Loss: 8.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15024, Training Loss: 7.170e-01, Validation Loss: 8.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15025, Training Loss: 7.170e-01, Validation Loss: 8.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15026, Training Loss: 7.169e-01, Validation Loss: 8.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15027, Training Loss: 7.169e-01, Validation Loss: 8.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15028, Training Loss: 7.168e-01, Validation Loss: 8.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15029, Training Loss: 7.168e-01, Validation Loss: 8.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15030, Training Loss: 7.168e-01, Validation Loss: 8.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15031, Training Loss: 7.167e-01, Validation Loss: 8.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15032, Training Loss: 7.167e-01, Validation Loss: 8.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15033, Training Loss: 7.166e-01, Validation Loss: 8.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15034, Training Loss: 7.166e-01, Validation Loss: 8.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15035, Training Loss: 7.165e-01, Validation Loss: 8.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15036, Training Loss: 7.165e-01, Validation Loss: 8.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15037, Training Loss: 7.164e-01, Validation Loss: 8.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15038, Training Loss: 7.164e-01, Validation Loss: 8.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15039, Training Loss: 7.163e-01, Validation Loss: 8.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15040, Training Loss: 7.163e-01, Validation Loss: 8.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15041, Training Loss: 7.162e-01, Validation Loss: 8.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15042, Training Loss: 7.162e-01, Validation Loss: 8.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15043, Training Loss: 7.162e-01, Validation Loss: 8.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15044, Training Loss: 7.161e-01, Validation Loss: 8.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15045, Training Loss: 7.161e-01, Validation Loss: 8.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15046, Training Loss: 7.160e-01, Validation Loss: 8.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15047, Training Loss: 7.160e-01, Validation Loss: 8.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15048, Training Loss: 7.159e-01, Validation Loss: 8.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15049, Training Loss: 7.159e-01, Validation Loss: 8.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15050, Training Loss: 7.158e-01, Validation Loss: 8.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15051, Training Loss: 7.158e-01, Validation Loss: 8.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15052, Training Loss: 7.157e-01, Validation Loss: 8.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15053, Training Loss: 7.157e-01, Validation Loss: 8.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15054, Training Loss: 7.156e-01, Validation Loss: 8.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15055, Training Loss: 7.156e-01, Validation Loss: 8.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15056, Training Loss: 7.156e-01, Validation Loss: 8.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15057, Training Loss: 7.155e-01, Validation Loss: 8.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15058, Training Loss: 7.155e-01, Validation Loss: 8.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15059, Training Loss: 7.154e-01, Validation Loss: 8.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15060, Training Loss: 7.154e-01, Validation Loss: 8.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15061, Training Loss: 7.153e-01, Validation Loss: 8.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15062, Training Loss: 7.153e-01, Validation Loss: 8.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15063, Training Loss: 7.152e-01, Validation Loss: 8.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15064, Training Loss: 7.152e-01, Validation Loss: 8.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15065, Training Loss: 7.151e-01, Validation Loss: 8.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15066, Training Loss: 7.151e-01, Validation Loss: 8.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15067, Training Loss: 7.150e-01, Validation Loss: 8.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15068, Training Loss: 7.150e-01, Validation Loss: 8.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15069, Training Loss: 7.150e-01, Validation Loss: 8.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15070, Training Loss: 7.149e-01, Validation Loss: 8.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15071, Training Loss: 7.149e-01, Validation Loss: 8.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15072, Training Loss: 7.148e-01, Validation Loss: 8.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15073, Training Loss: 7.148e-01, Validation Loss: 8.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15074, Training Loss: 7.147e-01, Validation Loss: 8.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15075, Training Loss: 7.147e-01, Validation Loss: 8.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15076, Training Loss: 7.146e-01, Validation Loss: 8.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15077, Training Loss: 7.146e-01, Validation Loss: 8.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15078, Training Loss: 7.145e-01, Validation Loss: 8.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15079, Training Loss: 7.145e-01, Validation Loss: 8.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15080, Training Loss: 7.145e-01, Validation Loss: 8.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15081, Training Loss: 7.144e-01, Validation Loss: 8.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15082, Training Loss: 7.144e-01, Validation Loss: 8.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15083, Training Loss: 7.143e-01, Validation Loss: 8.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15084, Training Loss: 7.143e-01, Validation Loss: 8.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15085, Training Loss: 7.142e-01, Validation Loss: 8.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15086, Training Loss: 7.142e-01, Validation Loss: 8.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15087, Training Loss: 7.141e-01, Validation Loss: 8.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15088, Training Loss: 7.141e-01, Validation Loss: 8.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15089, Training Loss: 7.140e-01, Validation Loss: 8.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15090, Training Loss: 7.140e-01, Validation Loss: 8.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15091, Training Loss: 7.139e-01, Validation Loss: 8.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15092, Training Loss: 7.139e-01, Validation Loss: 8.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15093, Training Loss: 7.139e-01, Validation Loss: 8.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15094, Training Loss: 7.138e-01, Validation Loss: 8.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15095, Training Loss: 7.138e-01, Validation Loss: 8.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15096, Training Loss: 7.137e-01, Validation Loss: 8.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15097, Training Loss: 7.137e-01, Validation Loss: 8.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15098, Training Loss: 7.136e-01, Validation Loss: 8.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15099, Training Loss: 7.136e-01, Validation Loss: 8.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15100, Training Loss: 7.135e-01, Validation Loss: 8.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15101, Training Loss: 7.135e-01, Validation Loss: 8.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15102, Training Loss: 7.134e-01, Validation Loss: 8.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15103, Training Loss: 7.134e-01, Validation Loss: 8.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15104, Training Loss: 7.134e-01, Validation Loss: 8.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15105, Training Loss: 7.133e-01, Validation Loss: 8.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15106, Training Loss: 7.133e-01, Validation Loss: 8.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15107, Training Loss: 7.132e-01, Validation Loss: 8.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15108, Training Loss: 7.132e-01, Validation Loss: 8.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15109, Training Loss: 7.131e-01, Validation Loss: 8.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15110, Training Loss: 7.131e-01, Validation Loss: 8.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15111, Training Loss: 7.130e-01, Validation Loss: 8.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15112, Training Loss: 7.130e-01, Validation Loss: 8.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15113, Training Loss: 7.129e-01, Validation Loss: 8.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15114, Training Loss: 7.129e-01, Validation Loss: 8.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15115, Training Loss: 7.128e-01, Validation Loss: 8.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15116, Training Loss: 7.128e-01, Validation Loss: 8.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15117, Training Loss: 7.128e-01, Validation Loss: 8.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15118, Training Loss: 7.127e-01, Validation Loss: 8.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15119, Training Loss: 7.127e-01, Validation Loss: 8.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15120, Training Loss: 7.126e-01, Validation Loss: 8.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15121, Training Loss: 7.126e-01, Validation Loss: 8.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15122, Training Loss: 7.125e-01, Validation Loss: 8.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15123, Training Loss: 7.125e-01, Validation Loss: 8.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15124, Training Loss: 7.124e-01, Validation Loss: 8.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15125, Training Loss: 7.124e-01, Validation Loss: 8.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15126, Training Loss: 7.123e-01, Validation Loss: 8.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15127, Training Loss: 7.123e-01, Validation Loss: 8.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15128, Training Loss: 7.123e-01, Validation Loss: 8.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15129, Training Loss: 7.122e-01, Validation Loss: 8.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15130, Training Loss: 7.122e-01, Validation Loss: 8.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15131, Training Loss: 7.121e-01, Validation Loss: 8.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15132, Training Loss: 7.121e-01, Validation Loss: 8.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15133, Training Loss: 7.120e-01, Validation Loss: 8.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15134, Training Loss: 7.120e-01, Validation Loss: 8.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15135, Training Loss: 7.119e-01, Validation Loss: 8.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15136, Training Loss: 7.119e-01, Validation Loss: 8.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15137, Training Loss: 7.118e-01, Validation Loss: 8.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15138, Training Loss: 7.118e-01, Validation Loss: 8.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15139, Training Loss: 7.118e-01, Validation Loss: 8.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15140, Training Loss: 7.117e-01, Validation Loss: 8.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15141, Training Loss: 7.117e-01, Validation Loss: 8.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15142, Training Loss: 7.116e-01, Validation Loss: 8.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15143, Training Loss: 7.116e-01, Validation Loss: 8.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15144, Training Loss: 7.115e-01, Validation Loss: 8.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15145, Training Loss: 7.115e-01, Validation Loss: 8.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15146, Training Loss: 7.114e-01, Validation Loss: 8.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15147, Training Loss: 7.114e-01, Validation Loss: 8.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15148, Training Loss: 7.113e-01, Validation Loss: 8.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15149, Training Loss: 7.113e-01, Validation Loss: 8.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15150, Training Loss: 7.113e-01, Validation Loss: 8.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15151, Training Loss: 7.112e-01, Validation Loss: 8.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15152, Training Loss: 7.112e-01, Validation Loss: 8.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15153, Training Loss: 7.111e-01, Validation Loss: 8.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15154, Training Loss: 7.111e-01, Validation Loss: 8.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15155, Training Loss: 7.110e-01, Validation Loss: 8.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15156, Training Loss: 7.110e-01, Validation Loss: 8.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15157, Training Loss: 7.109e-01, Validation Loss: 8.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15158, Training Loss: 7.109e-01, Validation Loss: 8.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15159, Training Loss: 7.108e-01, Validation Loss: 8.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15160, Training Loss: 7.108e-01, Validation Loss: 8.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15161, Training Loss: 7.108e-01, Validation Loss: 8.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15162, Training Loss: 7.107e-01, Validation Loss: 8.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15163, Training Loss: 7.107e-01, Validation Loss: 8.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15164, Training Loss: 7.106e-01, Validation Loss: 8.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15165, Training Loss: 7.106e-01, Validation Loss: 8.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15166, Training Loss: 7.105e-01, Validation Loss: 8.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15167, Training Loss: 7.105e-01, Validation Loss: 8.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15168, Training Loss: 7.104e-01, Validation Loss: 8.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15169, Training Loss: 7.104e-01, Validation Loss: 8.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15170, Training Loss: 7.103e-01, Validation Loss: 8.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15171, Training Loss: 7.103e-01, Validation Loss: 8.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15172, Training Loss: 7.103e-01, Validation Loss: 8.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15173, Training Loss: 7.102e-01, Validation Loss: 8.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15174, Training Loss: 7.102e-01, Validation Loss: 8.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15175, Training Loss: 7.101e-01, Validation Loss: 8.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15176, Training Loss: 7.101e-01, Validation Loss: 8.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15177, Training Loss: 7.100e-01, Validation Loss: 8.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15178, Training Loss: 7.100e-01, Validation Loss: 8.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15179, Training Loss: 7.099e-01, Validation Loss: 8.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15180, Training Loss: 7.099e-01, Validation Loss: 8.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15181, Training Loss: 7.098e-01, Validation Loss: 8.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15182, Training Loss: 7.098e-01, Validation Loss: 8.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15183, Training Loss: 7.098e-01, Validation Loss: 8.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15184, Training Loss: 7.097e-01, Validation Loss: 8.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15185, Training Loss: 7.097e-01, Validation Loss: 8.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15186, Training Loss: 7.096e-01, Validation Loss: 8.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15187, Training Loss: 7.096e-01, Validation Loss: 8.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15188, Training Loss: 7.095e-01, Validation Loss: 8.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15189, Training Loss: 7.095e-01, Validation Loss: 8.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15190, Training Loss: 7.094e-01, Validation Loss: 8.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15191, Training Loss: 7.094e-01, Validation Loss: 8.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15192, Training Loss: 7.093e-01, Validation Loss: 8.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15193, Training Loss: 7.093e-01, Validation Loss: 8.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15194, Training Loss: 7.093e-01, Validation Loss: 8.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15195, Training Loss: 7.092e-01, Validation Loss: 8.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15196, Training Loss: 7.092e-01, Validation Loss: 8.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15197, Training Loss: 7.091e-01, Validation Loss: 8.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15198, Training Loss: 7.091e-01, Validation Loss: 8.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15199, Training Loss: 7.090e-01, Validation Loss: 8.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15200, Training Loss: 7.090e-01, Validation Loss: 8.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15201, Training Loss: 7.089e-01, Validation Loss: 8.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15202, Training Loss: 7.089e-01, Validation Loss: 8.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15203, Training Loss: 7.088e-01, Validation Loss: 8.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15204, Training Loss: 7.088e-01, Validation Loss: 8.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15205, Training Loss: 7.088e-01, Validation Loss: 8.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15206, Training Loss: 7.087e-01, Validation Loss: 8.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15207, Training Loss: 7.087e-01, Validation Loss: 8.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15208, Training Loss: 7.086e-01, Validation Loss: 8.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15209, Training Loss: 7.086e-01, Validation Loss: 8.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15210, Training Loss: 7.085e-01, Validation Loss: 8.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15211, Training Loss: 7.085e-01, Validation Loss: 8.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15212, Training Loss: 7.084e-01, Validation Loss: 8.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15213, Training Loss: 7.084e-01, Validation Loss: 8.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15214, Training Loss: 7.083e-01, Validation Loss: 8.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15215, Training Loss: 7.083e-01, Validation Loss: 8.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15216, Training Loss: 7.083e-01, Validation Loss: 8.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15217, Training Loss: 7.082e-01, Validation Loss: 8.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15218, Training Loss: 7.082e-01, Validation Loss: 8.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15219, Training Loss: 7.081e-01, Validation Loss: 8.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15220, Training Loss: 7.081e-01, Validation Loss: 8.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15221, Training Loss: 7.080e-01, Validation Loss: 8.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15222, Training Loss: 7.080e-01, Validation Loss: 8.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15223, Training Loss: 7.079e-01, Validation Loss: 8.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15224, Training Loss: 7.079e-01, Validation Loss: 8.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15225, Training Loss: 7.079e-01, Validation Loss: 8.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15226, Training Loss: 7.078e-01, Validation Loss: 8.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15227, Training Loss: 7.078e-01, Validation Loss: 8.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15228, Training Loss: 7.077e-01, Validation Loss: 8.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15229, Training Loss: 7.077e-01, Validation Loss: 8.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15230, Training Loss: 7.076e-01, Validation Loss: 8.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15231, Training Loss: 7.076e-01, Validation Loss: 8.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15232, Training Loss: 7.075e-01, Validation Loss: 8.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15233, Training Loss: 7.075e-01, Validation Loss: 8.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15234, Training Loss: 7.074e-01, Validation Loss: 8.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15235, Training Loss: 7.074e-01, Validation Loss: 8.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15236, Training Loss: 7.074e-01, Validation Loss: 8.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15237, Training Loss: 7.073e-01, Validation Loss: 8.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15238, Training Loss: 7.073e-01, Validation Loss: 8.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15239, Training Loss: 7.072e-01, Validation Loss: 8.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15240, Training Loss: 7.072e-01, Validation Loss: 8.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15241, Training Loss: 7.071e-01, Validation Loss: 8.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15242, Training Loss: 7.071e-01, Validation Loss: 8.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15243, Training Loss: 7.070e-01, Validation Loss: 8.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15244, Training Loss: 7.070e-01, Validation Loss: 8.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15245, Training Loss: 7.069e-01, Validation Loss: 8.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15246, Training Loss: 7.069e-01, Validation Loss: 8.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15247, Training Loss: 7.069e-01, Validation Loss: 8.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15248, Training Loss: 7.068e-01, Validation Loss: 8.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15249, Training Loss: 7.068e-01, Validation Loss: 8.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15250, Training Loss: 7.067e-01, Validation Loss: 8.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15251, Training Loss: 7.067e-01, Validation Loss: 8.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15252, Training Loss: 7.066e-01, Validation Loss: 8.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15253, Training Loss: 7.066e-01, Validation Loss: 8.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15254, Training Loss: 7.065e-01, Validation Loss: 8.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15255, Training Loss: 7.065e-01, Validation Loss: 8.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15256, Training Loss: 7.064e-01, Validation Loss: 8.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15257, Training Loss: 7.064e-01, Validation Loss: 8.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15258, Training Loss: 7.064e-01, Validation Loss: 8.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15259, Training Loss: 7.063e-01, Validation Loss: 8.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15260, Training Loss: 7.063e-01, Validation Loss: 8.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15261, Training Loss: 7.062e-01, Validation Loss: 8.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15262, Training Loss: 7.062e-01, Validation Loss: 8.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15263, Training Loss: 7.061e-01, Validation Loss: 8.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15264, Training Loss: 7.061e-01, Validation Loss: 8.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15265, Training Loss: 7.060e-01, Validation Loss: 8.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15266, Training Loss: 7.060e-01, Validation Loss: 8.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15267, Training Loss: 7.059e-01, Validation Loss: 8.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15268, Training Loss: 7.059e-01, Validation Loss: 8.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15269, Training Loss: 7.059e-01, Validation Loss: 8.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15270, Training Loss: 7.058e-01, Validation Loss: 8.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15271, Training Loss: 7.058e-01, Validation Loss: 8.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15272, Training Loss: 7.057e-01, Validation Loss: 8.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15273, Training Loss: 7.057e-01, Validation Loss: 8.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15274, Training Loss: 7.056e-01, Validation Loss: 8.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15275, Training Loss: 7.056e-01, Validation Loss: 8.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15276, Training Loss: 7.055e-01, Validation Loss: 8.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15277, Training Loss: 7.055e-01, Validation Loss: 8.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15278, Training Loss: 7.054e-01, Validation Loss: 8.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15279, Training Loss: 7.054e-01, Validation Loss: 8.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15280, Training Loss: 7.054e-01, Validation Loss: 8.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15281, Training Loss: 7.053e-01, Validation Loss: 8.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15282, Training Loss: 7.053e-01, Validation Loss: 8.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15283, Training Loss: 7.052e-01, Validation Loss: 8.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15284, Training Loss: 7.052e-01, Validation Loss: 8.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15285, Training Loss: 7.051e-01, Validation Loss: 8.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15286, Training Loss: 7.051e-01, Validation Loss: 8.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15287, Training Loss: 7.050e-01, Validation Loss: 8.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15288, Training Loss: 7.050e-01, Validation Loss: 8.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15289, Training Loss: 7.049e-01, Validation Loss: 8.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15290, Training Loss: 7.049e-01, Validation Loss: 8.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15291, Training Loss: 7.049e-01, Validation Loss: 8.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15292, Training Loss: 7.048e-01, Validation Loss: 8.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15293, Training Loss: 7.048e-01, Validation Loss: 8.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15294, Training Loss: 7.047e-01, Validation Loss: 8.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15295, Training Loss: 7.047e-01, Validation Loss: 8.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15296, Training Loss: 7.046e-01, Validation Loss: 8.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15297, Training Loss: 7.046e-01, Validation Loss: 8.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15298, Training Loss: 7.045e-01, Validation Loss: 8.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15299, Training Loss: 7.045e-01, Validation Loss: 8.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15300, Training Loss: 7.044e-01, Validation Loss: 8.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15301, Training Loss: 7.044e-01, Validation Loss: 8.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15302, Training Loss: 7.044e-01, Validation Loss: 8.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15303, Training Loss: 7.043e-01, Validation Loss: 8.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15304, Training Loss: 7.043e-01, Validation Loss: 8.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15305, Training Loss: 7.042e-01, Validation Loss: 8.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15306, Training Loss: 7.042e-01, Validation Loss: 8.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15307, Training Loss: 7.041e-01, Validation Loss: 8.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15308, Training Loss: 7.041e-01, Validation Loss: 8.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15309, Training Loss: 7.040e-01, Validation Loss: 8.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15310, Training Loss: 7.040e-01, Validation Loss: 8.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15311, Training Loss: 7.039e-01, Validation Loss: 8.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15312, Training Loss: 7.039e-01, Validation Loss: 8.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15313, Training Loss: 7.039e-01, Validation Loss: 8.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15314, Training Loss: 7.038e-01, Validation Loss: 8.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15315, Training Loss: 7.038e-01, Validation Loss: 8.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15316, Training Loss: 7.037e-01, Validation Loss: 8.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15317, Training Loss: 7.037e-01, Validation Loss: 8.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15318, Training Loss: 7.036e-01, Validation Loss: 8.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15319, Training Loss: 7.036e-01, Validation Loss: 8.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15320, Training Loss: 7.035e-01, Validation Loss: 8.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15321, Training Loss: 7.035e-01, Validation Loss: 8.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15322, Training Loss: 7.034e-01, Validation Loss: 8.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15323, Training Loss: 7.034e-01, Validation Loss: 8.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15324, Training Loss: 7.034e-01, Validation Loss: 8.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15325, Training Loss: 7.033e-01, Validation Loss: 8.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15326, Training Loss: 7.033e-01, Validation Loss: 8.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15327, Training Loss: 7.032e-01, Validation Loss: 8.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15328, Training Loss: 7.032e-01, Validation Loss: 8.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15329, Training Loss: 7.031e-01, Validation Loss: 8.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15330, Training Loss: 7.031e-01, Validation Loss: 8.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15331, Training Loss: 7.030e-01, Validation Loss: 8.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15332, Training Loss: 7.030e-01, Validation Loss: 8.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15333, Training Loss: 7.029e-01, Validation Loss: 8.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15334, Training Loss: 7.029e-01, Validation Loss: 8.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15335, Training Loss: 7.029e-01, Validation Loss: 8.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15336, Training Loss: 7.028e-01, Validation Loss: 8.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15337, Training Loss: 7.028e-01, Validation Loss: 8.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15338, Training Loss: 7.027e-01, Validation Loss: 8.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15339, Training Loss: 7.027e-01, Validation Loss: 8.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15340, Training Loss: 7.026e-01, Validation Loss: 8.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15341, Training Loss: 7.026e-01, Validation Loss: 8.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15342, Training Loss: 7.025e-01, Validation Loss: 8.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15343, Training Loss: 7.025e-01, Validation Loss: 8.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15344, Training Loss: 7.025e-01, Validation Loss: 8.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15345, Training Loss: 7.024e-01, Validation Loss: 8.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15346, Training Loss: 7.024e-01, Validation Loss: 8.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15347, Training Loss: 7.023e-01, Validation Loss: 8.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15348, Training Loss: 7.023e-01, Validation Loss: 8.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15349, Training Loss: 7.022e-01, Validation Loss: 8.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15350, Training Loss: 7.022e-01, Validation Loss: 8.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15351, Training Loss: 7.021e-01, Validation Loss: 8.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15352, Training Loss: 7.021e-01, Validation Loss: 8.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15353, Training Loss: 7.020e-01, Validation Loss: 8.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15354, Training Loss: 7.020e-01, Validation Loss: 8.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15355, Training Loss: 7.020e-01, Validation Loss: 8.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15356, Training Loss: 7.019e-01, Validation Loss: 8.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15357, Training Loss: 7.019e-01, Validation Loss: 8.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15358, Training Loss: 7.018e-01, Validation Loss: 8.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15359, Training Loss: 7.018e-01, Validation Loss: 8.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15360, Training Loss: 7.017e-01, Validation Loss: 8.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15361, Training Loss: 7.017e-01, Validation Loss: 8.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15362, Training Loss: 7.016e-01, Validation Loss: 8.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15363, Training Loss: 7.016e-01, Validation Loss: 8.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15364, Training Loss: 7.016e-01, Validation Loss: 8.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15365, Training Loss: 7.015e-01, Validation Loss: 8.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15366, Training Loss: 7.015e-01, Validation Loss: 8.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15367, Training Loss: 7.014e-01, Validation Loss: 8.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15368, Training Loss: 7.014e-01, Validation Loss: 8.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15369, Training Loss: 7.013e-01, Validation Loss: 8.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15370, Training Loss: 7.013e-01, Validation Loss: 8.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15371, Training Loss: 7.012e-01, Validation Loss: 8.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15372, Training Loss: 7.012e-01, Validation Loss: 8.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15373, Training Loss: 7.011e-01, Validation Loss: 8.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15374, Training Loss: 7.011e-01, Validation Loss: 8.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15375, Training Loss: 7.011e-01, Validation Loss: 8.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15376, Training Loss: 7.010e-01, Validation Loss: 8.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15377, Training Loss: 7.010e-01, Validation Loss: 8.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15378, Training Loss: 7.009e-01, Validation Loss: 8.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15379, Training Loss: 7.009e-01, Validation Loss: 8.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15380, Training Loss: 7.008e-01, Validation Loss: 8.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15381, Training Loss: 7.008e-01, Validation Loss: 8.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15382, Training Loss: 7.007e-01, Validation Loss: 8.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15383, Training Loss: 7.007e-01, Validation Loss: 8.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15384, Training Loss: 7.007e-01, Validation Loss: 8.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15385, Training Loss: 7.006e-01, Validation Loss: 8.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15386, Training Loss: 7.006e-01, Validation Loss: 8.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15387, Training Loss: 7.005e-01, Validation Loss: 8.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15388, Training Loss: 7.005e-01, Validation Loss: 8.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15389, Training Loss: 7.004e-01, Validation Loss: 8.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15390, Training Loss: 7.004e-01, Validation Loss: 8.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15391, Training Loss: 7.003e-01, Validation Loss: 8.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15392, Training Loss: 7.003e-01, Validation Loss: 8.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15393, Training Loss: 7.003e-01, Validation Loss: 8.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15394, Training Loss: 7.002e-01, Validation Loss: 8.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15395, Training Loss: 7.002e-01, Validation Loss: 8.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15396, Training Loss: 7.001e-01, Validation Loss: 8.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15397, Training Loss: 7.001e-01, Validation Loss: 8.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15398, Training Loss: 7.000e-01, Validation Loss: 8.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15399, Training Loss: 7.000e-01, Validation Loss: 8.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15400, Training Loss: 6.999e-01, Validation Loss: 8.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15401, Training Loss: 6.999e-01, Validation Loss: 8.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15402, Training Loss: 6.999e-01, Validation Loss: 8.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15403, Training Loss: 6.998e-01, Validation Loss: 8.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15404, Training Loss: 6.998e-01, Validation Loss: 8.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15405, Training Loss: 6.997e-01, Validation Loss: 8.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15406, Training Loss: 6.997e-01, Validation Loss: 8.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15407, Training Loss: 6.996e-01, Validation Loss: 8.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15408, Training Loss: 6.996e-01, Validation Loss: 8.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15409, Training Loss: 6.995e-01, Validation Loss: 8.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15410, Training Loss: 6.995e-01, Validation Loss: 8.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15411, Training Loss: 6.995e-01, Validation Loss: 8.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15412, Training Loss: 6.994e-01, Validation Loss: 8.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15413, Training Loss: 6.994e-01, Validation Loss: 8.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15414, Training Loss: 6.993e-01, Validation Loss: 8.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15415, Training Loss: 6.993e-01, Validation Loss: 8.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15416, Training Loss: 6.992e-01, Validation Loss: 8.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15417, Training Loss: 6.992e-01, Validation Loss: 8.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15418, Training Loss: 6.991e-01, Validation Loss: 8.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15419, Training Loss: 6.991e-01, Validation Loss: 8.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15420, Training Loss: 6.991e-01, Validation Loss: 8.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15421, Training Loss: 6.990e-01, Validation Loss: 8.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15422, Training Loss: 6.990e-01, Validation Loss: 8.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15423, Training Loss: 6.989e-01, Validation Loss: 8.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15424, Training Loss: 6.989e-01, Validation Loss: 8.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15425, Training Loss: 6.988e-01, Validation Loss: 8.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15426, Training Loss: 6.988e-01, Validation Loss: 8.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15427, Training Loss: 6.987e-01, Validation Loss: 8.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15428, Training Loss: 6.987e-01, Validation Loss: 8.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15429, Training Loss: 6.987e-01, Validation Loss: 8.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15430, Training Loss: 6.986e-01, Validation Loss: 8.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15431, Training Loss: 6.986e-01, Validation Loss: 8.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15432, Training Loss: 6.985e-01, Validation Loss: 8.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15433, Training Loss: 6.985e-01, Validation Loss: 8.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15434, Training Loss: 6.984e-01, Validation Loss: 8.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15435, Training Loss: 6.984e-01, Validation Loss: 8.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15436, Training Loss: 6.983e-01, Validation Loss: 8.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15437, Training Loss: 6.983e-01, Validation Loss: 8.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15438, Training Loss: 6.983e-01, Validation Loss: 8.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15439, Training Loss: 6.982e-01, Validation Loss: 8.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15440, Training Loss: 6.982e-01, Validation Loss: 8.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15441, Training Loss: 6.981e-01, Validation Loss: 8.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15442, Training Loss: 6.981e-01, Validation Loss: 8.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15443, Training Loss: 6.980e-01, Validation Loss: 8.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15444, Training Loss: 6.980e-01, Validation Loss: 8.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15445, Training Loss: 6.979e-01, Validation Loss: 8.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15446, Training Loss: 6.979e-01, Validation Loss: 8.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15447, Training Loss: 6.979e-01, Validation Loss: 8.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15448, Training Loss: 6.978e-01, Validation Loss: 8.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15449, Training Loss: 6.978e-01, Validation Loss: 8.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15450, Training Loss: 6.977e-01, Validation Loss: 8.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15451, Training Loss: 6.977e-01, Validation Loss: 8.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15452, Training Loss: 6.976e-01, Validation Loss: 8.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15453, Training Loss: 6.976e-01, Validation Loss: 8.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15454, Training Loss: 6.975e-01, Validation Loss: 8.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15455, Training Loss: 6.975e-01, Validation Loss: 8.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15456, Training Loss: 6.975e-01, Validation Loss: 8.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15457, Training Loss: 6.974e-01, Validation Loss: 8.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15458, Training Loss: 6.974e-01, Validation Loss: 8.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15459, Training Loss: 6.973e-01, Validation Loss: 8.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15460, Training Loss: 6.973e-01, Validation Loss: 8.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15461, Training Loss: 6.972e-01, Validation Loss: 8.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15462, Training Loss: 6.972e-01, Validation Loss: 8.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15463, Training Loss: 6.971e-01, Validation Loss: 8.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15464, Training Loss: 6.971e-01, Validation Loss: 8.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15465, Training Loss: 6.971e-01, Validation Loss: 8.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15466, Training Loss: 6.970e-01, Validation Loss: 8.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15467, Training Loss: 6.970e-01, Validation Loss: 8.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15468, Training Loss: 6.969e-01, Validation Loss: 8.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15469, Training Loss: 6.969e-01, Validation Loss: 8.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15470, Training Loss: 6.968e-01, Validation Loss: 8.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15471, Training Loss: 6.968e-01, Validation Loss: 8.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15472, Training Loss: 6.967e-01, Validation Loss: 8.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15473, Training Loss: 6.967e-01, Validation Loss: 8.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15474, Training Loss: 6.967e-01, Validation Loss: 8.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15475, Training Loss: 6.966e-01, Validation Loss: 8.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15476, Training Loss: 6.966e-01, Validation Loss: 8.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15477, Training Loss: 6.965e-01, Validation Loss: 8.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15478, Training Loss: 6.965e-01, Validation Loss: 8.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15479, Training Loss: 6.964e-01, Validation Loss: 8.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15480, Training Loss: 6.964e-01, Validation Loss: 8.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15481, Training Loss: 6.964e-01, Validation Loss: 8.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15482, Training Loss: 6.963e-01, Validation Loss: 8.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15483, Training Loss: 6.963e-01, Validation Loss: 8.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15484, Training Loss: 6.962e-01, Validation Loss: 8.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15485, Training Loss: 6.962e-01, Validation Loss: 8.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15486, Training Loss: 6.961e-01, Validation Loss: 8.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15487, Training Loss: 6.961e-01, Validation Loss: 8.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15488, Training Loss: 6.960e-01, Validation Loss: 8.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15489, Training Loss: 6.960e-01, Validation Loss: 8.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15490, Training Loss: 6.960e-01, Validation Loss: 8.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15491, Training Loss: 6.959e-01, Validation Loss: 8.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15492, Training Loss: 6.959e-01, Validation Loss: 8.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15493, Training Loss: 6.958e-01, Validation Loss: 8.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15494, Training Loss: 6.958e-01, Validation Loss: 8.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15495, Training Loss: 6.957e-01, Validation Loss: 8.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15496, Training Loss: 6.957e-01, Validation Loss: 8.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15497, Training Loss: 6.956e-01, Validation Loss: 8.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15498, Training Loss: 6.956e-01, Validation Loss: 8.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15499, Training Loss: 6.956e-01, Validation Loss: 8.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15500, Training Loss: 6.955e-01, Validation Loss: 8.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15501, Training Loss: 6.955e-01, Validation Loss: 8.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15502, Training Loss: 6.954e-01, Validation Loss: 8.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15503, Training Loss: 6.954e-01, Validation Loss: 8.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15504, Training Loss: 6.953e-01, Validation Loss: 8.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15505, Training Loss: 6.953e-01, Validation Loss: 8.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15506, Training Loss: 6.953e-01, Validation Loss: 8.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15507, Training Loss: 6.952e-01, Validation Loss: 8.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15508, Training Loss: 6.952e-01, Validation Loss: 8.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15509, Training Loss: 6.951e-01, Validation Loss: 8.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15510, Training Loss: 6.951e-01, Validation Loss: 8.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15511, Training Loss: 6.950e-01, Validation Loss: 8.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15512, Training Loss: 6.950e-01, Validation Loss: 8.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15513, Training Loss: 6.949e-01, Validation Loss: 8.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15514, Training Loss: 6.949e-01, Validation Loss: 8.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15515, Training Loss: 6.949e-01, Validation Loss: 8.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15516, Training Loss: 6.948e-01, Validation Loss: 8.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15517, Training Loss: 6.948e-01, Validation Loss: 8.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15518, Training Loss: 6.947e-01, Validation Loss: 8.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15519, Training Loss: 6.947e-01, Validation Loss: 8.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15520, Training Loss: 6.946e-01, Validation Loss: 8.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15521, Training Loss: 6.946e-01, Validation Loss: 8.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15522, Training Loss: 6.945e-01, Validation Loss: 8.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15523, Training Loss: 6.945e-01, Validation Loss: 8.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15524, Training Loss: 6.945e-01, Validation Loss: 8.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15525, Training Loss: 6.944e-01, Validation Loss: 8.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15526, Training Loss: 6.944e-01, Validation Loss: 8.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15527, Training Loss: 6.943e-01, Validation Loss: 8.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15528, Training Loss: 6.943e-01, Validation Loss: 8.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15529, Training Loss: 6.942e-01, Validation Loss: 8.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15530, Training Loss: 6.942e-01, Validation Loss: 8.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15531, Training Loss: 6.942e-01, Validation Loss: 8.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15532, Training Loss: 6.941e-01, Validation Loss: 8.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15533, Training Loss: 6.941e-01, Validation Loss: 8.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15534, Training Loss: 6.940e-01, Validation Loss: 8.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15535, Training Loss: 6.940e-01, Validation Loss: 8.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15536, Training Loss: 6.939e-01, Validation Loss: 8.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15537, Training Loss: 6.939e-01, Validation Loss: 8.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15538, Training Loss: 6.938e-01, Validation Loss: 8.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15539, Training Loss: 6.938e-01, Validation Loss: 8.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15540, Training Loss: 6.938e-01, Validation Loss: 8.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15541, Training Loss: 6.937e-01, Validation Loss: 8.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15542, Training Loss: 6.937e-01, Validation Loss: 8.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15543, Training Loss: 6.936e-01, Validation Loss: 8.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15544, Training Loss: 6.936e-01, Validation Loss: 8.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15545, Training Loss: 6.935e-01, Validation Loss: 8.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15546, Training Loss: 6.935e-01, Validation Loss: 8.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15547, Training Loss: 6.935e-01, Validation Loss: 8.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15548, Training Loss: 6.934e-01, Validation Loss: 8.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15549, Training Loss: 6.934e-01, Validation Loss: 8.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15550, Training Loss: 6.933e-01, Validation Loss: 8.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15551, Training Loss: 6.933e-01, Validation Loss: 8.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15552, Training Loss: 6.932e-01, Validation Loss: 8.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15553, Training Loss: 6.932e-01, Validation Loss: 8.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15554, Training Loss: 6.931e-01, Validation Loss: 8.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15555, Training Loss: 6.931e-01, Validation Loss: 8.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15556, Training Loss: 6.931e-01, Validation Loss: 8.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15557, Training Loss: 6.930e-01, Validation Loss: 8.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15558, Training Loss: 6.930e-01, Validation Loss: 8.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15559, Training Loss: 6.929e-01, Validation Loss: 8.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15560, Training Loss: 6.929e-01, Validation Loss: 8.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15561, Training Loss: 6.928e-01, Validation Loss: 8.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15562, Training Loss: 6.928e-01, Validation Loss: 8.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15563, Training Loss: 6.928e-01, Validation Loss: 8.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15564, Training Loss: 6.927e-01, Validation Loss: 8.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15565, Training Loss: 6.927e-01, Validation Loss: 8.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15566, Training Loss: 6.926e-01, Validation Loss: 8.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15567, Training Loss: 6.926e-01, Validation Loss: 8.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15568, Training Loss: 6.925e-01, Validation Loss: 8.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15569, Training Loss: 6.925e-01, Validation Loss: 8.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15570, Training Loss: 6.924e-01, Validation Loss: 8.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15571, Training Loss: 6.924e-01, Validation Loss: 8.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15572, Training Loss: 6.924e-01, Validation Loss: 8.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15573, Training Loss: 6.923e-01, Validation Loss: 8.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15574, Training Loss: 6.923e-01, Validation Loss: 8.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15575, Training Loss: 6.922e-01, Validation Loss: 8.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15576, Training Loss: 6.922e-01, Validation Loss: 8.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15577, Training Loss: 6.921e-01, Validation Loss: 8.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15578, Training Loss: 6.921e-01, Validation Loss: 8.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15579, Training Loss: 6.921e-01, Validation Loss: 8.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15580, Training Loss: 6.920e-01, Validation Loss: 8.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15581, Training Loss: 6.920e-01, Validation Loss: 8.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15582, Training Loss: 6.919e-01, Validation Loss: 8.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15583, Training Loss: 6.919e-01, Validation Loss: 8.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15584, Training Loss: 6.918e-01, Validation Loss: 8.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15585, Training Loss: 6.918e-01, Validation Loss: 8.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15586, Training Loss: 6.917e-01, Validation Loss: 8.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15587, Training Loss: 6.917e-01, Validation Loss: 8.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15588, Training Loss: 6.917e-01, Validation Loss: 8.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15589, Training Loss: 6.916e-01, Validation Loss: 8.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15590, Training Loss: 6.916e-01, Validation Loss: 8.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15591, Training Loss: 6.915e-01, Validation Loss: 8.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15592, Training Loss: 6.915e-01, Validation Loss: 8.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15593, Training Loss: 6.914e-01, Validation Loss: 8.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15594, Training Loss: 6.914e-01, Validation Loss: 8.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15595, Training Loss: 6.914e-01, Validation Loss: 8.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15596, Training Loss: 6.913e-01, Validation Loss: 8.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15597, Training Loss: 6.913e-01, Validation Loss: 8.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15598, Training Loss: 6.912e-01, Validation Loss: 8.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15599, Training Loss: 6.912e-01, Validation Loss: 8.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15600, Training Loss: 6.911e-01, Validation Loss: 8.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15601, Training Loss: 6.911e-01, Validation Loss: 8.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15602, Training Loss: 6.911e-01, Validation Loss: 8.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15603, Training Loss: 6.910e-01, Validation Loss: 8.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15604, Training Loss: 6.910e-01, Validation Loss: 8.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15605, Training Loss: 6.909e-01, Validation Loss: 8.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15606, Training Loss: 6.909e-01, Validation Loss: 8.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15607, Training Loss: 6.908e-01, Validation Loss: 8.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15608, Training Loss: 6.908e-01, Validation Loss: 8.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15609, Training Loss: 6.907e-01, Validation Loss: 8.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15610, Training Loss: 6.907e-01, Validation Loss: 8.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15611, Training Loss: 6.907e-01, Validation Loss: 8.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15612, Training Loss: 6.906e-01, Validation Loss: 8.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15613, Training Loss: 6.906e-01, Validation Loss: 8.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15614, Training Loss: 6.905e-01, Validation Loss: 8.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15615, Training Loss: 6.905e-01, Validation Loss: 8.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15616, Training Loss: 6.904e-01, Validation Loss: 8.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15617, Training Loss: 6.904e-01, Validation Loss: 8.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15618, Training Loss: 6.904e-01, Validation Loss: 8.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15619, Training Loss: 6.903e-01, Validation Loss: 8.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15620, Training Loss: 6.903e-01, Validation Loss: 8.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15621, Training Loss: 6.902e-01, Validation Loss: 8.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15622, Training Loss: 6.902e-01, Validation Loss: 8.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15623, Training Loss: 6.901e-01, Validation Loss: 8.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15624, Training Loss: 6.901e-01, Validation Loss: 8.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15625, Training Loss: 6.901e-01, Validation Loss: 8.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15626, Training Loss: 6.900e-01, Validation Loss: 8.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15627, Training Loss: 6.900e-01, Validation Loss: 8.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15628, Training Loss: 6.899e-01, Validation Loss: 8.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15629, Training Loss: 6.899e-01, Validation Loss: 8.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15630, Training Loss: 6.898e-01, Validation Loss: 8.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15631, Training Loss: 6.898e-01, Validation Loss: 8.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15632, Training Loss: 6.897e-01, Validation Loss: 8.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15633, Training Loss: 6.897e-01, Validation Loss: 8.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15634, Training Loss: 6.897e-01, Validation Loss: 8.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15635, Training Loss: 6.896e-01, Validation Loss: 8.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15636, Training Loss: 6.896e-01, Validation Loss: 8.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15637, Training Loss: 6.895e-01, Validation Loss: 8.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15638, Training Loss: 6.895e-01, Validation Loss: 8.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15639, Training Loss: 6.894e-01, Validation Loss: 8.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15640, Training Loss: 6.894e-01, Validation Loss: 8.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15641, Training Loss: 6.894e-01, Validation Loss: 8.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15642, Training Loss: 6.893e-01, Validation Loss: 8.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15643, Training Loss: 6.893e-01, Validation Loss: 8.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15644, Training Loss: 6.892e-01, Validation Loss: 8.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15645, Training Loss: 6.892e-01, Validation Loss: 8.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15646, Training Loss: 6.891e-01, Validation Loss: 8.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15647, Training Loss: 6.891e-01, Validation Loss: 8.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15648, Training Loss: 6.891e-01, Validation Loss: 8.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15649, Training Loss: 6.890e-01, Validation Loss: 8.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15650, Training Loss: 6.890e-01, Validation Loss: 8.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15651, Training Loss: 6.889e-01, Validation Loss: 8.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15652, Training Loss: 6.889e-01, Validation Loss: 8.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15653, Training Loss: 6.888e-01, Validation Loss: 8.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15654, Training Loss: 6.888e-01, Validation Loss: 8.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15655, Training Loss: 6.888e-01, Validation Loss: 8.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15656, Training Loss: 6.887e-01, Validation Loss: 8.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15657, Training Loss: 6.887e-01, Validation Loss: 8.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15658, Training Loss: 6.886e-01, Validation Loss: 8.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15659, Training Loss: 6.886e-01, Validation Loss: 8.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15660, Training Loss: 6.885e-01, Validation Loss: 8.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15661, Training Loss: 6.885e-01, Validation Loss: 8.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15662, Training Loss: 6.885e-01, Validation Loss: 8.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15663, Training Loss: 6.884e-01, Validation Loss: 8.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15664, Training Loss: 6.884e-01, Validation Loss: 8.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15665, Training Loss: 6.883e-01, Validation Loss: 8.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15666, Training Loss: 6.883e-01, Validation Loss: 8.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15667, Training Loss: 6.882e-01, Validation Loss: 8.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15668, Training Loss: 6.882e-01, Validation Loss: 8.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15669, Training Loss: 6.881e-01, Validation Loss: 8.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15670, Training Loss: 6.881e-01, Validation Loss: 8.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15671, Training Loss: 6.881e-01, Validation Loss: 8.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15672, Training Loss: 6.880e-01, Validation Loss: 8.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15673, Training Loss: 6.880e-01, Validation Loss: 8.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15674, Training Loss: 6.879e-01, Validation Loss: 8.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15675, Training Loss: 6.879e-01, Validation Loss: 8.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15676, Training Loss: 6.878e-01, Validation Loss: 8.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15677, Training Loss: 6.878e-01, Validation Loss: 8.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15678, Training Loss: 6.878e-01, Validation Loss: 8.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15679, Training Loss: 6.877e-01, Validation Loss: 8.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15680, Training Loss: 6.877e-01, Validation Loss: 8.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15681, Training Loss: 6.876e-01, Validation Loss: 8.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15682, Training Loss: 6.876e-01, Validation Loss: 8.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15683, Training Loss: 6.875e-01, Validation Loss: 8.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15684, Training Loss: 6.875e-01, Validation Loss: 8.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15685, Training Loss: 6.875e-01, Validation Loss: 8.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15686, Training Loss: 6.874e-01, Validation Loss: 8.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15687, Training Loss: 6.874e-01, Validation Loss: 8.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15688, Training Loss: 6.873e-01, Validation Loss: 8.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15689, Training Loss: 6.873e-01, Validation Loss: 8.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15690, Training Loss: 6.872e-01, Validation Loss: 8.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15691, Training Loss: 6.872e-01, Validation Loss: 8.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15692, Training Loss: 6.872e-01, Validation Loss: 8.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15693, Training Loss: 6.871e-01, Validation Loss: 8.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15694, Training Loss: 6.871e-01, Validation Loss: 8.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15695, Training Loss: 6.870e-01, Validation Loss: 8.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15696, Training Loss: 6.870e-01, Validation Loss: 8.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15697, Training Loss: 6.869e-01, Validation Loss: 8.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15698, Training Loss: 6.869e-01, Validation Loss: 8.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15699, Training Loss: 6.869e-01, Validation Loss: 8.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15700, Training Loss: 6.868e-01, Validation Loss: 8.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15701, Training Loss: 6.868e-01, Validation Loss: 8.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15702, Training Loss: 6.867e-01, Validation Loss: 8.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15703, Training Loss: 6.867e-01, Validation Loss: 8.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15704, Training Loss: 6.866e-01, Validation Loss: 8.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15705, Training Loss: 6.866e-01, Validation Loss: 8.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15706, Training Loss: 6.866e-01, Validation Loss: 8.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15707, Training Loss: 6.865e-01, Validation Loss: 8.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15708, Training Loss: 6.865e-01, Validation Loss: 8.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15709, Training Loss: 6.864e-01, Validation Loss: 8.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15710, Training Loss: 6.864e-01, Validation Loss: 8.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15711, Training Loss: 6.863e-01, Validation Loss: 8.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15712, Training Loss: 6.863e-01, Validation Loss: 8.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15713, Training Loss: 6.863e-01, Validation Loss: 8.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15714, Training Loss: 6.862e-01, Validation Loss: 8.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15715, Training Loss: 6.862e-01, Validation Loss: 8.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15716, Training Loss: 6.861e-01, Validation Loss: 8.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15717, Training Loss: 6.861e-01, Validation Loss: 8.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15718, Training Loss: 6.860e-01, Validation Loss: 8.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15719, Training Loss: 6.860e-01, Validation Loss: 8.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15720, Training Loss: 6.860e-01, Validation Loss: 8.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15721, Training Loss: 6.859e-01, Validation Loss: 8.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15722, Training Loss: 6.859e-01, Validation Loss: 8.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15723, Training Loss: 6.858e-01, Validation Loss: 8.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15724, Training Loss: 6.858e-01, Validation Loss: 8.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15725, Training Loss: 6.857e-01, Validation Loss: 8.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15726, Training Loss: 6.857e-01, Validation Loss: 8.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15727, Training Loss: 6.857e-01, Validation Loss: 8.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15728, Training Loss: 6.856e-01, Validation Loss: 8.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15729, Training Loss: 6.856e-01, Validation Loss: 8.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15730, Training Loss: 6.855e-01, Validation Loss: 8.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15731, Training Loss: 6.855e-01, Validation Loss: 8.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15732, Training Loss: 6.854e-01, Validation Loss: 8.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15733, Training Loss: 6.854e-01, Validation Loss: 8.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15734, Training Loss: 6.854e-01, Validation Loss: 8.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15735, Training Loss: 6.853e-01, Validation Loss: 8.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15736, Training Loss: 6.853e-01, Validation Loss: 8.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15737, Training Loss: 6.852e-01, Validation Loss: 8.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15738, Training Loss: 6.852e-01, Validation Loss: 8.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15739, Training Loss: 6.851e-01, Validation Loss: 8.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15740, Training Loss: 6.851e-01, Validation Loss: 8.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15741, Training Loss: 6.851e-01, Validation Loss: 8.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15742, Training Loss: 6.850e-01, Validation Loss: 8.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15743, Training Loss: 6.850e-01, Validation Loss: 8.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15744, Training Loss: 6.849e-01, Validation Loss: 8.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15745, Training Loss: 6.849e-01, Validation Loss: 8.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15746, Training Loss: 6.848e-01, Validation Loss: 8.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15747, Training Loss: 6.848e-01, Validation Loss: 8.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15748, Training Loss: 6.848e-01, Validation Loss: 8.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15749, Training Loss: 6.847e-01, Validation Loss: 8.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15750, Training Loss: 6.847e-01, Validation Loss: 8.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15751, Training Loss: 6.846e-01, Validation Loss: 8.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15752, Training Loss: 6.846e-01, Validation Loss: 8.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15753, Training Loss: 6.845e-01, Validation Loss: 8.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15754, Training Loss: 6.845e-01, Validation Loss: 8.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15755, Training Loss: 6.845e-01, Validation Loss: 8.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15756, Training Loss: 6.844e-01, Validation Loss: 8.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15757, Training Loss: 6.844e-01, Validation Loss: 8.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15758, Training Loss: 6.843e-01, Validation Loss: 8.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15759, Training Loss: 6.843e-01, Validation Loss: 8.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15760, Training Loss: 6.842e-01, Validation Loss: 8.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15761, Training Loss: 6.842e-01, Validation Loss: 8.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15762, Training Loss: 6.842e-01, Validation Loss: 8.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15763, Training Loss: 6.841e-01, Validation Loss: 8.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15764, Training Loss: 6.841e-01, Validation Loss: 8.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15765, Training Loss: 6.840e-01, Validation Loss: 8.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15766, Training Loss: 6.840e-01, Validation Loss: 8.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15767, Training Loss: 6.839e-01, Validation Loss: 8.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15768, Training Loss: 6.839e-01, Validation Loss: 8.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15769, Training Loss: 6.839e-01, Validation Loss: 8.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15770, Training Loss: 6.838e-01, Validation Loss: 8.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15771, Training Loss: 6.838e-01, Validation Loss: 8.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15772, Training Loss: 6.837e-01, Validation Loss: 8.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15773, Training Loss: 6.837e-01, Validation Loss: 8.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15774, Training Loss: 6.836e-01, Validation Loss: 8.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15775, Training Loss: 6.836e-01, Validation Loss: 8.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15776, Training Loss: 6.836e-01, Validation Loss: 8.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15777, Training Loss: 6.835e-01, Validation Loss: 8.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15778, Training Loss: 6.835e-01, Validation Loss: 8.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15779, Training Loss: 6.834e-01, Validation Loss: 8.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15780, Training Loss: 6.834e-01, Validation Loss: 8.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15781, Training Loss: 6.833e-01, Validation Loss: 8.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15782, Training Loss: 6.833e-01, Validation Loss: 8.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15783, Training Loss: 6.833e-01, Validation Loss: 8.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15784, Training Loss: 6.832e-01, Validation Loss: 8.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15785, Training Loss: 6.832e-01, Validation Loss: 8.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15786, Training Loss: 6.831e-01, Validation Loss: 8.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15787, Training Loss: 6.831e-01, Validation Loss: 8.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15788, Training Loss: 6.830e-01, Validation Loss: 8.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15789, Training Loss: 6.830e-01, Validation Loss: 8.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15790, Training Loss: 6.830e-01, Validation Loss: 8.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15791, Training Loss: 6.829e-01, Validation Loss: 8.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15792, Training Loss: 6.829e-01, Validation Loss: 8.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15793, Training Loss: 6.828e-01, Validation Loss: 8.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15794, Training Loss: 6.828e-01, Validation Loss: 8.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15795, Training Loss: 6.828e-01, Validation Loss: 8.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15796, Training Loss: 6.827e-01, Validation Loss: 8.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15797, Training Loss: 6.827e-01, Validation Loss: 8.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15798, Training Loss: 6.826e-01, Validation Loss: 8.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15799, Training Loss: 6.826e-01, Validation Loss: 8.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15800, Training Loss: 6.825e-01, Validation Loss: 8.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15801, Training Loss: 6.825e-01, Validation Loss: 8.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15802, Training Loss: 6.825e-01, Validation Loss: 8.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15803, Training Loss: 6.824e-01, Validation Loss: 8.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15804, Training Loss: 6.824e-01, Validation Loss: 8.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15805, Training Loss: 6.823e-01, Validation Loss: 8.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15806, Training Loss: 6.823e-01, Validation Loss: 8.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15807, Training Loss: 6.822e-01, Validation Loss: 8.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15808, Training Loss: 6.822e-01, Validation Loss: 8.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15809, Training Loss: 6.822e-01, Validation Loss: 8.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15810, Training Loss: 6.821e-01, Validation Loss: 8.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15811, Training Loss: 6.821e-01, Validation Loss: 8.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15812, Training Loss: 6.820e-01, Validation Loss: 8.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15813, Training Loss: 6.820e-01, Validation Loss: 8.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15814, Training Loss: 6.819e-01, Validation Loss: 8.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15815, Training Loss: 6.819e-01, Validation Loss: 8.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15816, Training Loss: 6.819e-01, Validation Loss: 8.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15817, Training Loss: 6.818e-01, Validation Loss: 8.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15818, Training Loss: 6.818e-01, Validation Loss: 8.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15819, Training Loss: 6.817e-01, Validation Loss: 8.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15820, Training Loss: 6.817e-01, Validation Loss: 8.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15821, Training Loss: 6.816e-01, Validation Loss: 8.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15822, Training Loss: 6.816e-01, Validation Loss: 8.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15823, Training Loss: 6.816e-01, Validation Loss: 8.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15824, Training Loss: 6.815e-01, Validation Loss: 8.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15825, Training Loss: 6.815e-01, Validation Loss: 8.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15826, Training Loss: 6.814e-01, Validation Loss: 8.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15827, Training Loss: 6.814e-01, Validation Loss: 8.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15828, Training Loss: 6.813e-01, Validation Loss: 8.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15829, Training Loss: 6.813e-01, Validation Loss: 8.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15830, Training Loss: 6.813e-01, Validation Loss: 8.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15831, Training Loss: 6.812e-01, Validation Loss: 8.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15832, Training Loss: 6.812e-01, Validation Loss: 8.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15833, Training Loss: 6.811e-01, Validation Loss: 8.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15834, Training Loss: 6.811e-01, Validation Loss: 8.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15835, Training Loss: 6.811e-01, Validation Loss: 8.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15836, Training Loss: 6.810e-01, Validation Loss: 8.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15837, Training Loss: 6.810e-01, Validation Loss: 8.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15838, Training Loss: 6.809e-01, Validation Loss: 8.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15839, Training Loss: 6.809e-01, Validation Loss: 8.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15840, Training Loss: 6.808e-01, Validation Loss: 8.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15841, Training Loss: 6.808e-01, Validation Loss: 8.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15842, Training Loss: 6.808e-01, Validation Loss: 8.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15843, Training Loss: 6.807e-01, Validation Loss: 8.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15844, Training Loss: 6.807e-01, Validation Loss: 8.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15845, Training Loss: 6.806e-01, Validation Loss: 8.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15846, Training Loss: 6.806e-01, Validation Loss: 8.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15847, Training Loss: 6.805e-01, Validation Loss: 8.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15848, Training Loss: 6.805e-01, Validation Loss: 8.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15849, Training Loss: 6.805e-01, Validation Loss: 8.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15850, Training Loss: 6.804e-01, Validation Loss: 8.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15851, Training Loss: 6.804e-01, Validation Loss: 8.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15852, Training Loss: 6.803e-01, Validation Loss: 8.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15853, Training Loss: 6.803e-01, Validation Loss: 8.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15854, Training Loss: 6.803e-01, Validation Loss: 8.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15855, Training Loss: 6.802e-01, Validation Loss: 8.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15856, Training Loss: 6.802e-01, Validation Loss: 8.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15857, Training Loss: 6.801e-01, Validation Loss: 8.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15858, Training Loss: 6.801e-01, Validation Loss: 8.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15859, Training Loss: 6.800e-01, Validation Loss: 8.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15860, Training Loss: 6.800e-01, Validation Loss: 8.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15861, Training Loss: 6.800e-01, Validation Loss: 8.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15862, Training Loss: 6.799e-01, Validation Loss: 8.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15863, Training Loss: 6.799e-01, Validation Loss: 8.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15864, Training Loss: 6.798e-01, Validation Loss: 8.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15865, Training Loss: 6.798e-01, Validation Loss: 8.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15866, Training Loss: 6.797e-01, Validation Loss: 8.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15867, Training Loss: 6.797e-01, Validation Loss: 8.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15868, Training Loss: 6.797e-01, Validation Loss: 8.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15869, Training Loss: 6.796e-01, Validation Loss: 8.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15870, Training Loss: 6.796e-01, Validation Loss: 8.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15871, Training Loss: 6.795e-01, Validation Loss: 8.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15872, Training Loss: 6.795e-01, Validation Loss: 8.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15873, Training Loss: 6.794e-01, Validation Loss: 8.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15874, Training Loss: 6.794e-01, Validation Loss: 8.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15875, Training Loss: 6.794e-01, Validation Loss: 8.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15876, Training Loss: 6.793e-01, Validation Loss: 8.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15877, Training Loss: 6.793e-01, Validation Loss: 8.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15878, Training Loss: 6.792e-01, Validation Loss: 8.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15879, Training Loss: 6.792e-01, Validation Loss: 8.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15880, Training Loss: 6.792e-01, Validation Loss: 8.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15881, Training Loss: 6.791e-01, Validation Loss: 8.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15882, Training Loss: 6.791e-01, Validation Loss: 8.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15883, Training Loss: 6.790e-01, Validation Loss: 8.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15884, Training Loss: 6.790e-01, Validation Loss: 8.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15885, Training Loss: 6.789e-01, Validation Loss: 8.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15886, Training Loss: 6.789e-01, Validation Loss: 8.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15887, Training Loss: 6.789e-01, Validation Loss: 8.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15888, Training Loss: 6.788e-01, Validation Loss: 8.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15889, Training Loss: 6.788e-01, Validation Loss: 8.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15890, Training Loss: 6.787e-01, Validation Loss: 8.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15891, Training Loss: 6.787e-01, Validation Loss: 8.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15892, Training Loss: 6.786e-01, Validation Loss: 8.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15893, Training Loss: 6.786e-01, Validation Loss: 8.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15894, Training Loss: 6.786e-01, Validation Loss: 8.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15895, Training Loss: 6.785e-01, Validation Loss: 8.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15896, Training Loss: 6.785e-01, Validation Loss: 8.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15897, Training Loss: 6.784e-01, Validation Loss: 8.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15898, Training Loss: 6.784e-01, Validation Loss: 8.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15899, Training Loss: 6.784e-01, Validation Loss: 8.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15900, Training Loss: 6.783e-01, Validation Loss: 8.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15901, Training Loss: 6.783e-01, Validation Loss: 8.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15902, Training Loss: 6.782e-01, Validation Loss: 8.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15903, Training Loss: 6.782e-01, Validation Loss: 7.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15904, Training Loss: 6.781e-01, Validation Loss: 7.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15905, Training Loss: 6.781e-01, Validation Loss: 7.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15906, Training Loss: 6.781e-01, Validation Loss: 7.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15907, Training Loss: 6.780e-01, Validation Loss: 7.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15908, Training Loss: 6.780e-01, Validation Loss: 7.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15909, Training Loss: 6.779e-01, Validation Loss: 7.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15910, Training Loss: 6.779e-01, Validation Loss: 7.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15911, Training Loss: 6.778e-01, Validation Loss: 7.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15912, Training Loss: 6.778e-01, Validation Loss: 7.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15913, Training Loss: 6.778e-01, Validation Loss: 7.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15914, Training Loss: 6.777e-01, Validation Loss: 7.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15915, Training Loss: 6.777e-01, Validation Loss: 7.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15916, Training Loss: 6.776e-01, Validation Loss: 7.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15917, Training Loss: 6.776e-01, Validation Loss: 7.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15918, Training Loss: 6.776e-01, Validation Loss: 7.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15919, Training Loss: 6.775e-01, Validation Loss: 7.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15920, Training Loss: 6.775e-01, Validation Loss: 7.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15921, Training Loss: 6.774e-01, Validation Loss: 7.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15922, Training Loss: 6.774e-01, Validation Loss: 7.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15923, Training Loss: 6.773e-01, Validation Loss: 7.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15924, Training Loss: 6.773e-01, Validation Loss: 7.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15925, Training Loss: 6.773e-01, Validation Loss: 7.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15926, Training Loss: 6.772e-01, Validation Loss: 7.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15927, Training Loss: 6.772e-01, Validation Loss: 7.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15928, Training Loss: 6.771e-01, Validation Loss: 7.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15929, Training Loss: 6.771e-01, Validation Loss: 7.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15930, Training Loss: 6.771e-01, Validation Loss: 7.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15931, Training Loss: 6.770e-01, Validation Loss: 7.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15932, Training Loss: 6.770e-01, Validation Loss: 7.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15933, Training Loss: 6.769e-01, Validation Loss: 7.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15934, Training Loss: 6.769e-01, Validation Loss: 7.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15935, Training Loss: 6.768e-01, Validation Loss: 7.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15936, Training Loss: 6.768e-01, Validation Loss: 7.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15937, Training Loss: 6.768e-01, Validation Loss: 7.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15938, Training Loss: 6.767e-01, Validation Loss: 7.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15939, Training Loss: 6.767e-01, Validation Loss: 7.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15940, Training Loss: 6.766e-01, Validation Loss: 7.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15941, Training Loss: 6.766e-01, Validation Loss: 7.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15942, Training Loss: 6.765e-01, Validation Loss: 7.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15943, Training Loss: 6.765e-01, Validation Loss: 7.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15944, Training Loss: 6.765e-01, Validation Loss: 7.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15945, Training Loss: 6.764e-01, Validation Loss: 7.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15946, Training Loss: 6.764e-01, Validation Loss: 7.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15947, Training Loss: 6.763e-01, Validation Loss: 7.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15948, Training Loss: 6.763e-01, Validation Loss: 7.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15949, Training Loss: 6.763e-01, Validation Loss: 7.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15950, Training Loss: 6.762e-01, Validation Loss: 7.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15951, Training Loss: 6.762e-01, Validation Loss: 7.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15952, Training Loss: 6.761e-01, Validation Loss: 7.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15953, Training Loss: 6.761e-01, Validation Loss: 7.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15954, Training Loss: 6.760e-01, Validation Loss: 7.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15955, Training Loss: 6.760e-01, Validation Loss: 7.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15956, Training Loss: 6.760e-01, Validation Loss: 7.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15957, Training Loss: 6.759e-01, Validation Loss: 7.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15958, Training Loss: 6.759e-01, Validation Loss: 7.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15959, Training Loss: 6.758e-01, Validation Loss: 7.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15960, Training Loss: 6.758e-01, Validation Loss: 7.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15961, Training Loss: 6.758e-01, Validation Loss: 7.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15962, Training Loss: 6.757e-01, Validation Loss: 7.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15963, Training Loss: 6.757e-01, Validation Loss: 7.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15964, Training Loss: 6.756e-01, Validation Loss: 7.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15965, Training Loss: 6.756e-01, Validation Loss: 7.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15966, Training Loss: 6.755e-01, Validation Loss: 7.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15967, Training Loss: 6.755e-01, Validation Loss: 7.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15968, Training Loss: 6.755e-01, Validation Loss: 7.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15969, Training Loss: 6.754e-01, Validation Loss: 7.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15970, Training Loss: 6.754e-01, Validation Loss: 7.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15971, Training Loss: 6.753e-01, Validation Loss: 7.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15972, Training Loss: 6.753e-01, Validation Loss: 7.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15973, Training Loss: 6.753e-01, Validation Loss: 7.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15974, Training Loss: 6.752e-01, Validation Loss: 7.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15975, Training Loss: 6.752e-01, Validation Loss: 7.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15976, Training Loss: 6.751e-01, Validation Loss: 7.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15977, Training Loss: 6.751e-01, Validation Loss: 7.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15978, Training Loss: 6.750e-01, Validation Loss: 7.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15979, Training Loss: 6.750e-01, Validation Loss: 7.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15980, Training Loss: 6.750e-01, Validation Loss: 7.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15981, Training Loss: 6.749e-01, Validation Loss: 7.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15982, Training Loss: 6.749e-01, Validation Loss: 7.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15983, Training Loss: 6.748e-01, Validation Loss: 7.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15984, Training Loss: 6.748e-01, Validation Loss: 7.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15985, Training Loss: 6.748e-01, Validation Loss: 7.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15986, Training Loss: 6.747e-01, Validation Loss: 7.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15987, Training Loss: 6.747e-01, Validation Loss: 7.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15988, Training Loss: 6.746e-01, Validation Loss: 7.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15989, Training Loss: 6.746e-01, Validation Loss: 7.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15990, Training Loss: 6.745e-01, Validation Loss: 7.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15991, Training Loss: 6.745e-01, Validation Loss: 7.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15992, Training Loss: 6.745e-01, Validation Loss: 7.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15993, Training Loss: 6.744e-01, Validation Loss: 7.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15994, Training Loss: 6.744e-01, Validation Loss: 7.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15995, Training Loss: 6.743e-01, Validation Loss: 7.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15996, Training Loss: 6.743e-01, Validation Loss: 7.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15997, Training Loss: 6.743e-01, Validation Loss: 7.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15998, Training Loss: 6.742e-01, Validation Loss: 7.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15999, Training Loss: 6.742e-01, Validation Loss: 7.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16000, Training Loss: 6.741e-01, Validation Loss: 7.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16001, Training Loss: 6.741e-01, Validation Loss: 7.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16002, Training Loss: 6.740e-01, Validation Loss: 7.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16003, Training Loss: 6.740e-01, Validation Loss: 7.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16004, Training Loss: 6.740e-01, Validation Loss: 7.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16005, Training Loss: 6.739e-01, Validation Loss: 7.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16006, Training Loss: 6.739e-01, Validation Loss: 7.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16007, Training Loss: 6.738e-01, Validation Loss: 7.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16008, Training Loss: 6.738e-01, Validation Loss: 7.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16009, Training Loss: 6.738e-01, Validation Loss: 7.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16010, Training Loss: 6.737e-01, Validation Loss: 7.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16011, Training Loss: 6.737e-01, Validation Loss: 7.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16012, Training Loss: 6.736e-01, Validation Loss: 7.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16013, Training Loss: 6.736e-01, Validation Loss: 7.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16014, Training Loss: 6.735e-01, Validation Loss: 7.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16015, Training Loss: 6.735e-01, Validation Loss: 7.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16016, Training Loss: 6.735e-01, Validation Loss: 7.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16017, Training Loss: 6.734e-01, Validation Loss: 7.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16018, Training Loss: 6.734e-01, Validation Loss: 7.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16019, Training Loss: 6.733e-01, Validation Loss: 7.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16020, Training Loss: 6.733e-01, Validation Loss: 7.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16021, Training Loss: 6.733e-01, Validation Loss: 7.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16022, Training Loss: 6.732e-01, Validation Loss: 7.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16023, Training Loss: 6.732e-01, Validation Loss: 7.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16024, Training Loss: 6.731e-01, Validation Loss: 7.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16025, Training Loss: 6.731e-01, Validation Loss: 7.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16026, Training Loss: 6.730e-01, Validation Loss: 7.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16027, Training Loss: 6.730e-01, Validation Loss: 7.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16028, Training Loss: 6.730e-01, Validation Loss: 7.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16029, Training Loss: 6.729e-01, Validation Loss: 7.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16030, Training Loss: 6.729e-01, Validation Loss: 7.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16031, Training Loss: 6.728e-01, Validation Loss: 7.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16032, Training Loss: 6.728e-01, Validation Loss: 7.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16033, Training Loss: 6.728e-01, Validation Loss: 7.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16034, Training Loss: 6.727e-01, Validation Loss: 7.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16035, Training Loss: 6.727e-01, Validation Loss: 7.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16036, Training Loss: 6.726e-01, Validation Loss: 7.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16037, Training Loss: 6.726e-01, Validation Loss: 7.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16038, Training Loss: 6.726e-01, Validation Loss: 7.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16039, Training Loss: 6.725e-01, Validation Loss: 7.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16040, Training Loss: 6.725e-01, Validation Loss: 7.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16041, Training Loss: 6.724e-01, Validation Loss: 7.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16042, Training Loss: 6.724e-01, Validation Loss: 7.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16043, Training Loss: 6.723e-01, Validation Loss: 7.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16044, Training Loss: 6.723e-01, Validation Loss: 7.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16045, Training Loss: 6.723e-01, Validation Loss: 7.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16046, Training Loss: 6.722e-01, Validation Loss: 7.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16047, Training Loss: 6.722e-01, Validation Loss: 7.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16048, Training Loss: 6.721e-01, Validation Loss: 7.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16049, Training Loss: 6.721e-01, Validation Loss: 7.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16050, Training Loss: 6.721e-01, Validation Loss: 7.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16051, Training Loss: 6.720e-01, Validation Loss: 7.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16052, Training Loss: 6.720e-01, Validation Loss: 7.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16053, Training Loss: 6.719e-01, Validation Loss: 7.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16054, Training Loss: 6.719e-01, Validation Loss: 7.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16055, Training Loss: 6.718e-01, Validation Loss: 7.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16056, Training Loss: 6.718e-01, Validation Loss: 7.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16057, Training Loss: 6.718e-01, Validation Loss: 7.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16058, Training Loss: 6.717e-01, Validation Loss: 7.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16059, Training Loss: 6.717e-01, Validation Loss: 7.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16060, Training Loss: 6.716e-01, Validation Loss: 7.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16061, Training Loss: 6.716e-01, Validation Loss: 7.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16062, Training Loss: 6.716e-01, Validation Loss: 7.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16063, Training Loss: 6.715e-01, Validation Loss: 7.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16064, Training Loss: 6.715e-01, Validation Loss: 7.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16065, Training Loss: 6.714e-01, Validation Loss: 7.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16066, Training Loss: 6.714e-01, Validation Loss: 7.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16067, Training Loss: 6.714e-01, Validation Loss: 7.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16068, Training Loss: 6.713e-01, Validation Loss: 7.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16069, Training Loss: 6.713e-01, Validation Loss: 7.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16070, Training Loss: 6.712e-01, Validation Loss: 7.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16071, Training Loss: 6.712e-01, Validation Loss: 7.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16072, Training Loss: 6.711e-01, Validation Loss: 7.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16073, Training Loss: 6.711e-01, Validation Loss: 7.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16074, Training Loss: 6.711e-01, Validation Loss: 7.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16075, Training Loss: 6.710e-01, Validation Loss: 7.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16076, Training Loss: 6.710e-01, Validation Loss: 7.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16077, Training Loss: 6.709e-01, Validation Loss: 7.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16078, Training Loss: 6.709e-01, Validation Loss: 7.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16079, Training Loss: 6.709e-01, Validation Loss: 7.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16080, Training Loss: 6.708e-01, Validation Loss: 7.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16081, Training Loss: 6.708e-01, Validation Loss: 7.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16082, Training Loss: 6.707e-01, Validation Loss: 7.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16083, Training Loss: 6.707e-01, Validation Loss: 7.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16084, Training Loss: 6.707e-01, Validation Loss: 7.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16085, Training Loss: 6.706e-01, Validation Loss: 7.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16086, Training Loss: 6.706e-01, Validation Loss: 7.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16087, Training Loss: 6.705e-01, Validation Loss: 7.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16088, Training Loss: 6.705e-01, Validation Loss: 7.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16089, Training Loss: 6.704e-01, Validation Loss: 7.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16090, Training Loss: 6.704e-01, Validation Loss: 7.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16091, Training Loss: 6.704e-01, Validation Loss: 7.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16092, Training Loss: 6.703e-01, Validation Loss: 7.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16093, Training Loss: 6.703e-01, Validation Loss: 7.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16094, Training Loss: 6.702e-01, Validation Loss: 7.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16095, Training Loss: 6.702e-01, Validation Loss: 7.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16096, Training Loss: 6.702e-01, Validation Loss: 7.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16097, Training Loss: 6.701e-01, Validation Loss: 7.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16098, Training Loss: 6.701e-01, Validation Loss: 7.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16099, Training Loss: 6.700e-01, Validation Loss: 7.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16100, Training Loss: 6.700e-01, Validation Loss: 7.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16101, Training Loss: 6.699e-01, Validation Loss: 7.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16102, Training Loss: 6.699e-01, Validation Loss: 7.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16103, Training Loss: 6.699e-01, Validation Loss: 7.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16104, Training Loss: 6.698e-01, Validation Loss: 7.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16105, Training Loss: 6.698e-01, Validation Loss: 7.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16106, Training Loss: 6.697e-01, Validation Loss: 7.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16107, Training Loss: 6.697e-01, Validation Loss: 7.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16108, Training Loss: 6.697e-01, Validation Loss: 7.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16109, Training Loss: 6.696e-01, Validation Loss: 7.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16110, Training Loss: 6.696e-01, Validation Loss: 7.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16111, Training Loss: 6.695e-01, Validation Loss: 7.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16112, Training Loss: 6.695e-01, Validation Loss: 7.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16113, Training Loss: 6.695e-01, Validation Loss: 7.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16114, Training Loss: 6.694e-01, Validation Loss: 7.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16115, Training Loss: 6.694e-01, Validation Loss: 7.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16116, Training Loss: 6.693e-01, Validation Loss: 7.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16117, Training Loss: 6.693e-01, Validation Loss: 7.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16118, Training Loss: 6.693e-01, Validation Loss: 7.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16119, Training Loss: 6.692e-01, Validation Loss: 7.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16120, Training Loss: 6.692e-01, Validation Loss: 7.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16121, Training Loss: 6.691e-01, Validation Loss: 7.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16122, Training Loss: 6.691e-01, Validation Loss: 7.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16123, Training Loss: 6.690e-01, Validation Loss: 7.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16124, Training Loss: 6.690e-01, Validation Loss: 7.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16125, Training Loss: 6.690e-01, Validation Loss: 7.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16126, Training Loss: 6.689e-01, Validation Loss: 7.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16127, Training Loss: 6.689e-01, Validation Loss: 7.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16128, Training Loss: 6.688e-01, Validation Loss: 7.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16129, Training Loss: 6.688e-01, Validation Loss: 7.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16130, Training Loss: 6.688e-01, Validation Loss: 7.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16131, Training Loss: 6.687e-01, Validation Loss: 7.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16132, Training Loss: 6.687e-01, Validation Loss: 7.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16133, Training Loss: 6.686e-01, Validation Loss: 7.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16134, Training Loss: 6.686e-01, Validation Loss: 7.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16135, Training Loss: 6.686e-01, Validation Loss: 7.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16136, Training Loss: 6.685e-01, Validation Loss: 7.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16137, Training Loss: 6.685e-01, Validation Loss: 7.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16138, Training Loss: 6.684e-01, Validation Loss: 7.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16139, Training Loss: 6.684e-01, Validation Loss: 7.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16140, Training Loss: 6.683e-01, Validation Loss: 7.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16141, Training Loss: 6.683e-01, Validation Loss: 7.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16142, Training Loss: 6.683e-01, Validation Loss: 7.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16143, Training Loss: 6.682e-01, Validation Loss: 7.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16144, Training Loss: 6.682e-01, Validation Loss: 7.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16145, Training Loss: 6.681e-01, Validation Loss: 7.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16146, Training Loss: 6.681e-01, Validation Loss: 7.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16147, Training Loss: 6.681e-01, Validation Loss: 7.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16148, Training Loss: 6.680e-01, Validation Loss: 7.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16149, Training Loss: 6.680e-01, Validation Loss: 7.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16150, Training Loss: 6.679e-01, Validation Loss: 7.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16151, Training Loss: 6.679e-01, Validation Loss: 7.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16152, Training Loss: 6.679e-01, Validation Loss: 7.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16153, Training Loss: 6.678e-01, Validation Loss: 7.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16154, Training Loss: 6.678e-01, Validation Loss: 7.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16155, Training Loss: 6.677e-01, Validation Loss: 7.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16156, Training Loss: 6.677e-01, Validation Loss: 7.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16157, Training Loss: 6.677e-01, Validation Loss: 7.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16158, Training Loss: 6.676e-01, Validation Loss: 7.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16159, Training Loss: 6.676e-01, Validation Loss: 7.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16160, Training Loss: 6.675e-01, Validation Loss: 7.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16161, Training Loss: 6.675e-01, Validation Loss: 7.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16162, Training Loss: 6.674e-01, Validation Loss: 7.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16163, Training Loss: 6.674e-01, Validation Loss: 7.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16164, Training Loss: 6.674e-01, Validation Loss: 7.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16165, Training Loss: 6.673e-01, Validation Loss: 7.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16166, Training Loss: 6.673e-01, Validation Loss: 7.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16167, Training Loss: 6.672e-01, Validation Loss: 7.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16168, Training Loss: 6.672e-01, Validation Loss: 7.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16169, Training Loss: 6.672e-01, Validation Loss: 7.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16170, Training Loss: 6.671e-01, Validation Loss: 7.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16171, Training Loss: 6.671e-01, Validation Loss: 7.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16172, Training Loss: 6.670e-01, Validation Loss: 7.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16173, Training Loss: 6.670e-01, Validation Loss: 7.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16174, Training Loss: 6.670e-01, Validation Loss: 7.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16175, Training Loss: 6.669e-01, Validation Loss: 7.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16176, Training Loss: 6.669e-01, Validation Loss: 7.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16177, Training Loss: 6.668e-01, Validation Loss: 7.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16178, Training Loss: 6.668e-01, Validation Loss: 7.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16179, Training Loss: 6.668e-01, Validation Loss: 7.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16180, Training Loss: 6.667e-01, Validation Loss: 7.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16181, Training Loss: 6.667e-01, Validation Loss: 7.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16182, Training Loss: 6.666e-01, Validation Loss: 7.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16183, Training Loss: 6.666e-01, Validation Loss: 7.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16184, Training Loss: 6.665e-01, Validation Loss: 7.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16185, Training Loss: 6.665e-01, Validation Loss: 7.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16186, Training Loss: 6.665e-01, Validation Loss: 7.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16187, Training Loss: 6.664e-01, Validation Loss: 7.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16188, Training Loss: 6.664e-01, Validation Loss: 7.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16189, Training Loss: 6.663e-01, Validation Loss: 7.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16190, Training Loss: 6.663e-01, Validation Loss: 7.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16191, Training Loss: 6.663e-01, Validation Loss: 7.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16192, Training Loss: 6.662e-01, Validation Loss: 7.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16193, Training Loss: 6.662e-01, Validation Loss: 7.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16194, Training Loss: 6.661e-01, Validation Loss: 7.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16195, Training Loss: 6.661e-01, Validation Loss: 7.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16196, Training Loss: 6.661e-01, Validation Loss: 7.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16197, Training Loss: 6.660e-01, Validation Loss: 7.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16198, Training Loss: 6.660e-01, Validation Loss: 7.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16199, Training Loss: 6.659e-01, Validation Loss: 7.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16200, Training Loss: 6.659e-01, Validation Loss: 7.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16201, Training Loss: 6.659e-01, Validation Loss: 7.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16202, Training Loss: 6.658e-01, Validation Loss: 7.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16203, Training Loss: 6.658e-01, Validation Loss: 7.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16204, Training Loss: 6.657e-01, Validation Loss: 7.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16205, Training Loss: 6.657e-01, Validation Loss: 7.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16206, Training Loss: 6.657e-01, Validation Loss: 7.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16207, Training Loss: 6.656e-01, Validation Loss: 7.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16208, Training Loss: 6.656e-01, Validation Loss: 7.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16209, Training Loss: 6.655e-01, Validation Loss: 7.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16210, Training Loss: 6.655e-01, Validation Loss: 7.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16211, Training Loss: 6.654e-01, Validation Loss: 7.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16212, Training Loss: 6.654e-01, Validation Loss: 7.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16213, Training Loss: 6.654e-01, Validation Loss: 7.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16214, Training Loss: 6.653e-01, Validation Loss: 7.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16215, Training Loss: 6.653e-01, Validation Loss: 7.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16216, Training Loss: 6.652e-01, Validation Loss: 7.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16217, Training Loss: 6.652e-01, Validation Loss: 7.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16218, Training Loss: 6.652e-01, Validation Loss: 7.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16219, Training Loss: 6.651e-01, Validation Loss: 7.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16220, Training Loss: 6.651e-01, Validation Loss: 7.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16221, Training Loss: 6.650e-01, Validation Loss: 7.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16222, Training Loss: 6.650e-01, Validation Loss: 7.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16223, Training Loss: 6.650e-01, Validation Loss: 7.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16224, Training Loss: 6.649e-01, Validation Loss: 7.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16225, Training Loss: 6.649e-01, Validation Loss: 7.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16226, Training Loss: 6.648e-01, Validation Loss: 7.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16227, Training Loss: 6.648e-01, Validation Loss: 7.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16228, Training Loss: 6.648e-01, Validation Loss: 7.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16229, Training Loss: 6.647e-01, Validation Loss: 7.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16230, Training Loss: 6.647e-01, Validation Loss: 7.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16231, Training Loss: 6.646e-01, Validation Loss: 7.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16232, Training Loss: 6.646e-01, Validation Loss: 7.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16233, Training Loss: 6.646e-01, Validation Loss: 7.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16234, Training Loss: 6.645e-01, Validation Loss: 7.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16235, Training Loss: 6.645e-01, Validation Loss: 7.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16236, Training Loss: 6.644e-01, Validation Loss: 7.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16237, Training Loss: 6.644e-01, Validation Loss: 7.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16238, Training Loss: 6.644e-01, Validation Loss: 7.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16239, Training Loss: 6.643e-01, Validation Loss: 7.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16240, Training Loss: 6.643e-01, Validation Loss: 7.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16241, Training Loss: 6.642e-01, Validation Loss: 7.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16242, Training Loss: 6.642e-01, Validation Loss: 7.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16243, Training Loss: 6.642e-01, Validation Loss: 7.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16244, Training Loss: 6.641e-01, Validation Loss: 7.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16245, Training Loss: 6.641e-01, Validation Loss: 7.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16246, Training Loss: 6.640e-01, Validation Loss: 7.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16247, Training Loss: 6.640e-01, Validation Loss: 7.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16248, Training Loss: 6.639e-01, Validation Loss: 7.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16249, Training Loss: 6.639e-01, Validation Loss: 7.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16250, Training Loss: 6.639e-01, Validation Loss: 7.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16251, Training Loss: 6.638e-01, Validation Loss: 7.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16252, Training Loss: 6.638e-01, Validation Loss: 7.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16253, Training Loss: 6.637e-01, Validation Loss: 7.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16254, Training Loss: 6.637e-01, Validation Loss: 7.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16255, Training Loss: 6.637e-01, Validation Loss: 7.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16256, Training Loss: 6.636e-01, Validation Loss: 7.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16257, Training Loss: 6.636e-01, Validation Loss: 7.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16258, Training Loss: 6.635e-01, Validation Loss: 7.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16259, Training Loss: 6.635e-01, Validation Loss: 7.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16260, Training Loss: 6.635e-01, Validation Loss: 7.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16261, Training Loss: 6.634e-01, Validation Loss: 7.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16262, Training Loss: 6.634e-01, Validation Loss: 7.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16263, Training Loss: 6.633e-01, Validation Loss: 7.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16264, Training Loss: 6.633e-01, Validation Loss: 7.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16265, Training Loss: 6.633e-01, Validation Loss: 7.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16266, Training Loss: 6.632e-01, Validation Loss: 7.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16267, Training Loss: 6.632e-01, Validation Loss: 7.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16268, Training Loss: 6.631e-01, Validation Loss: 7.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16269, Training Loss: 6.631e-01, Validation Loss: 7.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16270, Training Loss: 6.631e-01, Validation Loss: 7.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16271, Training Loss: 6.630e-01, Validation Loss: 7.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16272, Training Loss: 6.630e-01, Validation Loss: 7.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16273, Training Loss: 6.629e-01, Validation Loss: 7.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16274, Training Loss: 6.629e-01, Validation Loss: 7.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16275, Training Loss: 6.629e-01, Validation Loss: 7.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16276, Training Loss: 6.628e-01, Validation Loss: 7.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16277, Training Loss: 6.628e-01, Validation Loss: 7.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16278, Training Loss: 6.627e-01, Validation Loss: 7.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16279, Training Loss: 6.627e-01, Validation Loss: 7.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16280, Training Loss: 6.627e-01, Validation Loss: 7.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16281, Training Loss: 6.626e-01, Validation Loss: 7.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16282, Training Loss: 6.626e-01, Validation Loss: 7.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16283, Training Loss: 6.625e-01, Validation Loss: 7.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16284, Training Loss: 6.625e-01, Validation Loss: 7.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16285, Training Loss: 6.625e-01, Validation Loss: 7.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16286, Training Loss: 6.624e-01, Validation Loss: 7.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16287, Training Loss: 6.624e-01, Validation Loss: 7.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16288, Training Loss: 6.623e-01, Validation Loss: 7.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16289, Training Loss: 6.623e-01, Validation Loss: 7.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16290, Training Loss: 6.623e-01, Validation Loss: 7.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16291, Training Loss: 6.622e-01, Validation Loss: 7.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16292, Training Loss: 6.622e-01, Validation Loss: 7.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16293, Training Loss: 6.621e-01, Validation Loss: 7.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16294, Training Loss: 6.621e-01, Validation Loss: 7.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16295, Training Loss: 6.620e-01, Validation Loss: 7.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16296, Training Loss: 6.620e-01, Validation Loss: 7.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16297, Training Loss: 6.620e-01, Validation Loss: 7.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16298, Training Loss: 6.619e-01, Validation Loss: 7.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16299, Training Loss: 6.619e-01, Validation Loss: 7.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16300, Training Loss: 6.618e-01, Validation Loss: 7.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16301, Training Loss: 6.618e-01, Validation Loss: 7.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16302, Training Loss: 6.618e-01, Validation Loss: 7.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16303, Training Loss: 6.617e-01, Validation Loss: 7.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16304, Training Loss: 6.617e-01, Validation Loss: 7.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16305, Training Loss: 6.616e-01, Validation Loss: 7.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16306, Training Loss: 6.616e-01, Validation Loss: 7.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16307, Training Loss: 6.616e-01, Validation Loss: 7.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16308, Training Loss: 6.615e-01, Validation Loss: 7.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16309, Training Loss: 6.615e-01, Validation Loss: 7.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16310, Training Loss: 6.614e-01, Validation Loss: 7.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16311, Training Loss: 6.614e-01, Validation Loss: 7.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16312, Training Loss: 6.614e-01, Validation Loss: 7.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16313, Training Loss: 6.613e-01, Validation Loss: 7.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16314, Training Loss: 6.613e-01, Validation Loss: 7.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16315, Training Loss: 6.612e-01, Validation Loss: 7.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16316, Training Loss: 6.612e-01, Validation Loss: 7.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16317, Training Loss: 6.612e-01, Validation Loss: 7.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16318, Training Loss: 6.611e-01, Validation Loss: 7.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16319, Training Loss: 6.611e-01, Validation Loss: 7.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16320, Training Loss: 6.610e-01, Validation Loss: 7.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16321, Training Loss: 6.610e-01, Validation Loss: 7.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16322, Training Loss: 6.610e-01, Validation Loss: 7.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16323, Training Loss: 6.609e-01, Validation Loss: 7.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16324, Training Loss: 6.609e-01, Validation Loss: 7.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16325, Training Loss: 6.608e-01, Validation Loss: 7.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16326, Training Loss: 6.608e-01, Validation Loss: 7.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16327, Training Loss: 6.608e-01, Validation Loss: 7.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16328, Training Loss: 6.607e-01, Validation Loss: 7.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16329, Training Loss: 6.607e-01, Validation Loss: 7.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16330, Training Loss: 6.606e-01, Validation Loss: 7.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16331, Training Loss: 6.606e-01, Validation Loss: 7.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16332, Training Loss: 6.606e-01, Validation Loss: 7.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16333, Training Loss: 6.605e-01, Validation Loss: 7.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16334, Training Loss: 6.605e-01, Validation Loss: 7.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16335, Training Loss: 6.604e-01, Validation Loss: 7.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16336, Training Loss: 6.604e-01, Validation Loss: 7.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16337, Training Loss: 6.604e-01, Validation Loss: 7.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16338, Training Loss: 6.603e-01, Validation Loss: 7.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16339, Training Loss: 6.603e-01, Validation Loss: 7.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16340, Training Loss: 6.602e-01, Validation Loss: 7.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16341, Training Loss: 6.602e-01, Validation Loss: 7.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16342, Training Loss: 6.602e-01, Validation Loss: 7.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16343, Training Loss: 6.601e-01, Validation Loss: 7.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16344, Training Loss: 6.601e-01, Validation Loss: 7.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16345, Training Loss: 6.600e-01, Validation Loss: 7.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16346, Training Loss: 6.600e-01, Validation Loss: 7.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16347, Training Loss: 6.600e-01, Validation Loss: 7.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16348, Training Loss: 6.599e-01, Validation Loss: 7.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16349, Training Loss: 6.599e-01, Validation Loss: 7.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16350, Training Loss: 6.598e-01, Validation Loss: 7.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16351, Training Loss: 6.598e-01, Validation Loss: 7.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16352, Training Loss: 6.598e-01, Validation Loss: 7.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16353, Training Loss: 6.597e-01, Validation Loss: 7.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16354, Training Loss: 6.597e-01, Validation Loss: 7.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16355, Training Loss: 6.596e-01, Validation Loss: 7.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16356, Training Loss: 6.596e-01, Validation Loss: 7.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16357, Training Loss: 6.596e-01, Validation Loss: 7.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16358, Training Loss: 6.595e-01, Validation Loss: 7.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16359, Training Loss: 6.595e-01, Validation Loss: 7.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16360, Training Loss: 6.594e-01, Validation Loss: 7.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16361, Training Loss: 6.594e-01, Validation Loss: 7.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16362, Training Loss: 6.594e-01, Validation Loss: 7.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16363, Training Loss: 6.593e-01, Validation Loss: 7.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16364, Training Loss: 6.593e-01, Validation Loss: 7.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16365, Training Loss: 6.592e-01, Validation Loss: 7.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16366, Training Loss: 6.592e-01, Validation Loss: 7.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16367, Training Loss: 6.592e-01, Validation Loss: 7.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16368, Training Loss: 6.591e-01, Validation Loss: 7.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16369, Training Loss: 6.591e-01, Validation Loss: 7.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16370, Training Loss: 6.590e-01, Validation Loss: 7.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16371, Training Loss: 6.590e-01, Validation Loss: 7.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16372, Training Loss: 6.590e-01, Validation Loss: 7.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16373, Training Loss: 6.589e-01, Validation Loss: 7.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16374, Training Loss: 6.589e-01, Validation Loss: 7.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16375, Training Loss: 6.588e-01, Validation Loss: 7.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16376, Training Loss: 6.588e-01, Validation Loss: 7.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16377, Training Loss: 6.588e-01, Validation Loss: 7.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16378, Training Loss: 6.587e-01, Validation Loss: 7.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16379, Training Loss: 6.587e-01, Validation Loss: 7.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16380, Training Loss: 6.586e-01, Validation Loss: 7.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16381, Training Loss: 6.586e-01, Validation Loss: 7.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16382, Training Loss: 6.586e-01, Validation Loss: 7.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16383, Training Loss: 6.585e-01, Validation Loss: 7.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16384, Training Loss: 6.585e-01, Validation Loss: 7.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16385, Training Loss: 6.584e-01, Validation Loss: 7.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16386, Training Loss: 6.584e-01, Validation Loss: 7.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16387, Training Loss: 6.584e-01, Validation Loss: 7.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16388, Training Loss: 6.583e-01, Validation Loss: 7.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16389, Training Loss: 6.583e-01, Validation Loss: 7.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16390, Training Loss: 6.582e-01, Validation Loss: 7.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16391, Training Loss: 6.582e-01, Validation Loss: 7.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16392, Training Loss: 6.582e-01, Validation Loss: 7.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16393, Training Loss: 6.581e-01, Validation Loss: 7.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16394, Training Loss: 6.581e-01, Validation Loss: 7.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16395, Training Loss: 6.580e-01, Validation Loss: 7.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16396, Training Loss: 6.580e-01, Validation Loss: 7.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16397, Training Loss: 6.580e-01, Validation Loss: 7.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16398, Training Loss: 6.579e-01, Validation Loss: 7.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16399, Training Loss: 6.579e-01, Validation Loss: 7.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16400, Training Loss: 6.578e-01, Validation Loss: 7.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16401, Training Loss: 6.578e-01, Validation Loss: 7.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16402, Training Loss: 6.578e-01, Validation Loss: 7.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16403, Training Loss: 6.577e-01, Validation Loss: 7.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16404, Training Loss: 6.577e-01, Validation Loss: 7.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16405, Training Loss: 6.576e-01, Validation Loss: 7.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16406, Training Loss: 6.576e-01, Validation Loss: 7.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16407, Training Loss: 6.576e-01, Validation Loss: 7.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16408, Training Loss: 6.575e-01, Validation Loss: 7.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16409, Training Loss: 6.575e-01, Validation Loss: 7.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16410, Training Loss: 6.574e-01, Validation Loss: 7.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16411, Training Loss: 6.574e-01, Validation Loss: 7.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16412, Training Loss: 6.574e-01, Validation Loss: 7.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16413, Training Loss: 6.573e-01, Validation Loss: 7.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16414, Training Loss: 6.573e-01, Validation Loss: 7.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16415, Training Loss: 6.572e-01, Validation Loss: 7.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16416, Training Loss: 6.572e-01, Validation Loss: 7.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16417, Training Loss: 6.572e-01, Validation Loss: 7.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16418, Training Loss: 6.571e-01, Validation Loss: 7.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16419, Training Loss: 6.571e-01, Validation Loss: 7.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16420, Training Loss: 6.570e-01, Validation Loss: 7.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16421, Training Loss: 6.570e-01, Validation Loss: 7.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16422, Training Loss: 6.570e-01, Validation Loss: 7.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16423, Training Loss: 6.569e-01, Validation Loss: 7.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16424, Training Loss: 6.569e-01, Validation Loss: 7.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16425, Training Loss: 6.568e-01, Validation Loss: 7.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16426, Training Loss: 6.568e-01, Validation Loss: 7.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16427, Training Loss: 6.568e-01, Validation Loss: 7.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16428, Training Loss: 6.567e-01, Validation Loss: 7.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16429, Training Loss: 6.567e-01, Validation Loss: 7.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16430, Training Loss: 6.566e-01, Validation Loss: 7.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16431, Training Loss: 6.566e-01, Validation Loss: 7.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16432, Training Loss: 6.566e-01, Validation Loss: 7.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16433, Training Loss: 6.565e-01, Validation Loss: 7.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16434, Training Loss: 6.565e-01, Validation Loss: 7.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16435, Training Loss: 6.564e-01, Validation Loss: 7.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16436, Training Loss: 6.564e-01, Validation Loss: 7.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16437, Training Loss: 6.564e-01, Validation Loss: 7.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16438, Training Loss: 6.563e-01, Validation Loss: 7.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16439, Training Loss: 6.563e-01, Validation Loss: 7.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16440, Training Loss: 6.563e-01, Validation Loss: 7.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16441, Training Loss: 6.562e-01, Validation Loss: 7.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16442, Training Loss: 6.562e-01, Validation Loss: 7.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16443, Training Loss: 6.561e-01, Validation Loss: 7.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16444, Training Loss: 6.561e-01, Validation Loss: 7.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16445, Training Loss: 6.561e-01, Validation Loss: 7.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16446, Training Loss: 6.560e-01, Validation Loss: 7.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16447, Training Loss: 6.560e-01, Validation Loss: 7.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16448, Training Loss: 6.559e-01, Validation Loss: 7.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16449, Training Loss: 6.559e-01, Validation Loss: 7.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16450, Training Loss: 6.559e-01, Validation Loss: 7.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16451, Training Loss: 6.558e-01, Validation Loss: 7.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16452, Training Loss: 6.558e-01, Validation Loss: 7.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16453, Training Loss: 6.557e-01, Validation Loss: 7.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16454, Training Loss: 6.557e-01, Validation Loss: 7.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16455, Training Loss: 6.557e-01, Validation Loss: 7.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16456, Training Loss: 6.556e-01, Validation Loss: 7.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16457, Training Loss: 6.556e-01, Validation Loss: 7.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16458, Training Loss: 6.555e-01, Validation Loss: 7.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16459, Training Loss: 6.555e-01, Validation Loss: 7.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16460, Training Loss: 6.555e-01, Validation Loss: 7.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16461, Training Loss: 6.554e-01, Validation Loss: 7.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16462, Training Loss: 6.554e-01, Validation Loss: 7.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16463, Training Loss: 6.553e-01, Validation Loss: 7.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16464, Training Loss: 6.553e-01, Validation Loss: 7.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16465, Training Loss: 6.553e-01, Validation Loss: 7.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16466, Training Loss: 6.552e-01, Validation Loss: 7.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16467, Training Loss: 6.552e-01, Validation Loss: 7.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16468, Training Loss: 6.551e-01, Validation Loss: 7.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16469, Training Loss: 6.551e-01, Validation Loss: 7.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16470, Training Loss: 6.551e-01, Validation Loss: 7.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16471, Training Loss: 6.550e-01, Validation Loss: 7.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16472, Training Loss: 6.550e-01, Validation Loss: 7.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16473, Training Loss: 6.549e-01, Validation Loss: 7.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16474, Training Loss: 6.549e-01, Validation Loss: 7.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16475, Training Loss: 6.549e-01, Validation Loss: 7.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16476, Training Loss: 6.548e-01, Validation Loss: 7.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16477, Training Loss: 6.548e-01, Validation Loss: 7.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16478, Training Loss: 6.547e-01, Validation Loss: 7.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16479, Training Loss: 6.547e-01, Validation Loss: 7.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16480, Training Loss: 6.547e-01, Validation Loss: 7.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16481, Training Loss: 6.546e-01, Validation Loss: 7.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16482, Training Loss: 6.546e-01, Validation Loss: 7.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16483, Training Loss: 6.545e-01, Validation Loss: 7.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16484, Training Loss: 6.545e-01, Validation Loss: 7.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16485, Training Loss: 6.545e-01, Validation Loss: 7.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16486, Training Loss: 6.544e-01, Validation Loss: 7.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16487, Training Loss: 6.544e-01, Validation Loss: 7.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16488, Training Loss: 6.543e-01, Validation Loss: 7.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16489, Training Loss: 6.543e-01, Validation Loss: 7.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16490, Training Loss: 6.543e-01, Validation Loss: 7.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16491, Training Loss: 6.542e-01, Validation Loss: 7.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16492, Training Loss: 6.542e-01, Validation Loss: 7.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16493, Training Loss: 6.542e-01, Validation Loss: 7.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16494, Training Loss: 6.541e-01, Validation Loss: 7.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16495, Training Loss: 6.541e-01, Validation Loss: 7.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16496, Training Loss: 6.540e-01, Validation Loss: 7.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16497, Training Loss: 6.540e-01, Validation Loss: 7.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16498, Training Loss: 6.540e-01, Validation Loss: 7.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16499, Training Loss: 6.539e-01, Validation Loss: 7.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16500, Training Loss: 6.539e-01, Validation Loss: 7.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16501, Training Loss: 6.538e-01, Validation Loss: 7.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16502, Training Loss: 6.538e-01, Validation Loss: 7.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16503, Training Loss: 6.538e-01, Validation Loss: 7.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16504, Training Loss: 6.537e-01, Validation Loss: 7.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16505, Training Loss: 6.537e-01, Validation Loss: 7.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16506, Training Loss: 6.536e-01, Validation Loss: 7.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16507, Training Loss: 6.536e-01, Validation Loss: 7.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16508, Training Loss: 6.536e-01, Validation Loss: 7.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16509, Training Loss: 6.535e-01, Validation Loss: 7.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16510, Training Loss: 6.535e-01, Validation Loss: 7.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16511, Training Loss: 6.534e-01, Validation Loss: 7.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16512, Training Loss: 6.534e-01, Validation Loss: 7.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16513, Training Loss: 6.534e-01, Validation Loss: 7.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16514, Training Loss: 6.533e-01, Validation Loss: 7.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16515, Training Loss: 6.533e-01, Validation Loss: 7.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16516, Training Loss: 6.532e-01, Validation Loss: 7.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16517, Training Loss: 6.532e-01, Validation Loss: 7.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16518, Training Loss: 6.532e-01, Validation Loss: 7.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16519, Training Loss: 6.531e-01, Validation Loss: 7.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16520, Training Loss: 6.531e-01, Validation Loss: 7.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16521, Training Loss: 6.530e-01, Validation Loss: 7.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16522, Training Loss: 6.530e-01, Validation Loss: 7.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16523, Training Loss: 6.530e-01, Validation Loss: 7.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16524, Training Loss: 6.529e-01, Validation Loss: 7.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16525, Training Loss: 6.529e-01, Validation Loss: 7.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16526, Training Loss: 6.529e-01, Validation Loss: 7.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16527, Training Loss: 6.528e-01, Validation Loss: 7.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16528, Training Loss: 6.528e-01, Validation Loss: 7.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16529, Training Loss: 6.527e-01, Validation Loss: 7.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16530, Training Loss: 6.527e-01, Validation Loss: 7.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16531, Training Loss: 6.527e-01, Validation Loss: 7.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16532, Training Loss: 6.526e-01, Validation Loss: 7.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16533, Training Loss: 6.526e-01, Validation Loss: 7.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16534, Training Loss: 6.525e-01, Validation Loss: 7.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16535, Training Loss: 6.525e-01, Validation Loss: 7.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16536, Training Loss: 6.525e-01, Validation Loss: 7.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16537, Training Loss: 6.524e-01, Validation Loss: 7.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16538, Training Loss: 6.524e-01, Validation Loss: 7.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16539, Training Loss: 6.523e-01, Validation Loss: 7.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16540, Training Loss: 6.523e-01, Validation Loss: 7.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16541, Training Loss: 6.523e-01, Validation Loss: 7.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16542, Training Loss: 6.522e-01, Validation Loss: 7.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16543, Training Loss: 6.522e-01, Validation Loss: 7.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16544, Training Loss: 6.521e-01, Validation Loss: 7.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16545, Training Loss: 6.521e-01, Validation Loss: 7.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16546, Training Loss: 6.521e-01, Validation Loss: 7.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16547, Training Loss: 6.520e-01, Validation Loss: 7.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16548, Training Loss: 6.520e-01, Validation Loss: 7.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16549, Training Loss: 6.519e-01, Validation Loss: 7.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16550, Training Loss: 6.519e-01, Validation Loss: 7.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16551, Training Loss: 6.519e-01, Validation Loss: 7.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16552, Training Loss: 6.518e-01, Validation Loss: 7.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16553, Training Loss: 6.518e-01, Validation Loss: 7.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16554, Training Loss: 6.518e-01, Validation Loss: 7.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16555, Training Loss: 6.517e-01, Validation Loss: 7.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16556, Training Loss: 6.517e-01, Validation Loss: 7.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16557, Training Loss: 6.516e-01, Validation Loss: 7.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16558, Training Loss: 6.516e-01, Validation Loss: 7.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16559, Training Loss: 6.516e-01, Validation Loss: 7.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16560, Training Loss: 6.515e-01, Validation Loss: 7.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16561, Training Loss: 6.515e-01, Validation Loss: 7.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16562, Training Loss: 6.514e-01, Validation Loss: 7.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16563, Training Loss: 6.514e-01, Validation Loss: 7.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16564, Training Loss: 6.514e-01, Validation Loss: 7.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16565, Training Loss: 6.513e-01, Validation Loss: 7.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16566, Training Loss: 6.513e-01, Validation Loss: 7.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16567, Training Loss: 6.512e-01, Validation Loss: 7.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16568, Training Loss: 6.512e-01, Validation Loss: 7.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16569, Training Loss: 6.512e-01, Validation Loss: 7.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16570, Training Loss: 6.511e-01, Validation Loss: 7.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16571, Training Loss: 6.511e-01, Validation Loss: 7.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16572, Training Loss: 6.510e-01, Validation Loss: 7.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16573, Training Loss: 6.510e-01, Validation Loss: 7.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16574, Training Loss: 6.510e-01, Validation Loss: 7.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16575, Training Loss: 6.509e-01, Validation Loss: 7.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16576, Training Loss: 6.509e-01, Validation Loss: 7.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16577, Training Loss: 6.508e-01, Validation Loss: 7.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16578, Training Loss: 6.508e-01, Validation Loss: 7.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16579, Training Loss: 6.508e-01, Validation Loss: 7.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16580, Training Loss: 6.507e-01, Validation Loss: 7.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16581, Training Loss: 6.507e-01, Validation Loss: 7.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16582, Training Loss: 6.507e-01, Validation Loss: 7.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16583, Training Loss: 6.506e-01, Validation Loss: 7.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16584, Training Loss: 6.506e-01, Validation Loss: 7.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16585, Training Loss: 6.505e-01, Validation Loss: 7.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16586, Training Loss: 6.505e-01, Validation Loss: 7.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16587, Training Loss: 6.505e-01, Validation Loss: 7.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16588, Training Loss: 6.504e-01, Validation Loss: 7.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16589, Training Loss: 6.504e-01, Validation Loss: 7.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16590, Training Loss: 6.503e-01, Validation Loss: 7.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16591, Training Loss: 6.503e-01, Validation Loss: 7.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16592, Training Loss: 6.503e-01, Validation Loss: 7.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16593, Training Loss: 6.502e-01, Validation Loss: 7.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16594, Training Loss: 6.502e-01, Validation Loss: 7.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16595, Training Loss: 6.501e-01, Validation Loss: 7.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16596, Training Loss: 6.501e-01, Validation Loss: 7.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16597, Training Loss: 6.501e-01, Validation Loss: 7.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16598, Training Loss: 6.500e-01, Validation Loss: 7.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16599, Training Loss: 6.500e-01, Validation Loss: 7.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16600, Training Loss: 6.499e-01, Validation Loss: 7.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16601, Training Loss: 6.499e-01, Validation Loss: 7.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16602, Training Loss: 6.499e-01, Validation Loss: 7.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16603, Training Loss: 6.498e-01, Validation Loss: 7.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16604, Training Loss: 6.498e-01, Validation Loss: 7.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16605, Training Loss: 6.498e-01, Validation Loss: 7.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16606, Training Loss: 6.497e-01, Validation Loss: 7.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16607, Training Loss: 6.497e-01, Validation Loss: 7.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16608, Training Loss: 6.496e-01, Validation Loss: 7.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16609, Training Loss: 6.496e-01, Validation Loss: 7.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16610, Training Loss: 6.496e-01, Validation Loss: 7.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16611, Training Loss: 6.495e-01, Validation Loss: 7.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16612, Training Loss: 6.495e-01, Validation Loss: 7.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16613, Training Loss: 6.494e-01, Validation Loss: 7.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16614, Training Loss: 6.494e-01, Validation Loss: 7.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16615, Training Loss: 6.494e-01, Validation Loss: 7.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16616, Training Loss: 6.493e-01, Validation Loss: 7.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16617, Training Loss: 6.493e-01, Validation Loss: 7.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16618, Training Loss: 6.492e-01, Validation Loss: 7.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16619, Training Loss: 6.492e-01, Validation Loss: 7.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16620, Training Loss: 6.492e-01, Validation Loss: 7.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16621, Training Loss: 6.491e-01, Validation Loss: 7.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16622, Training Loss: 6.491e-01, Validation Loss: 7.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16623, Training Loss: 6.491e-01, Validation Loss: 7.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16624, Training Loss: 6.490e-01, Validation Loss: 7.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16625, Training Loss: 6.490e-01, Validation Loss: 7.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16626, Training Loss: 6.489e-01, Validation Loss: 7.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16627, Training Loss: 6.489e-01, Validation Loss: 7.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16628, Training Loss: 6.489e-01, Validation Loss: 7.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16629, Training Loss: 6.488e-01, Validation Loss: 7.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16630, Training Loss: 6.488e-01, Validation Loss: 7.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16631, Training Loss: 6.487e-01, Validation Loss: 7.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16632, Training Loss: 6.487e-01, Validation Loss: 7.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16633, Training Loss: 6.487e-01, Validation Loss: 7.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16634, Training Loss: 6.486e-01, Validation Loss: 7.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16635, Training Loss: 6.486e-01, Validation Loss: 7.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16636, Training Loss: 6.485e-01, Validation Loss: 7.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16637, Training Loss: 6.485e-01, Validation Loss: 7.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16638, Training Loss: 6.485e-01, Validation Loss: 7.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16639, Training Loss: 6.484e-01, Validation Loss: 7.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16640, Training Loss: 6.484e-01, Validation Loss: 7.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16641, Training Loss: 6.484e-01, Validation Loss: 7.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16642, Training Loss: 6.483e-01, Validation Loss: 7.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16643, Training Loss: 6.483e-01, Validation Loss: 7.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16644, Training Loss: 6.482e-01, Validation Loss: 7.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16645, Training Loss: 6.482e-01, Validation Loss: 7.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16646, Training Loss: 6.482e-01, Validation Loss: 7.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16647, Training Loss: 6.481e-01, Validation Loss: 7.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16648, Training Loss: 6.481e-01, Validation Loss: 7.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16649, Training Loss: 6.480e-01, Validation Loss: 7.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16650, Training Loss: 6.480e-01, Validation Loss: 7.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16651, Training Loss: 6.480e-01, Validation Loss: 7.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16652, Training Loss: 6.479e-01, Validation Loss: 7.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16653, Training Loss: 6.479e-01, Validation Loss: 7.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16654, Training Loss: 6.478e-01, Validation Loss: 7.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16655, Training Loss: 6.478e-01, Validation Loss: 7.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16656, Training Loss: 6.478e-01, Validation Loss: 7.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16657, Training Loss: 6.477e-01, Validation Loss: 7.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16658, Training Loss: 6.477e-01, Validation Loss: 7.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16659, Training Loss: 6.477e-01, Validation Loss: 7.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16660, Training Loss: 6.476e-01, Validation Loss: 7.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16661, Training Loss: 6.476e-01, Validation Loss: 7.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16662, Training Loss: 6.475e-01, Validation Loss: 7.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16663, Training Loss: 6.475e-01, Validation Loss: 7.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16664, Training Loss: 6.475e-01, Validation Loss: 7.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16665, Training Loss: 6.474e-01, Validation Loss: 7.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16666, Training Loss: 6.474e-01, Validation Loss: 7.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16667, Training Loss: 6.473e-01, Validation Loss: 7.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16668, Training Loss: 6.473e-01, Validation Loss: 7.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16669, Training Loss: 6.473e-01, Validation Loss: 7.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16670, Training Loss: 6.472e-01, Validation Loss: 7.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16671, Training Loss: 6.472e-01, Validation Loss: 7.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16672, Training Loss: 6.471e-01, Validation Loss: 7.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16673, Training Loss: 6.471e-01, Validation Loss: 7.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16674, Training Loss: 6.471e-01, Validation Loss: 7.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16675, Training Loss: 6.470e-01, Validation Loss: 7.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16676, Training Loss: 6.470e-01, Validation Loss: 7.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16677, Training Loss: 6.470e-01, Validation Loss: 7.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16678, Training Loss: 6.469e-01, Validation Loss: 7.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16679, Training Loss: 6.469e-01, Validation Loss: 7.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16680, Training Loss: 6.468e-01, Validation Loss: 7.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16681, Training Loss: 6.468e-01, Validation Loss: 7.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16682, Training Loss: 6.468e-01, Validation Loss: 7.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16683, Training Loss: 6.467e-01, Validation Loss: 7.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16684, Training Loss: 6.467e-01, Validation Loss: 7.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16685, Training Loss: 6.466e-01, Validation Loss: 7.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16686, Training Loss: 6.466e-01, Validation Loss: 7.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16687, Training Loss: 6.466e-01, Validation Loss: 7.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16688, Training Loss: 6.465e-01, Validation Loss: 7.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16689, Training Loss: 6.465e-01, Validation Loss: 7.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16690, Training Loss: 6.465e-01, Validation Loss: 7.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16691, Training Loss: 6.464e-01, Validation Loss: 7.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16692, Training Loss: 6.464e-01, Validation Loss: 7.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16693, Training Loss: 6.463e-01, Validation Loss: 7.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16694, Training Loss: 6.463e-01, Validation Loss: 7.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16695, Training Loss: 6.463e-01, Validation Loss: 7.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16696, Training Loss: 6.462e-01, Validation Loss: 7.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16697, Training Loss: 6.462e-01, Validation Loss: 7.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16698, Training Loss: 6.461e-01, Validation Loss: 7.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16699, Training Loss: 6.461e-01, Validation Loss: 7.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16700, Training Loss: 6.461e-01, Validation Loss: 7.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16701, Training Loss: 6.460e-01, Validation Loss: 7.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16702, Training Loss: 6.460e-01, Validation Loss: 7.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16703, Training Loss: 6.459e-01, Validation Loss: 7.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16704, Training Loss: 6.459e-01, Validation Loss: 7.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16705, Training Loss: 6.459e-01, Validation Loss: 7.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16706, Training Loss: 6.458e-01, Validation Loss: 7.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16707, Training Loss: 6.458e-01, Validation Loss: 7.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16708, Training Loss: 6.458e-01, Validation Loss: 7.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16709, Training Loss: 6.457e-01, Validation Loss: 7.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16710, Training Loss: 6.457e-01, Validation Loss: 7.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16711, Training Loss: 6.456e-01, Validation Loss: 7.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16712, Training Loss: 6.456e-01, Validation Loss: 7.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16713, Training Loss: 6.456e-01, Validation Loss: 7.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16714, Training Loss: 6.455e-01, Validation Loss: 7.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16715, Training Loss: 6.455e-01, Validation Loss: 7.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16716, Training Loss: 6.454e-01, Validation Loss: 7.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16717, Training Loss: 6.454e-01, Validation Loss: 7.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16718, Training Loss: 6.454e-01, Validation Loss: 7.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16719, Training Loss: 6.453e-01, Validation Loss: 7.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16720, Training Loss: 6.453e-01, Validation Loss: 7.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16721, Training Loss: 6.453e-01, Validation Loss: 7.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16722, Training Loss: 6.452e-01, Validation Loss: 7.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16723, Training Loss: 6.452e-01, Validation Loss: 7.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16724, Training Loss: 6.451e-01, Validation Loss: 7.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16725, Training Loss: 6.451e-01, Validation Loss: 7.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16726, Training Loss: 6.451e-01, Validation Loss: 7.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16727, Training Loss: 6.450e-01, Validation Loss: 7.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16728, Training Loss: 6.450e-01, Validation Loss: 7.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16729, Training Loss: 6.449e-01, Validation Loss: 7.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16730, Training Loss: 6.449e-01, Validation Loss: 7.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16731, Training Loss: 6.449e-01, Validation Loss: 7.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16732, Training Loss: 6.448e-01, Validation Loss: 7.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16733, Training Loss: 6.448e-01, Validation Loss: 7.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16734, Training Loss: 6.448e-01, Validation Loss: 7.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16735, Training Loss: 6.447e-01, Validation Loss: 7.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16736, Training Loss: 6.447e-01, Validation Loss: 7.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16737, Training Loss: 6.446e-01, Validation Loss: 7.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16738, Training Loss: 6.446e-01, Validation Loss: 7.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16739, Training Loss: 6.446e-01, Validation Loss: 7.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16740, Training Loss: 6.445e-01, Validation Loss: 7.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16741, Training Loss: 6.445e-01, Validation Loss: 7.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16742, Training Loss: 6.444e-01, Validation Loss: 7.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16743, Training Loss: 6.444e-01, Validation Loss: 7.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16744, Training Loss: 6.444e-01, Validation Loss: 7.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16745, Training Loss: 6.443e-01, Validation Loss: 7.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16746, Training Loss: 6.443e-01, Validation Loss: 7.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16747, Training Loss: 6.443e-01, Validation Loss: 7.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16748, Training Loss: 6.442e-01, Validation Loss: 7.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16749, Training Loss: 6.442e-01, Validation Loss: 7.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16750, Training Loss: 6.441e-01, Validation Loss: 7.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16751, Training Loss: 6.441e-01, Validation Loss: 7.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16752, Training Loss: 6.441e-01, Validation Loss: 7.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16753, Training Loss: 6.440e-01, Validation Loss: 7.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16754, Training Loss: 6.440e-01, Validation Loss: 7.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16755, Training Loss: 6.439e-01, Validation Loss: 7.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16756, Training Loss: 6.439e-01, Validation Loss: 7.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16757, Training Loss: 6.439e-01, Validation Loss: 7.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16758, Training Loss: 6.438e-01, Validation Loss: 7.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16759, Training Loss: 6.438e-01, Validation Loss: 7.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16760, Training Loss: 6.438e-01, Validation Loss: 7.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16761, Training Loss: 6.437e-01, Validation Loss: 7.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16762, Training Loss: 6.437e-01, Validation Loss: 7.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16763, Training Loss: 6.436e-01, Validation Loss: 7.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16764, Training Loss: 6.436e-01, Validation Loss: 7.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16765, Training Loss: 6.436e-01, Validation Loss: 7.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16766, Training Loss: 6.435e-01, Validation Loss: 7.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16767, Training Loss: 6.435e-01, Validation Loss: 7.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16768, Training Loss: 6.434e-01, Validation Loss: 7.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16769, Training Loss: 6.434e-01, Validation Loss: 7.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16770, Training Loss: 6.434e-01, Validation Loss: 7.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16771, Training Loss: 6.433e-01, Validation Loss: 7.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16772, Training Loss: 6.433e-01, Validation Loss: 7.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16773, Training Loss: 6.433e-01, Validation Loss: 7.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16774, Training Loss: 6.432e-01, Validation Loss: 7.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16775, Training Loss: 6.432e-01, Validation Loss: 7.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16776, Training Loss: 6.431e-01, Validation Loss: 7.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16777, Training Loss: 6.431e-01, Validation Loss: 7.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16778, Training Loss: 6.431e-01, Validation Loss: 7.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16779, Training Loss: 6.430e-01, Validation Loss: 7.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16780, Training Loss: 6.430e-01, Validation Loss: 7.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16781, Training Loss: 6.429e-01, Validation Loss: 7.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16782, Training Loss: 6.429e-01, Validation Loss: 7.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16783, Training Loss: 6.429e-01, Validation Loss: 7.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16784, Training Loss: 6.428e-01, Validation Loss: 7.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16785, Training Loss: 6.428e-01, Validation Loss: 7.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16786, Training Loss: 6.428e-01, Validation Loss: 7.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16787, Training Loss: 6.427e-01, Validation Loss: 7.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16788, Training Loss: 6.427e-01, Validation Loss: 7.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16789, Training Loss: 6.426e-01, Validation Loss: 7.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16790, Training Loss: 6.426e-01, Validation Loss: 7.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16791, Training Loss: 6.426e-01, Validation Loss: 7.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16792, Training Loss: 6.425e-01, Validation Loss: 7.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16793, Training Loss: 6.425e-01, Validation Loss: 7.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16794, Training Loss: 6.424e-01, Validation Loss: 7.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16795, Training Loss: 6.424e-01, Validation Loss: 7.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16796, Training Loss: 6.424e-01, Validation Loss: 7.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16797, Training Loss: 6.423e-01, Validation Loss: 7.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16798, Training Loss: 6.423e-01, Validation Loss: 7.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16799, Training Loss: 6.423e-01, Validation Loss: 7.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16800, Training Loss: 6.422e-01, Validation Loss: 7.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16801, Training Loss: 6.422e-01, Validation Loss: 7.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16802, Training Loss: 6.421e-01, Validation Loss: 7.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16803, Training Loss: 6.421e-01, Validation Loss: 7.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16804, Training Loss: 6.421e-01, Validation Loss: 7.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16805, Training Loss: 6.420e-01, Validation Loss: 7.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16806, Training Loss: 6.420e-01, Validation Loss: 7.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16807, Training Loss: 6.420e-01, Validation Loss: 7.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16808, Training Loss: 6.419e-01, Validation Loss: 7.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16809, Training Loss: 6.419e-01, Validation Loss: 7.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16810, Training Loss: 6.418e-01, Validation Loss: 7.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16811, Training Loss: 6.418e-01, Validation Loss: 7.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16812, Training Loss: 6.418e-01, Validation Loss: 7.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16813, Training Loss: 6.417e-01, Validation Loss: 7.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16814, Training Loss: 6.417e-01, Validation Loss: 7.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16815, Training Loss: 6.416e-01, Validation Loss: 7.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16816, Training Loss: 6.416e-01, Validation Loss: 7.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16817, Training Loss: 6.416e-01, Validation Loss: 7.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16818, Training Loss: 6.415e-01, Validation Loss: 7.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16819, Training Loss: 6.415e-01, Validation Loss: 7.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16820, Training Loss: 6.415e-01, Validation Loss: 7.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16821, Training Loss: 6.414e-01, Validation Loss: 7.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16822, Training Loss: 6.414e-01, Validation Loss: 7.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16823, Training Loss: 6.413e-01, Validation Loss: 7.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16824, Training Loss: 6.413e-01, Validation Loss: 7.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16825, Training Loss: 6.413e-01, Validation Loss: 7.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16826, Training Loss: 6.412e-01, Validation Loss: 7.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16827, Training Loss: 6.412e-01, Validation Loss: 7.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16828, Training Loss: 6.412e-01, Validation Loss: 7.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16829, Training Loss: 6.411e-01, Validation Loss: 7.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16830, Training Loss: 6.411e-01, Validation Loss: 7.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16831, Training Loss: 6.410e-01, Validation Loss: 7.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16832, Training Loss: 6.410e-01, Validation Loss: 7.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16833, Training Loss: 6.410e-01, Validation Loss: 7.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16834, Training Loss: 6.409e-01, Validation Loss: 7.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16835, Training Loss: 6.409e-01, Validation Loss: 7.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16836, Training Loss: 6.408e-01, Validation Loss: 7.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16837, Training Loss: 6.408e-01, Validation Loss: 7.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16838, Training Loss: 6.408e-01, Validation Loss: 7.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16839, Training Loss: 6.407e-01, Validation Loss: 7.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16840, Training Loss: 6.407e-01, Validation Loss: 7.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16841, Training Loss: 6.407e-01, Validation Loss: 7.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16842, Training Loss: 6.406e-01, Validation Loss: 7.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16843, Training Loss: 6.406e-01, Validation Loss: 7.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16844, Training Loss: 6.405e-01, Validation Loss: 7.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16845, Training Loss: 6.405e-01, Validation Loss: 7.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16846, Training Loss: 6.405e-01, Validation Loss: 7.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16847, Training Loss: 6.404e-01, Validation Loss: 7.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16848, Training Loss: 6.404e-01, Validation Loss: 7.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16849, Training Loss: 6.404e-01, Validation Loss: 7.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16850, Training Loss: 6.403e-01, Validation Loss: 7.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16851, Training Loss: 6.403e-01, Validation Loss: 7.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16852, Training Loss: 6.402e-01, Validation Loss: 7.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16853, Training Loss: 6.402e-01, Validation Loss: 7.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16854, Training Loss: 6.402e-01, Validation Loss: 7.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16855, Training Loss: 6.401e-01, Validation Loss: 7.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16856, Training Loss: 6.401e-01, Validation Loss: 7.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16857, Training Loss: 6.400e-01, Validation Loss: 7.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16858, Training Loss: 6.400e-01, Validation Loss: 7.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16859, Training Loss: 6.400e-01, Validation Loss: 7.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16860, Training Loss: 6.399e-01, Validation Loss: 7.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16861, Training Loss: 6.399e-01, Validation Loss: 7.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16862, Training Loss: 6.399e-01, Validation Loss: 7.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16863, Training Loss: 6.398e-01, Validation Loss: 7.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16864, Training Loss: 6.398e-01, Validation Loss: 7.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16865, Training Loss: 6.397e-01, Validation Loss: 7.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16866, Training Loss: 6.397e-01, Validation Loss: 7.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16867, Training Loss: 6.397e-01, Validation Loss: 7.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16868, Training Loss: 6.396e-01, Validation Loss: 7.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16869, Training Loss: 6.396e-01, Validation Loss: 7.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16870, Training Loss: 6.396e-01, Validation Loss: 7.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16871, Training Loss: 6.395e-01, Validation Loss: 7.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16872, Training Loss: 6.395e-01, Validation Loss: 7.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16873, Training Loss: 6.394e-01, Validation Loss: 7.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16874, Training Loss: 6.394e-01, Validation Loss: 7.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16875, Training Loss: 6.394e-01, Validation Loss: 7.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16876, Training Loss: 6.393e-01, Validation Loss: 7.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16877, Training Loss: 6.393e-01, Validation Loss: 7.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16878, Training Loss: 6.392e-01, Validation Loss: 7.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16879, Training Loss: 6.392e-01, Validation Loss: 7.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16880, Training Loss: 6.392e-01, Validation Loss: 7.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16881, Training Loss: 6.391e-01, Validation Loss: 7.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16882, Training Loss: 6.391e-01, Validation Loss: 7.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16883, Training Loss: 6.391e-01, Validation Loss: 7.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16884, Training Loss: 6.390e-01, Validation Loss: 7.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16885, Training Loss: 6.390e-01, Validation Loss: 7.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16886, Training Loss: 6.389e-01, Validation Loss: 7.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16887, Training Loss: 6.389e-01, Validation Loss: 7.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16888, Training Loss: 6.389e-01, Validation Loss: 7.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16889, Training Loss: 6.388e-01, Validation Loss: 7.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16890, Training Loss: 6.388e-01, Validation Loss: 7.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16891, Training Loss: 6.388e-01, Validation Loss: 7.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16892, Training Loss: 6.387e-01, Validation Loss: 7.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16893, Training Loss: 6.387e-01, Validation Loss: 7.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16894, Training Loss: 6.386e-01, Validation Loss: 7.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16895, Training Loss: 6.386e-01, Validation Loss: 7.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16896, Training Loss: 6.386e-01, Validation Loss: 7.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16897, Training Loss: 6.385e-01, Validation Loss: 7.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16898, Training Loss: 6.385e-01, Validation Loss: 7.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16899, Training Loss: 6.385e-01, Validation Loss: 7.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16900, Training Loss: 6.384e-01, Validation Loss: 7.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16901, Training Loss: 6.384e-01, Validation Loss: 7.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16902, Training Loss: 6.383e-01, Validation Loss: 7.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16903, Training Loss: 6.383e-01, Validation Loss: 7.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16904, Training Loss: 6.383e-01, Validation Loss: 7.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16905, Training Loss: 6.382e-01, Validation Loss: 7.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16906, Training Loss: 6.382e-01, Validation Loss: 7.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16907, Training Loss: 6.382e-01, Validation Loss: 7.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16908, Training Loss: 6.381e-01, Validation Loss: 7.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16909, Training Loss: 6.381e-01, Validation Loss: 7.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16910, Training Loss: 6.380e-01, Validation Loss: 7.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16911, Training Loss: 6.380e-01, Validation Loss: 7.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16912, Training Loss: 6.380e-01, Validation Loss: 7.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16913, Training Loss: 6.379e-01, Validation Loss: 7.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16914, Training Loss: 6.379e-01, Validation Loss: 7.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16915, Training Loss: 6.378e-01, Validation Loss: 7.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16916, Training Loss: 6.378e-01, Validation Loss: 7.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16917, Training Loss: 6.378e-01, Validation Loss: 7.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16918, Training Loss: 6.377e-01, Validation Loss: 7.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16919, Training Loss: 6.377e-01, Validation Loss: 7.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16920, Training Loss: 6.377e-01, Validation Loss: 7.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16921, Training Loss: 6.376e-01, Validation Loss: 7.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16922, Training Loss: 6.376e-01, Validation Loss: 7.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16923, Training Loss: 6.375e-01, Validation Loss: 7.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16924, Training Loss: 6.375e-01, Validation Loss: 7.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16925, Training Loss: 6.375e-01, Validation Loss: 7.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16926, Training Loss: 6.374e-01, Validation Loss: 7.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16927, Training Loss: 6.374e-01, Validation Loss: 7.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16928, Training Loss: 6.374e-01, Validation Loss: 7.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16929, Training Loss: 6.373e-01, Validation Loss: 7.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16930, Training Loss: 6.373e-01, Validation Loss: 7.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16931, Training Loss: 6.372e-01, Validation Loss: 7.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16932, Training Loss: 6.372e-01, Validation Loss: 7.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16933, Training Loss: 6.372e-01, Validation Loss: 7.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16934, Training Loss: 6.371e-01, Validation Loss: 7.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16935, Training Loss: 6.371e-01, Validation Loss: 7.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16936, Training Loss: 6.371e-01, Validation Loss: 7.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16937, Training Loss: 6.370e-01, Validation Loss: 7.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16938, Training Loss: 6.370e-01, Validation Loss: 7.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16939, Training Loss: 6.369e-01, Validation Loss: 7.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16940, Training Loss: 6.369e-01, Validation Loss: 7.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16941, Training Loss: 6.369e-01, Validation Loss: 7.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16942, Training Loss: 6.368e-01, Validation Loss: 7.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16943, Training Loss: 6.368e-01, Validation Loss: 7.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16944, Training Loss: 6.368e-01, Validation Loss: 7.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16945, Training Loss: 6.367e-01, Validation Loss: 7.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16946, Training Loss: 6.367e-01, Validation Loss: 7.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16947, Training Loss: 6.366e-01, Validation Loss: 7.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16948, Training Loss: 6.366e-01, Validation Loss: 7.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16949, Training Loss: 6.366e-01, Validation Loss: 7.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16950, Training Loss: 6.365e-01, Validation Loss: 7.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16951, Training Loss: 6.365e-01, Validation Loss: 7.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16952, Training Loss: 6.365e-01, Validation Loss: 7.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16953, Training Loss: 6.364e-01, Validation Loss: 7.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16954, Training Loss: 6.364e-01, Validation Loss: 7.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16955, Training Loss: 6.363e-01, Validation Loss: 7.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16956, Training Loss: 6.363e-01, Validation Loss: 7.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16957, Training Loss: 6.363e-01, Validation Loss: 7.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16958, Training Loss: 6.362e-01, Validation Loss: 7.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16959, Training Loss: 6.362e-01, Validation Loss: 7.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16960, Training Loss: 6.362e-01, Validation Loss: 7.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16961, Training Loss: 6.361e-01, Validation Loss: 7.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16962, Training Loss: 6.361e-01, Validation Loss: 7.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16963, Training Loss: 6.360e-01, Validation Loss: 7.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16964, Training Loss: 6.360e-01, Validation Loss: 7.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16965, Training Loss: 6.360e-01, Validation Loss: 7.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16966, Training Loss: 6.359e-01, Validation Loss: 7.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16967, Training Loss: 6.359e-01, Validation Loss: 7.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16968, Training Loss: 6.359e-01, Validation Loss: 7.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16969, Training Loss: 6.358e-01, Validation Loss: 7.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16970, Training Loss: 6.358e-01, Validation Loss: 7.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16971, Training Loss: 6.357e-01, Validation Loss: 7.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16972, Training Loss: 6.357e-01, Validation Loss: 7.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16973, Training Loss: 6.357e-01, Validation Loss: 7.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16974, Training Loss: 6.356e-01, Validation Loss: 7.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16975, Training Loss: 6.356e-01, Validation Loss: 7.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16976, Training Loss: 6.356e-01, Validation Loss: 7.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16977, Training Loss: 6.355e-01, Validation Loss: 7.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16978, Training Loss: 6.355e-01, Validation Loss: 7.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16979, Training Loss: 6.354e-01, Validation Loss: 7.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16980, Training Loss: 6.354e-01, Validation Loss: 7.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16981, Training Loss: 6.354e-01, Validation Loss: 7.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16982, Training Loss: 6.353e-01, Validation Loss: 7.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16983, Training Loss: 6.353e-01, Validation Loss: 7.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16984, Training Loss: 6.353e-01, Validation Loss: 7.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16985, Training Loss: 6.352e-01, Validation Loss: 7.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16986, Training Loss: 6.352e-01, Validation Loss: 7.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16987, Training Loss: 6.351e-01, Validation Loss: 7.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16988, Training Loss: 6.351e-01, Validation Loss: 7.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16989, Training Loss: 6.351e-01, Validation Loss: 7.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16990, Training Loss: 6.350e-01, Validation Loss: 7.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16991, Training Loss: 6.350e-01, Validation Loss: 7.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16992, Training Loss: 6.350e-01, Validation Loss: 7.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16993, Training Loss: 6.349e-01, Validation Loss: 7.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16994, Training Loss: 6.349e-01, Validation Loss: 7.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16995, Training Loss: 6.348e-01, Validation Loss: 7.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16996, Training Loss: 6.348e-01, Validation Loss: 7.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16997, Training Loss: 6.348e-01, Validation Loss: 7.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16998, Training Loss: 6.347e-01, Validation Loss: 7.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16999, Training Loss: 6.347e-01, Validation Loss: 7.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17000, Training Loss: 6.347e-01, Validation Loss: 7.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17001, Training Loss: 6.346e-01, Validation Loss: 7.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17002, Training Loss: 6.346e-01, Validation Loss: 7.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17003, Training Loss: 6.345e-01, Validation Loss: 7.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17004, Training Loss: 6.345e-01, Validation Loss: 7.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17005, Training Loss: 6.345e-01, Validation Loss: 7.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17006, Training Loss: 6.344e-01, Validation Loss: 7.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17007, Training Loss: 6.344e-01, Validation Loss: 7.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17008, Training Loss: 6.344e-01, Validation Loss: 7.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17009, Training Loss: 6.343e-01, Validation Loss: 7.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17010, Training Loss: 6.343e-01, Validation Loss: 7.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17011, Training Loss: 6.342e-01, Validation Loss: 7.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17012, Training Loss: 6.342e-01, Validation Loss: 7.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17013, Training Loss: 6.342e-01, Validation Loss: 7.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17014, Training Loss: 6.341e-01, Validation Loss: 7.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17015, Training Loss: 6.341e-01, Validation Loss: 7.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17016, Training Loss: 6.341e-01, Validation Loss: 7.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17017, Training Loss: 6.340e-01, Validation Loss: 7.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17018, Training Loss: 6.340e-01, Validation Loss: 7.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17019, Training Loss: 6.339e-01, Validation Loss: 7.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17020, Training Loss: 6.339e-01, Validation Loss: 7.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17021, Training Loss: 6.339e-01, Validation Loss: 7.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17022, Training Loss: 6.338e-01, Validation Loss: 7.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17023, Training Loss: 6.338e-01, Validation Loss: 7.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17024, Training Loss: 6.338e-01, Validation Loss: 7.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17025, Training Loss: 6.337e-01, Validation Loss: 7.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17026, Training Loss: 6.337e-01, Validation Loss: 7.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17027, Training Loss: 6.336e-01, Validation Loss: 7.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17028, Training Loss: 6.336e-01, Validation Loss: 7.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17029, Training Loss: 6.336e-01, Validation Loss: 7.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17030, Training Loss: 6.335e-01, Validation Loss: 7.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17031, Training Loss: 6.335e-01, Validation Loss: 7.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17032, Training Loss: 6.335e-01, Validation Loss: 7.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17033, Training Loss: 6.334e-01, Validation Loss: 7.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17034, Training Loss: 6.334e-01, Validation Loss: 7.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17035, Training Loss: 6.333e-01, Validation Loss: 7.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17036, Training Loss: 6.333e-01, Validation Loss: 7.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17037, Training Loss: 6.333e-01, Validation Loss: 7.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17038, Training Loss: 6.332e-01, Validation Loss: 7.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17039, Training Loss: 6.332e-01, Validation Loss: 7.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17040, Training Loss: 6.332e-01, Validation Loss: 7.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17041, Training Loss: 6.331e-01, Validation Loss: 7.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17042, Training Loss: 6.331e-01, Validation Loss: 7.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17043, Training Loss: 6.330e-01, Validation Loss: 7.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17044, Training Loss: 6.330e-01, Validation Loss: 7.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17045, Training Loss: 6.330e-01, Validation Loss: 7.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17046, Training Loss: 6.329e-01, Validation Loss: 7.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17047, Training Loss: 6.329e-01, Validation Loss: 7.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17048, Training Loss: 6.329e-01, Validation Loss: 7.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17049, Training Loss: 6.328e-01, Validation Loss: 7.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17050, Training Loss: 6.328e-01, Validation Loss: 7.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17051, Training Loss: 6.327e-01, Validation Loss: 7.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17052, Training Loss: 6.327e-01, Validation Loss: 7.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17053, Training Loss: 6.327e-01, Validation Loss: 7.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17054, Training Loss: 6.326e-01, Validation Loss: 7.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17055, Training Loss: 6.326e-01, Validation Loss: 7.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17056, Training Loss: 6.326e-01, Validation Loss: 7.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17057, Training Loss: 6.325e-01, Validation Loss: 7.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17058, Training Loss: 6.325e-01, Validation Loss: 7.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17059, Training Loss: 6.324e-01, Validation Loss: 7.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17060, Training Loss: 6.324e-01, Validation Loss: 7.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17061, Training Loss: 6.324e-01, Validation Loss: 7.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17062, Training Loss: 6.323e-01, Validation Loss: 7.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17063, Training Loss: 6.323e-01, Validation Loss: 7.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17064, Training Loss: 6.323e-01, Validation Loss: 7.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17065, Training Loss: 6.322e-01, Validation Loss: 7.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17066, Training Loss: 6.322e-01, Validation Loss: 7.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17067, Training Loss: 6.321e-01, Validation Loss: 7.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17068, Training Loss: 6.321e-01, Validation Loss: 7.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17069, Training Loss: 6.321e-01, Validation Loss: 7.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17070, Training Loss: 6.320e-01, Validation Loss: 7.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17071, Training Loss: 6.320e-01, Validation Loss: 7.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17072, Training Loss: 6.320e-01, Validation Loss: 7.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17073, Training Loss: 6.319e-01, Validation Loss: 7.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17074, Training Loss: 6.319e-01, Validation Loss: 7.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17075, Training Loss: 6.319e-01, Validation Loss: 7.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17076, Training Loss: 6.318e-01, Validation Loss: 7.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17077, Training Loss: 6.318e-01, Validation Loss: 7.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17078, Training Loss: 6.317e-01, Validation Loss: 7.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17079, Training Loss: 6.317e-01, Validation Loss: 7.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17080, Training Loss: 6.317e-01, Validation Loss: 7.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17081, Training Loss: 6.316e-01, Validation Loss: 7.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17082, Training Loss: 6.316e-01, Validation Loss: 7.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17083, Training Loss: 6.316e-01, Validation Loss: 7.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17084, Training Loss: 6.315e-01, Validation Loss: 7.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17085, Training Loss: 6.315e-01, Validation Loss: 7.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17086, Training Loss: 6.314e-01, Validation Loss: 7.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17087, Training Loss: 6.314e-01, Validation Loss: 7.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17088, Training Loss: 6.314e-01, Validation Loss: 7.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17089, Training Loss: 6.313e-01, Validation Loss: 7.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17090, Training Loss: 6.313e-01, Validation Loss: 7.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17091, Training Loss: 6.313e-01, Validation Loss: 7.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17092, Training Loss: 6.312e-01, Validation Loss: 7.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17093, Training Loss: 6.312e-01, Validation Loss: 7.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17094, Training Loss: 6.311e-01, Validation Loss: 7.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17095, Training Loss: 6.311e-01, Validation Loss: 7.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17096, Training Loss: 6.311e-01, Validation Loss: 7.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17097, Training Loss: 6.310e-01, Validation Loss: 7.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17098, Training Loss: 6.310e-01, Validation Loss: 7.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17099, Training Loss: 6.310e-01, Validation Loss: 7.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17100, Training Loss: 6.309e-01, Validation Loss: 7.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17101, Training Loss: 6.309e-01, Validation Loss: 7.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17102, Training Loss: 6.309e-01, Validation Loss: 7.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17103, Training Loss: 6.308e-01, Validation Loss: 7.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17104, Training Loss: 6.308e-01, Validation Loss: 7.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17105, Training Loss: 6.307e-01, Validation Loss: 7.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17106, Training Loss: 6.307e-01, Validation Loss: 7.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17107, Training Loss: 6.307e-01, Validation Loss: 7.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17108, Training Loss: 6.306e-01, Validation Loss: 7.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17109, Training Loss: 6.306e-01, Validation Loss: 7.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17110, Training Loss: 6.306e-01, Validation Loss: 7.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17111, Training Loss: 6.305e-01, Validation Loss: 7.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17112, Training Loss: 6.305e-01, Validation Loss: 7.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17113, Training Loss: 6.304e-01, Validation Loss: 7.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17114, Training Loss: 6.304e-01, Validation Loss: 7.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17115, Training Loss: 6.304e-01, Validation Loss: 7.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17116, Training Loss: 6.303e-01, Validation Loss: 7.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17117, Training Loss: 6.303e-01, Validation Loss: 7.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17118, Training Loss: 6.303e-01, Validation Loss: 7.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17119, Training Loss: 6.302e-01, Validation Loss: 7.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17120, Training Loss: 6.302e-01, Validation Loss: 7.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17121, Training Loss: 6.301e-01, Validation Loss: 7.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17122, Training Loss: 6.301e-01, Validation Loss: 7.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17123, Training Loss: 6.301e-01, Validation Loss: 7.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17124, Training Loss: 6.300e-01, Validation Loss: 7.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17125, Training Loss: 6.300e-01, Validation Loss: 7.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17126, Training Loss: 6.300e-01, Validation Loss: 7.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17127, Training Loss: 6.299e-01, Validation Loss: 7.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17128, Training Loss: 6.299e-01, Validation Loss: 7.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17129, Training Loss: 6.299e-01, Validation Loss: 7.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17130, Training Loss: 6.298e-01, Validation Loss: 7.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17131, Training Loss: 6.298e-01, Validation Loss: 7.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17132, Training Loss: 6.297e-01, Validation Loss: 7.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17133, Training Loss: 6.297e-01, Validation Loss: 7.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17134, Training Loss: 6.297e-01, Validation Loss: 7.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17135, Training Loss: 6.296e-01, Validation Loss: 7.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17136, Training Loss: 6.296e-01, Validation Loss: 7.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17137, Training Loss: 6.296e-01, Validation Loss: 7.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17138, Training Loss: 6.295e-01, Validation Loss: 7.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17139, Training Loss: 6.295e-01, Validation Loss: 7.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17140, Training Loss: 6.294e-01, Validation Loss: 7.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17141, Training Loss: 6.294e-01, Validation Loss: 7.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17142, Training Loss: 6.294e-01, Validation Loss: 7.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17143, Training Loss: 6.293e-01, Validation Loss: 7.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17144, Training Loss: 6.293e-01, Validation Loss: 7.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17145, Training Loss: 6.293e-01, Validation Loss: 7.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17146, Training Loss: 6.292e-01, Validation Loss: 7.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17147, Training Loss: 6.292e-01, Validation Loss: 7.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17148, Training Loss: 6.292e-01, Validation Loss: 7.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17149, Training Loss: 6.291e-01, Validation Loss: 7.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17150, Training Loss: 6.291e-01, Validation Loss: 7.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17151, Training Loss: 6.290e-01, Validation Loss: 7.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17152, Training Loss: 6.290e-01, Validation Loss: 7.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17153, Training Loss: 6.290e-01, Validation Loss: 7.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17154, Training Loss: 6.289e-01, Validation Loss: 7.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17155, Training Loss: 6.289e-01, Validation Loss: 7.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17156, Training Loss: 6.289e-01, Validation Loss: 7.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17157, Training Loss: 6.288e-01, Validation Loss: 7.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17158, Training Loss: 6.288e-01, Validation Loss: 7.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17159, Training Loss: 6.287e-01, Validation Loss: 7.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17160, Training Loss: 6.287e-01, Validation Loss: 7.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17161, Training Loss: 6.287e-01, Validation Loss: 7.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17162, Training Loss: 6.286e-01, Validation Loss: 7.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17163, Training Loss: 6.286e-01, Validation Loss: 7.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17164, Training Loss: 6.286e-01, Validation Loss: 7.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17165, Training Loss: 6.285e-01, Validation Loss: 7.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17166, Training Loss: 6.285e-01, Validation Loss: 7.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17167, Training Loss: 6.285e-01, Validation Loss: 7.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17168, Training Loss: 6.284e-01, Validation Loss: 7.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17169, Training Loss: 6.284e-01, Validation Loss: 7.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17170, Training Loss: 6.283e-01, Validation Loss: 7.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17171, Training Loss: 6.283e-01, Validation Loss: 7.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17172, Training Loss: 6.283e-01, Validation Loss: 7.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17173, Training Loss: 6.282e-01, Validation Loss: 7.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17174, Training Loss: 6.282e-01, Validation Loss: 7.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17175, Training Loss: 6.282e-01, Validation Loss: 7.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17176, Training Loss: 6.281e-01, Validation Loss: 7.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17177, Training Loss: 6.281e-01, Validation Loss: 7.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17178, Training Loss: 6.280e-01, Validation Loss: 7.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17179, Training Loss: 6.280e-01, Validation Loss: 7.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17180, Training Loss: 6.280e-01, Validation Loss: 7.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17181, Training Loss: 6.279e-01, Validation Loss: 7.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17182, Training Loss: 6.279e-01, Validation Loss: 7.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17183, Training Loss: 6.279e-01, Validation Loss: 7.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17184, Training Loss: 6.278e-01, Validation Loss: 7.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17185, Training Loss: 6.278e-01, Validation Loss: 7.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17186, Training Loss: 6.278e-01, Validation Loss: 7.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17187, Training Loss: 6.277e-01, Validation Loss: 7.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17188, Training Loss: 6.277e-01, Validation Loss: 7.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17189, Training Loss: 6.276e-01, Validation Loss: 7.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17190, Training Loss: 6.276e-01, Validation Loss: 7.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17191, Training Loss: 6.276e-01, Validation Loss: 7.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17192, Training Loss: 6.275e-01, Validation Loss: 7.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17193, Training Loss: 6.275e-01, Validation Loss: 7.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17194, Training Loss: 6.275e-01, Validation Loss: 7.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17195, Training Loss: 6.274e-01, Validation Loss: 7.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17196, Training Loss: 6.274e-01, Validation Loss: 7.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17197, Training Loss: 6.273e-01, Validation Loss: 7.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17198, Training Loss: 6.273e-01, Validation Loss: 7.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17199, Training Loss: 6.273e-01, Validation Loss: 7.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17200, Training Loss: 6.272e-01, Validation Loss: 7.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17201, Training Loss: 6.272e-01, Validation Loss: 7.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17202, Training Loss: 6.272e-01, Validation Loss: 7.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17203, Training Loss: 6.271e-01, Validation Loss: 7.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17204, Training Loss: 6.271e-01, Validation Loss: 7.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17205, Training Loss: 6.271e-01, Validation Loss: 7.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17206, Training Loss: 6.270e-01, Validation Loss: 7.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17207, Training Loss: 6.270e-01, Validation Loss: 7.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17208, Training Loss: 6.269e-01, Validation Loss: 7.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17209, Training Loss: 6.269e-01, Validation Loss: 7.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17210, Training Loss: 6.269e-01, Validation Loss: 7.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17211, Training Loss: 6.268e-01, Validation Loss: 7.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17212, Training Loss: 6.268e-01, Validation Loss: 7.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17213, Training Loss: 6.268e-01, Validation Loss: 7.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17214, Training Loss: 6.267e-01, Validation Loss: 7.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17215, Training Loss: 6.267e-01, Validation Loss: 7.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17216, Training Loss: 6.267e-01, Validation Loss: 7.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17217, Training Loss: 6.266e-01, Validation Loss: 7.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17218, Training Loss: 6.266e-01, Validation Loss: 7.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17219, Training Loss: 6.265e-01, Validation Loss: 7.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17220, Training Loss: 6.265e-01, Validation Loss: 7.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17221, Training Loss: 6.265e-01, Validation Loss: 7.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17222, Training Loss: 6.264e-01, Validation Loss: 7.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17223, Training Loss: 6.264e-01, Validation Loss: 7.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17224, Training Loss: 6.264e-01, Validation Loss: 7.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17225, Training Loss: 6.263e-01, Validation Loss: 7.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17226, Training Loss: 6.263e-01, Validation Loss: 7.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17227, Training Loss: 6.262e-01, Validation Loss: 7.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17228, Training Loss: 6.262e-01, Validation Loss: 7.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17229, Training Loss: 6.262e-01, Validation Loss: 7.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17230, Training Loss: 6.261e-01, Validation Loss: 7.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17231, Training Loss: 6.261e-01, Validation Loss: 7.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17232, Training Loss: 6.261e-01, Validation Loss: 7.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17233, Training Loss: 6.260e-01, Validation Loss: 7.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17234, Training Loss: 6.260e-01, Validation Loss: 7.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17235, Training Loss: 6.260e-01, Validation Loss: 7.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17236, Training Loss: 6.259e-01, Validation Loss: 7.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17237, Training Loss: 6.259e-01, Validation Loss: 7.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17238, Training Loss: 6.258e-01, Validation Loss: 7.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17239, Training Loss: 6.258e-01, Validation Loss: 7.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17240, Training Loss: 6.258e-01, Validation Loss: 7.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17241, Training Loss: 6.257e-01, Validation Loss: 7.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17242, Training Loss: 6.257e-01, Validation Loss: 7.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17243, Training Loss: 6.257e-01, Validation Loss: 7.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17244, Training Loss: 6.256e-01, Validation Loss: 7.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17245, Training Loss: 6.256e-01, Validation Loss: 7.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17246, Training Loss: 6.256e-01, Validation Loss: 7.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17247, Training Loss: 6.255e-01, Validation Loss: 7.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17248, Training Loss: 6.255e-01, Validation Loss: 7.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17249, Training Loss: 6.254e-01, Validation Loss: 7.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17250, Training Loss: 6.254e-01, Validation Loss: 7.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17251, Training Loss: 6.254e-01, Validation Loss: 7.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17252, Training Loss: 6.253e-01, Validation Loss: 7.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17253, Training Loss: 6.253e-01, Validation Loss: 7.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17254, Training Loss: 6.253e-01, Validation Loss: 7.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17255, Training Loss: 6.252e-01, Validation Loss: 7.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17256, Training Loss: 6.252e-01, Validation Loss: 7.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17257, Training Loss: 6.252e-01, Validation Loss: 7.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17258, Training Loss: 6.251e-01, Validation Loss: 7.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17259, Training Loss: 6.251e-01, Validation Loss: 7.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17260, Training Loss: 6.250e-01, Validation Loss: 7.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17261, Training Loss: 6.250e-01, Validation Loss: 7.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17262, Training Loss: 6.250e-01, Validation Loss: 7.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17263, Training Loss: 6.249e-01, Validation Loss: 7.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17264, Training Loss: 6.249e-01, Validation Loss: 7.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17265, Training Loss: 6.249e-01, Validation Loss: 7.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17266, Training Loss: 6.248e-01, Validation Loss: 7.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17267, Training Loss: 6.248e-01, Validation Loss: 7.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17268, Training Loss: 6.248e-01, Validation Loss: 7.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17269, Training Loss: 6.247e-01, Validation Loss: 7.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17270, Training Loss: 6.247e-01, Validation Loss: 7.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17271, Training Loss: 6.246e-01, Validation Loss: 7.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17272, Training Loss: 6.246e-01, Validation Loss: 7.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17273, Training Loss: 6.246e-01, Validation Loss: 7.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17274, Training Loss: 6.245e-01, Validation Loss: 7.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17275, Training Loss: 6.245e-01, Validation Loss: 7.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17276, Training Loss: 6.245e-01, Validation Loss: 7.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17277, Training Loss: 6.244e-01, Validation Loss: 7.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17278, Training Loss: 6.244e-01, Validation Loss: 7.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17279, Training Loss: 6.244e-01, Validation Loss: 7.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17280, Training Loss: 6.243e-01, Validation Loss: 7.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17281, Training Loss: 6.243e-01, Validation Loss: 7.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17282, Training Loss: 6.242e-01, Validation Loss: 7.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17283, Training Loss: 6.242e-01, Validation Loss: 7.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17284, Training Loss: 6.242e-01, Validation Loss: 7.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17285, Training Loss: 6.241e-01, Validation Loss: 7.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17286, Training Loss: 6.241e-01, Validation Loss: 7.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17287, Training Loss: 6.241e-01, Validation Loss: 7.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17288, Training Loss: 6.240e-01, Validation Loss: 7.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17289, Training Loss: 6.240e-01, Validation Loss: 7.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17290, Training Loss: 6.240e-01, Validation Loss: 7.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17291, Training Loss: 6.239e-01, Validation Loss: 7.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17292, Training Loss: 6.239e-01, Validation Loss: 7.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17293, Training Loss: 6.238e-01, Validation Loss: 7.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17294, Training Loss: 6.238e-01, Validation Loss: 7.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17295, Training Loss: 6.238e-01, Validation Loss: 7.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17296, Training Loss: 6.237e-01, Validation Loss: 7.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17297, Training Loss: 6.237e-01, Validation Loss: 7.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17298, Training Loss: 6.237e-01, Validation Loss: 7.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17299, Training Loss: 6.236e-01, Validation Loss: 7.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17300, Training Loss: 6.236e-01, Validation Loss: 7.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17301, Training Loss: 6.236e-01, Validation Loss: 7.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17302, Training Loss: 6.235e-01, Validation Loss: 7.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17303, Training Loss: 6.235e-01, Validation Loss: 7.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17304, Training Loss: 6.234e-01, Validation Loss: 7.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17305, Training Loss: 6.234e-01, Validation Loss: 7.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17306, Training Loss: 6.234e-01, Validation Loss: 7.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17307, Training Loss: 6.233e-01, Validation Loss: 7.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17308, Training Loss: 6.233e-01, Validation Loss: 7.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17309, Training Loss: 6.233e-01, Validation Loss: 7.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17310, Training Loss: 6.232e-01, Validation Loss: 7.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17311, Training Loss: 6.232e-01, Validation Loss: 7.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17312, Training Loss: 6.232e-01, Validation Loss: 7.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17313, Training Loss: 6.231e-01, Validation Loss: 7.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17314, Training Loss: 6.231e-01, Validation Loss: 7.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17315, Training Loss: 6.230e-01, Validation Loss: 7.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17316, Training Loss: 6.230e-01, Validation Loss: 7.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17317, Training Loss: 6.230e-01, Validation Loss: 7.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17318, Training Loss: 6.229e-01, Validation Loss: 7.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17319, Training Loss: 6.229e-01, Validation Loss: 7.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17320, Training Loss: 6.229e-01, Validation Loss: 7.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17321, Training Loss: 6.228e-01, Validation Loss: 7.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17322, Training Loss: 6.228e-01, Validation Loss: 7.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17323, Training Loss: 6.228e-01, Validation Loss: 7.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17324, Training Loss: 6.227e-01, Validation Loss: 7.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17325, Training Loss: 6.227e-01, Validation Loss: 7.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17326, Training Loss: 6.226e-01, Validation Loss: 7.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17327, Training Loss: 6.226e-01, Validation Loss: 7.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17328, Training Loss: 6.226e-01, Validation Loss: 7.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17329, Training Loss: 6.225e-01, Validation Loss: 7.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17330, Training Loss: 6.225e-01, Validation Loss: 7.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17331, Training Loss: 6.225e-01, Validation Loss: 7.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17332, Training Loss: 6.224e-01, Validation Loss: 7.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17333, Training Loss: 6.224e-01, Validation Loss: 7.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17334, Training Loss: 6.224e-01, Validation Loss: 7.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17335, Training Loss: 6.223e-01, Validation Loss: 7.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17336, Training Loss: 6.223e-01, Validation Loss: 7.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17337, Training Loss: 6.222e-01, Validation Loss: 7.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17338, Training Loss: 6.222e-01, Validation Loss: 7.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17339, Training Loss: 6.222e-01, Validation Loss: 7.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17340, Training Loss: 6.221e-01, Validation Loss: 7.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17341, Training Loss: 6.221e-01, Validation Loss: 7.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17342, Training Loss: 6.221e-01, Validation Loss: 7.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17343, Training Loss: 6.220e-01, Validation Loss: 7.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17344, Training Loss: 6.220e-01, Validation Loss: 7.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17345, Training Loss: 6.220e-01, Validation Loss: 7.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17346, Training Loss: 6.219e-01, Validation Loss: 7.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17347, Training Loss: 6.219e-01, Validation Loss: 7.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17348, Training Loss: 6.218e-01, Validation Loss: 7.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17349, Training Loss: 6.218e-01, Validation Loss: 7.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17350, Training Loss: 6.218e-01, Validation Loss: 7.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17351, Training Loss: 6.217e-01, Validation Loss: 7.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17352, Training Loss: 6.217e-01, Validation Loss: 7.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17353, Training Loss: 6.217e-01, Validation Loss: 7.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17354, Training Loss: 6.216e-01, Validation Loss: 7.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17355, Training Loss: 6.216e-01, Validation Loss: 7.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17356, Training Loss: 6.216e-01, Validation Loss: 7.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17357, Training Loss: 6.215e-01, Validation Loss: 7.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17358, Training Loss: 6.215e-01, Validation Loss: 7.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17359, Training Loss: 6.214e-01, Validation Loss: 7.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17360, Training Loss: 6.214e-01, Validation Loss: 7.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17361, Training Loss: 6.214e-01, Validation Loss: 7.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17362, Training Loss: 6.213e-01, Validation Loss: 7.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17363, Training Loss: 6.213e-01, Validation Loss: 7.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17364, Training Loss: 6.213e-01, Validation Loss: 7.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17365, Training Loss: 6.212e-01, Validation Loss: 7.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17366, Training Loss: 6.212e-01, Validation Loss: 7.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17367, Training Loss: 6.212e-01, Validation Loss: 7.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17368, Training Loss: 6.211e-01, Validation Loss: 7.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17369, Training Loss: 6.211e-01, Validation Loss: 7.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17370, Training Loss: 6.210e-01, Validation Loss: 7.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17371, Training Loss: 6.210e-01, Validation Loss: 7.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17372, Training Loss: 6.210e-01, Validation Loss: 7.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17373, Training Loss: 6.209e-01, Validation Loss: 7.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17374, Training Loss: 6.209e-01, Validation Loss: 7.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17375, Training Loss: 6.209e-01, Validation Loss: 7.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17376, Training Loss: 6.208e-01, Validation Loss: 7.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17377, Training Loss: 6.208e-01, Validation Loss: 7.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17378, Training Loss: 6.208e-01, Validation Loss: 7.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17379, Training Loss: 6.207e-01, Validation Loss: 7.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17380, Training Loss: 6.207e-01, Validation Loss: 7.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17381, Training Loss: 6.207e-01, Validation Loss: 7.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17382, Training Loss: 6.206e-01, Validation Loss: 7.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17383, Training Loss: 6.206e-01, Validation Loss: 7.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17384, Training Loss: 6.205e-01, Validation Loss: 7.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17385, Training Loss: 6.205e-01, Validation Loss: 7.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17386, Training Loss: 6.205e-01, Validation Loss: 7.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17387, Training Loss: 6.204e-01, Validation Loss: 7.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17388, Training Loss: 6.204e-01, Validation Loss: 7.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17389, Training Loss: 6.204e-01, Validation Loss: 7.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17390, Training Loss: 6.203e-01, Validation Loss: 7.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17391, Training Loss: 6.203e-01, Validation Loss: 7.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17392, Training Loss: 6.203e-01, Validation Loss: 7.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17393, Training Loss: 6.202e-01, Validation Loss: 7.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17394, Training Loss: 6.202e-01, Validation Loss: 7.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17395, Training Loss: 6.201e-01, Validation Loss: 7.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17396, Training Loss: 6.201e-01, Validation Loss: 7.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17397, Training Loss: 6.201e-01, Validation Loss: 7.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17398, Training Loss: 6.200e-01, Validation Loss: 7.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17399, Training Loss: 6.200e-01, Validation Loss: 7.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17400, Training Loss: 6.200e-01, Validation Loss: 7.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17401, Training Loss: 6.199e-01, Validation Loss: 7.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17402, Training Loss: 6.199e-01, Validation Loss: 7.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17403, Training Loss: 6.199e-01, Validation Loss: 7.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17404, Training Loss: 6.198e-01, Validation Loss: 7.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17405, Training Loss: 6.198e-01, Validation Loss: 7.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17406, Training Loss: 6.197e-01, Validation Loss: 7.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17407, Training Loss: 6.197e-01, Validation Loss: 7.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17408, Training Loss: 6.197e-01, Validation Loss: 7.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17409, Training Loss: 6.196e-01, Validation Loss: 7.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17410, Training Loss: 6.196e-01, Validation Loss: 7.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17411, Training Loss: 6.196e-01, Validation Loss: 7.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17412, Training Loss: 6.195e-01, Validation Loss: 7.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17413, Training Loss: 6.195e-01, Validation Loss: 7.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17414, Training Loss: 6.195e-01, Validation Loss: 7.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17415, Training Loss: 6.194e-01, Validation Loss: 7.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17416, Training Loss: 6.194e-01, Validation Loss: 7.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17417, Training Loss: 6.194e-01, Validation Loss: 7.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17418, Training Loss: 6.193e-01, Validation Loss: 7.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17419, Training Loss: 6.193e-01, Validation Loss: 7.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17420, Training Loss: 6.192e-01, Validation Loss: 7.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17421, Training Loss: 6.192e-01, Validation Loss: 7.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17422, Training Loss: 6.192e-01, Validation Loss: 7.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17423, Training Loss: 6.191e-01, Validation Loss: 7.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17424, Training Loss: 6.191e-01, Validation Loss: 7.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17425, Training Loss: 6.191e-01, Validation Loss: 7.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17426, Training Loss: 6.190e-01, Validation Loss: 7.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17427, Training Loss: 6.190e-01, Validation Loss: 7.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17428, Training Loss: 6.190e-01, Validation Loss: 7.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17429, Training Loss: 6.189e-01, Validation Loss: 7.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17430, Training Loss: 6.189e-01, Validation Loss: 7.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17431, Training Loss: 6.188e-01, Validation Loss: 7.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17432, Training Loss: 6.188e-01, Validation Loss: 7.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17433, Training Loss: 6.188e-01, Validation Loss: 7.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17434, Training Loss: 6.187e-01, Validation Loss: 7.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17435, Training Loss: 6.187e-01, Validation Loss: 7.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17436, Training Loss: 6.187e-01, Validation Loss: 7.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17437, Training Loss: 6.186e-01, Validation Loss: 7.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17438, Training Loss: 6.186e-01, Validation Loss: 7.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17439, Training Loss: 6.186e-01, Validation Loss: 7.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17440, Training Loss: 6.185e-01, Validation Loss: 7.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17441, Training Loss: 6.185e-01, Validation Loss: 7.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17442, Training Loss: 6.185e-01, Validation Loss: 7.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17443, Training Loss: 6.184e-01, Validation Loss: 7.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17444, Training Loss: 6.184e-01, Validation Loss: 7.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17445, Training Loss: 6.183e-01, Validation Loss: 7.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17446, Training Loss: 6.183e-01, Validation Loss: 7.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17447, Training Loss: 6.183e-01, Validation Loss: 7.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17448, Training Loss: 6.182e-01, Validation Loss: 7.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17449, Training Loss: 6.182e-01, Validation Loss: 7.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17450, Training Loss: 6.182e-01, Validation Loss: 7.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17451, Training Loss: 6.181e-01, Validation Loss: 7.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17452, Training Loss: 6.181e-01, Validation Loss: 7.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17453, Training Loss: 6.181e-01, Validation Loss: 7.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17454, Training Loss: 6.180e-01, Validation Loss: 7.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17455, Training Loss: 6.180e-01, Validation Loss: 7.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17456, Training Loss: 6.180e-01, Validation Loss: 7.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17457, Training Loss: 6.179e-01, Validation Loss: 7.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17458, Training Loss: 6.179e-01, Validation Loss: 7.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17459, Training Loss: 6.178e-01, Validation Loss: 7.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17460, Training Loss: 6.178e-01, Validation Loss: 7.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17461, Training Loss: 6.178e-01, Validation Loss: 7.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17462, Training Loss: 6.177e-01, Validation Loss: 7.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17463, Training Loss: 6.177e-01, Validation Loss: 7.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17464, Training Loss: 6.177e-01, Validation Loss: 7.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17465, Training Loss: 6.176e-01, Validation Loss: 7.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17466, Training Loss: 6.176e-01, Validation Loss: 7.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17467, Training Loss: 6.176e-01, Validation Loss: 7.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17468, Training Loss: 6.175e-01, Validation Loss: 7.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17469, Training Loss: 6.175e-01, Validation Loss: 7.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17470, Training Loss: 6.174e-01, Validation Loss: 7.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17471, Training Loss: 6.174e-01, Validation Loss: 7.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17472, Training Loss: 6.174e-01, Validation Loss: 7.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17473, Training Loss: 6.173e-01, Validation Loss: 7.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17474, Training Loss: 6.173e-01, Validation Loss: 7.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17475, Training Loss: 6.173e-01, Validation Loss: 7.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17476, Training Loss: 6.172e-01, Validation Loss: 7.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17477, Training Loss: 6.172e-01, Validation Loss: 7.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17478, Training Loss: 6.172e-01, Validation Loss: 7.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17479, Training Loss: 6.171e-01, Validation Loss: 7.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17480, Training Loss: 6.171e-01, Validation Loss: 7.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17481, Training Loss: 6.171e-01, Validation Loss: 7.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17482, Training Loss: 6.170e-01, Validation Loss: 7.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17483, Training Loss: 6.170e-01, Validation Loss: 7.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17484, Training Loss: 6.169e-01, Validation Loss: 7.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17485, Training Loss: 6.169e-01, Validation Loss: 7.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17486, Training Loss: 6.169e-01, Validation Loss: 7.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17487, Training Loss: 6.168e-01, Validation Loss: 7.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17488, Training Loss: 6.168e-01, Validation Loss: 7.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17489, Training Loss: 6.168e-01, Validation Loss: 7.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17490, Training Loss: 6.167e-01, Validation Loss: 7.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17491, Training Loss: 6.167e-01, Validation Loss: 7.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17492, Training Loss: 6.167e-01, Validation Loss: 7.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17493, Training Loss: 6.166e-01, Validation Loss: 7.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17494, Training Loss: 6.166e-01, Validation Loss: 7.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17495, Training Loss: 6.166e-01, Validation Loss: 7.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17496, Training Loss: 6.165e-01, Validation Loss: 7.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17497, Training Loss: 6.165e-01, Validation Loss: 7.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17498, Training Loss: 6.164e-01, Validation Loss: 7.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17499, Training Loss: 6.164e-01, Validation Loss: 7.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17500, Training Loss: 6.164e-01, Validation Loss: 7.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17501, Training Loss: 6.163e-01, Validation Loss: 7.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17502, Training Loss: 6.163e-01, Validation Loss: 7.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17503, Training Loss: 6.163e-01, Validation Loss: 7.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17504, Training Loss: 6.162e-01, Validation Loss: 7.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17505, Training Loss: 6.162e-01, Validation Loss: 7.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17506, Training Loss: 6.162e-01, Validation Loss: 7.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17507, Training Loss: 6.161e-01, Validation Loss: 7.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17508, Training Loss: 6.161e-01, Validation Loss: 7.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17509, Training Loss: 6.161e-01, Validation Loss: 7.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17510, Training Loss: 6.160e-01, Validation Loss: 7.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17511, Training Loss: 6.160e-01, Validation Loss: 7.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17512, Training Loss: 6.159e-01, Validation Loss: 7.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17513, Training Loss: 6.159e-01, Validation Loss: 7.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17514, Training Loss: 6.159e-01, Validation Loss: 7.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17515, Training Loss: 6.158e-01, Validation Loss: 7.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17516, Training Loss: 6.158e-01, Validation Loss: 7.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17517, Training Loss: 6.158e-01, Validation Loss: 7.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17518, Training Loss: 6.157e-01, Validation Loss: 7.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17519, Training Loss: 6.157e-01, Validation Loss: 7.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17520, Training Loss: 6.157e-01, Validation Loss: 7.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17521, Training Loss: 6.156e-01, Validation Loss: 7.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17522, Training Loss: 6.156e-01, Validation Loss: 7.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17523, Training Loss: 6.156e-01, Validation Loss: 7.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17524, Training Loss: 6.155e-01, Validation Loss: 7.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17525, Training Loss: 6.155e-01, Validation Loss: 7.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17526, Training Loss: 6.154e-01, Validation Loss: 7.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17527, Training Loss: 6.154e-01, Validation Loss: 7.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17528, Training Loss: 6.154e-01, Validation Loss: 7.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17529, Training Loss: 6.153e-01, Validation Loss: 7.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17530, Training Loss: 6.153e-01, Validation Loss: 7.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17531, Training Loss: 6.153e-01, Validation Loss: 7.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17532, Training Loss: 6.152e-01, Validation Loss: 7.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17533, Training Loss: 6.152e-01, Validation Loss: 7.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17534, Training Loss: 6.152e-01, Validation Loss: 7.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17535, Training Loss: 6.151e-01, Validation Loss: 7.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17536, Training Loss: 6.151e-01, Validation Loss: 7.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17537, Training Loss: 6.151e-01, Validation Loss: 7.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17538, Training Loss: 6.150e-01, Validation Loss: 7.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17539, Training Loss: 6.150e-01, Validation Loss: 7.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17540, Training Loss: 6.150e-01, Validation Loss: 7.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17541, Training Loss: 6.149e-01, Validation Loss: 7.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17542, Training Loss: 6.149e-01, Validation Loss: 7.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17543, Training Loss: 6.148e-01, Validation Loss: 7.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17544, Training Loss: 6.148e-01, Validation Loss: 7.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17545, Training Loss: 6.148e-01, Validation Loss: 7.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17546, Training Loss: 6.147e-01, Validation Loss: 7.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17547, Training Loss: 6.147e-01, Validation Loss: 7.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17548, Training Loss: 6.147e-01, Validation Loss: 7.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17549, Training Loss: 6.146e-01, Validation Loss: 7.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17550, Training Loss: 6.146e-01, Validation Loss: 7.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17551, Training Loss: 6.146e-01, Validation Loss: 7.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17552, Training Loss: 6.145e-01, Validation Loss: 7.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17553, Training Loss: 6.145e-01, Validation Loss: 7.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17554, Training Loss: 6.145e-01, Validation Loss: 7.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17555, Training Loss: 6.144e-01, Validation Loss: 7.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17556, Training Loss: 6.144e-01, Validation Loss: 7.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17557, Training Loss: 6.143e-01, Validation Loss: 7.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17558, Training Loss: 6.143e-01, Validation Loss: 7.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17559, Training Loss: 6.143e-01, Validation Loss: 7.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17560, Training Loss: 6.142e-01, Validation Loss: 7.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17561, Training Loss: 6.142e-01, Validation Loss: 7.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17562, Training Loss: 6.142e-01, Validation Loss: 7.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17563, Training Loss: 6.141e-01, Validation Loss: 7.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17564, Training Loss: 6.141e-01, Validation Loss: 7.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17565, Training Loss: 6.141e-01, Validation Loss: 7.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17566, Training Loss: 6.140e-01, Validation Loss: 7.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17567, Training Loss: 6.140e-01, Validation Loss: 7.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17568, Training Loss: 6.140e-01, Validation Loss: 7.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17569, Training Loss: 6.139e-01, Validation Loss: 7.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17570, Training Loss: 6.139e-01, Validation Loss: 7.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17571, Training Loss: 6.139e-01, Validation Loss: 7.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17572, Training Loss: 6.138e-01, Validation Loss: 7.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17573, Training Loss: 6.138e-01, Validation Loss: 7.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17574, Training Loss: 6.137e-01, Validation Loss: 7.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17575, Training Loss: 6.137e-01, Validation Loss: 7.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17576, Training Loss: 6.137e-01, Validation Loss: 7.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17577, Training Loss: 6.136e-01, Validation Loss: 7.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17578, Training Loss: 6.136e-01, Validation Loss: 7.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17579, Training Loss: 6.136e-01, Validation Loss: 7.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17580, Training Loss: 6.135e-01, Validation Loss: 7.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17581, Training Loss: 6.135e-01, Validation Loss: 7.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17582, Training Loss: 6.135e-01, Validation Loss: 7.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17583, Training Loss: 6.134e-01, Validation Loss: 7.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17584, Training Loss: 6.134e-01, Validation Loss: 7.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17585, Training Loss: 6.134e-01, Validation Loss: 7.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17586, Training Loss: 6.133e-01, Validation Loss: 7.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17587, Training Loss: 6.133e-01, Validation Loss: 7.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17588, Training Loss: 6.132e-01, Validation Loss: 7.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17589, Training Loss: 6.132e-01, Validation Loss: 7.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17590, Training Loss: 6.132e-01, Validation Loss: 7.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17591, Training Loss: 6.131e-01, Validation Loss: 7.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17592, Training Loss: 6.131e-01, Validation Loss: 7.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17593, Training Loss: 6.131e-01, Validation Loss: 7.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17594, Training Loss: 6.130e-01, Validation Loss: 7.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17595, Training Loss: 6.130e-01, Validation Loss: 7.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17596, Training Loss: 6.130e-01, Validation Loss: 7.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17597, Training Loss: 6.129e-01, Validation Loss: 7.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17598, Training Loss: 6.129e-01, Validation Loss: 7.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17599, Training Loss: 6.129e-01, Validation Loss: 7.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17600, Training Loss: 6.128e-01, Validation Loss: 7.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17601, Training Loss: 6.128e-01, Validation Loss: 7.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17602, Training Loss: 6.128e-01, Validation Loss: 7.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17603, Training Loss: 6.127e-01, Validation Loss: 7.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17604, Training Loss: 6.127e-01, Validation Loss: 7.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17605, Training Loss: 6.126e-01, Validation Loss: 7.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17606, Training Loss: 6.126e-01, Validation Loss: 7.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17607, Training Loss: 6.126e-01, Validation Loss: 7.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17608, Training Loss: 6.125e-01, Validation Loss: 7.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17609, Training Loss: 6.125e-01, Validation Loss: 7.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17610, Training Loss: 6.125e-01, Validation Loss: 7.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17611, Training Loss: 6.124e-01, Validation Loss: 7.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17612, Training Loss: 6.124e-01, Validation Loss: 7.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17613, Training Loss: 6.124e-01, Validation Loss: 7.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17614, Training Loss: 6.123e-01, Validation Loss: 7.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17615, Training Loss: 6.123e-01, Validation Loss: 7.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17616, Training Loss: 6.123e-01, Validation Loss: 7.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17617, Training Loss: 6.122e-01, Validation Loss: 7.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17618, Training Loss: 6.122e-01, Validation Loss: 7.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17619, Training Loss: 6.122e-01, Validation Loss: 7.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17620, Training Loss: 6.121e-01, Validation Loss: 7.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17621, Training Loss: 6.121e-01, Validation Loss: 7.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17622, Training Loss: 6.120e-01, Validation Loss: 7.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17623, Training Loss: 6.120e-01, Validation Loss: 7.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17624, Training Loss: 6.120e-01, Validation Loss: 7.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17625, Training Loss: 6.119e-01, Validation Loss: 7.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17626, Training Loss: 6.119e-01, Validation Loss: 7.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17627, Training Loss: 6.119e-01, Validation Loss: 7.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17628, Training Loss: 6.118e-01, Validation Loss: 7.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17629, Training Loss: 6.118e-01, Validation Loss: 7.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17630, Training Loss: 6.118e-01, Validation Loss: 7.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17631, Training Loss: 6.117e-01, Validation Loss: 7.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17632, Training Loss: 6.117e-01, Validation Loss: 7.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17633, Training Loss: 6.117e-01, Validation Loss: 7.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17634, Training Loss: 6.116e-01, Validation Loss: 7.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17635, Training Loss: 6.116e-01, Validation Loss: 7.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17636, Training Loss: 6.116e-01, Validation Loss: 7.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17637, Training Loss: 6.115e-01, Validation Loss: 7.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17638, Training Loss: 6.115e-01, Validation Loss: 7.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17639, Training Loss: 6.115e-01, Validation Loss: 7.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17640, Training Loss: 6.114e-01, Validation Loss: 7.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17641, Training Loss: 6.114e-01, Validation Loss: 7.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17642, Training Loss: 6.113e-01, Validation Loss: 7.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17643, Training Loss: 6.113e-01, Validation Loss: 7.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17644, Training Loss: 6.113e-01, Validation Loss: 7.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17645, Training Loss: 6.112e-01, Validation Loss: 7.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17646, Training Loss: 6.112e-01, Validation Loss: 7.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17647, Training Loss: 6.112e-01, Validation Loss: 7.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17648, Training Loss: 6.111e-01, Validation Loss: 7.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17649, Training Loss: 6.111e-01, Validation Loss: 7.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17650, Training Loss: 6.111e-01, Validation Loss: 7.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17651, Training Loss: 6.110e-01, Validation Loss: 7.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17652, Training Loss: 6.110e-01, Validation Loss: 7.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17653, Training Loss: 6.110e-01, Validation Loss: 7.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17654, Training Loss: 6.109e-01, Validation Loss: 7.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17655, Training Loss: 6.109e-01, Validation Loss: 7.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17656, Training Loss: 6.109e-01, Validation Loss: 7.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17657, Training Loss: 6.108e-01, Validation Loss: 7.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17658, Training Loss: 6.108e-01, Validation Loss: 7.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17659, Training Loss: 6.107e-01, Validation Loss: 7.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17660, Training Loss: 6.107e-01, Validation Loss: 7.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17661, Training Loss: 6.107e-01, Validation Loss: 7.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17662, Training Loss: 6.106e-01, Validation Loss: 7.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17663, Training Loss: 6.106e-01, Validation Loss: 7.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17664, Training Loss: 6.106e-01, Validation Loss: 7.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17665, Training Loss: 6.105e-01, Validation Loss: 7.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17666, Training Loss: 6.105e-01, Validation Loss: 7.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17667, Training Loss: 6.105e-01, Validation Loss: 7.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17668, Training Loss: 6.104e-01, Validation Loss: 7.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17669, Training Loss: 6.104e-01, Validation Loss: 7.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17670, Training Loss: 6.104e-01, Validation Loss: 7.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17671, Training Loss: 6.103e-01, Validation Loss: 7.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17672, Training Loss: 6.103e-01, Validation Loss: 7.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17673, Training Loss: 6.103e-01, Validation Loss: 7.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17674, Training Loss: 6.102e-01, Validation Loss: 7.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17675, Training Loss: 6.102e-01, Validation Loss: 7.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17676, Training Loss: 6.102e-01, Validation Loss: 7.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17677, Training Loss: 6.101e-01, Validation Loss: 7.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17678, Training Loss: 6.101e-01, Validation Loss: 7.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17679, Training Loss: 6.100e-01, Validation Loss: 7.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17680, Training Loss: 6.100e-01, Validation Loss: 7.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17681, Training Loss: 6.100e-01, Validation Loss: 7.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17682, Training Loss: 6.099e-01, Validation Loss: 7.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17683, Training Loss: 6.099e-01, Validation Loss: 7.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17684, Training Loss: 6.099e-01, Validation Loss: 7.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17685, Training Loss: 6.098e-01, Validation Loss: 7.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17686, Training Loss: 6.098e-01, Validation Loss: 7.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17687, Training Loss: 6.098e-01, Validation Loss: 7.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17688, Training Loss: 6.097e-01, Validation Loss: 7.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17689, Training Loss: 6.097e-01, Validation Loss: 7.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17690, Training Loss: 6.097e-01, Validation Loss: 7.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17691, Training Loss: 6.096e-01, Validation Loss: 7.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17692, Training Loss: 6.096e-01, Validation Loss: 7.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17693, Training Loss: 6.096e-01, Validation Loss: 7.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17694, Training Loss: 6.095e-01, Validation Loss: 7.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17695, Training Loss: 6.095e-01, Validation Loss: 7.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17696, Training Loss: 6.095e-01, Validation Loss: 7.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17697, Training Loss: 6.094e-01, Validation Loss: 7.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17698, Training Loss: 6.094e-01, Validation Loss: 7.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17699, Training Loss: 6.093e-01, Validation Loss: 7.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17700, Training Loss: 6.093e-01, Validation Loss: 7.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17701, Training Loss: 6.093e-01, Validation Loss: 7.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17702, Training Loss: 6.092e-01, Validation Loss: 7.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17703, Training Loss: 6.092e-01, Validation Loss: 7.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17704, Training Loss: 6.092e-01, Validation Loss: 7.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17705, Training Loss: 6.091e-01, Validation Loss: 7.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17706, Training Loss: 6.091e-01, Validation Loss: 7.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17707, Training Loss: 6.091e-01, Validation Loss: 7.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17708, Training Loss: 6.090e-01, Validation Loss: 7.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17709, Training Loss: 6.090e-01, Validation Loss: 7.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17710, Training Loss: 6.090e-01, Validation Loss: 7.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17711, Training Loss: 6.089e-01, Validation Loss: 7.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17712, Training Loss: 6.089e-01, Validation Loss: 7.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17713, Training Loss: 6.089e-01, Validation Loss: 7.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17714, Training Loss: 6.088e-01, Validation Loss: 7.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17715, Training Loss: 6.088e-01, Validation Loss: 7.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17716, Training Loss: 6.088e-01, Validation Loss: 7.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17717, Training Loss: 6.087e-01, Validation Loss: 7.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17718, Training Loss: 6.087e-01, Validation Loss: 7.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17719, Training Loss: 6.086e-01, Validation Loss: 7.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17720, Training Loss: 6.086e-01, Validation Loss: 7.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17721, Training Loss: 6.086e-01, Validation Loss: 7.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17722, Training Loss: 6.085e-01, Validation Loss: 7.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17723, Training Loss: 6.085e-01, Validation Loss: 7.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17724, Training Loss: 6.085e-01, Validation Loss: 7.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17725, Training Loss: 6.084e-01, Validation Loss: 7.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17726, Training Loss: 6.084e-01, Validation Loss: 7.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17727, Training Loss: 6.084e-01, Validation Loss: 7.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17728, Training Loss: 6.083e-01, Validation Loss: 7.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17729, Training Loss: 6.083e-01, Validation Loss: 7.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17730, Training Loss: 6.083e-01, Validation Loss: 7.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17731, Training Loss: 6.082e-01, Validation Loss: 7.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17732, Training Loss: 6.082e-01, Validation Loss: 7.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17733, Training Loss: 6.082e-01, Validation Loss: 7.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17734, Training Loss: 6.081e-01, Validation Loss: 7.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17735, Training Loss: 6.081e-01, Validation Loss: 7.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17736, Training Loss: 6.081e-01, Validation Loss: 7.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17737, Training Loss: 6.080e-01, Validation Loss: 7.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17738, Training Loss: 6.080e-01, Validation Loss: 7.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17739, Training Loss: 6.080e-01, Validation Loss: 7.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17740, Training Loss: 6.079e-01, Validation Loss: 7.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17741, Training Loss: 6.079e-01, Validation Loss: 7.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17742, Training Loss: 6.078e-01, Validation Loss: 7.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17743, Training Loss: 6.078e-01, Validation Loss: 7.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17744, Training Loss: 6.078e-01, Validation Loss: 7.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17745, Training Loss: 6.077e-01, Validation Loss: 7.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17746, Training Loss: 6.077e-01, Validation Loss: 7.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17747, Training Loss: 6.077e-01, Validation Loss: 7.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17748, Training Loss: 6.076e-01, Validation Loss: 7.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17749, Training Loss: 6.076e-01, Validation Loss: 7.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17750, Training Loss: 6.076e-01, Validation Loss: 7.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17751, Training Loss: 6.075e-01, Validation Loss: 7.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17752, Training Loss: 6.075e-01, Validation Loss: 7.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17753, Training Loss: 6.075e-01, Validation Loss: 7.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17754, Training Loss: 6.074e-01, Validation Loss: 7.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17755, Training Loss: 6.074e-01, Validation Loss: 7.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17756, Training Loss: 6.074e-01, Validation Loss: 7.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17757, Training Loss: 6.073e-01, Validation Loss: 7.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17758, Training Loss: 6.073e-01, Validation Loss: 7.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17759, Training Loss: 6.073e-01, Validation Loss: 7.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17760, Training Loss: 6.072e-01, Validation Loss: 7.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17761, Training Loss: 6.072e-01, Validation Loss: 7.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17762, Training Loss: 6.072e-01, Validation Loss: 7.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17763, Training Loss: 6.071e-01, Validation Loss: 7.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17764, Training Loss: 6.071e-01, Validation Loss: 7.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17765, Training Loss: 6.070e-01, Validation Loss: 7.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17766, Training Loss: 6.070e-01, Validation Loss: 7.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17767, Training Loss: 6.070e-01, Validation Loss: 7.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17768, Training Loss: 6.069e-01, Validation Loss: 7.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17769, Training Loss: 6.069e-01, Validation Loss: 7.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17770, Training Loss: 6.069e-01, Validation Loss: 7.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17771, Training Loss: 6.068e-01, Validation Loss: 7.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17772, Training Loss: 6.068e-01, Validation Loss: 7.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17773, Training Loss: 6.068e-01, Validation Loss: 7.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17774, Training Loss: 6.067e-01, Validation Loss: 7.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17775, Training Loss: 6.067e-01, Validation Loss: 7.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17776, Training Loss: 6.067e-01, Validation Loss: 7.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17777, Training Loss: 6.066e-01, Validation Loss: 7.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17778, Training Loss: 6.066e-01, Validation Loss: 7.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17779, Training Loss: 6.066e-01, Validation Loss: 7.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17780, Training Loss: 6.065e-01, Validation Loss: 7.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17781, Training Loss: 6.065e-01, Validation Loss: 7.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17782, Training Loss: 6.065e-01, Validation Loss: 7.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17783, Training Loss: 6.064e-01, Validation Loss: 7.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17784, Training Loss: 6.064e-01, Validation Loss: 7.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17785, Training Loss: 6.064e-01, Validation Loss: 7.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17786, Training Loss: 6.063e-01, Validation Loss: 7.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17787, Training Loss: 6.063e-01, Validation Loss: 7.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17788, Training Loss: 6.062e-01, Validation Loss: 7.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17789, Training Loss: 6.062e-01, Validation Loss: 7.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17790, Training Loss: 6.062e-01, Validation Loss: 7.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17791, Training Loss: 6.061e-01, Validation Loss: 7.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17792, Training Loss: 6.061e-01, Validation Loss: 7.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17793, Training Loss: 6.061e-01, Validation Loss: 7.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17794, Training Loss: 6.060e-01, Validation Loss: 7.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17795, Training Loss: 6.060e-01, Validation Loss: 7.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17796, Training Loss: 6.060e-01, Validation Loss: 7.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17797, Training Loss: 6.059e-01, Validation Loss: 7.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17798, Training Loss: 6.059e-01, Validation Loss: 7.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17799, Training Loss: 6.059e-01, Validation Loss: 7.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17800, Training Loss: 6.058e-01, Validation Loss: 7.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17801, Training Loss: 6.058e-01, Validation Loss: 7.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17802, Training Loss: 6.058e-01, Validation Loss: 7.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17803, Training Loss: 6.057e-01, Validation Loss: 7.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17804, Training Loss: 6.057e-01, Validation Loss: 7.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17805, Training Loss: 6.057e-01, Validation Loss: 7.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17806, Training Loss: 6.056e-01, Validation Loss: 7.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17807, Training Loss: 6.056e-01, Validation Loss: 7.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17808, Training Loss: 6.056e-01, Validation Loss: 7.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17809, Training Loss: 6.055e-01, Validation Loss: 7.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17810, Training Loss: 6.055e-01, Validation Loss: 7.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17811, Training Loss: 6.055e-01, Validation Loss: 7.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17812, Training Loss: 6.054e-01, Validation Loss: 7.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17813, Training Loss: 6.054e-01, Validation Loss: 7.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17814, Training Loss: 6.053e-01, Validation Loss: 7.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17815, Training Loss: 6.053e-01, Validation Loss: 7.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17816, Training Loss: 6.053e-01, Validation Loss: 7.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17817, Training Loss: 6.052e-01, Validation Loss: 7.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17818, Training Loss: 6.052e-01, Validation Loss: 7.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17819, Training Loss: 6.052e-01, Validation Loss: 7.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17820, Training Loss: 6.051e-01, Validation Loss: 7.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17821, Training Loss: 6.051e-01, Validation Loss: 7.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17822, Training Loss: 6.051e-01, Validation Loss: 7.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17823, Training Loss: 6.050e-01, Validation Loss: 7.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17824, Training Loss: 6.050e-01, Validation Loss: 7.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17825, Training Loss: 6.050e-01, Validation Loss: 7.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17826, Training Loss: 6.049e-01, Validation Loss: 7.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17827, Training Loss: 6.049e-01, Validation Loss: 7.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17828, Training Loss: 6.049e-01, Validation Loss: 7.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17829, Training Loss: 6.048e-01, Validation Loss: 7.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17830, Training Loss: 6.048e-01, Validation Loss: 7.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17831, Training Loss: 6.048e-01, Validation Loss: 7.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17832, Training Loss: 6.047e-01, Validation Loss: 7.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17833, Training Loss: 6.047e-01, Validation Loss: 7.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17834, Training Loss: 6.047e-01, Validation Loss: 7.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17835, Training Loss: 6.046e-01, Validation Loss: 7.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17836, Training Loss: 6.046e-01, Validation Loss: 7.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17837, Training Loss: 6.046e-01, Validation Loss: 7.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17838, Training Loss: 6.045e-01, Validation Loss: 7.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17839, Training Loss: 6.045e-01, Validation Loss: 7.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17840, Training Loss: 6.045e-01, Validation Loss: 7.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17841, Training Loss: 6.044e-01, Validation Loss: 7.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17842, Training Loss: 6.044e-01, Validation Loss: 7.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17843, Training Loss: 6.043e-01, Validation Loss: 7.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17844, Training Loss: 6.043e-01, Validation Loss: 7.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17845, Training Loss: 6.043e-01, Validation Loss: 7.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17846, Training Loss: 6.042e-01, Validation Loss: 7.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17847, Training Loss: 6.042e-01, Validation Loss: 7.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17848, Training Loss: 6.042e-01, Validation Loss: 7.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17849, Training Loss: 6.041e-01, Validation Loss: 7.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17850, Training Loss: 6.041e-01, Validation Loss: 7.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17851, Training Loss: 6.041e-01, Validation Loss: 7.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17852, Training Loss: 6.040e-01, Validation Loss: 7.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17853, Training Loss: 6.040e-01, Validation Loss: 7.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17854, Training Loss: 6.040e-01, Validation Loss: 7.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17855, Training Loss: 6.039e-01, Validation Loss: 7.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17856, Training Loss: 6.039e-01, Validation Loss: 7.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17857, Training Loss: 6.039e-01, Validation Loss: 7.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17858, Training Loss: 6.038e-01, Validation Loss: 7.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17859, Training Loss: 6.038e-01, Validation Loss: 7.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17860, Training Loss: 6.038e-01, Validation Loss: 7.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17861, Training Loss: 6.037e-01, Validation Loss: 7.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17862, Training Loss: 6.037e-01, Validation Loss: 7.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17863, Training Loss: 6.037e-01, Validation Loss: 7.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17864, Training Loss: 6.036e-01, Validation Loss: 7.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17865, Training Loss: 6.036e-01, Validation Loss: 7.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17866, Training Loss: 6.036e-01, Validation Loss: 7.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17867, Training Loss: 6.035e-01, Validation Loss: 7.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17868, Training Loss: 6.035e-01, Validation Loss: 7.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17869, Training Loss: 6.035e-01, Validation Loss: 7.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17870, Training Loss: 6.034e-01, Validation Loss: 7.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17871, Training Loss: 6.034e-01, Validation Loss: 7.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17872, Training Loss: 6.033e-01, Validation Loss: 7.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17873, Training Loss: 6.033e-01, Validation Loss: 7.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17874, Training Loss: 6.033e-01, Validation Loss: 7.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17875, Training Loss: 6.032e-01, Validation Loss: 7.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17876, Training Loss: 6.032e-01, Validation Loss: 7.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17877, Training Loss: 6.032e-01, Validation Loss: 7.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17878, Training Loss: 6.031e-01, Validation Loss: 7.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17879, Training Loss: 6.031e-01, Validation Loss: 7.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17880, Training Loss: 6.031e-01, Validation Loss: 7.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17881, Training Loss: 6.030e-01, Validation Loss: 7.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17882, Training Loss: 6.030e-01, Validation Loss: 7.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17883, Training Loss: 6.030e-01, Validation Loss: 7.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17884, Training Loss: 6.029e-01, Validation Loss: 7.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17885, Training Loss: 6.029e-01, Validation Loss: 7.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17886, Training Loss: 6.029e-01, Validation Loss: 7.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17887, Training Loss: 6.028e-01, Validation Loss: 7.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17888, Training Loss: 6.028e-01, Validation Loss: 7.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17889, Training Loss: 6.028e-01, Validation Loss: 7.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17890, Training Loss: 6.027e-01, Validation Loss: 7.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17891, Training Loss: 6.027e-01, Validation Loss: 7.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17892, Training Loss: 6.027e-01, Validation Loss: 7.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17893, Training Loss: 6.026e-01, Validation Loss: 7.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17894, Training Loss: 6.026e-01, Validation Loss: 7.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17895, Training Loss: 6.026e-01, Validation Loss: 7.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17896, Training Loss: 6.025e-01, Validation Loss: 7.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17897, Training Loss: 6.025e-01, Validation Loss: 7.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17898, Training Loss: 6.025e-01, Validation Loss: 7.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17899, Training Loss: 6.024e-01, Validation Loss: 7.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17900, Training Loss: 6.024e-01, Validation Loss: 7.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17901, Training Loss: 6.024e-01, Validation Loss: 7.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17902, Training Loss: 6.023e-01, Validation Loss: 7.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17903, Training Loss: 6.023e-01, Validation Loss: 7.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17904, Training Loss: 6.023e-01, Validation Loss: 7.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17905, Training Loss: 6.022e-01, Validation Loss: 7.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17906, Training Loss: 6.022e-01, Validation Loss: 7.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17907, Training Loss: 6.021e-01, Validation Loss: 7.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17908, Training Loss: 6.021e-01, Validation Loss: 7.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17909, Training Loss: 6.021e-01, Validation Loss: 7.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17910, Training Loss: 6.020e-01, Validation Loss: 7.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17911, Training Loss: 6.020e-01, Validation Loss: 7.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17912, Training Loss: 6.020e-01, Validation Loss: 7.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17913, Training Loss: 6.019e-01, Validation Loss: 7.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17914, Training Loss: 6.019e-01, Validation Loss: 7.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17915, Training Loss: 6.019e-01, Validation Loss: 7.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17916, Training Loss: 6.018e-01, Validation Loss: 7.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17917, Training Loss: 6.018e-01, Validation Loss: 7.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17918, Training Loss: 6.018e-01, Validation Loss: 7.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17919, Training Loss: 6.017e-01, Validation Loss: 7.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17920, Training Loss: 6.017e-01, Validation Loss: 7.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17921, Training Loss: 6.017e-01, Validation Loss: 7.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17922, Training Loss: 6.016e-01, Validation Loss: 7.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17923, Training Loss: 6.016e-01, Validation Loss: 7.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17924, Training Loss: 6.016e-01, Validation Loss: 7.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17925, Training Loss: 6.015e-01, Validation Loss: 7.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17926, Training Loss: 6.015e-01, Validation Loss: 7.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17927, Training Loss: 6.015e-01, Validation Loss: 7.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17928, Training Loss: 6.014e-01, Validation Loss: 7.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17929, Training Loss: 6.014e-01, Validation Loss: 7.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17930, Training Loss: 6.014e-01, Validation Loss: 7.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17931, Training Loss: 6.013e-01, Validation Loss: 7.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17932, Training Loss: 6.013e-01, Validation Loss: 7.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17933, Training Loss: 6.013e-01, Validation Loss: 7.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17934, Training Loss: 6.012e-01, Validation Loss: 7.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17935, Training Loss: 6.012e-01, Validation Loss: 7.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17936, Training Loss: 6.012e-01, Validation Loss: 7.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17937, Training Loss: 6.011e-01, Validation Loss: 7.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17938, Training Loss: 6.011e-01, Validation Loss: 7.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17939, Training Loss: 6.011e-01, Validation Loss: 7.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17940, Training Loss: 6.010e-01, Validation Loss: 7.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17941, Training Loss: 6.010e-01, Validation Loss: 7.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17942, Training Loss: 6.010e-01, Validation Loss: 7.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17943, Training Loss: 6.009e-01, Validation Loss: 7.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17944, Training Loss: 6.009e-01, Validation Loss: 7.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17945, Training Loss: 6.008e-01, Validation Loss: 7.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17946, Training Loss: 6.008e-01, Validation Loss: 7.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17947, Training Loss: 6.008e-01, Validation Loss: 7.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17948, Training Loss: 6.007e-01, Validation Loss: 7.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17949, Training Loss: 6.007e-01, Validation Loss: 7.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17950, Training Loss: 6.007e-01, Validation Loss: 7.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17951, Training Loss: 6.006e-01, Validation Loss: 7.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17952, Training Loss: 6.006e-01, Validation Loss: 7.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17953, Training Loss: 6.006e-01, Validation Loss: 7.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17954, Training Loss: 6.005e-01, Validation Loss: 7.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17955, Training Loss: 6.005e-01, Validation Loss: 7.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17956, Training Loss: 6.005e-01, Validation Loss: 7.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17957, Training Loss: 6.004e-01, Validation Loss: 7.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17958, Training Loss: 6.004e-01, Validation Loss: 7.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17959, Training Loss: 6.004e-01, Validation Loss: 7.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17960, Training Loss: 6.003e-01, Validation Loss: 7.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17961, Training Loss: 6.003e-01, Validation Loss: 7.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17962, Training Loss: 6.003e-01, Validation Loss: 7.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17963, Training Loss: 6.002e-01, Validation Loss: 7.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17964, Training Loss: 6.002e-01, Validation Loss: 7.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17965, Training Loss: 6.002e-01, Validation Loss: 7.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17966, Training Loss: 6.001e-01, Validation Loss: 7.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17967, Training Loss: 6.001e-01, Validation Loss: 7.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17968, Training Loss: 6.001e-01, Validation Loss: 7.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17969, Training Loss: 6.000e-01, Validation Loss: 7.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17970, Training Loss: 6.000e-01, Validation Loss: 7.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17971, Training Loss: 6.000e-01, Validation Loss: 7.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17972, Training Loss: 5.999e-01, Validation Loss: 7.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17973, Training Loss: 5.999e-01, Validation Loss: 7.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17974, Training Loss: 5.999e-01, Validation Loss: 7.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17975, Training Loss: 5.998e-01, Validation Loss: 7.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17976, Training Loss: 5.998e-01, Validation Loss: 7.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17977, Training Loss: 5.998e-01, Validation Loss: 7.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17978, Training Loss: 5.997e-01, Validation Loss: 7.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17979, Training Loss: 5.997e-01, Validation Loss: 7.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17980, Training Loss: 5.997e-01, Validation Loss: 7.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17981, Training Loss: 5.996e-01, Validation Loss: 7.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17982, Training Loss: 5.996e-01, Validation Loss: 7.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17983, Training Loss: 5.996e-01, Validation Loss: 7.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17984, Training Loss: 5.995e-01, Validation Loss: 7.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17985, Training Loss: 5.995e-01, Validation Loss: 7.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17986, Training Loss: 5.995e-01, Validation Loss: 7.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17987, Training Loss: 5.994e-01, Validation Loss: 7.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17988, Training Loss: 5.994e-01, Validation Loss: 7.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17989, Training Loss: 5.994e-01, Validation Loss: 7.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17990, Training Loss: 5.993e-01, Validation Loss: 7.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17991, Training Loss: 5.993e-01, Validation Loss: 7.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17992, Training Loss: 5.992e-01, Validation Loss: 7.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17993, Training Loss: 5.992e-01, Validation Loss: 7.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17994, Training Loss: 5.992e-01, Validation Loss: 7.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17995, Training Loss: 5.991e-01, Validation Loss: 7.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17996, Training Loss: 5.991e-01, Validation Loss: 7.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17997, Training Loss: 5.991e-01, Validation Loss: 7.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17998, Training Loss: 5.990e-01, Validation Loss: 7.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17999, Training Loss: 5.990e-01, Validation Loss: 7.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18000, Training Loss: 5.990e-01, Validation Loss: 7.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18001, Training Loss: 5.989e-01, Validation Loss: 7.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18002, Training Loss: 5.989e-01, Validation Loss: 7.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18003, Training Loss: 5.989e-01, Validation Loss: 7.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18004, Training Loss: 5.988e-01, Validation Loss: 7.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18005, Training Loss: 5.988e-01, Validation Loss: 7.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18006, Training Loss: 5.988e-01, Validation Loss: 7.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18007, Training Loss: 5.987e-01, Validation Loss: 7.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18008, Training Loss: 5.987e-01, Validation Loss: 7.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18009, Training Loss: 5.987e-01, Validation Loss: 7.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18010, Training Loss: 5.986e-01, Validation Loss: 7.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18011, Training Loss: 5.986e-01, Validation Loss: 7.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18012, Training Loss: 5.986e-01, Validation Loss: 7.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18013, Training Loss: 5.985e-01, Validation Loss: 7.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18014, Training Loss: 5.985e-01, Validation Loss: 7.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18015, Training Loss: 5.985e-01, Validation Loss: 7.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18016, Training Loss: 5.984e-01, Validation Loss: 7.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18017, Training Loss: 5.984e-01, Validation Loss: 7.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18018, Training Loss: 5.984e-01, Validation Loss: 7.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18019, Training Loss: 5.983e-01, Validation Loss: 7.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18020, Training Loss: 5.983e-01, Validation Loss: 7.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18021, Training Loss: 5.983e-01, Validation Loss: 7.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18022, Training Loss: 5.982e-01, Validation Loss: 7.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18023, Training Loss: 5.982e-01, Validation Loss: 7.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18024, Training Loss: 5.982e-01, Validation Loss: 7.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18025, Training Loss: 5.981e-01, Validation Loss: 7.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18026, Training Loss: 5.981e-01, Validation Loss: 7.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18027, Training Loss: 5.981e-01, Validation Loss: 7.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18028, Training Loss: 5.980e-01, Validation Loss: 7.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18029, Training Loss: 5.980e-01, Validation Loss: 7.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18030, Training Loss: 5.980e-01, Validation Loss: 7.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18031, Training Loss: 5.979e-01, Validation Loss: 7.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18032, Training Loss: 5.979e-01, Validation Loss: 7.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18033, Training Loss: 5.979e-01, Validation Loss: 7.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18034, Training Loss: 5.978e-01, Validation Loss: 7.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18035, Training Loss: 5.978e-01, Validation Loss: 7.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18036, Training Loss: 5.978e-01, Validation Loss: 7.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18037, Training Loss: 5.977e-01, Validation Loss: 7.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18038, Training Loss: 5.977e-01, Validation Loss: 7.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18039, Training Loss: 5.977e-01, Validation Loss: 7.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18040, Training Loss: 5.976e-01, Validation Loss: 7.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18041, Training Loss: 5.976e-01, Validation Loss: 7.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18042, Training Loss: 5.976e-01, Validation Loss: 7.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18043, Training Loss: 5.975e-01, Validation Loss: 7.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18044, Training Loss: 5.975e-01, Validation Loss: 7.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18045, Training Loss: 5.975e-01, Validation Loss: 7.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18046, Training Loss: 5.974e-01, Validation Loss: 7.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18047, Training Loss: 5.974e-01, Validation Loss: 7.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18048, Training Loss: 5.974e-01, Validation Loss: 7.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18049, Training Loss: 5.973e-01, Validation Loss: 7.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18050, Training Loss: 5.973e-01, Validation Loss: 7.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18051, Training Loss: 5.973e-01, Validation Loss: 7.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18052, Training Loss: 5.972e-01, Validation Loss: 7.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18053, Training Loss: 5.972e-01, Validation Loss: 7.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18054, Training Loss: 5.972e-01, Validation Loss: 7.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18055, Training Loss: 5.971e-01, Validation Loss: 7.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18056, Training Loss: 5.971e-01, Validation Loss: 7.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18057, Training Loss: 5.970e-01, Validation Loss: 7.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18058, Training Loss: 5.970e-01, Validation Loss: 7.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18059, Training Loss: 5.970e-01, Validation Loss: 7.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18060, Training Loss: 5.969e-01, Validation Loss: 7.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18061, Training Loss: 5.969e-01, Validation Loss: 7.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18062, Training Loss: 5.969e-01, Validation Loss: 7.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18063, Training Loss: 5.968e-01, Validation Loss: 7.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18064, Training Loss: 5.968e-01, Validation Loss: 7.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18065, Training Loss: 5.968e-01, Validation Loss: 7.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18066, Training Loss: 5.967e-01, Validation Loss: 7.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18067, Training Loss: 5.967e-01, Validation Loss: 7.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18068, Training Loss: 5.967e-01, Validation Loss: 7.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18069, Training Loss: 5.966e-01, Validation Loss: 7.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18070, Training Loss: 5.966e-01, Validation Loss: 7.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18071, Training Loss: 5.966e-01, Validation Loss: 7.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18072, Training Loss: 5.965e-01, Validation Loss: 7.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18073, Training Loss: 5.965e-01, Validation Loss: 7.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18074, Training Loss: 5.965e-01, Validation Loss: 7.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18075, Training Loss: 5.964e-01, Validation Loss: 7.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18076, Training Loss: 5.964e-01, Validation Loss: 7.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18077, Training Loss: 5.964e-01, Validation Loss: 7.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18078, Training Loss: 5.963e-01, Validation Loss: 7.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18079, Training Loss: 5.963e-01, Validation Loss: 7.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18080, Training Loss: 5.963e-01, Validation Loss: 7.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18081, Training Loss: 5.962e-01, Validation Loss: 7.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18082, Training Loss: 5.962e-01, Validation Loss: 7.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18083, Training Loss: 5.962e-01, Validation Loss: 7.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18084, Training Loss: 5.961e-01, Validation Loss: 7.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18085, Training Loss: 5.961e-01, Validation Loss: 7.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18086, Training Loss: 5.961e-01, Validation Loss: 7.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18087, Training Loss: 5.960e-01, Validation Loss: 7.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18088, Training Loss: 5.960e-01, Validation Loss: 7.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18089, Training Loss: 5.960e-01, Validation Loss: 7.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18090, Training Loss: 5.959e-01, Validation Loss: 7.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18091, Training Loss: 5.959e-01, Validation Loss: 7.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18092, Training Loss: 5.959e-01, Validation Loss: 7.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18093, Training Loss: 5.958e-01, Validation Loss: 7.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18094, Training Loss: 5.958e-01, Validation Loss: 7.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18095, Training Loss: 5.958e-01, Validation Loss: 7.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18096, Training Loss: 5.957e-01, Validation Loss: 7.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18097, Training Loss: 5.957e-01, Validation Loss: 7.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18098, Training Loss: 5.957e-01, Validation Loss: 7.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18099, Training Loss: 5.956e-01, Validation Loss: 7.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18100, Training Loss: 5.956e-01, Validation Loss: 7.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18101, Training Loss: 5.956e-01, Validation Loss: 7.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18102, Training Loss: 5.955e-01, Validation Loss: 7.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18103, Training Loss: 5.955e-01, Validation Loss: 7.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18104, Training Loss: 5.955e-01, Validation Loss: 7.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18105, Training Loss: 5.954e-01, Validation Loss: 7.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18106, Training Loss: 5.954e-01, Validation Loss: 7.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18107, Training Loss: 5.954e-01, Validation Loss: 7.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18108, Training Loss: 5.953e-01, Validation Loss: 7.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18109, Training Loss: 5.953e-01, Validation Loss: 7.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18110, Training Loss: 5.953e-01, Validation Loss: 7.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18111, Training Loss: 5.952e-01, Validation Loss: 7.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18112, Training Loss: 5.952e-01, Validation Loss: 7.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18113, Training Loss: 5.952e-01, Validation Loss: 7.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18114, Training Loss: 5.951e-01, Validation Loss: 7.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18115, Training Loss: 5.951e-01, Validation Loss: 7.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18116, Training Loss: 5.951e-01, Validation Loss: 7.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18117, Training Loss: 5.950e-01, Validation Loss: 7.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18118, Training Loss: 5.950e-01, Validation Loss: 7.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18119, Training Loss: 5.950e-01, Validation Loss: 7.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18120, Training Loss: 5.949e-01, Validation Loss: 7.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18121, Training Loss: 5.949e-01, Validation Loss: 7.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18122, Training Loss: 5.949e-01, Validation Loss: 7.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18123, Training Loss: 5.948e-01, Validation Loss: 7.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18124, Training Loss: 5.948e-01, Validation Loss: 7.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18125, Training Loss: 5.948e-01, Validation Loss: 7.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18126, Training Loss: 5.947e-01, Validation Loss: 7.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18127, Training Loss: 5.947e-01, Validation Loss: 7.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18128, Training Loss: 5.947e-01, Validation Loss: 7.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18129, Training Loss: 5.946e-01, Validation Loss: 7.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18130, Training Loss: 5.946e-01, Validation Loss: 7.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18131, Training Loss: 5.946e-01, Validation Loss: 7.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18132, Training Loss: 5.945e-01, Validation Loss: 7.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18133, Training Loss: 5.945e-01, Validation Loss: 7.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18134, Training Loss: 5.945e-01, Validation Loss: 7.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18135, Training Loss: 5.944e-01, Validation Loss: 7.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18136, Training Loss: 5.944e-01, Validation Loss: 7.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18137, Training Loss: 5.944e-01, Validation Loss: 7.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18138, Training Loss: 5.943e-01, Validation Loss: 7.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18139, Training Loss: 5.943e-01, Validation Loss: 7.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18140, Training Loss: 5.943e-01, Validation Loss: 7.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18141, Training Loss: 5.942e-01, Validation Loss: 7.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18142, Training Loss: 5.942e-01, Validation Loss: 7.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18143, Training Loss: 5.942e-01, Validation Loss: 7.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18144, Training Loss: 5.941e-01, Validation Loss: 7.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18145, Training Loss: 5.941e-01, Validation Loss: 7.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18146, Training Loss: 5.941e-01, Validation Loss: 7.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18147, Training Loss: 5.940e-01, Validation Loss: 7.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18148, Training Loss: 5.940e-01, Validation Loss: 7.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18149, Training Loss: 5.940e-01, Validation Loss: 7.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18150, Training Loss: 5.939e-01, Validation Loss: 7.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18151, Training Loss: 5.939e-01, Validation Loss: 7.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18152, Training Loss: 5.939e-01, Validation Loss: 7.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18153, Training Loss: 5.938e-01, Validation Loss: 7.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18154, Training Loss: 5.938e-01, Validation Loss: 7.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18155, Training Loss: 5.938e-01, Validation Loss: 7.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18156, Training Loss: 5.937e-01, Validation Loss: 7.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18157, Training Loss: 5.937e-01, Validation Loss: 7.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18158, Training Loss: 5.937e-01, Validation Loss: 7.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18159, Training Loss: 5.936e-01, Validation Loss: 7.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18160, Training Loss: 5.936e-01, Validation Loss: 7.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18161, Training Loss: 5.936e-01, Validation Loss: 7.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18162, Training Loss: 5.935e-01, Validation Loss: 7.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18163, Training Loss: 5.935e-01, Validation Loss: 7.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18164, Training Loss: 5.935e-01, Validation Loss: 7.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18165, Training Loss: 5.934e-01, Validation Loss: 7.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18166, Training Loss: 5.934e-01, Validation Loss: 7.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18167, Training Loss: 5.934e-01, Validation Loss: 7.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18168, Training Loss: 5.933e-01, Validation Loss: 7.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18169, Training Loss: 5.933e-01, Validation Loss: 7.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18170, Training Loss: 5.933e-01, Validation Loss: 7.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18171, Training Loss: 5.932e-01, Validation Loss: 7.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18172, Training Loss: 5.932e-01, Validation Loss: 7.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18173, Training Loss: 5.932e-01, Validation Loss: 7.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18174, Training Loss: 5.931e-01, Validation Loss: 7.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18175, Training Loss: 5.931e-01, Validation Loss: 7.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18176, Training Loss: 5.931e-01, Validation Loss: 7.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18177, Training Loss: 5.930e-01, Validation Loss: 7.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18178, Training Loss: 5.930e-01, Validation Loss: 7.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18179, Training Loss: 5.930e-01, Validation Loss: 7.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18180, Training Loss: 5.929e-01, Validation Loss: 7.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18181, Training Loss: 5.929e-01, Validation Loss: 7.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18182, Training Loss: 5.929e-01, Validation Loss: 7.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18183, Training Loss: 5.928e-01, Validation Loss: 7.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18184, Training Loss: 5.928e-01, Validation Loss: 7.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18185, Training Loss: 5.928e-01, Validation Loss: 7.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18186, Training Loss: 5.927e-01, Validation Loss: 7.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18187, Training Loss: 5.927e-01, Validation Loss: 7.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18188, Training Loss: 5.927e-01, Validation Loss: 7.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18189, Training Loss: 5.926e-01, Validation Loss: 7.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18190, Training Loss: 5.926e-01, Validation Loss: 7.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18191, Training Loss: 5.926e-01, Validation Loss: 7.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18192, Training Loss: 5.925e-01, Validation Loss: 7.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18193, Training Loss: 5.925e-01, Validation Loss: 7.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18194, Training Loss: 5.925e-01, Validation Loss: 7.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18195, Training Loss: 5.924e-01, Validation Loss: 7.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18196, Training Loss: 5.924e-01, Validation Loss: 7.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18197, Training Loss: 5.924e-01, Validation Loss: 7.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18198, Training Loss: 5.923e-01, Validation Loss: 7.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18199, Training Loss: 5.923e-01, Validation Loss: 7.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18200, Training Loss: 5.923e-01, Validation Loss: 7.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18201, Training Loss: 5.922e-01, Validation Loss: 7.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18202, Training Loss: 5.922e-01, Validation Loss: 7.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18203, Training Loss: 5.922e-01, Validation Loss: 7.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18204, Training Loss: 5.921e-01, Validation Loss: 7.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18205, Training Loss: 5.921e-01, Validation Loss: 7.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18206, Training Loss: 5.921e-01, Validation Loss: 7.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18207, Training Loss: 5.920e-01, Validation Loss: 7.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18208, Training Loss: 5.920e-01, Validation Loss: 7.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18209, Training Loss: 5.920e-01, Validation Loss: 7.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18210, Training Loss: 5.919e-01, Validation Loss: 7.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18211, Training Loss: 5.919e-01, Validation Loss: 7.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18212, Training Loss: 5.919e-01, Validation Loss: 7.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18213, Training Loss: 5.918e-01, Validation Loss: 7.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18214, Training Loss: 5.918e-01, Validation Loss: 7.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18215, Training Loss: 5.918e-01, Validation Loss: 7.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18216, Training Loss: 5.917e-01, Validation Loss: 7.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18217, Training Loss: 5.917e-01, Validation Loss: 7.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18218, Training Loss: 5.917e-01, Validation Loss: 7.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18219, Training Loss: 5.916e-01, Validation Loss: 7.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18220, Training Loss: 5.916e-01, Validation Loss: 7.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18221, Training Loss: 5.916e-01, Validation Loss: 7.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18222, Training Loss: 5.915e-01, Validation Loss: 7.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18223, Training Loss: 5.915e-01, Validation Loss: 7.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18224, Training Loss: 5.915e-01, Validation Loss: 7.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18225, Training Loss: 5.914e-01, Validation Loss: 7.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18226, Training Loss: 5.914e-01, Validation Loss: 7.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18227, Training Loss: 5.914e-01, Validation Loss: 7.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18228, Training Loss: 5.913e-01, Validation Loss: 7.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18229, Training Loss: 5.913e-01, Validation Loss: 7.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18230, Training Loss: 5.913e-01, Validation Loss: 7.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18231, Training Loss: 5.912e-01, Validation Loss: 7.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18232, Training Loss: 5.912e-01, Validation Loss: 7.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18233, Training Loss: 5.912e-01, Validation Loss: 7.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18234, Training Loss: 5.911e-01, Validation Loss: 7.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18235, Training Loss: 5.911e-01, Validation Loss: 7.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18236, Training Loss: 5.911e-01, Validation Loss: 7.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18237, Training Loss: 5.910e-01, Validation Loss: 7.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18238, Training Loss: 5.910e-01, Validation Loss: 7.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18239, Training Loss: 5.910e-01, Validation Loss: 7.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18240, Training Loss: 5.909e-01, Validation Loss: 7.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18241, Training Loss: 5.909e-01, Validation Loss: 7.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18242, Training Loss: 5.909e-01, Validation Loss: 7.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18243, Training Loss: 5.908e-01, Validation Loss: 7.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18244, Training Loss: 5.908e-01, Validation Loss: 7.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18245, Training Loss: 5.908e-01, Validation Loss: 7.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18246, Training Loss: 5.907e-01, Validation Loss: 7.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18247, Training Loss: 5.907e-01, Validation Loss: 7.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18248, Training Loss: 5.907e-01, Validation Loss: 7.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18249, Training Loss: 5.906e-01, Validation Loss: 7.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18250, Training Loss: 5.906e-01, Validation Loss: 7.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18251, Training Loss: 5.906e-01, Validation Loss: 7.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18252, Training Loss: 5.905e-01, Validation Loss: 7.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18253, Training Loss: 5.905e-01, Validation Loss: 7.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18254, Training Loss: 5.905e-01, Validation Loss: 7.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18255, Training Loss: 5.904e-01, Validation Loss: 7.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18256, Training Loss: 5.904e-01, Validation Loss: 7.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18257, Training Loss: 5.904e-01, Validation Loss: 7.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18258, Training Loss: 5.903e-01, Validation Loss: 7.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18259, Training Loss: 5.903e-01, Validation Loss: 7.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18260, Training Loss: 5.903e-01, Validation Loss: 7.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18261, Training Loss: 5.902e-01, Validation Loss: 7.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18262, Training Loss: 5.902e-01, Validation Loss: 7.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18263, Training Loss: 5.902e-01, Validation Loss: 7.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18264, Training Loss: 5.901e-01, Validation Loss: 7.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18265, Training Loss: 5.901e-01, Validation Loss: 7.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18266, Training Loss: 5.901e-01, Validation Loss: 7.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18267, Training Loss: 5.900e-01, Validation Loss: 7.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18268, Training Loss: 5.900e-01, Validation Loss: 7.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18269, Training Loss: 5.900e-01, Validation Loss: 7.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18270, Training Loss: 5.899e-01, Validation Loss: 7.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18271, Training Loss: 5.899e-01, Validation Loss: 7.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18272, Training Loss: 5.899e-01, Validation Loss: 7.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18273, Training Loss: 5.898e-01, Validation Loss: 7.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18274, Training Loss: 5.898e-01, Validation Loss: 7.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18275, Training Loss: 5.898e-01, Validation Loss: 7.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18276, Training Loss: 5.897e-01, Validation Loss: 7.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18277, Training Loss: 5.897e-01, Validation Loss: 7.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18278, Training Loss: 5.897e-01, Validation Loss: 7.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18279, Training Loss: 5.896e-01, Validation Loss: 7.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18280, Training Loss: 5.896e-01, Validation Loss: 7.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18281, Training Loss: 5.896e-01, Validation Loss: 7.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18282, Training Loss: 5.895e-01, Validation Loss: 7.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18283, Training Loss: 5.895e-01, Validation Loss: 7.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18284, Training Loss: 5.895e-01, Validation Loss: 7.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18285, Training Loss: 5.894e-01, Validation Loss: 7.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18286, Training Loss: 5.894e-01, Validation Loss: 7.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18287, Training Loss: 5.894e-01, Validation Loss: 7.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18288, Training Loss: 5.893e-01, Validation Loss: 7.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18289, Training Loss: 5.893e-01, Validation Loss: 7.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18290, Training Loss: 5.893e-01, Validation Loss: 7.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18291, Training Loss: 5.892e-01, Validation Loss: 7.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18292, Training Loss: 5.892e-01, Validation Loss: 7.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18293, Training Loss: 5.892e-01, Validation Loss: 7.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18294, Training Loss: 5.891e-01, Validation Loss: 7.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18295, Training Loss: 5.891e-01, Validation Loss: 7.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18296, Training Loss: 5.891e-01, Validation Loss: 7.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18297, Training Loss: 5.890e-01, Validation Loss: 7.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18298, Training Loss: 5.890e-01, Validation Loss: 7.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18299, Training Loss: 5.890e-01, Validation Loss: 7.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18300, Training Loss: 5.889e-01, Validation Loss: 7.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18301, Training Loss: 5.889e-01, Validation Loss: 7.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18302, Training Loss: 5.889e-01, Validation Loss: 7.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18303, Training Loss: 5.888e-01, Validation Loss: 7.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18304, Training Loss: 5.888e-01, Validation Loss: 7.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18305, Training Loss: 5.888e-01, Validation Loss: 7.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18306, Training Loss: 5.887e-01, Validation Loss: 7.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18307, Training Loss: 5.887e-01, Validation Loss: 7.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18308, Training Loss: 5.887e-01, Validation Loss: 7.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18309, Training Loss: 5.886e-01, Validation Loss: 7.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18310, Training Loss: 5.886e-01, Validation Loss: 7.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18311, Training Loss: 5.886e-01, Validation Loss: 7.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18312, Training Loss: 5.885e-01, Validation Loss: 7.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18313, Training Loss: 5.885e-01, Validation Loss: 7.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18314, Training Loss: 5.885e-01, Validation Loss: 7.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18315, Training Loss: 5.884e-01, Validation Loss: 7.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18316, Training Loss: 5.884e-01, Validation Loss: 7.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18317, Training Loss: 5.884e-01, Validation Loss: 7.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18318, Training Loss: 5.884e-01, Validation Loss: 7.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18319, Training Loss: 5.883e-01, Validation Loss: 7.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18320, Training Loss: 5.883e-01, Validation Loss: 7.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18321, Training Loss: 5.883e-01, Validation Loss: 7.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18322, Training Loss: 5.882e-01, Validation Loss: 7.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18323, Training Loss: 5.882e-01, Validation Loss: 7.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18324, Training Loss: 5.882e-01, Validation Loss: 7.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18325, Training Loss: 5.881e-01, Validation Loss: 7.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18326, Training Loss: 5.881e-01, Validation Loss: 7.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18327, Training Loss: 5.881e-01, Validation Loss: 7.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18328, Training Loss: 5.880e-01, Validation Loss: 7.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18329, Training Loss: 5.880e-01, Validation Loss: 7.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18330, Training Loss: 5.880e-01, Validation Loss: 7.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18331, Training Loss: 5.879e-01, Validation Loss: 7.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18332, Training Loss: 5.879e-01, Validation Loss: 7.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18333, Training Loss: 5.879e-01, Validation Loss: 7.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18334, Training Loss: 5.878e-01, Validation Loss: 7.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18335, Training Loss: 5.878e-01, Validation Loss: 7.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18336, Training Loss: 5.878e-01, Validation Loss: 7.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18337, Training Loss: 5.877e-01, Validation Loss: 7.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18338, Training Loss: 5.877e-01, Validation Loss: 7.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18339, Training Loss: 5.877e-01, Validation Loss: 7.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18340, Training Loss: 5.876e-01, Validation Loss: 7.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18341, Training Loss: 5.876e-01, Validation Loss: 7.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18342, Training Loss: 5.876e-01, Validation Loss: 7.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18343, Training Loss: 5.875e-01, Validation Loss: 7.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18344, Training Loss: 5.875e-01, Validation Loss: 7.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18345, Training Loss: 5.875e-01, Validation Loss: 7.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18346, Training Loss: 5.874e-01, Validation Loss: 7.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18347, Training Loss: 5.874e-01, Validation Loss: 7.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18348, Training Loss: 5.874e-01, Validation Loss: 7.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18349, Training Loss: 5.873e-01, Validation Loss: 7.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18350, Training Loss: 5.873e-01, Validation Loss: 7.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18351, Training Loss: 5.873e-01, Validation Loss: 7.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18352, Training Loss: 5.872e-01, Validation Loss: 7.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18353, Training Loss: 5.872e-01, Validation Loss: 7.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18354, Training Loss: 5.872e-01, Validation Loss: 7.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18355, Training Loss: 5.871e-01, Validation Loss: 7.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18356, Training Loss: 5.871e-01, Validation Loss: 7.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18357, Training Loss: 5.871e-01, Validation Loss: 7.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18358, Training Loss: 5.870e-01, Validation Loss: 7.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18359, Training Loss: 5.870e-01, Validation Loss: 7.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18360, Training Loss: 5.870e-01, Validation Loss: 7.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18361, Training Loss: 5.869e-01, Validation Loss: 7.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18362, Training Loss: 5.869e-01, Validation Loss: 7.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18363, Training Loss: 5.869e-01, Validation Loss: 7.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18364, Training Loss: 5.868e-01, Validation Loss: 7.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18365, Training Loss: 5.868e-01, Validation Loss: 7.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18366, Training Loss: 5.868e-01, Validation Loss: 7.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18367, Training Loss: 5.867e-01, Validation Loss: 7.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18368, Training Loss: 5.867e-01, Validation Loss: 7.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18369, Training Loss: 5.867e-01, Validation Loss: 7.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18370, Training Loss: 5.866e-01, Validation Loss: 7.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18371, Training Loss: 5.866e-01, Validation Loss: 7.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18372, Training Loss: 5.866e-01, Validation Loss: 7.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18373, Training Loss: 5.865e-01, Validation Loss: 7.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18374, Training Loss: 5.865e-01, Validation Loss: 7.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18375, Training Loss: 5.865e-01, Validation Loss: 7.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18376, Training Loss: 5.864e-01, Validation Loss: 7.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18377, Training Loss: 5.864e-01, Validation Loss: 7.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18378, Training Loss: 5.864e-01, Validation Loss: 7.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18379, Training Loss: 5.863e-01, Validation Loss: 7.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18380, Training Loss: 5.863e-01, Validation Loss: 7.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18381, Training Loss: 5.863e-01, Validation Loss: 7.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18382, Training Loss: 5.863e-01, Validation Loss: 7.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18383, Training Loss: 5.862e-01, Validation Loss: 7.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18384, Training Loss: 5.862e-01, Validation Loss: 7.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18385, Training Loss: 5.862e-01, Validation Loss: 7.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18386, Training Loss: 5.861e-01, Validation Loss: 7.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18387, Training Loss: 5.861e-01, Validation Loss: 7.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18388, Training Loss: 5.861e-01, Validation Loss: 7.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18389, Training Loss: 5.860e-01, Validation Loss: 7.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18390, Training Loss: 5.860e-01, Validation Loss: 7.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18391, Training Loss: 5.860e-01, Validation Loss: 7.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18392, Training Loss: 5.859e-01, Validation Loss: 7.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18393, Training Loss: 5.859e-01, Validation Loss: 7.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18394, Training Loss: 5.859e-01, Validation Loss: 7.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18395, Training Loss: 5.858e-01, Validation Loss: 7.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18396, Training Loss: 5.858e-01, Validation Loss: 7.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18397, Training Loss: 5.858e-01, Validation Loss: 7.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18398, Training Loss: 5.857e-01, Validation Loss: 7.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18399, Training Loss: 5.857e-01, Validation Loss: 7.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18400, Training Loss: 5.857e-01, Validation Loss: 7.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18401, Training Loss: 5.856e-01, Validation Loss: 7.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18402, Training Loss: 5.856e-01, Validation Loss: 7.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18403, Training Loss: 5.856e-01, Validation Loss: 7.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18404, Training Loss: 5.855e-01, Validation Loss: 7.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18405, Training Loss: 5.855e-01, Validation Loss: 7.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18406, Training Loss: 5.855e-01, Validation Loss: 7.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18407, Training Loss: 5.854e-01, Validation Loss: 7.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18408, Training Loss: 5.854e-01, Validation Loss: 7.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18409, Training Loss: 5.854e-01, Validation Loss: 7.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18410, Training Loss: 5.853e-01, Validation Loss: 7.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18411, Training Loss: 5.853e-01, Validation Loss: 7.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18412, Training Loss: 5.853e-01, Validation Loss: 7.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18413, Training Loss: 5.852e-01, Validation Loss: 7.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18414, Training Loss: 5.852e-01, Validation Loss: 7.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18415, Training Loss: 5.852e-01, Validation Loss: 7.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18416, Training Loss: 5.851e-01, Validation Loss: 7.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18417, Training Loss: 5.851e-01, Validation Loss: 7.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18418, Training Loss: 5.851e-01, Validation Loss: 7.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18419, Training Loss: 5.850e-01, Validation Loss: 7.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18420, Training Loss: 5.850e-01, Validation Loss: 7.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18421, Training Loss: 5.850e-01, Validation Loss: 7.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18422, Training Loss: 5.849e-01, Validation Loss: 7.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18423, Training Loss: 5.849e-01, Validation Loss: 7.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18424, Training Loss: 5.849e-01, Validation Loss: 7.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18425, Training Loss: 5.848e-01, Validation Loss: 7.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18426, Training Loss: 5.848e-01, Validation Loss: 7.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18427, Training Loss: 5.848e-01, Validation Loss: 7.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18428, Training Loss: 5.847e-01, Validation Loss: 7.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18429, Training Loss: 5.847e-01, Validation Loss: 7.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18430, Training Loss: 5.847e-01, Validation Loss: 7.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18431, Training Loss: 5.846e-01, Validation Loss: 7.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18432, Training Loss: 5.846e-01, Validation Loss: 7.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18433, Training Loss: 5.846e-01, Validation Loss: 7.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18434, Training Loss: 5.845e-01, Validation Loss: 7.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18435, Training Loss: 5.845e-01, Validation Loss: 7.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18436, Training Loss: 5.845e-01, Validation Loss: 7.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18437, Training Loss: 5.845e-01, Validation Loss: 7.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18438, Training Loss: 5.844e-01, Validation Loss: 7.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18439, Training Loss: 5.844e-01, Validation Loss: 7.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18440, Training Loss: 5.844e-01, Validation Loss: 7.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18441, Training Loss: 5.843e-01, Validation Loss: 7.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18442, Training Loss: 5.843e-01, Validation Loss: 7.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18443, Training Loss: 5.843e-01, Validation Loss: 7.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18444, Training Loss: 5.842e-01, Validation Loss: 7.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18445, Training Loss: 5.842e-01, Validation Loss: 7.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18446, Training Loss: 5.842e-01, Validation Loss: 7.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18447, Training Loss: 5.841e-01, Validation Loss: 7.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18448, Training Loss: 5.841e-01, Validation Loss: 7.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18449, Training Loss: 5.841e-01, Validation Loss: 7.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18450, Training Loss: 5.840e-01, Validation Loss: 7.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18451, Training Loss: 5.840e-01, Validation Loss: 7.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18452, Training Loss: 5.840e-01, Validation Loss: 7.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18453, Training Loss: 5.839e-01, Validation Loss: 7.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18454, Training Loss: 5.839e-01, Validation Loss: 7.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18455, Training Loss: 5.839e-01, Validation Loss: 7.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18456, Training Loss: 5.838e-01, Validation Loss: 7.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18457, Training Loss: 5.838e-01, Validation Loss: 7.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18458, Training Loss: 5.838e-01, Validation Loss: 7.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18459, Training Loss: 5.837e-01, Validation Loss: 7.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18460, Training Loss: 5.837e-01, Validation Loss: 7.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18461, Training Loss: 5.837e-01, Validation Loss: 7.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18462, Training Loss: 5.836e-01, Validation Loss: 7.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18463, Training Loss: 5.836e-01, Validation Loss: 7.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18464, Training Loss: 5.836e-01, Validation Loss: 7.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18465, Training Loss: 5.835e-01, Validation Loss: 7.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18466, Training Loss: 5.835e-01, Validation Loss: 7.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18467, Training Loss: 5.835e-01, Validation Loss: 7.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18468, Training Loss: 5.834e-01, Validation Loss: 7.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18469, Training Loss: 5.834e-01, Validation Loss: 7.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18470, Training Loss: 5.834e-01, Validation Loss: 7.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18471, Training Loss: 5.833e-01, Validation Loss: 7.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18472, Training Loss: 5.833e-01, Validation Loss: 7.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18473, Training Loss: 5.833e-01, Validation Loss: 7.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18474, Training Loss: 5.832e-01, Validation Loss: 7.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18475, Training Loss: 5.832e-01, Validation Loss: 7.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18476, Training Loss: 5.832e-01, Validation Loss: 7.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18477, Training Loss: 5.831e-01, Validation Loss: 7.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18478, Training Loss: 5.831e-01, Validation Loss: 7.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18479, Training Loss: 5.831e-01, Validation Loss: 7.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18480, Training Loss: 5.831e-01, Validation Loss: 7.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18481, Training Loss: 5.830e-01, Validation Loss: 7.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18482, Training Loss: 5.830e-01, Validation Loss: 7.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18483, Training Loss: 5.830e-01, Validation Loss: 7.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18484, Training Loss: 5.829e-01, Validation Loss: 7.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18485, Training Loss: 5.829e-01, Validation Loss: 7.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18486, Training Loss: 5.829e-01, Validation Loss: 7.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18487, Training Loss: 5.828e-01, Validation Loss: 7.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18488, Training Loss: 5.828e-01, Validation Loss: 7.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18489, Training Loss: 5.828e-01, Validation Loss: 7.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18490, Training Loss: 5.827e-01, Validation Loss: 7.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18491, Training Loss: 5.827e-01, Validation Loss: 7.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18492, Training Loss: 5.827e-01, Validation Loss: 7.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18493, Training Loss: 5.826e-01, Validation Loss: 7.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18494, Training Loss: 5.826e-01, Validation Loss: 7.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18495, Training Loss: 5.826e-01, Validation Loss: 7.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18496, Training Loss: 5.825e-01, Validation Loss: 7.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18497, Training Loss: 5.825e-01, Validation Loss: 7.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18498, Training Loss: 5.825e-01, Validation Loss: 7.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18499, Training Loss: 5.824e-01, Validation Loss: 7.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18500, Training Loss: 5.824e-01, Validation Loss: 7.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18501, Training Loss: 5.824e-01, Validation Loss: 7.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18502, Training Loss: 5.823e-01, Validation Loss: 7.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18503, Training Loss: 5.823e-01, Validation Loss: 7.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18504, Training Loss: 5.823e-01, Validation Loss: 7.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18505, Training Loss: 5.822e-01, Validation Loss: 7.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18506, Training Loss: 5.822e-01, Validation Loss: 7.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18507, Training Loss: 5.822e-01, Validation Loss: 7.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18508, Training Loss: 5.821e-01, Validation Loss: 7.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18509, Training Loss: 5.821e-01, Validation Loss: 7.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18510, Training Loss: 5.821e-01, Validation Loss: 7.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18511, Training Loss: 5.820e-01, Validation Loss: 7.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18512, Training Loss: 5.820e-01, Validation Loss: 7.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18513, Training Loss: 5.820e-01, Validation Loss: 7.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18514, Training Loss: 5.819e-01, Validation Loss: 7.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18515, Training Loss: 5.819e-01, Validation Loss: 7.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18516, Training Loss: 5.819e-01, Validation Loss: 7.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18517, Training Loss: 5.819e-01, Validation Loss: 7.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18518, Training Loss: 5.818e-01, Validation Loss: 7.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18519, Training Loss: 5.818e-01, Validation Loss: 7.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18520, Training Loss: 5.818e-01, Validation Loss: 7.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18521, Training Loss: 5.817e-01, Validation Loss: 7.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18522, Training Loss: 5.817e-01, Validation Loss: 7.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18523, Training Loss: 5.817e-01, Validation Loss: 7.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18524, Training Loss: 5.816e-01, Validation Loss: 7.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18525, Training Loss: 5.816e-01, Validation Loss: 7.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18526, Training Loss: 5.816e-01, Validation Loss: 7.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18527, Training Loss: 5.815e-01, Validation Loss: 7.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18528, Training Loss: 5.815e-01, Validation Loss: 7.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18529, Training Loss: 5.815e-01, Validation Loss: 7.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18530, Training Loss: 5.814e-01, Validation Loss: 7.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18531, Training Loss: 5.814e-01, Validation Loss: 7.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18532, Training Loss: 5.814e-01, Validation Loss: 7.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18533, Training Loss: 5.813e-01, Validation Loss: 7.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18534, Training Loss: 5.813e-01, Validation Loss: 7.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18535, Training Loss: 5.813e-01, Validation Loss: 7.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18536, Training Loss: 5.812e-01, Validation Loss: 7.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18537, Training Loss: 5.812e-01, Validation Loss: 7.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18538, Training Loss: 5.812e-01, Validation Loss: 7.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18539, Training Loss: 5.811e-01, Validation Loss: 7.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18540, Training Loss: 5.811e-01, Validation Loss: 7.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18541, Training Loss: 5.811e-01, Validation Loss: 7.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18542, Training Loss: 5.810e-01, Validation Loss: 7.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18543, Training Loss: 5.810e-01, Validation Loss: 7.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18544, Training Loss: 5.810e-01, Validation Loss: 7.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18545, Training Loss: 5.809e-01, Validation Loss: 7.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18546, Training Loss: 5.809e-01, Validation Loss: 7.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18547, Training Loss: 5.809e-01, Validation Loss: 7.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18548, Training Loss: 5.808e-01, Validation Loss: 7.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18549, Training Loss: 5.808e-01, Validation Loss: 7.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18550, Training Loss: 5.808e-01, Validation Loss: 7.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18551, Training Loss: 5.808e-01, Validation Loss: 7.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18552, Training Loss: 5.807e-01, Validation Loss: 7.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18553, Training Loss: 5.807e-01, Validation Loss: 7.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18554, Training Loss: 5.807e-01, Validation Loss: 7.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18555, Training Loss: 5.806e-01, Validation Loss: 7.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18556, Training Loss: 5.806e-01, Validation Loss: 7.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18557, Training Loss: 5.806e-01, Validation Loss: 7.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18558, Training Loss: 5.805e-01, Validation Loss: 7.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18559, Training Loss: 5.805e-01, Validation Loss: 7.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18560, Training Loss: 5.805e-01, Validation Loss: 7.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18561, Training Loss: 5.804e-01, Validation Loss: 7.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18562, Training Loss: 5.804e-01, Validation Loss: 7.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18563, Training Loss: 5.804e-01, Validation Loss: 7.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18564, Training Loss: 5.803e-01, Validation Loss: 7.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18565, Training Loss: 5.803e-01, Validation Loss: 7.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18566, Training Loss: 5.803e-01, Validation Loss: 7.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18567, Training Loss: 5.802e-01, Validation Loss: 7.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18568, Training Loss: 5.802e-01, Validation Loss: 7.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18569, Training Loss: 5.802e-01, Validation Loss: 7.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18570, Training Loss: 5.801e-01, Validation Loss: 7.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18571, Training Loss: 5.801e-01, Validation Loss: 7.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18572, Training Loss: 5.801e-01, Validation Loss: 7.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18573, Training Loss: 5.800e-01, Validation Loss: 7.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18574, Training Loss: 5.800e-01, Validation Loss: 7.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18575, Training Loss: 5.800e-01, Validation Loss: 7.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18576, Training Loss: 5.799e-01, Validation Loss: 7.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18577, Training Loss: 5.799e-01, Validation Loss: 7.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18578, Training Loss: 5.799e-01, Validation Loss: 7.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18579, Training Loss: 5.799e-01, Validation Loss: 7.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18580, Training Loss: 5.798e-01, Validation Loss: 7.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18581, Training Loss: 5.798e-01, Validation Loss: 7.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18582, Training Loss: 5.798e-01, Validation Loss: 7.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18583, Training Loss: 5.797e-01, Validation Loss: 7.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18584, Training Loss: 5.797e-01, Validation Loss: 7.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18585, Training Loss: 5.797e-01, Validation Loss: 7.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18586, Training Loss: 5.796e-01, Validation Loss: 7.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18587, Training Loss: 5.796e-01, Validation Loss: 7.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18588, Training Loss: 5.796e-01, Validation Loss: 7.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18589, Training Loss: 5.795e-01, Validation Loss: 7.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18590, Training Loss: 5.795e-01, Validation Loss: 7.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18591, Training Loss: 5.795e-01, Validation Loss: 7.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18592, Training Loss: 5.794e-01, Validation Loss: 7.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18593, Training Loss: 5.794e-01, Validation Loss: 7.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18594, Training Loss: 5.794e-01, Validation Loss: 7.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18595, Training Loss: 5.793e-01, Validation Loss: 7.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18596, Training Loss: 5.793e-01, Validation Loss: 7.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18597, Training Loss: 5.793e-01, Validation Loss: 7.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18598, Training Loss: 5.792e-01, Validation Loss: 7.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18599, Training Loss: 5.792e-01, Validation Loss: 7.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18600, Training Loss: 5.792e-01, Validation Loss: 7.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18601, Training Loss: 5.791e-01, Validation Loss: 7.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18602, Training Loss: 5.791e-01, Validation Loss: 7.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18603, Training Loss: 5.791e-01, Validation Loss: 7.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18604, Training Loss: 5.790e-01, Validation Loss: 7.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18605, Training Loss: 5.790e-01, Validation Loss: 7.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18606, Training Loss: 5.790e-01, Validation Loss: 7.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18607, Training Loss: 5.790e-01, Validation Loss: 7.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18608, Training Loss: 5.789e-01, Validation Loss: 7.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18609, Training Loss: 5.789e-01, Validation Loss: 7.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18610, Training Loss: 5.789e-01, Validation Loss: 7.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18611, Training Loss: 5.788e-01, Validation Loss: 7.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18612, Training Loss: 5.788e-01, Validation Loss: 7.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18613, Training Loss: 5.788e-01, Validation Loss: 7.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18614, Training Loss: 5.787e-01, Validation Loss: 7.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18615, Training Loss: 5.787e-01, Validation Loss: 7.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18616, Training Loss: 5.787e-01, Validation Loss: 7.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18617, Training Loss: 5.786e-01, Validation Loss: 7.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18618, Training Loss: 5.786e-01, Validation Loss: 7.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18619, Training Loss: 5.786e-01, Validation Loss: 7.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18620, Training Loss: 5.785e-01, Validation Loss: 7.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18621, Training Loss: 5.785e-01, Validation Loss: 7.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18622, Training Loss: 5.785e-01, Validation Loss: 7.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18623, Training Loss: 5.784e-01, Validation Loss: 7.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18624, Training Loss: 5.784e-01, Validation Loss: 7.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18625, Training Loss: 5.784e-01, Validation Loss: 7.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18626, Training Loss: 5.783e-01, Validation Loss: 7.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18627, Training Loss: 5.783e-01, Validation Loss: 7.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18628, Training Loss: 5.783e-01, Validation Loss: 7.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18629, Training Loss: 5.782e-01, Validation Loss: 7.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18630, Training Loss: 5.782e-01, Validation Loss: 7.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18631, Training Loss: 5.782e-01, Validation Loss: 7.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18632, Training Loss: 5.782e-01, Validation Loss: 7.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18633, Training Loss: 5.781e-01, Validation Loss: 7.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18634, Training Loss: 5.781e-01, Validation Loss: 7.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18635, Training Loss: 5.781e-01, Validation Loss: 7.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18636, Training Loss: 5.780e-01, Validation Loss: 7.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18637, Training Loss: 5.780e-01, Validation Loss: 7.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18638, Training Loss: 5.780e-01, Validation Loss: 7.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18639, Training Loss: 5.779e-01, Validation Loss: 7.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18640, Training Loss: 5.779e-01, Validation Loss: 7.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18641, Training Loss: 5.779e-01, Validation Loss: 7.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18642, Training Loss: 5.778e-01, Validation Loss: 7.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18643, Training Loss: 5.778e-01, Validation Loss: 7.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18644, Training Loss: 5.778e-01, Validation Loss: 7.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18645, Training Loss: 5.777e-01, Validation Loss: 7.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18646, Training Loss: 5.777e-01, Validation Loss: 7.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18647, Training Loss: 5.777e-01, Validation Loss: 7.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18648, Training Loss: 5.776e-01, Validation Loss: 7.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18649, Training Loss: 5.776e-01, Validation Loss: 7.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18650, Training Loss: 5.776e-01, Validation Loss: 7.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18651, Training Loss: 5.775e-01, Validation Loss: 7.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18652, Training Loss: 5.775e-01, Validation Loss: 7.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18653, Training Loss: 5.775e-01, Validation Loss: 7.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18654, Training Loss: 5.774e-01, Validation Loss: 7.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18655, Training Loss: 5.774e-01, Validation Loss: 7.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18656, Training Loss: 5.774e-01, Validation Loss: 7.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18657, Training Loss: 5.774e-01, Validation Loss: 7.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18658, Training Loss: 5.773e-01, Validation Loss: 7.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18659, Training Loss: 5.773e-01, Validation Loss: 7.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18660, Training Loss: 5.773e-01, Validation Loss: 7.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18661, Training Loss: 5.772e-01, Validation Loss: 7.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18662, Training Loss: 5.772e-01, Validation Loss: 7.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18663, Training Loss: 5.772e-01, Validation Loss: 7.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18664, Training Loss: 5.771e-01, Validation Loss: 7.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18665, Training Loss: 5.771e-01, Validation Loss: 7.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18666, Training Loss: 5.771e-01, Validation Loss: 7.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18667, Training Loss: 5.770e-01, Validation Loss: 7.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18668, Training Loss: 5.770e-01, Validation Loss: 7.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18669, Training Loss: 5.770e-01, Validation Loss: 7.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18670, Training Loss: 5.769e-01, Validation Loss: 7.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18671, Training Loss: 5.769e-01, Validation Loss: 7.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18672, Training Loss: 5.769e-01, Validation Loss: 7.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18673, Training Loss: 5.768e-01, Validation Loss: 7.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18674, Training Loss: 5.768e-01, Validation Loss: 7.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18675, Training Loss: 5.768e-01, Validation Loss: 7.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18676, Training Loss: 5.767e-01, Validation Loss: 7.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18677, Training Loss: 5.767e-01, Validation Loss: 7.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18678, Training Loss: 5.767e-01, Validation Loss: 7.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18679, Training Loss: 5.767e-01, Validation Loss: 7.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18680, Training Loss: 5.766e-01, Validation Loss: 7.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18681, Training Loss: 5.766e-01, Validation Loss: 7.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18682, Training Loss: 5.766e-01, Validation Loss: 7.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18683, Training Loss: 5.765e-01, Validation Loss: 7.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18684, Training Loss: 5.765e-01, Validation Loss: 7.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18685, Training Loss: 5.765e-01, Validation Loss: 7.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18686, Training Loss: 5.764e-01, Validation Loss: 7.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18687, Training Loss: 5.764e-01, Validation Loss: 7.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18688, Training Loss: 5.764e-01, Validation Loss: 7.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18689, Training Loss: 5.763e-01, Validation Loss: 7.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18690, Training Loss: 5.763e-01, Validation Loss: 7.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18691, Training Loss: 5.763e-01, Validation Loss: 7.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18692, Training Loss: 5.762e-01, Validation Loss: 7.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18693, Training Loss: 5.762e-01, Validation Loss: 7.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18694, Training Loss: 5.762e-01, Validation Loss: 7.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18695, Training Loss: 5.761e-01, Validation Loss: 7.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18696, Training Loss: 5.761e-01, Validation Loss: 7.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18697, Training Loss: 5.761e-01, Validation Loss: 7.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18698, Training Loss: 5.760e-01, Validation Loss: 7.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18699, Training Loss: 5.760e-01, Validation Loss: 7.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18700, Training Loss: 5.760e-01, Validation Loss: 7.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18701, Training Loss: 5.760e-01, Validation Loss: 7.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18702, Training Loss: 5.759e-01, Validation Loss: 7.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18703, Training Loss: 5.759e-01, Validation Loss: 7.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18704, Training Loss: 5.759e-01, Validation Loss: 7.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18705, Training Loss: 5.758e-01, Validation Loss: 7.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18706, Training Loss: 5.758e-01, Validation Loss: 7.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18707, Training Loss: 5.758e-01, Validation Loss: 7.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18708, Training Loss: 5.757e-01, Validation Loss: 7.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18709, Training Loss: 5.757e-01, Validation Loss: 7.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18710, Training Loss: 5.757e-01, Validation Loss: 7.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18711, Training Loss: 5.756e-01, Validation Loss: 7.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18712, Training Loss: 5.756e-01, Validation Loss: 7.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18713, Training Loss: 5.756e-01, Validation Loss: 7.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18714, Training Loss: 5.755e-01, Validation Loss: 7.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18715, Training Loss: 5.755e-01, Validation Loss: 7.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18716, Training Loss: 5.755e-01, Validation Loss: 7.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18717, Training Loss: 5.754e-01, Validation Loss: 7.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18718, Training Loss: 5.754e-01, Validation Loss: 7.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18719, Training Loss: 5.754e-01, Validation Loss: 7.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18720, Training Loss: 5.753e-01, Validation Loss: 7.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18721, Training Loss: 5.753e-01, Validation Loss: 7.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18722, Training Loss: 5.753e-01, Validation Loss: 7.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18723, Training Loss: 5.753e-01, Validation Loss: 7.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18724, Training Loss: 5.752e-01, Validation Loss: 7.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18725, Training Loss: 5.752e-01, Validation Loss: 7.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18726, Training Loss: 5.752e-01, Validation Loss: 7.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18727, Training Loss: 5.751e-01, Validation Loss: 7.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18728, Training Loss: 5.751e-01, Validation Loss: 7.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18729, Training Loss: 5.751e-01, Validation Loss: 7.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18730, Training Loss: 5.750e-01, Validation Loss: 7.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18731, Training Loss: 5.750e-01, Validation Loss: 7.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18732, Training Loss: 5.750e-01, Validation Loss: 7.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18733, Training Loss: 5.749e-01, Validation Loss: 7.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18734, Training Loss: 5.749e-01, Validation Loss: 7.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18735, Training Loss: 5.749e-01, Validation Loss: 7.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18736, Training Loss: 5.748e-01, Validation Loss: 7.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18737, Training Loss: 5.748e-01, Validation Loss: 7.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18738, Training Loss: 5.748e-01, Validation Loss: 7.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18739, Training Loss: 5.747e-01, Validation Loss: 7.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18740, Training Loss: 5.747e-01, Validation Loss: 7.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18741, Training Loss: 5.747e-01, Validation Loss: 7.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18742, Training Loss: 5.746e-01, Validation Loss: 7.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18743, Training Loss: 5.746e-01, Validation Loss: 7.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18744, Training Loss: 5.746e-01, Validation Loss: 7.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18745, Training Loss: 5.746e-01, Validation Loss: 7.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18746, Training Loss: 5.745e-01, Validation Loss: 7.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18747, Training Loss: 5.745e-01, Validation Loss: 7.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18748, Training Loss: 5.745e-01, Validation Loss: 7.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18749, Training Loss: 5.744e-01, Validation Loss: 7.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18750, Training Loss: 5.744e-01, Validation Loss: 7.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18751, Training Loss: 5.744e-01, Validation Loss: 7.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18752, Training Loss: 5.743e-01, Validation Loss: 7.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18753, Training Loss: 5.743e-01, Validation Loss: 7.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18754, Training Loss: 5.743e-01, Validation Loss: 7.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18755, Training Loss: 5.742e-01, Validation Loss: 7.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18756, Training Loss: 5.742e-01, Validation Loss: 7.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18757, Training Loss: 5.742e-01, Validation Loss: 7.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18758, Training Loss: 5.741e-01, Validation Loss: 7.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18759, Training Loss: 5.741e-01, Validation Loss: 7.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18760, Training Loss: 5.741e-01, Validation Loss: 7.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18761, Training Loss: 5.740e-01, Validation Loss: 7.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18762, Training Loss: 5.740e-01, Validation Loss: 7.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18763, Training Loss: 5.740e-01, Validation Loss: 7.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18764, Training Loss: 5.740e-01, Validation Loss: 7.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18765, Training Loss: 5.739e-01, Validation Loss: 7.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18766, Training Loss: 5.739e-01, Validation Loss: 7.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18767, Training Loss: 5.739e-01, Validation Loss: 7.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18768, Training Loss: 5.738e-01, Validation Loss: 7.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18769, Training Loss: 5.738e-01, Validation Loss: 7.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18770, Training Loss: 5.738e-01, Validation Loss: 7.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18771, Training Loss: 5.737e-01, Validation Loss: 7.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18772, Training Loss: 5.737e-01, Validation Loss: 7.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18773, Training Loss: 5.737e-01, Validation Loss: 7.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18774, Training Loss: 5.736e-01, Validation Loss: 7.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18775, Training Loss: 5.736e-01, Validation Loss: 7.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18776, Training Loss: 5.736e-01, Validation Loss: 7.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18777, Training Loss: 5.735e-01, Validation Loss: 7.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18778, Training Loss: 5.735e-01, Validation Loss: 7.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18779, Training Loss: 5.735e-01, Validation Loss: 7.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18780, Training Loss: 5.734e-01, Validation Loss: 7.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18781, Training Loss: 5.734e-01, Validation Loss: 7.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18782, Training Loss: 5.734e-01, Validation Loss: 7.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18783, Training Loss: 5.734e-01, Validation Loss: 7.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18784, Training Loss: 5.733e-01, Validation Loss: 7.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18785, Training Loss: 5.733e-01, Validation Loss: 7.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18786, Training Loss: 5.733e-01, Validation Loss: 7.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18787, Training Loss: 5.732e-01, Validation Loss: 7.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18788, Training Loss: 5.732e-01, Validation Loss: 7.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18789, Training Loss: 5.732e-01, Validation Loss: 7.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18790, Training Loss: 5.731e-01, Validation Loss: 7.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18791, Training Loss: 5.731e-01, Validation Loss: 7.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18792, Training Loss: 5.731e-01, Validation Loss: 7.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18793, Training Loss: 5.730e-01, Validation Loss: 6.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18794, Training Loss: 5.730e-01, Validation Loss: 6.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18795, Training Loss: 5.730e-01, Validation Loss: 6.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18796, Training Loss: 5.729e-01, Validation Loss: 6.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18797, Training Loss: 5.729e-01, Validation Loss: 6.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18798, Training Loss: 5.729e-01, Validation Loss: 6.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18799, Training Loss: 5.728e-01, Validation Loss: 6.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18800, Training Loss: 5.728e-01, Validation Loss: 6.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18801, Training Loss: 5.728e-01, Validation Loss: 6.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18802, Training Loss: 5.728e-01, Validation Loss: 6.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18803, Training Loss: 5.727e-01, Validation Loss: 6.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18804, Training Loss: 5.727e-01, Validation Loss: 6.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18805, Training Loss: 5.727e-01, Validation Loss: 6.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18806, Training Loss: 5.726e-01, Validation Loss: 6.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18807, Training Loss: 5.726e-01, Validation Loss: 6.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18808, Training Loss: 5.726e-01, Validation Loss: 6.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18809, Training Loss: 5.725e-01, Validation Loss: 6.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18810, Training Loss: 5.725e-01, Validation Loss: 6.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18811, Training Loss: 5.725e-01, Validation Loss: 6.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18812, Training Loss: 5.724e-01, Validation Loss: 6.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18813, Training Loss: 5.724e-01, Validation Loss: 6.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18814, Training Loss: 5.724e-01, Validation Loss: 6.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18815, Training Loss: 5.723e-01, Validation Loss: 6.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18816, Training Loss: 5.723e-01, Validation Loss: 6.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18817, Training Loss: 5.723e-01, Validation Loss: 6.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18818, Training Loss: 5.723e-01, Validation Loss: 6.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18819, Training Loss: 5.722e-01, Validation Loss: 6.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18820, Training Loss: 5.722e-01, Validation Loss: 6.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18821, Training Loss: 5.722e-01, Validation Loss: 6.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18822, Training Loss: 5.721e-01, Validation Loss: 6.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18823, Training Loss: 5.721e-01, Validation Loss: 6.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18824, Training Loss: 5.721e-01, Validation Loss: 6.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18825, Training Loss: 5.720e-01, Validation Loss: 6.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18826, Training Loss: 5.720e-01, Validation Loss: 6.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18827, Training Loss: 5.720e-01, Validation Loss: 6.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18828, Training Loss: 5.719e-01, Validation Loss: 6.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18829, Training Loss: 5.719e-01, Validation Loss: 6.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18830, Training Loss: 5.719e-01, Validation Loss: 6.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18831, Training Loss: 5.718e-01, Validation Loss: 6.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18832, Training Loss: 5.718e-01, Validation Loss: 6.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18833, Training Loss: 5.718e-01, Validation Loss: 6.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18834, Training Loss: 5.717e-01, Validation Loss: 6.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18835, Training Loss: 5.717e-01, Validation Loss: 6.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18836, Training Loss: 5.717e-01, Validation Loss: 6.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18837, Training Loss: 5.717e-01, Validation Loss: 6.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18838, Training Loss: 5.716e-01, Validation Loss: 6.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18839, Training Loss: 5.716e-01, Validation Loss: 6.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18840, Training Loss: 5.716e-01, Validation Loss: 6.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18841, Training Loss: 5.715e-01, Validation Loss: 6.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18842, Training Loss: 5.715e-01, Validation Loss: 6.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18843, Training Loss: 5.715e-01, Validation Loss: 6.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18844, Training Loss: 5.714e-01, Validation Loss: 6.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18845, Training Loss: 5.714e-01, Validation Loss: 6.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18846, Training Loss: 5.714e-01, Validation Loss: 6.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18847, Training Loss: 5.713e-01, Validation Loss: 6.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18848, Training Loss: 5.713e-01, Validation Loss: 6.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18849, Training Loss: 5.713e-01, Validation Loss: 6.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18850, Training Loss: 5.712e-01, Validation Loss: 6.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18851, Training Loss: 5.712e-01, Validation Loss: 6.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18852, Training Loss: 5.712e-01, Validation Loss: 6.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18853, Training Loss: 5.712e-01, Validation Loss: 6.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18854, Training Loss: 5.711e-01, Validation Loss: 6.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18855, Training Loss: 5.711e-01, Validation Loss: 6.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18856, Training Loss: 5.711e-01, Validation Loss: 6.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18857, Training Loss: 5.710e-01, Validation Loss: 6.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18858, Training Loss: 5.710e-01, Validation Loss: 6.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18859, Training Loss: 5.710e-01, Validation Loss: 6.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18860, Training Loss: 5.709e-01, Validation Loss: 6.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18861, Training Loss: 5.709e-01, Validation Loss: 6.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18862, Training Loss: 5.709e-01, Validation Loss: 6.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18863, Training Loss: 5.708e-01, Validation Loss: 6.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18864, Training Loss: 5.708e-01, Validation Loss: 6.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18865, Training Loss: 5.708e-01, Validation Loss: 6.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18866, Training Loss: 5.707e-01, Validation Loss: 6.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18867, Training Loss: 5.707e-01, Validation Loss: 6.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18868, Training Loss: 5.707e-01, Validation Loss: 6.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18869, Training Loss: 5.707e-01, Validation Loss: 6.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18870, Training Loss: 5.706e-01, Validation Loss: 6.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18871, Training Loss: 5.706e-01, Validation Loss: 6.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18872, Training Loss: 5.706e-01, Validation Loss: 6.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18873, Training Loss: 5.705e-01, Validation Loss: 6.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18874, Training Loss: 5.705e-01, Validation Loss: 6.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18875, Training Loss: 5.705e-01, Validation Loss: 6.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18876, Training Loss: 5.704e-01, Validation Loss: 6.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18877, Training Loss: 5.704e-01, Validation Loss: 6.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18878, Training Loss: 5.704e-01, Validation Loss: 6.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18879, Training Loss: 5.703e-01, Validation Loss: 6.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18880, Training Loss: 5.703e-01, Validation Loss: 6.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18881, Training Loss: 5.703e-01, Validation Loss: 6.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18882, Training Loss: 5.702e-01, Validation Loss: 6.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18883, Training Loss: 5.702e-01, Validation Loss: 6.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18884, Training Loss: 5.702e-01, Validation Loss: 6.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18885, Training Loss: 5.702e-01, Validation Loss: 6.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18886, Training Loss: 5.701e-01, Validation Loss: 6.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18887, Training Loss: 5.701e-01, Validation Loss: 6.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18888, Training Loss: 5.701e-01, Validation Loss: 6.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18889, Training Loss: 5.700e-01, Validation Loss: 6.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18890, Training Loss: 5.700e-01, Validation Loss: 6.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18891, Training Loss: 5.700e-01, Validation Loss: 6.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18892, Training Loss: 5.699e-01, Validation Loss: 6.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18893, Training Loss: 5.699e-01, Validation Loss: 6.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18894, Training Loss: 5.699e-01, Validation Loss: 6.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18895, Training Loss: 5.698e-01, Validation Loss: 6.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18896, Training Loss: 5.698e-01, Validation Loss: 6.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18897, Training Loss: 5.698e-01, Validation Loss: 6.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18898, Training Loss: 5.697e-01, Validation Loss: 6.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18899, Training Loss: 5.697e-01, Validation Loss: 6.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18900, Training Loss: 5.697e-01, Validation Loss: 6.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18901, Training Loss: 5.697e-01, Validation Loss: 6.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18902, Training Loss: 5.696e-01, Validation Loss: 6.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18903, Training Loss: 5.696e-01, Validation Loss: 6.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18904, Training Loss: 5.696e-01, Validation Loss: 6.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18905, Training Loss: 5.695e-01, Validation Loss: 6.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18906, Training Loss: 5.695e-01, Validation Loss: 6.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18907, Training Loss: 5.695e-01, Validation Loss: 6.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18908, Training Loss: 5.694e-01, Validation Loss: 6.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18909, Training Loss: 5.694e-01, Validation Loss: 6.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18910, Training Loss: 5.694e-01, Validation Loss: 6.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18911, Training Loss: 5.693e-01, Validation Loss: 6.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18912, Training Loss: 5.693e-01, Validation Loss: 6.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18913, Training Loss: 5.693e-01, Validation Loss: 6.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18914, Training Loss: 5.692e-01, Validation Loss: 6.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18915, Training Loss: 5.692e-01, Validation Loss: 6.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18916, Training Loss: 5.692e-01, Validation Loss: 6.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18917, Training Loss: 5.692e-01, Validation Loss: 6.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18918, Training Loss: 5.691e-01, Validation Loss: 6.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18919, Training Loss: 5.691e-01, Validation Loss: 6.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18920, Training Loss: 5.691e-01, Validation Loss: 6.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18921, Training Loss: 5.690e-01, Validation Loss: 6.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18922, Training Loss: 5.690e-01, Validation Loss: 6.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18923, Training Loss: 5.690e-01, Validation Loss: 6.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18924, Training Loss: 5.689e-01, Validation Loss: 6.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18925, Training Loss: 5.689e-01, Validation Loss: 6.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18926, Training Loss: 5.689e-01, Validation Loss: 6.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18927, Training Loss: 5.688e-01, Validation Loss: 6.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18928, Training Loss: 5.688e-01, Validation Loss: 6.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18929, Training Loss: 5.688e-01, Validation Loss: 6.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18930, Training Loss: 5.687e-01, Validation Loss: 6.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18931, Training Loss: 5.687e-01, Validation Loss: 6.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18932, Training Loss: 5.687e-01, Validation Loss: 6.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18933, Training Loss: 5.687e-01, Validation Loss: 6.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18934, Training Loss: 5.686e-01, Validation Loss: 6.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18935, Training Loss: 5.686e-01, Validation Loss: 6.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18936, Training Loss: 5.686e-01, Validation Loss: 6.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18937, Training Loss: 5.685e-01, Validation Loss: 6.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18938, Training Loss: 5.685e-01, Validation Loss: 6.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18939, Training Loss: 5.685e-01, Validation Loss: 6.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18940, Training Loss: 5.684e-01, Validation Loss: 6.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18941, Training Loss: 5.684e-01, Validation Loss: 6.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18942, Training Loss: 5.684e-01, Validation Loss: 6.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18943, Training Loss: 5.683e-01, Validation Loss: 6.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18944, Training Loss: 5.683e-01, Validation Loss: 6.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18945, Training Loss: 5.683e-01, Validation Loss: 6.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18946, Training Loss: 5.683e-01, Validation Loss: 6.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18947, Training Loss: 5.682e-01, Validation Loss: 6.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18948, Training Loss: 5.682e-01, Validation Loss: 6.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18949, Training Loss: 5.682e-01, Validation Loss: 6.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18950, Training Loss: 5.681e-01, Validation Loss: 6.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18951, Training Loss: 5.681e-01, Validation Loss: 6.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18952, Training Loss: 5.681e-01, Validation Loss: 6.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18953, Training Loss: 5.680e-01, Validation Loss: 6.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18954, Training Loss: 5.680e-01, Validation Loss: 6.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18955, Training Loss: 5.680e-01, Validation Loss: 6.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18956, Training Loss: 5.679e-01, Validation Loss: 6.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18957, Training Loss: 5.679e-01, Validation Loss: 6.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18958, Training Loss: 5.679e-01, Validation Loss: 6.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18959, Training Loss: 5.678e-01, Validation Loss: 6.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18960, Training Loss: 5.678e-01, Validation Loss: 6.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18961, Training Loss: 5.678e-01, Validation Loss: 6.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18962, Training Loss: 5.678e-01, Validation Loss: 6.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18963, Training Loss: 5.677e-01, Validation Loss: 6.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18964, Training Loss: 5.677e-01, Validation Loss: 6.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18965, Training Loss: 5.677e-01, Validation Loss: 6.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18966, Training Loss: 5.676e-01, Validation Loss: 6.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18967, Training Loss: 5.676e-01, Validation Loss: 6.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18968, Training Loss: 5.676e-01, Validation Loss: 6.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18969, Training Loss: 5.675e-01, Validation Loss: 6.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18970, Training Loss: 5.675e-01, Validation Loss: 6.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18971, Training Loss: 5.675e-01, Validation Loss: 6.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18972, Training Loss: 5.674e-01, Validation Loss: 6.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18973, Training Loss: 5.674e-01, Validation Loss: 6.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18974, Training Loss: 5.674e-01, Validation Loss: 6.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18975, Training Loss: 5.674e-01, Validation Loss: 6.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18976, Training Loss: 5.673e-01, Validation Loss: 6.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18977, Training Loss: 5.673e-01, Validation Loss: 6.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18978, Training Loss: 5.673e-01, Validation Loss: 6.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18979, Training Loss: 5.672e-01, Validation Loss: 6.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18980, Training Loss: 5.672e-01, Validation Loss: 6.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18981, Training Loss: 5.672e-01, Validation Loss: 6.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18982, Training Loss: 5.671e-01, Validation Loss: 6.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18983, Training Loss: 5.671e-01, Validation Loss: 6.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18984, Training Loss: 5.671e-01, Validation Loss: 6.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18985, Training Loss: 5.670e-01, Validation Loss: 6.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18986, Training Loss: 5.670e-01, Validation Loss: 6.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18987, Training Loss: 5.670e-01, Validation Loss: 6.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18988, Training Loss: 5.670e-01, Validation Loss: 6.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18989, Training Loss: 5.669e-01, Validation Loss: 6.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18990, Training Loss: 5.669e-01, Validation Loss: 6.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18991, Training Loss: 5.669e-01, Validation Loss: 6.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18992, Training Loss: 5.668e-01, Validation Loss: 6.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18993, Training Loss: 5.668e-01, Validation Loss: 6.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18994, Training Loss: 5.668e-01, Validation Loss: 6.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18995, Training Loss: 5.667e-01, Validation Loss: 6.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18996, Training Loss: 5.667e-01, Validation Loss: 6.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18997, Training Loss: 5.667e-01, Validation Loss: 6.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18998, Training Loss: 5.666e-01, Validation Loss: 6.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18999, Training Loss: 5.666e-01, Validation Loss: 6.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19000, Training Loss: 5.666e-01, Validation Loss: 6.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19001, Training Loss: 5.665e-01, Validation Loss: 6.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19002, Training Loss: 5.665e-01, Validation Loss: 6.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19003, Training Loss: 5.665e-01, Validation Loss: 6.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19004, Training Loss: 5.665e-01, Validation Loss: 6.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19005, Training Loss: 5.664e-01, Validation Loss: 6.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19006, Training Loss: 5.664e-01, Validation Loss: 6.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19007, Training Loss: 5.664e-01, Validation Loss: 6.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19008, Training Loss: 5.663e-01, Validation Loss: 6.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19009, Training Loss: 5.663e-01, Validation Loss: 6.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19010, Training Loss: 5.663e-01, Validation Loss: 6.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19011, Training Loss: 5.662e-01, Validation Loss: 6.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19012, Training Loss: 5.662e-01, Validation Loss: 6.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19013, Training Loss: 5.662e-01, Validation Loss: 6.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19014, Training Loss: 5.661e-01, Validation Loss: 6.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19015, Training Loss: 5.661e-01, Validation Loss: 6.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19016, Training Loss: 5.661e-01, Validation Loss: 6.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19017, Training Loss: 5.661e-01, Validation Loss: 6.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19018, Training Loss: 5.660e-01, Validation Loss: 6.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19019, Training Loss: 5.660e-01, Validation Loss: 6.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19020, Training Loss: 5.660e-01, Validation Loss: 6.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19021, Training Loss: 5.659e-01, Validation Loss: 6.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19022, Training Loss: 5.659e-01, Validation Loss: 6.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19023, Training Loss: 5.659e-01, Validation Loss: 6.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19024, Training Loss: 5.658e-01, Validation Loss: 6.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19025, Training Loss: 5.658e-01, Validation Loss: 6.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19026, Training Loss: 5.658e-01, Validation Loss: 6.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19027, Training Loss: 5.657e-01, Validation Loss: 6.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19028, Training Loss: 5.657e-01, Validation Loss: 6.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19029, Training Loss: 5.657e-01, Validation Loss: 6.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19030, Training Loss: 5.657e-01, Validation Loss: 6.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19031, Training Loss: 5.656e-01, Validation Loss: 6.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19032, Training Loss: 5.656e-01, Validation Loss: 6.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19033, Training Loss: 5.656e-01, Validation Loss: 6.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19034, Training Loss: 5.655e-01, Validation Loss: 6.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19035, Training Loss: 5.655e-01, Validation Loss: 6.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19036, Training Loss: 5.655e-01, Validation Loss: 6.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19037, Training Loss: 5.654e-01, Validation Loss: 6.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19038, Training Loss: 5.654e-01, Validation Loss: 6.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19039, Training Loss: 5.654e-01, Validation Loss: 6.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19040, Training Loss: 5.653e-01, Validation Loss: 6.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19041, Training Loss: 5.653e-01, Validation Loss: 6.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19042, Training Loss: 5.653e-01, Validation Loss: 6.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19043, Training Loss: 5.653e-01, Validation Loss: 6.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19044, Training Loss: 5.652e-01, Validation Loss: 6.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19045, Training Loss: 5.652e-01, Validation Loss: 6.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19046, Training Loss: 5.652e-01, Validation Loss: 6.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19047, Training Loss: 5.651e-01, Validation Loss: 6.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19048, Training Loss: 5.651e-01, Validation Loss: 6.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19049, Training Loss: 5.651e-01, Validation Loss: 6.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19050, Training Loss: 5.650e-01, Validation Loss: 6.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19051, Training Loss: 5.650e-01, Validation Loss: 6.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19052, Training Loss: 5.650e-01, Validation Loss: 6.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19053, Training Loss: 5.649e-01, Validation Loss: 6.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19054, Training Loss: 5.649e-01, Validation Loss: 6.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19055, Training Loss: 5.649e-01, Validation Loss: 6.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19056, Training Loss: 5.649e-01, Validation Loss: 6.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19057, Training Loss: 5.648e-01, Validation Loss: 6.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19058, Training Loss: 5.648e-01, Validation Loss: 6.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19059, Training Loss: 5.648e-01, Validation Loss: 6.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19060, Training Loss: 5.647e-01, Validation Loss: 6.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19061, Training Loss: 5.647e-01, Validation Loss: 6.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19062, Training Loss: 5.647e-01, Validation Loss: 6.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19063, Training Loss: 5.646e-01, Validation Loss: 6.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19064, Training Loss: 5.646e-01, Validation Loss: 6.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19065, Training Loss: 5.646e-01, Validation Loss: 6.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19066, Training Loss: 5.645e-01, Validation Loss: 6.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19067, Training Loss: 5.645e-01, Validation Loss: 6.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19068, Training Loss: 5.645e-01, Validation Loss: 6.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19069, Training Loss: 5.645e-01, Validation Loss: 6.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19070, Training Loss: 5.644e-01, Validation Loss: 6.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19071, Training Loss: 5.644e-01, Validation Loss: 6.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19072, Training Loss: 5.644e-01, Validation Loss: 6.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19073, Training Loss: 5.643e-01, Validation Loss: 6.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19074, Training Loss: 5.643e-01, Validation Loss: 6.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19075, Training Loss: 5.643e-01, Validation Loss: 6.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19076, Training Loss: 5.642e-01, Validation Loss: 6.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19077, Training Loss: 5.642e-01, Validation Loss: 6.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19078, Training Loss: 5.642e-01, Validation Loss: 6.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19079, Training Loss: 5.641e-01, Validation Loss: 6.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19080, Training Loss: 5.641e-01, Validation Loss: 6.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19081, Training Loss: 5.641e-01, Validation Loss: 6.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19082, Training Loss: 5.641e-01, Validation Loss: 6.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19083, Training Loss: 5.640e-01, Validation Loss: 6.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19084, Training Loss: 5.640e-01, Validation Loss: 6.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19085, Training Loss: 5.640e-01, Validation Loss: 6.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19086, Training Loss: 5.639e-01, Validation Loss: 6.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19087, Training Loss: 5.639e-01, Validation Loss: 6.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19088, Training Loss: 5.639e-01, Validation Loss: 6.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19089, Training Loss: 5.638e-01, Validation Loss: 6.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19090, Training Loss: 5.638e-01, Validation Loss: 6.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19091, Training Loss: 5.638e-01, Validation Loss: 6.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19092, Training Loss: 5.637e-01, Validation Loss: 6.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19093, Training Loss: 5.637e-01, Validation Loss: 6.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19094, Training Loss: 5.637e-01, Validation Loss: 6.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19095, Training Loss: 5.637e-01, Validation Loss: 6.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19096, Training Loss: 5.636e-01, Validation Loss: 6.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19097, Training Loss: 5.636e-01, Validation Loss: 6.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19098, Training Loss: 5.636e-01, Validation Loss: 6.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19099, Training Loss: 5.635e-01, Validation Loss: 6.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19100, Training Loss: 5.635e-01, Validation Loss: 6.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19101, Training Loss: 5.635e-01, Validation Loss: 6.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19102, Training Loss: 5.634e-01, Validation Loss: 6.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19103, Training Loss: 5.634e-01, Validation Loss: 6.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19104, Training Loss: 5.634e-01, Validation Loss: 6.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19105, Training Loss: 5.634e-01, Validation Loss: 6.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19106, Training Loss: 5.633e-01, Validation Loss: 6.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19107, Training Loss: 5.633e-01, Validation Loss: 6.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19108, Training Loss: 5.633e-01, Validation Loss: 6.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19109, Training Loss: 5.632e-01, Validation Loss: 6.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19110, Training Loss: 5.632e-01, Validation Loss: 6.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19111, Training Loss: 5.632e-01, Validation Loss: 6.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19112, Training Loss: 5.631e-01, Validation Loss: 6.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19113, Training Loss: 5.631e-01, Validation Loss: 6.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19114, Training Loss: 5.631e-01, Validation Loss: 6.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19115, Training Loss: 5.630e-01, Validation Loss: 6.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19116, Training Loss: 5.630e-01, Validation Loss: 6.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19117, Training Loss: 5.630e-01, Validation Loss: 6.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19118, Training Loss: 5.630e-01, Validation Loss: 6.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19119, Training Loss: 5.629e-01, Validation Loss: 6.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19120, Training Loss: 5.629e-01, Validation Loss: 6.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19121, Training Loss: 5.629e-01, Validation Loss: 6.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19122, Training Loss: 5.628e-01, Validation Loss: 6.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19123, Training Loss: 5.628e-01, Validation Loss: 6.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19124, Training Loss: 5.628e-01, Validation Loss: 6.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19125, Training Loss: 5.627e-01, Validation Loss: 6.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19126, Training Loss: 5.627e-01, Validation Loss: 6.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19127, Training Loss: 5.627e-01, Validation Loss: 6.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19128, Training Loss: 5.626e-01, Validation Loss: 6.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19129, Training Loss: 5.626e-01, Validation Loss: 6.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19130, Training Loss: 5.626e-01, Validation Loss: 6.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19131, Training Loss: 5.626e-01, Validation Loss: 6.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19132, Training Loss: 5.625e-01, Validation Loss: 6.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19133, Training Loss: 5.625e-01, Validation Loss: 6.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19134, Training Loss: 5.625e-01, Validation Loss: 6.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19135, Training Loss: 5.624e-01, Validation Loss: 6.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19136, Training Loss: 5.624e-01, Validation Loss: 6.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19137, Training Loss: 5.624e-01, Validation Loss: 6.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19138, Training Loss: 5.623e-01, Validation Loss: 6.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19139, Training Loss: 5.623e-01, Validation Loss: 6.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19140, Training Loss: 5.623e-01, Validation Loss: 6.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19141, Training Loss: 5.623e-01, Validation Loss: 6.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19142, Training Loss: 5.622e-01, Validation Loss: 6.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19143, Training Loss: 5.622e-01, Validation Loss: 6.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19144, Training Loss: 5.622e-01, Validation Loss: 6.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19145, Training Loss: 5.621e-01, Validation Loss: 6.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19146, Training Loss: 5.621e-01, Validation Loss: 6.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19147, Training Loss: 5.621e-01, Validation Loss: 6.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19148, Training Loss: 5.620e-01, Validation Loss: 6.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19149, Training Loss: 5.620e-01, Validation Loss: 6.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19150, Training Loss: 5.620e-01, Validation Loss: 6.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19151, Training Loss: 5.619e-01, Validation Loss: 6.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19152, Training Loss: 5.619e-01, Validation Loss: 6.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19153, Training Loss: 5.619e-01, Validation Loss: 6.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19154, Training Loss: 5.619e-01, Validation Loss: 6.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19155, Training Loss: 5.618e-01, Validation Loss: 6.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19156, Training Loss: 5.618e-01, Validation Loss: 6.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19157, Training Loss: 5.618e-01, Validation Loss: 6.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19158, Training Loss: 5.617e-01, Validation Loss: 6.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19159, Training Loss: 5.617e-01, Validation Loss: 6.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19160, Training Loss: 5.617e-01, Validation Loss: 6.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19161, Training Loss: 5.616e-01, Validation Loss: 6.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19162, Training Loss: 5.616e-01, Validation Loss: 6.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19163, Training Loss: 5.616e-01, Validation Loss: 6.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19164, Training Loss: 5.616e-01, Validation Loss: 6.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19165, Training Loss: 5.615e-01, Validation Loss: 6.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19166, Training Loss: 5.615e-01, Validation Loss: 6.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19167, Training Loss: 5.615e-01, Validation Loss: 6.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19168, Training Loss: 5.614e-01, Validation Loss: 6.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19169, Training Loss: 5.614e-01, Validation Loss: 6.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19170, Training Loss: 5.614e-01, Validation Loss: 6.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19171, Training Loss: 5.613e-01, Validation Loss: 6.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19172, Training Loss: 5.613e-01, Validation Loss: 6.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19173, Training Loss: 5.613e-01, Validation Loss: 6.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19174, Training Loss: 5.613e-01, Validation Loss: 6.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19175, Training Loss: 5.612e-01, Validation Loss: 6.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19176, Training Loss: 5.612e-01, Validation Loss: 6.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19177, Training Loss: 5.612e-01, Validation Loss: 6.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19178, Training Loss: 5.611e-01, Validation Loss: 6.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19179, Training Loss: 5.611e-01, Validation Loss: 6.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19180, Training Loss: 5.611e-01, Validation Loss: 6.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19181, Training Loss: 5.610e-01, Validation Loss: 6.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19182, Training Loss: 5.610e-01, Validation Loss: 6.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19183, Training Loss: 5.610e-01, Validation Loss: 6.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19184, Training Loss: 5.609e-01, Validation Loss: 6.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19185, Training Loss: 5.609e-01, Validation Loss: 6.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19186, Training Loss: 5.609e-01, Validation Loss: 6.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19187, Training Loss: 5.609e-01, Validation Loss: 6.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19188, Training Loss: 5.608e-01, Validation Loss: 6.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19189, Training Loss: 5.608e-01, Validation Loss: 6.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19190, Training Loss: 5.608e-01, Validation Loss: 6.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19191, Training Loss: 5.607e-01, Validation Loss: 6.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19192, Training Loss: 5.607e-01, Validation Loss: 6.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19193, Training Loss: 5.607e-01, Validation Loss: 6.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19194, Training Loss: 5.606e-01, Validation Loss: 6.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19195, Training Loss: 5.606e-01, Validation Loss: 6.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19196, Training Loss: 5.606e-01, Validation Loss: 6.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19197, Training Loss: 5.606e-01, Validation Loss: 6.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19198, Training Loss: 5.605e-01, Validation Loss: 6.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19199, Training Loss: 5.605e-01, Validation Loss: 6.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19200, Training Loss: 5.605e-01, Validation Loss: 6.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19201, Training Loss: 5.604e-01, Validation Loss: 6.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19202, Training Loss: 5.604e-01, Validation Loss: 6.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19203, Training Loss: 5.604e-01, Validation Loss: 6.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19204, Training Loss: 5.603e-01, Validation Loss: 6.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19205, Training Loss: 5.603e-01, Validation Loss: 6.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19206, Training Loss: 5.603e-01, Validation Loss: 6.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19207, Training Loss: 5.603e-01, Validation Loss: 6.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19208, Training Loss: 5.602e-01, Validation Loss: 6.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19209, Training Loss: 5.602e-01, Validation Loss: 6.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19210, Training Loss: 5.602e-01, Validation Loss: 6.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19211, Training Loss: 5.601e-01, Validation Loss: 6.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19212, Training Loss: 5.601e-01, Validation Loss: 6.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19213, Training Loss: 5.601e-01, Validation Loss: 6.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19214, Training Loss: 5.600e-01, Validation Loss: 6.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19215, Training Loss: 5.600e-01, Validation Loss: 6.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19216, Training Loss: 5.600e-01, Validation Loss: 6.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19217, Training Loss: 5.599e-01, Validation Loss: 6.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19218, Training Loss: 5.599e-01, Validation Loss: 6.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19219, Training Loss: 5.599e-01, Validation Loss: 6.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19220, Training Loss: 5.599e-01, Validation Loss: 6.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19221, Training Loss: 5.598e-01, Validation Loss: 6.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19222, Training Loss: 5.598e-01, Validation Loss: 6.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19223, Training Loss: 5.598e-01, Validation Loss: 6.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19224, Training Loss: 5.597e-01, Validation Loss: 6.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19225, Training Loss: 5.597e-01, Validation Loss: 6.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19226, Training Loss: 5.597e-01, Validation Loss: 6.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19227, Training Loss: 5.596e-01, Validation Loss: 6.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19228, Training Loss: 5.596e-01, Validation Loss: 6.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19229, Training Loss: 5.596e-01, Validation Loss: 6.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19230, Training Loss: 5.596e-01, Validation Loss: 6.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19231, Training Loss: 5.595e-01, Validation Loss: 6.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19232, Training Loss: 5.595e-01, Validation Loss: 6.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19233, Training Loss: 5.595e-01, Validation Loss: 6.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19234, Training Loss: 5.594e-01, Validation Loss: 6.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19235, Training Loss: 5.594e-01, Validation Loss: 6.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19236, Training Loss: 5.594e-01, Validation Loss: 6.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19237, Training Loss: 5.593e-01, Validation Loss: 6.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19238, Training Loss: 5.593e-01, Validation Loss: 6.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19239, Training Loss: 5.593e-01, Validation Loss: 6.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19240, Training Loss: 5.593e-01, Validation Loss: 6.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19241, Training Loss: 5.592e-01, Validation Loss: 6.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19242, Training Loss: 5.592e-01, Validation Loss: 6.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19243, Training Loss: 5.592e-01, Validation Loss: 6.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19244, Training Loss: 5.591e-01, Validation Loss: 6.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19245, Training Loss: 5.591e-01, Validation Loss: 6.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19246, Training Loss: 5.591e-01, Validation Loss: 6.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19247, Training Loss: 5.590e-01, Validation Loss: 6.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19248, Training Loss: 5.590e-01, Validation Loss: 6.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19249, Training Loss: 5.590e-01, Validation Loss: 6.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19250, Training Loss: 5.590e-01, Validation Loss: 6.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19251, Training Loss: 5.589e-01, Validation Loss: 6.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19252, Training Loss: 5.589e-01, Validation Loss: 6.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19253, Training Loss: 5.589e-01, Validation Loss: 6.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19254, Training Loss: 5.588e-01, Validation Loss: 6.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19255, Training Loss: 5.588e-01, Validation Loss: 6.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19256, Training Loss: 5.588e-01, Validation Loss: 6.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19257, Training Loss: 5.587e-01, Validation Loss: 6.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19258, Training Loss: 5.587e-01, Validation Loss: 6.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19259, Training Loss: 5.587e-01, Validation Loss: 6.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19260, Training Loss: 5.586e-01, Validation Loss: 6.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19261, Training Loss: 5.586e-01, Validation Loss: 6.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19262, Training Loss: 5.586e-01, Validation Loss: 6.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19263, Training Loss: 5.586e-01, Validation Loss: 6.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19264, Training Loss: 5.585e-01, Validation Loss: 6.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19265, Training Loss: 5.585e-01, Validation Loss: 6.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19266, Training Loss: 5.585e-01, Validation Loss: 6.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19267, Training Loss: 5.584e-01, Validation Loss: 6.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19268, Training Loss: 5.584e-01, Validation Loss: 6.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19269, Training Loss: 5.584e-01, Validation Loss: 6.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19270, Training Loss: 5.583e-01, Validation Loss: 6.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19271, Training Loss: 5.583e-01, Validation Loss: 6.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19272, Training Loss: 5.583e-01, Validation Loss: 6.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19273, Training Loss: 5.583e-01, Validation Loss: 6.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19274, Training Loss: 5.582e-01, Validation Loss: 6.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19275, Training Loss: 5.582e-01, Validation Loss: 6.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19276, Training Loss: 5.582e-01, Validation Loss: 6.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19277, Training Loss: 5.581e-01, Validation Loss: 6.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19278, Training Loss: 5.581e-01, Validation Loss: 6.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19279, Training Loss: 5.581e-01, Validation Loss: 6.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19280, Training Loss: 5.580e-01, Validation Loss: 6.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19281, Training Loss: 5.580e-01, Validation Loss: 6.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19282, Training Loss: 5.580e-01, Validation Loss: 6.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19283, Training Loss: 5.580e-01, Validation Loss: 6.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19284, Training Loss: 5.579e-01, Validation Loss: 6.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19285, Training Loss: 5.579e-01, Validation Loss: 6.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19286, Training Loss: 5.579e-01, Validation Loss: 6.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19287, Training Loss: 5.578e-01, Validation Loss: 6.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19288, Training Loss: 5.578e-01, Validation Loss: 6.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19289, Training Loss: 5.578e-01, Validation Loss: 6.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19290, Training Loss: 5.577e-01, Validation Loss: 6.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19291, Training Loss: 5.577e-01, Validation Loss: 6.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19292, Training Loss: 5.577e-01, Validation Loss: 6.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19293, Training Loss: 5.577e-01, Validation Loss: 6.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19294, Training Loss: 5.576e-01, Validation Loss: 6.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19295, Training Loss: 5.576e-01, Validation Loss: 6.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19296, Training Loss: 5.576e-01, Validation Loss: 6.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19297, Training Loss: 5.575e-01, Validation Loss: 6.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19298, Training Loss: 5.575e-01, Validation Loss: 6.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19299, Training Loss: 5.575e-01, Validation Loss: 6.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19300, Training Loss: 5.574e-01, Validation Loss: 6.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19301, Training Loss: 5.574e-01, Validation Loss: 6.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19302, Training Loss: 5.574e-01, Validation Loss: 6.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19303, Training Loss: 5.574e-01, Validation Loss: 6.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19304, Training Loss: 5.573e-01, Validation Loss: 6.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19305, Training Loss: 5.573e-01, Validation Loss: 6.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19306, Training Loss: 5.573e-01, Validation Loss: 6.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19307, Training Loss: 5.572e-01, Validation Loss: 6.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19308, Training Loss: 5.572e-01, Validation Loss: 6.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19309, Training Loss: 5.572e-01, Validation Loss: 6.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19310, Training Loss: 5.571e-01, Validation Loss: 6.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19311, Training Loss: 5.571e-01, Validation Loss: 6.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19312, Training Loss: 5.571e-01, Validation Loss: 6.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19313, Training Loss: 5.571e-01, Validation Loss: 6.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19314, Training Loss: 5.570e-01, Validation Loss: 6.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19315, Training Loss: 5.570e-01, Validation Loss: 6.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19316, Training Loss: 5.570e-01, Validation Loss: 6.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19317, Training Loss: 5.569e-01, Validation Loss: 6.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19318, Training Loss: 5.569e-01, Validation Loss: 6.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19319, Training Loss: 5.569e-01, Validation Loss: 6.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19320, Training Loss: 5.568e-01, Validation Loss: 6.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19321, Training Loss: 5.568e-01, Validation Loss: 6.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19322, Training Loss: 5.568e-01, Validation Loss: 6.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19323, Training Loss: 5.568e-01, Validation Loss: 6.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19324, Training Loss: 5.567e-01, Validation Loss: 6.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19325, Training Loss: 5.567e-01, Validation Loss: 6.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19326, Training Loss: 5.567e-01, Validation Loss: 6.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19327, Training Loss: 5.566e-01, Validation Loss: 6.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19328, Training Loss: 5.566e-01, Validation Loss: 6.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19329, Training Loss: 5.566e-01, Validation Loss: 6.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19330, Training Loss: 5.565e-01, Validation Loss: 6.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19331, Training Loss: 5.565e-01, Validation Loss: 6.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19332, Training Loss: 5.565e-01, Validation Loss: 6.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19333, Training Loss: 5.565e-01, Validation Loss: 6.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19334, Training Loss: 5.564e-01, Validation Loss: 6.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19335, Training Loss: 5.564e-01, Validation Loss: 6.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19336, Training Loss: 5.564e-01, Validation Loss: 6.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19337, Training Loss: 5.563e-01, Validation Loss: 6.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19338, Training Loss: 5.563e-01, Validation Loss: 6.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19339, Training Loss: 5.563e-01, Validation Loss: 6.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19340, Training Loss: 5.562e-01, Validation Loss: 6.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19341, Training Loss: 5.562e-01, Validation Loss: 6.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19342, Training Loss: 5.562e-01, Validation Loss: 6.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19343, Training Loss: 5.562e-01, Validation Loss: 6.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19344, Training Loss: 5.561e-01, Validation Loss: 6.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19345, Training Loss: 5.561e-01, Validation Loss: 6.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19346, Training Loss: 5.561e-01, Validation Loss: 6.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19347, Training Loss: 5.560e-01, Validation Loss: 6.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19348, Training Loss: 5.560e-01, Validation Loss: 6.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19349, Training Loss: 5.560e-01, Validation Loss: 6.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19350, Training Loss: 5.559e-01, Validation Loss: 6.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19351, Training Loss: 5.559e-01, Validation Loss: 6.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19352, Training Loss: 5.559e-01, Validation Loss: 6.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19353, Training Loss: 5.559e-01, Validation Loss: 6.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19354, Training Loss: 5.558e-01, Validation Loss: 6.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19355, Training Loss: 5.558e-01, Validation Loss: 6.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19356, Training Loss: 5.558e-01, Validation Loss: 6.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19357, Training Loss: 5.557e-01, Validation Loss: 6.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19358, Training Loss: 5.557e-01, Validation Loss: 6.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19359, Training Loss: 5.557e-01, Validation Loss: 6.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19360, Training Loss: 5.557e-01, Validation Loss: 6.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19361, Training Loss: 5.556e-01, Validation Loss: 6.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19362, Training Loss: 5.556e-01, Validation Loss: 6.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19363, Training Loss: 5.556e-01, Validation Loss: 6.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19364, Training Loss: 5.555e-01, Validation Loss: 6.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19365, Training Loss: 5.555e-01, Validation Loss: 6.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19366, Training Loss: 5.555e-01, Validation Loss: 6.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19367, Training Loss: 5.554e-01, Validation Loss: 6.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19368, Training Loss: 5.554e-01, Validation Loss: 6.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19369, Training Loss: 5.554e-01, Validation Loss: 6.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19370, Training Loss: 5.554e-01, Validation Loss: 6.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19371, Training Loss: 5.553e-01, Validation Loss: 6.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19372, Training Loss: 5.553e-01, Validation Loss: 6.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19373, Training Loss: 5.553e-01, Validation Loss: 6.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19374, Training Loss: 5.552e-01, Validation Loss: 6.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19375, Training Loss: 5.552e-01, Validation Loss: 6.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19376, Training Loss: 5.552e-01, Validation Loss: 6.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19377, Training Loss: 5.551e-01, Validation Loss: 6.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19378, Training Loss: 5.551e-01, Validation Loss: 6.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19379, Training Loss: 5.551e-01, Validation Loss: 6.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19380, Training Loss: 5.551e-01, Validation Loss: 6.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19381, Training Loss: 5.550e-01, Validation Loss: 6.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19382, Training Loss: 5.550e-01, Validation Loss: 6.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19383, Training Loss: 5.550e-01, Validation Loss: 6.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19384, Training Loss: 5.549e-01, Validation Loss: 6.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19385, Training Loss: 5.549e-01, Validation Loss: 6.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19386, Training Loss: 5.549e-01, Validation Loss: 6.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19387, Training Loss: 5.548e-01, Validation Loss: 6.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19388, Training Loss: 5.548e-01, Validation Loss: 6.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19389, Training Loss: 5.548e-01, Validation Loss: 6.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19390, Training Loss: 5.548e-01, Validation Loss: 6.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19391, Training Loss: 5.547e-01, Validation Loss: 6.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19392, Training Loss: 5.547e-01, Validation Loss: 6.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19393, Training Loss: 5.547e-01, Validation Loss: 6.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19394, Training Loss: 5.546e-01, Validation Loss: 6.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19395, Training Loss: 5.546e-01, Validation Loss: 6.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19396, Training Loss: 5.546e-01, Validation Loss: 6.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19397, Training Loss: 5.545e-01, Validation Loss: 6.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19398, Training Loss: 5.545e-01, Validation Loss: 6.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19399, Training Loss: 5.545e-01, Validation Loss: 6.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19400, Training Loss: 5.545e-01, Validation Loss: 6.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19401, Training Loss: 5.544e-01, Validation Loss: 6.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19402, Training Loss: 5.544e-01, Validation Loss: 6.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19403, Training Loss: 5.544e-01, Validation Loss: 6.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19404, Training Loss: 5.543e-01, Validation Loss: 6.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19405, Training Loss: 5.543e-01, Validation Loss: 6.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19406, Training Loss: 5.543e-01, Validation Loss: 6.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19407, Training Loss: 5.543e-01, Validation Loss: 6.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19408, Training Loss: 5.542e-01, Validation Loss: 6.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19409, Training Loss: 5.542e-01, Validation Loss: 6.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19410, Training Loss: 5.542e-01, Validation Loss: 6.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19411, Training Loss: 5.541e-01, Validation Loss: 6.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19412, Training Loss: 5.541e-01, Validation Loss: 6.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19413, Training Loss: 5.541e-01, Validation Loss: 6.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19414, Training Loss: 5.540e-01, Validation Loss: 6.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19415, Training Loss: 5.540e-01, Validation Loss: 6.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19416, Training Loss: 5.540e-01, Validation Loss: 6.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19417, Training Loss: 5.540e-01, Validation Loss: 6.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19418, Training Loss: 5.539e-01, Validation Loss: 6.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19419, Training Loss: 5.539e-01, Validation Loss: 6.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19420, Training Loss: 5.539e-01, Validation Loss: 6.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19421, Training Loss: 5.538e-01, Validation Loss: 6.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19422, Training Loss: 5.538e-01, Validation Loss: 6.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19423, Training Loss: 5.538e-01, Validation Loss: 6.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19424, Training Loss: 5.537e-01, Validation Loss: 6.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19425, Training Loss: 5.537e-01, Validation Loss: 6.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19426, Training Loss: 5.537e-01, Validation Loss: 6.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19427, Training Loss: 5.537e-01, Validation Loss: 6.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19428, Training Loss: 5.536e-01, Validation Loss: 6.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19429, Training Loss: 5.536e-01, Validation Loss: 6.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19430, Training Loss: 5.536e-01, Validation Loss: 6.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19431, Training Loss: 5.535e-01, Validation Loss: 6.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19432, Training Loss: 5.535e-01, Validation Loss: 6.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19433, Training Loss: 5.535e-01, Validation Loss: 6.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19434, Training Loss: 5.534e-01, Validation Loss: 6.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19435, Training Loss: 5.534e-01, Validation Loss: 6.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19436, Training Loss: 5.534e-01, Validation Loss: 6.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19437, Training Loss: 5.534e-01, Validation Loss: 6.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19438, Training Loss: 5.533e-01, Validation Loss: 6.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19439, Training Loss: 5.533e-01, Validation Loss: 6.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19440, Training Loss: 5.533e-01, Validation Loss: 6.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19441, Training Loss: 5.532e-01, Validation Loss: 6.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19442, Training Loss: 5.532e-01, Validation Loss: 6.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19443, Training Loss: 5.532e-01, Validation Loss: 6.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19444, Training Loss: 5.532e-01, Validation Loss: 6.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19445, Training Loss: 5.531e-01, Validation Loss: 6.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19446, Training Loss: 5.531e-01, Validation Loss: 6.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19447, Training Loss: 5.531e-01, Validation Loss: 6.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19448, Training Loss: 5.530e-01, Validation Loss: 6.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19449, Training Loss: 5.530e-01, Validation Loss: 6.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19450, Training Loss: 5.530e-01, Validation Loss: 6.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19451, Training Loss: 5.529e-01, Validation Loss: 6.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19452, Training Loss: 5.529e-01, Validation Loss: 6.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19453, Training Loss: 5.529e-01, Validation Loss: 6.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19454, Training Loss: 5.529e-01, Validation Loss: 6.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19455, Training Loss: 5.528e-01, Validation Loss: 6.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19456, Training Loss: 5.528e-01, Validation Loss: 6.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19457, Training Loss: 5.528e-01, Validation Loss: 6.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19458, Training Loss: 5.527e-01, Validation Loss: 6.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19459, Training Loss: 5.527e-01, Validation Loss: 6.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19460, Training Loss: 5.527e-01, Validation Loss: 6.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19461, Training Loss: 5.527e-01, Validation Loss: 6.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19462, Training Loss: 5.526e-01, Validation Loss: 6.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19463, Training Loss: 5.526e-01, Validation Loss: 6.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19464, Training Loss: 5.526e-01, Validation Loss: 6.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19465, Training Loss: 5.525e-01, Validation Loss: 6.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19466, Training Loss: 5.525e-01, Validation Loss: 6.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19467, Training Loss: 5.525e-01, Validation Loss: 6.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19468, Training Loss: 5.524e-01, Validation Loss: 6.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19469, Training Loss: 5.524e-01, Validation Loss: 6.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19470, Training Loss: 5.524e-01, Validation Loss: 6.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19471, Training Loss: 5.524e-01, Validation Loss: 6.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19472, Training Loss: 5.523e-01, Validation Loss: 6.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19473, Training Loss: 5.523e-01, Validation Loss: 6.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19474, Training Loss: 5.523e-01, Validation Loss: 6.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19475, Training Loss: 5.522e-01, Validation Loss: 6.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19476, Training Loss: 5.522e-01, Validation Loss: 6.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19477, Training Loss: 5.522e-01, Validation Loss: 6.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19478, Training Loss: 5.521e-01, Validation Loss: 6.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19479, Training Loss: 5.521e-01, Validation Loss: 6.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19480, Training Loss: 5.521e-01, Validation Loss: 6.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19481, Training Loss: 5.521e-01, Validation Loss: 6.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19482, Training Loss: 5.520e-01, Validation Loss: 6.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19483, Training Loss: 5.520e-01, Validation Loss: 6.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19484, Training Loss: 5.520e-01, Validation Loss: 6.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19485, Training Loss: 5.519e-01, Validation Loss: 6.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19486, Training Loss: 5.519e-01, Validation Loss: 6.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19487, Training Loss: 5.519e-01, Validation Loss: 6.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19488, Training Loss: 5.519e-01, Validation Loss: 6.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19489, Training Loss: 5.518e-01, Validation Loss: 6.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19490, Training Loss: 5.518e-01, Validation Loss: 6.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19491, Training Loss: 5.518e-01, Validation Loss: 6.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19492, Training Loss: 5.517e-01, Validation Loss: 6.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19493, Training Loss: 5.517e-01, Validation Loss: 6.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19494, Training Loss: 5.517e-01, Validation Loss: 6.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19495, Training Loss: 5.516e-01, Validation Loss: 6.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19496, Training Loss: 5.516e-01, Validation Loss: 6.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19497, Training Loss: 5.516e-01, Validation Loss: 6.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19498, Training Loss: 5.516e-01, Validation Loss: 6.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19499, Training Loss: 5.515e-01, Validation Loss: 6.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19500, Training Loss: 5.515e-01, Validation Loss: 6.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19501, Training Loss: 5.515e-01, Validation Loss: 6.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19502, Training Loss: 5.514e-01, Validation Loss: 6.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19503, Training Loss: 5.514e-01, Validation Loss: 6.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19504, Training Loss: 5.514e-01, Validation Loss: 6.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19505, Training Loss: 5.514e-01, Validation Loss: 6.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19506, Training Loss: 5.513e-01, Validation Loss: 6.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19507, Training Loss: 5.513e-01, Validation Loss: 6.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19508, Training Loss: 5.513e-01, Validation Loss: 6.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19509, Training Loss: 5.512e-01, Validation Loss: 6.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19510, Training Loss: 5.512e-01, Validation Loss: 6.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19511, Training Loss: 5.512e-01, Validation Loss: 6.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19512, Training Loss: 5.511e-01, Validation Loss: 6.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19513, Training Loss: 5.511e-01, Validation Loss: 6.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19514, Training Loss: 5.511e-01, Validation Loss: 6.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19515, Training Loss: 5.511e-01, Validation Loss: 6.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19516, Training Loss: 5.510e-01, Validation Loss: 6.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19517, Training Loss: 5.510e-01, Validation Loss: 6.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19518, Training Loss: 5.510e-01, Validation Loss: 6.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19519, Training Loss: 5.509e-01, Validation Loss: 6.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19520, Training Loss: 5.509e-01, Validation Loss: 6.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19521, Training Loss: 5.509e-01, Validation Loss: 6.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19522, Training Loss: 5.509e-01, Validation Loss: 6.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19523, Training Loss: 5.508e-01, Validation Loss: 6.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19524, Training Loss: 5.508e-01, Validation Loss: 6.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19525, Training Loss: 5.508e-01, Validation Loss: 6.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19526, Training Loss: 5.507e-01, Validation Loss: 6.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19527, Training Loss: 5.507e-01, Validation Loss: 6.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19528, Training Loss: 5.507e-01, Validation Loss: 6.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19529, Training Loss: 5.506e-01, Validation Loss: 6.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19530, Training Loss: 5.506e-01, Validation Loss: 6.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19531, Training Loss: 5.506e-01, Validation Loss: 6.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19532, Training Loss: 5.506e-01, Validation Loss: 6.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19533, Training Loss: 5.505e-01, Validation Loss: 6.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19534, Training Loss: 5.505e-01, Validation Loss: 6.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19535, Training Loss: 5.505e-01, Validation Loss: 6.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19536, Training Loss: 5.504e-01, Validation Loss: 6.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19537, Training Loss: 5.504e-01, Validation Loss: 6.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19538, Training Loss: 5.504e-01, Validation Loss: 6.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19539, Training Loss: 5.504e-01, Validation Loss: 6.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19540, Training Loss: 5.503e-01, Validation Loss: 6.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19541, Training Loss: 5.503e-01, Validation Loss: 6.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19542, Training Loss: 5.503e-01, Validation Loss: 6.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19543, Training Loss: 5.502e-01, Validation Loss: 6.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19544, Training Loss: 5.502e-01, Validation Loss: 6.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19545, Training Loss: 5.502e-01, Validation Loss: 6.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19546, Training Loss: 5.501e-01, Validation Loss: 6.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19547, Training Loss: 5.501e-01, Validation Loss: 6.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19548, Training Loss: 5.501e-01, Validation Loss: 6.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19549, Training Loss: 5.501e-01, Validation Loss: 6.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19550, Training Loss: 5.500e-01, Validation Loss: 6.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19551, Training Loss: 5.500e-01, Validation Loss: 6.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19552, Training Loss: 5.500e-01, Validation Loss: 6.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19553, Training Loss: 5.499e-01, Validation Loss: 6.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19554, Training Loss: 5.499e-01, Validation Loss: 6.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19555, Training Loss: 5.499e-01, Validation Loss: 6.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19556, Training Loss: 5.499e-01, Validation Loss: 6.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19557, Training Loss: 5.498e-01, Validation Loss: 6.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19558, Training Loss: 5.498e-01, Validation Loss: 6.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19559, Training Loss: 5.498e-01, Validation Loss: 6.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19560, Training Loss: 5.497e-01, Validation Loss: 6.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19561, Training Loss: 5.497e-01, Validation Loss: 6.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19562, Training Loss: 5.497e-01, Validation Loss: 6.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19563, Training Loss: 5.496e-01, Validation Loss: 6.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19564, Training Loss: 5.496e-01, Validation Loss: 6.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19565, Training Loss: 5.496e-01, Validation Loss: 6.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19566, Training Loss: 5.496e-01, Validation Loss: 6.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19567, Training Loss: 5.495e-01, Validation Loss: 6.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19568, Training Loss: 5.495e-01, Validation Loss: 6.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19569, Training Loss: 5.495e-01, Validation Loss: 6.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19570, Training Loss: 5.494e-01, Validation Loss: 6.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19571, Training Loss: 5.494e-01, Validation Loss: 6.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19572, Training Loss: 5.494e-01, Validation Loss: 6.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19573, Training Loss: 5.494e-01, Validation Loss: 6.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19574, Training Loss: 5.493e-01, Validation Loss: 6.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19575, Training Loss: 5.493e-01, Validation Loss: 6.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19576, Training Loss: 5.493e-01, Validation Loss: 6.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19577, Training Loss: 5.492e-01, Validation Loss: 6.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19578, Training Loss: 5.492e-01, Validation Loss: 6.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19579, Training Loss: 5.492e-01, Validation Loss: 6.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19580, Training Loss: 5.491e-01, Validation Loss: 6.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19581, Training Loss: 5.491e-01, Validation Loss: 6.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19582, Training Loss: 5.491e-01, Validation Loss: 6.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19583, Training Loss: 5.491e-01, Validation Loss: 6.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19584, Training Loss: 5.490e-01, Validation Loss: 6.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19585, Training Loss: 5.490e-01, Validation Loss: 6.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19586, Training Loss: 5.490e-01, Validation Loss: 6.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19587, Training Loss: 5.489e-01, Validation Loss: 6.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19588, Training Loss: 5.489e-01, Validation Loss: 6.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19589, Training Loss: 5.489e-01, Validation Loss: 6.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19590, Training Loss: 5.489e-01, Validation Loss: 6.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19591, Training Loss: 5.488e-01, Validation Loss: 6.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19592, Training Loss: 5.488e-01, Validation Loss: 6.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19593, Training Loss: 5.488e-01, Validation Loss: 6.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19594, Training Loss: 5.487e-01, Validation Loss: 6.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19595, Training Loss: 5.487e-01, Validation Loss: 6.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19596, Training Loss: 5.487e-01, Validation Loss: 6.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19597, Training Loss: 5.487e-01, Validation Loss: 6.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19598, Training Loss: 5.486e-01, Validation Loss: 6.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19599, Training Loss: 5.486e-01, Validation Loss: 6.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19600, Training Loss: 5.486e-01, Validation Loss: 6.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19601, Training Loss: 5.485e-01, Validation Loss: 6.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19602, Training Loss: 5.485e-01, Validation Loss: 6.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19603, Training Loss: 5.485e-01, Validation Loss: 6.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19604, Training Loss: 5.484e-01, Validation Loss: 6.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19605, Training Loss: 5.484e-01, Validation Loss: 6.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19606, Training Loss: 5.484e-01, Validation Loss: 6.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19607, Training Loss: 5.484e-01, Validation Loss: 6.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19608, Training Loss: 5.483e-01, Validation Loss: 6.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19609, Training Loss: 5.483e-01, Validation Loss: 6.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19610, Training Loss: 5.483e-01, Validation Loss: 6.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19611, Training Loss: 5.482e-01, Validation Loss: 6.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19612, Training Loss: 5.482e-01, Validation Loss: 6.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19613, Training Loss: 5.482e-01, Validation Loss: 6.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19614, Training Loss: 5.482e-01, Validation Loss: 6.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19615, Training Loss: 5.481e-01, Validation Loss: 6.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19616, Training Loss: 5.481e-01, Validation Loss: 6.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19617, Training Loss: 5.481e-01, Validation Loss: 6.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19618, Training Loss: 5.480e-01, Validation Loss: 6.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19619, Training Loss: 5.480e-01, Validation Loss: 6.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19620, Training Loss: 5.480e-01, Validation Loss: 6.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19621, Training Loss: 5.480e-01, Validation Loss: 6.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19622, Training Loss: 5.479e-01, Validation Loss: 6.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19623, Training Loss: 5.479e-01, Validation Loss: 6.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19624, Training Loss: 5.479e-01, Validation Loss: 6.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19625, Training Loss: 5.478e-01, Validation Loss: 6.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19626, Training Loss: 5.478e-01, Validation Loss: 6.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19627, Training Loss: 5.478e-01, Validation Loss: 6.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19628, Training Loss: 5.477e-01, Validation Loss: 6.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19629, Training Loss: 5.477e-01, Validation Loss: 6.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19630, Training Loss: 5.477e-01, Validation Loss: 6.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19631, Training Loss: 5.477e-01, Validation Loss: 6.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19632, Training Loss: 5.476e-01, Validation Loss: 6.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19633, Training Loss: 5.476e-01, Validation Loss: 6.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19634, Training Loss: 5.476e-01, Validation Loss: 6.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19635, Training Loss: 5.475e-01, Validation Loss: 6.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19636, Training Loss: 5.475e-01, Validation Loss: 6.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19637, Training Loss: 5.475e-01, Validation Loss: 6.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19638, Training Loss: 5.475e-01, Validation Loss: 6.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19639, Training Loss: 5.474e-01, Validation Loss: 6.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19640, Training Loss: 5.474e-01, Validation Loss: 6.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19641, Training Loss: 5.474e-01, Validation Loss: 6.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19642, Training Loss: 5.473e-01, Validation Loss: 6.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19643, Training Loss: 5.473e-01, Validation Loss: 6.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19644, Training Loss: 5.473e-01, Validation Loss: 6.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19645, Training Loss: 5.473e-01, Validation Loss: 6.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19646, Training Loss: 5.472e-01, Validation Loss: 6.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19647, Training Loss: 5.472e-01, Validation Loss: 6.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19648, Training Loss: 5.472e-01, Validation Loss: 6.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19649, Training Loss: 5.471e-01, Validation Loss: 6.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19650, Training Loss: 5.471e-01, Validation Loss: 6.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19651, Training Loss: 5.471e-01, Validation Loss: 6.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19652, Training Loss: 5.470e-01, Validation Loss: 6.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19653, Training Loss: 5.470e-01, Validation Loss: 6.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19654, Training Loss: 5.470e-01, Validation Loss: 6.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19655, Training Loss: 5.470e-01, Validation Loss: 6.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19656, Training Loss: 5.469e-01, Validation Loss: 6.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19657, Training Loss: 5.469e-01, Validation Loss: 6.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19658, Training Loss: 5.469e-01, Validation Loss: 6.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19659, Training Loss: 5.468e-01, Validation Loss: 6.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19660, Training Loss: 5.468e-01, Validation Loss: 6.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19661, Training Loss: 5.468e-01, Validation Loss: 6.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19662, Training Loss: 5.468e-01, Validation Loss: 6.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19663, Training Loss: 5.467e-01, Validation Loss: 6.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19664, Training Loss: 5.467e-01, Validation Loss: 6.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19665, Training Loss: 5.467e-01, Validation Loss: 6.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19666, Training Loss: 5.466e-01, Validation Loss: 6.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19667, Training Loss: 5.466e-01, Validation Loss: 6.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19668, Training Loss: 5.466e-01, Validation Loss: 6.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19669, Training Loss: 5.466e-01, Validation Loss: 6.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19670, Training Loss: 5.465e-01, Validation Loss: 6.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19671, Training Loss: 5.465e-01, Validation Loss: 6.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19672, Training Loss: 5.465e-01, Validation Loss: 6.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19673, Training Loss: 5.464e-01, Validation Loss: 6.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19674, Training Loss: 5.464e-01, Validation Loss: 6.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19675, Training Loss: 5.464e-01, Validation Loss: 6.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19676, Training Loss: 5.464e-01, Validation Loss: 6.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19677, Training Loss: 5.463e-01, Validation Loss: 6.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19678, Training Loss: 5.463e-01, Validation Loss: 6.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19679, Training Loss: 5.463e-01, Validation Loss: 6.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19680, Training Loss: 5.462e-01, Validation Loss: 6.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19681, Training Loss: 5.462e-01, Validation Loss: 6.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19682, Training Loss: 5.462e-01, Validation Loss: 6.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19683, Training Loss: 5.461e-01, Validation Loss: 6.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19684, Training Loss: 5.461e-01, Validation Loss: 6.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19685, Training Loss: 5.461e-01, Validation Loss: 6.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19686, Training Loss: 5.461e-01, Validation Loss: 6.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19687, Training Loss: 5.460e-01, Validation Loss: 6.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19688, Training Loss: 5.460e-01, Validation Loss: 6.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19689, Training Loss: 5.460e-01, Validation Loss: 6.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19690, Training Loss: 5.459e-01, Validation Loss: 6.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19691, Training Loss: 5.459e-01, Validation Loss: 6.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19692, Training Loss: 5.459e-01, Validation Loss: 6.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19693, Training Loss: 5.459e-01, Validation Loss: 6.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19694, Training Loss: 5.458e-01, Validation Loss: 6.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19695, Training Loss: 5.458e-01, Validation Loss: 6.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19696, Training Loss: 5.458e-01, Validation Loss: 6.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19697, Training Loss: 5.457e-01, Validation Loss: 6.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19698, Training Loss: 5.457e-01, Validation Loss: 6.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19699, Training Loss: 5.457e-01, Validation Loss: 6.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19700, Training Loss: 5.457e-01, Validation Loss: 6.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19701, Training Loss: 5.456e-01, Validation Loss: 6.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19702, Training Loss: 5.456e-01, Validation Loss: 6.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19703, Training Loss: 5.456e-01, Validation Loss: 6.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19704, Training Loss: 5.455e-01, Validation Loss: 6.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19705, Training Loss: 5.455e-01, Validation Loss: 6.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19706, Training Loss: 5.455e-01, Validation Loss: 6.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19707, Training Loss: 5.455e-01, Validation Loss: 6.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19708, Training Loss: 5.454e-01, Validation Loss: 6.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19709, Training Loss: 5.454e-01, Validation Loss: 6.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19710, Training Loss: 5.454e-01, Validation Loss: 6.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19711, Training Loss: 5.453e-01, Validation Loss: 6.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19712, Training Loss: 5.453e-01, Validation Loss: 6.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19713, Training Loss: 5.453e-01, Validation Loss: 6.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19714, Training Loss: 5.453e-01, Validation Loss: 6.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19715, Training Loss: 5.452e-01, Validation Loss: 6.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19716, Training Loss: 5.452e-01, Validation Loss: 6.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19717, Training Loss: 5.452e-01, Validation Loss: 6.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19718, Training Loss: 5.451e-01, Validation Loss: 6.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19719, Training Loss: 5.451e-01, Validation Loss: 6.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19720, Training Loss: 5.451e-01, Validation Loss: 6.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19721, Training Loss: 5.451e-01, Validation Loss: 6.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19722, Training Loss: 5.450e-01, Validation Loss: 6.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19723, Training Loss: 5.450e-01, Validation Loss: 6.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19724, Training Loss: 5.450e-01, Validation Loss: 6.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19725, Training Loss: 5.449e-01, Validation Loss: 6.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19726, Training Loss: 5.449e-01, Validation Loss: 6.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19727, Training Loss: 5.449e-01, Validation Loss: 6.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19728, Training Loss: 5.448e-01, Validation Loss: 6.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19729, Training Loss: 5.448e-01, Validation Loss: 6.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19730, Training Loss: 5.448e-01, Validation Loss: 6.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19731, Training Loss: 5.448e-01, Validation Loss: 6.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19732, Training Loss: 5.447e-01, Validation Loss: 6.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19733, Training Loss: 5.447e-01, Validation Loss: 6.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19734, Training Loss: 5.447e-01, Validation Loss: 6.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19735, Training Loss: 5.446e-01, Validation Loss: 6.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19736, Training Loss: 5.446e-01, Validation Loss: 6.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19737, Training Loss: 5.446e-01, Validation Loss: 6.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19738, Training Loss: 5.446e-01, Validation Loss: 6.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19739, Training Loss: 5.445e-01, Validation Loss: 6.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19740, Training Loss: 5.445e-01, Validation Loss: 6.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19741, Training Loss: 5.445e-01, Validation Loss: 6.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19742, Training Loss: 5.444e-01, Validation Loss: 6.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19743, Training Loss: 5.444e-01, Validation Loss: 6.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19744, Training Loss: 5.444e-01, Validation Loss: 6.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19745, Training Loss: 5.444e-01, Validation Loss: 6.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19746, Training Loss: 5.443e-01, Validation Loss: 6.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19747, Training Loss: 5.443e-01, Validation Loss: 6.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19748, Training Loss: 5.443e-01, Validation Loss: 6.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19749, Training Loss: 5.442e-01, Validation Loss: 6.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19750, Training Loss: 5.442e-01, Validation Loss: 6.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19751, Training Loss: 5.442e-01, Validation Loss: 6.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19752, Training Loss: 5.442e-01, Validation Loss: 6.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19753, Training Loss: 5.441e-01, Validation Loss: 6.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19754, Training Loss: 5.441e-01, Validation Loss: 6.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19755, Training Loss: 5.441e-01, Validation Loss: 6.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19756, Training Loss: 5.440e-01, Validation Loss: 6.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19757, Training Loss: 5.440e-01, Validation Loss: 6.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19758, Training Loss: 5.440e-01, Validation Loss: 6.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19759, Training Loss: 5.440e-01, Validation Loss: 6.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19760, Training Loss: 5.439e-01, Validation Loss: 6.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19761, Training Loss: 5.439e-01, Validation Loss: 6.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19762, Training Loss: 5.439e-01, Validation Loss: 6.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19763, Training Loss: 5.438e-01, Validation Loss: 6.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19764, Training Loss: 5.438e-01, Validation Loss: 6.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19765, Training Loss: 5.438e-01, Validation Loss: 6.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19766, Training Loss: 5.438e-01, Validation Loss: 6.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19767, Training Loss: 5.437e-01, Validation Loss: 6.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19768, Training Loss: 5.437e-01, Validation Loss: 6.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19769, Training Loss: 5.437e-01, Validation Loss: 6.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19770, Training Loss: 5.436e-01, Validation Loss: 6.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19771, Training Loss: 5.436e-01, Validation Loss: 6.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19772, Training Loss: 5.436e-01, Validation Loss: 6.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19773, Training Loss: 5.436e-01, Validation Loss: 6.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19774, Training Loss: 5.435e-01, Validation Loss: 6.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19775, Training Loss: 5.435e-01, Validation Loss: 6.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19776, Training Loss: 5.435e-01, Validation Loss: 6.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19777, Training Loss: 5.434e-01, Validation Loss: 6.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19778, Training Loss: 5.434e-01, Validation Loss: 6.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19779, Training Loss: 5.434e-01, Validation Loss: 6.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19780, Training Loss: 5.434e-01, Validation Loss: 6.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19781, Training Loss: 5.433e-01, Validation Loss: 6.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19782, Training Loss: 5.433e-01, Validation Loss: 6.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19783, Training Loss: 5.433e-01, Validation Loss: 6.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19784, Training Loss: 5.432e-01, Validation Loss: 6.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19785, Training Loss: 5.432e-01, Validation Loss: 6.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19786, Training Loss: 5.432e-01, Validation Loss: 6.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19787, Training Loss: 5.431e-01, Validation Loss: 6.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19788, Training Loss: 5.431e-01, Validation Loss: 6.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19789, Training Loss: 5.431e-01, Validation Loss: 6.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19790, Training Loss: 5.431e-01, Validation Loss: 6.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19791, Training Loss: 5.430e-01, Validation Loss: 6.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19792, Training Loss: 5.430e-01, Validation Loss: 6.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19793, Training Loss: 5.430e-01, Validation Loss: 6.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19794, Training Loss: 5.429e-01, Validation Loss: 6.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19795, Training Loss: 5.429e-01, Validation Loss: 6.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19796, Training Loss: 5.429e-01, Validation Loss: 6.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19797, Training Loss: 5.429e-01, Validation Loss: 6.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19798, Training Loss: 5.428e-01, Validation Loss: 6.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19799, Training Loss: 5.428e-01, Validation Loss: 6.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19800, Training Loss: 5.428e-01, Validation Loss: 6.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19801, Training Loss: 5.427e-01, Validation Loss: 6.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19802, Training Loss: 5.427e-01, Validation Loss: 6.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19803, Training Loss: 5.427e-01, Validation Loss: 6.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19804, Training Loss: 5.427e-01, Validation Loss: 6.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19805, Training Loss: 5.426e-01, Validation Loss: 6.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19806, Training Loss: 5.426e-01, Validation Loss: 6.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19807, Training Loss: 5.426e-01, Validation Loss: 6.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19808, Training Loss: 5.425e-01, Validation Loss: 6.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19809, Training Loss: 5.425e-01, Validation Loss: 6.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19810, Training Loss: 5.425e-01, Validation Loss: 6.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19811, Training Loss: 5.425e-01, Validation Loss: 6.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19812, Training Loss: 5.424e-01, Validation Loss: 6.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19813, Training Loss: 5.424e-01, Validation Loss: 6.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19814, Training Loss: 5.424e-01, Validation Loss: 6.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19815, Training Loss: 5.423e-01, Validation Loss: 6.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19816, Training Loss: 5.423e-01, Validation Loss: 6.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19817, Training Loss: 5.423e-01, Validation Loss: 6.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19818, Training Loss: 5.423e-01, Validation Loss: 6.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19819, Training Loss: 5.422e-01, Validation Loss: 6.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19820, Training Loss: 5.422e-01, Validation Loss: 6.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19821, Training Loss: 5.422e-01, Validation Loss: 6.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19822, Training Loss: 5.421e-01, Validation Loss: 6.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19823, Training Loss: 5.421e-01, Validation Loss: 6.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19824, Training Loss: 5.421e-01, Validation Loss: 6.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19825, Training Loss: 5.421e-01, Validation Loss: 6.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19826, Training Loss: 5.420e-01, Validation Loss: 6.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19827, Training Loss: 5.420e-01, Validation Loss: 6.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19828, Training Loss: 5.420e-01, Validation Loss: 6.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19829, Training Loss: 5.419e-01, Validation Loss: 6.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19830, Training Loss: 5.419e-01, Validation Loss: 6.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19831, Training Loss: 5.419e-01, Validation Loss: 6.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19832, Training Loss: 5.419e-01, Validation Loss: 6.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19833, Training Loss: 5.418e-01, Validation Loss: 6.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19834, Training Loss: 5.418e-01, Validation Loss: 6.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19835, Training Loss: 5.418e-01, Validation Loss: 6.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19836, Training Loss: 5.417e-01, Validation Loss: 6.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19837, Training Loss: 5.417e-01, Validation Loss: 6.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19838, Training Loss: 5.417e-01, Validation Loss: 6.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19839, Training Loss: 5.417e-01, Validation Loss: 6.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19840, Training Loss: 5.416e-01, Validation Loss: 6.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19841, Training Loss: 5.416e-01, Validation Loss: 6.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19842, Training Loss: 5.416e-01, Validation Loss: 6.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19843, Training Loss: 5.415e-01, Validation Loss: 6.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19844, Training Loss: 5.415e-01, Validation Loss: 6.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19845, Training Loss: 5.415e-01, Validation Loss: 6.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19846, Training Loss: 5.415e-01, Validation Loss: 6.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19847, Training Loss: 5.414e-01, Validation Loss: 6.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19848, Training Loss: 5.414e-01, Validation Loss: 6.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19849, Training Loss: 5.414e-01, Validation Loss: 6.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19850, Training Loss: 5.413e-01, Validation Loss: 6.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19851, Training Loss: 5.413e-01, Validation Loss: 6.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19852, Training Loss: 5.413e-01, Validation Loss: 6.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19853, Training Loss: 5.413e-01, Validation Loss: 6.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19854, Training Loss: 5.412e-01, Validation Loss: 6.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19855, Training Loss: 5.412e-01, Validation Loss: 6.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19856, Training Loss: 5.412e-01, Validation Loss: 6.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19857, Training Loss: 5.411e-01, Validation Loss: 6.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19858, Training Loss: 5.411e-01, Validation Loss: 6.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19859, Training Loss: 5.411e-01, Validation Loss: 6.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19860, Training Loss: 5.411e-01, Validation Loss: 6.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19861, Training Loss: 5.410e-01, Validation Loss: 6.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19862, Training Loss: 5.410e-01, Validation Loss: 6.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19863, Training Loss: 5.410e-01, Validation Loss: 6.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19864, Training Loss: 5.409e-01, Validation Loss: 6.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19865, Training Loss: 5.409e-01, Validation Loss: 6.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19866, Training Loss: 5.409e-01, Validation Loss: 6.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19867, Training Loss: 5.409e-01, Validation Loss: 6.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19868, Training Loss: 5.408e-01, Validation Loss: 6.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19869, Training Loss: 5.408e-01, Validation Loss: 6.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19870, Training Loss: 5.408e-01, Validation Loss: 6.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19871, Training Loss: 5.407e-01, Validation Loss: 6.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19872, Training Loss: 5.407e-01, Validation Loss: 6.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19873, Training Loss: 5.407e-01, Validation Loss: 6.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19874, Training Loss: 5.407e-01, Validation Loss: 6.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19875, Training Loss: 5.406e-01, Validation Loss: 6.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19876, Training Loss: 5.406e-01, Validation Loss: 6.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19877, Training Loss: 5.406e-01, Validation Loss: 6.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19878, Training Loss: 5.405e-01, Validation Loss: 6.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19879, Training Loss: 5.405e-01, Validation Loss: 6.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19880, Training Loss: 5.405e-01, Validation Loss: 6.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19881, Training Loss: 5.405e-01, Validation Loss: 6.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19882, Training Loss: 5.404e-01, Validation Loss: 6.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19883, Training Loss: 5.404e-01, Validation Loss: 6.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19884, Training Loss: 5.404e-01, Validation Loss: 6.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19885, Training Loss: 5.403e-01, Validation Loss: 6.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19886, Training Loss: 5.403e-01, Validation Loss: 6.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19887, Training Loss: 5.403e-01, Validation Loss: 6.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19888, Training Loss: 5.403e-01, Validation Loss: 6.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19889, Training Loss: 5.402e-01, Validation Loss: 6.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19890, Training Loss: 5.402e-01, Validation Loss: 6.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19891, Training Loss: 5.402e-01, Validation Loss: 6.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19892, Training Loss: 5.402e-01, Validation Loss: 6.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19893, Training Loss: 5.401e-01, Validation Loss: 6.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19894, Training Loss: 5.401e-01, Validation Loss: 6.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19895, Training Loss: 5.401e-01, Validation Loss: 6.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19896, Training Loss: 5.400e-01, Validation Loss: 6.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19897, Training Loss: 5.400e-01, Validation Loss: 6.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19898, Training Loss: 5.400e-01, Validation Loss: 6.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19899, Training Loss: 5.400e-01, Validation Loss: 6.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19900, Training Loss: 5.399e-01, Validation Loss: 6.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19901, Training Loss: 5.399e-01, Validation Loss: 6.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19902, Training Loss: 5.399e-01, Validation Loss: 6.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19903, Training Loss: 5.398e-01, Validation Loss: 6.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19904, Training Loss: 5.398e-01, Validation Loss: 6.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19905, Training Loss: 5.398e-01, Validation Loss: 6.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19906, Training Loss: 5.398e-01, Validation Loss: 6.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19907, Training Loss: 5.397e-01, Validation Loss: 6.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19908, Training Loss: 5.397e-01, Validation Loss: 6.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19909, Training Loss: 5.397e-01, Validation Loss: 6.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19910, Training Loss: 5.396e-01, Validation Loss: 6.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19911, Training Loss: 5.396e-01, Validation Loss: 6.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19912, Training Loss: 5.396e-01, Validation Loss: 6.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19913, Training Loss: 5.396e-01, Validation Loss: 6.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19914, Training Loss: 5.395e-01, Validation Loss: 6.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19915, Training Loss: 5.395e-01, Validation Loss: 6.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19916, Training Loss: 5.395e-01, Validation Loss: 6.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19917, Training Loss: 5.394e-01, Validation Loss: 6.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19918, Training Loss: 5.394e-01, Validation Loss: 6.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19919, Training Loss: 5.394e-01, Validation Loss: 6.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19920, Training Loss: 5.394e-01, Validation Loss: 6.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19921, Training Loss: 5.393e-01, Validation Loss: 6.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19922, Training Loss: 5.393e-01, Validation Loss: 6.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19923, Training Loss: 5.393e-01, Validation Loss: 6.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19924, Training Loss: 5.392e-01, Validation Loss: 6.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19925, Training Loss: 5.392e-01, Validation Loss: 6.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19926, Training Loss: 5.392e-01, Validation Loss: 6.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19927, Training Loss: 5.392e-01, Validation Loss: 6.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19928, Training Loss: 5.391e-01, Validation Loss: 6.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19929, Training Loss: 5.391e-01, Validation Loss: 6.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19930, Training Loss: 5.391e-01, Validation Loss: 6.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19931, Training Loss: 5.390e-01, Validation Loss: 6.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19932, Training Loss: 5.390e-01, Validation Loss: 6.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19933, Training Loss: 5.390e-01, Validation Loss: 6.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19934, Training Loss: 5.390e-01, Validation Loss: 6.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19935, Training Loss: 5.389e-01, Validation Loss: 6.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19936, Training Loss: 5.389e-01, Validation Loss: 6.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19937, Training Loss: 5.389e-01, Validation Loss: 6.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19938, Training Loss: 5.388e-01, Validation Loss: 6.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19939, Training Loss: 5.388e-01, Validation Loss: 6.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19940, Training Loss: 5.388e-01, Validation Loss: 6.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19941, Training Loss: 5.388e-01, Validation Loss: 6.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19942, Training Loss: 5.387e-01, Validation Loss: 6.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19943, Training Loss: 5.387e-01, Validation Loss: 6.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19944, Training Loss: 5.387e-01, Validation Loss: 6.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19945, Training Loss: 5.386e-01, Validation Loss: 6.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19946, Training Loss: 5.386e-01, Validation Loss: 6.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19947, Training Loss: 5.386e-01, Validation Loss: 6.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19948, Training Loss: 5.386e-01, Validation Loss: 6.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19949, Training Loss: 5.385e-01, Validation Loss: 6.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19950, Training Loss: 5.385e-01, Validation Loss: 6.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19951, Training Loss: 5.385e-01, Validation Loss: 6.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19952, Training Loss: 5.384e-01, Validation Loss: 6.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19953, Training Loss: 5.384e-01, Validation Loss: 6.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19954, Training Loss: 5.384e-01, Validation Loss: 6.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19955, Training Loss: 5.384e-01, Validation Loss: 6.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19956, Training Loss: 5.383e-01, Validation Loss: 6.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19957, Training Loss: 5.383e-01, Validation Loss: 6.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19958, Training Loss: 5.383e-01, Validation Loss: 6.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19959, Training Loss: 5.383e-01, Validation Loss: 6.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19960, Training Loss: 5.382e-01, Validation Loss: 6.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19961, Training Loss: 5.382e-01, Validation Loss: 6.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19962, Training Loss: 5.382e-01, Validation Loss: 6.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19963, Training Loss: 5.381e-01, Validation Loss: 6.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19964, Training Loss: 5.381e-01, Validation Loss: 6.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19965, Training Loss: 5.381e-01, Validation Loss: 6.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19966, Training Loss: 5.381e-01, Validation Loss: 6.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19967, Training Loss: 5.380e-01, Validation Loss: 6.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19968, Training Loss: 5.380e-01, Validation Loss: 6.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19969, Training Loss: 5.380e-01, Validation Loss: 6.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19970, Training Loss: 5.379e-01, Validation Loss: 6.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19971, Training Loss: 5.379e-01, Validation Loss: 6.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19972, Training Loss: 5.379e-01, Validation Loss: 6.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19973, Training Loss: 5.379e-01, Validation Loss: 6.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19974, Training Loss: 5.378e-01, Validation Loss: 6.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19975, Training Loss: 5.378e-01, Validation Loss: 6.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19976, Training Loss: 5.378e-01, Validation Loss: 6.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19977, Training Loss: 5.377e-01, Validation Loss: 6.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19978, Training Loss: 5.377e-01, Validation Loss: 6.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19979, Training Loss: 5.377e-01, Validation Loss: 6.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19980, Training Loss: 5.377e-01, Validation Loss: 6.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19981, Training Loss: 5.376e-01, Validation Loss: 6.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19982, Training Loss: 5.376e-01, Validation Loss: 6.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19983, Training Loss: 5.376e-01, Validation Loss: 6.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19984, Training Loss: 5.375e-01, Validation Loss: 6.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19985, Training Loss: 5.375e-01, Validation Loss: 6.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19986, Training Loss: 5.375e-01, Validation Loss: 6.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19987, Training Loss: 5.375e-01, Validation Loss: 6.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19988, Training Loss: 5.374e-01, Validation Loss: 6.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19989, Training Loss: 5.374e-01, Validation Loss: 6.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19990, Training Loss: 5.374e-01, Validation Loss: 6.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19991, Training Loss: 5.373e-01, Validation Loss: 6.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19992, Training Loss: 5.373e-01, Validation Loss: 6.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19993, Training Loss: 5.373e-01, Validation Loss: 6.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19994, Training Loss: 5.373e-01, Validation Loss: 6.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19995, Training Loss: 5.372e-01, Validation Loss: 6.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19996, Training Loss: 5.372e-01, Validation Loss: 6.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19997, Training Loss: 5.372e-01, Validation Loss: 6.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19998, Training Loss: 5.372e-01, Validation Loss: 6.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19999, Training Loss: 5.371e-01, Validation Loss: 6.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19999, Training Loss: 5.371e-01, Validation Loss: 6.666e-01, Patience: 0\n"
     ]
    }
   ],
   "source": [
    "error_train, error_val = model_50.train(X_train, y_train, X_val, y_val, epochs=20000, learning_rate=1e-3, optimizer='sgd', generate_new_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_50.plot_training_error(error_train, error_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error : 0.6940664417810822\n",
      "(208, 900) (208, 15) (208, 15)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_50.test(X_test, y_test)\n",
    "print(X_test.shape, y_test.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8509615384615384\n",
      "Azmira - Precision: 0.8461538461538461, Recall: 1.0, F1 Score: 0.9166666666666666\n",
      "David - Precision: 0.6, Recall: 1.0, F1 Score: 0.7499999999999999\n",
      "Dimas - Precision: 0.8125, Recall: 0.9285714285714286, F1 Score: 0.8666666666666666\n",
      "Fadhli - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Fadlin - Precision: 0.8095238095238095, Recall: 1.0, F1 Score: 0.8947368421052632\n",
      "Hafidz - Precision: 0.8333333333333334, Recall: 0.7142857142857143, F1 Score: 0.7692307692307692\n",
      "Haidar - Precision: 0.8181818181818182, Recall: 0.75, F1 Score: 0.7826086956521738\n",
      "Hanna - Precision: 0.5625, Recall: 0.9, F1 Score: 0.6923076923076923\n",
      "Keiko - Precision: 0.9130434782608695, Recall: 1.0, F1 Score: 0.9545454545454545\n",
      "Khansa - Precision: 1.0, Recall: 0.42857142857142855, F1 Score: 0.6\n",
      "Mikhael - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Puti - Precision: 0.8571428571428571, Recall: 0.6666666666666666, F1 Score: 0.75\n",
      "Raesa - Precision: 0.8333333333333334, Recall: 0.4166666666666667, F1 Score: 0.5555555555555556\n",
      "Satwika - Precision: 0.9375, Recall: 0.8823529411764706, F1 Score: 0.9090909090909091\n",
      "Toni - Precision: 1.0, Recall: 0.9230769230769231, F1 Score: 0.9600000000000001\n",
      "Mean Precision: 0.8548808317286578\n",
      "Mean Recall: 0.8406794512676865\n",
      "Mean F1 Score: 0.8267606167880767\n"
     ]
    }
   ],
   "source": [
    "model_50.add_labels_from_folders(input_directory)\n",
    "model_50.evaluate_metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_50.plot_confusion_matrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_50.save_weights(\"./My_Model_50/08_Ishmael_Rotate.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
