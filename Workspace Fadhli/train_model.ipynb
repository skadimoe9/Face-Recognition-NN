{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_image import *\n",
    "from model_nn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found folders: ['Azmira', 'David', 'Dimas', 'Fadhli', 'Fadlin', 'Hafidz', 'Haidar', 'Hanna', 'Keiko', 'Khansa', 'Mikhael', 'Puti', 'Raesa', 'Satwika', 'Toni']\n",
      "(968, 2500) (968, 15) (208, 2500) (208, 15) (208, 2500) (208, 15)\n"
     ]
    }
   ],
   "source": [
    "input_directory = \"../Dataset/Foto_Resize_Rotate_50x50\" \n",
    "X_train, y_train, X_test, y_test, X_val, y_val, scalerinput = process_all(input_directory)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_50 = FaceRecognitionModel(X_train.shape[1], [64], y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params rewritten\n",
      "Epoch 0, Training Loss: 3.397e+00, Validation Loss: 3.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1, Training Loss: 3.275e+00, Validation Loss: 3.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2, Training Loss: 3.189e+00, Validation Loss: 3.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3, Training Loss: 3.125e+00, Validation Loss: 3.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4, Training Loss: 3.078e+00, Validation Loss: 3.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5, Training Loss: 3.041e+00, Validation Loss: 2.982e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6, Training Loss: 3.011e+00, Validation Loss: 2.963e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7, Training Loss: 2.987e+00, Validation Loss: 2.947e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8, Training Loss: 2.967e+00, Validation Loss: 2.933e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9, Training Loss: 2.950e+00, Validation Loss: 2.921e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10, Training Loss: 2.933e+00, Validation Loss: 2.909e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11, Training Loss: 2.919e+00, Validation Loss: 2.899e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12, Training Loss: 2.905e+00, Validation Loss: 2.889e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13, Training Loss: 2.893e+00, Validation Loss: 2.879e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14, Training Loss: 2.881e+00, Validation Loss: 2.870e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15, Training Loss: 2.870e+00, Validation Loss: 2.862e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16, Training Loss: 2.860e+00, Validation Loss: 2.854e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17, Training Loss: 2.851e+00, Validation Loss: 2.846e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18, Training Loss: 2.842e+00, Validation Loss: 2.839e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19, Training Loss: 2.834e+00, Validation Loss: 2.833e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 20, Training Loss: 2.826e+00, Validation Loss: 2.826e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 21, Training Loss: 2.818e+00, Validation Loss: 2.820e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 22, Training Loss: 2.811e+00, Validation Loss: 2.814e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 23, Training Loss: 2.805e+00, Validation Loss: 2.808e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 24, Training Loss: 2.798e+00, Validation Loss: 2.803e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 25, Training Loss: 2.793e+00, Validation Loss: 2.797e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 26, Training Loss: 2.787e+00, Validation Loss: 2.792e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 27, Training Loss: 2.782e+00, Validation Loss: 2.787e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 28, Training Loss: 2.776e+00, Validation Loss: 2.783e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 29, Training Loss: 2.772e+00, Validation Loss: 2.778e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 30, Training Loss: 2.767e+00, Validation Loss: 2.774e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 31, Training Loss: 2.762e+00, Validation Loss: 2.770e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 32, Training Loss: 2.758e+00, Validation Loss: 2.766e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 33, Training Loss: 2.754e+00, Validation Loss: 2.762e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 34, Training Loss: 2.750e+00, Validation Loss: 2.759e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 35, Training Loss: 2.746e+00, Validation Loss: 2.755e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 36, Training Loss: 2.742e+00, Validation Loss: 2.752e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 37, Training Loss: 2.739e+00, Validation Loss: 2.748e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 38, Training Loss: 2.735e+00, Validation Loss: 2.745e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 39, Training Loss: 2.731e+00, Validation Loss: 2.742e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 40, Training Loss: 2.728e+00, Validation Loss: 2.739e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 41, Training Loss: 2.725e+00, Validation Loss: 2.736e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 42, Training Loss: 2.721e+00, Validation Loss: 2.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 43, Training Loss: 2.718e+00, Validation Loss: 2.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 44, Training Loss: 2.715e+00, Validation Loss: 2.728e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 45, Training Loss: 2.712e+00, Validation Loss: 2.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 46, Training Loss: 2.709e+00, Validation Loss: 2.723e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 47, Training Loss: 2.706e+00, Validation Loss: 2.720e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 48, Training Loss: 2.704e+00, Validation Loss: 2.718e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 49, Training Loss: 2.701e+00, Validation Loss: 2.716e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 50, Training Loss: 2.698e+00, Validation Loss: 2.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 51, Training Loss: 2.696e+00, Validation Loss: 2.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 52, Training Loss: 2.693e+00, Validation Loss: 2.710e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 53, Training Loss: 2.691e+00, Validation Loss: 2.708e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 54, Training Loss: 2.688e+00, Validation Loss: 2.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 55, Training Loss: 2.686e+00, Validation Loss: 2.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 56, Training Loss: 2.684e+00, Validation Loss: 2.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 57, Training Loss: 2.681e+00, Validation Loss: 2.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 58, Training Loss: 2.679e+00, Validation Loss: 2.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 59, Training Loss: 2.677e+00, Validation Loss: 2.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 60, Training Loss: 2.675e+00, Validation Loss: 2.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 61, Training Loss: 2.673e+00, Validation Loss: 2.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 62, Training Loss: 2.670e+00, Validation Loss: 2.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 63, Training Loss: 2.668e+00, Validation Loss: 2.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 64, Training Loss: 2.666e+00, Validation Loss: 2.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 65, Training Loss: 2.665e+00, Validation Loss: 2.687e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 66, Training Loss: 2.663e+00, Validation Loss: 2.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 67, Training Loss: 2.661e+00, Validation Loss: 2.684e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 68, Training Loss: 2.659e+00, Validation Loss: 2.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 69, Training Loss: 2.657e+00, Validation Loss: 2.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 70, Training Loss: 2.656e+00, Validation Loss: 2.680e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 71, Training Loss: 2.654e+00, Validation Loss: 2.679e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 72, Training Loss: 2.653e+00, Validation Loss: 2.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 73, Training Loss: 2.651e+00, Validation Loss: 2.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 74, Training Loss: 2.650e+00, Validation Loss: 2.676e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 75, Training Loss: 2.648e+00, Validation Loss: 2.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 76, Training Loss: 2.647e+00, Validation Loss: 2.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 77, Training Loss: 2.645e+00, Validation Loss: 2.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 78, Training Loss: 2.644e+00, Validation Loss: 2.672e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 79, Training Loss: 2.643e+00, Validation Loss: 2.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 80, Training Loss: 2.641e+00, Validation Loss: 2.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 81, Training Loss: 2.640e+00, Validation Loss: 2.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 82, Training Loss: 2.639e+00, Validation Loss: 2.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 83, Training Loss: 2.638e+00, Validation Loss: 2.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 84, Training Loss: 2.636e+00, Validation Loss: 2.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 85, Training Loss: 2.635e+00, Validation Loss: 2.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 86, Training Loss: 2.634e+00, Validation Loss: 2.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 87, Training Loss: 2.633e+00, Validation Loss: 2.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 88, Training Loss: 2.632e+00, Validation Loss: 2.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 89, Training Loss: 2.630e+00, Validation Loss: 2.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 90, Training Loss: 2.629e+00, Validation Loss: 2.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 91, Training Loss: 2.628e+00, Validation Loss: 2.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 92, Training Loss: 2.627e+00, Validation Loss: 2.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 93, Training Loss: 2.626e+00, Validation Loss: 2.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 94, Training Loss: 2.625e+00, Validation Loss: 2.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 95, Training Loss: 2.624e+00, Validation Loss: 2.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 96, Training Loss: 2.623e+00, Validation Loss: 2.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 97, Training Loss: 2.622e+00, Validation Loss: 2.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 98, Training Loss: 2.621e+00, Validation Loss: 2.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 99, Training Loss: 2.620e+00, Validation Loss: 2.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 100, Training Loss: 2.618e+00, Validation Loss: 2.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 101, Training Loss: 2.617e+00, Validation Loss: 2.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 102, Training Loss: 2.616e+00, Validation Loss: 2.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 103, Training Loss: 2.615e+00, Validation Loss: 2.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 104, Training Loss: 2.614e+00, Validation Loss: 2.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 105, Training Loss: 2.613e+00, Validation Loss: 2.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 106, Training Loss: 2.612e+00, Validation Loss: 2.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 107, Training Loss: 2.611e+00, Validation Loss: 2.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 108, Training Loss: 2.610e+00, Validation Loss: 2.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 109, Training Loss: 2.609e+00, Validation Loss: 2.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 110, Training Loss: 2.608e+00, Validation Loss: 2.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 111, Training Loss: 2.607e+00, Validation Loss: 2.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 112, Training Loss: 2.606e+00, Validation Loss: 2.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 113, Training Loss: 2.606e+00, Validation Loss: 2.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 114, Training Loss: 2.605e+00, Validation Loss: 2.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 115, Training Loss: 2.604e+00, Validation Loss: 2.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 116, Training Loss: 2.603e+00, Validation Loss: 2.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 117, Training Loss: 2.602e+00, Validation Loss: 2.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 118, Training Loss: 2.601e+00, Validation Loss: 2.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 119, Training Loss: 2.600e+00, Validation Loss: 2.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 120, Training Loss: 2.599e+00, Validation Loss: 2.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 121, Training Loss: 2.599e+00, Validation Loss: 2.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 122, Training Loss: 2.598e+00, Validation Loss: 2.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 123, Training Loss: 2.597e+00, Validation Loss: 2.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 124, Training Loss: 2.596e+00, Validation Loss: 2.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 125, Training Loss: 2.595e+00, Validation Loss: 2.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 126, Training Loss: 2.594e+00, Validation Loss: 2.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 127, Training Loss: 2.594e+00, Validation Loss: 2.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 128, Training Loss: 2.593e+00, Validation Loss: 2.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 129, Training Loss: 2.592e+00, Validation Loss: 2.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 130, Training Loss: 2.591e+00, Validation Loss: 2.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 131, Training Loss: 2.590e+00, Validation Loss: 2.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 132, Training Loss: 2.589e+00, Validation Loss: 2.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 133, Training Loss: 2.589e+00, Validation Loss: 2.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 134, Training Loss: 2.588e+00, Validation Loss: 2.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 135, Training Loss: 2.587e+00, Validation Loss: 2.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 136, Training Loss: 2.586e+00, Validation Loss: 2.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 137, Training Loss: 2.585e+00, Validation Loss: 2.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 138, Training Loss: 2.584e+00, Validation Loss: 2.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 139, Training Loss: 2.584e+00, Validation Loss: 2.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 140, Training Loss: 2.583e+00, Validation Loss: 2.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 141, Training Loss: 2.582e+00, Validation Loss: 2.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 142, Training Loss: 2.581e+00, Validation Loss: 2.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 143, Training Loss: 2.581e+00, Validation Loss: 2.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 144, Training Loss: 2.580e+00, Validation Loss: 2.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 145, Training Loss: 2.579e+00, Validation Loss: 2.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 146, Training Loss: 2.578e+00, Validation Loss: 2.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 147, Training Loss: 2.578e+00, Validation Loss: 2.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 148, Training Loss: 2.577e+00, Validation Loss: 2.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 149, Training Loss: 2.576e+00, Validation Loss: 2.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 150, Training Loss: 2.575e+00, Validation Loss: 2.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 151, Training Loss: 2.575e+00, Validation Loss: 2.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 152, Training Loss: 2.574e+00, Validation Loss: 2.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 153, Training Loss: 2.573e+00, Validation Loss: 2.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 154, Training Loss: 2.572e+00, Validation Loss: 2.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 155, Training Loss: 2.572e+00, Validation Loss: 2.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 156, Training Loss: 2.571e+00, Validation Loss: 2.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 157, Training Loss: 2.570e+00, Validation Loss: 2.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 158, Training Loss: 2.570e+00, Validation Loss: 2.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 159, Training Loss: 2.569e+00, Validation Loss: 2.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 160, Training Loss: 2.568e+00, Validation Loss: 2.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 161, Training Loss: 2.568e+00, Validation Loss: 2.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 162, Training Loss: 2.567e+00, Validation Loss: 2.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 163, Training Loss: 2.566e+00, Validation Loss: 2.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 164, Training Loss: 2.565e+00, Validation Loss: 2.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 165, Training Loss: 2.565e+00, Validation Loss: 2.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 166, Training Loss: 2.564e+00, Validation Loss: 2.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 167, Training Loss: 2.563e+00, Validation Loss: 2.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 168, Training Loss: 2.563e+00, Validation Loss: 2.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 169, Training Loss: 2.562e+00, Validation Loss: 2.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 170, Training Loss: 2.561e+00, Validation Loss: 2.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 171, Training Loss: 2.560e+00, Validation Loss: 2.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 172, Training Loss: 2.560e+00, Validation Loss: 2.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 173, Training Loss: 2.559e+00, Validation Loss: 2.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 174, Training Loss: 2.558e+00, Validation Loss: 2.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 175, Training Loss: 2.558e+00, Validation Loss: 2.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 176, Training Loss: 2.557e+00, Validation Loss: 2.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 177, Training Loss: 2.556e+00, Validation Loss: 2.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 178, Training Loss: 2.556e+00, Validation Loss: 2.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 179, Training Loss: 2.555e+00, Validation Loss: 2.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 180, Training Loss: 2.554e+00, Validation Loss: 2.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 181, Training Loss: 2.554e+00, Validation Loss: 2.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 182, Training Loss: 2.553e+00, Validation Loss: 2.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 183, Training Loss: 2.552e+00, Validation Loss: 2.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 184, Training Loss: 2.552e+00, Validation Loss: 2.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 185, Training Loss: 2.551e+00, Validation Loss: 2.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 186, Training Loss: 2.550e+00, Validation Loss: 2.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 187, Training Loss: 2.550e+00, Validation Loss: 2.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 188, Training Loss: 2.549e+00, Validation Loss: 2.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 189, Training Loss: 2.548e+00, Validation Loss: 2.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 190, Training Loss: 2.547e+00, Validation Loss: 2.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 191, Training Loss: 2.547e+00, Validation Loss: 2.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 192, Training Loss: 2.546e+00, Validation Loss: 2.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 193, Training Loss: 2.545e+00, Validation Loss: 2.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 194, Training Loss: 2.545e+00, Validation Loss: 2.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 195, Training Loss: 2.544e+00, Validation Loss: 2.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 196, Training Loss: 2.543e+00, Validation Loss: 2.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 197, Training Loss: 2.542e+00, Validation Loss: 2.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 198, Training Loss: 2.542e+00, Validation Loss: 2.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 199, Training Loss: 2.541e+00, Validation Loss: 2.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 200, Training Loss: 2.540e+00, Validation Loss: 2.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 201, Training Loss: 2.539e+00, Validation Loss: 2.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 202, Training Loss: 2.539e+00, Validation Loss: 2.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 203, Training Loss: 2.538e+00, Validation Loss: 2.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 204, Training Loss: 2.537e+00, Validation Loss: 2.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 205, Training Loss: 2.537e+00, Validation Loss: 2.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 206, Training Loss: 2.536e+00, Validation Loss: 2.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 207, Training Loss: 2.535e+00, Validation Loss: 2.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 208, Training Loss: 2.535e+00, Validation Loss: 2.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 209, Training Loss: 2.534e+00, Validation Loss: 2.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 210, Training Loss: 2.533e+00, Validation Loss: 2.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 211, Training Loss: 2.532e+00, Validation Loss: 2.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 212, Training Loss: 2.532e+00, Validation Loss: 2.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 213, Training Loss: 2.531e+00, Validation Loss: 2.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 214, Training Loss: 2.530e+00, Validation Loss: 2.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 215, Training Loss: 2.530e+00, Validation Loss: 2.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 216, Training Loss: 2.529e+00, Validation Loss: 2.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 217, Training Loss: 2.528e+00, Validation Loss: 2.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 218, Training Loss: 2.528e+00, Validation Loss: 2.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 219, Training Loss: 2.527e+00, Validation Loss: 2.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 220, Training Loss: 2.527e+00, Validation Loss: 2.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 221, Training Loss: 2.526e+00, Validation Loss: 2.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 222, Training Loss: 2.525e+00, Validation Loss: 2.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 223, Training Loss: 2.525e+00, Validation Loss: 2.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 224, Training Loss: 2.524e+00, Validation Loss: 2.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 225, Training Loss: 2.523e+00, Validation Loss: 2.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 226, Training Loss: 2.523e+00, Validation Loss: 2.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 227, Training Loss: 2.522e+00, Validation Loss: 2.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 228, Training Loss: 2.522e+00, Validation Loss: 2.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 229, Training Loss: 2.521e+00, Validation Loss: 2.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 230, Training Loss: 2.520e+00, Validation Loss: 2.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 231, Training Loss: 2.520e+00, Validation Loss: 2.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 232, Training Loss: 2.519e+00, Validation Loss: 2.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 233, Training Loss: 2.518e+00, Validation Loss: 2.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 234, Training Loss: 2.518e+00, Validation Loss: 2.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 235, Training Loss: 2.517e+00, Validation Loss: 2.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 236, Training Loss: 2.517e+00, Validation Loss: 2.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 237, Training Loss: 2.516e+00, Validation Loss: 2.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 238, Training Loss: 2.516e+00, Validation Loss: 2.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 239, Training Loss: 2.515e+00, Validation Loss: 2.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 240, Training Loss: 2.514e+00, Validation Loss: 2.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 241, Training Loss: 2.514e+00, Validation Loss: 2.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 242, Training Loss: 2.513e+00, Validation Loss: 2.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 243, Training Loss: 2.513e+00, Validation Loss: 2.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 244, Training Loss: 2.512e+00, Validation Loss: 2.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 245, Training Loss: 2.511e+00, Validation Loss: 2.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 246, Training Loss: 2.511e+00, Validation Loss: 2.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 247, Training Loss: 2.510e+00, Validation Loss: 2.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 248, Training Loss: 2.510e+00, Validation Loss: 2.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 249, Training Loss: 2.509e+00, Validation Loss: 2.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 250, Training Loss: 2.508e+00, Validation Loss: 2.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 251, Training Loss: 2.508e+00, Validation Loss: 2.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 252, Training Loss: 2.507e+00, Validation Loss: 2.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 253, Training Loss: 2.507e+00, Validation Loss: 2.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 254, Training Loss: 2.506e+00, Validation Loss: 2.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 255, Training Loss: 2.506e+00, Validation Loss: 2.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 256, Training Loss: 2.505e+00, Validation Loss: 2.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 257, Training Loss: 2.504e+00, Validation Loss: 2.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 258, Training Loss: 2.504e+00, Validation Loss: 2.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 259, Training Loss: 2.503e+00, Validation Loss: 2.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 260, Training Loss: 2.503e+00, Validation Loss: 2.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 261, Training Loss: 2.502e+00, Validation Loss: 2.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 262, Training Loss: 2.502e+00, Validation Loss: 2.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 263, Training Loss: 2.501e+00, Validation Loss: 2.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 264, Training Loss: 2.501e+00, Validation Loss: 2.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 265, Training Loss: 2.500e+00, Validation Loss: 2.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 266, Training Loss: 2.499e+00, Validation Loss: 2.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 267, Training Loss: 2.499e+00, Validation Loss: 2.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 268, Training Loss: 2.498e+00, Validation Loss: 2.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 269, Training Loss: 2.498e+00, Validation Loss: 2.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 270, Training Loss: 2.497e+00, Validation Loss: 2.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 271, Training Loss: 2.497e+00, Validation Loss: 2.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 272, Training Loss: 2.496e+00, Validation Loss: 2.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 273, Training Loss: 2.496e+00, Validation Loss: 2.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 274, Training Loss: 2.495e+00, Validation Loss: 2.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 275, Training Loss: 2.494e+00, Validation Loss: 2.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 276, Training Loss: 2.494e+00, Validation Loss: 2.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 277, Training Loss: 2.493e+00, Validation Loss: 2.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 278, Training Loss: 2.493e+00, Validation Loss: 2.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 279, Training Loss: 2.492e+00, Validation Loss: 2.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 280, Training Loss: 2.492e+00, Validation Loss: 2.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 281, Training Loss: 2.491e+00, Validation Loss: 2.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 282, Training Loss: 2.491e+00, Validation Loss: 2.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 283, Training Loss: 2.490e+00, Validation Loss: 2.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 284, Training Loss: 2.490e+00, Validation Loss: 2.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 285, Training Loss: 2.489e+00, Validation Loss: 2.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 286, Training Loss: 2.489e+00, Validation Loss: 2.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 287, Training Loss: 2.488e+00, Validation Loss: 2.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 288, Training Loss: 2.487e+00, Validation Loss: 2.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 289, Training Loss: 2.487e+00, Validation Loss: 2.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 290, Training Loss: 2.486e+00, Validation Loss: 2.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 291, Training Loss: 2.486e+00, Validation Loss: 2.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 292, Training Loss: 2.485e+00, Validation Loss: 2.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 293, Training Loss: 2.485e+00, Validation Loss: 2.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 294, Training Loss: 2.484e+00, Validation Loss: 2.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 295, Training Loss: 2.484e+00, Validation Loss: 2.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 296, Training Loss: 2.483e+00, Validation Loss: 2.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 297, Training Loss: 2.483e+00, Validation Loss: 2.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 298, Training Loss: 2.482e+00, Validation Loss: 2.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 299, Training Loss: 2.482e+00, Validation Loss: 2.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 300, Training Loss: 2.481e+00, Validation Loss: 2.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 301, Training Loss: 2.480e+00, Validation Loss: 2.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 302, Training Loss: 2.480e+00, Validation Loss: 2.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 303, Training Loss: 2.479e+00, Validation Loss: 2.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 304, Training Loss: 2.479e+00, Validation Loss: 2.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 305, Training Loss: 2.478e+00, Validation Loss: 2.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 306, Training Loss: 2.478e+00, Validation Loss: 2.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 307, Training Loss: 2.477e+00, Validation Loss: 2.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 308, Training Loss: 2.477e+00, Validation Loss: 2.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 309, Training Loss: 2.476e+00, Validation Loss: 2.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 310, Training Loss: 2.476e+00, Validation Loss: 2.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 311, Training Loss: 2.475e+00, Validation Loss: 2.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 312, Training Loss: 2.475e+00, Validation Loss: 2.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 313, Training Loss: 2.474e+00, Validation Loss: 2.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 314, Training Loss: 2.473e+00, Validation Loss: 2.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 315, Training Loss: 2.473e+00, Validation Loss: 2.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 316, Training Loss: 2.472e+00, Validation Loss: 2.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 317, Training Loss: 2.472e+00, Validation Loss: 2.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 318, Training Loss: 2.471e+00, Validation Loss: 2.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 319, Training Loss: 2.471e+00, Validation Loss: 2.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 320, Training Loss: 2.470e+00, Validation Loss: 2.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 321, Training Loss: 2.470e+00, Validation Loss: 2.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 322, Training Loss: 2.469e+00, Validation Loss: 2.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 323, Training Loss: 2.469e+00, Validation Loss: 2.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 324, Training Loss: 2.468e+00, Validation Loss: 2.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 325, Training Loss: 2.468e+00, Validation Loss: 2.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 326, Training Loss: 2.467e+00, Validation Loss: 2.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 327, Training Loss: 2.467e+00, Validation Loss: 2.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 328, Training Loss: 2.466e+00, Validation Loss: 2.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 329, Training Loss: 2.465e+00, Validation Loss: 2.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 330, Training Loss: 2.465e+00, Validation Loss: 2.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 331, Training Loss: 2.464e+00, Validation Loss: 2.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 332, Training Loss: 2.464e+00, Validation Loss: 2.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 333, Training Loss: 2.463e+00, Validation Loss: 2.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 334, Training Loss: 2.463e+00, Validation Loss: 2.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 335, Training Loss: 2.462e+00, Validation Loss: 2.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 336, Training Loss: 2.462e+00, Validation Loss: 2.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 337, Training Loss: 2.461e+00, Validation Loss: 2.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 338, Training Loss: 2.461e+00, Validation Loss: 2.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 339, Training Loss: 2.460e+00, Validation Loss: 2.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 340, Training Loss: 2.460e+00, Validation Loss: 2.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 341, Training Loss: 2.459e+00, Validation Loss: 2.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 342, Training Loss: 2.459e+00, Validation Loss: 2.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 343, Training Loss: 2.458e+00, Validation Loss: 2.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 344, Training Loss: 2.458e+00, Validation Loss: 2.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 345, Training Loss: 2.457e+00, Validation Loss: 2.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 346, Training Loss: 2.456e+00, Validation Loss: 2.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 347, Training Loss: 2.456e+00, Validation Loss: 2.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 348, Training Loss: 2.455e+00, Validation Loss: 2.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 349, Training Loss: 2.455e+00, Validation Loss: 2.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 350, Training Loss: 2.454e+00, Validation Loss: 2.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 351, Training Loss: 2.454e+00, Validation Loss: 2.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 352, Training Loss: 2.453e+00, Validation Loss: 2.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 353, Training Loss: 2.453e+00, Validation Loss: 2.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 354, Training Loss: 2.452e+00, Validation Loss: 2.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 355, Training Loss: 2.452e+00, Validation Loss: 2.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 356, Training Loss: 2.451e+00, Validation Loss: 2.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 357, Training Loss: 2.451e+00, Validation Loss: 2.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 358, Training Loss: 2.450e+00, Validation Loss: 2.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 359, Training Loss: 2.450e+00, Validation Loss: 2.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 360, Training Loss: 2.449e+00, Validation Loss: 2.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 361, Training Loss: 2.449e+00, Validation Loss: 2.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 362, Training Loss: 2.448e+00, Validation Loss: 2.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 363, Training Loss: 2.448e+00, Validation Loss: 2.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 364, Training Loss: 2.447e+00, Validation Loss: 2.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 365, Training Loss: 2.446e+00, Validation Loss: 2.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 366, Training Loss: 2.446e+00, Validation Loss: 2.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 367, Training Loss: 2.445e+00, Validation Loss: 2.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 368, Training Loss: 2.445e+00, Validation Loss: 2.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 369, Training Loss: 2.444e+00, Validation Loss: 2.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 370, Training Loss: 2.444e+00, Validation Loss: 2.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 371, Training Loss: 2.443e+00, Validation Loss: 2.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 372, Training Loss: 2.443e+00, Validation Loss: 2.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 373, Training Loss: 2.442e+00, Validation Loss: 2.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 374, Training Loss: 2.442e+00, Validation Loss: 2.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 375, Training Loss: 2.441e+00, Validation Loss: 2.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 376, Training Loss: 2.441e+00, Validation Loss: 2.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 377, Training Loss: 2.440e+00, Validation Loss: 2.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 378, Training Loss: 2.440e+00, Validation Loss: 2.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 379, Training Loss: 2.439e+00, Validation Loss: 2.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 380, Training Loss: 2.439e+00, Validation Loss: 2.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 381, Training Loss: 2.438e+00, Validation Loss: 2.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 382, Training Loss: 2.438e+00, Validation Loss: 2.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 383, Training Loss: 2.437e+00, Validation Loss: 2.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 384, Training Loss: 2.437e+00, Validation Loss: 2.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 385, Training Loss: 2.436e+00, Validation Loss: 2.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 386, Training Loss: 2.436e+00, Validation Loss: 2.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 387, Training Loss: 2.435e+00, Validation Loss: 2.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 388, Training Loss: 2.434e+00, Validation Loss: 2.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 389, Training Loss: 2.434e+00, Validation Loss: 2.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 390, Training Loss: 2.433e+00, Validation Loss: 2.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 391, Training Loss: 2.433e+00, Validation Loss: 2.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 392, Training Loss: 2.432e+00, Validation Loss: 2.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 393, Training Loss: 2.432e+00, Validation Loss: 2.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 394, Training Loss: 2.431e+00, Validation Loss: 2.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 395, Training Loss: 2.431e+00, Validation Loss: 2.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 396, Training Loss: 2.430e+00, Validation Loss: 2.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 397, Training Loss: 2.430e+00, Validation Loss: 2.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 398, Training Loss: 2.429e+00, Validation Loss: 2.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 399, Training Loss: 2.429e+00, Validation Loss: 2.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 400, Training Loss: 2.428e+00, Validation Loss: 2.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 401, Training Loss: 2.428e+00, Validation Loss: 2.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 402, Training Loss: 2.427e+00, Validation Loss: 2.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 403, Training Loss: 2.427e+00, Validation Loss: 2.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 404, Training Loss: 2.426e+00, Validation Loss: 2.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 405, Training Loss: 2.426e+00, Validation Loss: 2.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 406, Training Loss: 2.425e+00, Validation Loss: 2.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 407, Training Loss: 2.425e+00, Validation Loss: 2.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 408, Training Loss: 2.424e+00, Validation Loss: 2.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 409, Training Loss: 2.424e+00, Validation Loss: 2.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 410, Training Loss: 2.423e+00, Validation Loss: 2.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 411, Training Loss: 2.423e+00, Validation Loss: 2.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 412, Training Loss: 2.422e+00, Validation Loss: 2.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 413, Training Loss: 2.422e+00, Validation Loss: 2.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 414, Training Loss: 2.421e+00, Validation Loss: 2.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 415, Training Loss: 2.421e+00, Validation Loss: 2.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 416, Training Loss: 2.420e+00, Validation Loss: 2.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 417, Training Loss: 2.420e+00, Validation Loss: 2.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 418, Training Loss: 2.419e+00, Validation Loss: 2.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 419, Training Loss: 2.419e+00, Validation Loss: 2.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 420, Training Loss: 2.418e+00, Validation Loss: 2.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 421, Training Loss: 2.417e+00, Validation Loss: 2.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 422, Training Loss: 2.417e+00, Validation Loss: 2.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 423, Training Loss: 2.416e+00, Validation Loss: 2.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 424, Training Loss: 2.416e+00, Validation Loss: 2.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 425, Training Loss: 2.415e+00, Validation Loss: 2.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 426, Training Loss: 2.415e+00, Validation Loss: 2.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 427, Training Loss: 2.414e+00, Validation Loss: 2.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 428, Training Loss: 2.414e+00, Validation Loss: 2.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 429, Training Loss: 2.413e+00, Validation Loss: 2.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 430, Training Loss: 2.413e+00, Validation Loss: 2.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 431, Training Loss: 2.412e+00, Validation Loss: 2.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 432, Training Loss: 2.412e+00, Validation Loss: 2.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 433, Training Loss: 2.411e+00, Validation Loss: 2.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 434, Training Loss: 2.411e+00, Validation Loss: 2.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 435, Training Loss: 2.410e+00, Validation Loss: 2.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 436, Training Loss: 2.410e+00, Validation Loss: 2.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 437, Training Loss: 2.409e+00, Validation Loss: 2.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 438, Training Loss: 2.409e+00, Validation Loss: 2.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 439, Training Loss: 2.408e+00, Validation Loss: 2.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 440, Training Loss: 2.408e+00, Validation Loss: 2.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 441, Training Loss: 2.407e+00, Validation Loss: 2.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 442, Training Loss: 2.407e+00, Validation Loss: 2.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 443, Training Loss: 2.406e+00, Validation Loss: 2.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 444, Training Loss: 2.406e+00, Validation Loss: 2.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 445, Training Loss: 2.405e+00, Validation Loss: 2.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 446, Training Loss: 2.405e+00, Validation Loss: 2.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 447, Training Loss: 2.404e+00, Validation Loss: 2.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 448, Training Loss: 2.404e+00, Validation Loss: 2.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 449, Training Loss: 2.403e+00, Validation Loss: 2.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 450, Training Loss: 2.403e+00, Validation Loss: 2.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 451, Training Loss: 2.402e+00, Validation Loss: 2.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 452, Training Loss: 2.402e+00, Validation Loss: 2.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 453, Training Loss: 2.401e+00, Validation Loss: 2.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 454, Training Loss: 2.401e+00, Validation Loss: 2.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 455, Training Loss: 2.400e+00, Validation Loss: 2.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 456, Training Loss: 2.400e+00, Validation Loss: 2.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 457, Training Loss: 2.399e+00, Validation Loss: 2.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 458, Training Loss: 2.399e+00, Validation Loss: 2.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 459, Training Loss: 2.398e+00, Validation Loss: 2.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 460, Training Loss: 2.397e+00, Validation Loss: 2.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 461, Training Loss: 2.397e+00, Validation Loss: 2.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 462, Training Loss: 2.396e+00, Validation Loss: 2.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 463, Training Loss: 2.396e+00, Validation Loss: 2.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 464, Training Loss: 2.395e+00, Validation Loss: 2.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 465, Training Loss: 2.395e+00, Validation Loss: 2.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 466, Training Loss: 2.394e+00, Validation Loss: 2.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 467, Training Loss: 2.394e+00, Validation Loss: 2.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 468, Training Loss: 2.393e+00, Validation Loss: 2.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 469, Training Loss: 2.393e+00, Validation Loss: 2.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 470, Training Loss: 2.392e+00, Validation Loss: 2.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 471, Training Loss: 2.392e+00, Validation Loss: 2.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 472, Training Loss: 2.391e+00, Validation Loss: 2.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 473, Training Loss: 2.391e+00, Validation Loss: 2.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 474, Training Loss: 2.390e+00, Validation Loss: 2.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 475, Training Loss: 2.390e+00, Validation Loss: 2.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 476, Training Loss: 2.389e+00, Validation Loss: 2.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 477, Training Loss: 2.389e+00, Validation Loss: 2.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 478, Training Loss: 2.388e+00, Validation Loss: 2.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 479, Training Loss: 2.388e+00, Validation Loss: 2.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 480, Training Loss: 2.387e+00, Validation Loss: 2.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 481, Training Loss: 2.387e+00, Validation Loss: 2.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 482, Training Loss: 2.386e+00, Validation Loss: 2.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 483, Training Loss: 2.386e+00, Validation Loss: 2.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 484, Training Loss: 2.385e+00, Validation Loss: 2.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 485, Training Loss: 2.385e+00, Validation Loss: 2.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 486, Training Loss: 2.384e+00, Validation Loss: 2.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 487, Training Loss: 2.384e+00, Validation Loss: 2.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 488, Training Loss: 2.383e+00, Validation Loss: 2.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 489, Training Loss: 2.383e+00, Validation Loss: 2.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 490, Training Loss: 2.382e+00, Validation Loss: 2.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 491, Training Loss: 2.382e+00, Validation Loss: 2.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 492, Training Loss: 2.381e+00, Validation Loss: 2.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 493, Training Loss: 2.381e+00, Validation Loss: 2.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 494, Training Loss: 2.380e+00, Validation Loss: 2.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 495, Training Loss: 2.379e+00, Validation Loss: 2.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 496, Training Loss: 2.379e+00, Validation Loss: 2.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 497, Training Loss: 2.378e+00, Validation Loss: 2.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 498, Training Loss: 2.378e+00, Validation Loss: 2.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 499, Training Loss: 2.377e+00, Validation Loss: 2.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 500, Training Loss: 2.377e+00, Validation Loss: 2.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 501, Training Loss: 2.376e+00, Validation Loss: 2.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 502, Training Loss: 2.376e+00, Validation Loss: 2.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 503, Training Loss: 2.375e+00, Validation Loss: 2.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 504, Training Loss: 2.375e+00, Validation Loss: 2.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 505, Training Loss: 2.374e+00, Validation Loss: 2.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 506, Training Loss: 2.374e+00, Validation Loss: 2.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 507, Training Loss: 2.373e+00, Validation Loss: 2.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 508, Training Loss: 2.373e+00, Validation Loss: 2.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 509, Training Loss: 2.372e+00, Validation Loss: 2.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 510, Training Loss: 2.372e+00, Validation Loss: 2.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 511, Training Loss: 2.371e+00, Validation Loss: 2.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 512, Training Loss: 2.371e+00, Validation Loss: 2.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 513, Training Loss: 2.370e+00, Validation Loss: 2.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 514, Training Loss: 2.370e+00, Validation Loss: 2.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 515, Training Loss: 2.369e+00, Validation Loss: 2.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 516, Training Loss: 2.369e+00, Validation Loss: 2.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 517, Training Loss: 2.368e+00, Validation Loss: 2.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 518, Training Loss: 2.368e+00, Validation Loss: 2.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 519, Training Loss: 2.367e+00, Validation Loss: 2.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 520, Training Loss: 2.367e+00, Validation Loss: 2.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 521, Training Loss: 2.366e+00, Validation Loss: 2.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 522, Training Loss: 2.366e+00, Validation Loss: 2.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 523, Training Loss: 2.365e+00, Validation Loss: 2.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 524, Training Loss: 2.365e+00, Validation Loss: 2.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 525, Training Loss: 2.364e+00, Validation Loss: 2.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 526, Training Loss: 2.364e+00, Validation Loss: 2.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 527, Training Loss: 2.363e+00, Validation Loss: 2.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 528, Training Loss: 2.363e+00, Validation Loss: 2.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 529, Training Loss: 2.362e+00, Validation Loss: 2.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 530, Training Loss: 2.361e+00, Validation Loss: 2.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 531, Training Loss: 2.361e+00, Validation Loss: 2.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 532, Training Loss: 2.360e+00, Validation Loss: 2.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 533, Training Loss: 2.360e+00, Validation Loss: 2.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 534, Training Loss: 2.359e+00, Validation Loss: 2.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 535, Training Loss: 2.359e+00, Validation Loss: 2.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 536, Training Loss: 2.358e+00, Validation Loss: 2.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 537, Training Loss: 2.358e+00, Validation Loss: 2.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 538, Training Loss: 2.357e+00, Validation Loss: 2.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 539, Training Loss: 2.357e+00, Validation Loss: 2.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 540, Training Loss: 2.356e+00, Validation Loss: 2.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 541, Training Loss: 2.356e+00, Validation Loss: 2.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 542, Training Loss: 2.355e+00, Validation Loss: 2.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 543, Training Loss: 2.355e+00, Validation Loss: 2.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 544, Training Loss: 2.354e+00, Validation Loss: 2.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 545, Training Loss: 2.354e+00, Validation Loss: 2.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 546, Training Loss: 2.353e+00, Validation Loss: 2.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 547, Training Loss: 2.353e+00, Validation Loss: 2.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 548, Training Loss: 2.352e+00, Validation Loss: 2.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 549, Training Loss: 2.352e+00, Validation Loss: 2.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 550, Training Loss: 2.351e+00, Validation Loss: 2.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 551, Training Loss: 2.351e+00, Validation Loss: 2.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 552, Training Loss: 2.350e+00, Validation Loss: 2.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 553, Training Loss: 2.350e+00, Validation Loss: 2.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 554, Training Loss: 2.349e+00, Validation Loss: 2.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 555, Training Loss: 2.349e+00, Validation Loss: 2.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 556, Training Loss: 2.348e+00, Validation Loss: 2.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 557, Training Loss: 2.348e+00, Validation Loss: 2.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 558, Training Loss: 2.347e+00, Validation Loss: 2.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 559, Training Loss: 2.347e+00, Validation Loss: 2.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 560, Training Loss: 2.346e+00, Validation Loss: 2.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 561, Training Loss: 2.346e+00, Validation Loss: 2.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 562, Training Loss: 2.345e+00, Validation Loss: 2.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 563, Training Loss: 2.345e+00, Validation Loss: 2.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 564, Training Loss: 2.344e+00, Validation Loss: 2.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 565, Training Loss: 2.344e+00, Validation Loss: 2.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 566, Training Loss: 2.343e+00, Validation Loss: 2.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 567, Training Loss: 2.343e+00, Validation Loss: 2.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 568, Training Loss: 2.342e+00, Validation Loss: 2.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 569, Training Loss: 2.342e+00, Validation Loss: 2.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 570, Training Loss: 2.341e+00, Validation Loss: 2.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 571, Training Loss: 2.341e+00, Validation Loss: 2.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 572, Training Loss: 2.340e+00, Validation Loss: 2.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 573, Training Loss: 2.340e+00, Validation Loss: 2.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 574, Training Loss: 2.339e+00, Validation Loss: 2.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 575, Training Loss: 2.339e+00, Validation Loss: 2.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 576, Training Loss: 2.338e+00, Validation Loss: 2.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 577, Training Loss: 2.338e+00, Validation Loss: 2.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 578, Training Loss: 2.337e+00, Validation Loss: 2.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 579, Training Loss: 2.337e+00, Validation Loss: 2.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 580, Training Loss: 2.336e+00, Validation Loss: 2.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 581, Training Loss: 2.336e+00, Validation Loss: 2.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 582, Training Loss: 2.335e+00, Validation Loss: 2.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 583, Training Loss: 2.335e+00, Validation Loss: 2.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 584, Training Loss: 2.334e+00, Validation Loss: 2.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 585, Training Loss: 2.333e+00, Validation Loss: 2.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 586, Training Loss: 2.333e+00, Validation Loss: 2.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 587, Training Loss: 2.332e+00, Validation Loss: 2.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 588, Training Loss: 2.332e+00, Validation Loss: 2.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 589, Training Loss: 2.331e+00, Validation Loss: 2.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 590, Training Loss: 2.331e+00, Validation Loss: 2.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 591, Training Loss: 2.330e+00, Validation Loss: 2.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 592, Training Loss: 2.330e+00, Validation Loss: 2.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 593, Training Loss: 2.329e+00, Validation Loss: 2.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 594, Training Loss: 2.329e+00, Validation Loss: 2.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 595, Training Loss: 2.328e+00, Validation Loss: 2.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 596, Training Loss: 2.328e+00, Validation Loss: 2.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 597, Training Loss: 2.327e+00, Validation Loss: 2.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 598, Training Loss: 2.327e+00, Validation Loss: 2.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 599, Training Loss: 2.326e+00, Validation Loss: 2.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 600, Training Loss: 2.326e+00, Validation Loss: 2.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 601, Training Loss: 2.325e+00, Validation Loss: 2.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 602, Training Loss: 2.325e+00, Validation Loss: 2.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 603, Training Loss: 2.324e+00, Validation Loss: 2.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 604, Training Loss: 2.324e+00, Validation Loss: 2.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 605, Training Loss: 2.323e+00, Validation Loss: 2.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 606, Training Loss: 2.323e+00, Validation Loss: 2.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 607, Training Loss: 2.322e+00, Validation Loss: 2.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 608, Training Loss: 2.322e+00, Validation Loss: 2.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 609, Training Loss: 2.321e+00, Validation Loss: 2.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 610, Training Loss: 2.321e+00, Validation Loss: 2.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 611, Training Loss: 2.320e+00, Validation Loss: 2.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 612, Training Loss: 2.320e+00, Validation Loss: 2.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 613, Training Loss: 2.319e+00, Validation Loss: 2.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 614, Training Loss: 2.319e+00, Validation Loss: 2.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 615, Training Loss: 2.318e+00, Validation Loss: 2.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 616, Training Loss: 2.318e+00, Validation Loss: 2.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 617, Training Loss: 2.317e+00, Validation Loss: 2.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 618, Training Loss: 2.317e+00, Validation Loss: 2.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 619, Training Loss: 2.316e+00, Validation Loss: 2.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 620, Training Loss: 2.316e+00, Validation Loss: 2.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 621, Training Loss: 2.315e+00, Validation Loss: 2.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 622, Training Loss: 2.315e+00, Validation Loss: 2.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 623, Training Loss: 2.314e+00, Validation Loss: 2.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 624, Training Loss: 2.314e+00, Validation Loss: 2.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 625, Training Loss: 2.313e+00, Validation Loss: 2.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 626, Training Loss: 2.313e+00, Validation Loss: 2.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 627, Training Loss: 2.312e+00, Validation Loss: 2.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 628, Training Loss: 2.312e+00, Validation Loss: 2.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 629, Training Loss: 2.311e+00, Validation Loss: 2.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 630, Training Loss: 2.311e+00, Validation Loss: 2.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 631, Training Loss: 2.310e+00, Validation Loss: 2.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 632, Training Loss: 2.310e+00, Validation Loss: 2.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 633, Training Loss: 2.309e+00, Validation Loss: 2.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 634, Training Loss: 2.309e+00, Validation Loss: 2.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 635, Training Loss: 2.308e+00, Validation Loss: 2.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 636, Training Loss: 2.308e+00, Validation Loss: 2.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 637, Training Loss: 2.307e+00, Validation Loss: 2.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 638, Training Loss: 2.307e+00, Validation Loss: 2.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 639, Training Loss: 2.306e+00, Validation Loss: 2.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 640, Training Loss: 2.306e+00, Validation Loss: 2.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 641, Training Loss: 2.305e+00, Validation Loss: 2.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 642, Training Loss: 2.305e+00, Validation Loss: 2.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 643, Training Loss: 2.304e+00, Validation Loss: 2.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 644, Training Loss: 2.304e+00, Validation Loss: 2.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 645, Training Loss: 2.303e+00, Validation Loss: 2.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 646, Training Loss: 2.303e+00, Validation Loss: 2.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 647, Training Loss: 2.302e+00, Validation Loss: 2.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 648, Training Loss: 2.302e+00, Validation Loss: 2.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 649, Training Loss: 2.302e+00, Validation Loss: 2.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 650, Training Loss: 2.301e+00, Validation Loss: 2.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 651, Training Loss: 2.301e+00, Validation Loss: 2.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 652, Training Loss: 2.300e+00, Validation Loss: 2.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 653, Training Loss: 2.300e+00, Validation Loss: 2.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 654, Training Loss: 2.299e+00, Validation Loss: 2.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 655, Training Loss: 2.299e+00, Validation Loss: 2.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 656, Training Loss: 2.298e+00, Validation Loss: 2.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 657, Training Loss: 2.298e+00, Validation Loss: 2.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 658, Training Loss: 2.297e+00, Validation Loss: 2.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 659, Training Loss: 2.297e+00, Validation Loss: 2.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 660, Training Loss: 2.296e+00, Validation Loss: 2.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 661, Training Loss: 2.296e+00, Validation Loss: 2.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 662, Training Loss: 2.295e+00, Validation Loss: 2.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 663, Training Loss: 2.295e+00, Validation Loss: 2.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 664, Training Loss: 2.294e+00, Validation Loss: 2.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 665, Training Loss: 2.294e+00, Validation Loss: 2.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 666, Training Loss: 2.293e+00, Validation Loss: 2.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 667, Training Loss: 2.293e+00, Validation Loss: 2.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 668, Training Loss: 2.292e+00, Validation Loss: 2.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 669, Training Loss: 2.292e+00, Validation Loss: 2.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 670, Training Loss: 2.291e+00, Validation Loss: 2.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 671, Training Loss: 2.291e+00, Validation Loss: 2.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 672, Training Loss: 2.290e+00, Validation Loss: 2.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 673, Training Loss: 2.290e+00, Validation Loss: 2.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 674, Training Loss: 2.289e+00, Validation Loss: 2.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 675, Training Loss: 2.289e+00, Validation Loss: 2.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 676, Training Loss: 2.288e+00, Validation Loss: 2.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 677, Training Loss: 2.288e+00, Validation Loss: 2.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 678, Training Loss: 2.287e+00, Validation Loss: 2.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 679, Training Loss: 2.287e+00, Validation Loss: 2.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 680, Training Loss: 2.286e+00, Validation Loss: 2.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 681, Training Loss: 2.286e+00, Validation Loss: 2.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 682, Training Loss: 2.285e+00, Validation Loss: 2.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 683, Training Loss: 2.285e+00, Validation Loss: 2.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 684, Training Loss: 2.284e+00, Validation Loss: 2.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 685, Training Loss: 2.284e+00, Validation Loss: 2.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 686, Training Loss: 2.283e+00, Validation Loss: 2.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 687, Training Loss: 2.283e+00, Validation Loss: 2.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 688, Training Loss: 2.282e+00, Validation Loss: 2.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 689, Training Loss: 2.282e+00, Validation Loss: 2.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 690, Training Loss: 2.281e+00, Validation Loss: 2.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 691, Training Loss: 2.281e+00, Validation Loss: 2.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 692, Training Loss: 2.280e+00, Validation Loss: 2.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 693, Training Loss: 2.280e+00, Validation Loss: 2.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 694, Training Loss: 2.279e+00, Validation Loss: 2.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 695, Training Loss: 2.279e+00, Validation Loss: 2.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 696, Training Loss: 2.278e+00, Validation Loss: 2.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 697, Training Loss: 2.278e+00, Validation Loss: 2.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 698, Training Loss: 2.277e+00, Validation Loss: 2.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 699, Training Loss: 2.277e+00, Validation Loss: 2.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 700, Training Loss: 2.276e+00, Validation Loss: 2.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 701, Training Loss: 2.276e+00, Validation Loss: 2.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 702, Training Loss: 2.275e+00, Validation Loss: 2.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 703, Training Loss: 2.275e+00, Validation Loss: 2.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 704, Training Loss: 2.274e+00, Validation Loss: 2.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 705, Training Loss: 2.274e+00, Validation Loss: 2.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 706, Training Loss: 2.273e+00, Validation Loss: 2.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 707, Training Loss: 2.273e+00, Validation Loss: 2.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 708, Training Loss: 2.272e+00, Validation Loss: 2.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 709, Training Loss: 2.272e+00, Validation Loss: 2.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 710, Training Loss: 2.271e+00, Validation Loss: 2.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 711, Training Loss: 2.271e+00, Validation Loss: 2.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 712, Training Loss: 2.270e+00, Validation Loss: 2.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 713, Training Loss: 2.270e+00, Validation Loss: 2.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 714, Training Loss: 2.269e+00, Validation Loss: 2.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 715, Training Loss: 2.269e+00, Validation Loss: 2.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 716, Training Loss: 2.268e+00, Validation Loss: 2.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 717, Training Loss: 2.268e+00, Validation Loss: 2.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 718, Training Loss: 2.267e+00, Validation Loss: 2.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 719, Training Loss: 2.267e+00, Validation Loss: 2.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 720, Training Loss: 2.266e+00, Validation Loss: 2.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 721, Training Loss: 2.266e+00, Validation Loss: 2.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 722, Training Loss: 2.265e+00, Validation Loss: 2.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 723, Training Loss: 2.265e+00, Validation Loss: 2.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 724, Training Loss: 2.264e+00, Validation Loss: 2.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 725, Training Loss: 2.264e+00, Validation Loss: 2.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 726, Training Loss: 2.263e+00, Validation Loss: 2.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 727, Training Loss: 2.263e+00, Validation Loss: 2.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 728, Training Loss: 2.262e+00, Validation Loss: 2.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 729, Training Loss: 2.262e+00, Validation Loss: 2.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 730, Training Loss: 2.262e+00, Validation Loss: 2.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 731, Training Loss: 2.261e+00, Validation Loss: 2.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 732, Training Loss: 2.261e+00, Validation Loss: 2.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 733, Training Loss: 2.260e+00, Validation Loss: 2.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 734, Training Loss: 2.260e+00, Validation Loss: 2.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 735, Training Loss: 2.259e+00, Validation Loss: 2.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 736, Training Loss: 2.259e+00, Validation Loss: 2.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 737, Training Loss: 2.258e+00, Validation Loss: 2.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 738, Training Loss: 2.258e+00, Validation Loss: 2.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 739, Training Loss: 2.257e+00, Validation Loss: 2.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 740, Training Loss: 2.257e+00, Validation Loss: 2.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 741, Training Loss: 2.256e+00, Validation Loss: 2.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 742, Training Loss: 2.256e+00, Validation Loss: 2.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 743, Training Loss: 2.255e+00, Validation Loss: 2.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 744, Training Loss: 2.255e+00, Validation Loss: 2.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 745, Training Loss: 2.254e+00, Validation Loss: 2.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 746, Training Loss: 2.254e+00, Validation Loss: 2.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 747, Training Loss: 2.253e+00, Validation Loss: 2.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 748, Training Loss: 2.253e+00, Validation Loss: 2.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 749, Training Loss: 2.252e+00, Validation Loss: 2.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 750, Training Loss: 2.252e+00, Validation Loss: 2.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 751, Training Loss: 2.251e+00, Validation Loss: 2.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 752, Training Loss: 2.251e+00, Validation Loss: 2.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 753, Training Loss: 2.250e+00, Validation Loss: 2.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 754, Training Loss: 2.250e+00, Validation Loss: 2.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 755, Training Loss: 2.249e+00, Validation Loss: 2.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 756, Training Loss: 2.249e+00, Validation Loss: 2.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 757, Training Loss: 2.248e+00, Validation Loss: 2.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 758, Training Loss: 2.248e+00, Validation Loss: 2.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 759, Training Loss: 2.247e+00, Validation Loss: 2.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 760, Training Loss: 2.247e+00, Validation Loss: 2.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 761, Training Loss: 2.246e+00, Validation Loss: 2.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 762, Training Loss: 2.246e+00, Validation Loss: 2.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 763, Training Loss: 2.245e+00, Validation Loss: 2.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 764, Training Loss: 2.245e+00, Validation Loss: 2.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 765, Training Loss: 2.244e+00, Validation Loss: 2.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 766, Training Loss: 2.244e+00, Validation Loss: 2.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 767, Training Loss: 2.243e+00, Validation Loss: 2.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 768, Training Loss: 2.243e+00, Validation Loss: 2.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 769, Training Loss: 2.242e+00, Validation Loss: 2.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 770, Training Loss: 2.242e+00, Validation Loss: 2.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 771, Training Loss: 2.242e+00, Validation Loss: 2.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 772, Training Loss: 2.241e+00, Validation Loss: 2.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 773, Training Loss: 2.241e+00, Validation Loss: 2.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 774, Training Loss: 2.240e+00, Validation Loss: 2.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 775, Training Loss: 2.239e+00, Validation Loss: 2.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 776, Training Loss: 2.239e+00, Validation Loss: 2.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 777, Training Loss: 2.238e+00, Validation Loss: 2.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 778, Training Loss: 2.238e+00, Validation Loss: 2.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 779, Training Loss: 2.237e+00, Validation Loss: 2.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 780, Training Loss: 2.237e+00, Validation Loss: 2.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 781, Training Loss: 2.236e+00, Validation Loss: 2.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 782, Training Loss: 2.236e+00, Validation Loss: 2.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 783, Training Loss: 2.235e+00, Validation Loss: 2.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 784, Training Loss: 2.235e+00, Validation Loss: 2.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 785, Training Loss: 2.234e+00, Validation Loss: 2.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 786, Training Loss: 2.234e+00, Validation Loss: 2.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 787, Training Loss: 2.233e+00, Validation Loss: 2.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 788, Training Loss: 2.233e+00, Validation Loss: 2.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 789, Training Loss: 2.232e+00, Validation Loss: 2.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 790, Training Loss: 2.232e+00, Validation Loss: 2.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 791, Training Loss: 2.231e+00, Validation Loss: 2.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 792, Training Loss: 2.231e+00, Validation Loss: 2.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 793, Training Loss: 2.230e+00, Validation Loss: 2.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 794, Training Loss: 2.230e+00, Validation Loss: 2.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 795, Training Loss: 2.229e+00, Validation Loss: 2.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 796, Training Loss: 2.229e+00, Validation Loss: 2.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 797, Training Loss: 2.228e+00, Validation Loss: 2.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 798, Training Loss: 2.228e+00, Validation Loss: 2.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 799, Training Loss: 2.227e+00, Validation Loss: 2.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 800, Training Loss: 2.227e+00, Validation Loss: 2.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 801, Training Loss: 2.226e+00, Validation Loss: 2.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 802, Training Loss: 2.226e+00, Validation Loss: 2.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 803, Training Loss: 2.225e+00, Validation Loss: 2.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 804, Training Loss: 2.225e+00, Validation Loss: 2.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 805, Training Loss: 2.224e+00, Validation Loss: 2.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 806, Training Loss: 2.224e+00, Validation Loss: 2.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 807, Training Loss: 2.223e+00, Validation Loss: 2.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 808, Training Loss: 2.223e+00, Validation Loss: 2.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 809, Training Loss: 2.222e+00, Validation Loss: 2.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 810, Training Loss: 2.221e+00, Validation Loss: 2.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 811, Training Loss: 2.221e+00, Validation Loss: 2.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 812, Training Loss: 2.220e+00, Validation Loss: 2.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 813, Training Loss: 2.220e+00, Validation Loss: 2.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 814, Training Loss: 2.219e+00, Validation Loss: 2.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 815, Training Loss: 2.219e+00, Validation Loss: 2.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 816, Training Loss: 2.218e+00, Validation Loss: 2.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 817, Training Loss: 2.218e+00, Validation Loss: 2.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 818, Training Loss: 2.217e+00, Validation Loss: 2.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 819, Training Loss: 2.217e+00, Validation Loss: 2.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 820, Training Loss: 2.216e+00, Validation Loss: 2.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 821, Training Loss: 2.216e+00, Validation Loss: 2.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 822, Training Loss: 2.215e+00, Validation Loss: 2.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 823, Training Loss: 2.215e+00, Validation Loss: 2.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 824, Training Loss: 2.214e+00, Validation Loss: 2.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 825, Training Loss: 2.214e+00, Validation Loss: 2.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 826, Training Loss: 2.213e+00, Validation Loss: 2.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 827, Training Loss: 2.213e+00, Validation Loss: 2.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 828, Training Loss: 2.212e+00, Validation Loss: 2.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 829, Training Loss: 2.212e+00, Validation Loss: 2.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 830, Training Loss: 2.211e+00, Validation Loss: 2.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 831, Training Loss: 2.211e+00, Validation Loss: 2.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 832, Training Loss: 2.210e+00, Validation Loss: 2.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 833, Training Loss: 2.210e+00, Validation Loss: 2.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 834, Training Loss: 2.209e+00, Validation Loss: 2.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 835, Training Loss: 2.209e+00, Validation Loss: 2.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 836, Training Loss: 2.208e+00, Validation Loss: 2.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 837, Training Loss: 2.208e+00, Validation Loss: 2.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 838, Training Loss: 2.207e+00, Validation Loss: 2.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 839, Training Loss: 2.207e+00, Validation Loss: 2.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 840, Training Loss: 2.206e+00, Validation Loss: 2.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 841, Training Loss: 2.206e+00, Validation Loss: 2.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 842, Training Loss: 2.205e+00, Validation Loss: 2.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 843, Training Loss: 2.205e+00, Validation Loss: 2.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 844, Training Loss: 2.204e+00, Validation Loss: 2.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 845, Training Loss: 2.204e+00, Validation Loss: 2.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 846, Training Loss: 2.203e+00, Validation Loss: 2.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 847, Training Loss: 2.203e+00, Validation Loss: 2.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 848, Training Loss: 2.202e+00, Validation Loss: 2.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 849, Training Loss: 2.202e+00, Validation Loss: 2.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 850, Training Loss: 2.201e+00, Validation Loss: 2.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 851, Training Loss: 2.201e+00, Validation Loss: 2.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 852, Training Loss: 2.200e+00, Validation Loss: 2.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 853, Training Loss: 2.200e+00, Validation Loss: 2.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 854, Training Loss: 2.199e+00, Validation Loss: 2.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 855, Training Loss: 2.199e+00, Validation Loss: 2.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 856, Training Loss: 2.198e+00, Validation Loss: 2.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 857, Training Loss: 2.198e+00, Validation Loss: 2.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 858, Training Loss: 2.197e+00, Validation Loss: 2.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 859, Training Loss: 2.197e+00, Validation Loss: 2.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 860, Training Loss: 2.196e+00, Validation Loss: 2.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 861, Training Loss: 2.196e+00, Validation Loss: 2.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 862, Training Loss: 2.195e+00, Validation Loss: 2.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 863, Training Loss: 2.195e+00, Validation Loss: 2.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 864, Training Loss: 2.194e+00, Validation Loss: 2.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 865, Training Loss: 2.194e+00, Validation Loss: 2.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 866, Training Loss: 2.193e+00, Validation Loss: 2.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 867, Training Loss: 2.193e+00, Validation Loss: 2.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 868, Training Loss: 2.192e+00, Validation Loss: 2.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 869, Training Loss: 2.192e+00, Validation Loss: 2.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 870, Training Loss: 2.191e+00, Validation Loss: 2.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 871, Training Loss: 2.191e+00, Validation Loss: 2.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 872, Training Loss: 2.190e+00, Validation Loss: 2.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 873, Training Loss: 2.190e+00, Validation Loss: 2.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 874, Training Loss: 2.189e+00, Validation Loss: 2.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 875, Training Loss: 2.189e+00, Validation Loss: 2.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 876, Training Loss: 2.188e+00, Validation Loss: 2.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 877, Training Loss: 2.188e+00, Validation Loss: 2.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 878, Training Loss: 2.187e+00, Validation Loss: 2.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 879, Training Loss: 2.187e+00, Validation Loss: 2.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 880, Training Loss: 2.186e+00, Validation Loss: 2.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 881, Training Loss: 2.186e+00, Validation Loss: 2.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 882, Training Loss: 2.185e+00, Validation Loss: 2.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 883, Training Loss: 2.185e+00, Validation Loss: 2.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 884, Training Loss: 2.184e+00, Validation Loss: 2.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 885, Training Loss: 2.184e+00, Validation Loss: 2.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 886, Training Loss: 2.183e+00, Validation Loss: 2.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 887, Training Loss: 2.183e+00, Validation Loss: 2.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 888, Training Loss: 2.182e+00, Validation Loss: 2.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 889, Training Loss: 2.182e+00, Validation Loss: 2.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 890, Training Loss: 2.181e+00, Validation Loss: 2.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 891, Training Loss: 2.181e+00, Validation Loss: 2.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 892, Training Loss: 2.180e+00, Validation Loss: 2.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 893, Training Loss: 2.180e+00, Validation Loss: 2.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 894, Training Loss: 2.179e+00, Validation Loss: 2.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 895, Training Loss: 2.179e+00, Validation Loss: 2.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 896, Training Loss: 2.178e+00, Validation Loss: 2.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 897, Training Loss: 2.178e+00, Validation Loss: 2.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 898, Training Loss: 2.177e+00, Validation Loss: 2.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 899, Training Loss: 2.177e+00, Validation Loss: 2.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 900, Training Loss: 2.176e+00, Validation Loss: 2.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 901, Training Loss: 2.176e+00, Validation Loss: 2.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 902, Training Loss: 2.175e+00, Validation Loss: 2.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 903, Training Loss: 2.175e+00, Validation Loss: 2.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 904, Training Loss: 2.174e+00, Validation Loss: 2.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 905, Training Loss: 2.174e+00, Validation Loss: 2.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 906, Training Loss: 2.173e+00, Validation Loss: 2.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 907, Training Loss: 2.173e+00, Validation Loss: 2.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 908, Training Loss: 2.172e+00, Validation Loss: 2.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 909, Training Loss: 2.172e+00, Validation Loss: 2.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 910, Training Loss: 2.171e+00, Validation Loss: 2.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 911, Training Loss: 2.171e+00, Validation Loss: 2.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 912, Training Loss: 2.170e+00, Validation Loss: 2.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 913, Training Loss: 2.170e+00, Validation Loss: 2.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 914, Training Loss: 2.169e+00, Validation Loss: 2.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 915, Training Loss: 2.169e+00, Validation Loss: 2.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 916, Training Loss: 2.168e+00, Validation Loss: 2.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 917, Training Loss: 2.168e+00, Validation Loss: 2.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 918, Training Loss: 2.167e+00, Validation Loss: 2.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 919, Training Loss: 2.167e+00, Validation Loss: 2.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 920, Training Loss: 2.166e+00, Validation Loss: 2.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 921, Training Loss: 2.166e+00, Validation Loss: 2.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 922, Training Loss: 2.165e+00, Validation Loss: 2.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 923, Training Loss: 2.165e+00, Validation Loss: 2.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 924, Training Loss: 2.164e+00, Validation Loss: 2.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 925, Training Loss: 2.164e+00, Validation Loss: 2.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 926, Training Loss: 2.163e+00, Validation Loss: 2.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 927, Training Loss: 2.163e+00, Validation Loss: 2.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 928, Training Loss: 2.163e+00, Validation Loss: 2.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 929, Training Loss: 2.162e+00, Validation Loss: 2.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 930, Training Loss: 2.162e+00, Validation Loss: 2.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 931, Training Loss: 2.161e+00, Validation Loss: 2.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 932, Training Loss: 2.161e+00, Validation Loss: 2.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 933, Training Loss: 2.160e+00, Validation Loss: 2.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 934, Training Loss: 2.160e+00, Validation Loss: 2.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 935, Training Loss: 2.159e+00, Validation Loss: 2.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 936, Training Loss: 2.159e+00, Validation Loss: 2.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 937, Training Loss: 2.158e+00, Validation Loss: 2.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 938, Training Loss: 2.158e+00, Validation Loss: 2.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 939, Training Loss: 2.157e+00, Validation Loss: 2.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 940, Training Loss: 2.157e+00, Validation Loss: 2.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 941, Training Loss: 2.156e+00, Validation Loss: 2.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 942, Training Loss: 2.156e+00, Validation Loss: 2.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 943, Training Loss: 2.155e+00, Validation Loss: 2.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 944, Training Loss: 2.155e+00, Validation Loss: 2.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 945, Training Loss: 2.154e+00, Validation Loss: 2.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 946, Training Loss: 2.154e+00, Validation Loss: 2.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 947, Training Loss: 2.153e+00, Validation Loss: 2.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 948, Training Loss: 2.153e+00, Validation Loss: 2.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 949, Training Loss: 2.152e+00, Validation Loss: 2.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 950, Training Loss: 2.152e+00, Validation Loss: 2.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 951, Training Loss: 2.151e+00, Validation Loss: 2.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 952, Training Loss: 2.151e+00, Validation Loss: 2.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 953, Training Loss: 2.150e+00, Validation Loss: 2.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 954, Training Loss: 2.150e+00, Validation Loss: 2.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 955, Training Loss: 2.149e+00, Validation Loss: 2.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 956, Training Loss: 2.149e+00, Validation Loss: 2.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 957, Training Loss: 2.148e+00, Validation Loss: 2.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 958, Training Loss: 2.148e+00, Validation Loss: 2.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 959, Training Loss: 2.147e+00, Validation Loss: 2.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 960, Training Loss: 2.147e+00, Validation Loss: 2.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 961, Training Loss: 2.146e+00, Validation Loss: 2.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 962, Training Loss: 2.146e+00, Validation Loss: 2.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 963, Training Loss: 2.145e+00, Validation Loss: 2.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 964, Training Loss: 2.145e+00, Validation Loss: 2.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 965, Training Loss: 2.145e+00, Validation Loss: 2.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 966, Training Loss: 2.144e+00, Validation Loss: 2.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 967, Training Loss: 2.144e+00, Validation Loss: 2.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 968, Training Loss: 2.143e+00, Validation Loss: 2.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 969, Training Loss: 2.143e+00, Validation Loss: 2.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 970, Training Loss: 2.142e+00, Validation Loss: 2.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 971, Training Loss: 2.142e+00, Validation Loss: 2.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 972, Training Loss: 2.141e+00, Validation Loss: 2.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 973, Training Loss: 2.141e+00, Validation Loss: 2.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 974, Training Loss: 2.140e+00, Validation Loss: 2.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 975, Training Loss: 2.140e+00, Validation Loss: 2.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 976, Training Loss: 2.139e+00, Validation Loss: 2.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 977, Training Loss: 2.139e+00, Validation Loss: 2.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 978, Training Loss: 2.138e+00, Validation Loss: 2.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 979, Training Loss: 2.138e+00, Validation Loss: 2.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 980, Training Loss: 2.137e+00, Validation Loss: 2.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 981, Training Loss: 2.137e+00, Validation Loss: 2.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 982, Training Loss: 2.136e+00, Validation Loss: 2.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 983, Training Loss: 2.136e+00, Validation Loss: 2.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 984, Training Loss: 2.135e+00, Validation Loss: 2.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 985, Training Loss: 2.135e+00, Validation Loss: 2.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 986, Training Loss: 2.134e+00, Validation Loss: 2.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 987, Training Loss: 2.134e+00, Validation Loss: 2.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 988, Training Loss: 2.133e+00, Validation Loss: 2.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 989, Training Loss: 2.133e+00, Validation Loss: 2.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 990, Training Loss: 2.132e+00, Validation Loss: 2.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 991, Training Loss: 2.132e+00, Validation Loss: 2.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 992, Training Loss: 2.131e+00, Validation Loss: 2.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 993, Training Loss: 2.131e+00, Validation Loss: 2.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 994, Training Loss: 2.130e+00, Validation Loss: 2.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 995, Training Loss: 2.130e+00, Validation Loss: 2.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 996, Training Loss: 2.130e+00, Validation Loss: 2.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 997, Training Loss: 2.129e+00, Validation Loss: 2.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 998, Training Loss: 2.129e+00, Validation Loss: 2.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 999, Training Loss: 2.128e+00, Validation Loss: 2.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1000, Training Loss: 2.128e+00, Validation Loss: 2.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1001, Training Loss: 2.127e+00, Validation Loss: 2.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1002, Training Loss: 2.127e+00, Validation Loss: 2.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1003, Training Loss: 2.126e+00, Validation Loss: 2.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1004, Training Loss: 2.126e+00, Validation Loss: 2.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1005, Training Loss: 2.125e+00, Validation Loss: 2.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1006, Training Loss: 2.125e+00, Validation Loss: 2.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1007, Training Loss: 2.124e+00, Validation Loss: 2.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1008, Training Loss: 2.124e+00, Validation Loss: 2.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1009, Training Loss: 2.123e+00, Validation Loss: 2.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1010, Training Loss: 2.123e+00, Validation Loss: 2.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1011, Training Loss: 2.122e+00, Validation Loss: 2.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1012, Training Loss: 2.122e+00, Validation Loss: 2.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1013, Training Loss: 2.121e+00, Validation Loss: 2.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1014, Training Loss: 2.121e+00, Validation Loss: 2.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1015, Training Loss: 2.120e+00, Validation Loss: 2.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1016, Training Loss: 2.120e+00, Validation Loss: 2.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1017, Training Loss: 2.119e+00, Validation Loss: 2.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1018, Training Loss: 2.119e+00, Validation Loss: 2.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1019, Training Loss: 2.118e+00, Validation Loss: 2.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1020, Training Loss: 2.118e+00, Validation Loss: 2.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1021, Training Loss: 2.117e+00, Validation Loss: 2.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1022, Training Loss: 2.117e+00, Validation Loss: 2.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1023, Training Loss: 2.117e+00, Validation Loss: 2.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1024, Training Loss: 2.116e+00, Validation Loss: 2.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1025, Training Loss: 2.116e+00, Validation Loss: 2.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1026, Training Loss: 2.115e+00, Validation Loss: 2.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1027, Training Loss: 2.115e+00, Validation Loss: 2.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1028, Training Loss: 2.114e+00, Validation Loss: 2.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1029, Training Loss: 2.114e+00, Validation Loss: 2.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1030, Training Loss: 2.113e+00, Validation Loss: 2.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1031, Training Loss: 2.113e+00, Validation Loss: 2.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1032, Training Loss: 2.112e+00, Validation Loss: 2.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1033, Training Loss: 2.112e+00, Validation Loss: 2.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1034, Training Loss: 2.111e+00, Validation Loss: 2.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1035, Training Loss: 2.111e+00, Validation Loss: 2.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1036, Training Loss: 2.110e+00, Validation Loss: 2.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1037, Training Loss: 2.110e+00, Validation Loss: 2.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1038, Training Loss: 2.109e+00, Validation Loss: 2.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1039, Training Loss: 2.109e+00, Validation Loss: 2.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1040, Training Loss: 2.108e+00, Validation Loss: 2.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1041, Training Loss: 2.108e+00, Validation Loss: 2.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1042, Training Loss: 2.107e+00, Validation Loss: 2.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1043, Training Loss: 2.107e+00, Validation Loss: 2.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1044, Training Loss: 2.106e+00, Validation Loss: 2.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1045, Training Loss: 2.106e+00, Validation Loss: 2.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1046, Training Loss: 2.106e+00, Validation Loss: 2.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1047, Training Loss: 2.105e+00, Validation Loss: 2.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1048, Training Loss: 2.105e+00, Validation Loss: 2.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1049, Training Loss: 2.104e+00, Validation Loss: 2.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1050, Training Loss: 2.104e+00, Validation Loss: 2.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1051, Training Loss: 2.103e+00, Validation Loss: 2.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1052, Training Loss: 2.103e+00, Validation Loss: 2.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1053, Training Loss: 2.102e+00, Validation Loss: 2.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1054, Training Loss: 2.102e+00, Validation Loss: 2.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1055, Training Loss: 2.101e+00, Validation Loss: 2.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1056, Training Loss: 2.101e+00, Validation Loss: 2.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1057, Training Loss: 2.100e+00, Validation Loss: 2.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1058, Training Loss: 2.100e+00, Validation Loss: 2.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1059, Training Loss: 2.099e+00, Validation Loss: 2.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1060, Training Loss: 2.099e+00, Validation Loss: 2.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1061, Training Loss: 2.098e+00, Validation Loss: 2.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1062, Training Loss: 2.098e+00, Validation Loss: 2.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1063, Training Loss: 2.097e+00, Validation Loss: 2.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1064, Training Loss: 2.097e+00, Validation Loss: 2.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1065, Training Loss: 2.097e+00, Validation Loss: 2.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1066, Training Loss: 2.096e+00, Validation Loss: 2.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1067, Training Loss: 2.096e+00, Validation Loss: 2.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1068, Training Loss: 2.095e+00, Validation Loss: 2.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1069, Training Loss: 2.095e+00, Validation Loss: 2.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1070, Training Loss: 2.094e+00, Validation Loss: 2.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1071, Training Loss: 2.094e+00, Validation Loss: 2.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1072, Training Loss: 2.093e+00, Validation Loss: 2.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1073, Training Loss: 2.093e+00, Validation Loss: 2.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1074, Training Loss: 2.092e+00, Validation Loss: 2.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1075, Training Loss: 2.092e+00, Validation Loss: 2.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1076, Training Loss: 2.091e+00, Validation Loss: 2.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1077, Training Loss: 2.091e+00, Validation Loss: 2.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1078, Training Loss: 2.090e+00, Validation Loss: 2.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1079, Training Loss: 2.090e+00, Validation Loss: 2.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1080, Training Loss: 2.089e+00, Validation Loss: 2.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1081, Training Loss: 2.089e+00, Validation Loss: 2.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1082, Training Loss: 2.088e+00, Validation Loss: 2.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1083, Training Loss: 2.088e+00, Validation Loss: 2.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1084, Training Loss: 2.088e+00, Validation Loss: 2.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1085, Training Loss: 2.087e+00, Validation Loss: 2.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1086, Training Loss: 2.087e+00, Validation Loss: 2.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1087, Training Loss: 2.086e+00, Validation Loss: 2.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1088, Training Loss: 2.086e+00, Validation Loss: 2.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1089, Training Loss: 2.085e+00, Validation Loss: 2.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1090, Training Loss: 2.085e+00, Validation Loss: 2.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1091, Training Loss: 2.084e+00, Validation Loss: 2.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1092, Training Loss: 2.084e+00, Validation Loss: 2.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1093, Training Loss: 2.083e+00, Validation Loss: 2.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1094, Training Loss: 2.083e+00, Validation Loss: 2.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1095, Training Loss: 2.082e+00, Validation Loss: 2.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1096, Training Loss: 2.082e+00, Validation Loss: 2.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1097, Training Loss: 2.081e+00, Validation Loss: 2.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1098, Training Loss: 2.081e+00, Validation Loss: 2.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1099, Training Loss: 2.080e+00, Validation Loss: 2.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1100, Training Loss: 2.080e+00, Validation Loss: 2.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1101, Training Loss: 2.079e+00, Validation Loss: 2.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1102, Training Loss: 2.079e+00, Validation Loss: 2.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1103, Training Loss: 2.079e+00, Validation Loss: 2.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1104, Training Loss: 2.078e+00, Validation Loss: 2.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1105, Training Loss: 2.078e+00, Validation Loss: 2.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1106, Training Loss: 2.077e+00, Validation Loss: 2.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1107, Training Loss: 2.077e+00, Validation Loss: 2.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1108, Training Loss: 2.076e+00, Validation Loss: 2.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1109, Training Loss: 2.076e+00, Validation Loss: 2.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1110, Training Loss: 2.075e+00, Validation Loss: 2.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1111, Training Loss: 2.075e+00, Validation Loss: 2.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1112, Training Loss: 2.074e+00, Validation Loss: 2.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1113, Training Loss: 2.074e+00, Validation Loss: 2.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1114, Training Loss: 2.073e+00, Validation Loss: 2.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1115, Training Loss: 2.073e+00, Validation Loss: 2.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1116, Training Loss: 2.072e+00, Validation Loss: 2.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1117, Training Loss: 2.072e+00, Validation Loss: 2.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1118, Training Loss: 2.072e+00, Validation Loss: 2.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1119, Training Loss: 2.071e+00, Validation Loss: 2.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1120, Training Loss: 2.071e+00, Validation Loss: 2.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1121, Training Loss: 2.070e+00, Validation Loss: 2.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1122, Training Loss: 2.070e+00, Validation Loss: 2.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1123, Training Loss: 2.069e+00, Validation Loss: 2.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1124, Training Loss: 2.069e+00, Validation Loss: 2.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1125, Training Loss: 2.068e+00, Validation Loss: 2.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1126, Training Loss: 2.068e+00, Validation Loss: 2.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1127, Training Loss: 2.067e+00, Validation Loss: 2.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1128, Training Loss: 2.067e+00, Validation Loss: 2.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1129, Training Loss: 2.066e+00, Validation Loss: 2.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1130, Training Loss: 2.066e+00, Validation Loss: 2.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1131, Training Loss: 2.065e+00, Validation Loss: 2.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1132, Training Loss: 2.065e+00, Validation Loss: 2.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1133, Training Loss: 2.064e+00, Validation Loss: 2.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1134, Training Loss: 2.064e+00, Validation Loss: 2.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1135, Training Loss: 2.064e+00, Validation Loss: 2.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1136, Training Loss: 2.063e+00, Validation Loss: 2.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1137, Training Loss: 2.063e+00, Validation Loss: 2.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1138, Training Loss: 2.062e+00, Validation Loss: 2.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1139, Training Loss: 2.062e+00, Validation Loss: 2.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1140, Training Loss: 2.061e+00, Validation Loss: 2.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1141, Training Loss: 2.061e+00, Validation Loss: 2.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1142, Training Loss: 2.060e+00, Validation Loss: 2.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1143, Training Loss: 2.060e+00, Validation Loss: 2.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1144, Training Loss: 2.059e+00, Validation Loss: 2.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1145, Training Loss: 2.059e+00, Validation Loss: 2.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1146, Training Loss: 2.058e+00, Validation Loss: 2.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1147, Training Loss: 2.058e+00, Validation Loss: 2.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1148, Training Loss: 2.057e+00, Validation Loss: 2.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1149, Training Loss: 2.057e+00, Validation Loss: 2.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1150, Training Loss: 2.057e+00, Validation Loss: 2.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1151, Training Loss: 2.056e+00, Validation Loss: 2.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1152, Training Loss: 2.056e+00, Validation Loss: 2.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1153, Training Loss: 2.055e+00, Validation Loss: 2.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1154, Training Loss: 2.055e+00, Validation Loss: 2.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1155, Training Loss: 2.054e+00, Validation Loss: 2.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1156, Training Loss: 2.054e+00, Validation Loss: 2.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1157, Training Loss: 2.053e+00, Validation Loss: 2.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1158, Training Loss: 2.053e+00, Validation Loss: 2.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1159, Training Loss: 2.052e+00, Validation Loss: 2.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1160, Training Loss: 2.052e+00, Validation Loss: 2.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1161, Training Loss: 2.051e+00, Validation Loss: 2.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1162, Training Loss: 2.051e+00, Validation Loss: 2.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1163, Training Loss: 2.050e+00, Validation Loss: 2.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1164, Training Loss: 2.050e+00, Validation Loss: 2.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1165, Training Loss: 2.050e+00, Validation Loss: 2.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1166, Training Loss: 2.049e+00, Validation Loss: 2.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1167, Training Loss: 2.049e+00, Validation Loss: 2.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1168, Training Loss: 2.048e+00, Validation Loss: 2.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1169, Training Loss: 2.048e+00, Validation Loss: 2.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1170, Training Loss: 2.047e+00, Validation Loss: 2.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1171, Training Loss: 2.047e+00, Validation Loss: 2.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1172, Training Loss: 2.046e+00, Validation Loss: 2.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1173, Training Loss: 2.046e+00, Validation Loss: 2.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1174, Training Loss: 2.045e+00, Validation Loss: 2.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1175, Training Loss: 2.045e+00, Validation Loss: 2.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1176, Training Loss: 2.044e+00, Validation Loss: 2.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1177, Training Loss: 2.044e+00, Validation Loss: 2.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1178, Training Loss: 2.044e+00, Validation Loss: 2.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1179, Training Loss: 2.043e+00, Validation Loss: 2.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1180, Training Loss: 2.043e+00, Validation Loss: 2.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1181, Training Loss: 2.042e+00, Validation Loss: 2.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1182, Training Loss: 2.042e+00, Validation Loss: 2.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1183, Training Loss: 2.041e+00, Validation Loss: 2.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1184, Training Loss: 2.041e+00, Validation Loss: 2.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1185, Training Loss: 2.040e+00, Validation Loss: 2.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1186, Training Loss: 2.040e+00, Validation Loss: 2.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1187, Training Loss: 2.039e+00, Validation Loss: 2.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1188, Training Loss: 2.039e+00, Validation Loss: 2.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1189, Training Loss: 2.038e+00, Validation Loss: 2.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1190, Training Loss: 2.038e+00, Validation Loss: 2.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1191, Training Loss: 2.038e+00, Validation Loss: 2.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1192, Training Loss: 2.037e+00, Validation Loss: 2.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1193, Training Loss: 2.037e+00, Validation Loss: 2.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1194, Training Loss: 2.036e+00, Validation Loss: 2.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1195, Training Loss: 2.036e+00, Validation Loss: 2.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1196, Training Loss: 2.035e+00, Validation Loss: 2.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1197, Training Loss: 2.035e+00, Validation Loss: 2.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1198, Training Loss: 2.034e+00, Validation Loss: 2.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1199, Training Loss: 2.034e+00, Validation Loss: 2.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1200, Training Loss: 2.033e+00, Validation Loss: 2.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1201, Training Loss: 2.033e+00, Validation Loss: 2.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1202, Training Loss: 2.032e+00, Validation Loss: 2.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1203, Training Loss: 2.032e+00, Validation Loss: 2.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1204, Training Loss: 2.032e+00, Validation Loss: 2.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1205, Training Loss: 2.031e+00, Validation Loss: 2.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1206, Training Loss: 2.031e+00, Validation Loss: 2.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1207, Training Loss: 2.030e+00, Validation Loss: 2.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1208, Training Loss: 2.030e+00, Validation Loss: 2.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1209, Training Loss: 2.029e+00, Validation Loss: 2.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1210, Training Loss: 2.029e+00, Validation Loss: 2.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1211, Training Loss: 2.028e+00, Validation Loss: 2.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1212, Training Loss: 2.028e+00, Validation Loss: 2.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1213, Training Loss: 2.027e+00, Validation Loss: 2.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1214, Training Loss: 2.027e+00, Validation Loss: 2.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1215, Training Loss: 2.026e+00, Validation Loss: 2.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1216, Training Loss: 2.026e+00, Validation Loss: 2.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1217, Training Loss: 2.026e+00, Validation Loss: 2.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1218, Training Loss: 2.025e+00, Validation Loss: 2.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1219, Training Loss: 2.025e+00, Validation Loss: 2.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1220, Training Loss: 2.024e+00, Validation Loss: 2.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1221, Training Loss: 2.024e+00, Validation Loss: 2.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1222, Training Loss: 2.023e+00, Validation Loss: 2.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1223, Training Loss: 2.023e+00, Validation Loss: 2.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1224, Training Loss: 2.022e+00, Validation Loss: 2.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1225, Training Loss: 2.022e+00, Validation Loss: 2.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1226, Training Loss: 2.021e+00, Validation Loss: 2.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1227, Training Loss: 2.021e+00, Validation Loss: 2.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1228, Training Loss: 2.021e+00, Validation Loss: 2.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1229, Training Loss: 2.020e+00, Validation Loss: 2.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1230, Training Loss: 2.020e+00, Validation Loss: 2.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1231, Training Loss: 2.019e+00, Validation Loss: 2.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1232, Training Loss: 2.019e+00, Validation Loss: 2.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1233, Training Loss: 2.018e+00, Validation Loss: 2.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1234, Training Loss: 2.018e+00, Validation Loss: 2.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1235, Training Loss: 2.017e+00, Validation Loss: 2.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1236, Training Loss: 2.017e+00, Validation Loss: 2.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1237, Training Loss: 2.016e+00, Validation Loss: 2.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1238, Training Loss: 2.016e+00, Validation Loss: 2.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1239, Training Loss: 2.016e+00, Validation Loss: 2.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1240, Training Loss: 2.015e+00, Validation Loss: 2.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1241, Training Loss: 2.015e+00, Validation Loss: 2.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1242, Training Loss: 2.014e+00, Validation Loss: 2.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1243, Training Loss: 2.014e+00, Validation Loss: 2.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1244, Training Loss: 2.013e+00, Validation Loss: 2.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1245, Training Loss: 2.013e+00, Validation Loss: 2.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1246, Training Loss: 2.012e+00, Validation Loss: 2.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1247, Training Loss: 2.012e+00, Validation Loss: 2.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1248, Training Loss: 2.011e+00, Validation Loss: 2.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1249, Training Loss: 2.011e+00, Validation Loss: 2.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1250, Training Loss: 2.011e+00, Validation Loss: 2.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1251, Training Loss: 2.010e+00, Validation Loss: 2.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1252, Training Loss: 2.010e+00, Validation Loss: 2.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1253, Training Loss: 2.009e+00, Validation Loss: 2.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1254, Training Loss: 2.009e+00, Validation Loss: 2.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1255, Training Loss: 2.008e+00, Validation Loss: 2.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1256, Training Loss: 2.008e+00, Validation Loss: 2.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1257, Training Loss: 2.007e+00, Validation Loss: 2.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1258, Training Loss: 2.007e+00, Validation Loss: 2.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1259, Training Loss: 2.006e+00, Validation Loss: 2.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1260, Training Loss: 2.006e+00, Validation Loss: 2.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1261, Training Loss: 2.006e+00, Validation Loss: 2.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1262, Training Loss: 2.005e+00, Validation Loss: 2.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1263, Training Loss: 2.005e+00, Validation Loss: 2.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1264, Training Loss: 2.004e+00, Validation Loss: 2.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1265, Training Loss: 2.004e+00, Validation Loss: 2.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1266, Training Loss: 2.003e+00, Validation Loss: 2.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1267, Training Loss: 2.003e+00, Validation Loss: 2.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1268, Training Loss: 2.002e+00, Validation Loss: 2.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1269, Training Loss: 2.002e+00, Validation Loss: 2.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1270, Training Loss: 2.001e+00, Validation Loss: 2.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1271, Training Loss: 2.001e+00, Validation Loss: 2.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1272, Training Loss: 2.001e+00, Validation Loss: 2.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1273, Training Loss: 2.000e+00, Validation Loss: 2.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1274, Training Loss: 2.000e+00, Validation Loss: 2.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1275, Training Loss: 1.999e+00, Validation Loss: 2.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1276, Training Loss: 1.999e+00, Validation Loss: 2.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1277, Training Loss: 1.998e+00, Validation Loss: 2.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1278, Training Loss: 1.998e+00, Validation Loss: 2.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1279, Training Loss: 1.997e+00, Validation Loss: 2.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1280, Training Loss: 1.997e+00, Validation Loss: 2.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1281, Training Loss: 1.996e+00, Validation Loss: 2.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1282, Training Loss: 1.996e+00, Validation Loss: 2.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1283, Training Loss: 1.996e+00, Validation Loss: 2.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1284, Training Loss: 1.995e+00, Validation Loss: 2.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1285, Training Loss: 1.995e+00, Validation Loss: 2.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1286, Training Loss: 1.994e+00, Validation Loss: 2.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1287, Training Loss: 1.994e+00, Validation Loss: 2.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1288, Training Loss: 1.993e+00, Validation Loss: 2.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1289, Training Loss: 1.993e+00, Validation Loss: 2.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1290, Training Loss: 1.992e+00, Validation Loss: 2.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1291, Training Loss: 1.992e+00, Validation Loss: 2.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1292, Training Loss: 1.991e+00, Validation Loss: 2.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1293, Training Loss: 1.991e+00, Validation Loss: 2.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1294, Training Loss: 1.991e+00, Validation Loss: 2.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1295, Training Loss: 1.990e+00, Validation Loss: 2.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1296, Training Loss: 1.990e+00, Validation Loss: 2.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1297, Training Loss: 1.989e+00, Validation Loss: 2.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1298, Training Loss: 1.989e+00, Validation Loss: 2.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1299, Training Loss: 1.988e+00, Validation Loss: 2.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1300, Training Loss: 1.988e+00, Validation Loss: 2.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1301, Training Loss: 1.987e+00, Validation Loss: 2.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1302, Training Loss: 1.987e+00, Validation Loss: 2.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1303, Training Loss: 1.987e+00, Validation Loss: 2.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1304, Training Loss: 1.986e+00, Validation Loss: 2.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1305, Training Loss: 1.986e+00, Validation Loss: 2.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1306, Training Loss: 1.985e+00, Validation Loss: 2.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1307, Training Loss: 1.985e+00, Validation Loss: 2.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1308, Training Loss: 1.984e+00, Validation Loss: 2.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1309, Training Loss: 1.984e+00, Validation Loss: 2.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1310, Training Loss: 1.983e+00, Validation Loss: 2.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1311, Training Loss: 1.983e+00, Validation Loss: 2.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1312, Training Loss: 1.982e+00, Validation Loss: 2.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1313, Training Loss: 1.982e+00, Validation Loss: 2.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1314, Training Loss: 1.982e+00, Validation Loss: 2.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1315, Training Loss: 1.981e+00, Validation Loss: 2.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1316, Training Loss: 1.981e+00, Validation Loss: 2.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1317, Training Loss: 1.980e+00, Validation Loss: 2.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1318, Training Loss: 1.980e+00, Validation Loss: 2.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1319, Training Loss: 1.979e+00, Validation Loss: 2.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1320, Training Loss: 1.979e+00, Validation Loss: 2.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1321, Training Loss: 1.978e+00, Validation Loss: 2.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1322, Training Loss: 1.978e+00, Validation Loss: 2.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1323, Training Loss: 1.978e+00, Validation Loss: 2.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1324, Training Loss: 1.977e+00, Validation Loss: 2.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1325, Training Loss: 1.977e+00, Validation Loss: 2.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1326, Training Loss: 1.976e+00, Validation Loss: 2.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1327, Training Loss: 1.976e+00, Validation Loss: 2.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1328, Training Loss: 1.975e+00, Validation Loss: 2.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1329, Training Loss: 1.975e+00, Validation Loss: 2.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1330, Training Loss: 1.974e+00, Validation Loss: 2.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1331, Training Loss: 1.974e+00, Validation Loss: 2.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1332, Training Loss: 1.973e+00, Validation Loss: 2.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1333, Training Loss: 1.973e+00, Validation Loss: 2.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1334, Training Loss: 1.973e+00, Validation Loss: 2.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1335, Training Loss: 1.972e+00, Validation Loss: 2.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1336, Training Loss: 1.972e+00, Validation Loss: 2.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1337, Training Loss: 1.971e+00, Validation Loss: 2.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1338, Training Loss: 1.971e+00, Validation Loss: 2.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1339, Training Loss: 1.970e+00, Validation Loss: 2.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1340, Training Loss: 1.970e+00, Validation Loss: 2.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1341, Training Loss: 1.969e+00, Validation Loss: 2.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1342, Training Loss: 1.969e+00, Validation Loss: 2.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1343, Training Loss: 1.969e+00, Validation Loss: 2.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1344, Training Loss: 1.968e+00, Validation Loss: 2.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1345, Training Loss: 1.968e+00, Validation Loss: 2.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1346, Training Loss: 1.967e+00, Validation Loss: 2.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1347, Training Loss: 1.967e+00, Validation Loss: 2.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1348, Training Loss: 1.966e+00, Validation Loss: 2.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1349, Training Loss: 1.966e+00, Validation Loss: 2.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1350, Training Loss: 1.965e+00, Validation Loss: 2.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1351, Training Loss: 1.965e+00, Validation Loss: 2.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1352, Training Loss: 1.965e+00, Validation Loss: 2.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1353, Training Loss: 1.964e+00, Validation Loss: 2.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1354, Training Loss: 1.964e+00, Validation Loss: 2.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1355, Training Loss: 1.963e+00, Validation Loss: 2.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1356, Training Loss: 1.963e+00, Validation Loss: 2.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1357, Training Loss: 1.962e+00, Validation Loss: 2.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1358, Training Loss: 1.962e+00, Validation Loss: 2.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1359, Training Loss: 1.961e+00, Validation Loss: 2.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1360, Training Loss: 1.961e+00, Validation Loss: 2.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1361, Training Loss: 1.961e+00, Validation Loss: 2.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1362, Training Loss: 1.960e+00, Validation Loss: 2.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1363, Training Loss: 1.960e+00, Validation Loss: 2.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1364, Training Loss: 1.959e+00, Validation Loss: 2.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1365, Training Loss: 1.959e+00, Validation Loss: 2.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1366, Training Loss: 1.958e+00, Validation Loss: 2.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1367, Training Loss: 1.958e+00, Validation Loss: 2.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1368, Training Loss: 1.957e+00, Validation Loss: 2.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1369, Training Loss: 1.957e+00, Validation Loss: 2.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1370, Training Loss: 1.957e+00, Validation Loss: 2.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1371, Training Loss: 1.956e+00, Validation Loss: 2.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1372, Training Loss: 1.956e+00, Validation Loss: 2.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1373, Training Loss: 1.955e+00, Validation Loss: 2.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1374, Training Loss: 1.955e+00, Validation Loss: 2.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1375, Training Loss: 1.954e+00, Validation Loss: 2.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1376, Training Loss: 1.954e+00, Validation Loss: 2.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1377, Training Loss: 1.953e+00, Validation Loss: 2.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1378, Training Loss: 1.953e+00, Validation Loss: 2.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1379, Training Loss: 1.953e+00, Validation Loss: 2.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1380, Training Loss: 1.952e+00, Validation Loss: 2.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1381, Training Loss: 1.952e+00, Validation Loss: 2.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1382, Training Loss: 1.951e+00, Validation Loss: 2.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1383, Training Loss: 1.951e+00, Validation Loss: 2.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1384, Training Loss: 1.950e+00, Validation Loss: 2.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1385, Training Loss: 1.950e+00, Validation Loss: 2.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1386, Training Loss: 1.949e+00, Validation Loss: 2.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1387, Training Loss: 1.949e+00, Validation Loss: 2.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1388, Training Loss: 1.949e+00, Validation Loss: 2.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1389, Training Loss: 1.948e+00, Validation Loss: 2.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1390, Training Loss: 1.948e+00, Validation Loss: 2.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1391, Training Loss: 1.947e+00, Validation Loss: 2.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1392, Training Loss: 1.947e+00, Validation Loss: 2.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1393, Training Loss: 1.946e+00, Validation Loss: 2.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1394, Training Loss: 1.946e+00, Validation Loss: 2.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1395, Training Loss: 1.945e+00, Validation Loss: 2.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1396, Training Loss: 1.945e+00, Validation Loss: 2.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1397, Training Loss: 1.945e+00, Validation Loss: 2.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1398, Training Loss: 1.944e+00, Validation Loss: 2.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1399, Training Loss: 1.944e+00, Validation Loss: 2.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1400, Training Loss: 1.943e+00, Validation Loss: 2.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1401, Training Loss: 1.943e+00, Validation Loss: 2.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1402, Training Loss: 1.942e+00, Validation Loss: 2.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1403, Training Loss: 1.942e+00, Validation Loss: 2.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1404, Training Loss: 1.941e+00, Validation Loss: 2.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1405, Training Loss: 1.941e+00, Validation Loss: 2.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1406, Training Loss: 1.941e+00, Validation Loss: 2.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1407, Training Loss: 1.940e+00, Validation Loss: 2.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1408, Training Loss: 1.940e+00, Validation Loss: 2.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1409, Training Loss: 1.939e+00, Validation Loss: 2.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1410, Training Loss: 1.939e+00, Validation Loss: 2.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1411, Training Loss: 1.938e+00, Validation Loss: 2.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1412, Training Loss: 1.938e+00, Validation Loss: 2.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1413, Training Loss: 1.937e+00, Validation Loss: 2.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1414, Training Loss: 1.937e+00, Validation Loss: 2.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1415, Training Loss: 1.937e+00, Validation Loss: 2.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1416, Training Loss: 1.936e+00, Validation Loss: 2.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1417, Training Loss: 1.936e+00, Validation Loss: 2.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1418, Training Loss: 1.935e+00, Validation Loss: 2.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1419, Training Loss: 1.935e+00, Validation Loss: 2.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1420, Training Loss: 1.934e+00, Validation Loss: 2.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1421, Training Loss: 1.934e+00, Validation Loss: 2.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1422, Training Loss: 1.934e+00, Validation Loss: 2.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1423, Training Loss: 1.933e+00, Validation Loss: 2.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1424, Training Loss: 1.933e+00, Validation Loss: 2.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1425, Training Loss: 1.932e+00, Validation Loss: 2.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1426, Training Loss: 1.932e+00, Validation Loss: 2.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1427, Training Loss: 1.931e+00, Validation Loss: 2.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1428, Training Loss: 1.931e+00, Validation Loss: 2.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1429, Training Loss: 1.930e+00, Validation Loss: 2.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1430, Training Loss: 1.930e+00, Validation Loss: 2.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1431, Training Loss: 1.930e+00, Validation Loss: 2.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1432, Training Loss: 1.929e+00, Validation Loss: 2.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1433, Training Loss: 1.929e+00, Validation Loss: 2.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1434, Training Loss: 1.928e+00, Validation Loss: 2.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1435, Training Loss: 1.928e+00, Validation Loss: 2.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1436, Training Loss: 1.927e+00, Validation Loss: 2.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1437, Training Loss: 1.927e+00, Validation Loss: 2.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1438, Training Loss: 1.926e+00, Validation Loss: 2.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1439, Training Loss: 1.926e+00, Validation Loss: 2.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1440, Training Loss: 1.926e+00, Validation Loss: 2.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1441, Training Loss: 1.925e+00, Validation Loss: 2.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1442, Training Loss: 1.925e+00, Validation Loss: 2.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1443, Training Loss: 1.924e+00, Validation Loss: 2.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1444, Training Loss: 1.924e+00, Validation Loss: 2.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1445, Training Loss: 1.923e+00, Validation Loss: 2.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1446, Training Loss: 1.923e+00, Validation Loss: 2.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1447, Training Loss: 1.922e+00, Validation Loss: 2.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1448, Training Loss: 1.922e+00, Validation Loss: 2.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1449, Training Loss: 1.922e+00, Validation Loss: 2.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1450, Training Loss: 1.921e+00, Validation Loss: 2.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1451, Training Loss: 1.921e+00, Validation Loss: 2.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1452, Training Loss: 1.920e+00, Validation Loss: 2.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1453, Training Loss: 1.920e+00, Validation Loss: 2.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1454, Training Loss: 1.919e+00, Validation Loss: 2.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1455, Training Loss: 1.919e+00, Validation Loss: 2.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1456, Training Loss: 1.919e+00, Validation Loss: 2.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1457, Training Loss: 1.918e+00, Validation Loss: 2.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1458, Training Loss: 1.918e+00, Validation Loss: 2.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1459, Training Loss: 1.917e+00, Validation Loss: 2.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1460, Training Loss: 1.917e+00, Validation Loss: 2.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1461, Training Loss: 1.916e+00, Validation Loss: 2.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1462, Training Loss: 1.916e+00, Validation Loss: 2.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1463, Training Loss: 1.915e+00, Validation Loss: 2.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1464, Training Loss: 1.915e+00, Validation Loss: 2.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1465, Training Loss: 1.915e+00, Validation Loss: 2.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1466, Training Loss: 1.914e+00, Validation Loss: 2.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1467, Training Loss: 1.914e+00, Validation Loss: 2.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1468, Training Loss: 1.913e+00, Validation Loss: 2.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1469, Training Loss: 1.913e+00, Validation Loss: 2.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1470, Training Loss: 1.912e+00, Validation Loss: 2.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1471, Training Loss: 1.912e+00, Validation Loss: 2.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1472, Training Loss: 1.912e+00, Validation Loss: 2.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1473, Training Loss: 1.911e+00, Validation Loss: 2.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1474, Training Loss: 1.911e+00, Validation Loss: 2.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1475, Training Loss: 1.910e+00, Validation Loss: 2.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1476, Training Loss: 1.910e+00, Validation Loss: 2.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1477, Training Loss: 1.909e+00, Validation Loss: 2.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1478, Training Loss: 1.909e+00, Validation Loss: 2.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1479, Training Loss: 1.908e+00, Validation Loss: 2.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1480, Training Loss: 1.908e+00, Validation Loss: 2.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1481, Training Loss: 1.908e+00, Validation Loss: 2.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1482, Training Loss: 1.907e+00, Validation Loss: 2.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1483, Training Loss: 1.907e+00, Validation Loss: 2.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1484, Training Loss: 1.906e+00, Validation Loss: 2.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1485, Training Loss: 1.906e+00, Validation Loss: 2.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1486, Training Loss: 1.905e+00, Validation Loss: 2.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1487, Training Loss: 1.905e+00, Validation Loss: 2.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1488, Training Loss: 1.905e+00, Validation Loss: 2.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1489, Training Loss: 1.904e+00, Validation Loss: 2.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1490, Training Loss: 1.904e+00, Validation Loss: 2.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1491, Training Loss: 1.903e+00, Validation Loss: 2.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1492, Training Loss: 1.903e+00, Validation Loss: 2.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1493, Training Loss: 1.902e+00, Validation Loss: 2.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1494, Training Loss: 1.902e+00, Validation Loss: 2.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1495, Training Loss: 1.901e+00, Validation Loss: 2.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1496, Training Loss: 1.901e+00, Validation Loss: 2.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1497, Training Loss: 1.901e+00, Validation Loss: 2.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1498, Training Loss: 1.900e+00, Validation Loss: 2.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1499, Training Loss: 1.900e+00, Validation Loss: 2.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1500, Training Loss: 1.899e+00, Validation Loss: 2.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1501, Training Loss: 1.899e+00, Validation Loss: 2.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1502, Training Loss: 1.898e+00, Validation Loss: 2.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1503, Training Loss: 1.898e+00, Validation Loss: 2.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1504, Training Loss: 1.898e+00, Validation Loss: 2.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1505, Training Loss: 1.897e+00, Validation Loss: 2.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1506, Training Loss: 1.897e+00, Validation Loss: 2.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1507, Training Loss: 1.896e+00, Validation Loss: 2.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1508, Training Loss: 1.896e+00, Validation Loss: 2.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1509, Training Loss: 1.895e+00, Validation Loss: 2.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1510, Training Loss: 1.895e+00, Validation Loss: 2.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1511, Training Loss: 1.894e+00, Validation Loss: 2.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1512, Training Loss: 1.894e+00, Validation Loss: 2.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1513, Training Loss: 1.894e+00, Validation Loss: 2.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1514, Training Loss: 1.893e+00, Validation Loss: 2.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1515, Training Loss: 1.893e+00, Validation Loss: 2.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1516, Training Loss: 1.892e+00, Validation Loss: 2.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1517, Training Loss: 1.892e+00, Validation Loss: 2.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1518, Training Loss: 1.891e+00, Validation Loss: 2.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1519, Training Loss: 1.891e+00, Validation Loss: 2.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1520, Training Loss: 1.891e+00, Validation Loss: 2.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1521, Training Loss: 1.890e+00, Validation Loss: 2.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1522, Training Loss: 1.890e+00, Validation Loss: 2.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1523, Training Loss: 1.889e+00, Validation Loss: 2.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1524, Training Loss: 1.889e+00, Validation Loss: 2.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1525, Training Loss: 1.888e+00, Validation Loss: 2.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1526, Training Loss: 1.888e+00, Validation Loss: 2.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1527, Training Loss: 1.888e+00, Validation Loss: 2.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1528, Training Loss: 1.887e+00, Validation Loss: 2.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1529, Training Loss: 1.887e+00, Validation Loss: 2.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1530, Training Loss: 1.886e+00, Validation Loss: 2.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1531, Training Loss: 1.886e+00, Validation Loss: 2.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1532, Training Loss: 1.885e+00, Validation Loss: 2.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1533, Training Loss: 1.885e+00, Validation Loss: 2.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1534, Training Loss: 1.884e+00, Validation Loss: 2.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1535, Training Loss: 1.884e+00, Validation Loss: 2.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1536, Training Loss: 1.884e+00, Validation Loss: 2.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1537, Training Loss: 1.883e+00, Validation Loss: 2.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1538, Training Loss: 1.883e+00, Validation Loss: 2.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1539, Training Loss: 1.882e+00, Validation Loss: 2.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1540, Training Loss: 1.882e+00, Validation Loss: 2.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1541, Training Loss: 1.881e+00, Validation Loss: 2.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1542, Training Loss: 1.881e+00, Validation Loss: 2.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1543, Training Loss: 1.881e+00, Validation Loss: 2.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1544, Training Loss: 1.880e+00, Validation Loss: 2.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1545, Training Loss: 1.880e+00, Validation Loss: 2.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1546, Training Loss: 1.879e+00, Validation Loss: 2.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1547, Training Loss: 1.879e+00, Validation Loss: 2.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1548, Training Loss: 1.878e+00, Validation Loss: 2.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1549, Training Loss: 1.878e+00, Validation Loss: 2.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1550, Training Loss: 1.878e+00, Validation Loss: 2.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1551, Training Loss: 1.877e+00, Validation Loss: 2.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1552, Training Loss: 1.877e+00, Validation Loss: 2.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1553, Training Loss: 1.876e+00, Validation Loss: 2.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1554, Training Loss: 1.876e+00, Validation Loss: 2.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1555, Training Loss: 1.875e+00, Validation Loss: 2.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1556, Training Loss: 1.875e+00, Validation Loss: 2.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1557, Training Loss: 1.874e+00, Validation Loss: 2.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1558, Training Loss: 1.874e+00, Validation Loss: 2.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1559, Training Loss: 1.874e+00, Validation Loss: 2.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1560, Training Loss: 1.873e+00, Validation Loss: 2.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1561, Training Loss: 1.873e+00, Validation Loss: 2.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1562, Training Loss: 1.872e+00, Validation Loss: 2.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1563, Training Loss: 1.872e+00, Validation Loss: 2.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1564, Training Loss: 1.871e+00, Validation Loss: 2.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1565, Training Loss: 1.871e+00, Validation Loss: 2.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1566, Training Loss: 1.871e+00, Validation Loss: 2.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1567, Training Loss: 1.870e+00, Validation Loss: 2.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1568, Training Loss: 1.870e+00, Validation Loss: 2.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1569, Training Loss: 1.869e+00, Validation Loss: 2.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1570, Training Loss: 1.869e+00, Validation Loss: 2.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1571, Training Loss: 1.868e+00, Validation Loss: 2.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1572, Training Loss: 1.868e+00, Validation Loss: 2.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1573, Training Loss: 1.868e+00, Validation Loss: 2.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1574, Training Loss: 1.867e+00, Validation Loss: 2.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1575, Training Loss: 1.867e+00, Validation Loss: 2.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1576, Training Loss: 1.866e+00, Validation Loss: 2.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1577, Training Loss: 1.866e+00, Validation Loss: 2.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1578, Training Loss: 1.865e+00, Validation Loss: 2.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1579, Training Loss: 1.865e+00, Validation Loss: 2.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1580, Training Loss: 1.865e+00, Validation Loss: 2.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1581, Training Loss: 1.864e+00, Validation Loss: 2.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1582, Training Loss: 1.864e+00, Validation Loss: 2.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1583, Training Loss: 1.863e+00, Validation Loss: 2.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1584, Training Loss: 1.863e+00, Validation Loss: 2.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1585, Training Loss: 1.862e+00, Validation Loss: 2.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1586, Training Loss: 1.862e+00, Validation Loss: 2.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1587, Training Loss: 1.862e+00, Validation Loss: 2.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1588, Training Loss: 1.861e+00, Validation Loss: 2.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1589, Training Loss: 1.861e+00, Validation Loss: 2.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1590, Training Loss: 1.860e+00, Validation Loss: 2.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1591, Training Loss: 1.860e+00, Validation Loss: 2.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1592, Training Loss: 1.859e+00, Validation Loss: 2.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1593, Training Loss: 1.859e+00, Validation Loss: 2.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1594, Training Loss: 1.859e+00, Validation Loss: 2.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1595, Training Loss: 1.858e+00, Validation Loss: 2.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1596, Training Loss: 1.858e+00, Validation Loss: 2.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1597, Training Loss: 1.857e+00, Validation Loss: 2.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1598, Training Loss: 1.857e+00, Validation Loss: 2.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1599, Training Loss: 1.856e+00, Validation Loss: 2.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1600, Training Loss: 1.856e+00, Validation Loss: 2.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1601, Training Loss: 1.856e+00, Validation Loss: 2.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1602, Training Loss: 1.855e+00, Validation Loss: 2.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1603, Training Loss: 1.855e+00, Validation Loss: 2.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1604, Training Loss: 1.854e+00, Validation Loss: 2.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1605, Training Loss: 1.854e+00, Validation Loss: 2.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1606, Training Loss: 1.853e+00, Validation Loss: 2.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1607, Training Loss: 1.853e+00, Validation Loss: 2.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1608, Training Loss: 1.853e+00, Validation Loss: 2.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1609, Training Loss: 1.852e+00, Validation Loss: 2.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1610, Training Loss: 1.852e+00, Validation Loss: 2.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1611, Training Loss: 1.851e+00, Validation Loss: 2.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1612, Training Loss: 1.851e+00, Validation Loss: 2.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1613, Training Loss: 1.850e+00, Validation Loss: 2.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1614, Training Loss: 1.850e+00, Validation Loss: 2.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1615, Training Loss: 1.850e+00, Validation Loss: 2.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1616, Training Loss: 1.849e+00, Validation Loss: 2.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1617, Training Loss: 1.849e+00, Validation Loss: 2.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1618, Training Loss: 1.848e+00, Validation Loss: 2.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1619, Training Loss: 1.848e+00, Validation Loss: 2.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1620, Training Loss: 1.847e+00, Validation Loss: 2.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1621, Training Loss: 1.847e+00, Validation Loss: 2.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1622, Training Loss: 1.847e+00, Validation Loss: 2.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1623, Training Loss: 1.846e+00, Validation Loss: 2.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1624, Training Loss: 1.846e+00, Validation Loss: 2.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1625, Training Loss: 1.845e+00, Validation Loss: 2.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1626, Training Loss: 1.845e+00, Validation Loss: 2.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1627, Training Loss: 1.844e+00, Validation Loss: 2.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1628, Training Loss: 1.844e+00, Validation Loss: 1.999e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1629, Training Loss: 1.844e+00, Validation Loss: 1.999e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1630, Training Loss: 1.843e+00, Validation Loss: 1.999e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1631, Training Loss: 1.843e+00, Validation Loss: 1.998e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1632, Training Loss: 1.842e+00, Validation Loss: 1.998e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1633, Training Loss: 1.842e+00, Validation Loss: 1.997e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1634, Training Loss: 1.841e+00, Validation Loss: 1.997e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1635, Training Loss: 1.841e+00, Validation Loss: 1.997e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1636, Training Loss: 1.841e+00, Validation Loss: 1.996e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1637, Training Loss: 1.840e+00, Validation Loss: 1.996e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1638, Training Loss: 1.840e+00, Validation Loss: 1.996e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1639, Training Loss: 1.839e+00, Validation Loss: 1.995e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1640, Training Loss: 1.839e+00, Validation Loss: 1.995e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1641, Training Loss: 1.839e+00, Validation Loss: 1.995e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1642, Training Loss: 1.838e+00, Validation Loss: 1.994e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1643, Training Loss: 1.838e+00, Validation Loss: 1.994e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1644, Training Loss: 1.837e+00, Validation Loss: 1.993e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1645, Training Loss: 1.837e+00, Validation Loss: 1.993e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1646, Training Loss: 1.836e+00, Validation Loss: 1.993e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1647, Training Loss: 1.836e+00, Validation Loss: 1.992e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1648, Training Loss: 1.836e+00, Validation Loss: 1.992e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1649, Training Loss: 1.835e+00, Validation Loss: 1.992e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1650, Training Loss: 1.835e+00, Validation Loss: 1.991e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1651, Training Loss: 1.834e+00, Validation Loss: 1.991e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1652, Training Loss: 1.834e+00, Validation Loss: 1.990e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1653, Training Loss: 1.833e+00, Validation Loss: 1.990e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1654, Training Loss: 1.833e+00, Validation Loss: 1.990e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1655, Training Loss: 1.833e+00, Validation Loss: 1.989e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1656, Training Loss: 1.832e+00, Validation Loss: 1.989e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1657, Training Loss: 1.832e+00, Validation Loss: 1.989e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1658, Training Loss: 1.831e+00, Validation Loss: 1.988e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1659, Training Loss: 1.831e+00, Validation Loss: 1.988e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1660, Training Loss: 1.830e+00, Validation Loss: 1.988e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1661, Training Loss: 1.830e+00, Validation Loss: 1.987e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1662, Training Loss: 1.830e+00, Validation Loss: 1.987e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1663, Training Loss: 1.829e+00, Validation Loss: 1.986e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1664, Training Loss: 1.829e+00, Validation Loss: 1.986e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1665, Training Loss: 1.828e+00, Validation Loss: 1.986e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1666, Training Loss: 1.828e+00, Validation Loss: 1.985e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1667, Training Loss: 1.828e+00, Validation Loss: 1.985e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1668, Training Loss: 1.827e+00, Validation Loss: 1.985e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1669, Training Loss: 1.827e+00, Validation Loss: 1.984e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1670, Training Loss: 1.826e+00, Validation Loss: 1.984e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1671, Training Loss: 1.826e+00, Validation Loss: 1.983e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1672, Training Loss: 1.825e+00, Validation Loss: 1.983e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1673, Training Loss: 1.825e+00, Validation Loss: 1.983e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1674, Training Loss: 1.825e+00, Validation Loss: 1.982e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1675, Training Loss: 1.824e+00, Validation Loss: 1.982e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1676, Training Loss: 1.824e+00, Validation Loss: 1.982e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1677, Training Loss: 1.823e+00, Validation Loss: 1.981e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1678, Training Loss: 1.823e+00, Validation Loss: 1.981e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1679, Training Loss: 1.822e+00, Validation Loss: 1.981e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1680, Training Loss: 1.822e+00, Validation Loss: 1.980e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1681, Training Loss: 1.822e+00, Validation Loss: 1.980e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1682, Training Loss: 1.821e+00, Validation Loss: 1.979e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1683, Training Loss: 1.821e+00, Validation Loss: 1.979e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1684, Training Loss: 1.820e+00, Validation Loss: 1.979e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1685, Training Loss: 1.820e+00, Validation Loss: 1.978e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1686, Training Loss: 1.820e+00, Validation Loss: 1.978e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1687, Training Loss: 1.819e+00, Validation Loss: 1.978e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1688, Training Loss: 1.819e+00, Validation Loss: 1.977e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1689, Training Loss: 1.818e+00, Validation Loss: 1.977e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1690, Training Loss: 1.818e+00, Validation Loss: 1.976e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1691, Training Loss: 1.817e+00, Validation Loss: 1.976e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1692, Training Loss: 1.817e+00, Validation Loss: 1.976e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1693, Training Loss: 1.817e+00, Validation Loss: 1.975e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1694, Training Loss: 1.816e+00, Validation Loss: 1.975e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1695, Training Loss: 1.816e+00, Validation Loss: 1.975e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1696, Training Loss: 1.815e+00, Validation Loss: 1.974e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1697, Training Loss: 1.815e+00, Validation Loss: 1.974e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1698, Training Loss: 1.814e+00, Validation Loss: 1.974e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1699, Training Loss: 1.814e+00, Validation Loss: 1.973e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1700, Training Loss: 1.814e+00, Validation Loss: 1.973e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1701, Training Loss: 1.813e+00, Validation Loss: 1.972e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1702, Training Loss: 1.813e+00, Validation Loss: 1.972e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1703, Training Loss: 1.812e+00, Validation Loss: 1.972e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1704, Training Loss: 1.812e+00, Validation Loss: 1.971e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1705, Training Loss: 1.812e+00, Validation Loss: 1.971e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1706, Training Loss: 1.811e+00, Validation Loss: 1.971e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1707, Training Loss: 1.811e+00, Validation Loss: 1.970e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1708, Training Loss: 1.810e+00, Validation Loss: 1.970e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1709, Training Loss: 1.810e+00, Validation Loss: 1.970e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1710, Training Loss: 1.809e+00, Validation Loss: 1.969e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1711, Training Loss: 1.809e+00, Validation Loss: 1.969e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1712, Training Loss: 1.809e+00, Validation Loss: 1.968e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1713, Training Loss: 1.808e+00, Validation Loss: 1.968e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1714, Training Loss: 1.808e+00, Validation Loss: 1.968e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1715, Training Loss: 1.807e+00, Validation Loss: 1.967e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1716, Training Loss: 1.807e+00, Validation Loss: 1.967e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1717, Training Loss: 1.807e+00, Validation Loss: 1.967e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1718, Training Loss: 1.806e+00, Validation Loss: 1.966e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1719, Training Loss: 1.806e+00, Validation Loss: 1.966e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1720, Training Loss: 1.805e+00, Validation Loss: 1.966e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1721, Training Loss: 1.805e+00, Validation Loss: 1.965e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1722, Training Loss: 1.804e+00, Validation Loss: 1.965e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1723, Training Loss: 1.804e+00, Validation Loss: 1.965e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1724, Training Loss: 1.804e+00, Validation Loss: 1.964e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1725, Training Loss: 1.803e+00, Validation Loss: 1.964e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1726, Training Loss: 1.803e+00, Validation Loss: 1.963e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1727, Training Loss: 1.802e+00, Validation Loss: 1.963e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1728, Training Loss: 1.802e+00, Validation Loss: 1.963e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1729, Training Loss: 1.802e+00, Validation Loss: 1.962e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1730, Training Loss: 1.801e+00, Validation Loss: 1.962e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1731, Training Loss: 1.801e+00, Validation Loss: 1.962e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1732, Training Loss: 1.800e+00, Validation Loss: 1.961e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1733, Training Loss: 1.800e+00, Validation Loss: 1.961e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1734, Training Loss: 1.799e+00, Validation Loss: 1.961e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1735, Training Loss: 1.799e+00, Validation Loss: 1.960e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1736, Training Loss: 1.799e+00, Validation Loss: 1.960e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1737, Training Loss: 1.798e+00, Validation Loss: 1.959e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1738, Training Loss: 1.798e+00, Validation Loss: 1.959e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1739, Training Loss: 1.797e+00, Validation Loss: 1.959e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1740, Training Loss: 1.797e+00, Validation Loss: 1.958e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1741, Training Loss: 1.797e+00, Validation Loss: 1.958e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1742, Training Loss: 1.796e+00, Validation Loss: 1.958e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1743, Training Loss: 1.796e+00, Validation Loss: 1.957e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1744, Training Loss: 1.795e+00, Validation Loss: 1.957e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1745, Training Loss: 1.795e+00, Validation Loss: 1.957e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1746, Training Loss: 1.794e+00, Validation Loss: 1.956e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1747, Training Loss: 1.794e+00, Validation Loss: 1.956e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1748, Training Loss: 1.794e+00, Validation Loss: 1.956e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1749, Training Loss: 1.793e+00, Validation Loss: 1.955e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1750, Training Loss: 1.793e+00, Validation Loss: 1.955e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1751, Training Loss: 1.792e+00, Validation Loss: 1.954e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1752, Training Loss: 1.792e+00, Validation Loss: 1.954e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1753, Training Loss: 1.792e+00, Validation Loss: 1.954e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1754, Training Loss: 1.791e+00, Validation Loss: 1.953e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1755, Training Loss: 1.791e+00, Validation Loss: 1.953e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1756, Training Loss: 1.790e+00, Validation Loss: 1.953e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1757, Training Loss: 1.790e+00, Validation Loss: 1.952e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1758, Training Loss: 1.790e+00, Validation Loss: 1.952e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1759, Training Loss: 1.789e+00, Validation Loss: 1.952e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1760, Training Loss: 1.789e+00, Validation Loss: 1.951e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1761, Training Loss: 1.788e+00, Validation Loss: 1.951e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1762, Training Loss: 1.788e+00, Validation Loss: 1.951e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1763, Training Loss: 1.787e+00, Validation Loss: 1.950e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1764, Training Loss: 1.787e+00, Validation Loss: 1.950e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1765, Training Loss: 1.787e+00, Validation Loss: 1.949e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1766, Training Loss: 1.786e+00, Validation Loss: 1.949e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1767, Training Loss: 1.786e+00, Validation Loss: 1.949e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1768, Training Loss: 1.785e+00, Validation Loss: 1.948e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1769, Training Loss: 1.785e+00, Validation Loss: 1.948e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1770, Training Loss: 1.785e+00, Validation Loss: 1.948e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1771, Training Loss: 1.784e+00, Validation Loss: 1.947e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1772, Training Loss: 1.784e+00, Validation Loss: 1.947e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1773, Training Loss: 1.783e+00, Validation Loss: 1.947e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1774, Training Loss: 1.783e+00, Validation Loss: 1.946e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1775, Training Loss: 1.783e+00, Validation Loss: 1.946e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1776, Training Loss: 1.782e+00, Validation Loss: 1.945e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1777, Training Loss: 1.782e+00, Validation Loss: 1.945e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1778, Training Loss: 1.781e+00, Validation Loss: 1.945e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1779, Training Loss: 1.781e+00, Validation Loss: 1.944e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1780, Training Loss: 1.780e+00, Validation Loss: 1.944e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1781, Training Loss: 1.780e+00, Validation Loss: 1.944e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1782, Training Loss: 1.780e+00, Validation Loss: 1.943e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1783, Training Loss: 1.779e+00, Validation Loss: 1.943e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1784, Training Loss: 1.779e+00, Validation Loss: 1.943e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1785, Training Loss: 1.778e+00, Validation Loss: 1.942e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1786, Training Loss: 1.778e+00, Validation Loss: 1.942e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1787, Training Loss: 1.778e+00, Validation Loss: 1.941e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1788, Training Loss: 1.777e+00, Validation Loss: 1.941e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1789, Training Loss: 1.777e+00, Validation Loss: 1.941e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1790, Training Loss: 1.776e+00, Validation Loss: 1.940e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1791, Training Loss: 1.776e+00, Validation Loss: 1.940e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1792, Training Loss: 1.776e+00, Validation Loss: 1.940e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1793, Training Loss: 1.775e+00, Validation Loss: 1.939e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1794, Training Loss: 1.775e+00, Validation Loss: 1.939e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1795, Training Loss: 1.774e+00, Validation Loss: 1.939e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1796, Training Loss: 1.774e+00, Validation Loss: 1.938e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1797, Training Loss: 1.774e+00, Validation Loss: 1.938e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1798, Training Loss: 1.773e+00, Validation Loss: 1.937e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1799, Training Loss: 1.773e+00, Validation Loss: 1.937e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1800, Training Loss: 1.772e+00, Validation Loss: 1.937e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1801, Training Loss: 1.772e+00, Validation Loss: 1.936e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1802, Training Loss: 1.771e+00, Validation Loss: 1.936e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1803, Training Loss: 1.771e+00, Validation Loss: 1.936e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1804, Training Loss: 1.771e+00, Validation Loss: 1.935e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1805, Training Loss: 1.770e+00, Validation Loss: 1.935e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1806, Training Loss: 1.770e+00, Validation Loss: 1.935e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1807, Training Loss: 1.769e+00, Validation Loss: 1.934e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1808, Training Loss: 1.769e+00, Validation Loss: 1.934e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1809, Training Loss: 1.769e+00, Validation Loss: 1.934e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1810, Training Loss: 1.768e+00, Validation Loss: 1.933e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1811, Training Loss: 1.768e+00, Validation Loss: 1.933e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1812, Training Loss: 1.767e+00, Validation Loss: 1.932e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1813, Training Loss: 1.767e+00, Validation Loss: 1.932e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1814, Training Loss: 1.767e+00, Validation Loss: 1.932e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1815, Training Loss: 1.766e+00, Validation Loss: 1.931e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1816, Training Loss: 1.766e+00, Validation Loss: 1.931e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1817, Training Loss: 1.765e+00, Validation Loss: 1.931e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1818, Training Loss: 1.765e+00, Validation Loss: 1.930e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1819, Training Loss: 1.765e+00, Validation Loss: 1.930e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1820, Training Loss: 1.764e+00, Validation Loss: 1.930e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1821, Training Loss: 1.764e+00, Validation Loss: 1.929e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1822, Training Loss: 1.763e+00, Validation Loss: 1.929e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1823, Training Loss: 1.763e+00, Validation Loss: 1.928e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1824, Training Loss: 1.763e+00, Validation Loss: 1.928e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1825, Training Loss: 1.762e+00, Validation Loss: 1.928e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1826, Training Loss: 1.762e+00, Validation Loss: 1.927e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1827, Training Loss: 1.761e+00, Validation Loss: 1.927e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1828, Training Loss: 1.761e+00, Validation Loss: 1.927e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1829, Training Loss: 1.760e+00, Validation Loss: 1.926e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1830, Training Loss: 1.760e+00, Validation Loss: 1.926e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1831, Training Loss: 1.760e+00, Validation Loss: 1.926e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1832, Training Loss: 1.759e+00, Validation Loss: 1.925e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1833, Training Loss: 1.759e+00, Validation Loss: 1.925e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1834, Training Loss: 1.758e+00, Validation Loss: 1.925e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1835, Training Loss: 1.758e+00, Validation Loss: 1.924e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1836, Training Loss: 1.758e+00, Validation Loss: 1.924e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1837, Training Loss: 1.757e+00, Validation Loss: 1.923e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1838, Training Loss: 1.757e+00, Validation Loss: 1.923e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1839, Training Loss: 1.756e+00, Validation Loss: 1.923e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1840, Training Loss: 1.756e+00, Validation Loss: 1.922e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1841, Training Loss: 1.756e+00, Validation Loss: 1.922e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1842, Training Loss: 1.755e+00, Validation Loss: 1.922e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1843, Training Loss: 1.755e+00, Validation Loss: 1.921e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1844, Training Loss: 1.754e+00, Validation Loss: 1.921e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1845, Training Loss: 1.754e+00, Validation Loss: 1.921e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1846, Training Loss: 1.754e+00, Validation Loss: 1.920e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1847, Training Loss: 1.753e+00, Validation Loss: 1.920e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1848, Training Loss: 1.753e+00, Validation Loss: 1.920e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1849, Training Loss: 1.752e+00, Validation Loss: 1.919e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1850, Training Loss: 1.752e+00, Validation Loss: 1.919e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1851, Training Loss: 1.752e+00, Validation Loss: 1.919e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1852, Training Loss: 1.751e+00, Validation Loss: 1.918e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1853, Training Loss: 1.751e+00, Validation Loss: 1.918e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1854, Training Loss: 1.750e+00, Validation Loss: 1.917e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1855, Training Loss: 1.750e+00, Validation Loss: 1.917e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1856, Training Loss: 1.750e+00, Validation Loss: 1.917e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1857, Training Loss: 1.749e+00, Validation Loss: 1.916e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1858, Training Loss: 1.749e+00, Validation Loss: 1.916e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1859, Training Loss: 1.748e+00, Validation Loss: 1.916e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1860, Training Loss: 1.748e+00, Validation Loss: 1.915e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1861, Training Loss: 1.748e+00, Validation Loss: 1.915e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1862, Training Loss: 1.747e+00, Validation Loss: 1.915e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1863, Training Loss: 1.747e+00, Validation Loss: 1.914e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1864, Training Loss: 1.746e+00, Validation Loss: 1.914e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1865, Training Loss: 1.746e+00, Validation Loss: 1.914e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1866, Training Loss: 1.746e+00, Validation Loss: 1.913e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1867, Training Loss: 1.745e+00, Validation Loss: 1.913e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1868, Training Loss: 1.745e+00, Validation Loss: 1.913e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1869, Training Loss: 1.744e+00, Validation Loss: 1.912e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1870, Training Loss: 1.744e+00, Validation Loss: 1.912e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1871, Training Loss: 1.743e+00, Validation Loss: 1.912e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1872, Training Loss: 1.743e+00, Validation Loss: 1.911e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1873, Training Loss: 1.743e+00, Validation Loss: 1.911e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1874, Training Loss: 1.742e+00, Validation Loss: 1.910e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1875, Training Loss: 1.742e+00, Validation Loss: 1.910e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1876, Training Loss: 1.741e+00, Validation Loss: 1.910e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1877, Training Loss: 1.741e+00, Validation Loss: 1.909e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1878, Training Loss: 1.741e+00, Validation Loss: 1.909e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1879, Training Loss: 1.740e+00, Validation Loss: 1.909e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1880, Training Loss: 1.740e+00, Validation Loss: 1.908e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1881, Training Loss: 1.739e+00, Validation Loss: 1.908e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1882, Training Loss: 1.739e+00, Validation Loss: 1.908e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1883, Training Loss: 1.739e+00, Validation Loss: 1.907e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1884, Training Loss: 1.738e+00, Validation Loss: 1.907e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1885, Training Loss: 1.738e+00, Validation Loss: 1.907e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1886, Training Loss: 1.737e+00, Validation Loss: 1.906e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1887, Training Loss: 1.737e+00, Validation Loss: 1.906e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1888, Training Loss: 1.737e+00, Validation Loss: 1.906e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1889, Training Loss: 1.736e+00, Validation Loss: 1.905e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1890, Training Loss: 1.736e+00, Validation Loss: 1.905e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1891, Training Loss: 1.735e+00, Validation Loss: 1.905e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1892, Training Loss: 1.735e+00, Validation Loss: 1.904e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1893, Training Loss: 1.735e+00, Validation Loss: 1.904e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1894, Training Loss: 1.734e+00, Validation Loss: 1.903e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1895, Training Loss: 1.734e+00, Validation Loss: 1.903e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1896, Training Loss: 1.733e+00, Validation Loss: 1.903e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1897, Training Loss: 1.733e+00, Validation Loss: 1.902e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1898, Training Loss: 1.733e+00, Validation Loss: 1.902e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1899, Training Loss: 1.732e+00, Validation Loss: 1.902e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1900, Training Loss: 1.732e+00, Validation Loss: 1.901e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1901, Training Loss: 1.732e+00, Validation Loss: 1.901e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1902, Training Loss: 1.731e+00, Validation Loss: 1.901e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1903, Training Loss: 1.731e+00, Validation Loss: 1.900e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1904, Training Loss: 1.730e+00, Validation Loss: 1.900e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1905, Training Loss: 1.730e+00, Validation Loss: 1.900e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1906, Training Loss: 1.730e+00, Validation Loss: 1.899e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1907, Training Loss: 1.729e+00, Validation Loss: 1.899e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1908, Training Loss: 1.729e+00, Validation Loss: 1.899e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1909, Training Loss: 1.728e+00, Validation Loss: 1.898e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1910, Training Loss: 1.728e+00, Validation Loss: 1.898e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1911, Training Loss: 1.728e+00, Validation Loss: 1.898e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1912, Training Loss: 1.727e+00, Validation Loss: 1.897e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1913, Training Loss: 1.727e+00, Validation Loss: 1.897e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1914, Training Loss: 1.726e+00, Validation Loss: 1.897e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1915, Training Loss: 1.726e+00, Validation Loss: 1.896e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1916, Training Loss: 1.726e+00, Validation Loss: 1.896e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1917, Training Loss: 1.725e+00, Validation Loss: 1.895e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1918, Training Loss: 1.725e+00, Validation Loss: 1.895e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1919, Training Loss: 1.724e+00, Validation Loss: 1.895e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1920, Training Loss: 1.724e+00, Validation Loss: 1.894e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1921, Training Loss: 1.724e+00, Validation Loss: 1.894e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1922, Training Loss: 1.723e+00, Validation Loss: 1.894e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1923, Training Loss: 1.723e+00, Validation Loss: 1.893e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1924, Training Loss: 1.722e+00, Validation Loss: 1.893e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1925, Training Loss: 1.722e+00, Validation Loss: 1.893e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1926, Training Loss: 1.722e+00, Validation Loss: 1.892e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1927, Training Loss: 1.721e+00, Validation Loss: 1.892e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1928, Training Loss: 1.721e+00, Validation Loss: 1.892e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1929, Training Loss: 1.720e+00, Validation Loss: 1.891e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1930, Training Loss: 1.720e+00, Validation Loss: 1.891e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1931, Training Loss: 1.720e+00, Validation Loss: 1.891e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1932, Training Loss: 1.719e+00, Validation Loss: 1.890e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1933, Training Loss: 1.719e+00, Validation Loss: 1.890e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1934, Training Loss: 1.718e+00, Validation Loss: 1.890e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1935, Training Loss: 1.718e+00, Validation Loss: 1.889e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1936, Training Loss: 1.718e+00, Validation Loss: 1.889e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1937, Training Loss: 1.717e+00, Validation Loss: 1.888e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1938, Training Loss: 1.717e+00, Validation Loss: 1.888e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1939, Training Loss: 1.716e+00, Validation Loss: 1.888e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1940, Training Loss: 1.716e+00, Validation Loss: 1.887e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1941, Training Loss: 1.716e+00, Validation Loss: 1.887e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1942, Training Loss: 1.715e+00, Validation Loss: 1.887e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1943, Training Loss: 1.715e+00, Validation Loss: 1.886e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1944, Training Loss: 1.714e+00, Validation Loss: 1.886e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1945, Training Loss: 1.714e+00, Validation Loss: 1.886e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1946, Training Loss: 1.714e+00, Validation Loss: 1.885e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1947, Training Loss: 1.713e+00, Validation Loss: 1.885e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1948, Training Loss: 1.713e+00, Validation Loss: 1.885e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1949, Training Loss: 1.713e+00, Validation Loss: 1.884e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1950, Training Loss: 1.712e+00, Validation Loss: 1.884e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1951, Training Loss: 1.712e+00, Validation Loss: 1.884e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1952, Training Loss: 1.711e+00, Validation Loss: 1.883e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1953, Training Loss: 1.711e+00, Validation Loss: 1.883e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1954, Training Loss: 1.711e+00, Validation Loss: 1.882e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1955, Training Loss: 1.710e+00, Validation Loss: 1.882e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1956, Training Loss: 1.710e+00, Validation Loss: 1.882e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1957, Training Loss: 1.709e+00, Validation Loss: 1.881e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1958, Training Loss: 1.709e+00, Validation Loss: 1.881e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1959, Training Loss: 1.709e+00, Validation Loss: 1.881e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1960, Training Loss: 1.708e+00, Validation Loss: 1.880e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1961, Training Loss: 1.708e+00, Validation Loss: 1.880e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1962, Training Loss: 1.707e+00, Validation Loss: 1.880e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1963, Training Loss: 1.707e+00, Validation Loss: 1.879e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1964, Training Loss: 1.707e+00, Validation Loss: 1.879e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1965, Training Loss: 1.706e+00, Validation Loss: 1.879e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1966, Training Loss: 1.706e+00, Validation Loss: 1.878e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1967, Training Loss: 1.705e+00, Validation Loss: 1.878e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1968, Training Loss: 1.705e+00, Validation Loss: 1.878e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1969, Training Loss: 1.705e+00, Validation Loss: 1.877e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1970, Training Loss: 1.704e+00, Validation Loss: 1.877e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1971, Training Loss: 1.704e+00, Validation Loss: 1.876e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1972, Training Loss: 1.704e+00, Validation Loss: 1.876e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1973, Training Loss: 1.703e+00, Validation Loss: 1.876e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1974, Training Loss: 1.703e+00, Validation Loss: 1.875e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1975, Training Loss: 1.702e+00, Validation Loss: 1.875e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1976, Training Loss: 1.702e+00, Validation Loss: 1.875e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1977, Training Loss: 1.702e+00, Validation Loss: 1.874e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1978, Training Loss: 1.701e+00, Validation Loss: 1.874e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1979, Training Loss: 1.701e+00, Validation Loss: 1.874e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1980, Training Loss: 1.700e+00, Validation Loss: 1.873e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1981, Training Loss: 1.700e+00, Validation Loss: 1.873e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1982, Training Loss: 1.700e+00, Validation Loss: 1.873e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1983, Training Loss: 1.699e+00, Validation Loss: 1.872e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1984, Training Loss: 1.699e+00, Validation Loss: 1.872e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1985, Training Loss: 1.698e+00, Validation Loss: 1.872e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1986, Training Loss: 1.698e+00, Validation Loss: 1.871e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1987, Training Loss: 1.698e+00, Validation Loss: 1.871e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1988, Training Loss: 1.697e+00, Validation Loss: 1.870e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1989, Training Loss: 1.697e+00, Validation Loss: 1.870e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1990, Training Loss: 1.696e+00, Validation Loss: 1.870e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1991, Training Loss: 1.696e+00, Validation Loss: 1.869e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1992, Training Loss: 1.696e+00, Validation Loss: 1.869e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1993, Training Loss: 1.695e+00, Validation Loss: 1.869e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1994, Training Loss: 1.695e+00, Validation Loss: 1.868e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1995, Training Loss: 1.695e+00, Validation Loss: 1.868e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1996, Training Loss: 1.694e+00, Validation Loss: 1.868e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1997, Training Loss: 1.694e+00, Validation Loss: 1.867e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1998, Training Loss: 1.693e+00, Validation Loss: 1.867e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1999, Training Loss: 1.693e+00, Validation Loss: 1.867e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2000, Training Loss: 1.693e+00, Validation Loss: 1.866e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2001, Training Loss: 1.692e+00, Validation Loss: 1.866e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2002, Training Loss: 1.692e+00, Validation Loss: 1.865e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2003, Training Loss: 1.691e+00, Validation Loss: 1.865e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2004, Training Loss: 1.691e+00, Validation Loss: 1.865e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2005, Training Loss: 1.691e+00, Validation Loss: 1.864e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2006, Training Loss: 1.690e+00, Validation Loss: 1.864e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2007, Training Loss: 1.690e+00, Validation Loss: 1.864e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2008, Training Loss: 1.689e+00, Validation Loss: 1.863e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2009, Training Loss: 1.689e+00, Validation Loss: 1.863e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2010, Training Loss: 1.689e+00, Validation Loss: 1.863e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2011, Training Loss: 1.688e+00, Validation Loss: 1.862e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2012, Training Loss: 1.688e+00, Validation Loss: 1.862e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2013, Training Loss: 1.688e+00, Validation Loss: 1.862e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2014, Training Loss: 1.687e+00, Validation Loss: 1.861e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2015, Training Loss: 1.687e+00, Validation Loss: 1.861e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2016, Training Loss: 1.686e+00, Validation Loss: 1.861e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2017, Training Loss: 1.686e+00, Validation Loss: 1.860e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2018, Training Loss: 1.686e+00, Validation Loss: 1.860e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2019, Training Loss: 1.685e+00, Validation Loss: 1.859e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2020, Training Loss: 1.685e+00, Validation Loss: 1.859e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2021, Training Loss: 1.684e+00, Validation Loss: 1.859e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2022, Training Loss: 1.684e+00, Validation Loss: 1.858e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2023, Training Loss: 1.684e+00, Validation Loss: 1.858e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2024, Training Loss: 1.683e+00, Validation Loss: 1.858e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2025, Training Loss: 1.683e+00, Validation Loss: 1.857e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2026, Training Loss: 1.683e+00, Validation Loss: 1.857e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2027, Training Loss: 1.682e+00, Validation Loss: 1.857e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2028, Training Loss: 1.682e+00, Validation Loss: 1.856e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2029, Training Loss: 1.681e+00, Validation Loss: 1.856e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2030, Training Loss: 1.681e+00, Validation Loss: 1.856e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2031, Training Loss: 1.681e+00, Validation Loss: 1.855e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2032, Training Loss: 1.680e+00, Validation Loss: 1.855e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2033, Training Loss: 1.680e+00, Validation Loss: 1.855e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2034, Training Loss: 1.679e+00, Validation Loss: 1.854e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2035, Training Loss: 1.679e+00, Validation Loss: 1.854e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2036, Training Loss: 1.679e+00, Validation Loss: 1.854e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2037, Training Loss: 1.678e+00, Validation Loss: 1.853e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2038, Training Loss: 1.678e+00, Validation Loss: 1.853e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2039, Training Loss: 1.678e+00, Validation Loss: 1.852e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2040, Training Loss: 1.677e+00, Validation Loss: 1.852e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2041, Training Loss: 1.677e+00, Validation Loss: 1.852e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2042, Training Loss: 1.676e+00, Validation Loss: 1.851e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2043, Training Loss: 1.676e+00, Validation Loss: 1.851e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2044, Training Loss: 1.676e+00, Validation Loss: 1.851e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2045, Training Loss: 1.675e+00, Validation Loss: 1.850e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2046, Training Loss: 1.675e+00, Validation Loss: 1.850e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2047, Training Loss: 1.674e+00, Validation Loss: 1.850e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2048, Training Loss: 1.674e+00, Validation Loss: 1.849e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2049, Training Loss: 1.674e+00, Validation Loss: 1.849e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2050, Training Loss: 1.673e+00, Validation Loss: 1.849e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2051, Training Loss: 1.673e+00, Validation Loss: 1.848e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2052, Training Loss: 1.673e+00, Validation Loss: 1.848e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2053, Training Loss: 1.672e+00, Validation Loss: 1.848e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2054, Training Loss: 1.672e+00, Validation Loss: 1.847e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2055, Training Loss: 1.671e+00, Validation Loss: 1.847e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2056, Training Loss: 1.671e+00, Validation Loss: 1.847e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2057, Training Loss: 1.671e+00, Validation Loss: 1.846e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2058, Training Loss: 1.670e+00, Validation Loss: 1.846e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2059, Training Loss: 1.670e+00, Validation Loss: 1.845e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2060, Training Loss: 1.669e+00, Validation Loss: 1.845e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2061, Training Loss: 1.669e+00, Validation Loss: 1.845e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2062, Training Loss: 1.669e+00, Validation Loss: 1.844e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2063, Training Loss: 1.668e+00, Validation Loss: 1.844e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2064, Training Loss: 1.668e+00, Validation Loss: 1.844e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2065, Training Loss: 1.668e+00, Validation Loss: 1.843e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2066, Training Loss: 1.667e+00, Validation Loss: 1.843e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2067, Training Loss: 1.667e+00, Validation Loss: 1.843e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2068, Training Loss: 1.666e+00, Validation Loss: 1.842e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2069, Training Loss: 1.666e+00, Validation Loss: 1.842e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2070, Training Loss: 1.666e+00, Validation Loss: 1.842e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2071, Training Loss: 1.665e+00, Validation Loss: 1.841e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2072, Training Loss: 1.665e+00, Validation Loss: 1.841e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2073, Training Loss: 1.665e+00, Validation Loss: 1.841e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2074, Training Loss: 1.664e+00, Validation Loss: 1.840e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2075, Training Loss: 1.664e+00, Validation Loss: 1.840e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2076, Training Loss: 1.663e+00, Validation Loss: 1.840e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2077, Training Loss: 1.663e+00, Validation Loss: 1.839e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2078, Training Loss: 1.663e+00, Validation Loss: 1.839e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2079, Training Loss: 1.662e+00, Validation Loss: 1.839e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2080, Training Loss: 1.662e+00, Validation Loss: 1.838e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2081, Training Loss: 1.661e+00, Validation Loss: 1.838e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2082, Training Loss: 1.661e+00, Validation Loss: 1.837e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2083, Training Loss: 1.661e+00, Validation Loss: 1.837e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2084, Training Loss: 1.660e+00, Validation Loss: 1.837e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2085, Training Loss: 1.660e+00, Validation Loss: 1.836e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2086, Training Loss: 1.660e+00, Validation Loss: 1.836e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2087, Training Loss: 1.659e+00, Validation Loss: 1.836e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2088, Training Loss: 1.659e+00, Validation Loss: 1.835e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2089, Training Loss: 1.658e+00, Validation Loss: 1.835e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2090, Training Loss: 1.658e+00, Validation Loss: 1.835e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2091, Training Loss: 1.658e+00, Validation Loss: 1.834e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2092, Training Loss: 1.657e+00, Validation Loss: 1.834e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2093, Training Loss: 1.657e+00, Validation Loss: 1.834e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2094, Training Loss: 1.657e+00, Validation Loss: 1.833e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2095, Training Loss: 1.656e+00, Validation Loss: 1.833e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2096, Training Loss: 1.656e+00, Validation Loss: 1.833e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2097, Training Loss: 1.655e+00, Validation Loss: 1.832e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2098, Training Loss: 1.655e+00, Validation Loss: 1.832e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2099, Training Loss: 1.655e+00, Validation Loss: 1.832e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2100, Training Loss: 1.654e+00, Validation Loss: 1.831e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2101, Training Loss: 1.654e+00, Validation Loss: 1.831e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2102, Training Loss: 1.654e+00, Validation Loss: 1.831e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2103, Training Loss: 1.653e+00, Validation Loss: 1.830e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2104, Training Loss: 1.653e+00, Validation Loss: 1.830e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2105, Training Loss: 1.652e+00, Validation Loss: 1.830e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2106, Training Loss: 1.652e+00, Validation Loss: 1.829e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2107, Training Loss: 1.652e+00, Validation Loss: 1.829e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2108, Training Loss: 1.651e+00, Validation Loss: 1.829e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2109, Training Loss: 1.651e+00, Validation Loss: 1.828e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2110, Training Loss: 1.651e+00, Validation Loss: 1.828e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2111, Training Loss: 1.650e+00, Validation Loss: 1.828e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2112, Training Loss: 1.650e+00, Validation Loss: 1.827e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2113, Training Loss: 1.649e+00, Validation Loss: 1.827e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2114, Training Loss: 1.649e+00, Validation Loss: 1.826e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2115, Training Loss: 1.649e+00, Validation Loss: 1.826e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2116, Training Loss: 1.648e+00, Validation Loss: 1.826e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2117, Training Loss: 1.648e+00, Validation Loss: 1.825e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2118, Training Loss: 1.648e+00, Validation Loss: 1.825e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2119, Training Loss: 1.647e+00, Validation Loss: 1.825e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2120, Training Loss: 1.647e+00, Validation Loss: 1.824e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2121, Training Loss: 1.646e+00, Validation Loss: 1.824e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2122, Training Loss: 1.646e+00, Validation Loss: 1.824e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2123, Training Loss: 1.646e+00, Validation Loss: 1.823e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2124, Training Loss: 1.645e+00, Validation Loss: 1.823e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2125, Training Loss: 1.645e+00, Validation Loss: 1.823e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2126, Training Loss: 1.645e+00, Validation Loss: 1.822e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2127, Training Loss: 1.644e+00, Validation Loss: 1.822e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2128, Training Loss: 1.644e+00, Validation Loss: 1.822e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2129, Training Loss: 1.643e+00, Validation Loss: 1.821e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2130, Training Loss: 1.643e+00, Validation Loss: 1.821e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2131, Training Loss: 1.643e+00, Validation Loss: 1.821e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2132, Training Loss: 1.642e+00, Validation Loss: 1.820e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2133, Training Loss: 1.642e+00, Validation Loss: 1.820e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2134, Training Loss: 1.642e+00, Validation Loss: 1.820e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2135, Training Loss: 1.641e+00, Validation Loss: 1.819e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2136, Training Loss: 1.641e+00, Validation Loss: 1.819e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2137, Training Loss: 1.640e+00, Validation Loss: 1.819e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2138, Training Loss: 1.640e+00, Validation Loss: 1.818e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2139, Training Loss: 1.640e+00, Validation Loss: 1.818e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2140, Training Loss: 1.639e+00, Validation Loss: 1.818e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2141, Training Loss: 1.639e+00, Validation Loss: 1.817e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2142, Training Loss: 1.639e+00, Validation Loss: 1.817e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2143, Training Loss: 1.638e+00, Validation Loss: 1.817e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2144, Training Loss: 1.638e+00, Validation Loss: 1.816e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2145, Training Loss: 1.637e+00, Validation Loss: 1.816e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2146, Training Loss: 1.637e+00, Validation Loss: 1.816e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2147, Training Loss: 1.637e+00, Validation Loss: 1.815e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2148, Training Loss: 1.636e+00, Validation Loss: 1.815e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2149, Training Loss: 1.636e+00, Validation Loss: 1.815e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2150, Training Loss: 1.636e+00, Validation Loss: 1.814e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2151, Training Loss: 1.635e+00, Validation Loss: 1.814e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2152, Training Loss: 1.635e+00, Validation Loss: 1.814e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2153, Training Loss: 1.635e+00, Validation Loss: 1.813e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2154, Training Loss: 1.634e+00, Validation Loss: 1.813e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2155, Training Loss: 1.634e+00, Validation Loss: 1.813e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2156, Training Loss: 1.633e+00, Validation Loss: 1.812e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2157, Training Loss: 1.633e+00, Validation Loss: 1.812e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2158, Training Loss: 1.633e+00, Validation Loss: 1.812e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2159, Training Loss: 1.632e+00, Validation Loss: 1.811e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2160, Training Loss: 1.632e+00, Validation Loss: 1.811e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2161, Training Loss: 1.632e+00, Validation Loss: 1.811e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2162, Training Loss: 1.631e+00, Validation Loss: 1.810e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2163, Training Loss: 1.631e+00, Validation Loss: 1.810e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2164, Training Loss: 1.630e+00, Validation Loss: 1.809e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2165, Training Loss: 1.630e+00, Validation Loss: 1.809e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2166, Training Loss: 1.630e+00, Validation Loss: 1.809e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2167, Training Loss: 1.629e+00, Validation Loss: 1.808e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2168, Training Loss: 1.629e+00, Validation Loss: 1.808e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2169, Training Loss: 1.629e+00, Validation Loss: 1.808e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2170, Training Loss: 1.628e+00, Validation Loss: 1.807e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2171, Training Loss: 1.628e+00, Validation Loss: 1.807e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2172, Training Loss: 1.627e+00, Validation Loss: 1.807e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2173, Training Loss: 1.627e+00, Validation Loss: 1.806e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2174, Training Loss: 1.627e+00, Validation Loss: 1.806e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2175, Training Loss: 1.626e+00, Validation Loss: 1.806e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2176, Training Loss: 1.626e+00, Validation Loss: 1.805e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2177, Training Loss: 1.626e+00, Validation Loss: 1.805e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2178, Training Loss: 1.625e+00, Validation Loss: 1.805e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2179, Training Loss: 1.625e+00, Validation Loss: 1.804e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2180, Training Loss: 1.625e+00, Validation Loss: 1.804e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2181, Training Loss: 1.624e+00, Validation Loss: 1.804e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2182, Training Loss: 1.624e+00, Validation Loss: 1.803e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2183, Training Loss: 1.623e+00, Validation Loss: 1.803e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2184, Training Loss: 1.623e+00, Validation Loss: 1.803e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2185, Training Loss: 1.623e+00, Validation Loss: 1.802e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2186, Training Loss: 1.622e+00, Validation Loss: 1.802e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2187, Training Loss: 1.622e+00, Validation Loss: 1.802e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2188, Training Loss: 1.622e+00, Validation Loss: 1.801e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2189, Training Loss: 1.621e+00, Validation Loss: 1.801e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2190, Training Loss: 1.621e+00, Validation Loss: 1.801e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2191, Training Loss: 1.621e+00, Validation Loss: 1.800e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2192, Training Loss: 1.620e+00, Validation Loss: 1.800e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2193, Training Loss: 1.620e+00, Validation Loss: 1.800e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2194, Training Loss: 1.619e+00, Validation Loss: 1.799e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2195, Training Loss: 1.619e+00, Validation Loss: 1.799e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2196, Training Loss: 1.619e+00, Validation Loss: 1.799e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2197, Training Loss: 1.618e+00, Validation Loss: 1.798e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2198, Training Loss: 1.618e+00, Validation Loss: 1.798e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2199, Training Loss: 1.618e+00, Validation Loss: 1.798e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2200, Training Loss: 1.617e+00, Validation Loss: 1.797e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2201, Training Loss: 1.617e+00, Validation Loss: 1.797e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2202, Training Loss: 1.616e+00, Validation Loss: 1.797e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2203, Training Loss: 1.616e+00, Validation Loss: 1.796e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2204, Training Loss: 1.616e+00, Validation Loss: 1.796e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2205, Training Loss: 1.615e+00, Validation Loss: 1.796e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2206, Training Loss: 1.615e+00, Validation Loss: 1.795e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2207, Training Loss: 1.615e+00, Validation Loss: 1.795e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2208, Training Loss: 1.614e+00, Validation Loss: 1.795e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2209, Training Loss: 1.614e+00, Validation Loss: 1.794e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2210, Training Loss: 1.614e+00, Validation Loss: 1.794e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2211, Training Loss: 1.613e+00, Validation Loss: 1.794e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2212, Training Loss: 1.613e+00, Validation Loss: 1.793e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2213, Training Loss: 1.612e+00, Validation Loss: 1.793e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2214, Training Loss: 1.612e+00, Validation Loss: 1.793e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2215, Training Loss: 1.612e+00, Validation Loss: 1.792e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2216, Training Loss: 1.611e+00, Validation Loss: 1.792e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2217, Training Loss: 1.611e+00, Validation Loss: 1.792e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2218, Training Loss: 1.611e+00, Validation Loss: 1.791e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2219, Training Loss: 1.610e+00, Validation Loss: 1.791e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2220, Training Loss: 1.610e+00, Validation Loss: 1.791e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2221, Training Loss: 1.610e+00, Validation Loss: 1.790e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2222, Training Loss: 1.609e+00, Validation Loss: 1.790e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2223, Training Loss: 1.609e+00, Validation Loss: 1.790e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2224, Training Loss: 1.608e+00, Validation Loss: 1.789e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2225, Training Loss: 1.608e+00, Validation Loss: 1.789e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2226, Training Loss: 1.608e+00, Validation Loss: 1.789e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2227, Training Loss: 1.607e+00, Validation Loss: 1.788e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2228, Training Loss: 1.607e+00, Validation Loss: 1.788e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2229, Training Loss: 1.607e+00, Validation Loss: 1.788e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2230, Training Loss: 1.606e+00, Validation Loss: 1.787e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2231, Training Loss: 1.606e+00, Validation Loss: 1.787e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2232, Training Loss: 1.606e+00, Validation Loss: 1.787e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2233, Training Loss: 1.605e+00, Validation Loss: 1.786e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2234, Training Loss: 1.605e+00, Validation Loss: 1.786e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2235, Training Loss: 1.604e+00, Validation Loss: 1.786e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2236, Training Loss: 1.604e+00, Validation Loss: 1.785e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2237, Training Loss: 1.604e+00, Validation Loss: 1.785e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2238, Training Loss: 1.603e+00, Validation Loss: 1.785e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2239, Training Loss: 1.603e+00, Validation Loss: 1.784e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2240, Training Loss: 1.603e+00, Validation Loss: 1.784e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2241, Training Loss: 1.602e+00, Validation Loss: 1.784e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2242, Training Loss: 1.602e+00, Validation Loss: 1.783e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2243, Training Loss: 1.602e+00, Validation Loss: 1.783e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2244, Training Loss: 1.601e+00, Validation Loss: 1.783e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2245, Training Loss: 1.601e+00, Validation Loss: 1.782e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2246, Training Loss: 1.601e+00, Validation Loss: 1.782e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2247, Training Loss: 1.600e+00, Validation Loss: 1.782e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2248, Training Loss: 1.600e+00, Validation Loss: 1.781e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2249, Training Loss: 1.599e+00, Validation Loss: 1.781e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2250, Training Loss: 1.599e+00, Validation Loss: 1.781e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2251, Training Loss: 1.599e+00, Validation Loss: 1.780e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2252, Training Loss: 1.598e+00, Validation Loss: 1.780e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2253, Training Loss: 1.598e+00, Validation Loss: 1.780e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2254, Training Loss: 1.598e+00, Validation Loss: 1.779e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2255, Training Loss: 1.597e+00, Validation Loss: 1.779e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2256, Training Loss: 1.597e+00, Validation Loss: 1.779e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2257, Training Loss: 1.597e+00, Validation Loss: 1.778e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2258, Training Loss: 1.596e+00, Validation Loss: 1.778e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2259, Training Loss: 1.596e+00, Validation Loss: 1.778e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2260, Training Loss: 1.595e+00, Validation Loss: 1.777e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2261, Training Loss: 1.595e+00, Validation Loss: 1.777e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2262, Training Loss: 1.595e+00, Validation Loss: 1.777e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2263, Training Loss: 1.594e+00, Validation Loss: 1.776e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2264, Training Loss: 1.594e+00, Validation Loss: 1.776e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2265, Training Loss: 1.594e+00, Validation Loss: 1.776e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2266, Training Loss: 1.593e+00, Validation Loss: 1.775e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2267, Training Loss: 1.593e+00, Validation Loss: 1.775e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2268, Training Loss: 1.593e+00, Validation Loss: 1.775e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2269, Training Loss: 1.592e+00, Validation Loss: 1.774e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2270, Training Loss: 1.592e+00, Validation Loss: 1.774e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2271, Training Loss: 1.592e+00, Validation Loss: 1.774e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2272, Training Loss: 1.591e+00, Validation Loss: 1.773e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2273, Training Loss: 1.591e+00, Validation Loss: 1.773e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2274, Training Loss: 1.590e+00, Validation Loss: 1.773e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2275, Training Loss: 1.590e+00, Validation Loss: 1.772e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2276, Training Loss: 1.590e+00, Validation Loss: 1.772e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2277, Training Loss: 1.589e+00, Validation Loss: 1.772e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2278, Training Loss: 1.589e+00, Validation Loss: 1.771e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2279, Training Loss: 1.589e+00, Validation Loss: 1.771e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2280, Training Loss: 1.588e+00, Validation Loss: 1.771e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2281, Training Loss: 1.588e+00, Validation Loss: 1.770e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2282, Training Loss: 1.588e+00, Validation Loss: 1.770e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2283, Training Loss: 1.587e+00, Validation Loss: 1.770e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2284, Training Loss: 1.587e+00, Validation Loss: 1.769e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2285, Training Loss: 1.587e+00, Validation Loss: 1.769e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2286, Training Loss: 1.586e+00, Validation Loss: 1.769e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2287, Training Loss: 1.586e+00, Validation Loss: 1.768e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2288, Training Loss: 1.585e+00, Validation Loss: 1.768e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2289, Training Loss: 1.585e+00, Validation Loss: 1.768e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2290, Training Loss: 1.585e+00, Validation Loss: 1.767e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2291, Training Loss: 1.584e+00, Validation Loss: 1.767e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2292, Training Loss: 1.584e+00, Validation Loss: 1.767e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2293, Training Loss: 1.584e+00, Validation Loss: 1.766e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2294, Training Loss: 1.583e+00, Validation Loss: 1.766e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2295, Training Loss: 1.583e+00, Validation Loss: 1.766e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2296, Training Loss: 1.583e+00, Validation Loss: 1.765e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2297, Training Loss: 1.582e+00, Validation Loss: 1.765e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2298, Training Loss: 1.582e+00, Validation Loss: 1.765e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2299, Training Loss: 1.582e+00, Validation Loss: 1.764e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2300, Training Loss: 1.581e+00, Validation Loss: 1.764e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2301, Training Loss: 1.581e+00, Validation Loss: 1.764e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2302, Training Loss: 1.581e+00, Validation Loss: 1.763e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2303, Training Loss: 1.580e+00, Validation Loss: 1.763e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2304, Training Loss: 1.580e+00, Validation Loss: 1.763e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2305, Training Loss: 1.579e+00, Validation Loss: 1.762e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2306, Training Loss: 1.579e+00, Validation Loss: 1.762e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2307, Training Loss: 1.579e+00, Validation Loss: 1.762e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2308, Training Loss: 1.578e+00, Validation Loss: 1.762e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2309, Training Loss: 1.578e+00, Validation Loss: 1.761e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2310, Training Loss: 1.578e+00, Validation Loss: 1.761e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2311, Training Loss: 1.577e+00, Validation Loss: 1.761e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2312, Training Loss: 1.577e+00, Validation Loss: 1.760e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2313, Training Loss: 1.577e+00, Validation Loss: 1.760e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2314, Training Loss: 1.576e+00, Validation Loss: 1.760e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2315, Training Loss: 1.576e+00, Validation Loss: 1.759e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2316, Training Loss: 1.576e+00, Validation Loss: 1.759e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2317, Training Loss: 1.575e+00, Validation Loss: 1.759e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2318, Training Loss: 1.575e+00, Validation Loss: 1.758e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2319, Training Loss: 1.575e+00, Validation Loss: 1.758e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2320, Training Loss: 1.574e+00, Validation Loss: 1.758e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2321, Training Loss: 1.574e+00, Validation Loss: 1.757e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2322, Training Loss: 1.573e+00, Validation Loss: 1.757e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2323, Training Loss: 1.573e+00, Validation Loss: 1.757e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2324, Training Loss: 1.573e+00, Validation Loss: 1.756e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2325, Training Loss: 1.572e+00, Validation Loss: 1.756e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2326, Training Loss: 1.572e+00, Validation Loss: 1.756e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2327, Training Loss: 1.572e+00, Validation Loss: 1.755e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2328, Training Loss: 1.571e+00, Validation Loss: 1.755e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2329, Training Loss: 1.571e+00, Validation Loss: 1.755e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2330, Training Loss: 1.571e+00, Validation Loss: 1.754e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2331, Training Loss: 1.570e+00, Validation Loss: 1.754e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2332, Training Loss: 1.570e+00, Validation Loss: 1.754e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2333, Training Loss: 1.570e+00, Validation Loss: 1.753e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2334, Training Loss: 1.569e+00, Validation Loss: 1.753e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2335, Training Loss: 1.569e+00, Validation Loss: 1.753e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2336, Training Loss: 1.569e+00, Validation Loss: 1.752e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2337, Training Loss: 1.568e+00, Validation Loss: 1.752e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2338, Training Loss: 1.568e+00, Validation Loss: 1.752e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2339, Training Loss: 1.567e+00, Validation Loss: 1.751e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2340, Training Loss: 1.567e+00, Validation Loss: 1.751e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2341, Training Loss: 1.567e+00, Validation Loss: 1.751e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2342, Training Loss: 1.566e+00, Validation Loss: 1.750e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2343, Training Loss: 1.566e+00, Validation Loss: 1.750e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2344, Training Loss: 1.566e+00, Validation Loss: 1.750e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2345, Training Loss: 1.565e+00, Validation Loss: 1.749e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2346, Training Loss: 1.565e+00, Validation Loss: 1.749e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2347, Training Loss: 1.565e+00, Validation Loss: 1.749e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2348, Training Loss: 1.564e+00, Validation Loss: 1.748e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2349, Training Loss: 1.564e+00, Validation Loss: 1.748e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2350, Training Loss: 1.564e+00, Validation Loss: 1.748e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2351, Training Loss: 1.563e+00, Validation Loss: 1.747e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2352, Training Loss: 1.563e+00, Validation Loss: 1.747e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2353, Training Loss: 1.563e+00, Validation Loss: 1.747e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2354, Training Loss: 1.562e+00, Validation Loss: 1.746e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2355, Training Loss: 1.562e+00, Validation Loss: 1.746e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2356, Training Loss: 1.562e+00, Validation Loss: 1.746e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2357, Training Loss: 1.561e+00, Validation Loss: 1.745e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2358, Training Loss: 1.561e+00, Validation Loss: 1.745e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2359, Training Loss: 1.560e+00, Validation Loss: 1.745e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2360, Training Loss: 1.560e+00, Validation Loss: 1.744e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2361, Training Loss: 1.560e+00, Validation Loss: 1.744e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2362, Training Loss: 1.559e+00, Validation Loss: 1.744e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2363, Training Loss: 1.559e+00, Validation Loss: 1.743e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2364, Training Loss: 1.559e+00, Validation Loss: 1.743e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2365, Training Loss: 1.558e+00, Validation Loss: 1.743e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2366, Training Loss: 1.558e+00, Validation Loss: 1.742e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2367, Training Loss: 1.558e+00, Validation Loss: 1.742e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2368, Training Loss: 1.557e+00, Validation Loss: 1.742e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2369, Training Loss: 1.557e+00, Validation Loss: 1.741e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2370, Training Loss: 1.557e+00, Validation Loss: 1.741e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2371, Training Loss: 1.556e+00, Validation Loss: 1.741e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2372, Training Loss: 1.556e+00, Validation Loss: 1.740e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2373, Training Loss: 1.556e+00, Validation Loss: 1.740e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2374, Training Loss: 1.555e+00, Validation Loss: 1.740e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2375, Training Loss: 1.555e+00, Validation Loss: 1.740e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2376, Training Loss: 1.555e+00, Validation Loss: 1.739e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2377, Training Loss: 1.554e+00, Validation Loss: 1.739e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2378, Training Loss: 1.554e+00, Validation Loss: 1.739e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2379, Training Loss: 1.553e+00, Validation Loss: 1.738e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2380, Training Loss: 1.553e+00, Validation Loss: 1.738e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2381, Training Loss: 1.553e+00, Validation Loss: 1.738e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2382, Training Loss: 1.552e+00, Validation Loss: 1.737e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2383, Training Loss: 1.552e+00, Validation Loss: 1.737e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2384, Training Loss: 1.552e+00, Validation Loss: 1.737e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2385, Training Loss: 1.551e+00, Validation Loss: 1.736e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2386, Training Loss: 1.551e+00, Validation Loss: 1.736e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2387, Training Loss: 1.551e+00, Validation Loss: 1.736e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2388, Training Loss: 1.550e+00, Validation Loss: 1.735e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2389, Training Loss: 1.550e+00, Validation Loss: 1.735e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2390, Training Loss: 1.550e+00, Validation Loss: 1.735e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2391, Training Loss: 1.549e+00, Validation Loss: 1.734e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2392, Training Loss: 1.549e+00, Validation Loss: 1.734e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2393, Training Loss: 1.549e+00, Validation Loss: 1.734e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2394, Training Loss: 1.548e+00, Validation Loss: 1.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2395, Training Loss: 1.548e+00, Validation Loss: 1.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2396, Training Loss: 1.548e+00, Validation Loss: 1.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2397, Training Loss: 1.547e+00, Validation Loss: 1.732e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2398, Training Loss: 1.547e+00, Validation Loss: 1.732e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2399, Training Loss: 1.547e+00, Validation Loss: 1.732e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2400, Training Loss: 1.546e+00, Validation Loss: 1.731e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2401, Training Loss: 1.546e+00, Validation Loss: 1.731e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2402, Training Loss: 1.546e+00, Validation Loss: 1.731e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2403, Training Loss: 1.545e+00, Validation Loss: 1.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2404, Training Loss: 1.545e+00, Validation Loss: 1.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2405, Training Loss: 1.544e+00, Validation Loss: 1.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2406, Training Loss: 1.544e+00, Validation Loss: 1.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2407, Training Loss: 1.544e+00, Validation Loss: 1.729e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2408, Training Loss: 1.543e+00, Validation Loss: 1.729e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2409, Training Loss: 1.543e+00, Validation Loss: 1.729e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2410, Training Loss: 1.543e+00, Validation Loss: 1.728e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2411, Training Loss: 1.542e+00, Validation Loss: 1.728e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2412, Training Loss: 1.542e+00, Validation Loss: 1.728e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2413, Training Loss: 1.542e+00, Validation Loss: 1.727e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2414, Training Loss: 1.541e+00, Validation Loss: 1.727e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2415, Training Loss: 1.541e+00, Validation Loss: 1.727e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2416, Training Loss: 1.541e+00, Validation Loss: 1.726e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2417, Training Loss: 1.540e+00, Validation Loss: 1.726e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2418, Training Loss: 1.540e+00, Validation Loss: 1.726e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2419, Training Loss: 1.540e+00, Validation Loss: 1.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2420, Training Loss: 1.539e+00, Validation Loss: 1.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2421, Training Loss: 1.539e+00, Validation Loss: 1.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2422, Training Loss: 1.539e+00, Validation Loss: 1.724e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2423, Training Loss: 1.538e+00, Validation Loss: 1.724e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2424, Training Loss: 1.538e+00, Validation Loss: 1.724e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2425, Training Loss: 1.538e+00, Validation Loss: 1.723e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2426, Training Loss: 1.537e+00, Validation Loss: 1.723e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2427, Training Loss: 1.537e+00, Validation Loss: 1.723e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2428, Training Loss: 1.537e+00, Validation Loss: 1.723e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2429, Training Loss: 1.536e+00, Validation Loss: 1.722e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2430, Training Loss: 1.536e+00, Validation Loss: 1.722e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2431, Training Loss: 1.536e+00, Validation Loss: 1.722e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2432, Training Loss: 1.535e+00, Validation Loss: 1.721e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2433, Training Loss: 1.535e+00, Validation Loss: 1.721e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2434, Training Loss: 1.535e+00, Validation Loss: 1.721e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2435, Training Loss: 1.534e+00, Validation Loss: 1.720e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2436, Training Loss: 1.534e+00, Validation Loss: 1.720e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2437, Training Loss: 1.534e+00, Validation Loss: 1.720e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2438, Training Loss: 1.533e+00, Validation Loss: 1.719e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2439, Training Loss: 1.533e+00, Validation Loss: 1.719e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2440, Training Loss: 1.532e+00, Validation Loss: 1.719e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2441, Training Loss: 1.532e+00, Validation Loss: 1.718e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2442, Training Loss: 1.532e+00, Validation Loss: 1.718e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2443, Training Loss: 1.531e+00, Validation Loss: 1.718e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2444, Training Loss: 1.531e+00, Validation Loss: 1.717e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2445, Training Loss: 1.531e+00, Validation Loss: 1.717e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2446, Training Loss: 1.530e+00, Validation Loss: 1.717e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2447, Training Loss: 1.530e+00, Validation Loss: 1.717e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2448, Training Loss: 1.530e+00, Validation Loss: 1.716e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2449, Training Loss: 1.529e+00, Validation Loss: 1.716e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2450, Training Loss: 1.529e+00, Validation Loss: 1.716e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2451, Training Loss: 1.529e+00, Validation Loss: 1.715e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2452, Training Loss: 1.528e+00, Validation Loss: 1.715e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2453, Training Loss: 1.528e+00, Validation Loss: 1.715e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2454, Training Loss: 1.528e+00, Validation Loss: 1.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2455, Training Loss: 1.527e+00, Validation Loss: 1.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2456, Training Loss: 1.527e+00, Validation Loss: 1.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2457, Training Loss: 1.527e+00, Validation Loss: 1.713e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2458, Training Loss: 1.526e+00, Validation Loss: 1.713e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2459, Training Loss: 1.526e+00, Validation Loss: 1.713e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2460, Training Loss: 1.526e+00, Validation Loss: 1.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2461, Training Loss: 1.525e+00, Validation Loss: 1.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2462, Training Loss: 1.525e+00, Validation Loss: 1.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2463, Training Loss: 1.525e+00, Validation Loss: 1.711e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2464, Training Loss: 1.524e+00, Validation Loss: 1.711e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2465, Training Loss: 1.524e+00, Validation Loss: 1.711e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2466, Training Loss: 1.524e+00, Validation Loss: 1.711e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2467, Training Loss: 1.523e+00, Validation Loss: 1.710e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2468, Training Loss: 1.523e+00, Validation Loss: 1.710e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2469, Training Loss: 1.523e+00, Validation Loss: 1.710e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2470, Training Loss: 1.522e+00, Validation Loss: 1.709e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2471, Training Loss: 1.522e+00, Validation Loss: 1.709e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2472, Training Loss: 1.522e+00, Validation Loss: 1.709e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2473, Training Loss: 1.521e+00, Validation Loss: 1.708e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2474, Training Loss: 1.521e+00, Validation Loss: 1.708e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2475, Training Loss: 1.521e+00, Validation Loss: 1.708e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2476, Training Loss: 1.520e+00, Validation Loss: 1.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2477, Training Loss: 1.520e+00, Validation Loss: 1.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2478, Training Loss: 1.520e+00, Validation Loss: 1.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2479, Training Loss: 1.519e+00, Validation Loss: 1.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2480, Training Loss: 1.519e+00, Validation Loss: 1.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2481, Training Loss: 1.519e+00, Validation Loss: 1.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2482, Training Loss: 1.518e+00, Validation Loss: 1.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2483, Training Loss: 1.518e+00, Validation Loss: 1.705e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2484, Training Loss: 1.518e+00, Validation Loss: 1.705e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2485, Training Loss: 1.517e+00, Validation Loss: 1.705e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2486, Training Loss: 1.517e+00, Validation Loss: 1.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2487, Training Loss: 1.517e+00, Validation Loss: 1.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2488, Training Loss: 1.516e+00, Validation Loss: 1.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2489, Training Loss: 1.516e+00, Validation Loss: 1.703e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2490, Training Loss: 1.516e+00, Validation Loss: 1.703e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2491, Training Loss: 1.515e+00, Validation Loss: 1.703e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2492, Training Loss: 1.515e+00, Validation Loss: 1.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2493, Training Loss: 1.515e+00, Validation Loss: 1.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2494, Training Loss: 1.514e+00, Validation Loss: 1.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2495, Training Loss: 1.514e+00, Validation Loss: 1.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2496, Training Loss: 1.514e+00, Validation Loss: 1.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2497, Training Loss: 1.513e+00, Validation Loss: 1.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2498, Training Loss: 1.513e+00, Validation Loss: 1.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2499, Training Loss: 1.513e+00, Validation Loss: 1.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2500, Training Loss: 1.512e+00, Validation Loss: 1.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2501, Training Loss: 1.512e+00, Validation Loss: 1.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2502, Training Loss: 1.512e+00, Validation Loss: 1.699e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2503, Training Loss: 1.511e+00, Validation Loss: 1.699e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2504, Training Loss: 1.511e+00, Validation Loss: 1.699e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2505, Training Loss: 1.510e+00, Validation Loss: 1.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2506, Training Loss: 1.510e+00, Validation Loss: 1.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2507, Training Loss: 1.510e+00, Validation Loss: 1.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2508, Training Loss: 1.509e+00, Validation Loss: 1.697e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2509, Training Loss: 1.509e+00, Validation Loss: 1.697e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2510, Training Loss: 1.509e+00, Validation Loss: 1.697e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2511, Training Loss: 1.508e+00, Validation Loss: 1.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2512, Training Loss: 1.508e+00, Validation Loss: 1.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2513, Training Loss: 1.508e+00, Validation Loss: 1.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2514, Training Loss: 1.507e+00, Validation Loss: 1.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2515, Training Loss: 1.507e+00, Validation Loss: 1.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2516, Training Loss: 1.507e+00, Validation Loss: 1.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2517, Training Loss: 1.506e+00, Validation Loss: 1.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2518, Training Loss: 1.506e+00, Validation Loss: 1.694e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2519, Training Loss: 1.506e+00, Validation Loss: 1.694e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2520, Training Loss: 1.505e+00, Validation Loss: 1.694e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2521, Training Loss: 1.505e+00, Validation Loss: 1.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2522, Training Loss: 1.505e+00, Validation Loss: 1.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2523, Training Loss: 1.504e+00, Validation Loss: 1.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2524, Training Loss: 1.504e+00, Validation Loss: 1.692e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2525, Training Loss: 1.504e+00, Validation Loss: 1.692e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2526, Training Loss: 1.503e+00, Validation Loss: 1.692e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2527, Training Loss: 1.503e+00, Validation Loss: 1.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2528, Training Loss: 1.503e+00, Validation Loss: 1.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2529, Training Loss: 1.502e+00, Validation Loss: 1.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2530, Training Loss: 1.502e+00, Validation Loss: 1.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2531, Training Loss: 1.502e+00, Validation Loss: 1.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2532, Training Loss: 1.501e+00, Validation Loss: 1.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2533, Training Loss: 1.501e+00, Validation Loss: 1.689e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2534, Training Loss: 1.501e+00, Validation Loss: 1.689e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2535, Training Loss: 1.500e+00, Validation Loss: 1.689e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2536, Training Loss: 1.500e+00, Validation Loss: 1.689e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2537, Training Loss: 1.500e+00, Validation Loss: 1.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2538, Training Loss: 1.499e+00, Validation Loss: 1.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2539, Training Loss: 1.499e+00, Validation Loss: 1.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2540, Training Loss: 1.499e+00, Validation Loss: 1.687e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2541, Training Loss: 1.498e+00, Validation Loss: 1.687e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2542, Training Loss: 1.498e+00, Validation Loss: 1.687e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2543, Training Loss: 1.498e+00, Validation Loss: 1.686e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2544, Training Loss: 1.497e+00, Validation Loss: 1.686e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2545, Training Loss: 1.497e+00, Validation Loss: 1.686e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2546, Training Loss: 1.497e+00, Validation Loss: 1.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2547, Training Loss: 1.496e+00, Validation Loss: 1.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2548, Training Loss: 1.496e+00, Validation Loss: 1.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2549, Training Loss: 1.496e+00, Validation Loss: 1.684e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2550, Training Loss: 1.495e+00, Validation Loss: 1.684e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2551, Training Loss: 1.495e+00, Validation Loss: 1.684e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2552, Training Loss: 1.495e+00, Validation Loss: 1.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2553, Training Loss: 1.494e+00, Validation Loss: 1.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2554, Training Loss: 1.494e+00, Validation Loss: 1.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2555, Training Loss: 1.494e+00, Validation Loss: 1.682e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2556, Training Loss: 1.493e+00, Validation Loss: 1.682e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2557, Training Loss: 1.493e+00, Validation Loss: 1.682e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2558, Training Loss: 1.493e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2559, Training Loss: 1.492e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2560, Training Loss: 1.492e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2561, Training Loss: 1.492e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2562, Training Loss: 1.491e+00, Validation Loss: 1.680e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2563, Training Loss: 1.491e+00, Validation Loss: 1.680e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2564, Training Loss: 1.491e+00, Validation Loss: 1.680e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2565, Training Loss: 1.490e+00, Validation Loss: 1.679e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2566, Training Loss: 1.490e+00, Validation Loss: 1.679e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2567, Training Loss: 1.490e+00, Validation Loss: 1.679e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2568, Training Loss: 1.489e+00, Validation Loss: 1.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2569, Training Loss: 1.489e+00, Validation Loss: 1.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2570, Training Loss: 1.489e+00, Validation Loss: 1.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2571, Training Loss: 1.488e+00, Validation Loss: 1.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2572, Training Loss: 1.488e+00, Validation Loss: 1.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2573, Training Loss: 1.488e+00, Validation Loss: 1.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2574, Training Loss: 1.487e+00, Validation Loss: 1.676e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2575, Training Loss: 1.487e+00, Validation Loss: 1.676e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2576, Training Loss: 1.487e+00, Validation Loss: 1.676e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2577, Training Loss: 1.486e+00, Validation Loss: 1.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2578, Training Loss: 1.486e+00, Validation Loss: 1.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2579, Training Loss: 1.486e+00, Validation Loss: 1.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2580, Training Loss: 1.485e+00, Validation Loss: 1.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2581, Training Loss: 1.485e+00, Validation Loss: 1.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2582, Training Loss: 1.485e+00, Validation Loss: 1.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2583, Training Loss: 1.484e+00, Validation Loss: 1.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2584, Training Loss: 1.484e+00, Validation Loss: 1.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2585, Training Loss: 1.484e+00, Validation Loss: 1.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2586, Training Loss: 1.483e+00, Validation Loss: 1.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2587, Training Loss: 1.483e+00, Validation Loss: 1.672e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2588, Training Loss: 1.483e+00, Validation Loss: 1.672e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2589, Training Loss: 1.482e+00, Validation Loss: 1.672e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2590, Training Loss: 1.482e+00, Validation Loss: 1.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2591, Training Loss: 1.482e+00, Validation Loss: 1.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2592, Training Loss: 1.481e+00, Validation Loss: 1.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2593, Training Loss: 1.481e+00, Validation Loss: 1.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2594, Training Loss: 1.481e+00, Validation Loss: 1.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2595, Training Loss: 1.480e+00, Validation Loss: 1.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2596, Training Loss: 1.480e+00, Validation Loss: 1.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2597, Training Loss: 1.480e+00, Validation Loss: 1.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2598, Training Loss: 1.480e+00, Validation Loss: 1.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2599, Training Loss: 1.479e+00, Validation Loss: 1.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2600, Training Loss: 1.479e+00, Validation Loss: 1.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2601, Training Loss: 1.479e+00, Validation Loss: 1.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2602, Training Loss: 1.478e+00, Validation Loss: 1.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2603, Training Loss: 1.478e+00, Validation Loss: 1.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2604, Training Loss: 1.478e+00, Validation Loss: 1.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2605, Training Loss: 1.477e+00, Validation Loss: 1.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2606, Training Loss: 1.477e+00, Validation Loss: 1.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2607, Training Loss: 1.477e+00, Validation Loss: 1.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2608, Training Loss: 1.476e+00, Validation Loss: 1.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2609, Training Loss: 1.476e+00, Validation Loss: 1.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2610, Training Loss: 1.476e+00, Validation Loss: 1.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2611, Training Loss: 1.475e+00, Validation Loss: 1.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2612, Training Loss: 1.475e+00, Validation Loss: 1.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2613, Training Loss: 1.475e+00, Validation Loss: 1.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2614, Training Loss: 1.474e+00, Validation Loss: 1.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2615, Training Loss: 1.474e+00, Validation Loss: 1.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2616, Training Loss: 1.474e+00, Validation Loss: 1.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2617, Training Loss: 1.473e+00, Validation Loss: 1.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2618, Training Loss: 1.473e+00, Validation Loss: 1.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2619, Training Loss: 1.473e+00, Validation Loss: 1.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2620, Training Loss: 1.472e+00, Validation Loss: 1.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2621, Training Loss: 1.472e+00, Validation Loss: 1.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2622, Training Loss: 1.472e+00, Validation Loss: 1.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2623, Training Loss: 1.471e+00, Validation Loss: 1.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2624, Training Loss: 1.471e+00, Validation Loss: 1.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2625, Training Loss: 1.471e+00, Validation Loss: 1.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2626, Training Loss: 1.470e+00, Validation Loss: 1.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2627, Training Loss: 1.470e+00, Validation Loss: 1.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2628, Training Loss: 1.470e+00, Validation Loss: 1.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2629, Training Loss: 1.469e+00, Validation Loss: 1.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2630, Training Loss: 1.469e+00, Validation Loss: 1.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2631, Training Loss: 1.469e+00, Validation Loss: 1.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2632, Training Loss: 1.468e+00, Validation Loss: 1.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2633, Training Loss: 1.468e+00, Validation Loss: 1.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2634, Training Loss: 1.468e+00, Validation Loss: 1.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2635, Training Loss: 1.467e+00, Validation Loss: 1.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2636, Training Loss: 1.467e+00, Validation Loss: 1.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2637, Training Loss: 1.467e+00, Validation Loss: 1.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2638, Training Loss: 1.466e+00, Validation Loss: 1.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2639, Training Loss: 1.466e+00, Validation Loss: 1.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2640, Training Loss: 1.466e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2641, Training Loss: 1.465e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2642, Training Loss: 1.465e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2643, Training Loss: 1.465e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2644, Training Loss: 1.465e+00, Validation Loss: 1.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2645, Training Loss: 1.464e+00, Validation Loss: 1.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2646, Training Loss: 1.464e+00, Validation Loss: 1.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2647, Training Loss: 1.464e+00, Validation Loss: 1.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2648, Training Loss: 1.463e+00, Validation Loss: 1.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2649, Training Loss: 1.463e+00, Validation Loss: 1.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2650, Training Loss: 1.463e+00, Validation Loss: 1.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2651, Training Loss: 1.462e+00, Validation Loss: 1.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2652, Training Loss: 1.462e+00, Validation Loss: 1.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2653, Training Loss: 1.462e+00, Validation Loss: 1.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2654, Training Loss: 1.461e+00, Validation Loss: 1.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2655, Training Loss: 1.461e+00, Validation Loss: 1.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2656, Training Loss: 1.461e+00, Validation Loss: 1.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2657, Training Loss: 1.460e+00, Validation Loss: 1.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2658, Training Loss: 1.460e+00, Validation Loss: 1.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2659, Training Loss: 1.460e+00, Validation Loss: 1.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2660, Training Loss: 1.459e+00, Validation Loss: 1.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2661, Training Loss: 1.459e+00, Validation Loss: 1.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2662, Training Loss: 1.459e+00, Validation Loss: 1.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2663, Training Loss: 1.458e+00, Validation Loss: 1.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2664, Training Loss: 1.458e+00, Validation Loss: 1.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2665, Training Loss: 1.458e+00, Validation Loss: 1.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2666, Training Loss: 1.458e+00, Validation Loss: 1.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2667, Training Loss: 1.457e+00, Validation Loss: 1.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2668, Training Loss: 1.457e+00, Validation Loss: 1.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2669, Training Loss: 1.457e+00, Validation Loss: 1.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2670, Training Loss: 1.456e+00, Validation Loss: 1.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2671, Training Loss: 1.456e+00, Validation Loss: 1.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2672, Training Loss: 1.456e+00, Validation Loss: 1.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2673, Training Loss: 1.455e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2674, Training Loss: 1.455e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2675, Training Loss: 1.455e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2676, Training Loss: 1.454e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2677, Training Loss: 1.454e+00, Validation Loss: 1.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2678, Training Loss: 1.454e+00, Validation Loss: 1.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2679, Training Loss: 1.453e+00, Validation Loss: 1.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2680, Training Loss: 1.453e+00, Validation Loss: 1.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2681, Training Loss: 1.453e+00, Validation Loss: 1.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2682, Training Loss: 1.452e+00, Validation Loss: 1.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2683, Training Loss: 1.452e+00, Validation Loss: 1.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2684, Training Loss: 1.452e+00, Validation Loss: 1.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2685, Training Loss: 1.452e+00, Validation Loss: 1.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2686, Training Loss: 1.451e+00, Validation Loss: 1.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2687, Training Loss: 1.451e+00, Validation Loss: 1.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2688, Training Loss: 1.451e+00, Validation Loss: 1.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2689, Training Loss: 1.450e+00, Validation Loss: 1.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2690, Training Loss: 1.450e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2691, Training Loss: 1.450e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2692, Training Loss: 1.449e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2693, Training Loss: 1.449e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2694, Training Loss: 1.449e+00, Validation Loss: 1.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2695, Training Loss: 1.448e+00, Validation Loss: 1.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2696, Training Loss: 1.448e+00, Validation Loss: 1.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2697, Training Loss: 1.448e+00, Validation Loss: 1.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2698, Training Loss: 1.447e+00, Validation Loss: 1.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2699, Training Loss: 1.447e+00, Validation Loss: 1.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2700, Training Loss: 1.447e+00, Validation Loss: 1.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2701, Training Loss: 1.447e+00, Validation Loss: 1.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2702, Training Loss: 1.446e+00, Validation Loss: 1.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2703, Training Loss: 1.446e+00, Validation Loss: 1.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2704, Training Loss: 1.446e+00, Validation Loss: 1.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2705, Training Loss: 1.445e+00, Validation Loss: 1.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2706, Training Loss: 1.445e+00, Validation Loss: 1.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2707, Training Loss: 1.445e+00, Validation Loss: 1.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2708, Training Loss: 1.444e+00, Validation Loss: 1.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2709, Training Loss: 1.444e+00, Validation Loss: 1.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2710, Training Loss: 1.444e+00, Validation Loss: 1.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2711, Training Loss: 1.443e+00, Validation Loss: 1.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2712, Training Loss: 1.443e+00, Validation Loss: 1.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2713, Training Loss: 1.443e+00, Validation Loss: 1.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2714, Training Loss: 1.443e+00, Validation Loss: 1.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2715, Training Loss: 1.442e+00, Validation Loss: 1.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2716, Training Loss: 1.442e+00, Validation Loss: 1.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2717, Training Loss: 1.442e+00, Validation Loss: 1.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2718, Training Loss: 1.441e+00, Validation Loss: 1.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2719, Training Loss: 1.441e+00, Validation Loss: 1.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2720, Training Loss: 1.441e+00, Validation Loss: 1.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2721, Training Loss: 1.440e+00, Validation Loss: 1.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2722, Training Loss: 1.440e+00, Validation Loss: 1.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2723, Training Loss: 1.440e+00, Validation Loss: 1.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2724, Training Loss: 1.439e+00, Validation Loss: 1.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2725, Training Loss: 1.439e+00, Validation Loss: 1.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2726, Training Loss: 1.439e+00, Validation Loss: 1.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2727, Training Loss: 1.439e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2728, Training Loss: 1.438e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2729, Training Loss: 1.438e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2730, Training Loss: 1.438e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2731, Training Loss: 1.437e+00, Validation Loss: 1.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2732, Training Loss: 1.437e+00, Validation Loss: 1.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2733, Training Loss: 1.437e+00, Validation Loss: 1.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2734, Training Loss: 1.436e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2735, Training Loss: 1.436e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2736, Training Loss: 1.436e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2737, Training Loss: 1.435e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2738, Training Loss: 1.435e+00, Validation Loss: 1.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2739, Training Loss: 1.435e+00, Validation Loss: 1.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2740, Training Loss: 1.435e+00, Validation Loss: 1.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2741, Training Loss: 1.434e+00, Validation Loss: 1.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2742, Training Loss: 1.434e+00, Validation Loss: 1.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2743, Training Loss: 1.434e+00, Validation Loss: 1.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2744, Training Loss: 1.433e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2745, Training Loss: 1.433e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2746, Training Loss: 1.433e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2747, Training Loss: 1.432e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2748, Training Loss: 1.432e+00, Validation Loss: 1.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2749, Training Loss: 1.432e+00, Validation Loss: 1.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2750, Training Loss: 1.431e+00, Validation Loss: 1.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2751, Training Loss: 1.431e+00, Validation Loss: 1.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2752, Training Loss: 1.431e+00, Validation Loss: 1.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2753, Training Loss: 1.431e+00, Validation Loss: 1.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2754, Training Loss: 1.430e+00, Validation Loss: 1.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2755, Training Loss: 1.430e+00, Validation Loss: 1.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2756, Training Loss: 1.430e+00, Validation Loss: 1.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2757, Training Loss: 1.429e+00, Validation Loss: 1.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2758, Training Loss: 1.429e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2759, Training Loss: 1.429e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2760, Training Loss: 1.428e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2761, Training Loss: 1.428e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2762, Training Loss: 1.428e+00, Validation Loss: 1.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2763, Training Loss: 1.427e+00, Validation Loss: 1.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2764, Training Loss: 1.427e+00, Validation Loss: 1.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2765, Training Loss: 1.427e+00, Validation Loss: 1.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2766, Training Loss: 1.427e+00, Validation Loss: 1.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2767, Training Loss: 1.426e+00, Validation Loss: 1.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2768, Training Loss: 1.426e+00, Validation Loss: 1.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2769, Training Loss: 1.426e+00, Validation Loss: 1.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2770, Training Loss: 1.425e+00, Validation Loss: 1.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2771, Training Loss: 1.425e+00, Validation Loss: 1.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2772, Training Loss: 1.425e+00, Validation Loss: 1.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2773, Training Loss: 1.424e+00, Validation Loss: 1.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2774, Training Loss: 1.424e+00, Validation Loss: 1.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2775, Training Loss: 1.424e+00, Validation Loss: 1.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2776, Training Loss: 1.424e+00, Validation Loss: 1.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2777, Training Loss: 1.423e+00, Validation Loss: 1.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2778, Training Loss: 1.423e+00, Validation Loss: 1.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2779, Training Loss: 1.423e+00, Validation Loss: 1.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2780, Training Loss: 1.422e+00, Validation Loss: 1.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2781, Training Loss: 1.422e+00, Validation Loss: 1.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2782, Training Loss: 1.422e+00, Validation Loss: 1.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2783, Training Loss: 1.421e+00, Validation Loss: 1.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2784, Training Loss: 1.421e+00, Validation Loss: 1.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2785, Training Loss: 1.421e+00, Validation Loss: 1.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2786, Training Loss: 1.421e+00, Validation Loss: 1.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2787, Training Loss: 1.420e+00, Validation Loss: 1.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2788, Training Loss: 1.420e+00, Validation Loss: 1.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2789, Training Loss: 1.420e+00, Validation Loss: 1.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2790, Training Loss: 1.419e+00, Validation Loss: 1.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2791, Training Loss: 1.419e+00, Validation Loss: 1.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2792, Training Loss: 1.419e+00, Validation Loss: 1.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2793, Training Loss: 1.418e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2794, Training Loss: 1.418e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2795, Training Loss: 1.418e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2796, Training Loss: 1.417e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2797, Training Loss: 1.417e+00, Validation Loss: 1.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2798, Training Loss: 1.417e+00, Validation Loss: 1.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2799, Training Loss: 1.417e+00, Validation Loss: 1.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2800, Training Loss: 1.416e+00, Validation Loss: 1.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2801, Training Loss: 1.416e+00, Validation Loss: 1.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2802, Training Loss: 1.416e+00, Validation Loss: 1.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2803, Training Loss: 1.415e+00, Validation Loss: 1.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2804, Training Loss: 1.415e+00, Validation Loss: 1.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2805, Training Loss: 1.415e+00, Validation Loss: 1.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2806, Training Loss: 1.414e+00, Validation Loss: 1.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2807, Training Loss: 1.414e+00, Validation Loss: 1.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2808, Training Loss: 1.414e+00, Validation Loss: 1.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2809, Training Loss: 1.414e+00, Validation Loss: 1.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2810, Training Loss: 1.413e+00, Validation Loss: 1.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2811, Training Loss: 1.413e+00, Validation Loss: 1.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2812, Training Loss: 1.413e+00, Validation Loss: 1.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2813, Training Loss: 1.412e+00, Validation Loss: 1.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2814, Training Loss: 1.412e+00, Validation Loss: 1.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2815, Training Loss: 1.412e+00, Validation Loss: 1.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2816, Training Loss: 1.411e+00, Validation Loss: 1.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2817, Training Loss: 1.411e+00, Validation Loss: 1.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2818, Training Loss: 1.411e+00, Validation Loss: 1.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2819, Training Loss: 1.411e+00, Validation Loss: 1.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2820, Training Loss: 1.410e+00, Validation Loss: 1.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2821, Training Loss: 1.410e+00, Validation Loss: 1.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2822, Training Loss: 1.410e+00, Validation Loss: 1.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2823, Training Loss: 1.409e+00, Validation Loss: 1.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2824, Training Loss: 1.409e+00, Validation Loss: 1.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2825, Training Loss: 1.409e+00, Validation Loss: 1.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2826, Training Loss: 1.409e+00, Validation Loss: 1.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2827, Training Loss: 1.408e+00, Validation Loss: 1.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2828, Training Loss: 1.408e+00, Validation Loss: 1.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2829, Training Loss: 1.408e+00, Validation Loss: 1.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2830, Training Loss: 1.407e+00, Validation Loss: 1.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2831, Training Loss: 1.407e+00, Validation Loss: 1.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2832, Training Loss: 1.407e+00, Validation Loss: 1.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2833, Training Loss: 1.406e+00, Validation Loss: 1.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2834, Training Loss: 1.406e+00, Validation Loss: 1.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2835, Training Loss: 1.406e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2836, Training Loss: 1.406e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2837, Training Loss: 1.405e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2838, Training Loss: 1.405e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2839, Training Loss: 1.405e+00, Validation Loss: 1.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2840, Training Loss: 1.404e+00, Validation Loss: 1.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2841, Training Loss: 1.404e+00, Validation Loss: 1.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2842, Training Loss: 1.404e+00, Validation Loss: 1.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2843, Training Loss: 1.403e+00, Validation Loss: 1.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2844, Training Loss: 1.403e+00, Validation Loss: 1.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2845, Training Loss: 1.403e+00, Validation Loss: 1.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2846, Training Loss: 1.403e+00, Validation Loss: 1.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2847, Training Loss: 1.402e+00, Validation Loss: 1.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2848, Training Loss: 1.402e+00, Validation Loss: 1.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2849, Training Loss: 1.402e+00, Validation Loss: 1.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2850, Training Loss: 1.401e+00, Validation Loss: 1.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2851, Training Loss: 1.401e+00, Validation Loss: 1.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2852, Training Loss: 1.401e+00, Validation Loss: 1.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2853, Training Loss: 1.400e+00, Validation Loss: 1.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2854, Training Loss: 1.400e+00, Validation Loss: 1.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2855, Training Loss: 1.400e+00, Validation Loss: 1.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2856, Training Loss: 1.400e+00, Validation Loss: 1.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2857, Training Loss: 1.399e+00, Validation Loss: 1.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2858, Training Loss: 1.399e+00, Validation Loss: 1.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2859, Training Loss: 1.399e+00, Validation Loss: 1.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2860, Training Loss: 1.398e+00, Validation Loss: 1.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2861, Training Loss: 1.398e+00, Validation Loss: 1.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2862, Training Loss: 1.398e+00, Validation Loss: 1.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2863, Training Loss: 1.398e+00, Validation Loss: 1.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2864, Training Loss: 1.397e+00, Validation Loss: 1.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2865, Training Loss: 1.397e+00, Validation Loss: 1.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2866, Training Loss: 1.397e+00, Validation Loss: 1.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2867, Training Loss: 1.396e+00, Validation Loss: 1.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2868, Training Loss: 1.396e+00, Validation Loss: 1.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2869, Training Loss: 1.396e+00, Validation Loss: 1.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2870, Training Loss: 1.395e+00, Validation Loss: 1.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2871, Training Loss: 1.395e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2872, Training Loss: 1.395e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2873, Training Loss: 1.395e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2874, Training Loss: 1.394e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2875, Training Loss: 1.394e+00, Validation Loss: 1.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2876, Training Loss: 1.394e+00, Validation Loss: 1.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2877, Training Loss: 1.393e+00, Validation Loss: 1.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2878, Training Loss: 1.393e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2879, Training Loss: 1.393e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2880, Training Loss: 1.393e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2881, Training Loss: 1.392e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2882, Training Loss: 1.392e+00, Validation Loss: 1.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2883, Training Loss: 1.392e+00, Validation Loss: 1.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2884, Training Loss: 1.391e+00, Validation Loss: 1.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2885, Training Loss: 1.391e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2886, Training Loss: 1.391e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2887, Training Loss: 1.390e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2888, Training Loss: 1.390e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2889, Training Loss: 1.390e+00, Validation Loss: 1.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2890, Training Loss: 1.390e+00, Validation Loss: 1.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2891, Training Loss: 1.389e+00, Validation Loss: 1.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2892, Training Loss: 1.389e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2893, Training Loss: 1.389e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2894, Training Loss: 1.388e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2895, Training Loss: 1.388e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2896, Training Loss: 1.388e+00, Validation Loss: 1.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2897, Training Loss: 1.388e+00, Validation Loss: 1.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2898, Training Loss: 1.387e+00, Validation Loss: 1.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2899, Training Loss: 1.387e+00, Validation Loss: 1.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2900, Training Loss: 1.387e+00, Validation Loss: 1.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2901, Training Loss: 1.386e+00, Validation Loss: 1.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2902, Training Loss: 1.386e+00, Validation Loss: 1.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2903, Training Loss: 1.386e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2904, Training Loss: 1.386e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2905, Training Loss: 1.385e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2906, Training Loss: 1.385e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2907, Training Loss: 1.385e+00, Validation Loss: 1.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2908, Training Loss: 1.384e+00, Validation Loss: 1.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2909, Training Loss: 1.384e+00, Validation Loss: 1.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2910, Training Loss: 1.384e+00, Validation Loss: 1.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2911, Training Loss: 1.384e+00, Validation Loss: 1.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2912, Training Loss: 1.383e+00, Validation Loss: 1.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2913, Training Loss: 1.383e+00, Validation Loss: 1.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2914, Training Loss: 1.383e+00, Validation Loss: 1.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2915, Training Loss: 1.382e+00, Validation Loss: 1.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2916, Training Loss: 1.382e+00, Validation Loss: 1.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2917, Training Loss: 1.382e+00, Validation Loss: 1.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2918, Training Loss: 1.381e+00, Validation Loss: 1.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2919, Training Loss: 1.381e+00, Validation Loss: 1.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2920, Training Loss: 1.381e+00, Validation Loss: 1.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2921, Training Loss: 1.381e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2922, Training Loss: 1.380e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2923, Training Loss: 1.380e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2924, Training Loss: 1.380e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2925, Training Loss: 1.379e+00, Validation Loss: 1.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2926, Training Loss: 1.379e+00, Validation Loss: 1.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2927, Training Loss: 1.379e+00, Validation Loss: 1.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2928, Training Loss: 1.379e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2929, Training Loss: 1.378e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2930, Training Loss: 1.378e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2931, Training Loss: 1.378e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2932, Training Loss: 1.377e+00, Validation Loss: 1.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2933, Training Loss: 1.377e+00, Validation Loss: 1.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2934, Training Loss: 1.377e+00, Validation Loss: 1.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2935, Training Loss: 1.377e+00, Validation Loss: 1.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2936, Training Loss: 1.376e+00, Validation Loss: 1.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2937, Training Loss: 1.376e+00, Validation Loss: 1.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2938, Training Loss: 1.376e+00, Validation Loss: 1.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2939, Training Loss: 1.375e+00, Validation Loss: 1.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2940, Training Loss: 1.375e+00, Validation Loss: 1.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2941, Training Loss: 1.375e+00, Validation Loss: 1.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2942, Training Loss: 1.375e+00, Validation Loss: 1.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2943, Training Loss: 1.374e+00, Validation Loss: 1.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2944, Training Loss: 1.374e+00, Validation Loss: 1.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2945, Training Loss: 1.374e+00, Validation Loss: 1.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2946, Training Loss: 1.373e+00, Validation Loss: 1.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2947, Training Loss: 1.373e+00, Validation Loss: 1.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2948, Training Loss: 1.373e+00, Validation Loss: 1.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2949, Training Loss: 1.373e+00, Validation Loss: 1.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2950, Training Loss: 1.372e+00, Validation Loss: 1.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2951, Training Loss: 1.372e+00, Validation Loss: 1.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2952, Training Loss: 1.372e+00, Validation Loss: 1.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2953, Training Loss: 1.371e+00, Validation Loss: 1.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2954, Training Loss: 1.371e+00, Validation Loss: 1.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2955, Training Loss: 1.371e+00, Validation Loss: 1.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2956, Training Loss: 1.371e+00, Validation Loss: 1.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2957, Training Loss: 1.370e+00, Validation Loss: 1.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2958, Training Loss: 1.370e+00, Validation Loss: 1.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2959, Training Loss: 1.370e+00, Validation Loss: 1.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2960, Training Loss: 1.369e+00, Validation Loss: 1.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2961, Training Loss: 1.369e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2962, Training Loss: 1.369e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2963, Training Loss: 1.369e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2964, Training Loss: 1.368e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2965, Training Loss: 1.368e+00, Validation Loss: 1.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2966, Training Loss: 1.368e+00, Validation Loss: 1.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2967, Training Loss: 1.367e+00, Validation Loss: 1.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2968, Training Loss: 1.367e+00, Validation Loss: 1.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2969, Training Loss: 1.367e+00, Validation Loss: 1.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2970, Training Loss: 1.367e+00, Validation Loss: 1.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2971, Training Loss: 1.366e+00, Validation Loss: 1.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2972, Training Loss: 1.366e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2973, Training Loss: 1.366e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2974, Training Loss: 1.365e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2975, Training Loss: 1.365e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2976, Training Loss: 1.365e+00, Validation Loss: 1.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2977, Training Loss: 1.365e+00, Validation Loss: 1.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2978, Training Loss: 1.364e+00, Validation Loss: 1.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2979, Training Loss: 1.364e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2980, Training Loss: 1.364e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2981, Training Loss: 1.363e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2982, Training Loss: 1.363e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2983, Training Loss: 1.363e+00, Validation Loss: 1.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2984, Training Loss: 1.363e+00, Validation Loss: 1.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2985, Training Loss: 1.362e+00, Validation Loss: 1.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2986, Training Loss: 1.362e+00, Validation Loss: 1.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2987, Training Loss: 1.362e+00, Validation Loss: 1.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2988, Training Loss: 1.361e+00, Validation Loss: 1.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2989, Training Loss: 1.361e+00, Validation Loss: 1.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2990, Training Loss: 1.361e+00, Validation Loss: 1.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2991, Training Loss: 1.361e+00, Validation Loss: 1.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2992, Training Loss: 1.360e+00, Validation Loss: 1.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2993, Training Loss: 1.360e+00, Validation Loss: 1.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2994, Training Loss: 1.360e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2995, Training Loss: 1.360e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2996, Training Loss: 1.359e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2997, Training Loss: 1.359e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2998, Training Loss: 1.359e+00, Validation Loss: 1.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2999, Training Loss: 1.358e+00, Validation Loss: 1.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3000, Training Loss: 1.358e+00, Validation Loss: 1.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3001, Training Loss: 1.358e+00, Validation Loss: 1.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3002, Training Loss: 1.358e+00, Validation Loss: 1.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3003, Training Loss: 1.357e+00, Validation Loss: 1.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3004, Training Loss: 1.357e+00, Validation Loss: 1.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3005, Training Loss: 1.357e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3006, Training Loss: 1.356e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3007, Training Loss: 1.356e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3008, Training Loss: 1.356e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3009, Training Loss: 1.356e+00, Validation Loss: 1.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3010, Training Loss: 1.355e+00, Validation Loss: 1.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3011, Training Loss: 1.355e+00, Validation Loss: 1.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3012, Training Loss: 1.355e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3013, Training Loss: 1.354e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3014, Training Loss: 1.354e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3015, Training Loss: 1.354e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3016, Training Loss: 1.354e+00, Validation Loss: 1.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3017, Training Loss: 1.353e+00, Validation Loss: 1.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3018, Training Loss: 1.353e+00, Validation Loss: 1.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3019, Training Loss: 1.353e+00, Validation Loss: 1.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3020, Training Loss: 1.353e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3021, Training Loss: 1.352e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3022, Training Loss: 1.352e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3023, Training Loss: 1.352e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3024, Training Loss: 1.351e+00, Validation Loss: 1.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3025, Training Loss: 1.351e+00, Validation Loss: 1.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3026, Training Loss: 1.351e+00, Validation Loss: 1.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3027, Training Loss: 1.351e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3028, Training Loss: 1.350e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3029, Training Loss: 1.350e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3030, Training Loss: 1.350e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3031, Training Loss: 1.349e+00, Validation Loss: 1.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3032, Training Loss: 1.349e+00, Validation Loss: 1.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3033, Training Loss: 1.349e+00, Validation Loss: 1.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3034, Training Loss: 1.349e+00, Validation Loss: 1.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3035, Training Loss: 1.348e+00, Validation Loss: 1.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3036, Training Loss: 1.348e+00, Validation Loss: 1.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3037, Training Loss: 1.348e+00, Validation Loss: 1.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3038, Training Loss: 1.347e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3039, Training Loss: 1.347e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3040, Training Loss: 1.347e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3041, Training Loss: 1.347e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3042, Training Loss: 1.346e+00, Validation Loss: 1.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3043, Training Loss: 1.346e+00, Validation Loss: 1.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3044, Training Loss: 1.346e+00, Validation Loss: 1.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3045, Training Loss: 1.346e+00, Validation Loss: 1.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3046, Training Loss: 1.345e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3047, Training Loss: 1.345e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3048, Training Loss: 1.345e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3049, Training Loss: 1.344e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3050, Training Loss: 1.344e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3051, Training Loss: 1.344e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3052, Training Loss: 1.344e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3053, Training Loss: 1.343e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3054, Training Loss: 1.343e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3055, Training Loss: 1.343e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3056, Training Loss: 1.343e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3057, Training Loss: 1.342e+00, Validation Loss: 1.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3058, Training Loss: 1.342e+00, Validation Loss: 1.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3059, Training Loss: 1.342e+00, Validation Loss: 1.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3060, Training Loss: 1.341e+00, Validation Loss: 1.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3061, Training Loss: 1.341e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3062, Training Loss: 1.341e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3063, Training Loss: 1.341e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3064, Training Loss: 1.340e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3065, Training Loss: 1.340e+00, Validation Loss: 1.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3066, Training Loss: 1.340e+00, Validation Loss: 1.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3067, Training Loss: 1.339e+00, Validation Loss: 1.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3068, Training Loss: 1.339e+00, Validation Loss: 1.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3069, Training Loss: 1.339e+00, Validation Loss: 1.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3070, Training Loss: 1.339e+00, Validation Loss: 1.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3071, Training Loss: 1.338e+00, Validation Loss: 1.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3072, Training Loss: 1.338e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3073, Training Loss: 1.338e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3074, Training Loss: 1.338e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3075, Training Loss: 1.337e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3076, Training Loss: 1.337e+00, Validation Loss: 1.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3077, Training Loss: 1.337e+00, Validation Loss: 1.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3078, Training Loss: 1.336e+00, Validation Loss: 1.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3079, Training Loss: 1.336e+00, Validation Loss: 1.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3080, Training Loss: 1.336e+00, Validation Loss: 1.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3081, Training Loss: 1.336e+00, Validation Loss: 1.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3082, Training Loss: 1.335e+00, Validation Loss: 1.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3083, Training Loss: 1.335e+00, Validation Loss: 1.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3084, Training Loss: 1.335e+00, Validation Loss: 1.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3085, Training Loss: 1.335e+00, Validation Loss: 1.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3086, Training Loss: 1.334e+00, Validation Loss: 1.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3087, Training Loss: 1.334e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3088, Training Loss: 1.334e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3089, Training Loss: 1.333e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3090, Training Loss: 1.333e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3091, Training Loss: 1.333e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3092, Training Loss: 1.333e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3093, Training Loss: 1.332e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3094, Training Loss: 1.332e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3095, Training Loss: 1.332e+00, Validation Loss: 1.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3096, Training Loss: 1.332e+00, Validation Loss: 1.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3097, Training Loss: 1.331e+00, Validation Loss: 1.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3098, Training Loss: 1.331e+00, Validation Loss: 1.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3099, Training Loss: 1.331e+00, Validation Loss: 1.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3100, Training Loss: 1.330e+00, Validation Loss: 1.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3101, Training Loss: 1.330e+00, Validation Loss: 1.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3102, Training Loss: 1.330e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3103, Training Loss: 1.330e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3104, Training Loss: 1.329e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3105, Training Loss: 1.329e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3106, Training Loss: 1.329e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3107, Training Loss: 1.329e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3108, Training Loss: 1.328e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3109, Training Loss: 1.328e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3110, Training Loss: 1.328e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3111, Training Loss: 1.327e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3112, Training Loss: 1.327e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3113, Training Loss: 1.327e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3114, Training Loss: 1.327e+00, Validation Loss: 1.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3115, Training Loss: 1.326e+00, Validation Loss: 1.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3116, Training Loss: 1.326e+00, Validation Loss: 1.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3117, Training Loss: 1.326e+00, Validation Loss: 1.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3118, Training Loss: 1.326e+00, Validation Loss: 1.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3119, Training Loss: 1.325e+00, Validation Loss: 1.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3120, Training Loss: 1.325e+00, Validation Loss: 1.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3121, Training Loss: 1.325e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3122, Training Loss: 1.324e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3123, Training Loss: 1.324e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3124, Training Loss: 1.324e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3125, Training Loss: 1.324e+00, Validation Loss: 1.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3126, Training Loss: 1.323e+00, Validation Loss: 1.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3127, Training Loss: 1.323e+00, Validation Loss: 1.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3128, Training Loss: 1.323e+00, Validation Loss: 1.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3129, Training Loss: 1.323e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3130, Training Loss: 1.322e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3131, Training Loss: 1.322e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3132, Training Loss: 1.322e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3133, Training Loss: 1.322e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3134, Training Loss: 1.321e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3135, Training Loss: 1.321e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3136, Training Loss: 1.321e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3137, Training Loss: 1.320e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3138, Training Loss: 1.320e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3139, Training Loss: 1.320e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3140, Training Loss: 1.320e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3141, Training Loss: 1.319e+00, Validation Loss: 1.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3142, Training Loss: 1.319e+00, Validation Loss: 1.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3143, Training Loss: 1.319e+00, Validation Loss: 1.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3144, Training Loss: 1.319e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3145, Training Loss: 1.318e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3146, Training Loss: 1.318e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3147, Training Loss: 1.318e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3148, Training Loss: 1.318e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3149, Training Loss: 1.317e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3150, Training Loss: 1.317e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3151, Training Loss: 1.317e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3152, Training Loss: 1.316e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3153, Training Loss: 1.316e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3154, Training Loss: 1.316e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3155, Training Loss: 1.316e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3156, Training Loss: 1.315e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3157, Training Loss: 1.315e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3158, Training Loss: 1.315e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3159, Training Loss: 1.315e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3160, Training Loss: 1.314e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3161, Training Loss: 1.314e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3162, Training Loss: 1.314e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3163, Training Loss: 1.314e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3164, Training Loss: 1.313e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3165, Training Loss: 1.313e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3166, Training Loss: 1.313e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3167, Training Loss: 1.312e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3168, Training Loss: 1.312e+00, Validation Loss: 1.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3169, Training Loss: 1.312e+00, Validation Loss: 1.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3170, Training Loss: 1.312e+00, Validation Loss: 1.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3171, Training Loss: 1.311e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3172, Training Loss: 1.311e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3173, Training Loss: 1.311e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3174, Training Loss: 1.311e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3175, Training Loss: 1.310e+00, Validation Loss: 1.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3176, Training Loss: 1.310e+00, Validation Loss: 1.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3177, Training Loss: 1.310e+00, Validation Loss: 1.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3178, Training Loss: 1.310e+00, Validation Loss: 1.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3179, Training Loss: 1.309e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3180, Training Loss: 1.309e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3181, Training Loss: 1.309e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3182, Training Loss: 1.308e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3183, Training Loss: 1.308e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3184, Training Loss: 1.308e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3185, Training Loss: 1.308e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3186, Training Loss: 1.307e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3187, Training Loss: 1.307e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3188, Training Loss: 1.307e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3189, Training Loss: 1.307e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3190, Training Loss: 1.306e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3191, Training Loss: 1.306e+00, Validation Loss: 1.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3192, Training Loss: 1.306e+00, Validation Loss: 1.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3193, Training Loss: 1.306e+00, Validation Loss: 1.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3194, Training Loss: 1.305e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3195, Training Loss: 1.305e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3196, Training Loss: 1.305e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3197, Training Loss: 1.305e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3198, Training Loss: 1.304e+00, Validation Loss: 1.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3199, Training Loss: 1.304e+00, Validation Loss: 1.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3200, Training Loss: 1.304e+00, Validation Loss: 1.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3201, Training Loss: 1.303e+00, Validation Loss: 1.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3202, Training Loss: 1.303e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3203, Training Loss: 1.303e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3204, Training Loss: 1.303e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3205, Training Loss: 1.302e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3206, Training Loss: 1.302e+00, Validation Loss: 1.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3207, Training Loss: 1.302e+00, Validation Loss: 1.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3208, Training Loss: 1.302e+00, Validation Loss: 1.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3209, Training Loss: 1.301e+00, Validation Loss: 1.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3210, Training Loss: 1.301e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3211, Training Loss: 1.301e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3212, Training Loss: 1.301e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3213, Training Loss: 1.300e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3214, Training Loss: 1.300e+00, Validation Loss: 1.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3215, Training Loss: 1.300e+00, Validation Loss: 1.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3216, Training Loss: 1.299e+00, Validation Loss: 1.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3217, Training Loss: 1.299e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3218, Training Loss: 1.299e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3219, Training Loss: 1.299e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3220, Training Loss: 1.298e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3221, Training Loss: 1.298e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3222, Training Loss: 1.298e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3223, Training Loss: 1.298e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3224, Training Loss: 1.297e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3225, Training Loss: 1.297e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3226, Training Loss: 1.297e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3227, Training Loss: 1.297e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3228, Training Loss: 1.296e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3229, Training Loss: 1.296e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3230, Training Loss: 1.296e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3231, Training Loss: 1.296e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3232, Training Loss: 1.295e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3233, Training Loss: 1.295e+00, Validation Loss: 1.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3234, Training Loss: 1.295e+00, Validation Loss: 1.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3235, Training Loss: 1.295e+00, Validation Loss: 1.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3236, Training Loss: 1.294e+00, Validation Loss: 1.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3237, Training Loss: 1.294e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3238, Training Loss: 1.294e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3239, Training Loss: 1.293e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3240, Training Loss: 1.293e+00, Validation Loss: 1.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3241, Training Loss: 1.293e+00, Validation Loss: 1.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3242, Training Loss: 1.293e+00, Validation Loss: 1.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3243, Training Loss: 1.292e+00, Validation Loss: 1.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3244, Training Loss: 1.292e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3245, Training Loss: 1.292e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3246, Training Loss: 1.292e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3247, Training Loss: 1.291e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3248, Training Loss: 1.291e+00, Validation Loss: 1.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3249, Training Loss: 1.291e+00, Validation Loss: 1.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3250, Training Loss: 1.291e+00, Validation Loss: 1.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3251, Training Loss: 1.290e+00, Validation Loss: 1.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3252, Training Loss: 1.290e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3253, Training Loss: 1.290e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3254, Training Loss: 1.290e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3255, Training Loss: 1.289e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3256, Training Loss: 1.289e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3257, Training Loss: 1.289e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3258, Training Loss: 1.289e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3259, Training Loss: 1.288e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3260, Training Loss: 1.288e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3261, Training Loss: 1.288e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3262, Training Loss: 1.288e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3263, Training Loss: 1.287e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3264, Training Loss: 1.287e+00, Validation Loss: 1.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3265, Training Loss: 1.287e+00, Validation Loss: 1.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3266, Training Loss: 1.286e+00, Validation Loss: 1.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3267, Training Loss: 1.286e+00, Validation Loss: 1.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3268, Training Loss: 1.286e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3269, Training Loss: 1.286e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3270, Training Loss: 1.285e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3271, Training Loss: 1.285e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3272, Training Loss: 1.285e+00, Validation Loss: 1.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3273, Training Loss: 1.285e+00, Validation Loss: 1.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3274, Training Loss: 1.284e+00, Validation Loss: 1.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3275, Training Loss: 1.284e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3276, Training Loss: 1.284e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3277, Training Loss: 1.284e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3278, Training Loss: 1.283e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3279, Training Loss: 1.283e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3280, Training Loss: 1.283e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3281, Training Loss: 1.283e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3282, Training Loss: 1.282e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3283, Training Loss: 1.282e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3284, Training Loss: 1.282e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3285, Training Loss: 1.282e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3286, Training Loss: 1.281e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3287, Training Loss: 1.281e+00, Validation Loss: 1.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3288, Training Loss: 1.281e+00, Validation Loss: 1.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3289, Training Loss: 1.281e+00, Validation Loss: 1.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3290, Training Loss: 1.280e+00, Validation Loss: 1.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3291, Training Loss: 1.280e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3292, Training Loss: 1.280e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3293, Training Loss: 1.280e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3294, Training Loss: 1.279e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3295, Training Loss: 1.279e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3296, Training Loss: 1.279e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3297, Training Loss: 1.279e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3298, Training Loss: 1.278e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3299, Training Loss: 1.278e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3300, Training Loss: 1.278e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3301, Training Loss: 1.278e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3302, Training Loss: 1.277e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3303, Training Loss: 1.277e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3304, Training Loss: 1.277e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3305, Training Loss: 1.276e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3306, Training Loss: 1.276e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3307, Training Loss: 1.276e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3308, Training Loss: 1.276e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3309, Training Loss: 1.275e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3310, Training Loss: 1.275e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3311, Training Loss: 1.275e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3312, Training Loss: 1.275e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3313, Training Loss: 1.274e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3314, Training Loss: 1.274e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3315, Training Loss: 1.274e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3316, Training Loss: 1.274e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3317, Training Loss: 1.273e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3318, Training Loss: 1.273e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3319, Training Loss: 1.273e+00, Validation Loss: 1.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3320, Training Loss: 1.273e+00, Validation Loss: 1.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3321, Training Loss: 1.272e+00, Validation Loss: 1.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3322, Training Loss: 1.272e+00, Validation Loss: 1.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3323, Training Loss: 1.272e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3324, Training Loss: 1.272e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3325, Training Loss: 1.271e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3326, Training Loss: 1.271e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3327, Training Loss: 1.271e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3328, Training Loss: 1.271e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3329, Training Loss: 1.270e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3330, Training Loss: 1.270e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3331, Training Loss: 1.270e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3332, Training Loss: 1.270e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3333, Training Loss: 1.269e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3334, Training Loss: 1.269e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3335, Training Loss: 1.269e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3336, Training Loss: 1.269e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3337, Training Loss: 1.268e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3338, Training Loss: 1.268e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3339, Training Loss: 1.268e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3340, Training Loss: 1.268e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3341, Training Loss: 1.267e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3342, Training Loss: 1.267e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3343, Training Loss: 1.267e+00, Validation Loss: 1.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3344, Training Loss: 1.267e+00, Validation Loss: 1.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3345, Training Loss: 1.266e+00, Validation Loss: 1.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3346, Training Loss: 1.266e+00, Validation Loss: 1.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3347, Training Loss: 1.266e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3348, Training Loss: 1.266e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3349, Training Loss: 1.265e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3350, Training Loss: 1.265e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3351, Training Loss: 1.265e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3352, Training Loss: 1.265e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3353, Training Loss: 1.264e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3354, Training Loss: 1.264e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3355, Training Loss: 1.264e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3356, Training Loss: 1.264e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3357, Training Loss: 1.263e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3358, Training Loss: 1.263e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3359, Training Loss: 1.263e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3360, Training Loss: 1.263e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3361, Training Loss: 1.262e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3362, Training Loss: 1.262e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3363, Training Loss: 1.262e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3364, Training Loss: 1.262e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3365, Training Loss: 1.261e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3366, Training Loss: 1.261e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3367, Training Loss: 1.261e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3368, Training Loss: 1.261e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3369, Training Loss: 1.260e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3370, Training Loss: 1.260e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3371, Training Loss: 1.260e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3372, Training Loss: 1.260e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3373, Training Loss: 1.259e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3374, Training Loss: 1.259e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3375, Training Loss: 1.259e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3376, Training Loss: 1.259e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3377, Training Loss: 1.258e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3378, Training Loss: 1.258e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3379, Training Loss: 1.258e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3380, Training Loss: 1.258e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3381, Training Loss: 1.257e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3382, Training Loss: 1.257e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3383, Training Loss: 1.257e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3384, Training Loss: 1.257e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3385, Training Loss: 1.256e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3386, Training Loss: 1.256e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3387, Training Loss: 1.256e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3388, Training Loss: 1.256e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3389, Training Loss: 1.255e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3390, Training Loss: 1.255e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3391, Training Loss: 1.255e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3392, Training Loss: 1.255e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3393, Training Loss: 1.254e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3394, Training Loss: 1.254e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3395, Training Loss: 1.254e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3396, Training Loss: 1.254e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3397, Training Loss: 1.253e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3398, Training Loss: 1.253e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3399, Training Loss: 1.253e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3400, Training Loss: 1.253e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3401, Training Loss: 1.252e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3402, Training Loss: 1.252e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3403, Training Loss: 1.252e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3404, Training Loss: 1.252e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3405, Training Loss: 1.251e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3406, Training Loss: 1.251e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3407, Training Loss: 1.251e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3408, Training Loss: 1.251e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3409, Training Loss: 1.250e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3410, Training Loss: 1.250e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3411, Training Loss: 1.250e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3412, Training Loss: 1.250e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3413, Training Loss: 1.249e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3414, Training Loss: 1.249e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3415, Training Loss: 1.249e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3416, Training Loss: 1.249e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3417, Training Loss: 1.248e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3418, Training Loss: 1.248e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3419, Training Loss: 1.248e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3420, Training Loss: 1.248e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3421, Training Loss: 1.247e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3422, Training Loss: 1.247e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3423, Training Loss: 1.247e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3424, Training Loss: 1.247e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3425, Training Loss: 1.246e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3426, Training Loss: 1.246e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3427, Training Loss: 1.246e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3428, Training Loss: 1.246e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3429, Training Loss: 1.245e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3430, Training Loss: 1.245e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3431, Training Loss: 1.245e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3432, Training Loss: 1.245e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3433, Training Loss: 1.244e+00, Validation Loss: 1.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3434, Training Loss: 1.244e+00, Validation Loss: 1.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3435, Training Loss: 1.244e+00, Validation Loss: 1.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3436, Training Loss: 1.244e+00, Validation Loss: 1.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3437, Training Loss: 1.243e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3438, Training Loss: 1.243e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3439, Training Loss: 1.243e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3440, Training Loss: 1.243e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3441, Training Loss: 1.242e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3442, Training Loss: 1.242e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3443, Training Loss: 1.242e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3444, Training Loss: 1.242e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3445, Training Loss: 1.242e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3446, Training Loss: 1.241e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3447, Training Loss: 1.241e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3448, Training Loss: 1.241e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3449, Training Loss: 1.241e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3450, Training Loss: 1.240e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3451, Training Loss: 1.240e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3452, Training Loss: 1.240e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3453, Training Loss: 1.240e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3454, Training Loss: 1.239e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3455, Training Loss: 1.239e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3456, Training Loss: 1.239e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3457, Training Loss: 1.239e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3458, Training Loss: 1.238e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3459, Training Loss: 1.238e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3460, Training Loss: 1.238e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3461, Training Loss: 1.238e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3462, Training Loss: 1.237e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3463, Training Loss: 1.237e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3464, Training Loss: 1.237e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3465, Training Loss: 1.237e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3466, Training Loss: 1.236e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3467, Training Loss: 1.236e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3468, Training Loss: 1.236e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3469, Training Loss: 1.236e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3470, Training Loss: 1.235e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3471, Training Loss: 1.235e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3472, Training Loss: 1.235e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3473, Training Loss: 1.235e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3474, Training Loss: 1.234e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3475, Training Loss: 1.234e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3476, Training Loss: 1.234e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3477, Training Loss: 1.234e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3478, Training Loss: 1.233e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3479, Training Loss: 1.233e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3480, Training Loss: 1.233e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3481, Training Loss: 1.233e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3482, Training Loss: 1.233e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3483, Training Loss: 1.232e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3484, Training Loss: 1.232e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3485, Training Loss: 1.232e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3486, Training Loss: 1.232e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3487, Training Loss: 1.231e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3488, Training Loss: 1.231e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3489, Training Loss: 1.231e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3490, Training Loss: 1.231e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3491, Training Loss: 1.230e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3492, Training Loss: 1.230e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3493, Training Loss: 1.230e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3494, Training Loss: 1.230e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3495, Training Loss: 1.229e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3496, Training Loss: 1.229e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3497, Training Loss: 1.229e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3498, Training Loss: 1.229e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3499, Training Loss: 1.228e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3500, Training Loss: 1.228e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3501, Training Loss: 1.228e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3502, Training Loss: 1.228e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3503, Training Loss: 1.227e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3504, Training Loss: 1.227e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3505, Training Loss: 1.227e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3506, Training Loss: 1.227e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3507, Training Loss: 1.227e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3508, Training Loss: 1.226e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3509, Training Loss: 1.226e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3510, Training Loss: 1.226e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3511, Training Loss: 1.226e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3512, Training Loss: 1.225e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3513, Training Loss: 1.225e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3514, Training Loss: 1.225e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3515, Training Loss: 1.225e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3516, Training Loss: 1.224e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3517, Training Loss: 1.224e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3518, Training Loss: 1.224e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3519, Training Loss: 1.224e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3520, Training Loss: 1.223e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3521, Training Loss: 1.223e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3522, Training Loss: 1.223e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3523, Training Loss: 1.223e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3524, Training Loss: 1.222e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3525, Training Loss: 1.222e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3526, Training Loss: 1.222e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3527, Training Loss: 1.222e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3528, Training Loss: 1.222e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3529, Training Loss: 1.221e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3530, Training Loss: 1.221e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3531, Training Loss: 1.221e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3532, Training Loss: 1.221e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3533, Training Loss: 1.220e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3534, Training Loss: 1.220e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3535, Training Loss: 1.220e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3536, Training Loss: 1.220e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3537, Training Loss: 1.219e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3538, Training Loss: 1.219e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3539, Training Loss: 1.219e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3540, Training Loss: 1.219e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3541, Training Loss: 1.218e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3542, Training Loss: 1.218e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3543, Training Loss: 1.218e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3544, Training Loss: 1.218e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3545, Training Loss: 1.217e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3546, Training Loss: 1.217e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3547, Training Loss: 1.217e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3548, Training Loss: 1.217e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3549, Training Loss: 1.217e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3550, Training Loss: 1.216e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3551, Training Loss: 1.216e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3552, Training Loss: 1.216e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3553, Training Loss: 1.216e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3554, Training Loss: 1.215e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3555, Training Loss: 1.215e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3556, Training Loss: 1.215e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3557, Training Loss: 1.215e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3558, Training Loss: 1.214e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3559, Training Loss: 1.214e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3560, Training Loss: 1.214e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3561, Training Loss: 1.214e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3562, Training Loss: 1.213e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3563, Training Loss: 1.213e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3564, Training Loss: 1.213e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3565, Training Loss: 1.213e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3566, Training Loss: 1.213e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3567, Training Loss: 1.212e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3568, Training Loss: 1.212e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3569, Training Loss: 1.212e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3570, Training Loss: 1.212e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3571, Training Loss: 1.211e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3572, Training Loss: 1.211e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3573, Training Loss: 1.211e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3574, Training Loss: 1.211e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3575, Training Loss: 1.210e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3576, Training Loss: 1.210e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3577, Training Loss: 1.210e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3578, Training Loss: 1.210e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3579, Training Loss: 1.210e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3580, Training Loss: 1.209e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3581, Training Loss: 1.209e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3582, Training Loss: 1.209e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3583, Training Loss: 1.209e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3584, Training Loss: 1.208e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3585, Training Loss: 1.208e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3586, Training Loss: 1.208e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3587, Training Loss: 1.208e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3588, Training Loss: 1.207e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3589, Training Loss: 1.207e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3590, Training Loss: 1.207e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3591, Training Loss: 1.207e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3592, Training Loss: 1.206e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3593, Training Loss: 1.206e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3594, Training Loss: 1.206e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3595, Training Loss: 1.206e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3596, Training Loss: 1.206e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3597, Training Loss: 1.205e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3598, Training Loss: 1.205e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3599, Training Loss: 1.205e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3600, Training Loss: 1.205e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3601, Training Loss: 1.204e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3602, Training Loss: 1.204e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3603, Training Loss: 1.204e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3604, Training Loss: 1.204e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3605, Training Loss: 1.203e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3606, Training Loss: 1.203e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3607, Training Loss: 1.203e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3608, Training Loss: 1.203e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3609, Training Loss: 1.203e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3610, Training Loss: 1.202e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3611, Training Loss: 1.202e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3612, Training Loss: 1.202e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3613, Training Loss: 1.202e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3614, Training Loss: 1.201e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3615, Training Loss: 1.201e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3616, Training Loss: 1.201e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3617, Training Loss: 1.201e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3618, Training Loss: 1.201e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3619, Training Loss: 1.200e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3620, Training Loss: 1.200e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3621, Training Loss: 1.200e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3622, Training Loss: 1.200e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3623, Training Loss: 1.199e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3624, Training Loss: 1.199e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3625, Training Loss: 1.199e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3626, Training Loss: 1.199e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3627, Training Loss: 1.198e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3628, Training Loss: 1.198e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3629, Training Loss: 1.198e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3630, Training Loss: 1.198e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3631, Training Loss: 1.198e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3632, Training Loss: 1.197e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3633, Training Loss: 1.197e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3634, Training Loss: 1.197e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3635, Training Loss: 1.197e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3636, Training Loss: 1.196e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3637, Training Loss: 1.196e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3638, Training Loss: 1.196e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3639, Training Loss: 1.196e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3640, Training Loss: 1.195e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3641, Training Loss: 1.195e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3642, Training Loss: 1.195e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3643, Training Loss: 1.195e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3644, Training Loss: 1.195e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3645, Training Loss: 1.194e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3646, Training Loss: 1.194e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3647, Training Loss: 1.194e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3648, Training Loss: 1.194e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3649, Training Loss: 1.193e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3650, Training Loss: 1.193e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3651, Training Loss: 1.193e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3652, Training Loss: 1.193e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3653, Training Loss: 1.193e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3654, Training Loss: 1.192e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3655, Training Loss: 1.192e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3656, Training Loss: 1.192e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3657, Training Loss: 1.192e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3658, Training Loss: 1.191e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3659, Training Loss: 1.191e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3660, Training Loss: 1.191e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3661, Training Loss: 1.191e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3662, Training Loss: 1.191e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3663, Training Loss: 1.190e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3664, Training Loss: 1.190e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3665, Training Loss: 1.190e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3666, Training Loss: 1.190e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3667, Training Loss: 1.189e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3668, Training Loss: 1.189e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3669, Training Loss: 1.189e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3670, Training Loss: 1.189e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3671, Training Loss: 1.188e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3672, Training Loss: 1.188e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3673, Training Loss: 1.188e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3674, Training Loss: 1.188e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3675, Training Loss: 1.188e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3676, Training Loss: 1.187e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3677, Training Loss: 1.187e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3678, Training Loss: 1.187e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3679, Training Loss: 1.187e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3680, Training Loss: 1.186e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3681, Training Loss: 1.186e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3682, Training Loss: 1.186e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3683, Training Loss: 1.186e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3684, Training Loss: 1.186e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3685, Training Loss: 1.185e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3686, Training Loss: 1.185e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3687, Training Loss: 1.185e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3688, Training Loss: 1.185e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3689, Training Loss: 1.184e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3690, Training Loss: 1.184e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3691, Training Loss: 1.184e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3692, Training Loss: 1.184e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3693, Training Loss: 1.184e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3694, Training Loss: 1.183e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3695, Training Loss: 1.183e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3696, Training Loss: 1.183e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3697, Training Loss: 1.183e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3698, Training Loss: 1.182e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3699, Training Loss: 1.182e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3700, Training Loss: 1.182e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3701, Training Loss: 1.182e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3702, Training Loss: 1.182e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3703, Training Loss: 1.181e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3704, Training Loss: 1.181e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3705, Training Loss: 1.181e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3706, Training Loss: 1.181e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3707, Training Loss: 1.180e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3708, Training Loss: 1.180e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3709, Training Loss: 1.180e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3710, Training Loss: 1.180e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3711, Training Loss: 1.180e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3712, Training Loss: 1.179e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3713, Training Loss: 1.179e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3714, Training Loss: 1.179e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3715, Training Loss: 1.179e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3716, Training Loss: 1.178e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3717, Training Loss: 1.178e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3718, Training Loss: 1.178e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3719, Training Loss: 1.178e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3720, Training Loss: 1.178e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3721, Training Loss: 1.177e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3722, Training Loss: 1.177e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3723, Training Loss: 1.177e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3724, Training Loss: 1.177e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3725, Training Loss: 1.176e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3726, Training Loss: 1.176e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3727, Training Loss: 1.176e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3728, Training Loss: 1.176e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3729, Training Loss: 1.176e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3730, Training Loss: 1.175e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3731, Training Loss: 1.175e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3732, Training Loss: 1.175e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3733, Training Loss: 1.175e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3734, Training Loss: 1.174e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3735, Training Loss: 1.174e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3736, Training Loss: 1.174e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3737, Training Loss: 1.174e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3738, Training Loss: 1.174e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3739, Training Loss: 1.173e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3740, Training Loss: 1.173e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3741, Training Loss: 1.173e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3742, Training Loss: 1.173e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3743, Training Loss: 1.172e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3744, Training Loss: 1.172e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3745, Training Loss: 1.172e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3746, Training Loss: 1.172e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3747, Training Loss: 1.172e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3748, Training Loss: 1.171e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3749, Training Loss: 1.171e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3750, Training Loss: 1.171e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3751, Training Loss: 1.171e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3752, Training Loss: 1.170e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3753, Training Loss: 1.170e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3754, Training Loss: 1.170e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3755, Training Loss: 1.170e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3756, Training Loss: 1.170e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3757, Training Loss: 1.169e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3758, Training Loss: 1.169e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3759, Training Loss: 1.169e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3760, Training Loss: 1.169e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3761, Training Loss: 1.169e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3762, Training Loss: 1.168e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3763, Training Loss: 1.168e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3764, Training Loss: 1.168e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3765, Training Loss: 1.168e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3766, Training Loss: 1.167e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3767, Training Loss: 1.167e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3768, Training Loss: 1.167e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3769, Training Loss: 1.167e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3770, Training Loss: 1.167e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3771, Training Loss: 1.166e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3772, Training Loss: 1.166e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3773, Training Loss: 1.166e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3774, Training Loss: 1.166e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3775, Training Loss: 1.165e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3776, Training Loss: 1.165e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3777, Training Loss: 1.165e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3778, Training Loss: 1.165e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3779, Training Loss: 1.165e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3780, Training Loss: 1.164e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3781, Training Loss: 1.164e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3782, Training Loss: 1.164e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3783, Training Loss: 1.164e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3784, Training Loss: 1.164e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3785, Training Loss: 1.163e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3786, Training Loss: 1.163e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3787, Training Loss: 1.163e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3788, Training Loss: 1.163e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3789, Training Loss: 1.162e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3790, Training Loss: 1.162e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3791, Training Loss: 1.162e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3792, Training Loss: 1.162e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3793, Training Loss: 1.162e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3794, Training Loss: 1.161e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3795, Training Loss: 1.161e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3796, Training Loss: 1.161e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3797, Training Loss: 1.161e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3798, Training Loss: 1.160e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3799, Training Loss: 1.160e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3800, Training Loss: 1.160e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3801, Training Loss: 1.160e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3802, Training Loss: 1.160e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3803, Training Loss: 1.159e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3804, Training Loss: 1.159e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3805, Training Loss: 1.159e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3806, Training Loss: 1.159e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3807, Training Loss: 1.159e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3808, Training Loss: 1.158e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3809, Training Loss: 1.158e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3810, Training Loss: 1.158e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3811, Training Loss: 1.158e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3812, Training Loss: 1.157e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3813, Training Loss: 1.157e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3814, Training Loss: 1.157e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3815, Training Loss: 1.157e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3816, Training Loss: 1.157e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3817, Training Loss: 1.156e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3818, Training Loss: 1.156e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3819, Training Loss: 1.156e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3820, Training Loss: 1.156e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3821, Training Loss: 1.156e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3822, Training Loss: 1.155e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3823, Training Loss: 1.155e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3824, Training Loss: 1.155e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3825, Training Loss: 1.155e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3826, Training Loss: 1.154e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3827, Training Loss: 1.154e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3828, Training Loss: 1.154e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3829, Training Loss: 1.154e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3830, Training Loss: 1.154e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3831, Training Loss: 1.153e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3832, Training Loss: 1.153e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3833, Training Loss: 1.153e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3834, Training Loss: 1.153e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3835, Training Loss: 1.153e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3836, Training Loss: 1.152e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3837, Training Loss: 1.152e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3838, Training Loss: 1.152e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3839, Training Loss: 1.152e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3840, Training Loss: 1.152e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3841, Training Loss: 1.151e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3842, Training Loss: 1.151e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3843, Training Loss: 1.151e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3844, Training Loss: 1.151e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3845, Training Loss: 1.150e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3846, Training Loss: 1.150e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3847, Training Loss: 1.150e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3848, Training Loss: 1.150e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3849, Training Loss: 1.150e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3850, Training Loss: 1.149e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3851, Training Loss: 1.149e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3852, Training Loss: 1.149e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3853, Training Loss: 1.149e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3854, Training Loss: 1.149e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3855, Training Loss: 1.148e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3856, Training Loss: 1.148e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3857, Training Loss: 1.148e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3858, Training Loss: 1.148e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3859, Training Loss: 1.147e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3860, Training Loss: 1.147e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3861, Training Loss: 1.147e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3862, Training Loss: 1.147e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3863, Training Loss: 1.147e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3864, Training Loss: 1.146e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3865, Training Loss: 1.146e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3866, Training Loss: 1.146e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3867, Training Loss: 1.146e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3868, Training Loss: 1.146e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3869, Training Loss: 1.145e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3870, Training Loss: 1.145e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3871, Training Loss: 1.145e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3872, Training Loss: 1.145e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3873, Training Loss: 1.145e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3874, Training Loss: 1.144e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3875, Training Loss: 1.144e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3876, Training Loss: 1.144e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3877, Training Loss: 1.144e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3878, Training Loss: 1.143e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3879, Training Loss: 1.143e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3880, Training Loss: 1.143e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3881, Training Loss: 1.143e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3882, Training Loss: 1.143e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3883, Training Loss: 1.142e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3884, Training Loss: 1.142e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3885, Training Loss: 1.142e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3886, Training Loss: 1.142e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3887, Training Loss: 1.142e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3888, Training Loss: 1.141e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3889, Training Loss: 1.141e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3890, Training Loss: 1.141e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3891, Training Loss: 1.141e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3892, Training Loss: 1.141e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3893, Training Loss: 1.140e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3894, Training Loss: 1.140e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3895, Training Loss: 1.140e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3896, Training Loss: 1.140e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3897, Training Loss: 1.140e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3898, Training Loss: 1.139e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3899, Training Loss: 1.139e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3900, Training Loss: 1.139e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3901, Training Loss: 1.139e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3902, Training Loss: 1.138e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3903, Training Loss: 1.138e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3904, Training Loss: 1.138e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3905, Training Loss: 1.138e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3906, Training Loss: 1.138e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3907, Training Loss: 1.137e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3908, Training Loss: 1.137e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3909, Training Loss: 1.137e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3910, Training Loss: 1.137e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3911, Training Loss: 1.137e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3912, Training Loss: 1.136e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3913, Training Loss: 1.136e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3914, Training Loss: 1.136e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3915, Training Loss: 1.136e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3916, Training Loss: 1.136e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3917, Training Loss: 1.135e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3918, Training Loss: 1.135e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3919, Training Loss: 1.135e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3920, Training Loss: 1.135e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3921, Training Loss: 1.135e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3922, Training Loss: 1.134e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3923, Training Loss: 1.134e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3924, Training Loss: 1.134e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3925, Training Loss: 1.134e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3926, Training Loss: 1.133e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3927, Training Loss: 1.133e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3928, Training Loss: 1.133e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3929, Training Loss: 1.133e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3930, Training Loss: 1.133e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3931, Training Loss: 1.132e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3932, Training Loss: 1.132e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3933, Training Loss: 1.132e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3934, Training Loss: 1.132e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3935, Training Loss: 1.132e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3936, Training Loss: 1.131e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3937, Training Loss: 1.131e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3938, Training Loss: 1.131e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3939, Training Loss: 1.131e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3940, Training Loss: 1.131e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3941, Training Loss: 1.130e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3942, Training Loss: 1.130e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3943, Training Loss: 1.130e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3944, Training Loss: 1.130e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3945, Training Loss: 1.130e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3946, Training Loss: 1.129e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3947, Training Loss: 1.129e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3948, Training Loss: 1.129e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3949, Training Loss: 1.129e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3950, Training Loss: 1.129e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3951, Training Loss: 1.128e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3952, Training Loss: 1.128e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3953, Training Loss: 1.128e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3954, Training Loss: 1.128e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3955, Training Loss: 1.128e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3956, Training Loss: 1.127e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3957, Training Loss: 1.127e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3958, Training Loss: 1.127e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3959, Training Loss: 1.127e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3960, Training Loss: 1.127e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3961, Training Loss: 1.126e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3962, Training Loss: 1.126e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3963, Training Loss: 1.126e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3964, Training Loss: 1.126e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3965, Training Loss: 1.125e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3966, Training Loss: 1.125e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3967, Training Loss: 1.125e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3968, Training Loss: 1.125e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3969, Training Loss: 1.125e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3970, Training Loss: 1.124e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3971, Training Loss: 1.124e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3972, Training Loss: 1.124e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3973, Training Loss: 1.124e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3974, Training Loss: 1.124e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3975, Training Loss: 1.123e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3976, Training Loss: 1.123e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3977, Training Loss: 1.123e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3978, Training Loss: 1.123e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3979, Training Loss: 1.123e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3980, Training Loss: 1.122e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3981, Training Loss: 1.122e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3982, Training Loss: 1.122e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3983, Training Loss: 1.122e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3984, Training Loss: 1.122e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3985, Training Loss: 1.121e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3986, Training Loss: 1.121e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3987, Training Loss: 1.121e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3988, Training Loss: 1.121e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3989, Training Loss: 1.121e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3990, Training Loss: 1.120e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3991, Training Loss: 1.120e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3992, Training Loss: 1.120e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3993, Training Loss: 1.120e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3994, Training Loss: 1.120e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3995, Training Loss: 1.119e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3996, Training Loss: 1.119e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3997, Training Loss: 1.119e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3998, Training Loss: 1.119e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3999, Training Loss: 1.119e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4000, Training Loss: 1.118e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4001, Training Loss: 1.118e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4002, Training Loss: 1.118e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4003, Training Loss: 1.118e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4004, Training Loss: 1.118e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4005, Training Loss: 1.117e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4006, Training Loss: 1.117e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4007, Training Loss: 1.117e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4008, Training Loss: 1.117e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4009, Training Loss: 1.117e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4010, Training Loss: 1.116e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4011, Training Loss: 1.116e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4012, Training Loss: 1.116e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4013, Training Loss: 1.116e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4014, Training Loss: 1.116e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4015, Training Loss: 1.115e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4016, Training Loss: 1.115e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4017, Training Loss: 1.115e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4018, Training Loss: 1.115e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4019, Training Loss: 1.115e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4020, Training Loss: 1.114e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4021, Training Loss: 1.114e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4022, Training Loss: 1.114e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4023, Training Loss: 1.114e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4024, Training Loss: 1.114e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4025, Training Loss: 1.113e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4026, Training Loss: 1.113e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4027, Training Loss: 1.113e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4028, Training Loss: 1.113e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4029, Training Loss: 1.113e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4030, Training Loss: 1.112e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4031, Training Loss: 1.112e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4032, Training Loss: 1.112e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4033, Training Loss: 1.112e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4034, Training Loss: 1.112e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4035, Training Loss: 1.111e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4036, Training Loss: 1.111e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4037, Training Loss: 1.111e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4038, Training Loss: 1.111e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4039, Training Loss: 1.111e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4040, Training Loss: 1.110e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4041, Training Loss: 1.110e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4042, Training Loss: 1.110e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4043, Training Loss: 1.110e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4044, Training Loss: 1.110e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4045, Training Loss: 1.109e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4046, Training Loss: 1.109e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4047, Training Loss: 1.109e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4048, Training Loss: 1.109e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4049, Training Loss: 1.109e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4050, Training Loss: 1.108e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4051, Training Loss: 1.108e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4052, Training Loss: 1.108e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4053, Training Loss: 1.108e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4054, Training Loss: 1.108e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4055, Training Loss: 1.107e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4056, Training Loss: 1.107e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4057, Training Loss: 1.107e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4058, Training Loss: 1.107e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4059, Training Loss: 1.107e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4060, Training Loss: 1.106e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4061, Training Loss: 1.106e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4062, Training Loss: 1.106e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4063, Training Loss: 1.106e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4064, Training Loss: 1.106e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4065, Training Loss: 1.105e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4066, Training Loss: 1.105e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4067, Training Loss: 1.105e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4068, Training Loss: 1.105e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4069, Training Loss: 1.105e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4070, Training Loss: 1.104e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4071, Training Loss: 1.104e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4072, Training Loss: 1.104e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4073, Training Loss: 1.104e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4074, Training Loss: 1.104e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4075, Training Loss: 1.103e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4076, Training Loss: 1.103e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4077, Training Loss: 1.103e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4078, Training Loss: 1.103e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4079, Training Loss: 1.103e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4080, Training Loss: 1.102e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4081, Training Loss: 1.102e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4082, Training Loss: 1.102e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4083, Training Loss: 1.102e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4084, Training Loss: 1.102e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4085, Training Loss: 1.101e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4086, Training Loss: 1.101e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4087, Training Loss: 1.101e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4088, Training Loss: 1.101e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4089, Training Loss: 1.101e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4090, Training Loss: 1.100e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4091, Training Loss: 1.100e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4092, Training Loss: 1.100e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4093, Training Loss: 1.100e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4094, Training Loss: 1.100e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4095, Training Loss: 1.100e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4096, Training Loss: 1.099e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4097, Training Loss: 1.099e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4098, Training Loss: 1.099e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4099, Training Loss: 1.099e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4100, Training Loss: 1.099e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4101, Training Loss: 1.098e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4102, Training Loss: 1.098e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4103, Training Loss: 1.098e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4104, Training Loss: 1.098e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4105, Training Loss: 1.098e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4106, Training Loss: 1.097e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4107, Training Loss: 1.097e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4108, Training Loss: 1.097e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4109, Training Loss: 1.097e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4110, Training Loss: 1.097e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4111, Training Loss: 1.096e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4112, Training Loss: 1.096e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4113, Training Loss: 1.096e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4114, Training Loss: 1.096e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4115, Training Loss: 1.096e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4116, Training Loss: 1.095e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4117, Training Loss: 1.095e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4118, Training Loss: 1.095e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4119, Training Loss: 1.095e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4120, Training Loss: 1.095e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4121, Training Loss: 1.094e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4122, Training Loss: 1.094e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4123, Training Loss: 1.094e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4124, Training Loss: 1.094e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4125, Training Loss: 1.094e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4126, Training Loss: 1.093e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4127, Training Loss: 1.093e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4128, Training Loss: 1.093e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4129, Training Loss: 1.093e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4130, Training Loss: 1.093e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4131, Training Loss: 1.092e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4132, Training Loss: 1.092e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4133, Training Loss: 1.092e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4134, Training Loss: 1.092e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4135, Training Loss: 1.092e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4136, Training Loss: 1.091e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4137, Training Loss: 1.091e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4138, Training Loss: 1.091e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4139, Training Loss: 1.091e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4140, Training Loss: 1.091e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4141, Training Loss: 1.091e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4142, Training Loss: 1.090e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4143, Training Loss: 1.090e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4144, Training Loss: 1.090e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4145, Training Loss: 1.090e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4146, Training Loss: 1.090e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4147, Training Loss: 1.089e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4148, Training Loss: 1.089e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4149, Training Loss: 1.089e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4150, Training Loss: 1.089e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4151, Training Loss: 1.089e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4152, Training Loss: 1.088e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4153, Training Loss: 1.088e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4154, Training Loss: 1.088e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4155, Training Loss: 1.088e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4156, Training Loss: 1.088e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4157, Training Loss: 1.087e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4158, Training Loss: 1.087e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4159, Training Loss: 1.087e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4160, Training Loss: 1.087e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4161, Training Loss: 1.087e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4162, Training Loss: 1.086e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4163, Training Loss: 1.086e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4164, Training Loss: 1.086e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4165, Training Loss: 1.086e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4166, Training Loss: 1.086e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4167, Training Loss: 1.085e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4168, Training Loss: 1.085e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4169, Training Loss: 1.085e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4170, Training Loss: 1.085e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4171, Training Loss: 1.085e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4172, Training Loss: 1.085e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4173, Training Loss: 1.084e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4174, Training Loss: 1.084e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4175, Training Loss: 1.084e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4176, Training Loss: 1.084e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4177, Training Loss: 1.084e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4178, Training Loss: 1.083e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4179, Training Loss: 1.083e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4180, Training Loss: 1.083e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4181, Training Loss: 1.083e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4182, Training Loss: 1.083e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4183, Training Loss: 1.082e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4184, Training Loss: 1.082e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4185, Training Loss: 1.082e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4186, Training Loss: 1.082e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4187, Training Loss: 1.082e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4188, Training Loss: 1.081e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4189, Training Loss: 1.081e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4190, Training Loss: 1.081e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4191, Training Loss: 1.081e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4192, Training Loss: 1.081e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4193, Training Loss: 1.080e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4194, Training Loss: 1.080e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4195, Training Loss: 1.080e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4196, Training Loss: 1.080e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4197, Training Loss: 1.080e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4198, Training Loss: 1.080e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4199, Training Loss: 1.079e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4200, Training Loss: 1.079e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4201, Training Loss: 1.079e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4202, Training Loss: 1.079e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4203, Training Loss: 1.079e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4204, Training Loss: 1.078e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4205, Training Loss: 1.078e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4206, Training Loss: 1.078e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4207, Training Loss: 1.078e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4208, Training Loss: 1.078e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4209, Training Loss: 1.077e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4210, Training Loss: 1.077e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4211, Training Loss: 1.077e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4212, Training Loss: 1.077e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4213, Training Loss: 1.077e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4214, Training Loss: 1.077e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4215, Training Loss: 1.076e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4216, Training Loss: 1.076e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4217, Training Loss: 1.076e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4218, Training Loss: 1.076e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4219, Training Loss: 1.076e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4220, Training Loss: 1.075e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4221, Training Loss: 1.075e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4222, Training Loss: 1.075e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4223, Training Loss: 1.075e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4224, Training Loss: 1.075e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4225, Training Loss: 1.074e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4226, Training Loss: 1.074e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4227, Training Loss: 1.074e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4228, Training Loss: 1.074e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4229, Training Loss: 1.074e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4230, Training Loss: 1.074e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4231, Training Loss: 1.073e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4232, Training Loss: 1.073e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4233, Training Loss: 1.073e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4234, Training Loss: 1.073e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4235, Training Loss: 1.073e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4236, Training Loss: 1.072e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4237, Training Loss: 1.072e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4238, Training Loss: 1.072e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4239, Training Loss: 1.072e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4240, Training Loss: 1.072e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4241, Training Loss: 1.071e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4242, Training Loss: 1.071e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4243, Training Loss: 1.071e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4244, Training Loss: 1.071e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4245, Training Loss: 1.071e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4246, Training Loss: 1.071e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4247, Training Loss: 1.070e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4248, Training Loss: 1.070e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4249, Training Loss: 1.070e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4250, Training Loss: 1.070e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4251, Training Loss: 1.070e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4252, Training Loss: 1.069e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4253, Training Loss: 1.069e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4254, Training Loss: 1.069e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4255, Training Loss: 1.069e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4256, Training Loss: 1.069e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4257, Training Loss: 1.068e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4258, Training Loss: 1.068e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4259, Training Loss: 1.068e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4260, Training Loss: 1.068e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4261, Training Loss: 1.068e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4262, Training Loss: 1.068e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4263, Training Loss: 1.067e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4264, Training Loss: 1.067e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4265, Training Loss: 1.067e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4266, Training Loss: 1.067e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4267, Training Loss: 1.067e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4268, Training Loss: 1.066e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4269, Training Loss: 1.066e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4270, Training Loss: 1.066e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4271, Training Loss: 1.066e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4272, Training Loss: 1.066e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4273, Training Loss: 1.065e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4274, Training Loss: 1.065e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4275, Training Loss: 1.065e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4276, Training Loss: 1.065e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4277, Training Loss: 1.065e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4278, Training Loss: 1.065e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4279, Training Loss: 1.064e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4280, Training Loss: 1.064e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4281, Training Loss: 1.064e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4282, Training Loss: 1.064e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4283, Training Loss: 1.064e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4284, Training Loss: 1.063e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4285, Training Loss: 1.063e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4286, Training Loss: 1.063e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4287, Training Loss: 1.063e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4288, Training Loss: 1.063e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4289, Training Loss: 1.063e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4290, Training Loss: 1.062e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4291, Training Loss: 1.062e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4292, Training Loss: 1.062e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4293, Training Loss: 1.062e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4294, Training Loss: 1.062e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4295, Training Loss: 1.061e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4296, Training Loss: 1.061e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4297, Training Loss: 1.061e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4298, Training Loss: 1.061e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4299, Training Loss: 1.061e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4300, Training Loss: 1.061e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4301, Training Loss: 1.060e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4302, Training Loss: 1.060e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4303, Training Loss: 1.060e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4304, Training Loss: 1.060e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4305, Training Loss: 1.060e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4306, Training Loss: 1.059e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4307, Training Loss: 1.059e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4308, Training Loss: 1.059e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4309, Training Loss: 1.059e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4310, Training Loss: 1.059e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4311, Training Loss: 1.058e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4312, Training Loss: 1.058e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4313, Training Loss: 1.058e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4314, Training Loss: 1.058e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4315, Training Loss: 1.058e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4316, Training Loss: 1.058e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4317, Training Loss: 1.057e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4318, Training Loss: 1.057e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4319, Training Loss: 1.057e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4320, Training Loss: 1.057e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4321, Training Loss: 1.057e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4322, Training Loss: 1.056e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4323, Training Loss: 1.056e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4324, Training Loss: 1.056e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4325, Training Loss: 1.056e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4326, Training Loss: 1.056e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4327, Training Loss: 1.056e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4328, Training Loss: 1.055e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4329, Training Loss: 1.055e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4330, Training Loss: 1.055e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4331, Training Loss: 1.055e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4332, Training Loss: 1.055e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4333, Training Loss: 1.054e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4334, Training Loss: 1.054e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4335, Training Loss: 1.054e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4336, Training Loss: 1.054e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4337, Training Loss: 1.054e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4338, Training Loss: 1.054e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4339, Training Loss: 1.053e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4340, Training Loss: 1.053e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4341, Training Loss: 1.053e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4342, Training Loss: 1.053e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4343, Training Loss: 1.053e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4344, Training Loss: 1.052e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4345, Training Loss: 1.052e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4346, Training Loss: 1.052e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4347, Training Loss: 1.052e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4348, Training Loss: 1.052e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4349, Training Loss: 1.052e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4350, Training Loss: 1.051e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4351, Training Loss: 1.051e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4352, Training Loss: 1.051e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4353, Training Loss: 1.051e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4354, Training Loss: 1.051e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4355, Training Loss: 1.051e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4356, Training Loss: 1.050e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4357, Training Loss: 1.050e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4358, Training Loss: 1.050e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4359, Training Loss: 1.050e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4360, Training Loss: 1.050e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4361, Training Loss: 1.049e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4362, Training Loss: 1.049e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4363, Training Loss: 1.049e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4364, Training Loss: 1.049e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4365, Training Loss: 1.049e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4366, Training Loss: 1.049e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4367, Training Loss: 1.048e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4368, Training Loss: 1.048e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4369, Training Loss: 1.048e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4370, Training Loss: 1.048e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4371, Training Loss: 1.048e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4372, Training Loss: 1.047e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4373, Training Loss: 1.047e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4374, Training Loss: 1.047e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4375, Training Loss: 1.047e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4376, Training Loss: 1.047e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4377, Training Loss: 1.047e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4378, Training Loss: 1.046e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4379, Training Loss: 1.046e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4380, Training Loss: 1.046e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4381, Training Loss: 1.046e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4382, Training Loss: 1.046e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4383, Training Loss: 1.045e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4384, Training Loss: 1.045e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4385, Training Loss: 1.045e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4386, Training Loss: 1.045e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4387, Training Loss: 1.045e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4388, Training Loss: 1.045e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4389, Training Loss: 1.044e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4390, Training Loss: 1.044e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4391, Training Loss: 1.044e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4392, Training Loss: 1.044e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4393, Training Loss: 1.044e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4394, Training Loss: 1.044e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4395, Training Loss: 1.043e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4396, Training Loss: 1.043e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4397, Training Loss: 1.043e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4398, Training Loss: 1.043e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4399, Training Loss: 1.043e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4400, Training Loss: 1.042e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4401, Training Loss: 1.042e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4402, Training Loss: 1.042e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4403, Training Loss: 1.042e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4404, Training Loss: 1.042e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4405, Training Loss: 1.042e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4406, Training Loss: 1.041e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4407, Training Loss: 1.041e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4408, Training Loss: 1.041e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4409, Training Loss: 1.041e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4410, Training Loss: 1.041e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4411, Training Loss: 1.040e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4412, Training Loss: 1.040e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4413, Training Loss: 1.040e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4414, Training Loss: 1.040e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4415, Training Loss: 1.040e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4416, Training Loss: 1.040e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4417, Training Loss: 1.039e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4418, Training Loss: 1.039e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4419, Training Loss: 1.039e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4420, Training Loss: 1.039e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4421, Training Loss: 1.039e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4422, Training Loss: 1.039e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4423, Training Loss: 1.038e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4424, Training Loss: 1.038e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4425, Training Loss: 1.038e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4426, Training Loss: 1.038e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4427, Training Loss: 1.038e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4428, Training Loss: 1.037e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4429, Training Loss: 1.037e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4430, Training Loss: 1.037e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4431, Training Loss: 1.037e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4432, Training Loss: 1.037e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4433, Training Loss: 1.037e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4434, Training Loss: 1.036e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4435, Training Loss: 1.036e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4436, Training Loss: 1.036e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4437, Training Loss: 1.036e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4438, Training Loss: 1.036e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4439, Training Loss: 1.036e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4440, Training Loss: 1.035e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4441, Training Loss: 1.035e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4442, Training Loss: 1.035e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4443, Training Loss: 1.035e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4444, Training Loss: 1.035e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4445, Training Loss: 1.035e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4446, Training Loss: 1.034e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4447, Training Loss: 1.034e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4448, Training Loss: 1.034e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4449, Training Loss: 1.034e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4450, Training Loss: 1.034e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4451, Training Loss: 1.033e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4452, Training Loss: 1.033e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4453, Training Loss: 1.033e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4454, Training Loss: 1.033e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4455, Training Loss: 1.033e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4456, Training Loss: 1.033e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4457, Training Loss: 1.032e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4458, Training Loss: 1.032e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4459, Training Loss: 1.032e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4460, Training Loss: 1.032e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4461, Training Loss: 1.032e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4462, Training Loss: 1.032e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4463, Training Loss: 1.031e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4464, Training Loss: 1.031e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4465, Training Loss: 1.031e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4466, Training Loss: 1.031e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4467, Training Loss: 1.031e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4468, Training Loss: 1.030e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4469, Training Loss: 1.030e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4470, Training Loss: 1.030e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4471, Training Loss: 1.030e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4472, Training Loss: 1.030e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4473, Training Loss: 1.030e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4474, Training Loss: 1.029e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4475, Training Loss: 1.029e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4476, Training Loss: 1.029e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4477, Training Loss: 1.029e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4478, Training Loss: 1.029e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4479, Training Loss: 1.029e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4480, Training Loss: 1.028e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4481, Training Loss: 1.028e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4482, Training Loss: 1.028e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4483, Training Loss: 1.028e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4484, Training Loss: 1.028e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4485, Training Loss: 1.028e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4486, Training Loss: 1.027e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4487, Training Loss: 1.027e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4488, Training Loss: 1.027e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4489, Training Loss: 1.027e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4490, Training Loss: 1.027e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4491, Training Loss: 1.026e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4492, Training Loss: 1.026e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4493, Training Loss: 1.026e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4494, Training Loss: 1.026e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4495, Training Loss: 1.026e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4496, Training Loss: 1.026e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4497, Training Loss: 1.025e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4498, Training Loss: 1.025e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4499, Training Loss: 1.025e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4500, Training Loss: 1.025e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4501, Training Loss: 1.025e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4502, Training Loss: 1.025e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4503, Training Loss: 1.024e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4504, Training Loss: 1.024e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4505, Training Loss: 1.024e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4506, Training Loss: 1.024e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4507, Training Loss: 1.024e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4508, Training Loss: 1.024e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4509, Training Loss: 1.023e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4510, Training Loss: 1.023e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4511, Training Loss: 1.023e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4512, Training Loss: 1.023e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4513, Training Loss: 1.023e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4514, Training Loss: 1.023e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4515, Training Loss: 1.022e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4516, Training Loss: 1.022e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4517, Training Loss: 1.022e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4518, Training Loss: 1.022e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4519, Training Loss: 1.022e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4520, Training Loss: 1.021e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4521, Training Loss: 1.021e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4522, Training Loss: 1.021e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4523, Training Loss: 1.021e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4524, Training Loss: 1.021e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4525, Training Loss: 1.021e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4526, Training Loss: 1.020e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4527, Training Loss: 1.020e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4528, Training Loss: 1.020e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4529, Training Loss: 1.020e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4530, Training Loss: 1.020e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4531, Training Loss: 1.020e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4532, Training Loss: 1.019e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4533, Training Loss: 1.019e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4534, Training Loss: 1.019e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4535, Training Loss: 1.019e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4536, Training Loss: 1.019e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4537, Training Loss: 1.019e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4538, Training Loss: 1.018e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4539, Training Loss: 1.018e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4540, Training Loss: 1.018e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4541, Training Loss: 1.018e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4542, Training Loss: 1.018e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4543, Training Loss: 1.018e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4544, Training Loss: 1.017e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4545, Training Loss: 1.017e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4546, Training Loss: 1.017e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4547, Training Loss: 1.017e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4548, Training Loss: 1.017e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4549, Training Loss: 1.017e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4550, Training Loss: 1.016e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4551, Training Loss: 1.016e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4552, Training Loss: 1.016e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4553, Training Loss: 1.016e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4554, Training Loss: 1.016e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4555, Training Loss: 1.016e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4556, Training Loss: 1.015e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4557, Training Loss: 1.015e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4558, Training Loss: 1.015e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4559, Training Loss: 1.015e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4560, Training Loss: 1.015e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4561, Training Loss: 1.015e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4562, Training Loss: 1.014e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4563, Training Loss: 1.014e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4564, Training Loss: 1.014e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4565, Training Loss: 1.014e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4566, Training Loss: 1.014e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4567, Training Loss: 1.013e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4568, Training Loss: 1.013e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4569, Training Loss: 1.013e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4570, Training Loss: 1.013e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4571, Training Loss: 1.013e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4572, Training Loss: 1.013e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4573, Training Loss: 1.012e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4574, Training Loss: 1.012e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4575, Training Loss: 1.012e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4576, Training Loss: 1.012e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4577, Training Loss: 1.012e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4578, Training Loss: 1.012e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4579, Training Loss: 1.011e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4580, Training Loss: 1.011e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4581, Training Loss: 1.011e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4582, Training Loss: 1.011e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4583, Training Loss: 1.011e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4584, Training Loss: 1.011e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4585, Training Loss: 1.010e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4586, Training Loss: 1.010e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4587, Training Loss: 1.010e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4588, Training Loss: 1.010e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4589, Training Loss: 1.010e+00, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4590, Training Loss: 1.010e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4591, Training Loss: 1.009e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4592, Training Loss: 1.009e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4593, Training Loss: 1.009e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4594, Training Loss: 1.009e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4595, Training Loss: 1.009e+00, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4596, Training Loss: 1.009e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4597, Training Loss: 1.008e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4598, Training Loss: 1.008e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4599, Training Loss: 1.008e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4600, Training Loss: 1.008e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4601, Training Loss: 1.008e+00, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4602, Training Loss: 1.008e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4603, Training Loss: 1.007e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4604, Training Loss: 1.007e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4605, Training Loss: 1.007e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4606, Training Loss: 1.007e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4607, Training Loss: 1.007e+00, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4608, Training Loss: 1.007e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4609, Training Loss: 1.006e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4610, Training Loss: 1.006e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4611, Training Loss: 1.006e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4612, Training Loss: 1.006e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4613, Training Loss: 1.006e+00, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4614, Training Loss: 1.006e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4615, Training Loss: 1.005e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4616, Training Loss: 1.005e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4617, Training Loss: 1.005e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4618, Training Loss: 1.005e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4619, Training Loss: 1.005e+00, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4620, Training Loss: 1.005e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4621, Training Loss: 1.004e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4622, Training Loss: 1.004e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4623, Training Loss: 1.004e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4624, Training Loss: 1.004e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4625, Training Loss: 1.004e+00, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4626, Training Loss: 1.004e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4627, Training Loss: 1.003e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4628, Training Loss: 1.003e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4629, Training Loss: 1.003e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4630, Training Loss: 1.003e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4631, Training Loss: 1.003e+00, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4632, Training Loss: 1.003e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4633, Training Loss: 1.002e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4634, Training Loss: 1.002e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4635, Training Loss: 1.002e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4636, Training Loss: 1.002e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4637, Training Loss: 1.002e+00, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4638, Training Loss: 1.002e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4639, Training Loss: 1.001e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4640, Training Loss: 1.001e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4641, Training Loss: 1.001e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4642, Training Loss: 1.001e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4643, Training Loss: 1.001e+00, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4644, Training Loss: 1.001e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4645, Training Loss: 1.000e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4646, Training Loss: 1.000e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4647, Training Loss: 1.000e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4648, Training Loss: 1.000e+00, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4649, Training Loss: 9.998e-01, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4650, Training Loss: 9.997e-01, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4651, Training Loss: 9.995e-01, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4652, Training Loss: 9.993e-01, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4653, Training Loss: 9.992e-01, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4654, Training Loss: 9.990e-01, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4655, Training Loss: 9.988e-01, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4656, Training Loss: 9.987e-01, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4657, Training Loss: 9.985e-01, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4658, Training Loss: 9.983e-01, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4659, Training Loss: 9.982e-01, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4660, Training Loss: 9.980e-01, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4661, Training Loss: 9.978e-01, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4662, Training Loss: 9.977e-01, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4663, Training Loss: 9.975e-01, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4664, Training Loss: 9.974e-01, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4665, Training Loss: 9.972e-01, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4666, Training Loss: 9.970e-01, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4667, Training Loss: 9.969e-01, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4668, Training Loss: 9.967e-01, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4669, Training Loss: 9.965e-01, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4670, Training Loss: 9.964e-01, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4671, Training Loss: 9.962e-01, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4672, Training Loss: 9.960e-01, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4673, Training Loss: 9.959e-01, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4674, Training Loss: 9.957e-01, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4675, Training Loss: 9.956e-01, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4676, Training Loss: 9.954e-01, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4677, Training Loss: 9.952e-01, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4678, Training Loss: 9.951e-01, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4679, Training Loss: 9.949e-01, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4680, Training Loss: 9.947e-01, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4681, Training Loss: 9.946e-01, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4682, Training Loss: 9.944e-01, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4683, Training Loss: 9.942e-01, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4684, Training Loss: 9.941e-01, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4685, Training Loss: 9.939e-01, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4686, Training Loss: 9.938e-01, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4687, Training Loss: 9.936e-01, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4688, Training Loss: 9.934e-01, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4689, Training Loss: 9.933e-01, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4690, Training Loss: 9.931e-01, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4691, Training Loss: 9.929e-01, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4692, Training Loss: 9.928e-01, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4693, Training Loss: 9.926e-01, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4694, Training Loss: 9.925e-01, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4695, Training Loss: 9.923e-01, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4696, Training Loss: 9.921e-01, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4697, Training Loss: 9.920e-01, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4698, Training Loss: 9.918e-01, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4699, Training Loss: 9.916e-01, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4700, Training Loss: 9.915e-01, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4701, Training Loss: 9.913e-01, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4702, Training Loss: 9.912e-01, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4703, Training Loss: 9.910e-01, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4704, Training Loss: 9.908e-01, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4705, Training Loss: 9.907e-01, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4706, Training Loss: 9.905e-01, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4707, Training Loss: 9.903e-01, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4708, Training Loss: 9.902e-01, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4709, Training Loss: 9.900e-01, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4710, Training Loss: 9.899e-01, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4711, Training Loss: 9.897e-01, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4712, Training Loss: 9.895e-01, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4713, Training Loss: 9.894e-01, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4714, Training Loss: 9.892e-01, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4715, Training Loss: 9.891e-01, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4716, Training Loss: 9.889e-01, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4717, Training Loss: 9.887e-01, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4718, Training Loss: 9.886e-01, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4719, Training Loss: 9.884e-01, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4720, Training Loss: 9.882e-01, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4721, Training Loss: 9.881e-01, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4722, Training Loss: 9.879e-01, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4723, Training Loss: 9.878e-01, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4724, Training Loss: 9.876e-01, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4725, Training Loss: 9.874e-01, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4726, Training Loss: 9.873e-01, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4727, Training Loss: 9.871e-01, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4728, Training Loss: 9.870e-01, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4729, Training Loss: 9.868e-01, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4730, Training Loss: 9.866e-01, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4731, Training Loss: 9.865e-01, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4732, Training Loss: 9.863e-01, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4733, Training Loss: 9.861e-01, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4734, Training Loss: 9.860e-01, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4735, Training Loss: 9.858e-01, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4736, Training Loss: 9.857e-01, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4737, Training Loss: 9.855e-01, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4738, Training Loss: 9.853e-01, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4739, Training Loss: 9.852e-01, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4740, Training Loss: 9.850e-01, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4741, Training Loss: 9.849e-01, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4742, Training Loss: 9.847e-01, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4743, Training Loss: 9.845e-01, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4744, Training Loss: 9.844e-01, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4745, Training Loss: 9.842e-01, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4746, Training Loss: 9.840e-01, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4747, Training Loss: 9.839e-01, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4748, Training Loss: 9.837e-01, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4749, Training Loss: 9.836e-01, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4750, Training Loss: 9.834e-01, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4751, Training Loss: 9.832e-01, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4752, Training Loss: 9.831e-01, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4753, Training Loss: 9.829e-01, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4754, Training Loss: 9.828e-01, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4755, Training Loss: 9.826e-01, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4756, Training Loss: 9.824e-01, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4757, Training Loss: 9.823e-01, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4758, Training Loss: 9.821e-01, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4759, Training Loss: 9.820e-01, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4760, Training Loss: 9.818e-01, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4761, Training Loss: 9.816e-01, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4762, Training Loss: 9.815e-01, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4763, Training Loss: 9.813e-01, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4764, Training Loss: 9.812e-01, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4765, Training Loss: 9.810e-01, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4766, Training Loss: 9.808e-01, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4767, Training Loss: 9.807e-01, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4768, Training Loss: 9.805e-01, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4769, Training Loss: 9.804e-01, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4770, Training Loss: 9.802e-01, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4771, Training Loss: 9.800e-01, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4772, Training Loss: 9.799e-01, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4773, Training Loss: 9.797e-01, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4774, Training Loss: 9.796e-01, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4775, Training Loss: 9.794e-01, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4776, Training Loss: 9.792e-01, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4777, Training Loss: 9.791e-01, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4778, Training Loss: 9.789e-01, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4779, Training Loss: 9.788e-01, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4780, Training Loss: 9.786e-01, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4781, Training Loss: 9.785e-01, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4782, Training Loss: 9.783e-01, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4783, Training Loss: 9.781e-01, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4784, Training Loss: 9.780e-01, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4785, Training Loss: 9.778e-01, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4786, Training Loss: 9.777e-01, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4787, Training Loss: 9.775e-01, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4788, Training Loss: 9.773e-01, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4789, Training Loss: 9.772e-01, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4790, Training Loss: 9.770e-01, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4791, Training Loss: 9.769e-01, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4792, Training Loss: 9.767e-01, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4793, Training Loss: 9.765e-01, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4794, Training Loss: 9.764e-01, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4795, Training Loss: 9.762e-01, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4796, Training Loss: 9.761e-01, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4797, Training Loss: 9.759e-01, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4798, Training Loss: 9.758e-01, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4799, Training Loss: 9.756e-01, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4800, Training Loss: 9.754e-01, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4801, Training Loss: 9.753e-01, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4802, Training Loss: 9.751e-01, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4803, Training Loss: 9.750e-01, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4804, Training Loss: 9.748e-01, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4805, Training Loss: 9.747e-01, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4806, Training Loss: 9.745e-01, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4807, Training Loss: 9.743e-01, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4808, Training Loss: 9.742e-01, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4809, Training Loss: 9.740e-01, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4810, Training Loss: 9.739e-01, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4811, Training Loss: 9.737e-01, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4812, Training Loss: 9.736e-01, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4813, Training Loss: 9.734e-01, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4814, Training Loss: 9.732e-01, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4815, Training Loss: 9.731e-01, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4816, Training Loss: 9.729e-01, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4817, Training Loss: 9.728e-01, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4818, Training Loss: 9.726e-01, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4819, Training Loss: 9.725e-01, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4820, Training Loss: 9.723e-01, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4821, Training Loss: 9.721e-01, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4822, Training Loss: 9.720e-01, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4823, Training Loss: 9.718e-01, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4824, Training Loss: 9.717e-01, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4825, Training Loss: 9.715e-01, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4826, Training Loss: 9.714e-01, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4827, Training Loss: 9.712e-01, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4828, Training Loss: 9.711e-01, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4829, Training Loss: 9.709e-01, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4830, Training Loss: 9.707e-01, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4831, Training Loss: 9.706e-01, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4832, Training Loss: 9.704e-01, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4833, Training Loss: 9.703e-01, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4834, Training Loss: 9.701e-01, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4835, Training Loss: 9.700e-01, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4836, Training Loss: 9.698e-01, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4837, Training Loss: 9.696e-01, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4838, Training Loss: 9.695e-01, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4839, Training Loss: 9.693e-01, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4840, Training Loss: 9.692e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4841, Training Loss: 9.690e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4842, Training Loss: 9.689e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4843, Training Loss: 9.687e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4844, Training Loss: 9.686e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4845, Training Loss: 9.684e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4846, Training Loss: 9.682e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4847, Training Loss: 9.681e-01, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4848, Training Loss: 9.679e-01, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4849, Training Loss: 9.678e-01, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4850, Training Loss: 9.676e-01, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4851, Training Loss: 9.675e-01, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4852, Training Loss: 9.673e-01, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4853, Training Loss: 9.672e-01, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4854, Training Loss: 9.670e-01, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4855, Training Loss: 9.669e-01, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4856, Training Loss: 9.667e-01, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4857, Training Loss: 9.665e-01, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4858, Training Loss: 9.664e-01, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4859, Training Loss: 9.662e-01, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4860, Training Loss: 9.661e-01, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4861, Training Loss: 9.659e-01, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4862, Training Loss: 9.658e-01, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4863, Training Loss: 9.656e-01, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4864, Training Loss: 9.655e-01, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4865, Training Loss: 9.653e-01, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4866, Training Loss: 9.652e-01, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4867, Training Loss: 9.650e-01, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4868, Training Loss: 9.648e-01, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4869, Training Loss: 9.647e-01, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4870, Training Loss: 9.645e-01, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4871, Training Loss: 9.644e-01, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4872, Training Loss: 9.642e-01, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4873, Training Loss: 9.641e-01, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4874, Training Loss: 9.639e-01, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4875, Training Loss: 9.638e-01, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4876, Training Loss: 9.636e-01, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4877, Training Loss: 9.635e-01, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4878, Training Loss: 9.633e-01, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4879, Training Loss: 9.631e-01, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4880, Training Loss: 9.630e-01, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4881, Training Loss: 9.628e-01, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4882, Training Loss: 9.627e-01, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4883, Training Loss: 9.625e-01, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4884, Training Loss: 9.624e-01, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4885, Training Loss: 9.622e-01, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4886, Training Loss: 9.621e-01, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4887, Training Loss: 9.619e-01, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4888, Training Loss: 9.618e-01, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4889, Training Loss: 9.616e-01, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4890, Training Loss: 9.615e-01, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4891, Training Loss: 9.613e-01, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4892, Training Loss: 9.611e-01, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4893, Training Loss: 9.610e-01, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4894, Training Loss: 9.608e-01, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4895, Training Loss: 9.607e-01, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4896, Training Loss: 9.605e-01, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4897, Training Loss: 9.604e-01, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4898, Training Loss: 9.602e-01, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4899, Training Loss: 9.601e-01, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4900, Training Loss: 9.599e-01, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4901, Training Loss: 9.598e-01, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4902, Training Loss: 9.596e-01, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4903, Training Loss: 9.595e-01, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4904, Training Loss: 9.593e-01, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4905, Training Loss: 9.592e-01, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4906, Training Loss: 9.590e-01, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4907, Training Loss: 9.588e-01, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4908, Training Loss: 9.587e-01, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4909, Training Loss: 9.585e-01, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4910, Training Loss: 9.584e-01, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4911, Training Loss: 9.582e-01, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4912, Training Loss: 9.581e-01, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4913, Training Loss: 9.579e-01, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4914, Training Loss: 9.578e-01, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4915, Training Loss: 9.576e-01, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4916, Training Loss: 9.575e-01, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4917, Training Loss: 9.573e-01, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4918, Training Loss: 9.572e-01, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4919, Training Loss: 9.570e-01, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4920, Training Loss: 9.569e-01, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4921, Training Loss: 9.567e-01, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4922, Training Loss: 9.566e-01, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4923, Training Loss: 9.564e-01, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4924, Training Loss: 9.563e-01, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4925, Training Loss: 9.561e-01, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4926, Training Loss: 9.560e-01, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4927, Training Loss: 9.558e-01, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4928, Training Loss: 9.556e-01, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4929, Training Loss: 9.555e-01, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4930, Training Loss: 9.553e-01, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4931, Training Loss: 9.552e-01, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4932, Training Loss: 9.550e-01, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4933, Training Loss: 9.549e-01, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4934, Training Loss: 9.547e-01, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4935, Training Loss: 9.546e-01, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4936, Training Loss: 9.544e-01, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4937, Training Loss: 9.543e-01, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4938, Training Loss: 9.541e-01, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4939, Training Loss: 9.540e-01, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4940, Training Loss: 9.538e-01, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4941, Training Loss: 9.537e-01, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4942, Training Loss: 9.535e-01, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4943, Training Loss: 9.534e-01, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4944, Training Loss: 9.532e-01, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4945, Training Loss: 9.531e-01, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4946, Training Loss: 9.529e-01, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4947, Training Loss: 9.528e-01, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4948, Training Loss: 9.526e-01, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4949, Training Loss: 9.525e-01, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4950, Training Loss: 9.523e-01, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4951, Training Loss: 9.522e-01, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4952, Training Loss: 9.520e-01, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4953, Training Loss: 9.519e-01, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4954, Training Loss: 9.517e-01, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4955, Training Loss: 9.516e-01, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4956, Training Loss: 9.514e-01, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4957, Training Loss: 9.513e-01, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4958, Training Loss: 9.511e-01, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4959, Training Loss: 9.510e-01, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4960, Training Loss: 9.508e-01, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4961, Training Loss: 9.507e-01, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4962, Training Loss: 9.505e-01, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4963, Training Loss: 9.504e-01, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4964, Training Loss: 9.502e-01, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4965, Training Loss: 9.501e-01, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4966, Training Loss: 9.499e-01, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4967, Training Loss: 9.498e-01, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4968, Training Loss: 9.496e-01, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4969, Training Loss: 9.495e-01, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4970, Training Loss: 9.493e-01, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4971, Training Loss: 9.492e-01, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4972, Training Loss: 9.490e-01, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4973, Training Loss: 9.489e-01, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4974, Training Loss: 9.487e-01, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4975, Training Loss: 9.486e-01, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4976, Training Loss: 9.484e-01, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4977, Training Loss: 9.483e-01, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4978, Training Loss: 9.481e-01, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4979, Training Loss: 9.480e-01, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4980, Training Loss: 9.478e-01, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4981, Training Loss: 9.477e-01, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4982, Training Loss: 9.475e-01, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4983, Training Loss: 9.474e-01, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4984, Training Loss: 9.472e-01, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4985, Training Loss: 9.471e-01, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4986, Training Loss: 9.469e-01, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4987, Training Loss: 9.468e-01, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4988, Training Loss: 9.466e-01, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4989, Training Loss: 9.465e-01, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4990, Training Loss: 9.463e-01, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4991, Training Loss: 9.462e-01, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4992, Training Loss: 9.460e-01, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4993, Training Loss: 9.459e-01, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4994, Training Loss: 9.457e-01, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4995, Training Loss: 9.456e-01, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4996, Training Loss: 9.454e-01, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4997, Training Loss: 9.453e-01, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4998, Training Loss: 9.451e-01, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4999, Training Loss: 9.450e-01, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5000, Training Loss: 9.448e-01, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5001, Training Loss: 9.447e-01, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5002, Training Loss: 9.445e-01, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5003, Training Loss: 9.444e-01, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5004, Training Loss: 9.442e-01, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5005, Training Loss: 9.441e-01, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5006, Training Loss: 9.439e-01, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5007, Training Loss: 9.438e-01, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5008, Training Loss: 9.436e-01, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5009, Training Loss: 9.435e-01, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5010, Training Loss: 9.433e-01, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5011, Training Loss: 9.432e-01, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5012, Training Loss: 9.430e-01, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5013, Training Loss: 9.429e-01, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5014, Training Loss: 9.427e-01, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5015, Training Loss: 9.426e-01, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5016, Training Loss: 9.425e-01, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5017, Training Loss: 9.423e-01, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5018, Training Loss: 9.422e-01, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5019, Training Loss: 9.420e-01, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5020, Training Loss: 9.419e-01, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5021, Training Loss: 9.417e-01, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5022, Training Loss: 9.416e-01, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5023, Training Loss: 9.414e-01, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5024, Training Loss: 9.413e-01, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5025, Training Loss: 9.411e-01, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5026, Training Loss: 9.410e-01, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5027, Training Loss: 9.408e-01, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5028, Training Loss: 9.407e-01, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5029, Training Loss: 9.405e-01, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5030, Training Loss: 9.404e-01, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5031, Training Loss: 9.402e-01, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5032, Training Loss: 9.401e-01, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5033, Training Loss: 9.399e-01, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5034, Training Loss: 9.398e-01, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5035, Training Loss: 9.396e-01, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5036, Training Loss: 9.395e-01, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5037, Training Loss: 9.394e-01, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5038, Training Loss: 9.392e-01, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5039, Training Loss: 9.391e-01, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5040, Training Loss: 9.389e-01, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5041, Training Loss: 9.388e-01, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5042, Training Loss: 9.386e-01, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5043, Training Loss: 9.385e-01, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5044, Training Loss: 9.383e-01, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5045, Training Loss: 9.382e-01, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5046, Training Loss: 9.380e-01, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5047, Training Loss: 9.379e-01, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5048, Training Loss: 9.377e-01, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5049, Training Loss: 9.376e-01, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5050, Training Loss: 9.374e-01, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5051, Training Loss: 9.373e-01, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5052, Training Loss: 9.371e-01, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5053, Training Loss: 9.370e-01, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5054, Training Loss: 9.369e-01, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5055, Training Loss: 9.367e-01, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5056, Training Loss: 9.366e-01, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5057, Training Loss: 9.364e-01, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5058, Training Loss: 9.363e-01, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5059, Training Loss: 9.361e-01, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5060, Training Loss: 9.360e-01, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5061, Training Loss: 9.358e-01, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5062, Training Loss: 9.357e-01, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5063, Training Loss: 9.355e-01, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5064, Training Loss: 9.354e-01, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5065, Training Loss: 9.352e-01, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5066, Training Loss: 9.351e-01, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5067, Training Loss: 9.350e-01, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5068, Training Loss: 9.348e-01, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5069, Training Loss: 9.347e-01, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5070, Training Loss: 9.345e-01, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5071, Training Loss: 9.344e-01, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5072, Training Loss: 9.342e-01, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5073, Training Loss: 9.341e-01, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5074, Training Loss: 9.339e-01, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5075, Training Loss: 9.338e-01, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5076, Training Loss: 9.336e-01, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5077, Training Loss: 9.335e-01, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5078, Training Loss: 9.333e-01, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5079, Training Loss: 9.332e-01, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5080, Training Loss: 9.331e-01, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5081, Training Loss: 9.329e-01, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5082, Training Loss: 9.328e-01, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5083, Training Loss: 9.326e-01, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5084, Training Loss: 9.325e-01, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5085, Training Loss: 9.323e-01, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5086, Training Loss: 9.322e-01, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5087, Training Loss: 9.320e-01, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5088, Training Loss: 9.319e-01, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5089, Training Loss: 9.317e-01, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5090, Training Loss: 9.316e-01, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5091, Training Loss: 9.315e-01, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5092, Training Loss: 9.313e-01, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5093, Training Loss: 9.312e-01, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5094, Training Loss: 9.310e-01, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5095, Training Loss: 9.309e-01, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5096, Training Loss: 9.307e-01, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5097, Training Loss: 9.306e-01, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5098, Training Loss: 9.304e-01, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5099, Training Loss: 9.303e-01, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5100, Training Loss: 9.302e-01, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5101, Training Loss: 9.300e-01, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5102, Training Loss: 9.299e-01, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5103, Training Loss: 9.297e-01, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5104, Training Loss: 9.296e-01, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5105, Training Loss: 9.294e-01, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5106, Training Loss: 9.293e-01, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5107, Training Loss: 9.291e-01, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5108, Training Loss: 9.290e-01, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5109, Training Loss: 9.289e-01, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5110, Training Loss: 9.287e-01, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5111, Training Loss: 9.286e-01, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5112, Training Loss: 9.284e-01, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5113, Training Loss: 9.283e-01, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5114, Training Loss: 9.281e-01, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5115, Training Loss: 9.280e-01, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5116, Training Loss: 9.278e-01, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5117, Training Loss: 9.277e-01, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5118, Training Loss: 9.276e-01, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5119, Training Loss: 9.274e-01, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5120, Training Loss: 9.273e-01, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5121, Training Loss: 9.271e-01, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5122, Training Loss: 9.270e-01, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5123, Training Loss: 9.268e-01, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5124, Training Loss: 9.267e-01, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5125, Training Loss: 9.265e-01, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5126, Training Loss: 9.264e-01, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5127, Training Loss: 9.263e-01, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5128, Training Loss: 9.261e-01, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5129, Training Loss: 9.260e-01, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5130, Training Loss: 9.258e-01, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5131, Training Loss: 9.257e-01, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5132, Training Loss: 9.255e-01, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5133, Training Loss: 9.254e-01, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5134, Training Loss: 9.253e-01, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5135, Training Loss: 9.251e-01, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5136, Training Loss: 9.250e-01, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5137, Training Loss: 9.248e-01, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5138, Training Loss: 9.247e-01, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5139, Training Loss: 9.245e-01, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5140, Training Loss: 9.244e-01, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5141, Training Loss: 9.243e-01, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5142, Training Loss: 9.241e-01, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5143, Training Loss: 9.240e-01, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5144, Training Loss: 9.238e-01, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5145, Training Loss: 9.237e-01, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5146, Training Loss: 9.235e-01, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5147, Training Loss: 9.234e-01, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5148, Training Loss: 9.233e-01, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5149, Training Loss: 9.231e-01, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5150, Training Loss: 9.230e-01, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5151, Training Loss: 9.228e-01, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5152, Training Loss: 9.227e-01, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5153, Training Loss: 9.225e-01, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5154, Training Loss: 9.224e-01, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5155, Training Loss: 9.223e-01, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5156, Training Loss: 9.221e-01, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5157, Training Loss: 9.220e-01, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5158, Training Loss: 9.218e-01, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5159, Training Loss: 9.217e-01, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5160, Training Loss: 9.215e-01, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5161, Training Loss: 9.214e-01, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5162, Training Loss: 9.213e-01, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5163, Training Loss: 9.211e-01, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5164, Training Loss: 9.210e-01, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5165, Training Loss: 9.208e-01, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5166, Training Loss: 9.207e-01, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5167, Training Loss: 9.205e-01, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5168, Training Loss: 9.204e-01, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5169, Training Loss: 9.203e-01, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5170, Training Loss: 9.201e-01, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5171, Training Loss: 9.200e-01, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5172, Training Loss: 9.198e-01, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5173, Training Loss: 9.197e-01, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5174, Training Loss: 9.196e-01, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5175, Training Loss: 9.194e-01, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5176, Training Loss: 9.193e-01, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5177, Training Loss: 9.191e-01, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5178, Training Loss: 9.190e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5179, Training Loss: 9.188e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5180, Training Loss: 9.187e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5181, Training Loss: 9.186e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5182, Training Loss: 9.184e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5183, Training Loss: 9.183e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5184, Training Loss: 9.181e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5185, Training Loss: 9.180e-01, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5186, Training Loss: 9.179e-01, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5187, Training Loss: 9.177e-01, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5188, Training Loss: 9.176e-01, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5189, Training Loss: 9.174e-01, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5190, Training Loss: 9.173e-01, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5191, Training Loss: 9.172e-01, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5192, Training Loss: 9.170e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5193, Training Loss: 9.169e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5194, Training Loss: 9.167e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5195, Training Loss: 9.166e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5196, Training Loss: 9.165e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5197, Training Loss: 9.163e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5198, Training Loss: 9.162e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5199, Training Loss: 9.160e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5200, Training Loss: 9.159e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5201, Training Loss: 9.157e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5202, Training Loss: 9.156e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5203, Training Loss: 9.155e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5204, Training Loss: 9.153e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5205, Training Loss: 9.152e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5206, Training Loss: 9.150e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5207, Training Loss: 9.149e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5208, Training Loss: 9.148e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5209, Training Loss: 9.146e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5210, Training Loss: 9.145e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5211, Training Loss: 9.143e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5212, Training Loss: 9.142e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5213, Training Loss: 9.141e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5214, Training Loss: 9.139e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5215, Training Loss: 9.138e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5216, Training Loss: 9.136e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5217, Training Loss: 9.135e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5218, Training Loss: 9.134e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5219, Training Loss: 9.132e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5220, Training Loss: 9.131e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5221, Training Loss: 9.129e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5222, Training Loss: 9.128e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5223, Training Loss: 9.127e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5224, Training Loss: 9.125e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5225, Training Loss: 9.124e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5226, Training Loss: 9.122e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5227, Training Loss: 9.121e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5228, Training Loss: 9.120e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5229, Training Loss: 9.118e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5230, Training Loss: 9.117e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5231, Training Loss: 9.115e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5232, Training Loss: 9.114e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5233, Training Loss: 9.113e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5234, Training Loss: 9.111e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5235, Training Loss: 9.110e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5236, Training Loss: 9.109e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5237, Training Loss: 9.107e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5238, Training Loss: 9.106e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5239, Training Loss: 9.104e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5240, Training Loss: 9.103e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5241, Training Loss: 9.102e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5242, Training Loss: 9.100e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5243, Training Loss: 9.099e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5244, Training Loss: 9.097e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5245, Training Loss: 9.096e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5246, Training Loss: 9.095e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5247, Training Loss: 9.093e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5248, Training Loss: 9.092e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5249, Training Loss: 9.090e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5250, Training Loss: 9.089e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5251, Training Loss: 9.088e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5252, Training Loss: 9.086e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5253, Training Loss: 9.085e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5254, Training Loss: 9.084e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5255, Training Loss: 9.082e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5256, Training Loss: 9.081e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5257, Training Loss: 9.079e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5258, Training Loss: 9.078e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5259, Training Loss: 9.077e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5260, Training Loss: 9.075e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5261, Training Loss: 9.074e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5262, Training Loss: 9.072e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5263, Training Loss: 9.071e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5264, Training Loss: 9.070e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5265, Training Loss: 9.068e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5266, Training Loss: 9.067e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5267, Training Loss: 9.066e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5268, Training Loss: 9.064e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5269, Training Loss: 9.063e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5270, Training Loss: 9.061e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5271, Training Loss: 9.060e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5272, Training Loss: 9.059e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5273, Training Loss: 9.057e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5274, Training Loss: 9.056e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5275, Training Loss: 9.054e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5276, Training Loss: 9.053e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5277, Training Loss: 9.052e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5278, Training Loss: 9.050e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5279, Training Loss: 9.049e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5280, Training Loss: 9.048e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5281, Training Loss: 9.046e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5282, Training Loss: 9.045e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5283, Training Loss: 9.043e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5284, Training Loss: 9.042e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5285, Training Loss: 9.041e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5286, Training Loss: 9.039e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5287, Training Loss: 9.038e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5288, Training Loss: 9.037e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5289, Training Loss: 9.035e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5290, Training Loss: 9.034e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5291, Training Loss: 9.032e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5292, Training Loss: 9.031e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5293, Training Loss: 9.030e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5294, Training Loss: 9.028e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5295, Training Loss: 9.027e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5296, Training Loss: 9.026e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5297, Training Loss: 9.024e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5298, Training Loss: 9.023e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5299, Training Loss: 9.022e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5300, Training Loss: 9.020e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5301, Training Loss: 9.019e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5302, Training Loss: 9.017e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5303, Training Loss: 9.016e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5304, Training Loss: 9.015e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5305, Training Loss: 9.013e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5306, Training Loss: 9.012e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5307, Training Loss: 9.011e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5308, Training Loss: 9.009e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5309, Training Loss: 9.008e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5310, Training Loss: 9.006e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5311, Training Loss: 9.005e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5312, Training Loss: 9.004e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5313, Training Loss: 9.002e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5314, Training Loss: 9.001e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5315, Training Loss: 9.000e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5316, Training Loss: 8.998e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5317, Training Loss: 8.997e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5318, Training Loss: 8.996e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5319, Training Loss: 8.994e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5320, Training Loss: 8.993e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5321, Training Loss: 8.991e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5322, Training Loss: 8.990e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5323, Training Loss: 8.989e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5324, Training Loss: 8.987e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5325, Training Loss: 8.986e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5326, Training Loss: 8.985e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5327, Training Loss: 8.983e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5328, Training Loss: 8.982e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5329, Training Loss: 8.981e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5330, Training Loss: 8.979e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5331, Training Loss: 8.978e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5332, Training Loss: 8.976e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5333, Training Loss: 8.975e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5334, Training Loss: 8.974e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5335, Training Loss: 8.972e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5336, Training Loss: 8.971e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5337, Training Loss: 8.970e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5338, Training Loss: 8.968e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5339, Training Loss: 8.967e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5340, Training Loss: 8.966e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5341, Training Loss: 8.964e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5342, Training Loss: 8.963e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5343, Training Loss: 8.962e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5344, Training Loss: 8.960e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5345, Training Loss: 8.959e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5346, Training Loss: 8.958e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5347, Training Loss: 8.956e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5348, Training Loss: 8.955e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5349, Training Loss: 8.953e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5350, Training Loss: 8.952e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5351, Training Loss: 8.951e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5352, Training Loss: 8.949e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5353, Training Loss: 8.948e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5354, Training Loss: 8.947e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5355, Training Loss: 8.945e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5356, Training Loss: 8.944e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5357, Training Loss: 8.943e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5358, Training Loss: 8.941e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5359, Training Loss: 8.940e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5360, Training Loss: 8.939e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5361, Training Loss: 8.937e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5362, Training Loss: 8.936e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5363, Training Loss: 8.935e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5364, Training Loss: 8.933e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5365, Training Loss: 8.932e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5366, Training Loss: 8.931e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5367, Training Loss: 8.929e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5368, Training Loss: 8.928e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5369, Training Loss: 8.926e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5370, Training Loss: 8.925e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5371, Training Loss: 8.924e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5372, Training Loss: 8.922e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5373, Training Loss: 8.921e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5374, Training Loss: 8.920e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5375, Training Loss: 8.918e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5376, Training Loss: 8.917e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5377, Training Loss: 8.916e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5378, Training Loss: 8.914e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5379, Training Loss: 8.913e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5380, Training Loss: 8.912e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5381, Training Loss: 8.910e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5382, Training Loss: 8.909e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5383, Training Loss: 8.908e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5384, Training Loss: 8.906e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5385, Training Loss: 8.905e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5386, Training Loss: 8.904e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5387, Training Loss: 8.902e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5388, Training Loss: 8.901e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5389, Training Loss: 8.900e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5390, Training Loss: 8.898e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5391, Training Loss: 8.897e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5392, Training Loss: 8.896e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5393, Training Loss: 8.894e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5394, Training Loss: 8.893e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5395, Training Loss: 8.892e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5396, Training Loss: 8.890e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5397, Training Loss: 8.889e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5398, Training Loss: 8.888e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5399, Training Loss: 8.886e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5400, Training Loss: 8.885e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5401, Training Loss: 8.884e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5402, Training Loss: 8.882e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5403, Training Loss: 8.881e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5404, Training Loss: 8.880e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5405, Training Loss: 8.878e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5406, Training Loss: 8.877e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5407, Training Loss: 8.876e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5408, Training Loss: 8.874e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5409, Training Loss: 8.873e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5410, Training Loss: 8.872e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5411, Training Loss: 8.870e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5412, Training Loss: 8.869e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5413, Training Loss: 8.868e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5414, Training Loss: 8.866e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5415, Training Loss: 8.865e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5416, Training Loss: 8.864e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5417, Training Loss: 8.862e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5418, Training Loss: 8.861e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5419, Training Loss: 8.860e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5420, Training Loss: 8.858e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5421, Training Loss: 8.857e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5422, Training Loss: 8.856e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5423, Training Loss: 8.854e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5424, Training Loss: 8.853e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5425, Training Loss: 8.852e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5426, Training Loss: 8.850e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5427, Training Loss: 8.849e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5428, Training Loss: 8.848e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5429, Training Loss: 8.846e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5430, Training Loss: 8.845e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5431, Training Loss: 8.844e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5432, Training Loss: 8.842e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5433, Training Loss: 8.841e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5434, Training Loss: 8.840e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5435, Training Loss: 8.838e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5436, Training Loss: 8.837e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5437, Training Loss: 8.836e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5438, Training Loss: 8.834e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5439, Training Loss: 8.833e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5440, Training Loss: 8.832e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5441, Training Loss: 8.830e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5442, Training Loss: 8.829e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5443, Training Loss: 8.828e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5444, Training Loss: 8.827e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5445, Training Loss: 8.825e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5446, Training Loss: 8.824e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5447, Training Loss: 8.823e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5448, Training Loss: 8.821e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5449, Training Loss: 8.820e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5450, Training Loss: 8.819e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5451, Training Loss: 8.817e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5452, Training Loss: 8.816e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5453, Training Loss: 8.815e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5454, Training Loss: 8.813e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5455, Training Loss: 8.812e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5456, Training Loss: 8.811e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5457, Training Loss: 8.809e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5458, Training Loss: 8.808e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5459, Training Loss: 8.807e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5460, Training Loss: 8.805e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5461, Training Loss: 8.804e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5462, Training Loss: 8.803e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5463, Training Loss: 8.802e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5464, Training Loss: 8.800e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5465, Training Loss: 8.799e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5466, Training Loss: 8.798e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5467, Training Loss: 8.796e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5468, Training Loss: 8.795e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5469, Training Loss: 8.794e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5470, Training Loss: 8.792e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5471, Training Loss: 8.791e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5472, Training Loss: 8.790e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5473, Training Loss: 8.788e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5474, Training Loss: 8.787e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5475, Training Loss: 8.786e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5476, Training Loss: 8.785e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5477, Training Loss: 8.783e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5478, Training Loss: 8.782e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5479, Training Loss: 8.781e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5480, Training Loss: 8.779e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5481, Training Loss: 8.778e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5482, Training Loss: 8.777e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5483, Training Loss: 8.775e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5484, Training Loss: 8.774e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5485, Training Loss: 8.773e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5486, Training Loss: 8.771e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5487, Training Loss: 8.770e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5488, Training Loss: 8.769e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5489, Training Loss: 8.768e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5490, Training Loss: 8.766e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5491, Training Loss: 8.765e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5492, Training Loss: 8.764e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5493, Training Loss: 8.762e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5494, Training Loss: 8.761e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5495, Training Loss: 8.760e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5496, Training Loss: 8.758e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5497, Training Loss: 8.757e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5498, Training Loss: 8.756e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5499, Training Loss: 8.755e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5500, Training Loss: 8.753e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5501, Training Loss: 8.752e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5502, Training Loss: 8.751e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5503, Training Loss: 8.749e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5504, Training Loss: 8.748e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5505, Training Loss: 8.747e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5506, Training Loss: 8.745e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5507, Training Loss: 8.744e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5508, Training Loss: 8.743e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5509, Training Loss: 8.742e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5510, Training Loss: 8.740e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5511, Training Loss: 8.739e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5512, Training Loss: 8.738e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5513, Training Loss: 8.736e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5514, Training Loss: 8.735e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5515, Training Loss: 8.734e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5516, Training Loss: 8.732e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5517, Training Loss: 8.731e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5518, Training Loss: 8.730e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5519, Training Loss: 8.729e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5520, Training Loss: 8.727e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5521, Training Loss: 8.726e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5522, Training Loss: 8.725e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5523, Training Loss: 8.723e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5524, Training Loss: 8.722e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5525, Training Loss: 8.721e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5526, Training Loss: 8.720e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5527, Training Loss: 8.718e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5528, Training Loss: 8.717e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5529, Training Loss: 8.716e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5530, Training Loss: 8.714e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5531, Training Loss: 8.713e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5532, Training Loss: 8.712e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5533, Training Loss: 8.711e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5534, Training Loss: 8.709e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5535, Training Loss: 8.708e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5536, Training Loss: 8.707e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5537, Training Loss: 8.705e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5538, Training Loss: 8.704e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5539, Training Loss: 8.703e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5540, Training Loss: 8.702e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5541, Training Loss: 8.700e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5542, Training Loss: 8.699e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5543, Training Loss: 8.698e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5544, Training Loss: 8.696e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5545, Training Loss: 8.695e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5546, Training Loss: 8.694e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5547, Training Loss: 8.693e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5548, Training Loss: 8.691e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5549, Training Loss: 8.690e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5550, Training Loss: 8.689e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5551, Training Loss: 8.687e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5552, Training Loss: 8.686e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5553, Training Loss: 8.685e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5554, Training Loss: 8.684e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5555, Training Loss: 8.682e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5556, Training Loss: 8.681e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5557, Training Loss: 8.680e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5558, Training Loss: 8.678e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5559, Training Loss: 8.677e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5560, Training Loss: 8.676e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5561, Training Loss: 8.675e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5562, Training Loss: 8.673e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5563, Training Loss: 8.672e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5564, Training Loss: 8.671e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5565, Training Loss: 8.669e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5566, Training Loss: 8.668e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5567, Training Loss: 8.667e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5568, Training Loss: 8.666e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5569, Training Loss: 8.664e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5570, Training Loss: 8.663e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5571, Training Loss: 8.662e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5572, Training Loss: 8.660e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5573, Training Loss: 8.659e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5574, Training Loss: 8.658e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5575, Training Loss: 8.657e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5576, Training Loss: 8.655e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5577, Training Loss: 8.654e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5578, Training Loss: 8.653e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5579, Training Loss: 8.651e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5580, Training Loss: 8.650e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5581, Training Loss: 8.649e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5582, Training Loss: 8.648e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5583, Training Loss: 8.646e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5584, Training Loss: 8.645e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5585, Training Loss: 8.644e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5586, Training Loss: 8.643e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5587, Training Loss: 8.641e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5588, Training Loss: 8.640e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5589, Training Loss: 8.639e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5590, Training Loss: 8.637e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5591, Training Loss: 8.636e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5592, Training Loss: 8.635e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5593, Training Loss: 8.634e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5594, Training Loss: 8.632e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5595, Training Loss: 8.631e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5596, Training Loss: 8.630e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5597, Training Loss: 8.629e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5598, Training Loss: 8.627e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5599, Training Loss: 8.626e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5600, Training Loss: 8.625e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5601, Training Loss: 8.623e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5602, Training Loss: 8.622e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5603, Training Loss: 8.621e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5604, Training Loss: 8.620e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5605, Training Loss: 8.618e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5606, Training Loss: 8.617e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5607, Training Loss: 8.616e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5608, Training Loss: 8.615e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5609, Training Loss: 8.613e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5610, Training Loss: 8.612e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5611, Training Loss: 8.611e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5612, Training Loss: 8.609e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5613, Training Loss: 8.608e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5614, Training Loss: 8.607e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5615, Training Loss: 8.606e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5616, Training Loss: 8.604e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5617, Training Loss: 8.603e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5618, Training Loss: 8.602e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5619, Training Loss: 8.601e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5620, Training Loss: 8.599e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5621, Training Loss: 8.598e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5622, Training Loss: 8.597e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5623, Training Loss: 8.596e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5624, Training Loss: 8.594e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5625, Training Loss: 8.593e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5626, Training Loss: 8.592e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5627, Training Loss: 8.591e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5628, Training Loss: 8.589e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5629, Training Loss: 8.588e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5630, Training Loss: 8.587e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5631, Training Loss: 8.585e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5632, Training Loss: 8.584e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5633, Training Loss: 8.583e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5634, Training Loss: 8.582e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5635, Training Loss: 8.580e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5636, Training Loss: 8.579e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5637, Training Loss: 8.578e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5638, Training Loss: 8.577e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5639, Training Loss: 8.575e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5640, Training Loss: 8.574e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5641, Training Loss: 8.573e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5642, Training Loss: 8.572e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5643, Training Loss: 8.570e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5644, Training Loss: 8.569e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5645, Training Loss: 8.568e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5646, Training Loss: 8.567e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5647, Training Loss: 8.565e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5648, Training Loss: 8.564e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5649, Training Loss: 8.563e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5650, Training Loss: 8.562e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5651, Training Loss: 8.560e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5652, Training Loss: 8.559e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5653, Training Loss: 8.558e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5654, Training Loss: 8.557e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5655, Training Loss: 8.555e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5656, Training Loss: 8.554e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5657, Training Loss: 8.553e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5658, Training Loss: 8.552e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5659, Training Loss: 8.550e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5660, Training Loss: 8.549e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5661, Training Loss: 8.548e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5662, Training Loss: 8.547e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5663, Training Loss: 8.545e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5664, Training Loss: 8.544e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5665, Training Loss: 8.543e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5666, Training Loss: 8.542e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5667, Training Loss: 8.540e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5668, Training Loss: 8.539e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5669, Training Loss: 8.538e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5670, Training Loss: 8.537e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5671, Training Loss: 8.535e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5672, Training Loss: 8.534e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5673, Training Loss: 8.533e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5674, Training Loss: 8.532e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5675, Training Loss: 8.530e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5676, Training Loss: 8.529e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5677, Training Loss: 8.528e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5678, Training Loss: 8.527e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5679, Training Loss: 8.525e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5680, Training Loss: 8.524e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5681, Training Loss: 8.523e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5682, Training Loss: 8.522e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5683, Training Loss: 8.521e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5684, Training Loss: 8.519e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5685, Training Loss: 8.518e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5686, Training Loss: 8.517e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5687, Training Loss: 8.516e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5688, Training Loss: 8.514e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5689, Training Loss: 8.513e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5690, Training Loss: 8.512e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5691, Training Loss: 8.511e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5692, Training Loss: 8.509e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5693, Training Loss: 8.508e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5694, Training Loss: 8.507e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5695, Training Loss: 8.506e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5696, Training Loss: 8.504e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5697, Training Loss: 8.503e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5698, Training Loss: 8.502e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5699, Training Loss: 8.501e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5700, Training Loss: 8.499e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5701, Training Loss: 8.498e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5702, Training Loss: 8.497e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5703, Training Loss: 8.496e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5704, Training Loss: 8.494e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5705, Training Loss: 8.493e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5706, Training Loss: 8.492e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5707, Training Loss: 8.491e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5708, Training Loss: 8.490e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5709, Training Loss: 8.488e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5710, Training Loss: 8.487e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5711, Training Loss: 8.486e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5712, Training Loss: 8.485e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5713, Training Loss: 8.483e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5714, Training Loss: 8.482e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5715, Training Loss: 8.481e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5716, Training Loss: 8.480e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5717, Training Loss: 8.478e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5718, Training Loss: 8.477e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5719, Training Loss: 8.476e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5720, Training Loss: 8.475e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5721, Training Loss: 8.474e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5722, Training Loss: 8.472e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5723, Training Loss: 8.471e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5724, Training Loss: 8.470e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5725, Training Loss: 8.469e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5726, Training Loss: 8.467e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5727, Training Loss: 8.466e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5728, Training Loss: 8.465e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5729, Training Loss: 8.464e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5730, Training Loss: 8.462e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5731, Training Loss: 8.461e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5732, Training Loss: 8.460e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5733, Training Loss: 8.459e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5734, Training Loss: 8.458e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5735, Training Loss: 8.456e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5736, Training Loss: 8.455e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5737, Training Loss: 8.454e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5738, Training Loss: 8.453e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5739, Training Loss: 8.451e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5740, Training Loss: 8.450e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5741, Training Loss: 8.449e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5742, Training Loss: 8.448e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5743, Training Loss: 8.447e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5744, Training Loss: 8.445e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5745, Training Loss: 8.444e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5746, Training Loss: 8.443e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5747, Training Loss: 8.442e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5748, Training Loss: 8.440e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5749, Training Loss: 8.439e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5750, Training Loss: 8.438e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5751, Training Loss: 8.437e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5752, Training Loss: 8.436e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5753, Training Loss: 8.434e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5754, Training Loss: 8.433e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5755, Training Loss: 8.432e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5756, Training Loss: 8.431e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5757, Training Loss: 8.429e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5758, Training Loss: 8.428e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5759, Training Loss: 8.427e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5760, Training Loss: 8.426e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5761, Training Loss: 8.425e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5762, Training Loss: 8.423e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5763, Training Loss: 8.422e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5764, Training Loss: 8.421e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5765, Training Loss: 8.420e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5766, Training Loss: 8.418e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5767, Training Loss: 8.417e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5768, Training Loss: 8.416e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5769, Training Loss: 8.415e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5770, Training Loss: 8.414e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5771, Training Loss: 8.412e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5772, Training Loss: 8.411e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5773, Training Loss: 8.410e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5774, Training Loss: 8.409e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5775, Training Loss: 8.408e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5776, Training Loss: 8.406e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5777, Training Loss: 8.405e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5778, Training Loss: 8.404e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5779, Training Loss: 8.403e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5780, Training Loss: 8.401e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5781, Training Loss: 8.400e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5782, Training Loss: 8.399e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5783, Training Loss: 8.398e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5784, Training Loss: 8.397e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5785, Training Loss: 8.395e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5786, Training Loss: 8.394e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5787, Training Loss: 8.393e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5788, Training Loss: 8.392e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5789, Training Loss: 8.391e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5790, Training Loss: 8.389e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5791, Training Loss: 8.388e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5792, Training Loss: 8.387e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5793, Training Loss: 8.386e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5794, Training Loss: 8.385e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5795, Training Loss: 8.383e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5796, Training Loss: 8.382e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5797, Training Loss: 8.381e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5798, Training Loss: 8.380e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5799, Training Loss: 8.378e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5800, Training Loss: 8.377e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5801, Training Loss: 8.376e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5802, Training Loss: 8.375e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5803, Training Loss: 8.374e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5804, Training Loss: 8.372e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5805, Training Loss: 8.371e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5806, Training Loss: 8.370e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5807, Training Loss: 8.369e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5808, Training Loss: 8.368e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5809, Training Loss: 8.366e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5810, Training Loss: 8.365e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5811, Training Loss: 8.364e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5812, Training Loss: 8.363e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5813, Training Loss: 8.362e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5814, Training Loss: 8.360e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5815, Training Loss: 8.359e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5816, Training Loss: 8.358e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5817, Training Loss: 8.357e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5818, Training Loss: 8.356e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5819, Training Loss: 8.354e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5820, Training Loss: 8.353e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5821, Training Loss: 8.352e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5822, Training Loss: 8.351e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5823, Training Loss: 8.350e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5824, Training Loss: 8.348e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5825, Training Loss: 8.347e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5826, Training Loss: 8.346e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5827, Training Loss: 8.345e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5828, Training Loss: 8.344e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5829, Training Loss: 8.342e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5830, Training Loss: 8.341e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5831, Training Loss: 8.340e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5832, Training Loss: 8.339e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5833, Training Loss: 8.338e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5834, Training Loss: 8.336e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5835, Training Loss: 8.335e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5836, Training Loss: 8.334e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5837, Training Loss: 8.333e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5838, Training Loss: 8.332e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5839, Training Loss: 8.330e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5840, Training Loss: 8.329e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5841, Training Loss: 8.328e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5842, Training Loss: 8.327e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5843, Training Loss: 8.326e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5844, Training Loss: 8.324e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5845, Training Loss: 8.323e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5846, Training Loss: 8.322e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5847, Training Loss: 8.321e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5848, Training Loss: 8.320e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5849, Training Loss: 8.318e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5850, Training Loss: 8.317e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5851, Training Loss: 8.316e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5852, Training Loss: 8.315e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5853, Training Loss: 8.314e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5854, Training Loss: 8.313e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5855, Training Loss: 8.311e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5856, Training Loss: 8.310e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5857, Training Loss: 8.309e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5858, Training Loss: 8.308e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5859, Training Loss: 8.307e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5860, Training Loss: 8.305e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5861, Training Loss: 8.304e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5862, Training Loss: 8.303e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5863, Training Loss: 8.302e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5864, Training Loss: 8.301e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5865, Training Loss: 8.299e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5866, Training Loss: 8.298e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5867, Training Loss: 8.297e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5868, Training Loss: 8.296e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5869, Training Loss: 8.295e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5870, Training Loss: 8.294e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5871, Training Loss: 8.292e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5872, Training Loss: 8.291e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5873, Training Loss: 8.290e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5874, Training Loss: 8.289e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5875, Training Loss: 8.288e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5876, Training Loss: 8.286e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5877, Training Loss: 8.285e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5878, Training Loss: 8.284e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5879, Training Loss: 8.283e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5880, Training Loss: 8.282e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5881, Training Loss: 8.280e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5882, Training Loss: 8.279e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5883, Training Loss: 8.278e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5884, Training Loss: 8.277e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5885, Training Loss: 8.276e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5886, Training Loss: 8.275e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5887, Training Loss: 8.273e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5888, Training Loss: 8.272e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5889, Training Loss: 8.271e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5890, Training Loss: 8.270e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5891, Training Loss: 8.269e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5892, Training Loss: 8.268e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5893, Training Loss: 8.266e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5894, Training Loss: 8.265e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5895, Training Loss: 8.264e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5896, Training Loss: 8.263e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5897, Training Loss: 8.262e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5898, Training Loss: 8.260e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5899, Training Loss: 8.259e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5900, Training Loss: 8.258e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5901, Training Loss: 8.257e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5902, Training Loss: 8.256e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5903, Training Loss: 8.255e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5904, Training Loss: 8.253e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5905, Training Loss: 8.252e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5906, Training Loss: 8.251e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5907, Training Loss: 8.250e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5908, Training Loss: 8.249e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5909, Training Loss: 8.248e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5910, Training Loss: 8.246e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5911, Training Loss: 8.245e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5912, Training Loss: 8.244e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5913, Training Loss: 8.243e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5914, Training Loss: 8.242e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5915, Training Loss: 8.240e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5916, Training Loss: 8.239e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5917, Training Loss: 8.238e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5918, Training Loss: 8.237e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5919, Training Loss: 8.236e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5920, Training Loss: 8.235e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5921, Training Loss: 8.233e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5922, Training Loss: 8.232e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5923, Training Loss: 8.231e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5924, Training Loss: 8.230e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5925, Training Loss: 8.229e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5926, Training Loss: 8.228e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5927, Training Loss: 8.226e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5928, Training Loss: 8.225e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5929, Training Loss: 8.224e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5930, Training Loss: 8.223e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5931, Training Loss: 8.222e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5932, Training Loss: 8.221e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5933, Training Loss: 8.219e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5934, Training Loss: 8.218e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5935, Training Loss: 8.217e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5936, Training Loss: 8.216e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5937, Training Loss: 8.215e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5938, Training Loss: 8.214e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5939, Training Loss: 8.212e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5940, Training Loss: 8.211e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5941, Training Loss: 8.210e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5942, Training Loss: 8.209e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5943, Training Loss: 8.208e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5944, Training Loss: 8.207e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5945, Training Loss: 8.205e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5946, Training Loss: 8.204e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5947, Training Loss: 8.203e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5948, Training Loss: 8.202e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5949, Training Loss: 8.201e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5950, Training Loss: 8.200e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5951, Training Loss: 8.198e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5952, Training Loss: 8.197e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5953, Training Loss: 8.196e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5954, Training Loss: 8.195e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5955, Training Loss: 8.194e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5956, Training Loss: 8.193e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5957, Training Loss: 8.191e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5958, Training Loss: 8.190e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5959, Training Loss: 8.189e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5960, Training Loss: 8.188e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5961, Training Loss: 8.187e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5962, Training Loss: 8.186e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5963, Training Loss: 8.184e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5964, Training Loss: 8.183e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5965, Training Loss: 8.182e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5966, Training Loss: 8.181e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5967, Training Loss: 8.180e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5968, Training Loss: 8.179e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5969, Training Loss: 8.177e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5970, Training Loss: 8.176e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5971, Training Loss: 8.175e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5972, Training Loss: 8.174e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5973, Training Loss: 8.173e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5974, Training Loss: 8.172e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5975, Training Loss: 8.170e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5976, Training Loss: 8.169e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5977, Training Loss: 8.168e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5978, Training Loss: 8.167e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5979, Training Loss: 8.166e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5980, Training Loss: 8.165e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5981, Training Loss: 8.164e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5982, Training Loss: 8.162e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5983, Training Loss: 8.161e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5984, Training Loss: 8.160e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5985, Training Loss: 8.159e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5986, Training Loss: 8.158e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5987, Training Loss: 8.157e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5988, Training Loss: 8.155e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5989, Training Loss: 8.154e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5990, Training Loss: 8.153e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5991, Training Loss: 8.152e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5992, Training Loss: 8.151e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5993, Training Loss: 8.150e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5994, Training Loss: 8.149e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5995, Training Loss: 8.147e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5996, Training Loss: 8.146e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5997, Training Loss: 8.145e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5998, Training Loss: 8.144e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5999, Training Loss: 8.143e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6000, Training Loss: 8.142e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6001, Training Loss: 8.141e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6002, Training Loss: 8.139e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6003, Training Loss: 8.138e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6004, Training Loss: 8.137e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6005, Training Loss: 8.136e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6006, Training Loss: 8.135e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6007, Training Loss: 8.134e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6008, Training Loss: 8.133e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6009, Training Loss: 8.131e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6010, Training Loss: 8.130e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6011, Training Loss: 8.129e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6012, Training Loss: 8.128e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6013, Training Loss: 8.127e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6014, Training Loss: 8.126e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6015, Training Loss: 8.125e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6016, Training Loss: 8.123e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6017, Training Loss: 8.122e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6018, Training Loss: 8.121e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6019, Training Loss: 8.120e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6020, Training Loss: 8.119e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6021, Training Loss: 8.118e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6022, Training Loss: 8.117e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6023, Training Loss: 8.115e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6024, Training Loss: 8.114e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6025, Training Loss: 8.113e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6026, Training Loss: 8.112e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6027, Training Loss: 8.111e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6028, Training Loss: 8.110e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6029, Training Loss: 8.109e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6030, Training Loss: 8.107e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6031, Training Loss: 8.106e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6032, Training Loss: 8.105e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6033, Training Loss: 8.104e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6034, Training Loss: 8.103e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6035, Training Loss: 8.102e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6036, Training Loss: 8.101e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6037, Training Loss: 8.099e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6038, Training Loss: 8.098e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6039, Training Loss: 8.097e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6040, Training Loss: 8.096e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6041, Training Loss: 8.095e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6042, Training Loss: 8.094e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6043, Training Loss: 8.093e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6044, Training Loss: 8.092e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6045, Training Loss: 8.090e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6046, Training Loss: 8.089e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6047, Training Loss: 8.088e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6048, Training Loss: 8.087e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6049, Training Loss: 8.086e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6050, Training Loss: 8.085e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6051, Training Loss: 8.084e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6052, Training Loss: 8.082e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6053, Training Loss: 8.081e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6054, Training Loss: 8.080e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6055, Training Loss: 8.079e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6056, Training Loss: 8.078e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6057, Training Loss: 8.077e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6058, Training Loss: 8.076e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6059, Training Loss: 8.075e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6060, Training Loss: 8.073e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6061, Training Loss: 8.072e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6062, Training Loss: 8.071e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6063, Training Loss: 8.070e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6064, Training Loss: 8.069e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6065, Training Loss: 8.068e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6066, Training Loss: 8.067e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6067, Training Loss: 8.066e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6068, Training Loss: 8.064e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6069, Training Loss: 8.063e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6070, Training Loss: 8.062e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6071, Training Loss: 8.061e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6072, Training Loss: 8.060e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6073, Training Loss: 8.059e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6074, Training Loss: 8.058e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6075, Training Loss: 8.057e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6076, Training Loss: 8.055e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6077, Training Loss: 8.054e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6078, Training Loss: 8.053e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6079, Training Loss: 8.052e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6080, Training Loss: 8.051e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6081, Training Loss: 8.050e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6082, Training Loss: 8.049e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6083, Training Loss: 8.048e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6084, Training Loss: 8.046e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6085, Training Loss: 8.045e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6086, Training Loss: 8.044e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6087, Training Loss: 8.043e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6088, Training Loss: 8.042e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6089, Training Loss: 8.041e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6090, Training Loss: 8.040e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6091, Training Loss: 8.039e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6092, Training Loss: 8.038e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6093, Training Loss: 8.036e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6094, Training Loss: 8.035e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6095, Training Loss: 8.034e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6096, Training Loss: 8.033e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6097, Training Loss: 8.032e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6098, Training Loss: 8.031e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6099, Training Loss: 8.030e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6100, Training Loss: 8.029e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6101, Training Loss: 8.027e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6102, Training Loss: 8.026e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6103, Training Loss: 8.025e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6104, Training Loss: 8.024e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6105, Training Loss: 8.023e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6106, Training Loss: 8.022e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6107, Training Loss: 8.021e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6108, Training Loss: 8.020e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6109, Training Loss: 8.019e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6110, Training Loss: 8.017e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6111, Training Loss: 8.016e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6112, Training Loss: 8.015e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6113, Training Loss: 8.014e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6114, Training Loss: 8.013e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6115, Training Loss: 8.012e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6116, Training Loss: 8.011e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6117, Training Loss: 8.010e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6118, Training Loss: 8.009e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6119, Training Loss: 8.007e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6120, Training Loss: 8.006e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6121, Training Loss: 8.005e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6122, Training Loss: 8.004e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6123, Training Loss: 8.003e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6124, Training Loss: 8.002e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6125, Training Loss: 8.001e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6126, Training Loss: 8.000e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6127, Training Loss: 7.999e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6128, Training Loss: 7.997e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6129, Training Loss: 7.996e-01, Validation Loss: 9.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6130, Training Loss: 7.995e-01, Validation Loss: 9.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6131, Training Loss: 7.994e-01, Validation Loss: 9.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6132, Training Loss: 7.993e-01, Validation Loss: 9.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6133, Training Loss: 7.992e-01, Validation Loss: 9.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6134, Training Loss: 7.991e-01, Validation Loss: 9.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6135, Training Loss: 7.990e-01, Validation Loss: 9.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6136, Training Loss: 7.989e-01, Validation Loss: 9.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6137, Training Loss: 7.987e-01, Validation Loss: 9.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6138, Training Loss: 7.986e-01, Validation Loss: 9.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6139, Training Loss: 7.985e-01, Validation Loss: 9.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6140, Training Loss: 7.984e-01, Validation Loss: 9.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6141, Training Loss: 7.983e-01, Validation Loss: 9.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6142, Training Loss: 7.982e-01, Validation Loss: 9.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6143, Training Loss: 7.981e-01, Validation Loss: 9.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6144, Training Loss: 7.980e-01, Validation Loss: 9.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6145, Training Loss: 7.979e-01, Validation Loss: 9.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6146, Training Loss: 7.978e-01, Validation Loss: 9.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6147, Training Loss: 7.976e-01, Validation Loss: 9.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6148, Training Loss: 7.975e-01, Validation Loss: 9.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6149, Training Loss: 7.974e-01, Validation Loss: 9.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6150, Training Loss: 7.973e-01, Validation Loss: 9.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6151, Training Loss: 7.972e-01, Validation Loss: 9.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6152, Training Loss: 7.971e-01, Validation Loss: 9.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6153, Training Loss: 7.970e-01, Validation Loss: 9.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6154, Training Loss: 7.969e-01, Validation Loss: 9.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6155, Training Loss: 7.968e-01, Validation Loss: 9.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6156, Training Loss: 7.966e-01, Validation Loss: 9.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6157, Training Loss: 7.965e-01, Validation Loss: 9.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6158, Training Loss: 7.964e-01, Validation Loss: 9.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6159, Training Loss: 7.963e-01, Validation Loss: 9.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6160, Training Loss: 7.962e-01, Validation Loss: 9.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6161, Training Loss: 7.961e-01, Validation Loss: 9.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6162, Training Loss: 7.960e-01, Validation Loss: 9.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6163, Training Loss: 7.959e-01, Validation Loss: 9.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6164, Training Loss: 7.958e-01, Validation Loss: 9.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6165, Training Loss: 7.957e-01, Validation Loss: 9.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6166, Training Loss: 7.955e-01, Validation Loss: 9.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6167, Training Loss: 7.954e-01, Validation Loss: 9.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6168, Training Loss: 7.953e-01, Validation Loss: 9.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6169, Training Loss: 7.952e-01, Validation Loss: 9.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6170, Training Loss: 7.951e-01, Validation Loss: 9.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6171, Training Loss: 7.950e-01, Validation Loss: 9.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6172, Training Loss: 7.949e-01, Validation Loss: 9.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6173, Training Loss: 7.948e-01, Validation Loss: 9.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6174, Training Loss: 7.947e-01, Validation Loss: 9.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6175, Training Loss: 7.946e-01, Validation Loss: 9.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6176, Training Loss: 7.944e-01, Validation Loss: 9.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6177, Training Loss: 7.943e-01, Validation Loss: 9.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6178, Training Loss: 7.942e-01, Validation Loss: 9.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6179, Training Loss: 7.941e-01, Validation Loss: 9.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6180, Training Loss: 7.940e-01, Validation Loss: 9.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6181, Training Loss: 7.939e-01, Validation Loss: 9.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6182, Training Loss: 7.938e-01, Validation Loss: 9.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6183, Training Loss: 7.937e-01, Validation Loss: 9.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6184, Training Loss: 7.936e-01, Validation Loss: 9.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6185, Training Loss: 7.935e-01, Validation Loss: 9.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6186, Training Loss: 7.933e-01, Validation Loss: 9.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6187, Training Loss: 7.932e-01, Validation Loss: 9.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6188, Training Loss: 7.931e-01, Validation Loss: 9.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6189, Training Loss: 7.930e-01, Validation Loss: 9.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6190, Training Loss: 7.929e-01, Validation Loss: 9.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6191, Training Loss: 7.928e-01, Validation Loss: 9.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6192, Training Loss: 7.927e-01, Validation Loss: 9.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6193, Training Loss: 7.926e-01, Validation Loss: 9.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6194, Training Loss: 7.925e-01, Validation Loss: 9.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6195, Training Loss: 7.924e-01, Validation Loss: 9.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6196, Training Loss: 7.923e-01, Validation Loss: 9.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6197, Training Loss: 7.921e-01, Validation Loss: 9.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6198, Training Loss: 7.920e-01, Validation Loss: 9.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6199, Training Loss: 7.919e-01, Validation Loss: 9.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6200, Training Loss: 7.918e-01, Validation Loss: 9.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6201, Training Loss: 7.917e-01, Validation Loss: 9.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6202, Training Loss: 7.916e-01, Validation Loss: 9.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6203, Training Loss: 7.915e-01, Validation Loss: 9.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6204, Training Loss: 7.914e-01, Validation Loss: 9.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6205, Training Loss: 7.913e-01, Validation Loss: 9.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6206, Training Loss: 7.912e-01, Validation Loss: 9.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6207, Training Loss: 7.911e-01, Validation Loss: 9.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6208, Training Loss: 7.909e-01, Validation Loss: 9.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6209, Training Loss: 7.908e-01, Validation Loss: 9.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6210, Training Loss: 7.907e-01, Validation Loss: 9.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6211, Training Loss: 7.906e-01, Validation Loss: 9.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6212, Training Loss: 7.905e-01, Validation Loss: 9.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6213, Training Loss: 7.904e-01, Validation Loss: 9.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6214, Training Loss: 7.903e-01, Validation Loss: 9.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6215, Training Loss: 7.902e-01, Validation Loss: 9.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6216, Training Loss: 7.901e-01, Validation Loss: 9.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6217, Training Loss: 7.900e-01, Validation Loss: 9.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6218, Training Loss: 7.899e-01, Validation Loss: 9.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6219, Training Loss: 7.897e-01, Validation Loss: 9.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6220, Training Loss: 7.896e-01, Validation Loss: 9.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6221, Training Loss: 7.895e-01, Validation Loss: 9.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6222, Training Loss: 7.894e-01, Validation Loss: 9.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6223, Training Loss: 7.893e-01, Validation Loss: 9.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6224, Training Loss: 7.892e-01, Validation Loss: 9.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6225, Training Loss: 7.891e-01, Validation Loss: 9.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6226, Training Loss: 7.890e-01, Validation Loss: 9.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6227, Training Loss: 7.889e-01, Validation Loss: 9.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6228, Training Loss: 7.888e-01, Validation Loss: 9.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6229, Training Loss: 7.887e-01, Validation Loss: 9.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6230, Training Loss: 7.886e-01, Validation Loss: 9.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6231, Training Loss: 7.884e-01, Validation Loss: 9.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6232, Training Loss: 7.883e-01, Validation Loss: 9.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6233, Training Loss: 7.882e-01, Validation Loss: 9.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6234, Training Loss: 7.881e-01, Validation Loss: 9.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6235, Training Loss: 7.880e-01, Validation Loss: 9.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6236, Training Loss: 7.879e-01, Validation Loss: 9.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6237, Training Loss: 7.878e-01, Validation Loss: 9.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6238, Training Loss: 7.877e-01, Validation Loss: 9.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6239, Training Loss: 7.876e-01, Validation Loss: 9.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6240, Training Loss: 7.875e-01, Validation Loss: 9.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6241, Training Loss: 7.874e-01, Validation Loss: 9.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6242, Training Loss: 7.873e-01, Validation Loss: 9.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6243, Training Loss: 7.872e-01, Validation Loss: 9.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6244, Training Loss: 7.870e-01, Validation Loss: 9.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6245, Training Loss: 7.869e-01, Validation Loss: 9.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6246, Training Loss: 7.868e-01, Validation Loss: 9.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6247, Training Loss: 7.867e-01, Validation Loss: 9.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6248, Training Loss: 7.866e-01, Validation Loss: 9.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6249, Training Loss: 7.865e-01, Validation Loss: 9.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6250, Training Loss: 7.864e-01, Validation Loss: 9.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6251, Training Loss: 7.863e-01, Validation Loss: 9.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6252, Training Loss: 7.862e-01, Validation Loss: 9.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6253, Training Loss: 7.861e-01, Validation Loss: 9.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6254, Training Loss: 7.860e-01, Validation Loss: 9.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6255, Training Loss: 7.859e-01, Validation Loss: 9.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6256, Training Loss: 7.858e-01, Validation Loss: 9.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6257, Training Loss: 7.856e-01, Validation Loss: 9.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6258, Training Loss: 7.855e-01, Validation Loss: 9.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6259, Training Loss: 7.854e-01, Validation Loss: 9.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6260, Training Loss: 7.853e-01, Validation Loss: 9.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6261, Training Loss: 7.852e-01, Validation Loss: 9.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6262, Training Loss: 7.851e-01, Validation Loss: 9.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6263, Training Loss: 7.850e-01, Validation Loss: 9.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6264, Training Loss: 7.849e-01, Validation Loss: 9.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6265, Training Loss: 7.848e-01, Validation Loss: 9.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6266, Training Loss: 7.847e-01, Validation Loss: 9.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6267, Training Loss: 7.846e-01, Validation Loss: 9.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6268, Training Loss: 7.845e-01, Validation Loss: 9.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6269, Training Loss: 7.844e-01, Validation Loss: 9.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6270, Training Loss: 7.842e-01, Validation Loss: 9.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6271, Training Loss: 7.841e-01, Validation Loss: 9.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6272, Training Loss: 7.840e-01, Validation Loss: 9.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6273, Training Loss: 7.839e-01, Validation Loss: 9.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6274, Training Loss: 7.838e-01, Validation Loss: 9.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6275, Training Loss: 7.837e-01, Validation Loss: 9.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6276, Training Loss: 7.836e-01, Validation Loss: 9.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6277, Training Loss: 7.835e-01, Validation Loss: 9.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6278, Training Loss: 7.834e-01, Validation Loss: 9.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6279, Training Loss: 7.833e-01, Validation Loss: 9.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6280, Training Loss: 7.832e-01, Validation Loss: 9.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6281, Training Loss: 7.831e-01, Validation Loss: 9.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6282, Training Loss: 7.830e-01, Validation Loss: 9.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6283, Training Loss: 7.829e-01, Validation Loss: 9.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6284, Training Loss: 7.828e-01, Validation Loss: 9.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6285, Training Loss: 7.826e-01, Validation Loss: 9.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6286, Training Loss: 7.825e-01, Validation Loss: 9.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6287, Training Loss: 7.824e-01, Validation Loss: 9.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6288, Training Loss: 7.823e-01, Validation Loss: 9.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6289, Training Loss: 7.822e-01, Validation Loss: 9.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6290, Training Loss: 7.821e-01, Validation Loss: 9.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6291, Training Loss: 7.820e-01, Validation Loss: 9.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6292, Training Loss: 7.819e-01, Validation Loss: 9.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6293, Training Loss: 7.818e-01, Validation Loss: 9.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6294, Training Loss: 7.817e-01, Validation Loss: 9.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6295, Training Loss: 7.816e-01, Validation Loss: 9.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6296, Training Loss: 7.815e-01, Validation Loss: 9.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6297, Training Loss: 7.814e-01, Validation Loss: 9.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6298, Training Loss: 7.813e-01, Validation Loss: 9.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6299, Training Loss: 7.812e-01, Validation Loss: 9.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6300, Training Loss: 7.811e-01, Validation Loss: 9.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6301, Training Loss: 7.809e-01, Validation Loss: 9.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6302, Training Loss: 7.808e-01, Validation Loss: 9.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6303, Training Loss: 7.807e-01, Validation Loss: 9.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6304, Training Loss: 7.806e-01, Validation Loss: 9.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6305, Training Loss: 7.805e-01, Validation Loss: 9.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6306, Training Loss: 7.804e-01, Validation Loss: 9.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6307, Training Loss: 7.803e-01, Validation Loss: 9.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6308, Training Loss: 7.802e-01, Validation Loss: 9.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6309, Training Loss: 7.801e-01, Validation Loss: 9.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6310, Training Loss: 7.800e-01, Validation Loss: 9.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6311, Training Loss: 7.799e-01, Validation Loss: 9.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6312, Training Loss: 7.798e-01, Validation Loss: 9.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6313, Training Loss: 7.797e-01, Validation Loss: 9.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6314, Training Loss: 7.796e-01, Validation Loss: 9.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6315, Training Loss: 7.795e-01, Validation Loss: 9.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6316, Training Loss: 7.794e-01, Validation Loss: 9.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6317, Training Loss: 7.792e-01, Validation Loss: 9.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6318, Training Loss: 7.791e-01, Validation Loss: 9.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6319, Training Loss: 7.790e-01, Validation Loss: 9.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6320, Training Loss: 7.789e-01, Validation Loss: 9.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6321, Training Loss: 7.788e-01, Validation Loss: 9.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6322, Training Loss: 7.787e-01, Validation Loss: 9.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6323, Training Loss: 7.786e-01, Validation Loss: 9.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6324, Training Loss: 7.785e-01, Validation Loss: 9.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6325, Training Loss: 7.784e-01, Validation Loss: 9.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6326, Training Loss: 7.783e-01, Validation Loss: 9.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6327, Training Loss: 7.782e-01, Validation Loss: 9.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6328, Training Loss: 7.781e-01, Validation Loss: 9.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6329, Training Loss: 7.780e-01, Validation Loss: 9.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6330, Training Loss: 7.779e-01, Validation Loss: 9.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6331, Training Loss: 7.778e-01, Validation Loss: 9.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6332, Training Loss: 7.777e-01, Validation Loss: 9.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6333, Training Loss: 7.776e-01, Validation Loss: 9.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6334, Training Loss: 7.775e-01, Validation Loss: 9.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6335, Training Loss: 7.773e-01, Validation Loss: 9.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6336, Training Loss: 7.772e-01, Validation Loss: 9.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6337, Training Loss: 7.771e-01, Validation Loss: 9.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6338, Training Loss: 7.770e-01, Validation Loss: 9.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6339, Training Loss: 7.769e-01, Validation Loss: 9.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6340, Training Loss: 7.768e-01, Validation Loss: 9.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6341, Training Loss: 7.767e-01, Validation Loss: 9.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6342, Training Loss: 7.766e-01, Validation Loss: 9.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6343, Training Loss: 7.765e-01, Validation Loss: 9.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6344, Training Loss: 7.764e-01, Validation Loss: 9.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6345, Training Loss: 7.763e-01, Validation Loss: 9.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6346, Training Loss: 7.762e-01, Validation Loss: 9.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6347, Training Loss: 7.761e-01, Validation Loss: 9.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6348, Training Loss: 7.760e-01, Validation Loss: 9.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6349, Training Loss: 7.759e-01, Validation Loss: 9.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6350, Training Loss: 7.758e-01, Validation Loss: 9.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6351, Training Loss: 7.757e-01, Validation Loss: 9.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6352, Training Loss: 7.756e-01, Validation Loss: 9.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6353, Training Loss: 7.755e-01, Validation Loss: 9.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6354, Training Loss: 7.754e-01, Validation Loss: 9.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6355, Training Loss: 7.752e-01, Validation Loss: 9.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6356, Training Loss: 7.751e-01, Validation Loss: 9.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6357, Training Loss: 7.750e-01, Validation Loss: 9.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6358, Training Loss: 7.749e-01, Validation Loss: 9.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6359, Training Loss: 7.748e-01, Validation Loss: 9.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6360, Training Loss: 7.747e-01, Validation Loss: 9.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6361, Training Loss: 7.746e-01, Validation Loss: 9.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6362, Training Loss: 7.745e-01, Validation Loss: 9.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6363, Training Loss: 7.744e-01, Validation Loss: 9.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6364, Training Loss: 7.743e-01, Validation Loss: 9.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6365, Training Loss: 7.742e-01, Validation Loss: 9.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6366, Training Loss: 7.741e-01, Validation Loss: 9.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6367, Training Loss: 7.740e-01, Validation Loss: 9.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6368, Training Loss: 7.739e-01, Validation Loss: 9.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6369, Training Loss: 7.738e-01, Validation Loss: 9.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6370, Training Loss: 7.737e-01, Validation Loss: 9.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6371, Training Loss: 7.736e-01, Validation Loss: 9.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6372, Training Loss: 7.735e-01, Validation Loss: 9.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6373, Training Loss: 7.734e-01, Validation Loss: 9.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6374, Training Loss: 7.733e-01, Validation Loss: 9.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6375, Training Loss: 7.732e-01, Validation Loss: 9.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6376, Training Loss: 7.731e-01, Validation Loss: 9.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6377, Training Loss: 7.730e-01, Validation Loss: 9.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6378, Training Loss: 7.728e-01, Validation Loss: 9.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6379, Training Loss: 7.727e-01, Validation Loss: 9.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6380, Training Loss: 7.726e-01, Validation Loss: 9.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6381, Training Loss: 7.725e-01, Validation Loss: 9.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6382, Training Loss: 7.724e-01, Validation Loss: 9.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6383, Training Loss: 7.723e-01, Validation Loss: 9.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6384, Training Loss: 7.722e-01, Validation Loss: 9.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6385, Training Loss: 7.721e-01, Validation Loss: 9.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6386, Training Loss: 7.720e-01, Validation Loss: 9.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6387, Training Loss: 7.719e-01, Validation Loss: 9.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6388, Training Loss: 7.718e-01, Validation Loss: 9.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6389, Training Loss: 7.717e-01, Validation Loss: 9.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6390, Training Loss: 7.716e-01, Validation Loss: 9.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6391, Training Loss: 7.715e-01, Validation Loss: 9.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6392, Training Loss: 7.714e-01, Validation Loss: 9.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6393, Training Loss: 7.713e-01, Validation Loss: 9.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6394, Training Loss: 7.712e-01, Validation Loss: 9.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6395, Training Loss: 7.711e-01, Validation Loss: 9.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6396, Training Loss: 7.710e-01, Validation Loss: 9.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6397, Training Loss: 7.709e-01, Validation Loss: 9.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6398, Training Loss: 7.708e-01, Validation Loss: 9.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6399, Training Loss: 7.707e-01, Validation Loss: 9.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6400, Training Loss: 7.706e-01, Validation Loss: 9.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6401, Training Loss: 7.705e-01, Validation Loss: 9.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6402, Training Loss: 7.704e-01, Validation Loss: 9.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6403, Training Loss: 7.703e-01, Validation Loss: 9.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6404, Training Loss: 7.701e-01, Validation Loss: 9.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6405, Training Loss: 7.700e-01, Validation Loss: 9.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6406, Training Loss: 7.699e-01, Validation Loss: 9.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6407, Training Loss: 7.698e-01, Validation Loss: 9.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6408, Training Loss: 7.697e-01, Validation Loss: 9.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6409, Training Loss: 7.696e-01, Validation Loss: 9.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6410, Training Loss: 7.695e-01, Validation Loss: 9.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6411, Training Loss: 7.694e-01, Validation Loss: 9.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6412, Training Loss: 7.693e-01, Validation Loss: 9.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6413, Training Loss: 7.692e-01, Validation Loss: 9.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6414, Training Loss: 7.691e-01, Validation Loss: 9.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6415, Training Loss: 7.690e-01, Validation Loss: 9.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6416, Training Loss: 7.689e-01, Validation Loss: 9.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6417, Training Loss: 7.688e-01, Validation Loss: 9.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6418, Training Loss: 7.687e-01, Validation Loss: 9.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6419, Training Loss: 7.686e-01, Validation Loss: 9.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6420, Training Loss: 7.685e-01, Validation Loss: 9.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6421, Training Loss: 7.684e-01, Validation Loss: 9.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6422, Training Loss: 7.683e-01, Validation Loss: 9.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6423, Training Loss: 7.682e-01, Validation Loss: 9.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6424, Training Loss: 7.681e-01, Validation Loss: 9.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6425, Training Loss: 7.680e-01, Validation Loss: 9.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6426, Training Loss: 7.679e-01, Validation Loss: 9.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6427, Training Loss: 7.678e-01, Validation Loss: 9.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6428, Training Loss: 7.677e-01, Validation Loss: 9.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6429, Training Loss: 7.676e-01, Validation Loss: 9.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6430, Training Loss: 7.675e-01, Validation Loss: 9.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6431, Training Loss: 7.674e-01, Validation Loss: 9.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6432, Training Loss: 7.673e-01, Validation Loss: 9.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6433, Training Loss: 7.672e-01, Validation Loss: 9.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6434, Training Loss: 7.671e-01, Validation Loss: 9.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6435, Training Loss: 7.670e-01, Validation Loss: 9.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6436, Training Loss: 7.668e-01, Validation Loss: 9.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6437, Training Loss: 7.667e-01, Validation Loss: 9.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6438, Training Loss: 7.666e-01, Validation Loss: 9.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6439, Training Loss: 7.665e-01, Validation Loss: 9.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6440, Training Loss: 7.664e-01, Validation Loss: 9.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6441, Training Loss: 7.663e-01, Validation Loss: 9.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6442, Training Loss: 7.662e-01, Validation Loss: 9.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6443, Training Loss: 7.661e-01, Validation Loss: 9.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6444, Training Loss: 7.660e-01, Validation Loss: 9.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6445, Training Loss: 7.659e-01, Validation Loss: 9.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6446, Training Loss: 7.658e-01, Validation Loss: 9.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6447, Training Loss: 7.657e-01, Validation Loss: 9.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6448, Training Loss: 7.656e-01, Validation Loss: 9.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6449, Training Loss: 7.655e-01, Validation Loss: 9.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6450, Training Loss: 7.654e-01, Validation Loss: 9.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6451, Training Loss: 7.653e-01, Validation Loss: 9.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6452, Training Loss: 7.652e-01, Validation Loss: 9.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6453, Training Loss: 7.651e-01, Validation Loss: 9.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6454, Training Loss: 7.650e-01, Validation Loss: 9.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6455, Training Loss: 7.649e-01, Validation Loss: 9.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6456, Training Loss: 7.648e-01, Validation Loss: 9.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6457, Training Loss: 7.647e-01, Validation Loss: 9.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6458, Training Loss: 7.646e-01, Validation Loss: 9.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6459, Training Loss: 7.645e-01, Validation Loss: 9.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6460, Training Loss: 7.644e-01, Validation Loss: 9.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6461, Training Loss: 7.643e-01, Validation Loss: 9.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6462, Training Loss: 7.642e-01, Validation Loss: 9.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6463, Training Loss: 7.641e-01, Validation Loss: 9.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6464, Training Loss: 7.640e-01, Validation Loss: 9.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6465, Training Loss: 7.639e-01, Validation Loss: 9.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6466, Training Loss: 7.638e-01, Validation Loss: 9.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6467, Training Loss: 7.637e-01, Validation Loss: 9.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6468, Training Loss: 7.636e-01, Validation Loss: 9.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6469, Training Loss: 7.635e-01, Validation Loss: 9.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6470, Training Loss: 7.634e-01, Validation Loss: 9.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6471, Training Loss: 7.633e-01, Validation Loss: 9.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6472, Training Loss: 7.632e-01, Validation Loss: 9.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6473, Training Loss: 7.631e-01, Validation Loss: 9.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6474, Training Loss: 7.630e-01, Validation Loss: 9.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6475, Training Loss: 7.629e-01, Validation Loss: 9.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6476, Training Loss: 7.628e-01, Validation Loss: 9.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6477, Training Loss: 7.627e-01, Validation Loss: 9.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6478, Training Loss: 7.626e-01, Validation Loss: 9.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6479, Training Loss: 7.625e-01, Validation Loss: 9.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6480, Training Loss: 7.624e-01, Validation Loss: 9.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6481, Training Loss: 7.623e-01, Validation Loss: 9.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6482, Training Loss: 7.621e-01, Validation Loss: 9.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6483, Training Loss: 7.620e-01, Validation Loss: 9.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6484, Training Loss: 7.619e-01, Validation Loss: 9.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6485, Training Loss: 7.618e-01, Validation Loss: 9.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6486, Training Loss: 7.617e-01, Validation Loss: 9.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6487, Training Loss: 7.616e-01, Validation Loss: 9.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6488, Training Loss: 7.615e-01, Validation Loss: 9.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6489, Training Loss: 7.614e-01, Validation Loss: 9.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6490, Training Loss: 7.613e-01, Validation Loss: 9.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6491, Training Loss: 7.612e-01, Validation Loss: 9.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6492, Training Loss: 7.611e-01, Validation Loss: 9.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6493, Training Loss: 7.610e-01, Validation Loss: 9.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6494, Training Loss: 7.609e-01, Validation Loss: 9.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6495, Training Loss: 7.608e-01, Validation Loss: 9.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6496, Training Loss: 7.607e-01, Validation Loss: 9.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6497, Training Loss: 7.606e-01, Validation Loss: 9.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6498, Training Loss: 7.605e-01, Validation Loss: 9.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6499, Training Loss: 7.604e-01, Validation Loss: 9.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6500, Training Loss: 7.603e-01, Validation Loss: 9.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6501, Training Loss: 7.602e-01, Validation Loss: 9.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6502, Training Loss: 7.601e-01, Validation Loss: 9.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6503, Training Loss: 7.600e-01, Validation Loss: 9.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6504, Training Loss: 7.599e-01, Validation Loss: 9.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6505, Training Loss: 7.598e-01, Validation Loss: 9.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6506, Training Loss: 7.597e-01, Validation Loss: 9.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6507, Training Loss: 7.596e-01, Validation Loss: 9.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6508, Training Loss: 7.595e-01, Validation Loss: 9.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6509, Training Loss: 7.594e-01, Validation Loss: 9.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6510, Training Loss: 7.593e-01, Validation Loss: 9.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6511, Training Loss: 7.592e-01, Validation Loss: 9.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6512, Training Loss: 7.591e-01, Validation Loss: 9.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6513, Training Loss: 7.590e-01, Validation Loss: 9.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6514, Training Loss: 7.589e-01, Validation Loss: 9.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6515, Training Loss: 7.588e-01, Validation Loss: 9.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6516, Training Loss: 7.587e-01, Validation Loss: 9.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6517, Training Loss: 7.586e-01, Validation Loss: 9.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6518, Training Loss: 7.585e-01, Validation Loss: 9.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6519, Training Loss: 7.584e-01, Validation Loss: 9.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6520, Training Loss: 7.583e-01, Validation Loss: 9.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6521, Training Loss: 7.582e-01, Validation Loss: 9.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6522, Training Loss: 7.581e-01, Validation Loss: 9.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6523, Training Loss: 7.580e-01, Validation Loss: 9.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6524, Training Loss: 7.579e-01, Validation Loss: 9.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6525, Training Loss: 7.578e-01, Validation Loss: 9.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6526, Training Loss: 7.577e-01, Validation Loss: 9.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6527, Training Loss: 7.576e-01, Validation Loss: 9.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6528, Training Loss: 7.575e-01, Validation Loss: 9.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6529, Training Loss: 7.574e-01, Validation Loss: 9.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6530, Training Loss: 7.573e-01, Validation Loss: 9.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6531, Training Loss: 7.572e-01, Validation Loss: 9.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6532, Training Loss: 7.571e-01, Validation Loss: 9.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6533, Training Loss: 7.570e-01, Validation Loss: 9.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6534, Training Loss: 7.569e-01, Validation Loss: 9.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6535, Training Loss: 7.568e-01, Validation Loss: 9.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6536, Training Loss: 7.567e-01, Validation Loss: 9.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6537, Training Loss: 7.566e-01, Validation Loss: 9.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6538, Training Loss: 7.565e-01, Validation Loss: 9.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6539, Training Loss: 7.564e-01, Validation Loss: 9.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6540, Training Loss: 7.563e-01, Validation Loss: 9.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6541, Training Loss: 7.562e-01, Validation Loss: 9.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6542, Training Loss: 7.561e-01, Validation Loss: 9.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6543, Training Loss: 7.560e-01, Validation Loss: 9.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6544, Training Loss: 7.559e-01, Validation Loss: 9.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6545, Training Loss: 7.558e-01, Validation Loss: 9.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6546, Training Loss: 7.557e-01, Validation Loss: 9.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6547, Training Loss: 7.556e-01, Validation Loss: 9.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6548, Training Loss: 7.555e-01, Validation Loss: 9.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6549, Training Loss: 7.554e-01, Validation Loss: 9.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6550, Training Loss: 7.553e-01, Validation Loss: 9.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6551, Training Loss: 7.552e-01, Validation Loss: 9.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6552, Training Loss: 7.551e-01, Validation Loss: 9.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6553, Training Loss: 7.550e-01, Validation Loss: 9.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6554, Training Loss: 7.549e-01, Validation Loss: 9.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6555, Training Loss: 7.548e-01, Validation Loss: 9.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6556, Training Loss: 7.547e-01, Validation Loss: 9.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6557, Training Loss: 7.546e-01, Validation Loss: 9.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6558, Training Loss: 7.545e-01, Validation Loss: 9.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6559, Training Loss: 7.544e-01, Validation Loss: 9.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6560, Training Loss: 7.543e-01, Validation Loss: 9.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6561, Training Loss: 7.542e-01, Validation Loss: 9.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6562, Training Loss: 7.541e-01, Validation Loss: 9.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6563, Training Loss: 7.540e-01, Validation Loss: 9.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6564, Training Loss: 7.539e-01, Validation Loss: 9.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6565, Training Loss: 7.538e-01, Validation Loss: 9.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6566, Training Loss: 7.537e-01, Validation Loss: 9.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6567, Training Loss: 7.536e-01, Validation Loss: 9.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6568, Training Loss: 7.535e-01, Validation Loss: 9.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6569, Training Loss: 7.534e-01, Validation Loss: 9.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6570, Training Loss: 7.533e-01, Validation Loss: 9.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6571, Training Loss: 7.532e-01, Validation Loss: 9.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6572, Training Loss: 7.531e-01, Validation Loss: 9.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6573, Training Loss: 7.530e-01, Validation Loss: 9.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6574, Training Loss: 7.529e-01, Validation Loss: 9.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6575, Training Loss: 7.528e-01, Validation Loss: 9.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6576, Training Loss: 7.527e-01, Validation Loss: 9.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6577, Training Loss: 7.526e-01, Validation Loss: 9.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6578, Training Loss: 7.525e-01, Validation Loss: 9.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6579, Training Loss: 7.524e-01, Validation Loss: 9.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6580, Training Loss: 7.523e-01, Validation Loss: 9.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6581, Training Loss: 7.522e-01, Validation Loss: 9.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6582, Training Loss: 7.521e-01, Validation Loss: 9.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6583, Training Loss: 7.520e-01, Validation Loss: 9.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6584, Training Loss: 7.519e-01, Validation Loss: 9.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6585, Training Loss: 7.518e-01, Validation Loss: 9.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6586, Training Loss: 7.517e-01, Validation Loss: 9.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6587, Training Loss: 7.516e-01, Validation Loss: 9.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6588, Training Loss: 7.515e-01, Validation Loss: 9.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6589, Training Loss: 7.514e-01, Validation Loss: 9.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6590, Training Loss: 7.513e-01, Validation Loss: 9.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6591, Training Loss: 7.512e-01, Validation Loss: 9.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6592, Training Loss: 7.511e-01, Validation Loss: 9.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6593, Training Loss: 7.510e-01, Validation Loss: 9.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6594, Training Loss: 7.509e-01, Validation Loss: 9.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6595, Training Loss: 7.508e-01, Validation Loss: 9.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6596, Training Loss: 7.507e-01, Validation Loss: 9.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6597, Training Loss: 7.506e-01, Validation Loss: 9.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6598, Training Loss: 7.505e-01, Validation Loss: 9.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6599, Training Loss: 7.504e-01, Validation Loss: 9.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6600, Training Loss: 7.503e-01, Validation Loss: 9.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6601, Training Loss: 7.502e-01, Validation Loss: 9.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6602, Training Loss: 7.501e-01, Validation Loss: 9.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6603, Training Loss: 7.500e-01, Validation Loss: 9.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6604, Training Loss: 7.499e-01, Validation Loss: 9.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6605, Training Loss: 7.498e-01, Validation Loss: 9.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6606, Training Loss: 7.497e-01, Validation Loss: 9.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6607, Training Loss: 7.496e-01, Validation Loss: 9.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6608, Training Loss: 7.495e-01, Validation Loss: 9.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6609, Training Loss: 7.494e-01, Validation Loss: 9.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6610, Training Loss: 7.493e-01, Validation Loss: 9.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6611, Training Loss: 7.492e-01, Validation Loss: 9.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6612, Training Loss: 7.491e-01, Validation Loss: 9.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6613, Training Loss: 7.491e-01, Validation Loss: 9.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6614, Training Loss: 7.490e-01, Validation Loss: 9.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6615, Training Loss: 7.489e-01, Validation Loss: 9.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6616, Training Loss: 7.488e-01, Validation Loss: 9.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6617, Training Loss: 7.487e-01, Validation Loss: 9.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6618, Training Loss: 7.486e-01, Validation Loss: 9.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6619, Training Loss: 7.485e-01, Validation Loss: 9.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6620, Training Loss: 7.484e-01, Validation Loss: 9.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6621, Training Loss: 7.483e-01, Validation Loss: 9.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6622, Training Loss: 7.482e-01, Validation Loss: 9.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6623, Training Loss: 7.481e-01, Validation Loss: 9.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6624, Training Loss: 7.480e-01, Validation Loss: 9.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6625, Training Loss: 7.479e-01, Validation Loss: 9.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6626, Training Loss: 7.478e-01, Validation Loss: 9.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6627, Training Loss: 7.477e-01, Validation Loss: 9.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6628, Training Loss: 7.476e-01, Validation Loss: 9.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6629, Training Loss: 7.475e-01, Validation Loss: 9.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6630, Training Loss: 7.474e-01, Validation Loss: 9.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6631, Training Loss: 7.473e-01, Validation Loss: 9.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6632, Training Loss: 7.472e-01, Validation Loss: 9.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6633, Training Loss: 7.471e-01, Validation Loss: 9.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6634, Training Loss: 7.470e-01, Validation Loss: 9.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6635, Training Loss: 7.469e-01, Validation Loss: 9.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6636, Training Loss: 7.468e-01, Validation Loss: 9.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6637, Training Loss: 7.467e-01, Validation Loss: 9.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6638, Training Loss: 7.466e-01, Validation Loss: 9.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6639, Training Loss: 7.465e-01, Validation Loss: 9.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6640, Training Loss: 7.464e-01, Validation Loss: 9.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6641, Training Loss: 7.463e-01, Validation Loss: 9.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6642, Training Loss: 7.462e-01, Validation Loss: 9.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6643, Training Loss: 7.461e-01, Validation Loss: 9.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6644, Training Loss: 7.460e-01, Validation Loss: 9.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6645, Training Loss: 7.459e-01, Validation Loss: 9.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6646, Training Loss: 7.458e-01, Validation Loss: 9.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6647, Training Loss: 7.457e-01, Validation Loss: 9.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6648, Training Loss: 7.456e-01, Validation Loss: 9.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6649, Training Loss: 7.455e-01, Validation Loss: 9.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6650, Training Loss: 7.454e-01, Validation Loss: 9.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6651, Training Loss: 7.453e-01, Validation Loss: 9.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6652, Training Loss: 7.452e-01, Validation Loss: 9.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6653, Training Loss: 7.451e-01, Validation Loss: 9.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6654, Training Loss: 7.450e-01, Validation Loss: 9.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6655, Training Loss: 7.449e-01, Validation Loss: 9.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6656, Training Loss: 7.448e-01, Validation Loss: 9.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6657, Training Loss: 7.447e-01, Validation Loss: 9.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6658, Training Loss: 7.446e-01, Validation Loss: 9.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6659, Training Loss: 7.445e-01, Validation Loss: 9.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6660, Training Loss: 7.445e-01, Validation Loss: 9.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6661, Training Loss: 7.444e-01, Validation Loss: 9.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6662, Training Loss: 7.443e-01, Validation Loss: 9.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6663, Training Loss: 7.442e-01, Validation Loss: 9.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6664, Training Loss: 7.441e-01, Validation Loss: 9.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6665, Training Loss: 7.440e-01, Validation Loss: 9.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6666, Training Loss: 7.439e-01, Validation Loss: 9.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6667, Training Loss: 7.438e-01, Validation Loss: 9.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6668, Training Loss: 7.437e-01, Validation Loss: 9.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6669, Training Loss: 7.436e-01, Validation Loss: 9.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6670, Training Loss: 7.435e-01, Validation Loss: 9.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6671, Training Loss: 7.434e-01, Validation Loss: 9.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6672, Training Loss: 7.433e-01, Validation Loss: 9.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6673, Training Loss: 7.432e-01, Validation Loss: 9.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6674, Training Loss: 7.431e-01, Validation Loss: 9.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6675, Training Loss: 7.430e-01, Validation Loss: 9.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6676, Training Loss: 7.429e-01, Validation Loss: 9.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6677, Training Loss: 7.428e-01, Validation Loss: 9.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6678, Training Loss: 7.427e-01, Validation Loss: 9.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6679, Training Loss: 7.426e-01, Validation Loss: 9.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6680, Training Loss: 7.425e-01, Validation Loss: 9.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6681, Training Loss: 7.424e-01, Validation Loss: 9.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6682, Training Loss: 7.423e-01, Validation Loss: 9.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6683, Training Loss: 7.422e-01, Validation Loss: 9.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6684, Training Loss: 7.421e-01, Validation Loss: 9.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6685, Training Loss: 7.420e-01, Validation Loss: 9.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6686, Training Loss: 7.419e-01, Validation Loss: 9.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6687, Training Loss: 7.418e-01, Validation Loss: 9.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6688, Training Loss: 7.417e-01, Validation Loss: 9.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6689, Training Loss: 7.416e-01, Validation Loss: 9.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6690, Training Loss: 7.415e-01, Validation Loss: 9.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6691, Training Loss: 7.414e-01, Validation Loss: 9.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6692, Training Loss: 7.414e-01, Validation Loss: 9.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6693, Training Loss: 7.413e-01, Validation Loss: 9.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6694, Training Loss: 7.412e-01, Validation Loss: 9.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6695, Training Loss: 7.411e-01, Validation Loss: 9.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6696, Training Loss: 7.410e-01, Validation Loss: 9.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6697, Training Loss: 7.409e-01, Validation Loss: 9.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6698, Training Loss: 7.408e-01, Validation Loss: 9.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6699, Training Loss: 7.407e-01, Validation Loss: 9.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6700, Training Loss: 7.406e-01, Validation Loss: 9.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6701, Training Loss: 7.405e-01, Validation Loss: 9.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6702, Training Loss: 7.404e-01, Validation Loss: 9.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6703, Training Loss: 7.403e-01, Validation Loss: 9.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6704, Training Loss: 7.402e-01, Validation Loss: 9.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6705, Training Loss: 7.401e-01, Validation Loss: 9.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6706, Training Loss: 7.400e-01, Validation Loss: 9.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6707, Training Loss: 7.399e-01, Validation Loss: 9.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6708, Training Loss: 7.398e-01, Validation Loss: 9.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6709, Training Loss: 7.397e-01, Validation Loss: 9.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6710, Training Loss: 7.396e-01, Validation Loss: 9.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6711, Training Loss: 7.395e-01, Validation Loss: 9.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6712, Training Loss: 7.394e-01, Validation Loss: 9.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6713, Training Loss: 7.393e-01, Validation Loss: 9.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6714, Training Loss: 7.392e-01, Validation Loss: 9.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6715, Training Loss: 7.391e-01, Validation Loss: 9.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6716, Training Loss: 7.390e-01, Validation Loss: 9.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6717, Training Loss: 7.389e-01, Validation Loss: 9.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6718, Training Loss: 7.388e-01, Validation Loss: 9.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6719, Training Loss: 7.388e-01, Validation Loss: 9.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6720, Training Loss: 7.387e-01, Validation Loss: 9.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6721, Training Loss: 7.386e-01, Validation Loss: 9.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6722, Training Loss: 7.385e-01, Validation Loss: 9.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6723, Training Loss: 7.384e-01, Validation Loss: 9.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6724, Training Loss: 7.383e-01, Validation Loss: 9.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6725, Training Loss: 7.382e-01, Validation Loss: 9.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6726, Training Loss: 7.381e-01, Validation Loss: 9.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6727, Training Loss: 7.380e-01, Validation Loss: 9.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6728, Training Loss: 7.379e-01, Validation Loss: 9.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6729, Training Loss: 7.378e-01, Validation Loss: 9.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6730, Training Loss: 7.377e-01, Validation Loss: 9.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6731, Training Loss: 7.376e-01, Validation Loss: 9.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6732, Training Loss: 7.375e-01, Validation Loss: 9.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6733, Training Loss: 7.374e-01, Validation Loss: 9.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6734, Training Loss: 7.373e-01, Validation Loss: 9.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6735, Training Loss: 7.372e-01, Validation Loss: 9.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6736, Training Loss: 7.371e-01, Validation Loss: 9.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6737, Training Loss: 7.370e-01, Validation Loss: 9.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6738, Training Loss: 7.369e-01, Validation Loss: 9.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6739, Training Loss: 7.368e-01, Validation Loss: 9.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6740, Training Loss: 7.367e-01, Validation Loss: 9.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6741, Training Loss: 7.366e-01, Validation Loss: 9.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6742, Training Loss: 7.366e-01, Validation Loss: 9.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6743, Training Loss: 7.365e-01, Validation Loss: 9.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6744, Training Loss: 7.364e-01, Validation Loss: 9.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6745, Training Loss: 7.363e-01, Validation Loss: 9.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6746, Training Loss: 7.362e-01, Validation Loss: 9.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6747, Training Loss: 7.361e-01, Validation Loss: 9.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6748, Training Loss: 7.360e-01, Validation Loss: 9.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6749, Training Loss: 7.359e-01, Validation Loss: 9.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6750, Training Loss: 7.358e-01, Validation Loss: 9.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6751, Training Loss: 7.357e-01, Validation Loss: 9.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6752, Training Loss: 7.356e-01, Validation Loss: 9.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6753, Training Loss: 7.355e-01, Validation Loss: 9.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6754, Training Loss: 7.354e-01, Validation Loss: 9.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6755, Training Loss: 7.353e-01, Validation Loss: 9.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6756, Training Loss: 7.352e-01, Validation Loss: 9.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6757, Training Loss: 7.351e-01, Validation Loss: 9.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6758, Training Loss: 7.350e-01, Validation Loss: 9.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6759, Training Loss: 7.349e-01, Validation Loss: 9.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6760, Training Loss: 7.348e-01, Validation Loss: 9.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6761, Training Loss: 7.347e-01, Validation Loss: 9.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6762, Training Loss: 7.347e-01, Validation Loss: 9.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6763, Training Loss: 7.346e-01, Validation Loss: 9.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6764, Training Loss: 7.345e-01, Validation Loss: 9.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6765, Training Loss: 7.344e-01, Validation Loss: 9.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6766, Training Loss: 7.343e-01, Validation Loss: 9.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6767, Training Loss: 7.342e-01, Validation Loss: 9.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6768, Training Loss: 7.341e-01, Validation Loss: 9.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6769, Training Loss: 7.340e-01, Validation Loss: 9.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6770, Training Loss: 7.339e-01, Validation Loss: 9.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6771, Training Loss: 7.338e-01, Validation Loss: 9.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6772, Training Loss: 7.337e-01, Validation Loss: 9.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6773, Training Loss: 7.336e-01, Validation Loss: 9.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6774, Training Loss: 7.335e-01, Validation Loss: 9.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6775, Training Loss: 7.334e-01, Validation Loss: 9.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6776, Training Loss: 7.333e-01, Validation Loss: 9.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6777, Training Loss: 7.332e-01, Validation Loss: 9.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6778, Training Loss: 7.331e-01, Validation Loss: 9.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6779, Training Loss: 7.330e-01, Validation Loss: 9.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6780, Training Loss: 7.329e-01, Validation Loss: 9.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6781, Training Loss: 7.329e-01, Validation Loss: 9.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6782, Training Loss: 7.328e-01, Validation Loss: 9.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6783, Training Loss: 7.327e-01, Validation Loss: 9.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6784, Training Loss: 7.326e-01, Validation Loss: 9.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6785, Training Loss: 7.325e-01, Validation Loss: 9.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6786, Training Loss: 7.324e-01, Validation Loss: 9.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6787, Training Loss: 7.323e-01, Validation Loss: 9.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6788, Training Loss: 7.322e-01, Validation Loss: 9.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6789, Training Loss: 7.321e-01, Validation Loss: 9.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6790, Training Loss: 7.320e-01, Validation Loss: 9.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6791, Training Loss: 7.319e-01, Validation Loss: 9.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6792, Training Loss: 7.318e-01, Validation Loss: 9.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6793, Training Loss: 7.317e-01, Validation Loss: 9.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6794, Training Loss: 7.316e-01, Validation Loss: 9.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6795, Training Loss: 7.315e-01, Validation Loss: 9.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6796, Training Loss: 7.314e-01, Validation Loss: 9.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6797, Training Loss: 7.313e-01, Validation Loss: 9.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6798, Training Loss: 7.312e-01, Validation Loss: 9.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6799, Training Loss: 7.312e-01, Validation Loss: 9.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6800, Training Loss: 7.311e-01, Validation Loss: 9.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6801, Training Loss: 7.310e-01, Validation Loss: 9.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6802, Training Loss: 7.309e-01, Validation Loss: 9.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6803, Training Loss: 7.308e-01, Validation Loss: 9.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6804, Training Loss: 7.307e-01, Validation Loss: 9.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6805, Training Loss: 7.306e-01, Validation Loss: 9.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6806, Training Loss: 7.305e-01, Validation Loss: 9.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6807, Training Loss: 7.304e-01, Validation Loss: 9.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6808, Training Loss: 7.303e-01, Validation Loss: 9.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6809, Training Loss: 7.302e-01, Validation Loss: 9.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6810, Training Loss: 7.301e-01, Validation Loss: 9.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6811, Training Loss: 7.300e-01, Validation Loss: 9.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6812, Training Loss: 7.299e-01, Validation Loss: 9.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6813, Training Loss: 7.298e-01, Validation Loss: 9.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6814, Training Loss: 7.297e-01, Validation Loss: 9.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6815, Training Loss: 7.296e-01, Validation Loss: 9.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6816, Training Loss: 7.296e-01, Validation Loss: 9.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6817, Training Loss: 7.295e-01, Validation Loss: 9.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6818, Training Loss: 7.294e-01, Validation Loss: 9.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6819, Training Loss: 7.293e-01, Validation Loss: 9.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6820, Training Loss: 7.292e-01, Validation Loss: 9.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6821, Training Loss: 7.291e-01, Validation Loss: 9.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6822, Training Loss: 7.290e-01, Validation Loss: 9.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6823, Training Loss: 7.289e-01, Validation Loss: 9.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6824, Training Loss: 7.288e-01, Validation Loss: 9.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6825, Training Loss: 7.287e-01, Validation Loss: 9.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6826, Training Loss: 7.286e-01, Validation Loss: 9.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6827, Training Loss: 7.285e-01, Validation Loss: 9.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6828, Training Loss: 7.284e-01, Validation Loss: 9.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6829, Training Loss: 7.283e-01, Validation Loss: 9.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6830, Training Loss: 7.282e-01, Validation Loss: 9.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6831, Training Loss: 7.281e-01, Validation Loss: 9.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6832, Training Loss: 7.281e-01, Validation Loss: 9.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6833, Training Loss: 7.280e-01, Validation Loss: 9.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6834, Training Loss: 7.279e-01, Validation Loss: 9.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6835, Training Loss: 7.278e-01, Validation Loss: 9.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6836, Training Loss: 7.277e-01, Validation Loss: 9.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6837, Training Loss: 7.276e-01, Validation Loss: 9.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6838, Training Loss: 7.275e-01, Validation Loss: 9.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6839, Training Loss: 7.274e-01, Validation Loss: 9.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6840, Training Loss: 7.273e-01, Validation Loss: 9.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6841, Training Loss: 7.272e-01, Validation Loss: 9.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6842, Training Loss: 7.271e-01, Validation Loss: 9.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6843, Training Loss: 7.270e-01, Validation Loss: 9.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6844, Training Loss: 7.269e-01, Validation Loss: 9.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6845, Training Loss: 7.268e-01, Validation Loss: 9.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6846, Training Loss: 7.268e-01, Validation Loss: 9.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6847, Training Loss: 7.267e-01, Validation Loss: 9.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6848, Training Loss: 7.266e-01, Validation Loss: 9.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6849, Training Loss: 7.265e-01, Validation Loss: 9.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6850, Training Loss: 7.264e-01, Validation Loss: 9.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6851, Training Loss: 7.263e-01, Validation Loss: 9.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6852, Training Loss: 7.262e-01, Validation Loss: 9.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6853, Training Loss: 7.261e-01, Validation Loss: 9.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6854, Training Loss: 7.260e-01, Validation Loss: 9.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6855, Training Loss: 7.259e-01, Validation Loss: 9.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6856, Training Loss: 7.258e-01, Validation Loss: 9.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6857, Training Loss: 7.257e-01, Validation Loss: 9.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6858, Training Loss: 7.256e-01, Validation Loss: 9.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6859, Training Loss: 7.255e-01, Validation Loss: 9.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6860, Training Loss: 7.254e-01, Validation Loss: 9.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6861, Training Loss: 7.254e-01, Validation Loss: 9.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6862, Training Loss: 7.253e-01, Validation Loss: 9.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6863, Training Loss: 7.252e-01, Validation Loss: 9.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6864, Training Loss: 7.251e-01, Validation Loss: 9.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6865, Training Loss: 7.250e-01, Validation Loss: 9.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6866, Training Loss: 7.249e-01, Validation Loss: 9.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6867, Training Loss: 7.248e-01, Validation Loss: 9.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6868, Training Loss: 7.247e-01, Validation Loss: 9.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6869, Training Loss: 7.246e-01, Validation Loss: 9.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6870, Training Loss: 7.245e-01, Validation Loss: 9.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6871, Training Loss: 7.244e-01, Validation Loss: 9.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6872, Training Loss: 7.243e-01, Validation Loss: 9.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6873, Training Loss: 7.242e-01, Validation Loss: 9.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6874, Training Loss: 7.242e-01, Validation Loss: 9.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6875, Training Loss: 7.241e-01, Validation Loss: 9.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6876, Training Loss: 7.240e-01, Validation Loss: 9.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6877, Training Loss: 7.239e-01, Validation Loss: 9.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6878, Training Loss: 7.238e-01, Validation Loss: 9.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6879, Training Loss: 7.237e-01, Validation Loss: 9.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6880, Training Loss: 7.236e-01, Validation Loss: 9.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6881, Training Loss: 7.235e-01, Validation Loss: 9.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6882, Training Loss: 7.234e-01, Validation Loss: 9.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6883, Training Loss: 7.233e-01, Validation Loss: 9.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6884, Training Loss: 7.232e-01, Validation Loss: 9.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6885, Training Loss: 7.231e-01, Validation Loss: 9.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6886, Training Loss: 7.230e-01, Validation Loss: 9.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6887, Training Loss: 7.230e-01, Validation Loss: 9.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6888, Training Loss: 7.229e-01, Validation Loss: 9.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6889, Training Loss: 7.228e-01, Validation Loss: 9.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6890, Training Loss: 7.227e-01, Validation Loss: 9.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6891, Training Loss: 7.226e-01, Validation Loss: 9.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6892, Training Loss: 7.225e-01, Validation Loss: 9.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6893, Training Loss: 7.224e-01, Validation Loss: 9.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6894, Training Loss: 7.223e-01, Validation Loss: 9.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6895, Training Loss: 7.222e-01, Validation Loss: 9.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6896, Training Loss: 7.221e-01, Validation Loss: 9.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6897, Training Loss: 7.220e-01, Validation Loss: 9.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6898, Training Loss: 7.219e-01, Validation Loss: 9.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6899, Training Loss: 7.218e-01, Validation Loss: 9.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6900, Training Loss: 7.218e-01, Validation Loss: 9.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6901, Training Loss: 7.217e-01, Validation Loss: 9.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6902, Training Loss: 7.216e-01, Validation Loss: 9.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6903, Training Loss: 7.215e-01, Validation Loss: 9.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6904, Training Loss: 7.214e-01, Validation Loss: 9.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6905, Training Loss: 7.213e-01, Validation Loss: 9.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6906, Training Loss: 7.212e-01, Validation Loss: 9.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6907, Training Loss: 7.211e-01, Validation Loss: 9.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6908, Training Loss: 7.210e-01, Validation Loss: 9.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6909, Training Loss: 7.209e-01, Validation Loss: 9.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6910, Training Loss: 7.208e-01, Validation Loss: 9.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6911, Training Loss: 7.207e-01, Validation Loss: 9.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6912, Training Loss: 7.207e-01, Validation Loss: 9.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6913, Training Loss: 7.206e-01, Validation Loss: 9.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6914, Training Loss: 7.205e-01, Validation Loss: 9.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6915, Training Loss: 7.204e-01, Validation Loss: 9.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6916, Training Loss: 7.203e-01, Validation Loss: 9.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6917, Training Loss: 7.202e-01, Validation Loss: 9.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6918, Training Loss: 7.201e-01, Validation Loss: 9.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6919, Training Loss: 7.200e-01, Validation Loss: 9.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6920, Training Loss: 7.199e-01, Validation Loss: 9.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6921, Training Loss: 7.198e-01, Validation Loss: 9.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6922, Training Loss: 7.197e-01, Validation Loss: 9.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6923, Training Loss: 7.196e-01, Validation Loss: 9.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6924, Training Loss: 7.196e-01, Validation Loss: 9.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6925, Training Loss: 7.195e-01, Validation Loss: 9.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6926, Training Loss: 7.194e-01, Validation Loss: 9.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6927, Training Loss: 7.193e-01, Validation Loss: 9.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6928, Training Loss: 7.192e-01, Validation Loss: 9.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6929, Training Loss: 7.191e-01, Validation Loss: 9.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6930, Training Loss: 7.190e-01, Validation Loss: 9.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6931, Training Loss: 7.189e-01, Validation Loss: 9.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6932, Training Loss: 7.188e-01, Validation Loss: 9.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6933, Training Loss: 7.187e-01, Validation Loss: 9.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6934, Training Loss: 7.186e-01, Validation Loss: 9.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6935, Training Loss: 7.186e-01, Validation Loss: 9.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6936, Training Loss: 7.185e-01, Validation Loss: 9.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6937, Training Loss: 7.184e-01, Validation Loss: 9.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6938, Training Loss: 7.183e-01, Validation Loss: 9.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6939, Training Loss: 7.182e-01, Validation Loss: 9.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6940, Training Loss: 7.181e-01, Validation Loss: 9.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6941, Training Loss: 7.180e-01, Validation Loss: 9.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6942, Training Loss: 7.179e-01, Validation Loss: 9.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6943, Training Loss: 7.178e-01, Validation Loss: 9.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6944, Training Loss: 7.177e-01, Validation Loss: 9.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6945, Training Loss: 7.176e-01, Validation Loss: 9.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6946, Training Loss: 7.176e-01, Validation Loss: 9.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6947, Training Loss: 7.175e-01, Validation Loss: 9.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6948, Training Loss: 7.174e-01, Validation Loss: 9.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6949, Training Loss: 7.173e-01, Validation Loss: 9.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6950, Training Loss: 7.172e-01, Validation Loss: 9.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6951, Training Loss: 7.171e-01, Validation Loss: 9.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6952, Training Loss: 7.170e-01, Validation Loss: 9.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6953, Training Loss: 7.169e-01, Validation Loss: 9.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6954, Training Loss: 7.168e-01, Validation Loss: 9.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6955, Training Loss: 7.167e-01, Validation Loss: 9.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6956, Training Loss: 7.166e-01, Validation Loss: 9.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6957, Training Loss: 7.166e-01, Validation Loss: 9.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6958, Training Loss: 7.165e-01, Validation Loss: 9.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6959, Training Loss: 7.164e-01, Validation Loss: 9.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6960, Training Loss: 7.163e-01, Validation Loss: 9.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6961, Training Loss: 7.162e-01, Validation Loss: 9.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6962, Training Loss: 7.161e-01, Validation Loss: 9.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6963, Training Loss: 7.160e-01, Validation Loss: 9.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6964, Training Loss: 7.159e-01, Validation Loss: 9.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6965, Training Loss: 7.158e-01, Validation Loss: 9.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6966, Training Loss: 7.157e-01, Validation Loss: 9.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6967, Training Loss: 7.156e-01, Validation Loss: 9.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6968, Training Loss: 7.156e-01, Validation Loss: 9.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6969, Training Loss: 7.155e-01, Validation Loss: 9.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6970, Training Loss: 7.154e-01, Validation Loss: 9.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6971, Training Loss: 7.153e-01, Validation Loss: 9.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6972, Training Loss: 7.152e-01, Validation Loss: 9.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6973, Training Loss: 7.151e-01, Validation Loss: 9.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6974, Training Loss: 7.150e-01, Validation Loss: 9.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6975, Training Loss: 7.149e-01, Validation Loss: 9.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6976, Training Loss: 7.148e-01, Validation Loss: 9.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6977, Training Loss: 7.147e-01, Validation Loss: 9.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6978, Training Loss: 7.147e-01, Validation Loss: 9.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6979, Training Loss: 7.146e-01, Validation Loss: 9.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6980, Training Loss: 7.145e-01, Validation Loss: 9.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6981, Training Loss: 7.144e-01, Validation Loss: 9.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6982, Training Loss: 7.143e-01, Validation Loss: 9.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6983, Training Loss: 7.142e-01, Validation Loss: 9.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6984, Training Loss: 7.141e-01, Validation Loss: 9.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6985, Training Loss: 7.140e-01, Validation Loss: 9.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6986, Training Loss: 7.139e-01, Validation Loss: 9.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6987, Training Loss: 7.138e-01, Validation Loss: 9.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6988, Training Loss: 7.137e-01, Validation Loss: 9.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6989, Training Loss: 7.137e-01, Validation Loss: 9.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6990, Training Loss: 7.136e-01, Validation Loss: 9.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6991, Training Loss: 7.135e-01, Validation Loss: 9.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6992, Training Loss: 7.134e-01, Validation Loss: 9.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6993, Training Loss: 7.133e-01, Validation Loss: 9.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6994, Training Loss: 7.132e-01, Validation Loss: 9.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6995, Training Loss: 7.131e-01, Validation Loss: 9.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6996, Training Loss: 7.130e-01, Validation Loss: 9.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6997, Training Loss: 7.129e-01, Validation Loss: 9.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6998, Training Loss: 7.129e-01, Validation Loss: 9.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6999, Training Loss: 7.128e-01, Validation Loss: 9.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7000, Training Loss: 7.127e-01, Validation Loss: 9.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7001, Training Loss: 7.126e-01, Validation Loss: 9.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7002, Training Loss: 7.125e-01, Validation Loss: 9.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7003, Training Loss: 7.124e-01, Validation Loss: 9.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7004, Training Loss: 7.123e-01, Validation Loss: 9.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7005, Training Loss: 7.122e-01, Validation Loss: 9.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7006, Training Loss: 7.121e-01, Validation Loss: 9.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7007, Training Loss: 7.120e-01, Validation Loss: 9.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7008, Training Loss: 7.120e-01, Validation Loss: 9.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7009, Training Loss: 7.119e-01, Validation Loss: 9.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7010, Training Loss: 7.118e-01, Validation Loss: 9.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7011, Training Loss: 7.117e-01, Validation Loss: 9.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7012, Training Loss: 7.116e-01, Validation Loss: 9.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7013, Training Loss: 7.115e-01, Validation Loss: 9.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7014, Training Loss: 7.114e-01, Validation Loss: 9.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7015, Training Loss: 7.113e-01, Validation Loss: 9.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7016, Training Loss: 7.112e-01, Validation Loss: 9.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7017, Training Loss: 7.111e-01, Validation Loss: 9.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7018, Training Loss: 7.111e-01, Validation Loss: 9.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7019, Training Loss: 7.110e-01, Validation Loss: 9.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7020, Training Loss: 7.109e-01, Validation Loss: 9.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7021, Training Loss: 7.108e-01, Validation Loss: 9.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7022, Training Loss: 7.107e-01, Validation Loss: 9.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7023, Training Loss: 7.106e-01, Validation Loss: 9.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7024, Training Loss: 7.105e-01, Validation Loss: 9.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7025, Training Loss: 7.104e-01, Validation Loss: 9.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7026, Training Loss: 7.103e-01, Validation Loss: 9.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7027, Training Loss: 7.103e-01, Validation Loss: 9.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7028, Training Loss: 7.102e-01, Validation Loss: 9.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7029, Training Loss: 7.101e-01, Validation Loss: 9.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7030, Training Loss: 7.100e-01, Validation Loss: 9.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7031, Training Loss: 7.099e-01, Validation Loss: 9.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7032, Training Loss: 7.098e-01, Validation Loss: 9.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7033, Training Loss: 7.097e-01, Validation Loss: 9.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7034, Training Loss: 7.096e-01, Validation Loss: 9.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7035, Training Loss: 7.095e-01, Validation Loss: 9.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7036, Training Loss: 7.095e-01, Validation Loss: 9.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7037, Training Loss: 7.094e-01, Validation Loss: 9.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7038, Training Loss: 7.093e-01, Validation Loss: 9.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7039, Training Loss: 7.092e-01, Validation Loss: 9.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7040, Training Loss: 7.091e-01, Validation Loss: 9.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7041, Training Loss: 7.090e-01, Validation Loss: 9.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7042, Training Loss: 7.089e-01, Validation Loss: 9.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7043, Training Loss: 7.088e-01, Validation Loss: 9.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7044, Training Loss: 7.087e-01, Validation Loss: 9.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7045, Training Loss: 7.087e-01, Validation Loss: 9.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7046, Training Loss: 7.086e-01, Validation Loss: 9.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7047, Training Loss: 7.085e-01, Validation Loss: 9.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7048, Training Loss: 7.084e-01, Validation Loss: 9.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7049, Training Loss: 7.083e-01, Validation Loss: 9.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7050, Training Loss: 7.082e-01, Validation Loss: 9.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7051, Training Loss: 7.081e-01, Validation Loss: 9.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7052, Training Loss: 7.080e-01, Validation Loss: 9.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7053, Training Loss: 7.079e-01, Validation Loss: 9.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7054, Training Loss: 7.079e-01, Validation Loss: 9.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7055, Training Loss: 7.078e-01, Validation Loss: 9.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7056, Training Loss: 7.077e-01, Validation Loss: 9.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7057, Training Loss: 7.076e-01, Validation Loss: 9.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7058, Training Loss: 7.075e-01, Validation Loss: 9.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7059, Training Loss: 7.074e-01, Validation Loss: 9.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7060, Training Loss: 7.073e-01, Validation Loss: 9.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7061, Training Loss: 7.072e-01, Validation Loss: 9.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7062, Training Loss: 7.071e-01, Validation Loss: 9.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7063, Training Loss: 7.071e-01, Validation Loss: 9.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7064, Training Loss: 7.070e-01, Validation Loss: 9.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7065, Training Loss: 7.069e-01, Validation Loss: 9.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7066, Training Loss: 7.068e-01, Validation Loss: 9.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7067, Training Loss: 7.067e-01, Validation Loss: 9.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7068, Training Loss: 7.066e-01, Validation Loss: 9.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7069, Training Loss: 7.065e-01, Validation Loss: 9.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7070, Training Loss: 7.064e-01, Validation Loss: 9.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7071, Training Loss: 7.063e-01, Validation Loss: 9.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7072, Training Loss: 7.063e-01, Validation Loss: 9.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7073, Training Loss: 7.062e-01, Validation Loss: 9.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7074, Training Loss: 7.061e-01, Validation Loss: 9.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7075, Training Loss: 7.060e-01, Validation Loss: 9.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7076, Training Loss: 7.059e-01, Validation Loss: 9.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7077, Training Loss: 7.058e-01, Validation Loss: 9.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7078, Training Loss: 7.057e-01, Validation Loss: 9.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7079, Training Loss: 7.056e-01, Validation Loss: 9.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7080, Training Loss: 7.056e-01, Validation Loss: 9.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7081, Training Loss: 7.055e-01, Validation Loss: 9.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7082, Training Loss: 7.054e-01, Validation Loss: 9.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7083, Training Loss: 7.053e-01, Validation Loss: 9.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7084, Training Loss: 7.052e-01, Validation Loss: 9.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7085, Training Loss: 7.051e-01, Validation Loss: 9.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7086, Training Loss: 7.050e-01, Validation Loss: 9.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7087, Training Loss: 7.049e-01, Validation Loss: 9.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7088, Training Loss: 7.048e-01, Validation Loss: 9.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7089, Training Loss: 7.048e-01, Validation Loss: 9.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7090, Training Loss: 7.047e-01, Validation Loss: 9.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7091, Training Loss: 7.046e-01, Validation Loss: 9.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7092, Training Loss: 7.045e-01, Validation Loss: 9.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7093, Training Loss: 7.044e-01, Validation Loss: 9.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7094, Training Loss: 7.043e-01, Validation Loss: 9.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7095, Training Loss: 7.042e-01, Validation Loss: 9.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7096, Training Loss: 7.041e-01, Validation Loss: 9.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7097, Training Loss: 7.041e-01, Validation Loss: 9.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7098, Training Loss: 7.040e-01, Validation Loss: 9.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7099, Training Loss: 7.039e-01, Validation Loss: 9.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7100, Training Loss: 7.038e-01, Validation Loss: 9.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7101, Training Loss: 7.037e-01, Validation Loss: 9.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7102, Training Loss: 7.036e-01, Validation Loss: 9.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7103, Training Loss: 7.035e-01, Validation Loss: 9.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7104, Training Loss: 7.034e-01, Validation Loss: 9.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7105, Training Loss: 7.034e-01, Validation Loss: 9.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7106, Training Loss: 7.033e-01, Validation Loss: 9.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7107, Training Loss: 7.032e-01, Validation Loss: 9.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7108, Training Loss: 7.031e-01, Validation Loss: 9.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7109, Training Loss: 7.030e-01, Validation Loss: 9.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7110, Training Loss: 7.029e-01, Validation Loss: 9.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7111, Training Loss: 7.028e-01, Validation Loss: 9.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7112, Training Loss: 7.027e-01, Validation Loss: 9.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7113, Training Loss: 7.027e-01, Validation Loss: 9.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7114, Training Loss: 7.026e-01, Validation Loss: 9.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7115, Training Loss: 7.025e-01, Validation Loss: 9.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7116, Training Loss: 7.024e-01, Validation Loss: 9.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7117, Training Loss: 7.023e-01, Validation Loss: 9.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7118, Training Loss: 7.022e-01, Validation Loss: 9.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7119, Training Loss: 7.021e-01, Validation Loss: 9.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7120, Training Loss: 7.020e-01, Validation Loss: 9.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7121, Training Loss: 7.020e-01, Validation Loss: 9.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7122, Training Loss: 7.019e-01, Validation Loss: 9.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7123, Training Loss: 7.018e-01, Validation Loss: 9.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7124, Training Loss: 7.017e-01, Validation Loss: 9.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7125, Training Loss: 7.016e-01, Validation Loss: 9.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7126, Training Loss: 7.015e-01, Validation Loss: 9.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7127, Training Loss: 7.014e-01, Validation Loss: 9.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7128, Training Loss: 7.013e-01, Validation Loss: 9.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7129, Training Loss: 7.013e-01, Validation Loss: 9.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7130, Training Loss: 7.012e-01, Validation Loss: 9.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7131, Training Loss: 7.011e-01, Validation Loss: 9.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7132, Training Loss: 7.010e-01, Validation Loss: 9.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7133, Training Loss: 7.009e-01, Validation Loss: 9.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7134, Training Loss: 7.008e-01, Validation Loss: 9.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7135, Training Loss: 7.007e-01, Validation Loss: 9.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7136, Training Loss: 7.006e-01, Validation Loss: 9.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7137, Training Loss: 7.006e-01, Validation Loss: 9.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7138, Training Loss: 7.005e-01, Validation Loss: 9.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7139, Training Loss: 7.004e-01, Validation Loss: 9.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7140, Training Loss: 7.003e-01, Validation Loss: 9.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7141, Training Loss: 7.002e-01, Validation Loss: 9.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7142, Training Loss: 7.001e-01, Validation Loss: 9.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7143, Training Loss: 7.000e-01, Validation Loss: 9.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7144, Training Loss: 7.000e-01, Validation Loss: 9.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7145, Training Loss: 6.999e-01, Validation Loss: 9.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7146, Training Loss: 6.998e-01, Validation Loss: 9.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7147, Training Loss: 6.997e-01, Validation Loss: 9.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7148, Training Loss: 6.996e-01, Validation Loss: 9.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7149, Training Loss: 6.995e-01, Validation Loss: 9.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7150, Training Loss: 6.994e-01, Validation Loss: 9.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7151, Training Loss: 6.993e-01, Validation Loss: 9.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7152, Training Loss: 6.993e-01, Validation Loss: 9.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7153, Training Loss: 6.992e-01, Validation Loss: 9.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7154, Training Loss: 6.991e-01, Validation Loss: 9.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7155, Training Loss: 6.990e-01, Validation Loss: 9.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7156, Training Loss: 6.989e-01, Validation Loss: 9.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7157, Training Loss: 6.988e-01, Validation Loss: 9.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7158, Training Loss: 6.987e-01, Validation Loss: 9.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7159, Training Loss: 6.986e-01, Validation Loss: 9.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7160, Training Loss: 6.986e-01, Validation Loss: 9.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7161, Training Loss: 6.985e-01, Validation Loss: 9.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7162, Training Loss: 6.984e-01, Validation Loss: 9.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7163, Training Loss: 6.983e-01, Validation Loss: 9.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7164, Training Loss: 6.982e-01, Validation Loss: 9.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7165, Training Loss: 6.981e-01, Validation Loss: 9.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7166, Training Loss: 6.980e-01, Validation Loss: 9.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7167, Training Loss: 6.980e-01, Validation Loss: 9.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7168, Training Loss: 6.979e-01, Validation Loss: 9.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7169, Training Loss: 6.978e-01, Validation Loss: 9.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7170, Training Loss: 6.977e-01, Validation Loss: 9.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7171, Training Loss: 6.976e-01, Validation Loss: 9.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7172, Training Loss: 6.975e-01, Validation Loss: 8.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7173, Training Loss: 6.974e-01, Validation Loss: 8.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7174, Training Loss: 6.974e-01, Validation Loss: 8.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7175, Training Loss: 6.973e-01, Validation Loss: 8.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7176, Training Loss: 6.972e-01, Validation Loss: 8.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7177, Training Loss: 6.971e-01, Validation Loss: 8.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7178, Training Loss: 6.970e-01, Validation Loss: 8.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7179, Training Loss: 6.969e-01, Validation Loss: 8.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7180, Training Loss: 6.968e-01, Validation Loss: 8.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7181, Training Loss: 6.967e-01, Validation Loss: 8.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7182, Training Loss: 6.967e-01, Validation Loss: 8.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7183, Training Loss: 6.966e-01, Validation Loss: 8.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7184, Training Loss: 6.965e-01, Validation Loss: 8.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7185, Training Loss: 6.964e-01, Validation Loss: 8.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7186, Training Loss: 6.963e-01, Validation Loss: 8.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7187, Training Loss: 6.962e-01, Validation Loss: 8.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7188, Training Loss: 6.961e-01, Validation Loss: 8.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7189, Training Loss: 6.961e-01, Validation Loss: 8.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7190, Training Loss: 6.960e-01, Validation Loss: 8.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7191, Training Loss: 6.959e-01, Validation Loss: 8.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7192, Training Loss: 6.958e-01, Validation Loss: 8.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7193, Training Loss: 6.957e-01, Validation Loss: 8.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7194, Training Loss: 6.956e-01, Validation Loss: 8.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7195, Training Loss: 6.955e-01, Validation Loss: 8.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7196, Training Loss: 6.955e-01, Validation Loss: 8.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7197, Training Loss: 6.954e-01, Validation Loss: 8.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7198, Training Loss: 6.953e-01, Validation Loss: 8.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7199, Training Loss: 6.952e-01, Validation Loss: 8.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7200, Training Loss: 6.951e-01, Validation Loss: 8.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7201, Training Loss: 6.950e-01, Validation Loss: 8.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7202, Training Loss: 6.949e-01, Validation Loss: 8.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7203, Training Loss: 6.949e-01, Validation Loss: 8.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7204, Training Loss: 6.948e-01, Validation Loss: 8.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7205, Training Loss: 6.947e-01, Validation Loss: 8.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7206, Training Loss: 6.946e-01, Validation Loss: 8.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7207, Training Loss: 6.945e-01, Validation Loss: 8.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7208, Training Loss: 6.944e-01, Validation Loss: 8.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7209, Training Loss: 6.943e-01, Validation Loss: 8.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7210, Training Loss: 6.943e-01, Validation Loss: 8.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7211, Training Loss: 6.942e-01, Validation Loss: 8.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7212, Training Loss: 6.941e-01, Validation Loss: 8.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7213, Training Loss: 6.940e-01, Validation Loss: 8.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7214, Training Loss: 6.939e-01, Validation Loss: 8.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7215, Training Loss: 6.938e-01, Validation Loss: 8.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7216, Training Loss: 6.937e-01, Validation Loss: 8.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7217, Training Loss: 6.937e-01, Validation Loss: 8.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7218, Training Loss: 6.936e-01, Validation Loss: 8.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7219, Training Loss: 6.935e-01, Validation Loss: 8.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7220, Training Loss: 6.934e-01, Validation Loss: 8.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7221, Training Loss: 6.933e-01, Validation Loss: 8.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7222, Training Loss: 6.932e-01, Validation Loss: 8.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7223, Training Loss: 6.931e-01, Validation Loss: 8.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7224, Training Loss: 6.931e-01, Validation Loss: 8.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7225, Training Loss: 6.930e-01, Validation Loss: 8.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7226, Training Loss: 6.929e-01, Validation Loss: 8.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7227, Training Loss: 6.928e-01, Validation Loss: 8.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7228, Training Loss: 6.927e-01, Validation Loss: 8.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7229, Training Loss: 6.926e-01, Validation Loss: 8.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7230, Training Loss: 6.925e-01, Validation Loss: 8.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7231, Training Loss: 6.925e-01, Validation Loss: 8.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7232, Training Loss: 6.924e-01, Validation Loss: 8.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7233, Training Loss: 6.923e-01, Validation Loss: 8.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7234, Training Loss: 6.922e-01, Validation Loss: 8.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7235, Training Loss: 6.921e-01, Validation Loss: 8.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7236, Training Loss: 6.920e-01, Validation Loss: 8.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7237, Training Loss: 6.920e-01, Validation Loss: 8.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7238, Training Loss: 6.919e-01, Validation Loss: 8.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7239, Training Loss: 6.918e-01, Validation Loss: 8.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7240, Training Loss: 6.917e-01, Validation Loss: 8.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7241, Training Loss: 6.916e-01, Validation Loss: 8.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7242, Training Loss: 6.915e-01, Validation Loss: 8.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7243, Training Loss: 6.914e-01, Validation Loss: 8.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7244, Training Loss: 6.914e-01, Validation Loss: 8.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7245, Training Loss: 6.913e-01, Validation Loss: 8.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7246, Training Loss: 6.912e-01, Validation Loss: 8.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7247, Training Loss: 6.911e-01, Validation Loss: 8.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7248, Training Loss: 6.910e-01, Validation Loss: 8.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7249, Training Loss: 6.909e-01, Validation Loss: 8.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7250, Training Loss: 6.908e-01, Validation Loss: 8.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7251, Training Loss: 6.908e-01, Validation Loss: 8.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7252, Training Loss: 6.907e-01, Validation Loss: 8.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7253, Training Loss: 6.906e-01, Validation Loss: 8.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7254, Training Loss: 6.905e-01, Validation Loss: 8.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7255, Training Loss: 6.904e-01, Validation Loss: 8.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7256, Training Loss: 6.903e-01, Validation Loss: 8.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7257, Training Loss: 6.903e-01, Validation Loss: 8.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7258, Training Loss: 6.902e-01, Validation Loss: 8.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7259, Training Loss: 6.901e-01, Validation Loss: 8.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7260, Training Loss: 6.900e-01, Validation Loss: 8.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7261, Training Loss: 6.899e-01, Validation Loss: 8.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7262, Training Loss: 6.898e-01, Validation Loss: 8.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7263, Training Loss: 6.897e-01, Validation Loss: 8.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7264, Training Loss: 6.897e-01, Validation Loss: 8.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7265, Training Loss: 6.896e-01, Validation Loss: 8.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7266, Training Loss: 6.895e-01, Validation Loss: 8.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7267, Training Loss: 6.894e-01, Validation Loss: 8.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7268, Training Loss: 6.893e-01, Validation Loss: 8.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7269, Training Loss: 6.892e-01, Validation Loss: 8.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7270, Training Loss: 6.892e-01, Validation Loss: 8.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7271, Training Loss: 6.891e-01, Validation Loss: 8.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7272, Training Loss: 6.890e-01, Validation Loss: 8.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7273, Training Loss: 6.889e-01, Validation Loss: 8.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7274, Training Loss: 6.888e-01, Validation Loss: 8.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7275, Training Loss: 6.887e-01, Validation Loss: 8.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7276, Training Loss: 6.886e-01, Validation Loss: 8.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7277, Training Loss: 6.886e-01, Validation Loss: 8.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7278, Training Loss: 6.885e-01, Validation Loss: 8.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7279, Training Loss: 6.884e-01, Validation Loss: 8.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7280, Training Loss: 6.883e-01, Validation Loss: 8.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7281, Training Loss: 6.882e-01, Validation Loss: 8.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7282, Training Loss: 6.881e-01, Validation Loss: 8.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7283, Training Loss: 6.881e-01, Validation Loss: 8.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7284, Training Loss: 6.880e-01, Validation Loss: 8.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7285, Training Loss: 6.879e-01, Validation Loss: 8.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7286, Training Loss: 6.878e-01, Validation Loss: 8.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7287, Training Loss: 6.877e-01, Validation Loss: 8.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7288, Training Loss: 6.876e-01, Validation Loss: 8.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7289, Training Loss: 6.876e-01, Validation Loss: 8.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7290, Training Loss: 6.875e-01, Validation Loss: 8.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7291, Training Loss: 6.874e-01, Validation Loss: 8.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7292, Training Loss: 6.873e-01, Validation Loss: 8.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7293, Training Loss: 6.872e-01, Validation Loss: 8.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7294, Training Loss: 6.871e-01, Validation Loss: 8.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7295, Training Loss: 6.870e-01, Validation Loss: 8.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7296, Training Loss: 6.870e-01, Validation Loss: 8.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7297, Training Loss: 6.869e-01, Validation Loss: 8.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7298, Training Loss: 6.868e-01, Validation Loss: 8.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7299, Training Loss: 6.867e-01, Validation Loss: 8.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7300, Training Loss: 6.866e-01, Validation Loss: 8.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7301, Training Loss: 6.865e-01, Validation Loss: 8.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7302, Training Loss: 6.865e-01, Validation Loss: 8.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7303, Training Loss: 6.864e-01, Validation Loss: 8.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7304, Training Loss: 6.863e-01, Validation Loss: 8.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7305, Training Loss: 6.862e-01, Validation Loss: 8.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7306, Training Loss: 6.861e-01, Validation Loss: 8.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7307, Training Loss: 6.860e-01, Validation Loss: 8.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7308, Training Loss: 6.860e-01, Validation Loss: 8.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7309, Training Loss: 6.859e-01, Validation Loss: 8.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7310, Training Loss: 6.858e-01, Validation Loss: 8.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7311, Training Loss: 6.857e-01, Validation Loss: 8.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7312, Training Loss: 6.856e-01, Validation Loss: 8.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7313, Training Loss: 6.855e-01, Validation Loss: 8.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7314, Training Loss: 6.855e-01, Validation Loss: 8.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7315, Training Loss: 6.854e-01, Validation Loss: 8.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7316, Training Loss: 6.853e-01, Validation Loss: 8.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7317, Training Loss: 6.852e-01, Validation Loss: 8.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7318, Training Loss: 6.851e-01, Validation Loss: 8.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7319, Training Loss: 6.850e-01, Validation Loss: 8.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7320, Training Loss: 6.850e-01, Validation Loss: 8.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7321, Training Loss: 6.849e-01, Validation Loss: 8.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7322, Training Loss: 6.848e-01, Validation Loss: 8.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7323, Training Loss: 6.847e-01, Validation Loss: 8.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7324, Training Loss: 6.846e-01, Validation Loss: 8.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7325, Training Loss: 6.845e-01, Validation Loss: 8.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7326, Training Loss: 6.845e-01, Validation Loss: 8.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7327, Training Loss: 6.844e-01, Validation Loss: 8.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7328, Training Loss: 6.843e-01, Validation Loss: 8.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7329, Training Loss: 6.842e-01, Validation Loss: 8.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7330, Training Loss: 6.841e-01, Validation Loss: 8.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7331, Training Loss: 6.840e-01, Validation Loss: 8.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7332, Training Loss: 6.840e-01, Validation Loss: 8.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7333, Training Loss: 6.839e-01, Validation Loss: 8.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7334, Training Loss: 6.838e-01, Validation Loss: 8.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7335, Training Loss: 6.837e-01, Validation Loss: 8.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7336, Training Loss: 6.836e-01, Validation Loss: 8.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7337, Training Loss: 6.835e-01, Validation Loss: 8.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7338, Training Loss: 6.835e-01, Validation Loss: 8.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7339, Training Loss: 6.834e-01, Validation Loss: 8.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7340, Training Loss: 6.833e-01, Validation Loss: 8.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7341, Training Loss: 6.832e-01, Validation Loss: 8.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7342, Training Loss: 6.831e-01, Validation Loss: 8.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7343, Training Loss: 6.830e-01, Validation Loss: 8.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7344, Training Loss: 6.830e-01, Validation Loss: 8.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7345, Training Loss: 6.829e-01, Validation Loss: 8.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7346, Training Loss: 6.828e-01, Validation Loss: 8.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7347, Training Loss: 6.827e-01, Validation Loss: 8.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7348, Training Loss: 6.826e-01, Validation Loss: 8.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7349, Training Loss: 6.825e-01, Validation Loss: 8.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7350, Training Loss: 6.825e-01, Validation Loss: 8.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7351, Training Loss: 6.824e-01, Validation Loss: 8.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7352, Training Loss: 6.823e-01, Validation Loss: 8.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7353, Training Loss: 6.822e-01, Validation Loss: 8.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7354, Training Loss: 6.821e-01, Validation Loss: 8.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7355, Training Loss: 6.820e-01, Validation Loss: 8.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7356, Training Loss: 6.820e-01, Validation Loss: 8.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7357, Training Loss: 6.819e-01, Validation Loss: 8.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7358, Training Loss: 6.818e-01, Validation Loss: 8.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7359, Training Loss: 6.817e-01, Validation Loss: 8.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7360, Training Loss: 6.816e-01, Validation Loss: 8.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7361, Training Loss: 6.815e-01, Validation Loss: 8.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7362, Training Loss: 6.815e-01, Validation Loss: 8.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7363, Training Loss: 6.814e-01, Validation Loss: 8.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7364, Training Loss: 6.813e-01, Validation Loss: 8.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7365, Training Loss: 6.812e-01, Validation Loss: 8.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7366, Training Loss: 6.811e-01, Validation Loss: 8.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7367, Training Loss: 6.810e-01, Validation Loss: 8.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7368, Training Loss: 6.810e-01, Validation Loss: 8.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7369, Training Loss: 6.809e-01, Validation Loss: 8.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7370, Training Loss: 6.808e-01, Validation Loss: 8.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7371, Training Loss: 6.807e-01, Validation Loss: 8.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7372, Training Loss: 6.806e-01, Validation Loss: 8.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7373, Training Loss: 6.806e-01, Validation Loss: 8.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7374, Training Loss: 6.805e-01, Validation Loss: 8.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7375, Training Loss: 6.804e-01, Validation Loss: 8.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7376, Training Loss: 6.803e-01, Validation Loss: 8.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7377, Training Loss: 6.802e-01, Validation Loss: 8.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7378, Training Loss: 6.801e-01, Validation Loss: 8.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7379, Training Loss: 6.801e-01, Validation Loss: 8.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7380, Training Loss: 6.800e-01, Validation Loss: 8.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7381, Training Loss: 6.799e-01, Validation Loss: 8.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7382, Training Loss: 6.798e-01, Validation Loss: 8.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7383, Training Loss: 6.797e-01, Validation Loss: 8.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7384, Training Loss: 6.796e-01, Validation Loss: 8.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7385, Training Loss: 6.796e-01, Validation Loss: 8.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7386, Training Loss: 6.795e-01, Validation Loss: 8.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7387, Training Loss: 6.794e-01, Validation Loss: 8.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7388, Training Loss: 6.793e-01, Validation Loss: 8.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7389, Training Loss: 6.792e-01, Validation Loss: 8.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7390, Training Loss: 6.791e-01, Validation Loss: 8.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7391, Training Loss: 6.791e-01, Validation Loss: 8.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7392, Training Loss: 6.790e-01, Validation Loss: 8.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7393, Training Loss: 6.789e-01, Validation Loss: 8.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7394, Training Loss: 6.788e-01, Validation Loss: 8.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7395, Training Loss: 6.787e-01, Validation Loss: 8.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7396, Training Loss: 6.787e-01, Validation Loss: 8.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7397, Training Loss: 6.786e-01, Validation Loss: 8.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7398, Training Loss: 6.785e-01, Validation Loss: 8.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7399, Training Loss: 6.784e-01, Validation Loss: 8.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7400, Training Loss: 6.783e-01, Validation Loss: 8.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7401, Training Loss: 6.782e-01, Validation Loss: 8.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7402, Training Loss: 6.782e-01, Validation Loss: 8.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7403, Training Loss: 6.781e-01, Validation Loss: 8.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7404, Training Loss: 6.780e-01, Validation Loss: 8.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7405, Training Loss: 6.779e-01, Validation Loss: 8.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7406, Training Loss: 6.778e-01, Validation Loss: 8.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7407, Training Loss: 6.778e-01, Validation Loss: 8.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7408, Training Loss: 6.777e-01, Validation Loss: 8.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7409, Training Loss: 6.776e-01, Validation Loss: 8.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7410, Training Loss: 6.775e-01, Validation Loss: 8.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7411, Training Loss: 6.774e-01, Validation Loss: 8.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7412, Training Loss: 6.773e-01, Validation Loss: 8.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7413, Training Loss: 6.773e-01, Validation Loss: 8.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7414, Training Loss: 6.772e-01, Validation Loss: 8.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7415, Training Loss: 6.771e-01, Validation Loss: 8.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7416, Training Loss: 6.770e-01, Validation Loss: 8.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7417, Training Loss: 6.769e-01, Validation Loss: 8.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7418, Training Loss: 6.768e-01, Validation Loss: 8.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7419, Training Loss: 6.768e-01, Validation Loss: 8.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7420, Training Loss: 6.767e-01, Validation Loss: 8.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7421, Training Loss: 6.766e-01, Validation Loss: 8.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7422, Training Loss: 6.765e-01, Validation Loss: 8.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7423, Training Loss: 6.764e-01, Validation Loss: 8.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7424, Training Loss: 6.764e-01, Validation Loss: 8.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7425, Training Loss: 6.763e-01, Validation Loss: 8.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7426, Training Loss: 6.762e-01, Validation Loss: 8.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7427, Training Loss: 6.761e-01, Validation Loss: 8.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7428, Training Loss: 6.760e-01, Validation Loss: 8.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7429, Training Loss: 6.760e-01, Validation Loss: 8.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7430, Training Loss: 6.759e-01, Validation Loss: 8.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7431, Training Loss: 6.758e-01, Validation Loss: 8.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7432, Training Loss: 6.757e-01, Validation Loss: 8.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7433, Training Loss: 6.756e-01, Validation Loss: 8.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7434, Training Loss: 6.755e-01, Validation Loss: 8.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7435, Training Loss: 6.755e-01, Validation Loss: 8.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7436, Training Loss: 6.754e-01, Validation Loss: 8.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7437, Training Loss: 6.753e-01, Validation Loss: 8.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7438, Training Loss: 6.752e-01, Validation Loss: 8.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7439, Training Loss: 6.751e-01, Validation Loss: 8.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7440, Training Loss: 6.751e-01, Validation Loss: 8.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7441, Training Loss: 6.750e-01, Validation Loss: 8.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7442, Training Loss: 6.749e-01, Validation Loss: 8.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7443, Training Loss: 6.748e-01, Validation Loss: 8.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7444, Training Loss: 6.747e-01, Validation Loss: 8.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7445, Training Loss: 6.746e-01, Validation Loss: 8.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7446, Training Loss: 6.746e-01, Validation Loss: 8.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7447, Training Loss: 6.745e-01, Validation Loss: 8.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7448, Training Loss: 6.744e-01, Validation Loss: 8.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7449, Training Loss: 6.743e-01, Validation Loss: 8.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7450, Training Loss: 6.742e-01, Validation Loss: 8.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7451, Training Loss: 6.742e-01, Validation Loss: 8.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7452, Training Loss: 6.741e-01, Validation Loss: 8.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7453, Training Loss: 6.740e-01, Validation Loss: 8.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7454, Training Loss: 6.739e-01, Validation Loss: 8.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7455, Training Loss: 6.738e-01, Validation Loss: 8.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7456, Training Loss: 6.738e-01, Validation Loss: 8.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7457, Training Loss: 6.737e-01, Validation Loss: 8.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7458, Training Loss: 6.736e-01, Validation Loss: 8.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7459, Training Loss: 6.735e-01, Validation Loss: 8.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7460, Training Loss: 6.734e-01, Validation Loss: 8.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7461, Training Loss: 6.733e-01, Validation Loss: 8.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7462, Training Loss: 6.733e-01, Validation Loss: 8.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7463, Training Loss: 6.732e-01, Validation Loss: 8.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7464, Training Loss: 6.731e-01, Validation Loss: 8.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7465, Training Loss: 6.730e-01, Validation Loss: 8.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7466, Training Loss: 6.729e-01, Validation Loss: 8.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7467, Training Loss: 6.729e-01, Validation Loss: 8.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7468, Training Loss: 6.728e-01, Validation Loss: 8.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7469, Training Loss: 6.727e-01, Validation Loss: 8.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7470, Training Loss: 6.726e-01, Validation Loss: 8.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7471, Training Loss: 6.725e-01, Validation Loss: 8.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7472, Training Loss: 6.725e-01, Validation Loss: 8.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7473, Training Loss: 6.724e-01, Validation Loss: 8.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7474, Training Loss: 6.723e-01, Validation Loss: 8.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7475, Training Loss: 6.722e-01, Validation Loss: 8.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7476, Training Loss: 6.721e-01, Validation Loss: 8.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7477, Training Loss: 6.721e-01, Validation Loss: 8.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7478, Training Loss: 6.720e-01, Validation Loss: 8.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7479, Training Loss: 6.719e-01, Validation Loss: 8.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7480, Training Loss: 6.718e-01, Validation Loss: 8.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7481, Training Loss: 6.717e-01, Validation Loss: 8.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7482, Training Loss: 6.716e-01, Validation Loss: 8.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7483, Training Loss: 6.716e-01, Validation Loss: 8.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7484, Training Loss: 6.715e-01, Validation Loss: 8.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7485, Training Loss: 6.714e-01, Validation Loss: 8.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7486, Training Loss: 6.713e-01, Validation Loss: 8.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7487, Training Loss: 6.712e-01, Validation Loss: 8.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7488, Training Loss: 6.712e-01, Validation Loss: 8.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7489, Training Loss: 6.711e-01, Validation Loss: 8.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7490, Training Loss: 6.710e-01, Validation Loss: 8.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7491, Training Loss: 6.709e-01, Validation Loss: 8.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7492, Training Loss: 6.708e-01, Validation Loss: 8.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7493, Training Loss: 6.708e-01, Validation Loss: 8.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7494, Training Loss: 6.707e-01, Validation Loss: 8.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7495, Training Loss: 6.706e-01, Validation Loss: 8.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7496, Training Loss: 6.705e-01, Validation Loss: 8.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7497, Training Loss: 6.704e-01, Validation Loss: 8.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7498, Training Loss: 6.704e-01, Validation Loss: 8.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7499, Training Loss: 6.703e-01, Validation Loss: 8.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7500, Training Loss: 6.702e-01, Validation Loss: 8.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7501, Training Loss: 6.701e-01, Validation Loss: 8.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7502, Training Loss: 6.700e-01, Validation Loss: 8.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7503, Training Loss: 6.700e-01, Validation Loss: 8.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7504, Training Loss: 6.699e-01, Validation Loss: 8.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7505, Training Loss: 6.698e-01, Validation Loss: 8.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7506, Training Loss: 6.697e-01, Validation Loss: 8.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7507, Training Loss: 6.696e-01, Validation Loss: 8.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7508, Training Loss: 6.696e-01, Validation Loss: 8.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7509, Training Loss: 6.695e-01, Validation Loss: 8.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7510, Training Loss: 6.694e-01, Validation Loss: 8.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7511, Training Loss: 6.693e-01, Validation Loss: 8.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7512, Training Loss: 6.692e-01, Validation Loss: 8.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7513, Training Loss: 6.692e-01, Validation Loss: 8.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7514, Training Loss: 6.691e-01, Validation Loss: 8.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7515, Training Loss: 6.690e-01, Validation Loss: 8.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7516, Training Loss: 6.689e-01, Validation Loss: 8.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7517, Training Loss: 6.688e-01, Validation Loss: 8.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7518, Training Loss: 6.688e-01, Validation Loss: 8.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7519, Training Loss: 6.687e-01, Validation Loss: 8.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7520, Training Loss: 6.686e-01, Validation Loss: 8.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7521, Training Loss: 6.685e-01, Validation Loss: 8.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7522, Training Loss: 6.684e-01, Validation Loss: 8.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7523, Training Loss: 6.684e-01, Validation Loss: 8.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7524, Training Loss: 6.683e-01, Validation Loss: 8.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7525, Training Loss: 6.682e-01, Validation Loss: 8.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7526, Training Loss: 6.681e-01, Validation Loss: 8.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7527, Training Loss: 6.680e-01, Validation Loss: 8.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7528, Training Loss: 6.680e-01, Validation Loss: 8.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7529, Training Loss: 6.679e-01, Validation Loss: 8.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7530, Training Loss: 6.678e-01, Validation Loss: 8.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7531, Training Loss: 6.677e-01, Validation Loss: 8.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7532, Training Loss: 6.676e-01, Validation Loss: 8.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7533, Training Loss: 6.676e-01, Validation Loss: 8.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7534, Training Loss: 6.675e-01, Validation Loss: 8.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7535, Training Loss: 6.674e-01, Validation Loss: 8.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7536, Training Loss: 6.673e-01, Validation Loss: 8.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7537, Training Loss: 6.672e-01, Validation Loss: 8.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7538, Training Loss: 6.672e-01, Validation Loss: 8.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7539, Training Loss: 6.671e-01, Validation Loss: 8.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7540, Training Loss: 6.670e-01, Validation Loss: 8.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7541, Training Loss: 6.669e-01, Validation Loss: 8.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7542, Training Loss: 6.668e-01, Validation Loss: 8.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7543, Training Loss: 6.668e-01, Validation Loss: 8.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7544, Training Loss: 6.667e-01, Validation Loss: 8.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7545, Training Loss: 6.666e-01, Validation Loss: 8.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7546, Training Loss: 6.665e-01, Validation Loss: 8.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7547, Training Loss: 6.664e-01, Validation Loss: 8.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7548, Training Loss: 6.664e-01, Validation Loss: 8.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7549, Training Loss: 6.663e-01, Validation Loss: 8.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7550, Training Loss: 6.662e-01, Validation Loss: 8.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7551, Training Loss: 6.661e-01, Validation Loss: 8.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7552, Training Loss: 6.660e-01, Validation Loss: 8.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7553, Training Loss: 6.660e-01, Validation Loss: 8.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7554, Training Loss: 6.659e-01, Validation Loss: 8.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7555, Training Loss: 6.658e-01, Validation Loss: 8.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7556, Training Loss: 6.657e-01, Validation Loss: 8.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7557, Training Loss: 6.656e-01, Validation Loss: 8.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7558, Training Loss: 6.656e-01, Validation Loss: 8.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7559, Training Loss: 6.655e-01, Validation Loss: 8.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7560, Training Loss: 6.654e-01, Validation Loss: 8.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7561, Training Loss: 6.653e-01, Validation Loss: 8.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7562, Training Loss: 6.652e-01, Validation Loss: 8.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7563, Training Loss: 6.652e-01, Validation Loss: 8.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7564, Training Loss: 6.651e-01, Validation Loss: 8.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7565, Training Loss: 6.650e-01, Validation Loss: 8.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7566, Training Loss: 6.649e-01, Validation Loss: 8.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7567, Training Loss: 6.649e-01, Validation Loss: 8.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7568, Training Loss: 6.648e-01, Validation Loss: 8.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7569, Training Loss: 6.647e-01, Validation Loss: 8.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7570, Training Loss: 6.646e-01, Validation Loss: 8.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7571, Training Loss: 6.645e-01, Validation Loss: 8.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7572, Training Loss: 6.645e-01, Validation Loss: 8.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7573, Training Loss: 6.644e-01, Validation Loss: 8.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7574, Training Loss: 6.643e-01, Validation Loss: 8.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7575, Training Loss: 6.642e-01, Validation Loss: 8.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7576, Training Loss: 6.641e-01, Validation Loss: 8.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7577, Training Loss: 6.641e-01, Validation Loss: 8.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7578, Training Loss: 6.640e-01, Validation Loss: 8.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7579, Training Loss: 6.639e-01, Validation Loss: 8.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7580, Training Loss: 6.638e-01, Validation Loss: 8.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7581, Training Loss: 6.637e-01, Validation Loss: 8.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7582, Training Loss: 6.637e-01, Validation Loss: 8.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7583, Training Loss: 6.636e-01, Validation Loss: 8.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7584, Training Loss: 6.635e-01, Validation Loss: 8.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7585, Training Loss: 6.634e-01, Validation Loss: 8.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7586, Training Loss: 6.633e-01, Validation Loss: 8.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7587, Training Loss: 6.633e-01, Validation Loss: 8.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7588, Training Loss: 6.632e-01, Validation Loss: 8.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7589, Training Loss: 6.631e-01, Validation Loss: 8.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7590, Training Loss: 6.630e-01, Validation Loss: 8.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7591, Training Loss: 6.630e-01, Validation Loss: 8.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7592, Training Loss: 6.629e-01, Validation Loss: 8.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7593, Training Loss: 6.628e-01, Validation Loss: 8.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7594, Training Loss: 6.627e-01, Validation Loss: 8.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7595, Training Loss: 6.626e-01, Validation Loss: 8.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7596, Training Loss: 6.626e-01, Validation Loss: 8.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7597, Training Loss: 6.625e-01, Validation Loss: 8.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7598, Training Loss: 6.624e-01, Validation Loss: 8.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7599, Training Loss: 6.623e-01, Validation Loss: 8.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7600, Training Loss: 6.622e-01, Validation Loss: 8.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7601, Training Loss: 6.622e-01, Validation Loss: 8.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7602, Training Loss: 6.621e-01, Validation Loss: 8.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7603, Training Loss: 6.620e-01, Validation Loss: 8.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7604, Training Loss: 6.619e-01, Validation Loss: 8.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7605, Training Loss: 6.618e-01, Validation Loss: 8.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7606, Training Loss: 6.618e-01, Validation Loss: 8.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7607, Training Loss: 6.617e-01, Validation Loss: 8.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7608, Training Loss: 6.616e-01, Validation Loss: 8.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7609, Training Loss: 6.615e-01, Validation Loss: 8.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7610, Training Loss: 6.615e-01, Validation Loss: 8.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7611, Training Loss: 6.614e-01, Validation Loss: 8.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7612, Training Loss: 6.613e-01, Validation Loss: 8.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7613, Training Loss: 6.612e-01, Validation Loss: 8.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7614, Training Loss: 6.611e-01, Validation Loss: 8.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7615, Training Loss: 6.611e-01, Validation Loss: 8.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7616, Training Loss: 6.610e-01, Validation Loss: 8.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7617, Training Loss: 6.609e-01, Validation Loss: 8.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7618, Training Loss: 6.608e-01, Validation Loss: 8.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7619, Training Loss: 6.607e-01, Validation Loss: 8.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7620, Training Loss: 6.607e-01, Validation Loss: 8.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7621, Training Loss: 6.606e-01, Validation Loss: 8.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7622, Training Loss: 6.605e-01, Validation Loss: 8.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7623, Training Loss: 6.604e-01, Validation Loss: 8.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7624, Training Loss: 6.604e-01, Validation Loss: 8.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7625, Training Loss: 6.603e-01, Validation Loss: 8.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7626, Training Loss: 6.602e-01, Validation Loss: 8.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7627, Training Loss: 6.601e-01, Validation Loss: 8.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7628, Training Loss: 6.600e-01, Validation Loss: 8.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7629, Training Loss: 6.600e-01, Validation Loss: 8.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7630, Training Loss: 6.599e-01, Validation Loss: 8.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7631, Training Loss: 6.598e-01, Validation Loss: 8.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7632, Training Loss: 6.597e-01, Validation Loss: 8.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7633, Training Loss: 6.596e-01, Validation Loss: 8.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7634, Training Loss: 6.596e-01, Validation Loss: 8.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7635, Training Loss: 6.595e-01, Validation Loss: 8.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7636, Training Loss: 6.594e-01, Validation Loss: 8.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7637, Training Loss: 6.593e-01, Validation Loss: 8.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7638, Training Loss: 6.593e-01, Validation Loss: 8.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7639, Training Loss: 6.592e-01, Validation Loss: 8.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7640, Training Loss: 6.591e-01, Validation Loss: 8.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7641, Training Loss: 6.590e-01, Validation Loss: 8.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7642, Training Loss: 6.589e-01, Validation Loss: 8.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7643, Training Loss: 6.589e-01, Validation Loss: 8.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7644, Training Loss: 6.588e-01, Validation Loss: 8.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7645, Training Loss: 6.587e-01, Validation Loss: 8.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7646, Training Loss: 6.586e-01, Validation Loss: 8.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7647, Training Loss: 6.586e-01, Validation Loss: 8.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7648, Training Loss: 6.585e-01, Validation Loss: 8.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7649, Training Loss: 6.584e-01, Validation Loss: 8.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7650, Training Loss: 6.583e-01, Validation Loss: 8.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7651, Training Loss: 6.582e-01, Validation Loss: 8.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7652, Training Loss: 6.582e-01, Validation Loss: 8.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7653, Training Loss: 6.581e-01, Validation Loss: 8.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7654, Training Loss: 6.580e-01, Validation Loss: 8.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7655, Training Loss: 6.579e-01, Validation Loss: 8.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7656, Training Loss: 6.579e-01, Validation Loss: 8.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7657, Training Loss: 6.578e-01, Validation Loss: 8.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7658, Training Loss: 6.577e-01, Validation Loss: 8.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7659, Training Loss: 6.576e-01, Validation Loss: 8.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7660, Training Loss: 6.575e-01, Validation Loss: 8.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7661, Training Loss: 6.575e-01, Validation Loss: 8.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7662, Training Loss: 6.574e-01, Validation Loss: 8.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7663, Training Loss: 6.573e-01, Validation Loss: 8.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7664, Training Loss: 6.572e-01, Validation Loss: 8.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7665, Training Loss: 6.572e-01, Validation Loss: 8.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7666, Training Loss: 6.571e-01, Validation Loss: 8.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7667, Training Loss: 6.570e-01, Validation Loss: 8.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7668, Training Loss: 6.569e-01, Validation Loss: 8.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7669, Training Loss: 6.568e-01, Validation Loss: 8.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7670, Training Loss: 6.568e-01, Validation Loss: 8.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7671, Training Loss: 6.567e-01, Validation Loss: 8.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7672, Training Loss: 6.566e-01, Validation Loss: 8.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7673, Training Loss: 6.565e-01, Validation Loss: 8.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7674, Training Loss: 6.565e-01, Validation Loss: 8.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7675, Training Loss: 6.564e-01, Validation Loss: 8.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7676, Training Loss: 6.563e-01, Validation Loss: 8.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7677, Training Loss: 6.562e-01, Validation Loss: 8.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7678, Training Loss: 6.561e-01, Validation Loss: 8.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7679, Training Loss: 6.561e-01, Validation Loss: 8.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7680, Training Loss: 6.560e-01, Validation Loss: 8.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7681, Training Loss: 6.559e-01, Validation Loss: 8.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7682, Training Loss: 6.558e-01, Validation Loss: 8.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7683, Training Loss: 6.558e-01, Validation Loss: 8.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7684, Training Loss: 6.557e-01, Validation Loss: 8.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7685, Training Loss: 6.556e-01, Validation Loss: 8.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7686, Training Loss: 6.555e-01, Validation Loss: 8.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7687, Training Loss: 6.554e-01, Validation Loss: 8.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7688, Training Loss: 6.554e-01, Validation Loss: 8.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7689, Training Loss: 6.553e-01, Validation Loss: 8.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7690, Training Loss: 6.552e-01, Validation Loss: 8.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7691, Training Loss: 6.551e-01, Validation Loss: 8.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7692, Training Loss: 6.551e-01, Validation Loss: 8.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7693, Training Loss: 6.550e-01, Validation Loss: 8.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7694, Training Loss: 6.549e-01, Validation Loss: 8.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7695, Training Loss: 6.548e-01, Validation Loss: 8.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7696, Training Loss: 6.548e-01, Validation Loss: 8.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7697, Training Loss: 6.547e-01, Validation Loss: 8.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7698, Training Loss: 6.546e-01, Validation Loss: 8.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7699, Training Loss: 6.545e-01, Validation Loss: 8.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7700, Training Loss: 6.544e-01, Validation Loss: 8.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7701, Training Loss: 6.544e-01, Validation Loss: 8.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7702, Training Loss: 6.543e-01, Validation Loss: 8.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7703, Training Loss: 6.542e-01, Validation Loss: 8.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7704, Training Loss: 6.541e-01, Validation Loss: 8.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7705, Training Loss: 6.541e-01, Validation Loss: 8.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7706, Training Loss: 6.540e-01, Validation Loss: 8.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7707, Training Loss: 6.539e-01, Validation Loss: 8.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7708, Training Loss: 6.538e-01, Validation Loss: 8.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7709, Training Loss: 6.538e-01, Validation Loss: 8.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7710, Training Loss: 6.537e-01, Validation Loss: 8.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7711, Training Loss: 6.536e-01, Validation Loss: 8.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7712, Training Loss: 6.535e-01, Validation Loss: 8.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7713, Training Loss: 6.534e-01, Validation Loss: 8.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7714, Training Loss: 6.534e-01, Validation Loss: 8.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7715, Training Loss: 6.533e-01, Validation Loss: 8.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7716, Training Loss: 6.532e-01, Validation Loss: 8.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7717, Training Loss: 6.531e-01, Validation Loss: 8.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7718, Training Loss: 6.531e-01, Validation Loss: 8.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7719, Training Loss: 6.530e-01, Validation Loss: 8.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7720, Training Loss: 6.529e-01, Validation Loss: 8.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7721, Training Loss: 6.528e-01, Validation Loss: 8.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7722, Training Loss: 6.528e-01, Validation Loss: 8.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7723, Training Loss: 6.527e-01, Validation Loss: 8.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7724, Training Loss: 6.526e-01, Validation Loss: 8.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7725, Training Loss: 6.525e-01, Validation Loss: 8.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7726, Training Loss: 6.524e-01, Validation Loss: 8.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7727, Training Loss: 6.524e-01, Validation Loss: 8.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7728, Training Loss: 6.523e-01, Validation Loss: 8.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7729, Training Loss: 6.522e-01, Validation Loss: 8.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7730, Training Loss: 6.521e-01, Validation Loss: 8.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7731, Training Loss: 6.521e-01, Validation Loss: 8.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7732, Training Loss: 6.520e-01, Validation Loss: 8.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7733, Training Loss: 6.519e-01, Validation Loss: 8.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7734, Training Loss: 6.518e-01, Validation Loss: 8.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7735, Training Loss: 6.518e-01, Validation Loss: 8.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7736, Training Loss: 6.517e-01, Validation Loss: 8.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7737, Training Loss: 6.516e-01, Validation Loss: 8.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7738, Training Loss: 6.515e-01, Validation Loss: 8.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7739, Training Loss: 6.514e-01, Validation Loss: 8.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7740, Training Loss: 6.514e-01, Validation Loss: 8.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7741, Training Loss: 6.513e-01, Validation Loss: 8.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7742, Training Loss: 6.512e-01, Validation Loss: 8.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7743, Training Loss: 6.511e-01, Validation Loss: 8.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7744, Training Loss: 6.511e-01, Validation Loss: 8.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7745, Training Loss: 6.510e-01, Validation Loss: 8.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7746, Training Loss: 6.509e-01, Validation Loss: 8.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7747, Training Loss: 6.508e-01, Validation Loss: 8.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7748, Training Loss: 6.508e-01, Validation Loss: 8.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7749, Training Loss: 6.507e-01, Validation Loss: 8.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7750, Training Loss: 6.506e-01, Validation Loss: 8.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7751, Training Loss: 6.505e-01, Validation Loss: 8.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7752, Training Loss: 6.505e-01, Validation Loss: 8.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7753, Training Loss: 6.504e-01, Validation Loss: 8.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7754, Training Loss: 6.503e-01, Validation Loss: 8.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7755, Training Loss: 6.502e-01, Validation Loss: 8.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7756, Training Loss: 6.501e-01, Validation Loss: 8.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7757, Training Loss: 6.501e-01, Validation Loss: 8.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7758, Training Loss: 6.500e-01, Validation Loss: 8.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7759, Training Loss: 6.499e-01, Validation Loss: 8.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7760, Training Loss: 6.498e-01, Validation Loss: 8.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7761, Training Loss: 6.498e-01, Validation Loss: 8.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7762, Training Loss: 6.497e-01, Validation Loss: 8.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7763, Training Loss: 6.496e-01, Validation Loss: 8.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7764, Training Loss: 6.495e-01, Validation Loss: 8.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7765, Training Loss: 6.495e-01, Validation Loss: 8.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7766, Training Loss: 6.494e-01, Validation Loss: 8.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7767, Training Loss: 6.493e-01, Validation Loss: 8.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7768, Training Loss: 6.492e-01, Validation Loss: 8.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7769, Training Loss: 6.492e-01, Validation Loss: 8.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7770, Training Loss: 6.491e-01, Validation Loss: 8.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7771, Training Loss: 6.490e-01, Validation Loss: 8.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7772, Training Loss: 6.489e-01, Validation Loss: 8.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7773, Training Loss: 6.489e-01, Validation Loss: 8.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7774, Training Loss: 6.488e-01, Validation Loss: 8.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7775, Training Loss: 6.487e-01, Validation Loss: 8.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7776, Training Loss: 6.486e-01, Validation Loss: 8.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7777, Training Loss: 6.486e-01, Validation Loss: 8.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7778, Training Loss: 6.485e-01, Validation Loss: 8.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7779, Training Loss: 6.484e-01, Validation Loss: 8.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7780, Training Loss: 6.483e-01, Validation Loss: 8.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7781, Training Loss: 6.482e-01, Validation Loss: 8.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7782, Training Loss: 6.482e-01, Validation Loss: 8.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7783, Training Loss: 6.481e-01, Validation Loss: 8.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7784, Training Loss: 6.480e-01, Validation Loss: 8.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7785, Training Loss: 6.479e-01, Validation Loss: 8.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7786, Training Loss: 6.479e-01, Validation Loss: 8.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7787, Training Loss: 6.478e-01, Validation Loss: 8.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7788, Training Loss: 6.477e-01, Validation Loss: 8.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7789, Training Loss: 6.476e-01, Validation Loss: 8.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7790, Training Loss: 6.476e-01, Validation Loss: 8.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7791, Training Loss: 6.475e-01, Validation Loss: 8.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7792, Training Loss: 6.474e-01, Validation Loss: 8.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7793, Training Loss: 6.473e-01, Validation Loss: 8.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7794, Training Loss: 6.473e-01, Validation Loss: 8.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7795, Training Loss: 6.472e-01, Validation Loss: 8.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7796, Training Loss: 6.471e-01, Validation Loss: 8.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7797, Training Loss: 6.470e-01, Validation Loss: 8.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7798, Training Loss: 6.470e-01, Validation Loss: 8.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7799, Training Loss: 6.469e-01, Validation Loss: 8.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7800, Training Loss: 6.468e-01, Validation Loss: 8.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7801, Training Loss: 6.467e-01, Validation Loss: 8.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7802, Training Loss: 6.467e-01, Validation Loss: 8.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7803, Training Loss: 6.466e-01, Validation Loss: 8.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7804, Training Loss: 6.465e-01, Validation Loss: 8.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7805, Training Loss: 6.464e-01, Validation Loss: 8.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7806, Training Loss: 6.464e-01, Validation Loss: 8.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7807, Training Loss: 6.463e-01, Validation Loss: 8.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7808, Training Loss: 6.462e-01, Validation Loss: 8.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7809, Training Loss: 6.461e-01, Validation Loss: 8.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7810, Training Loss: 6.461e-01, Validation Loss: 8.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7811, Training Loss: 6.460e-01, Validation Loss: 8.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7812, Training Loss: 6.459e-01, Validation Loss: 8.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7813, Training Loss: 6.458e-01, Validation Loss: 8.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7814, Training Loss: 6.458e-01, Validation Loss: 8.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7815, Training Loss: 6.457e-01, Validation Loss: 8.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7816, Training Loss: 6.456e-01, Validation Loss: 8.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7817, Training Loss: 6.455e-01, Validation Loss: 8.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7818, Training Loss: 6.455e-01, Validation Loss: 8.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7819, Training Loss: 6.454e-01, Validation Loss: 8.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7820, Training Loss: 6.453e-01, Validation Loss: 8.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7821, Training Loss: 6.452e-01, Validation Loss: 8.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7822, Training Loss: 6.452e-01, Validation Loss: 8.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7823, Training Loss: 6.451e-01, Validation Loss: 8.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7824, Training Loss: 6.450e-01, Validation Loss: 8.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7825, Training Loss: 6.449e-01, Validation Loss: 8.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7826, Training Loss: 6.449e-01, Validation Loss: 8.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7827, Training Loss: 6.448e-01, Validation Loss: 8.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7828, Training Loss: 6.447e-01, Validation Loss: 8.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7829, Training Loss: 6.446e-01, Validation Loss: 8.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7830, Training Loss: 6.446e-01, Validation Loss: 8.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7831, Training Loss: 6.445e-01, Validation Loss: 8.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7832, Training Loss: 6.444e-01, Validation Loss: 8.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7833, Training Loss: 6.443e-01, Validation Loss: 8.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7834, Training Loss: 6.443e-01, Validation Loss: 8.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7835, Training Loss: 6.442e-01, Validation Loss: 8.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7836, Training Loss: 6.441e-01, Validation Loss: 8.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7837, Training Loss: 6.440e-01, Validation Loss: 8.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7838, Training Loss: 6.440e-01, Validation Loss: 8.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7839, Training Loss: 6.439e-01, Validation Loss: 8.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7840, Training Loss: 6.438e-01, Validation Loss: 8.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7841, Training Loss: 6.437e-01, Validation Loss: 8.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7842, Training Loss: 6.437e-01, Validation Loss: 8.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7843, Training Loss: 6.436e-01, Validation Loss: 8.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7844, Training Loss: 6.435e-01, Validation Loss: 8.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7845, Training Loss: 6.434e-01, Validation Loss: 8.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7846, Training Loss: 6.434e-01, Validation Loss: 8.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7847, Training Loss: 6.433e-01, Validation Loss: 8.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7848, Training Loss: 6.432e-01, Validation Loss: 8.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7849, Training Loss: 6.431e-01, Validation Loss: 8.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7850, Training Loss: 6.431e-01, Validation Loss: 8.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7851, Training Loss: 6.430e-01, Validation Loss: 8.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7852, Training Loss: 6.429e-01, Validation Loss: 8.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7853, Training Loss: 6.428e-01, Validation Loss: 8.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7854, Training Loss: 6.428e-01, Validation Loss: 8.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7855, Training Loss: 6.427e-01, Validation Loss: 8.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7856, Training Loss: 6.426e-01, Validation Loss: 8.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7857, Training Loss: 6.425e-01, Validation Loss: 8.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7858, Training Loss: 6.425e-01, Validation Loss: 8.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7859, Training Loss: 6.424e-01, Validation Loss: 8.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7860, Training Loss: 6.423e-01, Validation Loss: 8.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7861, Training Loss: 6.422e-01, Validation Loss: 8.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7862, Training Loss: 6.422e-01, Validation Loss: 8.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7863, Training Loss: 6.421e-01, Validation Loss: 8.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7864, Training Loss: 6.420e-01, Validation Loss: 8.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7865, Training Loss: 6.419e-01, Validation Loss: 8.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7866, Training Loss: 6.419e-01, Validation Loss: 8.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7867, Training Loss: 6.418e-01, Validation Loss: 8.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7868, Training Loss: 6.417e-01, Validation Loss: 8.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7869, Training Loss: 6.416e-01, Validation Loss: 8.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7870, Training Loss: 6.416e-01, Validation Loss: 8.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7871, Training Loss: 6.415e-01, Validation Loss: 8.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7872, Training Loss: 6.414e-01, Validation Loss: 8.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7873, Training Loss: 6.413e-01, Validation Loss: 8.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7874, Training Loss: 6.413e-01, Validation Loss: 8.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7875, Training Loss: 6.412e-01, Validation Loss: 8.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7876, Training Loss: 6.411e-01, Validation Loss: 8.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7877, Training Loss: 6.410e-01, Validation Loss: 8.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7878, Training Loss: 6.410e-01, Validation Loss: 8.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7879, Training Loss: 6.409e-01, Validation Loss: 8.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7880, Training Loss: 6.408e-01, Validation Loss: 8.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7881, Training Loss: 6.407e-01, Validation Loss: 8.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7882, Training Loss: 6.407e-01, Validation Loss: 8.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7883, Training Loss: 6.406e-01, Validation Loss: 8.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7884, Training Loss: 6.405e-01, Validation Loss: 8.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7885, Training Loss: 6.404e-01, Validation Loss: 8.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7886, Training Loss: 6.404e-01, Validation Loss: 8.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7887, Training Loss: 6.403e-01, Validation Loss: 8.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7888, Training Loss: 6.402e-01, Validation Loss: 8.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7889, Training Loss: 6.402e-01, Validation Loss: 8.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7890, Training Loss: 6.401e-01, Validation Loss: 8.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7891, Training Loss: 6.400e-01, Validation Loss: 8.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7892, Training Loss: 6.399e-01, Validation Loss: 8.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7893, Training Loss: 6.399e-01, Validation Loss: 8.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7894, Training Loss: 6.398e-01, Validation Loss: 8.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7895, Training Loss: 6.397e-01, Validation Loss: 8.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7896, Training Loss: 6.396e-01, Validation Loss: 8.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7897, Training Loss: 6.396e-01, Validation Loss: 8.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7898, Training Loss: 6.395e-01, Validation Loss: 8.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7899, Training Loss: 6.394e-01, Validation Loss: 8.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7900, Training Loss: 6.393e-01, Validation Loss: 8.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7901, Training Loss: 6.393e-01, Validation Loss: 8.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7902, Training Loss: 6.392e-01, Validation Loss: 8.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7903, Training Loss: 6.391e-01, Validation Loss: 8.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7904, Training Loss: 6.390e-01, Validation Loss: 8.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7905, Training Loss: 6.390e-01, Validation Loss: 8.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7906, Training Loss: 6.389e-01, Validation Loss: 8.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7907, Training Loss: 6.388e-01, Validation Loss: 8.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7908, Training Loss: 6.387e-01, Validation Loss: 8.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7909, Training Loss: 6.387e-01, Validation Loss: 8.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7910, Training Loss: 6.386e-01, Validation Loss: 8.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7911, Training Loss: 6.385e-01, Validation Loss: 8.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7912, Training Loss: 6.385e-01, Validation Loss: 8.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7913, Training Loss: 6.384e-01, Validation Loss: 8.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7914, Training Loss: 6.383e-01, Validation Loss: 8.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7915, Training Loss: 6.382e-01, Validation Loss: 8.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7916, Training Loss: 6.382e-01, Validation Loss: 8.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7917, Training Loss: 6.381e-01, Validation Loss: 8.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7918, Training Loss: 6.380e-01, Validation Loss: 8.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7919, Training Loss: 6.379e-01, Validation Loss: 8.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7920, Training Loss: 6.379e-01, Validation Loss: 8.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7921, Training Loss: 6.378e-01, Validation Loss: 8.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7922, Training Loss: 6.377e-01, Validation Loss: 8.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7923, Training Loss: 6.376e-01, Validation Loss: 8.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7924, Training Loss: 6.376e-01, Validation Loss: 8.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7925, Training Loss: 6.375e-01, Validation Loss: 8.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7926, Training Loss: 6.374e-01, Validation Loss: 8.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7927, Training Loss: 6.373e-01, Validation Loss: 8.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7928, Training Loss: 6.373e-01, Validation Loss: 8.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7929, Training Loss: 6.372e-01, Validation Loss: 8.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7930, Training Loss: 6.371e-01, Validation Loss: 8.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7931, Training Loss: 6.371e-01, Validation Loss: 8.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7932, Training Loss: 6.370e-01, Validation Loss: 8.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7933, Training Loss: 6.369e-01, Validation Loss: 8.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7934, Training Loss: 6.368e-01, Validation Loss: 8.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7935, Training Loss: 6.368e-01, Validation Loss: 8.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7936, Training Loss: 6.367e-01, Validation Loss: 8.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7937, Training Loss: 6.366e-01, Validation Loss: 8.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7938, Training Loss: 6.365e-01, Validation Loss: 8.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7939, Training Loss: 6.365e-01, Validation Loss: 8.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7940, Training Loss: 6.364e-01, Validation Loss: 8.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7941, Training Loss: 6.363e-01, Validation Loss: 8.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7942, Training Loss: 6.362e-01, Validation Loss: 8.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7943, Training Loss: 6.362e-01, Validation Loss: 8.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7944, Training Loss: 6.361e-01, Validation Loss: 8.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7945, Training Loss: 6.360e-01, Validation Loss: 8.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7946, Training Loss: 6.359e-01, Validation Loss: 8.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7947, Training Loss: 6.359e-01, Validation Loss: 8.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7948, Training Loss: 6.358e-01, Validation Loss: 8.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7949, Training Loss: 6.357e-01, Validation Loss: 8.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7950, Training Loss: 6.357e-01, Validation Loss: 8.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7951, Training Loss: 6.356e-01, Validation Loss: 8.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7952, Training Loss: 6.355e-01, Validation Loss: 8.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7953, Training Loss: 6.354e-01, Validation Loss: 8.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7954, Training Loss: 6.354e-01, Validation Loss: 8.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7955, Training Loss: 6.353e-01, Validation Loss: 8.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7956, Training Loss: 6.352e-01, Validation Loss: 8.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7957, Training Loss: 6.351e-01, Validation Loss: 8.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7958, Training Loss: 6.351e-01, Validation Loss: 8.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7959, Training Loss: 6.350e-01, Validation Loss: 8.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7960, Training Loss: 6.349e-01, Validation Loss: 8.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7961, Training Loss: 6.349e-01, Validation Loss: 8.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7962, Training Loss: 6.348e-01, Validation Loss: 8.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7963, Training Loss: 6.347e-01, Validation Loss: 8.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7964, Training Loss: 6.346e-01, Validation Loss: 8.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7965, Training Loss: 6.346e-01, Validation Loss: 8.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7966, Training Loss: 6.345e-01, Validation Loss: 8.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7967, Training Loss: 6.344e-01, Validation Loss: 8.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7968, Training Loss: 6.343e-01, Validation Loss: 8.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7969, Training Loss: 6.343e-01, Validation Loss: 8.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7970, Training Loss: 6.342e-01, Validation Loss: 8.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7971, Training Loss: 6.341e-01, Validation Loss: 8.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7972, Training Loss: 6.340e-01, Validation Loss: 8.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7973, Training Loss: 6.340e-01, Validation Loss: 8.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7974, Training Loss: 6.339e-01, Validation Loss: 8.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7975, Training Loss: 6.338e-01, Validation Loss: 8.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7976, Training Loss: 6.338e-01, Validation Loss: 8.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7977, Training Loss: 6.337e-01, Validation Loss: 8.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7978, Training Loss: 6.336e-01, Validation Loss: 8.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7979, Training Loss: 6.335e-01, Validation Loss: 8.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7980, Training Loss: 6.335e-01, Validation Loss: 8.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7981, Training Loss: 6.334e-01, Validation Loss: 8.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7982, Training Loss: 6.333e-01, Validation Loss: 8.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7983, Training Loss: 6.332e-01, Validation Loss: 8.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7984, Training Loss: 6.332e-01, Validation Loss: 8.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7985, Training Loss: 6.331e-01, Validation Loss: 8.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7986, Training Loss: 6.330e-01, Validation Loss: 8.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7987, Training Loss: 6.330e-01, Validation Loss: 8.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7988, Training Loss: 6.329e-01, Validation Loss: 8.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7989, Training Loss: 6.328e-01, Validation Loss: 8.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7990, Training Loss: 6.327e-01, Validation Loss: 8.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7991, Training Loss: 6.327e-01, Validation Loss: 8.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7992, Training Loss: 6.326e-01, Validation Loss: 8.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7993, Training Loss: 6.325e-01, Validation Loss: 8.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7994, Training Loss: 6.324e-01, Validation Loss: 8.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7995, Training Loss: 6.324e-01, Validation Loss: 8.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7996, Training Loss: 6.323e-01, Validation Loss: 8.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7997, Training Loss: 6.322e-01, Validation Loss: 8.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7998, Training Loss: 6.322e-01, Validation Loss: 8.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7999, Training Loss: 6.321e-01, Validation Loss: 8.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8000, Training Loss: 6.320e-01, Validation Loss: 8.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8001, Training Loss: 6.319e-01, Validation Loss: 8.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8002, Training Loss: 6.319e-01, Validation Loss: 8.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8003, Training Loss: 6.318e-01, Validation Loss: 8.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8004, Training Loss: 6.317e-01, Validation Loss: 8.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8005, Training Loss: 6.316e-01, Validation Loss: 8.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8006, Training Loss: 6.316e-01, Validation Loss: 8.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8007, Training Loss: 6.315e-01, Validation Loss: 8.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8008, Training Loss: 6.314e-01, Validation Loss: 8.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8009, Training Loss: 6.314e-01, Validation Loss: 8.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8010, Training Loss: 6.313e-01, Validation Loss: 8.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8011, Training Loss: 6.312e-01, Validation Loss: 8.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8012, Training Loss: 6.311e-01, Validation Loss: 8.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8013, Training Loss: 6.311e-01, Validation Loss: 8.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8014, Training Loss: 6.310e-01, Validation Loss: 8.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8015, Training Loss: 6.309e-01, Validation Loss: 8.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8016, Training Loss: 6.309e-01, Validation Loss: 8.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8017, Training Loss: 6.308e-01, Validation Loss: 8.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8018, Training Loss: 6.307e-01, Validation Loss: 8.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8019, Training Loss: 6.306e-01, Validation Loss: 8.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8020, Training Loss: 6.306e-01, Validation Loss: 8.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8021, Training Loss: 6.305e-01, Validation Loss: 8.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8022, Training Loss: 6.304e-01, Validation Loss: 8.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8023, Training Loss: 6.303e-01, Validation Loss: 8.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8024, Training Loss: 6.303e-01, Validation Loss: 8.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8025, Training Loss: 6.302e-01, Validation Loss: 8.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8026, Training Loss: 6.301e-01, Validation Loss: 8.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8027, Training Loss: 6.301e-01, Validation Loss: 8.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8028, Training Loss: 6.300e-01, Validation Loss: 8.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8029, Training Loss: 6.299e-01, Validation Loss: 8.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8030, Training Loss: 6.298e-01, Validation Loss: 8.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8031, Training Loss: 6.298e-01, Validation Loss: 8.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8032, Training Loss: 6.297e-01, Validation Loss: 8.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8033, Training Loss: 6.296e-01, Validation Loss: 8.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8034, Training Loss: 6.296e-01, Validation Loss: 8.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8035, Training Loss: 6.295e-01, Validation Loss: 8.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8036, Training Loss: 6.294e-01, Validation Loss: 8.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8037, Training Loss: 6.293e-01, Validation Loss: 8.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8038, Training Loss: 6.293e-01, Validation Loss: 8.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8039, Training Loss: 6.292e-01, Validation Loss: 8.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8040, Training Loss: 6.291e-01, Validation Loss: 8.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8041, Training Loss: 6.290e-01, Validation Loss: 8.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8042, Training Loss: 6.290e-01, Validation Loss: 8.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8043, Training Loss: 6.289e-01, Validation Loss: 8.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8044, Training Loss: 6.288e-01, Validation Loss: 8.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8045, Training Loss: 6.288e-01, Validation Loss: 8.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8046, Training Loss: 6.287e-01, Validation Loss: 8.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8047, Training Loss: 6.286e-01, Validation Loss: 8.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8048, Training Loss: 6.285e-01, Validation Loss: 8.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8049, Training Loss: 6.285e-01, Validation Loss: 8.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8050, Training Loss: 6.284e-01, Validation Loss: 8.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8051, Training Loss: 6.283e-01, Validation Loss: 8.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8052, Training Loss: 6.283e-01, Validation Loss: 8.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8053, Training Loss: 6.282e-01, Validation Loss: 8.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8054, Training Loss: 6.281e-01, Validation Loss: 8.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8055, Training Loss: 6.280e-01, Validation Loss: 8.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8056, Training Loss: 6.280e-01, Validation Loss: 8.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8057, Training Loss: 6.279e-01, Validation Loss: 8.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8058, Training Loss: 6.278e-01, Validation Loss: 8.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8059, Training Loss: 6.278e-01, Validation Loss: 8.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8060, Training Loss: 6.277e-01, Validation Loss: 8.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8061, Training Loss: 6.276e-01, Validation Loss: 8.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8062, Training Loss: 6.275e-01, Validation Loss: 8.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8063, Training Loss: 6.275e-01, Validation Loss: 8.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8064, Training Loss: 6.274e-01, Validation Loss: 8.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8065, Training Loss: 6.273e-01, Validation Loss: 8.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8066, Training Loss: 6.272e-01, Validation Loss: 8.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8067, Training Loss: 6.272e-01, Validation Loss: 8.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8068, Training Loss: 6.271e-01, Validation Loss: 8.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8069, Training Loss: 6.270e-01, Validation Loss: 8.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8070, Training Loss: 6.270e-01, Validation Loss: 8.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8071, Training Loss: 6.269e-01, Validation Loss: 8.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8072, Training Loss: 6.268e-01, Validation Loss: 8.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8073, Training Loss: 6.267e-01, Validation Loss: 8.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8074, Training Loss: 6.267e-01, Validation Loss: 8.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8075, Training Loss: 6.266e-01, Validation Loss: 8.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8076, Training Loss: 6.265e-01, Validation Loss: 8.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8077, Training Loss: 6.265e-01, Validation Loss: 8.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8078, Training Loss: 6.264e-01, Validation Loss: 8.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8079, Training Loss: 6.263e-01, Validation Loss: 8.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8080, Training Loss: 6.262e-01, Validation Loss: 8.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8081, Training Loss: 6.262e-01, Validation Loss: 8.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8082, Training Loss: 6.261e-01, Validation Loss: 8.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8083, Training Loss: 6.260e-01, Validation Loss: 8.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8084, Training Loss: 6.260e-01, Validation Loss: 8.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8085, Training Loss: 6.259e-01, Validation Loss: 8.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8086, Training Loss: 6.258e-01, Validation Loss: 8.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8087, Training Loss: 6.257e-01, Validation Loss: 8.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8088, Training Loss: 6.257e-01, Validation Loss: 8.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8089, Training Loss: 6.256e-01, Validation Loss: 8.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8090, Training Loss: 6.255e-01, Validation Loss: 8.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8091, Training Loss: 6.255e-01, Validation Loss: 8.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8092, Training Loss: 6.254e-01, Validation Loss: 8.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8093, Training Loss: 6.253e-01, Validation Loss: 8.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8094, Training Loss: 6.252e-01, Validation Loss: 8.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8095, Training Loss: 6.252e-01, Validation Loss: 8.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8096, Training Loss: 6.251e-01, Validation Loss: 8.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8097, Training Loss: 6.250e-01, Validation Loss: 8.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8098, Training Loss: 6.250e-01, Validation Loss: 8.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8099, Training Loss: 6.249e-01, Validation Loss: 8.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8100, Training Loss: 6.248e-01, Validation Loss: 8.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8101, Training Loss: 6.248e-01, Validation Loss: 8.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8102, Training Loss: 6.247e-01, Validation Loss: 8.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8103, Training Loss: 6.246e-01, Validation Loss: 8.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8104, Training Loss: 6.245e-01, Validation Loss: 8.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8105, Training Loss: 6.245e-01, Validation Loss: 8.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8106, Training Loss: 6.244e-01, Validation Loss: 8.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8107, Training Loss: 6.243e-01, Validation Loss: 8.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8108, Training Loss: 6.243e-01, Validation Loss: 8.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8109, Training Loss: 6.242e-01, Validation Loss: 8.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8110, Training Loss: 6.241e-01, Validation Loss: 8.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8111, Training Loss: 6.240e-01, Validation Loss: 8.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8112, Training Loss: 6.240e-01, Validation Loss: 8.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8113, Training Loss: 6.239e-01, Validation Loss: 8.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8114, Training Loss: 6.238e-01, Validation Loss: 8.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8115, Training Loss: 6.238e-01, Validation Loss: 8.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8116, Training Loss: 6.237e-01, Validation Loss: 8.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8117, Training Loss: 6.236e-01, Validation Loss: 8.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8118, Training Loss: 6.235e-01, Validation Loss: 8.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8119, Training Loss: 6.235e-01, Validation Loss: 8.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8120, Training Loss: 6.234e-01, Validation Loss: 8.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8121, Training Loss: 6.233e-01, Validation Loss: 8.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8122, Training Loss: 6.233e-01, Validation Loss: 8.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8123, Training Loss: 6.232e-01, Validation Loss: 8.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8124, Training Loss: 6.231e-01, Validation Loss: 8.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8125, Training Loss: 6.230e-01, Validation Loss: 8.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8126, Training Loss: 6.230e-01, Validation Loss: 8.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8127, Training Loss: 6.229e-01, Validation Loss: 8.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8128, Training Loss: 6.228e-01, Validation Loss: 8.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8129, Training Loss: 6.228e-01, Validation Loss: 8.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8130, Training Loss: 6.227e-01, Validation Loss: 8.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8131, Training Loss: 6.226e-01, Validation Loss: 8.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8132, Training Loss: 6.226e-01, Validation Loss: 8.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8133, Training Loss: 6.225e-01, Validation Loss: 8.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8134, Training Loss: 6.224e-01, Validation Loss: 8.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8135, Training Loss: 6.223e-01, Validation Loss: 8.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8136, Training Loss: 6.223e-01, Validation Loss: 8.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8137, Training Loss: 6.222e-01, Validation Loss: 8.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8138, Training Loss: 6.221e-01, Validation Loss: 8.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8139, Training Loss: 6.221e-01, Validation Loss: 8.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8140, Training Loss: 6.220e-01, Validation Loss: 8.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8141, Training Loss: 6.219e-01, Validation Loss: 8.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8142, Training Loss: 6.218e-01, Validation Loss: 8.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8143, Training Loss: 6.218e-01, Validation Loss: 8.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8144, Training Loss: 6.217e-01, Validation Loss: 8.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8145, Training Loss: 6.216e-01, Validation Loss: 8.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8146, Training Loss: 6.216e-01, Validation Loss: 8.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8147, Training Loss: 6.215e-01, Validation Loss: 8.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8148, Training Loss: 6.214e-01, Validation Loss: 8.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8149, Training Loss: 6.214e-01, Validation Loss: 8.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8150, Training Loss: 6.213e-01, Validation Loss: 8.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8151, Training Loss: 6.212e-01, Validation Loss: 8.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8152, Training Loss: 6.211e-01, Validation Loss: 8.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8153, Training Loss: 6.211e-01, Validation Loss: 8.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8154, Training Loss: 6.210e-01, Validation Loss: 8.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8155, Training Loss: 6.209e-01, Validation Loss: 8.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8156, Training Loss: 6.209e-01, Validation Loss: 8.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8157, Training Loss: 6.208e-01, Validation Loss: 8.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8158, Training Loss: 6.207e-01, Validation Loss: 8.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8159, Training Loss: 6.206e-01, Validation Loss: 8.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8160, Training Loss: 6.206e-01, Validation Loss: 8.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8161, Training Loss: 6.205e-01, Validation Loss: 8.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8162, Training Loss: 6.204e-01, Validation Loss: 8.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8163, Training Loss: 6.204e-01, Validation Loss: 8.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8164, Training Loss: 6.203e-01, Validation Loss: 8.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8165, Training Loss: 6.202e-01, Validation Loss: 8.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8166, Training Loss: 6.202e-01, Validation Loss: 8.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8167, Training Loss: 6.201e-01, Validation Loss: 8.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8168, Training Loss: 6.200e-01, Validation Loss: 8.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8169, Training Loss: 6.199e-01, Validation Loss: 8.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8170, Training Loss: 6.199e-01, Validation Loss: 8.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8171, Training Loss: 6.198e-01, Validation Loss: 8.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8172, Training Loss: 6.197e-01, Validation Loss: 8.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8173, Training Loss: 6.197e-01, Validation Loss: 8.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8174, Training Loss: 6.196e-01, Validation Loss: 8.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8175, Training Loss: 6.195e-01, Validation Loss: 8.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8176, Training Loss: 6.195e-01, Validation Loss: 8.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8177, Training Loss: 6.194e-01, Validation Loss: 8.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8178, Training Loss: 6.193e-01, Validation Loss: 8.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8179, Training Loss: 6.192e-01, Validation Loss: 8.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8180, Training Loss: 6.192e-01, Validation Loss: 8.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8181, Training Loss: 6.191e-01, Validation Loss: 8.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8182, Training Loss: 6.190e-01, Validation Loss: 8.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8183, Training Loss: 6.190e-01, Validation Loss: 8.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8184, Training Loss: 6.189e-01, Validation Loss: 8.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8185, Training Loss: 6.188e-01, Validation Loss: 8.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8186, Training Loss: 6.188e-01, Validation Loss: 8.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8187, Training Loss: 6.187e-01, Validation Loss: 8.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8188, Training Loss: 6.186e-01, Validation Loss: 8.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8189, Training Loss: 6.185e-01, Validation Loss: 8.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8190, Training Loss: 6.185e-01, Validation Loss: 8.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8191, Training Loss: 6.184e-01, Validation Loss: 8.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8192, Training Loss: 6.183e-01, Validation Loss: 8.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8193, Training Loss: 6.183e-01, Validation Loss: 8.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8194, Training Loss: 6.182e-01, Validation Loss: 8.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8195, Training Loss: 6.181e-01, Validation Loss: 8.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8196, Training Loss: 6.181e-01, Validation Loss: 8.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8197, Training Loss: 6.180e-01, Validation Loss: 8.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8198, Training Loss: 6.179e-01, Validation Loss: 8.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8199, Training Loss: 6.178e-01, Validation Loss: 8.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8200, Training Loss: 6.178e-01, Validation Loss: 8.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8201, Training Loss: 6.177e-01, Validation Loss: 8.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8202, Training Loss: 6.176e-01, Validation Loss: 8.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8203, Training Loss: 6.176e-01, Validation Loss: 8.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8204, Training Loss: 6.175e-01, Validation Loss: 8.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8205, Training Loss: 6.174e-01, Validation Loss: 8.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8206, Training Loss: 6.174e-01, Validation Loss: 8.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8207, Training Loss: 6.173e-01, Validation Loss: 8.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8208, Training Loss: 6.172e-01, Validation Loss: 8.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8209, Training Loss: 6.171e-01, Validation Loss: 8.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8210, Training Loss: 6.171e-01, Validation Loss: 8.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8211, Training Loss: 6.170e-01, Validation Loss: 8.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8212, Training Loss: 6.169e-01, Validation Loss: 8.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8213, Training Loss: 6.169e-01, Validation Loss: 8.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8214, Training Loss: 6.168e-01, Validation Loss: 8.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8215, Training Loss: 6.167e-01, Validation Loss: 8.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8216, Training Loss: 6.167e-01, Validation Loss: 8.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8217, Training Loss: 6.166e-01, Validation Loss: 8.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8218, Training Loss: 6.165e-01, Validation Loss: 8.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8219, Training Loss: 6.164e-01, Validation Loss: 8.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8220, Training Loss: 6.164e-01, Validation Loss: 8.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8221, Training Loss: 6.163e-01, Validation Loss: 8.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8222, Training Loss: 6.162e-01, Validation Loss: 8.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8223, Training Loss: 6.162e-01, Validation Loss: 8.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8224, Training Loss: 6.161e-01, Validation Loss: 8.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8225, Training Loss: 6.160e-01, Validation Loss: 8.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8226, Training Loss: 6.160e-01, Validation Loss: 8.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8227, Training Loss: 6.159e-01, Validation Loss: 8.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8228, Training Loss: 6.158e-01, Validation Loss: 8.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8229, Training Loss: 6.158e-01, Validation Loss: 8.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8230, Training Loss: 6.157e-01, Validation Loss: 8.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8231, Training Loss: 6.156e-01, Validation Loss: 8.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8232, Training Loss: 6.155e-01, Validation Loss: 8.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8233, Training Loss: 6.155e-01, Validation Loss: 8.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8234, Training Loss: 6.154e-01, Validation Loss: 8.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8235, Training Loss: 6.153e-01, Validation Loss: 8.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8236, Training Loss: 6.153e-01, Validation Loss: 8.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8237, Training Loss: 6.152e-01, Validation Loss: 8.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8238, Training Loss: 6.151e-01, Validation Loss: 8.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8239, Training Loss: 6.151e-01, Validation Loss: 8.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8240, Training Loss: 6.150e-01, Validation Loss: 8.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8241, Training Loss: 6.149e-01, Validation Loss: 8.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8242, Training Loss: 6.148e-01, Validation Loss: 8.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8243, Training Loss: 6.148e-01, Validation Loss: 8.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8244, Training Loss: 6.147e-01, Validation Loss: 8.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8245, Training Loss: 6.146e-01, Validation Loss: 8.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8246, Training Loss: 6.146e-01, Validation Loss: 8.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8247, Training Loss: 6.145e-01, Validation Loss: 8.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8248, Training Loss: 6.144e-01, Validation Loss: 8.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8249, Training Loss: 6.144e-01, Validation Loss: 8.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8250, Training Loss: 6.143e-01, Validation Loss: 8.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8251, Training Loss: 6.142e-01, Validation Loss: 8.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8252, Training Loss: 6.142e-01, Validation Loss: 8.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8253, Training Loss: 6.141e-01, Validation Loss: 8.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8254, Training Loss: 6.140e-01, Validation Loss: 8.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8255, Training Loss: 6.139e-01, Validation Loss: 8.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8256, Training Loss: 6.139e-01, Validation Loss: 8.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8257, Training Loss: 6.138e-01, Validation Loss: 8.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8258, Training Loss: 6.137e-01, Validation Loss: 8.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8259, Training Loss: 6.137e-01, Validation Loss: 8.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8260, Training Loss: 6.136e-01, Validation Loss: 8.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8261, Training Loss: 6.135e-01, Validation Loss: 8.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8262, Training Loss: 6.135e-01, Validation Loss: 8.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8263, Training Loss: 6.134e-01, Validation Loss: 8.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8264, Training Loss: 6.133e-01, Validation Loss: 8.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8265, Training Loss: 6.133e-01, Validation Loss: 8.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8266, Training Loss: 6.132e-01, Validation Loss: 8.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8267, Training Loss: 6.131e-01, Validation Loss: 8.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8268, Training Loss: 6.131e-01, Validation Loss: 8.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8269, Training Loss: 6.130e-01, Validation Loss: 8.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8270, Training Loss: 6.129e-01, Validation Loss: 8.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8271, Training Loss: 6.128e-01, Validation Loss: 8.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8272, Training Loss: 6.128e-01, Validation Loss: 8.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8273, Training Loss: 6.127e-01, Validation Loss: 8.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8274, Training Loss: 6.126e-01, Validation Loss: 8.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8275, Training Loss: 6.126e-01, Validation Loss: 8.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8276, Training Loss: 6.125e-01, Validation Loss: 8.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8277, Training Loss: 6.124e-01, Validation Loss: 8.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8278, Training Loss: 6.124e-01, Validation Loss: 8.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8279, Training Loss: 6.123e-01, Validation Loss: 8.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8280, Training Loss: 6.122e-01, Validation Loss: 8.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8281, Training Loss: 6.122e-01, Validation Loss: 8.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8282, Training Loss: 6.121e-01, Validation Loss: 8.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8283, Training Loss: 6.120e-01, Validation Loss: 8.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8284, Training Loss: 6.119e-01, Validation Loss: 8.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8285, Training Loss: 6.119e-01, Validation Loss: 8.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8286, Training Loss: 6.118e-01, Validation Loss: 8.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8287, Training Loss: 6.117e-01, Validation Loss: 8.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8288, Training Loss: 6.117e-01, Validation Loss: 8.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8289, Training Loss: 6.116e-01, Validation Loss: 8.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8290, Training Loss: 6.115e-01, Validation Loss: 8.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8291, Training Loss: 6.115e-01, Validation Loss: 8.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8292, Training Loss: 6.114e-01, Validation Loss: 8.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8293, Training Loss: 6.113e-01, Validation Loss: 8.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8294, Training Loss: 6.113e-01, Validation Loss: 8.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8295, Training Loss: 6.112e-01, Validation Loss: 8.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8296, Training Loss: 6.111e-01, Validation Loss: 8.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8297, Training Loss: 6.111e-01, Validation Loss: 8.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8298, Training Loss: 6.110e-01, Validation Loss: 8.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8299, Training Loss: 6.109e-01, Validation Loss: 8.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8300, Training Loss: 6.108e-01, Validation Loss: 8.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8301, Training Loss: 6.108e-01, Validation Loss: 8.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8302, Training Loss: 6.107e-01, Validation Loss: 8.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8303, Training Loss: 6.106e-01, Validation Loss: 8.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8304, Training Loss: 6.106e-01, Validation Loss: 8.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8305, Training Loss: 6.105e-01, Validation Loss: 8.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8306, Training Loss: 6.104e-01, Validation Loss: 8.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8307, Training Loss: 6.104e-01, Validation Loss: 8.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8308, Training Loss: 6.103e-01, Validation Loss: 8.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8309, Training Loss: 6.102e-01, Validation Loss: 8.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8310, Training Loss: 6.102e-01, Validation Loss: 8.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8311, Training Loss: 6.101e-01, Validation Loss: 8.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8312, Training Loss: 6.100e-01, Validation Loss: 8.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8313, Training Loss: 6.100e-01, Validation Loss: 8.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8314, Training Loss: 6.099e-01, Validation Loss: 8.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8315, Training Loss: 6.098e-01, Validation Loss: 8.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8316, Training Loss: 6.098e-01, Validation Loss: 8.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8317, Training Loss: 6.097e-01, Validation Loss: 8.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8318, Training Loss: 6.096e-01, Validation Loss: 8.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8319, Training Loss: 6.095e-01, Validation Loss: 8.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8320, Training Loss: 6.095e-01, Validation Loss: 8.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8321, Training Loss: 6.094e-01, Validation Loss: 8.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8322, Training Loss: 6.093e-01, Validation Loss: 8.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8323, Training Loss: 6.093e-01, Validation Loss: 8.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8324, Training Loss: 6.092e-01, Validation Loss: 8.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8325, Training Loss: 6.091e-01, Validation Loss: 8.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8326, Training Loss: 6.091e-01, Validation Loss: 8.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8327, Training Loss: 6.090e-01, Validation Loss: 8.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8328, Training Loss: 6.089e-01, Validation Loss: 8.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8329, Training Loss: 6.089e-01, Validation Loss: 8.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8330, Training Loss: 6.088e-01, Validation Loss: 8.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8331, Training Loss: 6.087e-01, Validation Loss: 8.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8332, Training Loss: 6.087e-01, Validation Loss: 8.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8333, Training Loss: 6.086e-01, Validation Loss: 8.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8334, Training Loss: 6.085e-01, Validation Loss: 8.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8335, Training Loss: 6.085e-01, Validation Loss: 8.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8336, Training Loss: 6.084e-01, Validation Loss: 8.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8337, Training Loss: 6.083e-01, Validation Loss: 8.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8338, Training Loss: 6.083e-01, Validation Loss: 8.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8339, Training Loss: 6.082e-01, Validation Loss: 8.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8340, Training Loss: 6.081e-01, Validation Loss: 8.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8341, Training Loss: 6.080e-01, Validation Loss: 8.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8342, Training Loss: 6.080e-01, Validation Loss: 8.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8343, Training Loss: 6.079e-01, Validation Loss: 8.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8344, Training Loss: 6.078e-01, Validation Loss: 8.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8345, Training Loss: 6.078e-01, Validation Loss: 8.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8346, Training Loss: 6.077e-01, Validation Loss: 8.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8347, Training Loss: 6.076e-01, Validation Loss: 8.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8348, Training Loss: 6.076e-01, Validation Loss: 8.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8349, Training Loss: 6.075e-01, Validation Loss: 8.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8350, Training Loss: 6.074e-01, Validation Loss: 8.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8351, Training Loss: 6.074e-01, Validation Loss: 8.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8352, Training Loss: 6.073e-01, Validation Loss: 8.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8353, Training Loss: 6.072e-01, Validation Loss: 8.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8354, Training Loss: 6.072e-01, Validation Loss: 8.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8355, Training Loss: 6.071e-01, Validation Loss: 8.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8356, Training Loss: 6.070e-01, Validation Loss: 8.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8357, Training Loss: 6.070e-01, Validation Loss: 8.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8358, Training Loss: 6.069e-01, Validation Loss: 8.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8359, Training Loss: 6.068e-01, Validation Loss: 8.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8360, Training Loss: 6.068e-01, Validation Loss: 8.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8361, Training Loss: 6.067e-01, Validation Loss: 8.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8362, Training Loss: 6.066e-01, Validation Loss: 8.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8363, Training Loss: 6.066e-01, Validation Loss: 8.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8364, Training Loss: 6.065e-01, Validation Loss: 8.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8365, Training Loss: 6.064e-01, Validation Loss: 8.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8366, Training Loss: 6.064e-01, Validation Loss: 8.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8367, Training Loss: 6.063e-01, Validation Loss: 8.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8368, Training Loss: 6.062e-01, Validation Loss: 8.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8369, Training Loss: 6.061e-01, Validation Loss: 8.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8370, Training Loss: 6.061e-01, Validation Loss: 8.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8371, Training Loss: 6.060e-01, Validation Loss: 8.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8372, Training Loss: 6.059e-01, Validation Loss: 8.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8373, Training Loss: 6.059e-01, Validation Loss: 8.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8374, Training Loss: 6.058e-01, Validation Loss: 8.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8375, Training Loss: 6.057e-01, Validation Loss: 8.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8376, Training Loss: 6.057e-01, Validation Loss: 8.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8377, Training Loss: 6.056e-01, Validation Loss: 8.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8378, Training Loss: 6.055e-01, Validation Loss: 8.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8379, Training Loss: 6.055e-01, Validation Loss: 8.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8380, Training Loss: 6.054e-01, Validation Loss: 8.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8381, Training Loss: 6.053e-01, Validation Loss: 8.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8382, Training Loss: 6.053e-01, Validation Loss: 8.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8383, Training Loss: 6.052e-01, Validation Loss: 8.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8384, Training Loss: 6.051e-01, Validation Loss: 8.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8385, Training Loss: 6.051e-01, Validation Loss: 8.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8386, Training Loss: 6.050e-01, Validation Loss: 8.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8387, Training Loss: 6.049e-01, Validation Loss: 8.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8388, Training Loss: 6.049e-01, Validation Loss: 8.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8389, Training Loss: 6.048e-01, Validation Loss: 8.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8390, Training Loss: 6.047e-01, Validation Loss: 8.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8391, Training Loss: 6.047e-01, Validation Loss: 8.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8392, Training Loss: 6.046e-01, Validation Loss: 8.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8393, Training Loss: 6.045e-01, Validation Loss: 8.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8394, Training Loss: 6.045e-01, Validation Loss: 8.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8395, Training Loss: 6.044e-01, Validation Loss: 8.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8396, Training Loss: 6.043e-01, Validation Loss: 8.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8397, Training Loss: 6.043e-01, Validation Loss: 8.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8398, Training Loss: 6.042e-01, Validation Loss: 8.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8399, Training Loss: 6.041e-01, Validation Loss: 8.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8400, Training Loss: 6.041e-01, Validation Loss: 8.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8401, Training Loss: 6.040e-01, Validation Loss: 8.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8402, Training Loss: 6.039e-01, Validation Loss: 8.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8403, Training Loss: 6.039e-01, Validation Loss: 8.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8404, Training Loss: 6.038e-01, Validation Loss: 8.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8405, Training Loss: 6.037e-01, Validation Loss: 8.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8406, Training Loss: 6.037e-01, Validation Loss: 8.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8407, Training Loss: 6.036e-01, Validation Loss: 8.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8408, Training Loss: 6.035e-01, Validation Loss: 8.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8409, Training Loss: 6.034e-01, Validation Loss: 8.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8410, Training Loss: 6.034e-01, Validation Loss: 8.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8411, Training Loss: 6.033e-01, Validation Loss: 8.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8412, Training Loss: 6.032e-01, Validation Loss: 8.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8413, Training Loss: 6.032e-01, Validation Loss: 8.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8414, Training Loss: 6.031e-01, Validation Loss: 8.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8415, Training Loss: 6.030e-01, Validation Loss: 8.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8416, Training Loss: 6.030e-01, Validation Loss: 8.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8417, Training Loss: 6.029e-01, Validation Loss: 8.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8418, Training Loss: 6.028e-01, Validation Loss: 8.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8419, Training Loss: 6.028e-01, Validation Loss: 8.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8420, Training Loss: 6.027e-01, Validation Loss: 8.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8421, Training Loss: 6.026e-01, Validation Loss: 8.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8422, Training Loss: 6.026e-01, Validation Loss: 8.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8423, Training Loss: 6.025e-01, Validation Loss: 8.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8424, Training Loss: 6.024e-01, Validation Loss: 8.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8425, Training Loss: 6.024e-01, Validation Loss: 8.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8426, Training Loss: 6.023e-01, Validation Loss: 8.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8427, Training Loss: 6.022e-01, Validation Loss: 8.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8428, Training Loss: 6.022e-01, Validation Loss: 8.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8429, Training Loss: 6.021e-01, Validation Loss: 8.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8430, Training Loss: 6.020e-01, Validation Loss: 8.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8431, Training Loss: 6.020e-01, Validation Loss: 8.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8432, Training Loss: 6.019e-01, Validation Loss: 8.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8433, Training Loss: 6.018e-01, Validation Loss: 8.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8434, Training Loss: 6.018e-01, Validation Loss: 8.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8435, Training Loss: 6.017e-01, Validation Loss: 8.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8436, Training Loss: 6.016e-01, Validation Loss: 8.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8437, Training Loss: 6.016e-01, Validation Loss: 8.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8438, Training Loss: 6.015e-01, Validation Loss: 8.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8439, Training Loss: 6.014e-01, Validation Loss: 8.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8440, Training Loss: 6.014e-01, Validation Loss: 8.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8441, Training Loss: 6.013e-01, Validation Loss: 8.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8442, Training Loss: 6.012e-01, Validation Loss: 8.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8443, Training Loss: 6.012e-01, Validation Loss: 8.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8444, Training Loss: 6.011e-01, Validation Loss: 8.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8445, Training Loss: 6.010e-01, Validation Loss: 8.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8446, Training Loss: 6.010e-01, Validation Loss: 8.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8447, Training Loss: 6.009e-01, Validation Loss: 8.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8448, Training Loss: 6.008e-01, Validation Loss: 8.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8449, Training Loss: 6.008e-01, Validation Loss: 8.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8450, Training Loss: 6.007e-01, Validation Loss: 8.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8451, Training Loss: 6.006e-01, Validation Loss: 8.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8452, Training Loss: 6.006e-01, Validation Loss: 8.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8453, Training Loss: 6.005e-01, Validation Loss: 8.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8454, Training Loss: 6.004e-01, Validation Loss: 8.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8455, Training Loss: 6.004e-01, Validation Loss: 8.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8456, Training Loss: 6.003e-01, Validation Loss: 8.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8457, Training Loss: 6.002e-01, Validation Loss: 8.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8458, Training Loss: 6.002e-01, Validation Loss: 8.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8459, Training Loss: 6.001e-01, Validation Loss: 8.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8460, Training Loss: 6.000e-01, Validation Loss: 8.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8461, Training Loss: 6.000e-01, Validation Loss: 8.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8462, Training Loss: 5.999e-01, Validation Loss: 8.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8463, Training Loss: 5.998e-01, Validation Loss: 8.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8464, Training Loss: 5.998e-01, Validation Loss: 8.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8465, Training Loss: 5.997e-01, Validation Loss: 8.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8466, Training Loss: 5.996e-01, Validation Loss: 8.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8467, Training Loss: 5.996e-01, Validation Loss: 8.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8468, Training Loss: 5.995e-01, Validation Loss: 8.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8469, Training Loss: 5.994e-01, Validation Loss: 8.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8470, Training Loss: 5.994e-01, Validation Loss: 8.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8471, Training Loss: 5.993e-01, Validation Loss: 8.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8472, Training Loss: 5.992e-01, Validation Loss: 8.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8473, Training Loss: 5.992e-01, Validation Loss: 8.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8474, Training Loss: 5.991e-01, Validation Loss: 8.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8475, Training Loss: 5.990e-01, Validation Loss: 8.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8476, Training Loss: 5.990e-01, Validation Loss: 8.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8477, Training Loss: 5.989e-01, Validation Loss: 8.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8478, Training Loss: 5.988e-01, Validation Loss: 8.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8479, Training Loss: 5.988e-01, Validation Loss: 8.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8480, Training Loss: 5.987e-01, Validation Loss: 8.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8481, Training Loss: 5.986e-01, Validation Loss: 8.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8482, Training Loss: 5.986e-01, Validation Loss: 8.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8483, Training Loss: 5.985e-01, Validation Loss: 8.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8484, Training Loss: 5.984e-01, Validation Loss: 8.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8485, Training Loss: 5.984e-01, Validation Loss: 8.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8486, Training Loss: 5.983e-01, Validation Loss: 8.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8487, Training Loss: 5.982e-01, Validation Loss: 8.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8488, Training Loss: 5.982e-01, Validation Loss: 8.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8489, Training Loss: 5.981e-01, Validation Loss: 8.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8490, Training Loss: 5.980e-01, Validation Loss: 8.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8491, Training Loss: 5.980e-01, Validation Loss: 8.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8492, Training Loss: 5.979e-01, Validation Loss: 8.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8493, Training Loss: 5.979e-01, Validation Loss: 8.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8494, Training Loss: 5.978e-01, Validation Loss: 8.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8495, Training Loss: 5.977e-01, Validation Loss: 8.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8496, Training Loss: 5.977e-01, Validation Loss: 8.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8497, Training Loss: 5.976e-01, Validation Loss: 8.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8498, Training Loss: 5.975e-01, Validation Loss: 8.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8499, Training Loss: 5.975e-01, Validation Loss: 8.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8500, Training Loss: 5.974e-01, Validation Loss: 8.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8501, Training Loss: 5.973e-01, Validation Loss: 8.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8502, Training Loss: 5.973e-01, Validation Loss: 8.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8503, Training Loss: 5.972e-01, Validation Loss: 8.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8504, Training Loss: 5.971e-01, Validation Loss: 8.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8505, Training Loss: 5.971e-01, Validation Loss: 8.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8506, Training Loss: 5.970e-01, Validation Loss: 8.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8507, Training Loss: 5.969e-01, Validation Loss: 8.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8508, Training Loss: 5.969e-01, Validation Loss: 8.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8509, Training Loss: 5.968e-01, Validation Loss: 8.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8510, Training Loss: 5.967e-01, Validation Loss: 8.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8511, Training Loss: 5.967e-01, Validation Loss: 8.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8512, Training Loss: 5.966e-01, Validation Loss: 8.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8513, Training Loss: 5.965e-01, Validation Loss: 8.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8514, Training Loss: 5.965e-01, Validation Loss: 8.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8515, Training Loss: 5.964e-01, Validation Loss: 8.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8516, Training Loss: 5.963e-01, Validation Loss: 8.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8517, Training Loss: 5.963e-01, Validation Loss: 8.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8518, Training Loss: 5.962e-01, Validation Loss: 8.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8519, Training Loss: 5.961e-01, Validation Loss: 8.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8520, Training Loss: 5.961e-01, Validation Loss: 8.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8521, Training Loss: 5.960e-01, Validation Loss: 8.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8522, Training Loss: 5.959e-01, Validation Loss: 8.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8523, Training Loss: 5.959e-01, Validation Loss: 8.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8524, Training Loss: 5.958e-01, Validation Loss: 8.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8525, Training Loss: 5.957e-01, Validation Loss: 8.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8526, Training Loss: 5.957e-01, Validation Loss: 8.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8527, Training Loss: 5.956e-01, Validation Loss: 8.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8528, Training Loss: 5.955e-01, Validation Loss: 8.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8529, Training Loss: 5.955e-01, Validation Loss: 8.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8530, Training Loss: 5.954e-01, Validation Loss: 8.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8531, Training Loss: 5.953e-01, Validation Loss: 8.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8532, Training Loss: 5.953e-01, Validation Loss: 8.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8533, Training Loss: 5.952e-01, Validation Loss: 8.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8534, Training Loss: 5.951e-01, Validation Loss: 8.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8535, Training Loss: 5.951e-01, Validation Loss: 8.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8536, Training Loss: 5.950e-01, Validation Loss: 8.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8537, Training Loss: 5.950e-01, Validation Loss: 8.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8538, Training Loss: 5.949e-01, Validation Loss: 8.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8539, Training Loss: 5.948e-01, Validation Loss: 8.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8540, Training Loss: 5.948e-01, Validation Loss: 8.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8541, Training Loss: 5.947e-01, Validation Loss: 8.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8542, Training Loss: 5.946e-01, Validation Loss: 8.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8543, Training Loss: 5.946e-01, Validation Loss: 8.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8544, Training Loss: 5.945e-01, Validation Loss: 8.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8545, Training Loss: 5.944e-01, Validation Loss: 8.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8546, Training Loss: 5.944e-01, Validation Loss: 8.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8547, Training Loss: 5.943e-01, Validation Loss: 8.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8548, Training Loss: 5.942e-01, Validation Loss: 8.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8549, Training Loss: 5.942e-01, Validation Loss: 8.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8550, Training Loss: 5.941e-01, Validation Loss: 8.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8551, Training Loss: 5.940e-01, Validation Loss: 8.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8552, Training Loss: 5.940e-01, Validation Loss: 8.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8553, Training Loss: 5.939e-01, Validation Loss: 8.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8554, Training Loss: 5.938e-01, Validation Loss: 8.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8555, Training Loss: 5.938e-01, Validation Loss: 8.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8556, Training Loss: 5.937e-01, Validation Loss: 8.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8557, Training Loss: 5.936e-01, Validation Loss: 8.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8558, Training Loss: 5.936e-01, Validation Loss: 8.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8559, Training Loss: 5.935e-01, Validation Loss: 8.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8560, Training Loss: 5.934e-01, Validation Loss: 8.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8561, Training Loss: 5.934e-01, Validation Loss: 8.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8562, Training Loss: 5.933e-01, Validation Loss: 8.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8563, Training Loss: 5.933e-01, Validation Loss: 8.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8564, Training Loss: 5.932e-01, Validation Loss: 8.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8565, Training Loss: 5.931e-01, Validation Loss: 8.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8566, Training Loss: 5.931e-01, Validation Loss: 8.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8567, Training Loss: 5.930e-01, Validation Loss: 8.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8568, Training Loss: 5.929e-01, Validation Loss: 8.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8569, Training Loss: 5.929e-01, Validation Loss: 8.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8570, Training Loss: 5.928e-01, Validation Loss: 8.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8571, Training Loss: 5.927e-01, Validation Loss: 8.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8572, Training Loss: 5.927e-01, Validation Loss: 8.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8573, Training Loss: 5.926e-01, Validation Loss: 8.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8574, Training Loss: 5.925e-01, Validation Loss: 8.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8575, Training Loss: 5.925e-01, Validation Loss: 7.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8576, Training Loss: 5.924e-01, Validation Loss: 7.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8577, Training Loss: 5.923e-01, Validation Loss: 7.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8578, Training Loss: 5.923e-01, Validation Loss: 7.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8579, Training Loss: 5.922e-01, Validation Loss: 7.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8580, Training Loss: 5.921e-01, Validation Loss: 7.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8581, Training Loss: 5.921e-01, Validation Loss: 7.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8582, Training Loss: 5.920e-01, Validation Loss: 7.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8583, Training Loss: 5.919e-01, Validation Loss: 7.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8584, Training Loss: 5.919e-01, Validation Loss: 7.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8585, Training Loss: 5.918e-01, Validation Loss: 7.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8586, Training Loss: 5.918e-01, Validation Loss: 7.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8587, Training Loss: 5.917e-01, Validation Loss: 7.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8588, Training Loss: 5.916e-01, Validation Loss: 7.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8589, Training Loss: 5.916e-01, Validation Loss: 7.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8590, Training Loss: 5.915e-01, Validation Loss: 7.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8591, Training Loss: 5.914e-01, Validation Loss: 7.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8592, Training Loss: 5.914e-01, Validation Loss: 7.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8593, Training Loss: 5.913e-01, Validation Loss: 7.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8594, Training Loss: 5.912e-01, Validation Loss: 7.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8595, Training Loss: 5.912e-01, Validation Loss: 7.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8596, Training Loss: 5.911e-01, Validation Loss: 7.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8597, Training Loss: 5.910e-01, Validation Loss: 7.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8598, Training Loss: 5.910e-01, Validation Loss: 7.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8599, Training Loss: 5.909e-01, Validation Loss: 7.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8600, Training Loss: 5.908e-01, Validation Loss: 7.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8601, Training Loss: 5.908e-01, Validation Loss: 7.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8602, Training Loss: 5.907e-01, Validation Loss: 7.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8603, Training Loss: 5.906e-01, Validation Loss: 7.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8604, Training Loss: 5.906e-01, Validation Loss: 7.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8605, Training Loss: 5.905e-01, Validation Loss: 7.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8606, Training Loss: 5.905e-01, Validation Loss: 7.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8607, Training Loss: 5.904e-01, Validation Loss: 7.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8608, Training Loss: 5.903e-01, Validation Loss: 7.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8609, Training Loss: 5.903e-01, Validation Loss: 7.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8610, Training Loss: 5.902e-01, Validation Loss: 7.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8611, Training Loss: 5.901e-01, Validation Loss: 7.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8612, Training Loss: 5.901e-01, Validation Loss: 7.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8613, Training Loss: 5.900e-01, Validation Loss: 7.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8614, Training Loss: 5.899e-01, Validation Loss: 7.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8615, Training Loss: 5.899e-01, Validation Loss: 7.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8616, Training Loss: 5.898e-01, Validation Loss: 7.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8617, Training Loss: 5.897e-01, Validation Loss: 7.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8618, Training Loss: 5.897e-01, Validation Loss: 7.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8619, Training Loss: 5.896e-01, Validation Loss: 7.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8620, Training Loss: 5.895e-01, Validation Loss: 7.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8621, Training Loss: 5.895e-01, Validation Loss: 7.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8622, Training Loss: 5.894e-01, Validation Loss: 7.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8623, Training Loss: 5.894e-01, Validation Loss: 7.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8624, Training Loss: 5.893e-01, Validation Loss: 7.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8625, Training Loss: 5.892e-01, Validation Loss: 7.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8626, Training Loss: 5.892e-01, Validation Loss: 7.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8627, Training Loss: 5.891e-01, Validation Loss: 7.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8628, Training Loss: 5.890e-01, Validation Loss: 7.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8629, Training Loss: 5.890e-01, Validation Loss: 7.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8630, Training Loss: 5.889e-01, Validation Loss: 7.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8631, Training Loss: 5.888e-01, Validation Loss: 7.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8632, Training Loss: 5.888e-01, Validation Loss: 7.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8633, Training Loss: 5.887e-01, Validation Loss: 7.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8634, Training Loss: 5.886e-01, Validation Loss: 7.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8635, Training Loss: 5.886e-01, Validation Loss: 7.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8636, Training Loss: 5.885e-01, Validation Loss: 7.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8637, Training Loss: 5.885e-01, Validation Loss: 7.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8638, Training Loss: 5.884e-01, Validation Loss: 7.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8639, Training Loss: 5.883e-01, Validation Loss: 7.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8640, Training Loss: 5.883e-01, Validation Loss: 7.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8641, Training Loss: 5.882e-01, Validation Loss: 7.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8642, Training Loss: 5.881e-01, Validation Loss: 7.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8643, Training Loss: 5.881e-01, Validation Loss: 7.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8644, Training Loss: 5.880e-01, Validation Loss: 7.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8645, Training Loss: 5.879e-01, Validation Loss: 7.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8646, Training Loss: 5.879e-01, Validation Loss: 7.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8647, Training Loss: 5.878e-01, Validation Loss: 7.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8648, Training Loss: 5.877e-01, Validation Loss: 7.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8649, Training Loss: 5.877e-01, Validation Loss: 7.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8650, Training Loss: 5.876e-01, Validation Loss: 7.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8651, Training Loss: 5.876e-01, Validation Loss: 7.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8652, Training Loss: 5.875e-01, Validation Loss: 7.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8653, Training Loss: 5.874e-01, Validation Loss: 7.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8654, Training Loss: 5.874e-01, Validation Loss: 7.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8655, Training Loss: 5.873e-01, Validation Loss: 7.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8656, Training Loss: 5.872e-01, Validation Loss: 7.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8657, Training Loss: 5.872e-01, Validation Loss: 7.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8658, Training Loss: 5.871e-01, Validation Loss: 7.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8659, Training Loss: 5.870e-01, Validation Loss: 7.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8660, Training Loss: 5.870e-01, Validation Loss: 7.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8661, Training Loss: 5.869e-01, Validation Loss: 7.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8662, Training Loss: 5.868e-01, Validation Loss: 7.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8663, Training Loss: 5.868e-01, Validation Loss: 7.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8664, Training Loss: 5.867e-01, Validation Loss: 7.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8665, Training Loss: 5.867e-01, Validation Loss: 7.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8666, Training Loss: 5.866e-01, Validation Loss: 7.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8667, Training Loss: 5.865e-01, Validation Loss: 7.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8668, Training Loss: 5.865e-01, Validation Loss: 7.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8669, Training Loss: 5.864e-01, Validation Loss: 7.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8670, Training Loss: 5.863e-01, Validation Loss: 7.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8671, Training Loss: 5.863e-01, Validation Loss: 7.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8672, Training Loss: 5.862e-01, Validation Loss: 7.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8673, Training Loss: 5.861e-01, Validation Loss: 7.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8674, Training Loss: 5.861e-01, Validation Loss: 7.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8675, Training Loss: 5.860e-01, Validation Loss: 7.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8676, Training Loss: 5.860e-01, Validation Loss: 7.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8677, Training Loss: 5.859e-01, Validation Loss: 7.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8678, Training Loss: 5.858e-01, Validation Loss: 7.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8679, Training Loss: 5.858e-01, Validation Loss: 7.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8680, Training Loss: 5.857e-01, Validation Loss: 7.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8681, Training Loss: 5.856e-01, Validation Loss: 7.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8682, Training Loss: 5.856e-01, Validation Loss: 7.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8683, Training Loss: 5.855e-01, Validation Loss: 7.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8684, Training Loss: 5.854e-01, Validation Loss: 7.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8685, Training Loss: 5.854e-01, Validation Loss: 7.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8686, Training Loss: 5.853e-01, Validation Loss: 7.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8687, Training Loss: 5.853e-01, Validation Loss: 7.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8688, Training Loss: 5.852e-01, Validation Loss: 7.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8689, Training Loss: 5.851e-01, Validation Loss: 7.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8690, Training Loss: 5.851e-01, Validation Loss: 7.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8691, Training Loss: 5.850e-01, Validation Loss: 7.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8692, Training Loss: 5.849e-01, Validation Loss: 7.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8693, Training Loss: 5.849e-01, Validation Loss: 7.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8694, Training Loss: 5.848e-01, Validation Loss: 7.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8695, Training Loss: 5.847e-01, Validation Loss: 7.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8696, Training Loss: 5.847e-01, Validation Loss: 7.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8697, Training Loss: 5.846e-01, Validation Loss: 7.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8698, Training Loss: 5.846e-01, Validation Loss: 7.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8699, Training Loss: 5.845e-01, Validation Loss: 7.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8700, Training Loss: 5.844e-01, Validation Loss: 7.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8701, Training Loss: 5.844e-01, Validation Loss: 7.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8702, Training Loss: 5.843e-01, Validation Loss: 7.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8703, Training Loss: 5.842e-01, Validation Loss: 7.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8704, Training Loss: 5.842e-01, Validation Loss: 7.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8705, Training Loss: 5.841e-01, Validation Loss: 7.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8706, Training Loss: 5.840e-01, Validation Loss: 7.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8707, Training Loss: 5.840e-01, Validation Loss: 7.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8708, Training Loss: 5.839e-01, Validation Loss: 7.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8709, Training Loss: 5.839e-01, Validation Loss: 7.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8710, Training Loss: 5.838e-01, Validation Loss: 7.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8711, Training Loss: 5.837e-01, Validation Loss: 7.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8712, Training Loss: 5.837e-01, Validation Loss: 7.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8713, Training Loss: 5.836e-01, Validation Loss: 7.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8714, Training Loss: 5.835e-01, Validation Loss: 7.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8715, Training Loss: 5.835e-01, Validation Loss: 7.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8716, Training Loss: 5.834e-01, Validation Loss: 7.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8717, Training Loss: 5.833e-01, Validation Loss: 7.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8718, Training Loss: 5.833e-01, Validation Loss: 7.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8719, Training Loss: 5.832e-01, Validation Loss: 7.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8720, Training Loss: 5.832e-01, Validation Loss: 7.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8721, Training Loss: 5.831e-01, Validation Loss: 7.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8722, Training Loss: 5.830e-01, Validation Loss: 7.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8723, Training Loss: 5.830e-01, Validation Loss: 7.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8724, Training Loss: 5.829e-01, Validation Loss: 7.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8725, Training Loss: 5.828e-01, Validation Loss: 7.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8726, Training Loss: 5.828e-01, Validation Loss: 7.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8727, Training Loss: 5.827e-01, Validation Loss: 7.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8728, Training Loss: 5.826e-01, Validation Loss: 7.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8729, Training Loss: 5.826e-01, Validation Loss: 7.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8730, Training Loss: 5.825e-01, Validation Loss: 7.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8731, Training Loss: 5.825e-01, Validation Loss: 7.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8732, Training Loss: 5.824e-01, Validation Loss: 7.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8733, Training Loss: 5.823e-01, Validation Loss: 7.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8734, Training Loss: 5.823e-01, Validation Loss: 7.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8735, Training Loss: 5.822e-01, Validation Loss: 7.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8736, Training Loss: 5.821e-01, Validation Loss: 7.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8737, Training Loss: 5.821e-01, Validation Loss: 7.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8738, Training Loss: 5.820e-01, Validation Loss: 7.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8739, Training Loss: 5.820e-01, Validation Loss: 7.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8740, Training Loss: 5.819e-01, Validation Loss: 7.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8741, Training Loss: 5.818e-01, Validation Loss: 7.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8742, Training Loss: 5.818e-01, Validation Loss: 7.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8743, Training Loss: 5.817e-01, Validation Loss: 7.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8744, Training Loss: 5.816e-01, Validation Loss: 7.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8745, Training Loss: 5.816e-01, Validation Loss: 7.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8746, Training Loss: 5.815e-01, Validation Loss: 7.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8747, Training Loss: 5.815e-01, Validation Loss: 7.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8748, Training Loss: 5.814e-01, Validation Loss: 7.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8749, Training Loss: 5.813e-01, Validation Loss: 7.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8750, Training Loss: 5.813e-01, Validation Loss: 7.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8751, Training Loss: 5.812e-01, Validation Loss: 7.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8752, Training Loss: 5.811e-01, Validation Loss: 7.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8753, Training Loss: 5.811e-01, Validation Loss: 7.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8754, Training Loss: 5.810e-01, Validation Loss: 7.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8755, Training Loss: 5.809e-01, Validation Loss: 7.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8756, Training Loss: 5.809e-01, Validation Loss: 7.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8757, Training Loss: 5.808e-01, Validation Loss: 7.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8758, Training Loss: 5.808e-01, Validation Loss: 7.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8759, Training Loss: 5.807e-01, Validation Loss: 7.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8760, Training Loss: 5.806e-01, Validation Loss: 7.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8761, Training Loss: 5.806e-01, Validation Loss: 7.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8762, Training Loss: 5.805e-01, Validation Loss: 7.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8763, Training Loss: 5.804e-01, Validation Loss: 7.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8764, Training Loss: 5.804e-01, Validation Loss: 7.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8765, Training Loss: 5.803e-01, Validation Loss: 7.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8766, Training Loss: 5.803e-01, Validation Loss: 7.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8767, Training Loss: 5.802e-01, Validation Loss: 7.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8768, Training Loss: 5.801e-01, Validation Loss: 7.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8769, Training Loss: 5.801e-01, Validation Loss: 7.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8770, Training Loss: 5.800e-01, Validation Loss: 7.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8771, Training Loss: 5.799e-01, Validation Loss: 7.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8772, Training Loss: 5.799e-01, Validation Loss: 7.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8773, Training Loss: 5.798e-01, Validation Loss: 7.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8774, Training Loss: 5.798e-01, Validation Loss: 7.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8775, Training Loss: 5.797e-01, Validation Loss: 7.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8776, Training Loss: 5.796e-01, Validation Loss: 7.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8777, Training Loss: 5.796e-01, Validation Loss: 7.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8778, Training Loss: 5.795e-01, Validation Loss: 7.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8779, Training Loss: 5.794e-01, Validation Loss: 7.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8780, Training Loss: 5.794e-01, Validation Loss: 7.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8781, Training Loss: 5.793e-01, Validation Loss: 7.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8782, Training Loss: 5.793e-01, Validation Loss: 7.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8783, Training Loss: 5.792e-01, Validation Loss: 7.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8784, Training Loss: 5.791e-01, Validation Loss: 7.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8785, Training Loss: 5.791e-01, Validation Loss: 7.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8786, Training Loss: 5.790e-01, Validation Loss: 7.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8787, Training Loss: 5.789e-01, Validation Loss: 7.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8788, Training Loss: 5.789e-01, Validation Loss: 7.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8789, Training Loss: 5.788e-01, Validation Loss: 7.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8790, Training Loss: 5.788e-01, Validation Loss: 7.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8791, Training Loss: 5.787e-01, Validation Loss: 7.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8792, Training Loss: 5.786e-01, Validation Loss: 7.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8793, Training Loss: 5.786e-01, Validation Loss: 7.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8794, Training Loss: 5.785e-01, Validation Loss: 7.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8795, Training Loss: 5.784e-01, Validation Loss: 7.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8796, Training Loss: 5.784e-01, Validation Loss: 7.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8797, Training Loss: 5.783e-01, Validation Loss: 7.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8798, Training Loss: 5.783e-01, Validation Loss: 7.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8799, Training Loss: 5.782e-01, Validation Loss: 7.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8800, Training Loss: 5.781e-01, Validation Loss: 7.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8801, Training Loss: 5.781e-01, Validation Loss: 7.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8802, Training Loss: 5.780e-01, Validation Loss: 7.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8803, Training Loss: 5.779e-01, Validation Loss: 7.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8804, Training Loss: 5.779e-01, Validation Loss: 7.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8805, Training Loss: 5.778e-01, Validation Loss: 7.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8806, Training Loss: 5.778e-01, Validation Loss: 7.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8807, Training Loss: 5.777e-01, Validation Loss: 7.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8808, Training Loss: 5.776e-01, Validation Loss: 7.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8809, Training Loss: 5.776e-01, Validation Loss: 7.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8810, Training Loss: 5.775e-01, Validation Loss: 7.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8811, Training Loss: 5.774e-01, Validation Loss: 7.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8812, Training Loss: 5.774e-01, Validation Loss: 7.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8813, Training Loss: 5.773e-01, Validation Loss: 7.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8814, Training Loss: 5.773e-01, Validation Loss: 7.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8815, Training Loss: 5.772e-01, Validation Loss: 7.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8816, Training Loss: 5.771e-01, Validation Loss: 7.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8817, Training Loss: 5.771e-01, Validation Loss: 7.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8818, Training Loss: 5.770e-01, Validation Loss: 7.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8819, Training Loss: 5.769e-01, Validation Loss: 7.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8820, Training Loss: 5.769e-01, Validation Loss: 7.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8821, Training Loss: 5.768e-01, Validation Loss: 7.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8822, Training Loss: 5.768e-01, Validation Loss: 7.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8823, Training Loss: 5.767e-01, Validation Loss: 7.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8824, Training Loss: 5.766e-01, Validation Loss: 7.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8825, Training Loss: 5.766e-01, Validation Loss: 7.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8826, Training Loss: 5.765e-01, Validation Loss: 7.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8827, Training Loss: 5.764e-01, Validation Loss: 7.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8828, Training Loss: 5.764e-01, Validation Loss: 7.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8829, Training Loss: 5.763e-01, Validation Loss: 7.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8830, Training Loss: 5.763e-01, Validation Loss: 7.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8831, Training Loss: 5.762e-01, Validation Loss: 7.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8832, Training Loss: 5.761e-01, Validation Loss: 7.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8833, Training Loss: 5.761e-01, Validation Loss: 7.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8834, Training Loss: 5.760e-01, Validation Loss: 7.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8835, Training Loss: 5.760e-01, Validation Loss: 7.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8836, Training Loss: 5.759e-01, Validation Loss: 7.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8837, Training Loss: 5.758e-01, Validation Loss: 7.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8838, Training Loss: 5.758e-01, Validation Loss: 7.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8839, Training Loss: 5.757e-01, Validation Loss: 7.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8840, Training Loss: 5.756e-01, Validation Loss: 7.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8841, Training Loss: 5.756e-01, Validation Loss: 7.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8842, Training Loss: 5.755e-01, Validation Loss: 7.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8843, Training Loss: 5.755e-01, Validation Loss: 7.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8844, Training Loss: 5.754e-01, Validation Loss: 7.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8845, Training Loss: 5.753e-01, Validation Loss: 7.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8846, Training Loss: 5.753e-01, Validation Loss: 7.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8847, Training Loss: 5.752e-01, Validation Loss: 7.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8848, Training Loss: 5.751e-01, Validation Loss: 7.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8849, Training Loss: 5.751e-01, Validation Loss: 7.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8850, Training Loss: 5.750e-01, Validation Loss: 7.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8851, Training Loss: 5.750e-01, Validation Loss: 7.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8852, Training Loss: 5.749e-01, Validation Loss: 7.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8853, Training Loss: 5.748e-01, Validation Loss: 7.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8854, Training Loss: 5.748e-01, Validation Loss: 7.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8855, Training Loss: 5.747e-01, Validation Loss: 7.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8856, Training Loss: 5.747e-01, Validation Loss: 7.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8857, Training Loss: 5.746e-01, Validation Loss: 7.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8858, Training Loss: 5.745e-01, Validation Loss: 7.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8859, Training Loss: 5.745e-01, Validation Loss: 7.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8860, Training Loss: 5.744e-01, Validation Loss: 7.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8861, Training Loss: 5.743e-01, Validation Loss: 7.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8862, Training Loss: 5.743e-01, Validation Loss: 7.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8863, Training Loss: 5.742e-01, Validation Loss: 7.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8864, Training Loss: 5.742e-01, Validation Loss: 7.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8865, Training Loss: 5.741e-01, Validation Loss: 7.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8866, Training Loss: 5.740e-01, Validation Loss: 7.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8867, Training Loss: 5.740e-01, Validation Loss: 7.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8868, Training Loss: 5.739e-01, Validation Loss: 7.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8869, Training Loss: 5.739e-01, Validation Loss: 7.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8870, Training Loss: 5.738e-01, Validation Loss: 7.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8871, Training Loss: 5.737e-01, Validation Loss: 7.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8872, Training Loss: 5.737e-01, Validation Loss: 7.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8873, Training Loss: 5.736e-01, Validation Loss: 7.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8874, Training Loss: 5.735e-01, Validation Loss: 7.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8875, Training Loss: 5.735e-01, Validation Loss: 7.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8876, Training Loss: 5.734e-01, Validation Loss: 7.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8877, Training Loss: 5.734e-01, Validation Loss: 7.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8878, Training Loss: 5.733e-01, Validation Loss: 7.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8879, Training Loss: 5.732e-01, Validation Loss: 7.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8880, Training Loss: 5.732e-01, Validation Loss: 7.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8881, Training Loss: 5.731e-01, Validation Loss: 7.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8882, Training Loss: 5.731e-01, Validation Loss: 7.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8883, Training Loss: 5.730e-01, Validation Loss: 7.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8884, Training Loss: 5.729e-01, Validation Loss: 7.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8885, Training Loss: 5.729e-01, Validation Loss: 7.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8886, Training Loss: 5.728e-01, Validation Loss: 7.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8887, Training Loss: 5.727e-01, Validation Loss: 7.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8888, Training Loss: 5.727e-01, Validation Loss: 7.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8889, Training Loss: 5.726e-01, Validation Loss: 7.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8890, Training Loss: 5.726e-01, Validation Loss: 7.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8891, Training Loss: 5.725e-01, Validation Loss: 7.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8892, Training Loss: 5.724e-01, Validation Loss: 7.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8893, Training Loss: 5.724e-01, Validation Loss: 7.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8894, Training Loss: 5.723e-01, Validation Loss: 7.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8895, Training Loss: 5.723e-01, Validation Loss: 7.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8896, Training Loss: 5.722e-01, Validation Loss: 7.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8897, Training Loss: 5.721e-01, Validation Loss: 7.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8898, Training Loss: 5.721e-01, Validation Loss: 7.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8899, Training Loss: 5.720e-01, Validation Loss: 7.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8900, Training Loss: 5.719e-01, Validation Loss: 7.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8901, Training Loss: 5.719e-01, Validation Loss: 7.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8902, Training Loss: 5.718e-01, Validation Loss: 7.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8903, Training Loss: 5.718e-01, Validation Loss: 7.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8904, Training Loss: 5.717e-01, Validation Loss: 7.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8905, Training Loss: 5.716e-01, Validation Loss: 7.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8906, Training Loss: 5.716e-01, Validation Loss: 7.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8907, Training Loss: 5.715e-01, Validation Loss: 7.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8908, Training Loss: 5.715e-01, Validation Loss: 7.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8909, Training Loss: 5.714e-01, Validation Loss: 7.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8910, Training Loss: 5.713e-01, Validation Loss: 7.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8911, Training Loss: 5.713e-01, Validation Loss: 7.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8912, Training Loss: 5.712e-01, Validation Loss: 7.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8913, Training Loss: 5.712e-01, Validation Loss: 7.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8914, Training Loss: 5.711e-01, Validation Loss: 7.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8915, Training Loss: 5.710e-01, Validation Loss: 7.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8916, Training Loss: 5.710e-01, Validation Loss: 7.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8917, Training Loss: 5.709e-01, Validation Loss: 7.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8918, Training Loss: 5.708e-01, Validation Loss: 7.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8919, Training Loss: 5.708e-01, Validation Loss: 7.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8920, Training Loss: 5.707e-01, Validation Loss: 7.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8921, Training Loss: 5.707e-01, Validation Loss: 7.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8922, Training Loss: 5.706e-01, Validation Loss: 7.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8923, Training Loss: 5.705e-01, Validation Loss: 7.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8924, Training Loss: 5.705e-01, Validation Loss: 7.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8925, Training Loss: 5.704e-01, Validation Loss: 7.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8926, Training Loss: 5.704e-01, Validation Loss: 7.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8927, Training Loss: 5.703e-01, Validation Loss: 7.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8928, Training Loss: 5.702e-01, Validation Loss: 7.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8929, Training Loss: 5.702e-01, Validation Loss: 7.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8930, Training Loss: 5.701e-01, Validation Loss: 7.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8931, Training Loss: 5.701e-01, Validation Loss: 7.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8932, Training Loss: 5.700e-01, Validation Loss: 7.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8933, Training Loss: 5.699e-01, Validation Loss: 7.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8934, Training Loss: 5.699e-01, Validation Loss: 7.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8935, Training Loss: 5.698e-01, Validation Loss: 7.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8936, Training Loss: 5.698e-01, Validation Loss: 7.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8937, Training Loss: 5.697e-01, Validation Loss: 7.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8938, Training Loss: 5.696e-01, Validation Loss: 7.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8939, Training Loss: 5.696e-01, Validation Loss: 7.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8940, Training Loss: 5.695e-01, Validation Loss: 7.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8941, Training Loss: 5.694e-01, Validation Loss: 7.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8942, Training Loss: 5.694e-01, Validation Loss: 7.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8943, Training Loss: 5.693e-01, Validation Loss: 7.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8944, Training Loss: 5.693e-01, Validation Loss: 7.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8945, Training Loss: 5.692e-01, Validation Loss: 7.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8946, Training Loss: 5.691e-01, Validation Loss: 7.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8947, Training Loss: 5.691e-01, Validation Loss: 7.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8948, Training Loss: 5.690e-01, Validation Loss: 7.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8949, Training Loss: 5.690e-01, Validation Loss: 7.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8950, Training Loss: 5.689e-01, Validation Loss: 7.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8951, Training Loss: 5.688e-01, Validation Loss: 7.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8952, Training Loss: 5.688e-01, Validation Loss: 7.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8953, Training Loss: 5.687e-01, Validation Loss: 7.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8954, Training Loss: 5.687e-01, Validation Loss: 7.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8955, Training Loss: 5.686e-01, Validation Loss: 7.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8956, Training Loss: 5.685e-01, Validation Loss: 7.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8957, Training Loss: 5.685e-01, Validation Loss: 7.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8958, Training Loss: 5.684e-01, Validation Loss: 7.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8959, Training Loss: 5.684e-01, Validation Loss: 7.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8960, Training Loss: 5.683e-01, Validation Loss: 7.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8961, Training Loss: 5.682e-01, Validation Loss: 7.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8962, Training Loss: 5.682e-01, Validation Loss: 7.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8963, Training Loss: 5.681e-01, Validation Loss: 7.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8964, Training Loss: 5.680e-01, Validation Loss: 7.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8965, Training Loss: 5.680e-01, Validation Loss: 7.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8966, Training Loss: 5.679e-01, Validation Loss: 7.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8967, Training Loss: 5.679e-01, Validation Loss: 7.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8968, Training Loss: 5.678e-01, Validation Loss: 7.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8969, Training Loss: 5.677e-01, Validation Loss: 7.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8970, Training Loss: 5.677e-01, Validation Loss: 7.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8971, Training Loss: 5.676e-01, Validation Loss: 7.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8972, Training Loss: 5.675e-01, Validation Loss: 7.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8973, Training Loss: 5.675e-01, Validation Loss: 7.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8974, Training Loss: 5.674e-01, Validation Loss: 7.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8975, Training Loss: 5.674e-01, Validation Loss: 7.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8976, Training Loss: 5.673e-01, Validation Loss: 7.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8977, Training Loss: 5.672e-01, Validation Loss: 7.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8978, Training Loss: 5.672e-01, Validation Loss: 7.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8979, Training Loss: 5.671e-01, Validation Loss: 7.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8980, Training Loss: 5.671e-01, Validation Loss: 7.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8981, Training Loss: 5.670e-01, Validation Loss: 7.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8982, Training Loss: 5.669e-01, Validation Loss: 7.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8983, Training Loss: 5.669e-01, Validation Loss: 7.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8984, Training Loss: 5.668e-01, Validation Loss: 7.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8985, Training Loss: 5.667e-01, Validation Loss: 7.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8986, Training Loss: 5.667e-01, Validation Loss: 7.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8987, Training Loss: 5.666e-01, Validation Loss: 7.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8988, Training Loss: 5.666e-01, Validation Loss: 7.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8989, Training Loss: 5.665e-01, Validation Loss: 7.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8990, Training Loss: 5.664e-01, Validation Loss: 7.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8991, Training Loss: 5.664e-01, Validation Loss: 7.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8992, Training Loss: 5.663e-01, Validation Loss: 7.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8993, Training Loss: 5.662e-01, Validation Loss: 7.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8994, Training Loss: 5.662e-01, Validation Loss: 7.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8995, Training Loss: 5.661e-01, Validation Loss: 7.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8996, Training Loss: 5.661e-01, Validation Loss: 7.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8997, Training Loss: 5.660e-01, Validation Loss: 7.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8998, Training Loss: 5.659e-01, Validation Loss: 7.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8999, Training Loss: 5.659e-01, Validation Loss: 7.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9000, Training Loss: 5.658e-01, Validation Loss: 7.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9001, Training Loss: 5.658e-01, Validation Loss: 7.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9002, Training Loss: 5.657e-01, Validation Loss: 7.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9003, Training Loss: 5.656e-01, Validation Loss: 7.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9004, Training Loss: 5.656e-01, Validation Loss: 7.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9005, Training Loss: 5.655e-01, Validation Loss: 7.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9006, Training Loss: 5.654e-01, Validation Loss: 7.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9007, Training Loss: 5.654e-01, Validation Loss: 7.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9008, Training Loss: 5.653e-01, Validation Loss: 7.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9009, Training Loss: 5.653e-01, Validation Loss: 7.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9010, Training Loss: 5.652e-01, Validation Loss: 7.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9011, Training Loss: 5.651e-01, Validation Loss: 7.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9012, Training Loss: 5.651e-01, Validation Loss: 7.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9013, Training Loss: 5.650e-01, Validation Loss: 7.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9014, Training Loss: 5.650e-01, Validation Loss: 7.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9015, Training Loss: 5.649e-01, Validation Loss: 7.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9016, Training Loss: 5.648e-01, Validation Loss: 7.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9017, Training Loss: 5.648e-01, Validation Loss: 7.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9018, Training Loss: 5.647e-01, Validation Loss: 7.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9019, Training Loss: 5.646e-01, Validation Loss: 7.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9020, Training Loss: 5.646e-01, Validation Loss: 7.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9021, Training Loss: 5.645e-01, Validation Loss: 7.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9022, Training Loss: 5.645e-01, Validation Loss: 7.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9023, Training Loss: 5.644e-01, Validation Loss: 7.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9024, Training Loss: 5.643e-01, Validation Loss: 7.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9025, Training Loss: 5.643e-01, Validation Loss: 7.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9026, Training Loss: 5.642e-01, Validation Loss: 7.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9027, Training Loss: 5.642e-01, Validation Loss: 7.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9028, Training Loss: 5.641e-01, Validation Loss: 7.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9029, Training Loss: 5.640e-01, Validation Loss: 7.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9030, Training Loss: 5.640e-01, Validation Loss: 7.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9031, Training Loss: 5.639e-01, Validation Loss: 7.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9032, Training Loss: 5.639e-01, Validation Loss: 7.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9033, Training Loss: 5.638e-01, Validation Loss: 7.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9034, Training Loss: 5.637e-01, Validation Loss: 7.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9035, Training Loss: 5.637e-01, Validation Loss: 7.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9036, Training Loss: 5.636e-01, Validation Loss: 7.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9037, Training Loss: 5.635e-01, Validation Loss: 7.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9038, Training Loss: 5.635e-01, Validation Loss: 7.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9039, Training Loss: 5.634e-01, Validation Loss: 7.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9040, Training Loss: 5.634e-01, Validation Loss: 7.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9041, Training Loss: 5.633e-01, Validation Loss: 7.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9042, Training Loss: 5.632e-01, Validation Loss: 7.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9043, Training Loss: 5.632e-01, Validation Loss: 7.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9044, Training Loss: 5.631e-01, Validation Loss: 7.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9045, Training Loss: 5.631e-01, Validation Loss: 7.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9046, Training Loss: 5.630e-01, Validation Loss: 7.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9047, Training Loss: 5.629e-01, Validation Loss: 7.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9048, Training Loss: 5.629e-01, Validation Loss: 7.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9049, Training Loss: 5.628e-01, Validation Loss: 7.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9050, Training Loss: 5.628e-01, Validation Loss: 7.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9051, Training Loss: 5.627e-01, Validation Loss: 7.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9052, Training Loss: 5.626e-01, Validation Loss: 7.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9053, Training Loss: 5.626e-01, Validation Loss: 7.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9054, Training Loss: 5.625e-01, Validation Loss: 7.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9055, Training Loss: 5.624e-01, Validation Loss: 7.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9056, Training Loss: 5.624e-01, Validation Loss: 7.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9057, Training Loss: 5.623e-01, Validation Loss: 7.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9058, Training Loss: 5.623e-01, Validation Loss: 7.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9059, Training Loss: 5.622e-01, Validation Loss: 7.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9060, Training Loss: 5.621e-01, Validation Loss: 7.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9061, Training Loss: 5.621e-01, Validation Loss: 7.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9062, Training Loss: 5.620e-01, Validation Loss: 7.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9063, Training Loss: 5.620e-01, Validation Loss: 7.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9064, Training Loss: 5.619e-01, Validation Loss: 7.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9065, Training Loss: 5.618e-01, Validation Loss: 7.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9066, Training Loss: 5.618e-01, Validation Loss: 7.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9067, Training Loss: 5.617e-01, Validation Loss: 7.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9068, Training Loss: 5.617e-01, Validation Loss: 7.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9069, Training Loss: 5.616e-01, Validation Loss: 7.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9070, Training Loss: 5.615e-01, Validation Loss: 7.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9071, Training Loss: 5.615e-01, Validation Loss: 7.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9072, Training Loss: 5.614e-01, Validation Loss: 7.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9073, Training Loss: 5.614e-01, Validation Loss: 7.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9074, Training Loss: 5.613e-01, Validation Loss: 7.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9075, Training Loss: 5.612e-01, Validation Loss: 7.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9076, Training Loss: 5.612e-01, Validation Loss: 7.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9077, Training Loss: 5.611e-01, Validation Loss: 7.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9078, Training Loss: 5.611e-01, Validation Loss: 7.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9079, Training Loss: 5.610e-01, Validation Loss: 7.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9080, Training Loss: 5.609e-01, Validation Loss: 7.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9081, Training Loss: 5.609e-01, Validation Loss: 7.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9082, Training Loss: 5.608e-01, Validation Loss: 7.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9083, Training Loss: 5.608e-01, Validation Loss: 7.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9084, Training Loss: 5.607e-01, Validation Loss: 7.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9085, Training Loss: 5.606e-01, Validation Loss: 7.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9086, Training Loss: 5.606e-01, Validation Loss: 7.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9087, Training Loss: 5.605e-01, Validation Loss: 7.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9088, Training Loss: 5.605e-01, Validation Loss: 7.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9089, Training Loss: 5.604e-01, Validation Loss: 7.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9090, Training Loss: 5.603e-01, Validation Loss: 7.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9091, Training Loss: 5.603e-01, Validation Loss: 7.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9092, Training Loss: 5.602e-01, Validation Loss: 7.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9093, Training Loss: 5.602e-01, Validation Loss: 7.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9094, Training Loss: 5.601e-01, Validation Loss: 7.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9095, Training Loss: 5.601e-01, Validation Loss: 7.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9096, Training Loss: 5.600e-01, Validation Loss: 7.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9097, Training Loss: 5.599e-01, Validation Loss: 7.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9098, Training Loss: 5.599e-01, Validation Loss: 7.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9099, Training Loss: 5.598e-01, Validation Loss: 7.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9100, Training Loss: 5.598e-01, Validation Loss: 7.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9101, Training Loss: 5.597e-01, Validation Loss: 7.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9102, Training Loss: 5.596e-01, Validation Loss: 7.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9103, Training Loss: 5.596e-01, Validation Loss: 7.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9104, Training Loss: 5.595e-01, Validation Loss: 7.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9105, Training Loss: 5.595e-01, Validation Loss: 7.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9106, Training Loss: 5.594e-01, Validation Loss: 7.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9107, Training Loss: 5.593e-01, Validation Loss: 7.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9108, Training Loss: 5.593e-01, Validation Loss: 7.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9109, Training Loss: 5.592e-01, Validation Loss: 7.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9110, Training Loss: 5.592e-01, Validation Loss: 7.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9111, Training Loss: 5.591e-01, Validation Loss: 7.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9112, Training Loss: 5.590e-01, Validation Loss: 7.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9113, Training Loss: 5.590e-01, Validation Loss: 7.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9114, Training Loss: 5.589e-01, Validation Loss: 7.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9115, Training Loss: 5.589e-01, Validation Loss: 7.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9116, Training Loss: 5.588e-01, Validation Loss: 7.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9117, Training Loss: 5.587e-01, Validation Loss: 7.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9118, Training Loss: 5.587e-01, Validation Loss: 7.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9119, Training Loss: 5.586e-01, Validation Loss: 7.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9120, Training Loss: 5.586e-01, Validation Loss: 7.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9121, Training Loss: 5.585e-01, Validation Loss: 7.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9122, Training Loss: 5.585e-01, Validation Loss: 7.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9123, Training Loss: 5.584e-01, Validation Loss: 7.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9124, Training Loss: 5.583e-01, Validation Loss: 7.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9125, Training Loss: 5.583e-01, Validation Loss: 7.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9126, Training Loss: 5.582e-01, Validation Loss: 7.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9127, Training Loss: 5.582e-01, Validation Loss: 7.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9128, Training Loss: 5.581e-01, Validation Loss: 7.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9129, Training Loss: 5.580e-01, Validation Loss: 7.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9130, Training Loss: 5.580e-01, Validation Loss: 7.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9131, Training Loss: 5.579e-01, Validation Loss: 7.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9132, Training Loss: 5.579e-01, Validation Loss: 7.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9133, Training Loss: 5.578e-01, Validation Loss: 7.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9134, Training Loss: 5.577e-01, Validation Loss: 7.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9135, Training Loss: 5.577e-01, Validation Loss: 7.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9136, Training Loss: 5.576e-01, Validation Loss: 7.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9137, Training Loss: 5.576e-01, Validation Loss: 7.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9138, Training Loss: 5.575e-01, Validation Loss: 7.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9139, Training Loss: 5.575e-01, Validation Loss: 7.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9140, Training Loss: 5.574e-01, Validation Loss: 7.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9141, Training Loss: 5.573e-01, Validation Loss: 7.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9142, Training Loss: 5.573e-01, Validation Loss: 7.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9143, Training Loss: 5.572e-01, Validation Loss: 7.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9144, Training Loss: 5.572e-01, Validation Loss: 7.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9145, Training Loss: 5.571e-01, Validation Loss: 7.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9146, Training Loss: 5.570e-01, Validation Loss: 7.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9147, Training Loss: 5.570e-01, Validation Loss: 7.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9148, Training Loss: 5.569e-01, Validation Loss: 7.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9149, Training Loss: 5.569e-01, Validation Loss: 7.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9150, Training Loss: 5.568e-01, Validation Loss: 7.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9151, Training Loss: 5.568e-01, Validation Loss: 7.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9152, Training Loss: 5.567e-01, Validation Loss: 7.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9153, Training Loss: 5.566e-01, Validation Loss: 7.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9154, Training Loss: 5.566e-01, Validation Loss: 7.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9155, Training Loss: 5.565e-01, Validation Loss: 7.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9156, Training Loss: 5.565e-01, Validation Loss: 7.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9157, Training Loss: 5.564e-01, Validation Loss: 7.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9158, Training Loss: 5.563e-01, Validation Loss: 7.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9159, Training Loss: 5.563e-01, Validation Loss: 7.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9160, Training Loss: 5.562e-01, Validation Loss: 7.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9161, Training Loss: 5.562e-01, Validation Loss: 7.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9162, Training Loss: 5.561e-01, Validation Loss: 7.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9163, Training Loss: 5.560e-01, Validation Loss: 7.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9164, Training Loss: 5.560e-01, Validation Loss: 7.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9165, Training Loss: 5.559e-01, Validation Loss: 7.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9166, Training Loss: 5.559e-01, Validation Loss: 7.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9167, Training Loss: 5.558e-01, Validation Loss: 7.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9168, Training Loss: 5.558e-01, Validation Loss: 7.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9169, Training Loss: 5.557e-01, Validation Loss: 7.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9170, Training Loss: 5.556e-01, Validation Loss: 7.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9171, Training Loss: 5.556e-01, Validation Loss: 7.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9172, Training Loss: 5.555e-01, Validation Loss: 7.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9173, Training Loss: 5.555e-01, Validation Loss: 7.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9174, Training Loss: 5.554e-01, Validation Loss: 7.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9175, Training Loss: 5.553e-01, Validation Loss: 7.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9176, Training Loss: 5.553e-01, Validation Loss: 7.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9177, Training Loss: 5.552e-01, Validation Loss: 7.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9178, Training Loss: 5.552e-01, Validation Loss: 7.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9179, Training Loss: 5.551e-01, Validation Loss: 7.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9180, Training Loss: 5.551e-01, Validation Loss: 7.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9181, Training Loss: 5.550e-01, Validation Loss: 7.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9182, Training Loss: 5.549e-01, Validation Loss: 7.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9183, Training Loss: 5.549e-01, Validation Loss: 7.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9184, Training Loss: 5.548e-01, Validation Loss: 7.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9185, Training Loss: 5.548e-01, Validation Loss: 7.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9186, Training Loss: 5.547e-01, Validation Loss: 7.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9187, Training Loss: 5.547e-01, Validation Loss: 7.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9188, Training Loss: 5.546e-01, Validation Loss: 7.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9189, Training Loss: 5.545e-01, Validation Loss: 7.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9190, Training Loss: 5.545e-01, Validation Loss: 7.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9191, Training Loss: 5.544e-01, Validation Loss: 7.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9192, Training Loss: 5.544e-01, Validation Loss: 7.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9193, Training Loss: 5.543e-01, Validation Loss: 7.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9194, Training Loss: 5.542e-01, Validation Loss: 7.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9195, Training Loss: 5.542e-01, Validation Loss: 7.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9196, Training Loss: 5.541e-01, Validation Loss: 7.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9197, Training Loss: 5.541e-01, Validation Loss: 7.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9198, Training Loss: 5.540e-01, Validation Loss: 7.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9199, Training Loss: 5.540e-01, Validation Loss: 7.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9200, Training Loss: 5.539e-01, Validation Loss: 7.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9201, Training Loss: 5.538e-01, Validation Loss: 7.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9202, Training Loss: 5.538e-01, Validation Loss: 7.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9203, Training Loss: 5.537e-01, Validation Loss: 7.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9204, Training Loss: 5.537e-01, Validation Loss: 7.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9205, Training Loss: 5.536e-01, Validation Loss: 7.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9206, Training Loss: 5.535e-01, Validation Loss: 7.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9207, Training Loss: 5.535e-01, Validation Loss: 7.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9208, Training Loss: 5.534e-01, Validation Loss: 7.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9209, Training Loss: 5.534e-01, Validation Loss: 7.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9210, Training Loss: 5.533e-01, Validation Loss: 7.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9211, Training Loss: 5.533e-01, Validation Loss: 7.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9212, Training Loss: 5.532e-01, Validation Loss: 7.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9213, Training Loss: 5.531e-01, Validation Loss: 7.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9214, Training Loss: 5.531e-01, Validation Loss: 7.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9215, Training Loss: 5.530e-01, Validation Loss: 7.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9216, Training Loss: 5.530e-01, Validation Loss: 7.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9217, Training Loss: 5.529e-01, Validation Loss: 7.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9218, Training Loss: 5.529e-01, Validation Loss: 7.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9219, Training Loss: 5.528e-01, Validation Loss: 7.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9220, Training Loss: 5.527e-01, Validation Loss: 7.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9221, Training Loss: 5.527e-01, Validation Loss: 7.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9222, Training Loss: 5.526e-01, Validation Loss: 7.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9223, Training Loss: 5.526e-01, Validation Loss: 7.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9224, Training Loss: 5.525e-01, Validation Loss: 7.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9225, Training Loss: 5.524e-01, Validation Loss: 7.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9226, Training Loss: 5.524e-01, Validation Loss: 7.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9227, Training Loss: 5.523e-01, Validation Loss: 7.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9228, Training Loss: 5.523e-01, Validation Loss: 7.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9229, Training Loss: 5.522e-01, Validation Loss: 7.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9230, Training Loss: 5.522e-01, Validation Loss: 7.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9231, Training Loss: 5.521e-01, Validation Loss: 7.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9232, Training Loss: 5.520e-01, Validation Loss: 7.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9233, Training Loss: 5.520e-01, Validation Loss: 7.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9234, Training Loss: 5.519e-01, Validation Loss: 7.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9235, Training Loss: 5.519e-01, Validation Loss: 7.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9236, Training Loss: 5.518e-01, Validation Loss: 7.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9237, Training Loss: 5.518e-01, Validation Loss: 7.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9238, Training Loss: 5.517e-01, Validation Loss: 7.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9239, Training Loss: 5.516e-01, Validation Loss: 7.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9240, Training Loss: 5.516e-01, Validation Loss: 7.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9241, Training Loss: 5.515e-01, Validation Loss: 7.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9242, Training Loss: 5.515e-01, Validation Loss: 7.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9243, Training Loss: 5.514e-01, Validation Loss: 7.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9244, Training Loss: 5.514e-01, Validation Loss: 7.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9245, Training Loss: 5.513e-01, Validation Loss: 7.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9246, Training Loss: 5.512e-01, Validation Loss: 7.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9247, Training Loss: 5.512e-01, Validation Loss: 7.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9248, Training Loss: 5.511e-01, Validation Loss: 7.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9249, Training Loss: 5.511e-01, Validation Loss: 7.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9250, Training Loss: 5.510e-01, Validation Loss: 7.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9251, Training Loss: 5.510e-01, Validation Loss: 7.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9252, Training Loss: 5.509e-01, Validation Loss: 7.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9253, Training Loss: 5.508e-01, Validation Loss: 7.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9254, Training Loss: 5.508e-01, Validation Loss: 7.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9255, Training Loss: 5.507e-01, Validation Loss: 7.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9256, Training Loss: 5.507e-01, Validation Loss: 7.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9257, Training Loss: 5.506e-01, Validation Loss: 7.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9258, Training Loss: 5.506e-01, Validation Loss: 7.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9259, Training Loss: 5.505e-01, Validation Loss: 7.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9260, Training Loss: 5.504e-01, Validation Loss: 7.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9261, Training Loss: 5.504e-01, Validation Loss: 7.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9262, Training Loss: 5.503e-01, Validation Loss: 7.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9263, Training Loss: 5.503e-01, Validation Loss: 7.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9264, Training Loss: 5.502e-01, Validation Loss: 7.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9265, Training Loss: 5.502e-01, Validation Loss: 7.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9266, Training Loss: 5.501e-01, Validation Loss: 7.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9267, Training Loss: 5.500e-01, Validation Loss: 7.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9268, Training Loss: 5.500e-01, Validation Loss: 7.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9269, Training Loss: 5.499e-01, Validation Loss: 7.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9270, Training Loss: 5.499e-01, Validation Loss: 7.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9271, Training Loss: 5.498e-01, Validation Loss: 7.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9272, Training Loss: 5.497e-01, Validation Loss: 7.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9273, Training Loss: 5.497e-01, Validation Loss: 7.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9274, Training Loss: 5.496e-01, Validation Loss: 7.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9275, Training Loss: 5.496e-01, Validation Loss: 7.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9276, Training Loss: 5.495e-01, Validation Loss: 7.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9277, Training Loss: 5.495e-01, Validation Loss: 7.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9278, Training Loss: 5.494e-01, Validation Loss: 7.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9279, Training Loss: 5.493e-01, Validation Loss: 7.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9280, Training Loss: 5.493e-01, Validation Loss: 7.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9281, Training Loss: 5.492e-01, Validation Loss: 7.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9282, Training Loss: 5.492e-01, Validation Loss: 7.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9283, Training Loss: 5.491e-01, Validation Loss: 7.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9284, Training Loss: 5.491e-01, Validation Loss: 7.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9285, Training Loss: 5.490e-01, Validation Loss: 7.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9286, Training Loss: 5.489e-01, Validation Loss: 7.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9287, Training Loss: 5.489e-01, Validation Loss: 7.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9288, Training Loss: 5.488e-01, Validation Loss: 7.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9289, Training Loss: 5.488e-01, Validation Loss: 7.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9290, Training Loss: 5.487e-01, Validation Loss: 7.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9291, Training Loss: 5.487e-01, Validation Loss: 7.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9292, Training Loss: 5.486e-01, Validation Loss: 7.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9293, Training Loss: 5.486e-01, Validation Loss: 7.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9294, Training Loss: 5.485e-01, Validation Loss: 7.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9295, Training Loss: 5.484e-01, Validation Loss: 7.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9296, Training Loss: 5.484e-01, Validation Loss: 7.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9297, Training Loss: 5.483e-01, Validation Loss: 7.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9298, Training Loss: 5.483e-01, Validation Loss: 7.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9299, Training Loss: 5.482e-01, Validation Loss: 7.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9300, Training Loss: 5.482e-01, Validation Loss: 7.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9301, Training Loss: 5.481e-01, Validation Loss: 7.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9302, Training Loss: 5.480e-01, Validation Loss: 7.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9303, Training Loss: 5.480e-01, Validation Loss: 7.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9304, Training Loss: 5.479e-01, Validation Loss: 7.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9305, Training Loss: 5.479e-01, Validation Loss: 7.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9306, Training Loss: 5.478e-01, Validation Loss: 7.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9307, Training Loss: 5.478e-01, Validation Loss: 7.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9308, Training Loss: 5.477e-01, Validation Loss: 7.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9309, Training Loss: 5.476e-01, Validation Loss: 7.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9310, Training Loss: 5.476e-01, Validation Loss: 7.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9311, Training Loss: 5.475e-01, Validation Loss: 7.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9312, Training Loss: 5.475e-01, Validation Loss: 7.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9313, Training Loss: 5.474e-01, Validation Loss: 7.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9314, Training Loss: 5.474e-01, Validation Loss: 7.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9315, Training Loss: 5.473e-01, Validation Loss: 7.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9316, Training Loss: 5.472e-01, Validation Loss: 7.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9317, Training Loss: 5.472e-01, Validation Loss: 7.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9318, Training Loss: 5.471e-01, Validation Loss: 7.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9319, Training Loss: 5.471e-01, Validation Loss: 7.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9320, Training Loss: 5.470e-01, Validation Loss: 7.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9321, Training Loss: 5.470e-01, Validation Loss: 7.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9322, Training Loss: 5.469e-01, Validation Loss: 7.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9323, Training Loss: 5.468e-01, Validation Loss: 7.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9324, Training Loss: 5.468e-01, Validation Loss: 7.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9325, Training Loss: 5.467e-01, Validation Loss: 7.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9326, Training Loss: 5.467e-01, Validation Loss: 7.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9327, Training Loss: 5.466e-01, Validation Loss: 7.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9328, Training Loss: 5.466e-01, Validation Loss: 7.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9329, Training Loss: 5.465e-01, Validation Loss: 7.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9330, Training Loss: 5.464e-01, Validation Loss: 7.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9331, Training Loss: 5.464e-01, Validation Loss: 7.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9332, Training Loss: 5.463e-01, Validation Loss: 7.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9333, Training Loss: 5.463e-01, Validation Loss: 7.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9334, Training Loss: 5.462e-01, Validation Loss: 7.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9335, Training Loss: 5.462e-01, Validation Loss: 7.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9336, Training Loss: 5.461e-01, Validation Loss: 7.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9337, Training Loss: 5.461e-01, Validation Loss: 7.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9338, Training Loss: 5.460e-01, Validation Loss: 7.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9339, Training Loss: 5.459e-01, Validation Loss: 7.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9340, Training Loss: 5.459e-01, Validation Loss: 7.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9341, Training Loss: 5.458e-01, Validation Loss: 7.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9342, Training Loss: 5.458e-01, Validation Loss: 7.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9343, Training Loss: 5.457e-01, Validation Loss: 7.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9344, Training Loss: 5.457e-01, Validation Loss: 7.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9345, Training Loss: 5.456e-01, Validation Loss: 7.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9346, Training Loss: 5.455e-01, Validation Loss: 7.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9347, Training Loss: 5.455e-01, Validation Loss: 7.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9348, Training Loss: 5.454e-01, Validation Loss: 7.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9349, Training Loss: 5.454e-01, Validation Loss: 7.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9350, Training Loss: 5.453e-01, Validation Loss: 7.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9351, Training Loss: 5.453e-01, Validation Loss: 7.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9352, Training Loss: 5.452e-01, Validation Loss: 7.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9353, Training Loss: 5.451e-01, Validation Loss: 7.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9354, Training Loss: 5.451e-01, Validation Loss: 7.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9355, Training Loss: 5.450e-01, Validation Loss: 7.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9356, Training Loss: 5.450e-01, Validation Loss: 7.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9357, Training Loss: 5.449e-01, Validation Loss: 7.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9358, Training Loss: 5.449e-01, Validation Loss: 7.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9359, Training Loss: 5.448e-01, Validation Loss: 7.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9360, Training Loss: 5.447e-01, Validation Loss: 7.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9361, Training Loss: 5.447e-01, Validation Loss: 7.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9362, Training Loss: 5.446e-01, Validation Loss: 7.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9363, Training Loss: 5.446e-01, Validation Loss: 7.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9364, Training Loss: 5.445e-01, Validation Loss: 7.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9365, Training Loss: 5.445e-01, Validation Loss: 7.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9366, Training Loss: 5.444e-01, Validation Loss: 7.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9367, Training Loss: 5.444e-01, Validation Loss: 7.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9368, Training Loss: 5.443e-01, Validation Loss: 7.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9369, Training Loss: 5.442e-01, Validation Loss: 7.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9370, Training Loss: 5.442e-01, Validation Loss: 7.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9371, Training Loss: 5.441e-01, Validation Loss: 7.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9372, Training Loss: 5.441e-01, Validation Loss: 7.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9373, Training Loss: 5.440e-01, Validation Loss: 7.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9374, Training Loss: 5.440e-01, Validation Loss: 7.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9375, Training Loss: 5.439e-01, Validation Loss: 7.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9376, Training Loss: 5.438e-01, Validation Loss: 7.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9377, Training Loss: 5.438e-01, Validation Loss: 7.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9378, Training Loss: 5.437e-01, Validation Loss: 7.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9379, Training Loss: 5.437e-01, Validation Loss: 7.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9380, Training Loss: 5.436e-01, Validation Loss: 7.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9381, Training Loss: 5.436e-01, Validation Loss: 7.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9382, Training Loss: 5.435e-01, Validation Loss: 7.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9383, Training Loss: 5.435e-01, Validation Loss: 7.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9384, Training Loss: 5.434e-01, Validation Loss: 7.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9385, Training Loss: 5.433e-01, Validation Loss: 7.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9386, Training Loss: 5.433e-01, Validation Loss: 7.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9387, Training Loss: 5.432e-01, Validation Loss: 7.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9388, Training Loss: 5.432e-01, Validation Loss: 7.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9389, Training Loss: 5.431e-01, Validation Loss: 7.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9390, Training Loss: 5.431e-01, Validation Loss: 7.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9391, Training Loss: 5.430e-01, Validation Loss: 7.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9392, Training Loss: 5.429e-01, Validation Loss: 7.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9393, Training Loss: 5.429e-01, Validation Loss: 7.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9394, Training Loss: 5.428e-01, Validation Loss: 7.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9395, Training Loss: 5.428e-01, Validation Loss: 7.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9396, Training Loss: 5.427e-01, Validation Loss: 7.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9397, Training Loss: 5.427e-01, Validation Loss: 7.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9398, Training Loss: 5.426e-01, Validation Loss: 7.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9399, Training Loss: 5.426e-01, Validation Loss: 7.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9400, Training Loss: 5.425e-01, Validation Loss: 7.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9401, Training Loss: 5.424e-01, Validation Loss: 7.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9402, Training Loss: 5.424e-01, Validation Loss: 7.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9403, Training Loss: 5.423e-01, Validation Loss: 7.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9404, Training Loss: 5.423e-01, Validation Loss: 7.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9405, Training Loss: 5.422e-01, Validation Loss: 7.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9406, Training Loss: 5.422e-01, Validation Loss: 7.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9407, Training Loss: 5.421e-01, Validation Loss: 7.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9408, Training Loss: 5.420e-01, Validation Loss: 7.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9409, Training Loss: 5.420e-01, Validation Loss: 7.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9410, Training Loss: 5.419e-01, Validation Loss: 7.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9411, Training Loss: 5.419e-01, Validation Loss: 7.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9412, Training Loss: 5.418e-01, Validation Loss: 7.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9413, Training Loss: 5.418e-01, Validation Loss: 7.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9414, Training Loss: 5.417e-01, Validation Loss: 7.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9415, Training Loss: 5.417e-01, Validation Loss: 7.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9416, Training Loss: 5.416e-01, Validation Loss: 7.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9417, Training Loss: 5.415e-01, Validation Loss: 7.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9418, Training Loss: 5.415e-01, Validation Loss: 7.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9419, Training Loss: 5.414e-01, Validation Loss: 7.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9420, Training Loss: 5.414e-01, Validation Loss: 7.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9421, Training Loss: 5.413e-01, Validation Loss: 7.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9422, Training Loss: 5.413e-01, Validation Loss: 7.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9423, Training Loss: 5.412e-01, Validation Loss: 7.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9424, Training Loss: 5.412e-01, Validation Loss: 7.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9425, Training Loss: 5.411e-01, Validation Loss: 7.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9426, Training Loss: 5.410e-01, Validation Loss: 7.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9427, Training Loss: 5.410e-01, Validation Loss: 7.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9428, Training Loss: 5.409e-01, Validation Loss: 7.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9429, Training Loss: 5.409e-01, Validation Loss: 7.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9430, Training Loss: 5.408e-01, Validation Loss: 7.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9431, Training Loss: 5.408e-01, Validation Loss: 7.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9432, Training Loss: 5.407e-01, Validation Loss: 7.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9433, Training Loss: 5.407e-01, Validation Loss: 7.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9434, Training Loss: 5.406e-01, Validation Loss: 7.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9435, Training Loss: 5.405e-01, Validation Loss: 7.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9436, Training Loss: 5.405e-01, Validation Loss: 7.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9437, Training Loss: 5.404e-01, Validation Loss: 7.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9438, Training Loss: 5.404e-01, Validation Loss: 7.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9439, Training Loss: 5.403e-01, Validation Loss: 7.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9440, Training Loss: 5.403e-01, Validation Loss: 7.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9441, Training Loss: 5.402e-01, Validation Loss: 7.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9442, Training Loss: 5.401e-01, Validation Loss: 7.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9443, Training Loss: 5.401e-01, Validation Loss: 7.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9444, Training Loss: 5.400e-01, Validation Loss: 7.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9445, Training Loss: 5.400e-01, Validation Loss: 7.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9446, Training Loss: 5.399e-01, Validation Loss: 7.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9447, Training Loss: 5.399e-01, Validation Loss: 7.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9448, Training Loss: 5.398e-01, Validation Loss: 7.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9449, Training Loss: 5.398e-01, Validation Loss: 7.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9450, Training Loss: 5.397e-01, Validation Loss: 7.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9451, Training Loss: 5.396e-01, Validation Loss: 7.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9452, Training Loss: 5.396e-01, Validation Loss: 7.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9453, Training Loss: 5.395e-01, Validation Loss: 7.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9454, Training Loss: 5.395e-01, Validation Loss: 7.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9455, Training Loss: 5.394e-01, Validation Loss: 7.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9456, Training Loss: 5.394e-01, Validation Loss: 7.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9457, Training Loss: 5.393e-01, Validation Loss: 7.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9458, Training Loss: 5.393e-01, Validation Loss: 7.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9459, Training Loss: 5.392e-01, Validation Loss: 7.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9460, Training Loss: 5.391e-01, Validation Loss: 7.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9461, Training Loss: 5.391e-01, Validation Loss: 7.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9462, Training Loss: 5.390e-01, Validation Loss: 7.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9463, Training Loss: 5.390e-01, Validation Loss: 7.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9464, Training Loss: 5.389e-01, Validation Loss: 7.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9465, Training Loss: 5.389e-01, Validation Loss: 7.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9466, Training Loss: 5.388e-01, Validation Loss: 7.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9467, Training Loss: 5.388e-01, Validation Loss: 7.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9468, Training Loss: 5.387e-01, Validation Loss: 7.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9469, Training Loss: 5.386e-01, Validation Loss: 7.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9470, Training Loss: 5.386e-01, Validation Loss: 7.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9471, Training Loss: 5.385e-01, Validation Loss: 7.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9472, Training Loss: 5.385e-01, Validation Loss: 7.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9473, Training Loss: 5.384e-01, Validation Loss: 7.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9474, Training Loss: 5.384e-01, Validation Loss: 7.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9475, Training Loss: 5.383e-01, Validation Loss: 7.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9476, Training Loss: 5.383e-01, Validation Loss: 7.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9477, Training Loss: 5.382e-01, Validation Loss: 7.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9478, Training Loss: 5.381e-01, Validation Loss: 7.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9479, Training Loss: 5.381e-01, Validation Loss: 7.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9480, Training Loss: 5.380e-01, Validation Loss: 7.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9481, Training Loss: 5.380e-01, Validation Loss: 7.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9482, Training Loss: 5.379e-01, Validation Loss: 7.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9483, Training Loss: 5.379e-01, Validation Loss: 7.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9484, Training Loss: 5.378e-01, Validation Loss: 7.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9485, Training Loss: 5.378e-01, Validation Loss: 7.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9486, Training Loss: 5.377e-01, Validation Loss: 7.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9487, Training Loss: 5.377e-01, Validation Loss: 7.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9488, Training Loss: 5.376e-01, Validation Loss: 7.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9489, Training Loss: 5.375e-01, Validation Loss: 7.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9490, Training Loss: 5.375e-01, Validation Loss: 7.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9491, Training Loss: 5.374e-01, Validation Loss: 7.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9492, Training Loss: 5.374e-01, Validation Loss: 7.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9493, Training Loss: 5.373e-01, Validation Loss: 7.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9494, Training Loss: 5.373e-01, Validation Loss: 7.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9495, Training Loss: 5.372e-01, Validation Loss: 7.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9496, Training Loss: 5.372e-01, Validation Loss: 7.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9497, Training Loss: 5.371e-01, Validation Loss: 7.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9498, Training Loss: 5.370e-01, Validation Loss: 7.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9499, Training Loss: 5.370e-01, Validation Loss: 7.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9500, Training Loss: 5.369e-01, Validation Loss: 7.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9501, Training Loss: 5.369e-01, Validation Loss: 7.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9502, Training Loss: 5.368e-01, Validation Loss: 7.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9503, Training Loss: 5.368e-01, Validation Loss: 7.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9504, Training Loss: 5.367e-01, Validation Loss: 7.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9505, Training Loss: 5.367e-01, Validation Loss: 7.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9506, Training Loss: 5.366e-01, Validation Loss: 7.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9507, Training Loss: 5.365e-01, Validation Loss: 7.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9508, Training Loss: 5.365e-01, Validation Loss: 7.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9509, Training Loss: 5.364e-01, Validation Loss: 7.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9510, Training Loss: 5.364e-01, Validation Loss: 7.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9511, Training Loss: 5.363e-01, Validation Loss: 7.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9512, Training Loss: 5.363e-01, Validation Loss: 7.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9513, Training Loss: 5.362e-01, Validation Loss: 7.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9514, Training Loss: 5.362e-01, Validation Loss: 7.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9515, Training Loss: 5.361e-01, Validation Loss: 7.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9516, Training Loss: 5.361e-01, Validation Loss: 7.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9517, Training Loss: 5.360e-01, Validation Loss: 7.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9518, Training Loss: 5.359e-01, Validation Loss: 7.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9519, Training Loss: 5.359e-01, Validation Loss: 7.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9520, Training Loss: 5.358e-01, Validation Loss: 7.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9521, Training Loss: 5.358e-01, Validation Loss: 7.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9522, Training Loss: 5.357e-01, Validation Loss: 7.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9523, Training Loss: 5.357e-01, Validation Loss: 7.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9524, Training Loss: 5.356e-01, Validation Loss: 7.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9525, Training Loss: 5.356e-01, Validation Loss: 7.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9526, Training Loss: 5.355e-01, Validation Loss: 7.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9527, Training Loss: 5.354e-01, Validation Loss: 7.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9528, Training Loss: 5.354e-01, Validation Loss: 7.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9529, Training Loss: 5.353e-01, Validation Loss: 7.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9530, Training Loss: 5.353e-01, Validation Loss: 7.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9531, Training Loss: 5.352e-01, Validation Loss: 7.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9532, Training Loss: 5.352e-01, Validation Loss: 7.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9533, Training Loss: 5.351e-01, Validation Loss: 7.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9534, Training Loss: 5.351e-01, Validation Loss: 7.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9535, Training Loss: 5.350e-01, Validation Loss: 7.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9536, Training Loss: 5.350e-01, Validation Loss: 7.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9537, Training Loss: 5.349e-01, Validation Loss: 7.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9538, Training Loss: 5.348e-01, Validation Loss: 7.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9539, Training Loss: 5.348e-01, Validation Loss: 7.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9540, Training Loss: 5.347e-01, Validation Loss: 7.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9541, Training Loss: 5.347e-01, Validation Loss: 7.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9542, Training Loss: 5.346e-01, Validation Loss: 7.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9543, Training Loss: 5.346e-01, Validation Loss: 7.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9544, Training Loss: 5.345e-01, Validation Loss: 7.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9545, Training Loss: 5.345e-01, Validation Loss: 7.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9546, Training Loss: 5.344e-01, Validation Loss: 7.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9547, Training Loss: 5.343e-01, Validation Loss: 7.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9548, Training Loss: 5.343e-01, Validation Loss: 7.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9549, Training Loss: 5.342e-01, Validation Loss: 7.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9550, Training Loss: 5.342e-01, Validation Loss: 7.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9551, Training Loss: 5.341e-01, Validation Loss: 7.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9552, Training Loss: 5.341e-01, Validation Loss: 7.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9553, Training Loss: 5.340e-01, Validation Loss: 7.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9554, Training Loss: 5.340e-01, Validation Loss: 7.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9555, Training Loss: 5.339e-01, Validation Loss: 7.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9556, Training Loss: 5.339e-01, Validation Loss: 7.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9557, Training Loss: 5.338e-01, Validation Loss: 7.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9558, Training Loss: 5.337e-01, Validation Loss: 7.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9559, Training Loss: 5.337e-01, Validation Loss: 7.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9560, Training Loss: 5.336e-01, Validation Loss: 7.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9561, Training Loss: 5.336e-01, Validation Loss: 7.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9562, Training Loss: 5.335e-01, Validation Loss: 7.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9563, Training Loss: 5.335e-01, Validation Loss: 7.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9564, Training Loss: 5.334e-01, Validation Loss: 7.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9565, Training Loss: 5.334e-01, Validation Loss: 7.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9566, Training Loss: 5.333e-01, Validation Loss: 7.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9567, Training Loss: 5.333e-01, Validation Loss: 7.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9568, Training Loss: 5.332e-01, Validation Loss: 7.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9569, Training Loss: 5.331e-01, Validation Loss: 7.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9570, Training Loss: 5.331e-01, Validation Loss: 7.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9571, Training Loss: 5.330e-01, Validation Loss: 7.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9572, Training Loss: 5.330e-01, Validation Loss: 7.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9573, Training Loss: 5.329e-01, Validation Loss: 7.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9574, Training Loss: 5.329e-01, Validation Loss: 7.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9575, Training Loss: 5.328e-01, Validation Loss: 7.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9576, Training Loss: 5.328e-01, Validation Loss: 7.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9577, Training Loss: 5.327e-01, Validation Loss: 7.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9578, Training Loss: 5.327e-01, Validation Loss: 7.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9579, Training Loss: 5.326e-01, Validation Loss: 7.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9580, Training Loss: 5.325e-01, Validation Loss: 7.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9581, Training Loss: 5.325e-01, Validation Loss: 7.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9582, Training Loss: 5.324e-01, Validation Loss: 7.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9583, Training Loss: 5.324e-01, Validation Loss: 7.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9584, Training Loss: 5.323e-01, Validation Loss: 7.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9585, Training Loss: 5.323e-01, Validation Loss: 7.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9586, Training Loss: 5.322e-01, Validation Loss: 7.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9587, Training Loss: 5.322e-01, Validation Loss: 7.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9588, Training Loss: 5.321e-01, Validation Loss: 7.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9589, Training Loss: 5.321e-01, Validation Loss: 7.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9590, Training Loss: 5.320e-01, Validation Loss: 7.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9591, Training Loss: 5.319e-01, Validation Loss: 7.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9592, Training Loss: 5.319e-01, Validation Loss: 7.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9593, Training Loss: 5.318e-01, Validation Loss: 7.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9594, Training Loss: 5.318e-01, Validation Loss: 7.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9595, Training Loss: 5.317e-01, Validation Loss: 7.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9596, Training Loss: 5.317e-01, Validation Loss: 7.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9597, Training Loss: 5.316e-01, Validation Loss: 7.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9598, Training Loss: 5.316e-01, Validation Loss: 7.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9599, Training Loss: 5.315e-01, Validation Loss: 7.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9600, Training Loss: 5.315e-01, Validation Loss: 7.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9601, Training Loss: 5.314e-01, Validation Loss: 7.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9602, Training Loss: 5.313e-01, Validation Loss: 7.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9603, Training Loss: 5.313e-01, Validation Loss: 7.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9604, Training Loss: 5.312e-01, Validation Loss: 7.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9605, Training Loss: 5.312e-01, Validation Loss: 7.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9606, Training Loss: 5.311e-01, Validation Loss: 7.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9607, Training Loss: 5.311e-01, Validation Loss: 7.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9608, Training Loss: 5.310e-01, Validation Loss: 7.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9609, Training Loss: 5.310e-01, Validation Loss: 7.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9610, Training Loss: 5.309e-01, Validation Loss: 7.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9611, Training Loss: 5.309e-01, Validation Loss: 7.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9612, Training Loss: 5.308e-01, Validation Loss: 7.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9613, Training Loss: 5.307e-01, Validation Loss: 7.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9614, Training Loss: 5.307e-01, Validation Loss: 7.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9615, Training Loss: 5.306e-01, Validation Loss: 7.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9616, Training Loss: 5.306e-01, Validation Loss: 7.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9617, Training Loss: 5.305e-01, Validation Loss: 7.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9618, Training Loss: 5.305e-01, Validation Loss: 7.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9619, Training Loss: 5.304e-01, Validation Loss: 7.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9620, Training Loss: 5.304e-01, Validation Loss: 7.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9621, Training Loss: 5.303e-01, Validation Loss: 7.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9622, Training Loss: 5.303e-01, Validation Loss: 7.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9623, Training Loss: 5.302e-01, Validation Loss: 7.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9624, Training Loss: 5.302e-01, Validation Loss: 7.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9625, Training Loss: 5.301e-01, Validation Loss: 7.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9626, Training Loss: 5.300e-01, Validation Loss: 7.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9627, Training Loss: 5.300e-01, Validation Loss: 7.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9628, Training Loss: 5.299e-01, Validation Loss: 7.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9629, Training Loss: 5.299e-01, Validation Loss: 7.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9630, Training Loss: 5.298e-01, Validation Loss: 7.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9631, Training Loss: 5.298e-01, Validation Loss: 7.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9632, Training Loss: 5.297e-01, Validation Loss: 7.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9633, Training Loss: 5.297e-01, Validation Loss: 7.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9634, Training Loss: 5.296e-01, Validation Loss: 7.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9635, Training Loss: 5.296e-01, Validation Loss: 7.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9636, Training Loss: 5.295e-01, Validation Loss: 7.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9637, Training Loss: 5.294e-01, Validation Loss: 7.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9638, Training Loss: 5.294e-01, Validation Loss: 7.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9639, Training Loss: 5.293e-01, Validation Loss: 7.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9640, Training Loss: 5.293e-01, Validation Loss: 7.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9641, Training Loss: 5.292e-01, Validation Loss: 7.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9642, Training Loss: 5.292e-01, Validation Loss: 7.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9643, Training Loss: 5.291e-01, Validation Loss: 7.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9644, Training Loss: 5.291e-01, Validation Loss: 7.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9645, Training Loss: 5.290e-01, Validation Loss: 7.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9646, Training Loss: 5.290e-01, Validation Loss: 7.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9647, Training Loss: 5.289e-01, Validation Loss: 7.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9648, Training Loss: 5.289e-01, Validation Loss: 7.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9649, Training Loss: 5.288e-01, Validation Loss: 7.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9650, Training Loss: 5.288e-01, Validation Loss: 7.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9651, Training Loss: 5.287e-01, Validation Loss: 7.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9652, Training Loss: 5.286e-01, Validation Loss: 7.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9653, Training Loss: 5.286e-01, Validation Loss: 7.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9654, Training Loss: 5.285e-01, Validation Loss: 7.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9655, Training Loss: 5.285e-01, Validation Loss: 7.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9656, Training Loss: 5.284e-01, Validation Loss: 7.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9657, Training Loss: 5.284e-01, Validation Loss: 7.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9658, Training Loss: 5.283e-01, Validation Loss: 7.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9659, Training Loss: 5.283e-01, Validation Loss: 7.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9660, Training Loss: 5.282e-01, Validation Loss: 7.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9661, Training Loss: 5.282e-01, Validation Loss: 7.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9662, Training Loss: 5.281e-01, Validation Loss: 7.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9663, Training Loss: 5.281e-01, Validation Loss: 7.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9664, Training Loss: 5.280e-01, Validation Loss: 7.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9665, Training Loss: 5.279e-01, Validation Loss: 7.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9666, Training Loss: 5.279e-01, Validation Loss: 7.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9667, Training Loss: 5.278e-01, Validation Loss: 7.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9668, Training Loss: 5.278e-01, Validation Loss: 7.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9669, Training Loss: 5.277e-01, Validation Loss: 7.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9670, Training Loss: 5.277e-01, Validation Loss: 7.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9671, Training Loss: 5.276e-01, Validation Loss: 7.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9672, Training Loss: 5.276e-01, Validation Loss: 7.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9673, Training Loss: 5.275e-01, Validation Loss: 7.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9674, Training Loss: 5.275e-01, Validation Loss: 7.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9675, Training Loss: 5.274e-01, Validation Loss: 7.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9676, Training Loss: 5.274e-01, Validation Loss: 7.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9677, Training Loss: 5.273e-01, Validation Loss: 7.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9678, Training Loss: 5.272e-01, Validation Loss: 7.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9679, Training Loss: 5.272e-01, Validation Loss: 7.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9680, Training Loss: 5.271e-01, Validation Loss: 7.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9681, Training Loss: 5.271e-01, Validation Loss: 7.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9682, Training Loss: 5.270e-01, Validation Loss: 7.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9683, Training Loss: 5.270e-01, Validation Loss: 7.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9684, Training Loss: 5.269e-01, Validation Loss: 7.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9685, Training Loss: 5.269e-01, Validation Loss: 7.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9686, Training Loss: 5.268e-01, Validation Loss: 7.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9687, Training Loss: 5.268e-01, Validation Loss: 7.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9688, Training Loss: 5.267e-01, Validation Loss: 7.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9689, Training Loss: 5.267e-01, Validation Loss: 7.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9690, Training Loss: 5.266e-01, Validation Loss: 7.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9691, Training Loss: 5.266e-01, Validation Loss: 7.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9692, Training Loss: 5.265e-01, Validation Loss: 7.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9693, Training Loss: 5.264e-01, Validation Loss: 7.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9694, Training Loss: 5.264e-01, Validation Loss: 7.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9695, Training Loss: 5.263e-01, Validation Loss: 7.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9696, Training Loss: 5.263e-01, Validation Loss: 7.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9697, Training Loss: 5.262e-01, Validation Loss: 7.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9698, Training Loss: 5.262e-01, Validation Loss: 7.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9699, Training Loss: 5.261e-01, Validation Loss: 7.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9700, Training Loss: 5.261e-01, Validation Loss: 7.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9701, Training Loss: 5.260e-01, Validation Loss: 7.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9702, Training Loss: 5.260e-01, Validation Loss: 7.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9703, Training Loss: 5.259e-01, Validation Loss: 7.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9704, Training Loss: 5.259e-01, Validation Loss: 7.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9705, Training Loss: 5.258e-01, Validation Loss: 7.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9706, Training Loss: 5.258e-01, Validation Loss: 7.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9707, Training Loss: 5.257e-01, Validation Loss: 7.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9708, Training Loss: 5.256e-01, Validation Loss: 7.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9709, Training Loss: 5.256e-01, Validation Loss: 7.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9710, Training Loss: 5.255e-01, Validation Loss: 7.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9711, Training Loss: 5.255e-01, Validation Loss: 7.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9712, Training Loss: 5.254e-01, Validation Loss: 7.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9713, Training Loss: 5.254e-01, Validation Loss: 7.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9714, Training Loss: 5.253e-01, Validation Loss: 7.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9715, Training Loss: 5.253e-01, Validation Loss: 7.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9716, Training Loss: 5.252e-01, Validation Loss: 7.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9717, Training Loss: 5.252e-01, Validation Loss: 7.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9718, Training Loss: 5.251e-01, Validation Loss: 7.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9719, Training Loss: 5.251e-01, Validation Loss: 7.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9720, Training Loss: 5.250e-01, Validation Loss: 7.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9721, Training Loss: 5.250e-01, Validation Loss: 7.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9722, Training Loss: 5.249e-01, Validation Loss: 7.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9723, Training Loss: 5.249e-01, Validation Loss: 7.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9724, Training Loss: 5.248e-01, Validation Loss: 7.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9725, Training Loss: 5.247e-01, Validation Loss: 7.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9726, Training Loss: 5.247e-01, Validation Loss: 7.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9727, Training Loss: 5.246e-01, Validation Loss: 7.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9728, Training Loss: 5.246e-01, Validation Loss: 7.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9729, Training Loss: 5.245e-01, Validation Loss: 7.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9730, Training Loss: 5.245e-01, Validation Loss: 7.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9731, Training Loss: 5.244e-01, Validation Loss: 7.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9732, Training Loss: 5.244e-01, Validation Loss: 7.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9733, Training Loss: 5.243e-01, Validation Loss: 7.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9734, Training Loss: 5.243e-01, Validation Loss: 7.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9735, Training Loss: 5.242e-01, Validation Loss: 7.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9736, Training Loss: 5.242e-01, Validation Loss: 7.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9737, Training Loss: 5.241e-01, Validation Loss: 7.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9738, Training Loss: 5.241e-01, Validation Loss: 7.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9739, Training Loss: 5.240e-01, Validation Loss: 7.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9740, Training Loss: 5.240e-01, Validation Loss: 7.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9741, Training Loss: 5.239e-01, Validation Loss: 7.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9742, Training Loss: 5.238e-01, Validation Loss: 7.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9743, Training Loss: 5.238e-01, Validation Loss: 7.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9744, Training Loss: 5.237e-01, Validation Loss: 7.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9745, Training Loss: 5.237e-01, Validation Loss: 7.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9746, Training Loss: 5.236e-01, Validation Loss: 7.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9747, Training Loss: 5.236e-01, Validation Loss: 7.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9748, Training Loss: 5.235e-01, Validation Loss: 7.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9749, Training Loss: 5.235e-01, Validation Loss: 7.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9750, Training Loss: 5.234e-01, Validation Loss: 7.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9751, Training Loss: 5.234e-01, Validation Loss: 7.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9752, Training Loss: 5.233e-01, Validation Loss: 7.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9753, Training Loss: 5.233e-01, Validation Loss: 7.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9754, Training Loss: 5.232e-01, Validation Loss: 7.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9755, Training Loss: 5.232e-01, Validation Loss: 7.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9756, Training Loss: 5.231e-01, Validation Loss: 7.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9757, Training Loss: 5.231e-01, Validation Loss: 7.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9758, Training Loss: 5.230e-01, Validation Loss: 7.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9759, Training Loss: 5.229e-01, Validation Loss: 7.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9760, Training Loss: 5.229e-01, Validation Loss: 7.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9761, Training Loss: 5.228e-01, Validation Loss: 7.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9762, Training Loss: 5.228e-01, Validation Loss: 7.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9763, Training Loss: 5.227e-01, Validation Loss: 7.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9764, Training Loss: 5.227e-01, Validation Loss: 7.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9765, Training Loss: 5.226e-01, Validation Loss: 7.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9766, Training Loss: 5.226e-01, Validation Loss: 7.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9767, Training Loss: 5.225e-01, Validation Loss: 7.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9768, Training Loss: 5.225e-01, Validation Loss: 7.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9769, Training Loss: 5.224e-01, Validation Loss: 7.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9770, Training Loss: 5.224e-01, Validation Loss: 7.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9771, Training Loss: 5.223e-01, Validation Loss: 7.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9772, Training Loss: 5.223e-01, Validation Loss: 7.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9773, Training Loss: 5.222e-01, Validation Loss: 7.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9774, Training Loss: 5.222e-01, Validation Loss: 7.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9775, Training Loss: 5.221e-01, Validation Loss: 7.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9776, Training Loss: 5.221e-01, Validation Loss: 7.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9777, Training Loss: 5.220e-01, Validation Loss: 7.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9778, Training Loss: 5.219e-01, Validation Loss: 7.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9779, Training Loss: 5.219e-01, Validation Loss: 7.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9780, Training Loss: 5.218e-01, Validation Loss: 7.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9781, Training Loss: 5.218e-01, Validation Loss: 7.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9782, Training Loss: 5.217e-01, Validation Loss: 7.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9783, Training Loss: 5.217e-01, Validation Loss: 7.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9784, Training Loss: 5.216e-01, Validation Loss: 7.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9785, Training Loss: 5.216e-01, Validation Loss: 7.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9786, Training Loss: 5.215e-01, Validation Loss: 7.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9787, Training Loss: 5.215e-01, Validation Loss: 7.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9788, Training Loss: 5.214e-01, Validation Loss: 7.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9789, Training Loss: 5.214e-01, Validation Loss: 7.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9790, Training Loss: 5.213e-01, Validation Loss: 7.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9791, Training Loss: 5.213e-01, Validation Loss: 7.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9792, Training Loss: 5.212e-01, Validation Loss: 7.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9793, Training Loss: 5.212e-01, Validation Loss: 7.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9794, Training Loss: 5.211e-01, Validation Loss: 7.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9795, Training Loss: 5.211e-01, Validation Loss: 7.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9796, Training Loss: 5.210e-01, Validation Loss: 7.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9797, Training Loss: 5.210e-01, Validation Loss: 7.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9798, Training Loss: 5.209e-01, Validation Loss: 7.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9799, Training Loss: 5.208e-01, Validation Loss: 7.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9800, Training Loss: 5.208e-01, Validation Loss: 7.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9801, Training Loss: 5.207e-01, Validation Loss: 7.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9802, Training Loss: 5.207e-01, Validation Loss: 7.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9803, Training Loss: 5.206e-01, Validation Loss: 7.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9804, Training Loss: 5.206e-01, Validation Loss: 7.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9805, Training Loss: 5.205e-01, Validation Loss: 7.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9806, Training Loss: 5.205e-01, Validation Loss: 7.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9807, Training Loss: 5.204e-01, Validation Loss: 7.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9808, Training Loss: 5.204e-01, Validation Loss: 7.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9809, Training Loss: 5.203e-01, Validation Loss: 7.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9810, Training Loss: 5.203e-01, Validation Loss: 7.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9811, Training Loss: 5.202e-01, Validation Loss: 7.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9812, Training Loss: 5.202e-01, Validation Loss: 7.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9813, Training Loss: 5.201e-01, Validation Loss: 7.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9814, Training Loss: 5.201e-01, Validation Loss: 7.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9815, Training Loss: 5.200e-01, Validation Loss: 7.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9816, Training Loss: 5.200e-01, Validation Loss: 7.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9817, Training Loss: 5.199e-01, Validation Loss: 7.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9818, Training Loss: 5.199e-01, Validation Loss: 7.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9819, Training Loss: 5.198e-01, Validation Loss: 7.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9820, Training Loss: 5.197e-01, Validation Loss: 7.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9821, Training Loss: 5.197e-01, Validation Loss: 7.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9822, Training Loss: 5.196e-01, Validation Loss: 7.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9823, Training Loss: 5.196e-01, Validation Loss: 7.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9824, Training Loss: 5.195e-01, Validation Loss: 7.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9825, Training Loss: 5.195e-01, Validation Loss: 7.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9826, Training Loss: 5.194e-01, Validation Loss: 7.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9827, Training Loss: 5.194e-01, Validation Loss: 7.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9828, Training Loss: 5.193e-01, Validation Loss: 7.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9829, Training Loss: 5.193e-01, Validation Loss: 7.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9830, Training Loss: 5.192e-01, Validation Loss: 7.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9831, Training Loss: 5.192e-01, Validation Loss: 7.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9832, Training Loss: 5.191e-01, Validation Loss: 7.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9833, Training Loss: 5.191e-01, Validation Loss: 7.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9834, Training Loss: 5.190e-01, Validation Loss: 7.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9835, Training Loss: 5.190e-01, Validation Loss: 7.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9836, Training Loss: 5.189e-01, Validation Loss: 7.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9837, Training Loss: 5.189e-01, Validation Loss: 7.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9838, Training Loss: 5.188e-01, Validation Loss: 7.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9839, Training Loss: 5.188e-01, Validation Loss: 7.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9840, Training Loss: 5.187e-01, Validation Loss: 7.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9841, Training Loss: 5.187e-01, Validation Loss: 7.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9842, Training Loss: 5.186e-01, Validation Loss: 7.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9843, Training Loss: 5.186e-01, Validation Loss: 7.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9844, Training Loss: 5.185e-01, Validation Loss: 7.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9845, Training Loss: 5.184e-01, Validation Loss: 7.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9846, Training Loss: 5.184e-01, Validation Loss: 7.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9847, Training Loss: 5.183e-01, Validation Loss: 7.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9848, Training Loss: 5.183e-01, Validation Loss: 7.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9849, Training Loss: 5.182e-01, Validation Loss: 7.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9850, Training Loss: 5.182e-01, Validation Loss: 7.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9851, Training Loss: 5.181e-01, Validation Loss: 7.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9852, Training Loss: 5.181e-01, Validation Loss: 7.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9853, Training Loss: 5.180e-01, Validation Loss: 7.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9854, Training Loss: 5.180e-01, Validation Loss: 7.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9855, Training Loss: 5.179e-01, Validation Loss: 7.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9856, Training Loss: 5.179e-01, Validation Loss: 7.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9857, Training Loss: 5.178e-01, Validation Loss: 7.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9858, Training Loss: 5.178e-01, Validation Loss: 7.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9859, Training Loss: 5.177e-01, Validation Loss: 7.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9860, Training Loss: 5.177e-01, Validation Loss: 7.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9861, Training Loss: 5.176e-01, Validation Loss: 7.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9862, Training Loss: 5.176e-01, Validation Loss: 7.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9863, Training Loss: 5.175e-01, Validation Loss: 7.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9864, Training Loss: 5.175e-01, Validation Loss: 7.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9865, Training Loss: 5.174e-01, Validation Loss: 7.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9866, Training Loss: 5.174e-01, Validation Loss: 7.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9867, Training Loss: 5.173e-01, Validation Loss: 7.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9868, Training Loss: 5.173e-01, Validation Loss: 7.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9869, Training Loss: 5.172e-01, Validation Loss: 7.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9870, Training Loss: 5.172e-01, Validation Loss: 7.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9871, Training Loss: 5.171e-01, Validation Loss: 7.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9872, Training Loss: 5.170e-01, Validation Loss: 7.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9873, Training Loss: 5.170e-01, Validation Loss: 7.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9874, Training Loss: 5.169e-01, Validation Loss: 7.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9875, Training Loss: 5.169e-01, Validation Loss: 7.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9876, Training Loss: 5.168e-01, Validation Loss: 7.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9877, Training Loss: 5.168e-01, Validation Loss: 7.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9878, Training Loss: 5.167e-01, Validation Loss: 7.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9879, Training Loss: 5.167e-01, Validation Loss: 7.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9880, Training Loss: 5.166e-01, Validation Loss: 7.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9881, Training Loss: 5.166e-01, Validation Loss: 7.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9882, Training Loss: 5.165e-01, Validation Loss: 7.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9883, Training Loss: 5.165e-01, Validation Loss: 7.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9884, Training Loss: 5.164e-01, Validation Loss: 7.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9885, Training Loss: 5.164e-01, Validation Loss: 7.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9886, Training Loss: 5.163e-01, Validation Loss: 7.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9887, Training Loss: 5.163e-01, Validation Loss: 7.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9888, Training Loss: 5.162e-01, Validation Loss: 7.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9889, Training Loss: 5.162e-01, Validation Loss: 7.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9890, Training Loss: 5.161e-01, Validation Loss: 7.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9891, Training Loss: 5.161e-01, Validation Loss: 7.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9892, Training Loss: 5.160e-01, Validation Loss: 7.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9893, Training Loss: 5.160e-01, Validation Loss: 7.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9894, Training Loss: 5.159e-01, Validation Loss: 7.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9895, Training Loss: 5.159e-01, Validation Loss: 7.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9896, Training Loss: 5.158e-01, Validation Loss: 7.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9897, Training Loss: 5.158e-01, Validation Loss: 7.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9898, Training Loss: 5.157e-01, Validation Loss: 7.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9899, Training Loss: 5.157e-01, Validation Loss: 7.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9900, Training Loss: 5.156e-01, Validation Loss: 7.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9901, Training Loss: 5.156e-01, Validation Loss: 7.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9902, Training Loss: 5.155e-01, Validation Loss: 7.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9903, Training Loss: 5.155e-01, Validation Loss: 7.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9904, Training Loss: 5.154e-01, Validation Loss: 7.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9905, Training Loss: 5.153e-01, Validation Loss: 7.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9906, Training Loss: 5.153e-01, Validation Loss: 7.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9907, Training Loss: 5.152e-01, Validation Loss: 7.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9908, Training Loss: 5.152e-01, Validation Loss: 7.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9909, Training Loss: 5.151e-01, Validation Loss: 7.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9910, Training Loss: 5.151e-01, Validation Loss: 7.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9911, Training Loss: 5.150e-01, Validation Loss: 7.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9912, Training Loss: 5.150e-01, Validation Loss: 7.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9913, Training Loss: 5.149e-01, Validation Loss: 7.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9914, Training Loss: 5.149e-01, Validation Loss: 7.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9915, Training Loss: 5.148e-01, Validation Loss: 7.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9916, Training Loss: 5.148e-01, Validation Loss: 7.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9917, Training Loss: 5.147e-01, Validation Loss: 7.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9918, Training Loss: 5.147e-01, Validation Loss: 7.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9919, Training Loss: 5.146e-01, Validation Loss: 7.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9920, Training Loss: 5.146e-01, Validation Loss: 7.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9921, Training Loss: 5.145e-01, Validation Loss: 7.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9922, Training Loss: 5.145e-01, Validation Loss: 7.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9923, Training Loss: 5.144e-01, Validation Loss: 7.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9924, Training Loss: 5.144e-01, Validation Loss: 7.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9925, Training Loss: 5.143e-01, Validation Loss: 7.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9926, Training Loss: 5.143e-01, Validation Loss: 7.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9927, Training Loss: 5.142e-01, Validation Loss: 7.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9928, Training Loss: 5.142e-01, Validation Loss: 7.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9929, Training Loss: 5.141e-01, Validation Loss: 7.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9930, Training Loss: 5.141e-01, Validation Loss: 7.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9931, Training Loss: 5.140e-01, Validation Loss: 7.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9932, Training Loss: 5.140e-01, Validation Loss: 7.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9933, Training Loss: 5.139e-01, Validation Loss: 7.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9934, Training Loss: 5.139e-01, Validation Loss: 7.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9935, Training Loss: 5.138e-01, Validation Loss: 7.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9936, Training Loss: 5.138e-01, Validation Loss: 7.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9937, Training Loss: 5.137e-01, Validation Loss: 7.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9938, Training Loss: 5.137e-01, Validation Loss: 7.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9939, Training Loss: 5.136e-01, Validation Loss: 7.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9940, Training Loss: 5.136e-01, Validation Loss: 7.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9941, Training Loss: 5.135e-01, Validation Loss: 7.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9942, Training Loss: 5.135e-01, Validation Loss: 7.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9943, Training Loss: 5.134e-01, Validation Loss: 7.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9944, Training Loss: 5.133e-01, Validation Loss: 7.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9945, Training Loss: 5.133e-01, Validation Loss: 7.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9946, Training Loss: 5.132e-01, Validation Loss: 7.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9947, Training Loss: 5.132e-01, Validation Loss: 7.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9948, Training Loss: 5.131e-01, Validation Loss: 7.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9949, Training Loss: 5.131e-01, Validation Loss: 7.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9950, Training Loss: 5.130e-01, Validation Loss: 7.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9951, Training Loss: 5.130e-01, Validation Loss: 7.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9952, Training Loss: 5.129e-01, Validation Loss: 7.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9953, Training Loss: 5.129e-01, Validation Loss: 7.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9954, Training Loss: 5.128e-01, Validation Loss: 7.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9955, Training Loss: 5.128e-01, Validation Loss: 7.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9956, Training Loss: 5.127e-01, Validation Loss: 7.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9957, Training Loss: 5.127e-01, Validation Loss: 7.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9958, Training Loss: 5.126e-01, Validation Loss: 7.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9959, Training Loss: 5.126e-01, Validation Loss: 7.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9960, Training Loss: 5.125e-01, Validation Loss: 7.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9961, Training Loss: 5.125e-01, Validation Loss: 7.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9962, Training Loss: 5.124e-01, Validation Loss: 7.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9963, Training Loss: 5.124e-01, Validation Loss: 7.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9964, Training Loss: 5.123e-01, Validation Loss: 7.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9965, Training Loss: 5.123e-01, Validation Loss: 7.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9966, Training Loss: 5.122e-01, Validation Loss: 7.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9967, Training Loss: 5.122e-01, Validation Loss: 7.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9968, Training Loss: 5.121e-01, Validation Loss: 7.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9969, Training Loss: 5.121e-01, Validation Loss: 7.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9970, Training Loss: 5.120e-01, Validation Loss: 7.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9971, Training Loss: 5.120e-01, Validation Loss: 7.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9972, Training Loss: 5.119e-01, Validation Loss: 7.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9973, Training Loss: 5.119e-01, Validation Loss: 7.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9974, Training Loss: 5.118e-01, Validation Loss: 7.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9975, Training Loss: 5.118e-01, Validation Loss: 7.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9976, Training Loss: 5.117e-01, Validation Loss: 7.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9977, Training Loss: 5.117e-01, Validation Loss: 7.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9978, Training Loss: 5.116e-01, Validation Loss: 7.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9979, Training Loss: 5.116e-01, Validation Loss: 7.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9980, Training Loss: 5.115e-01, Validation Loss: 7.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9981, Training Loss: 5.115e-01, Validation Loss: 7.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9982, Training Loss: 5.114e-01, Validation Loss: 7.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9983, Training Loss: 5.114e-01, Validation Loss: 7.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9984, Training Loss: 5.113e-01, Validation Loss: 7.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9985, Training Loss: 5.113e-01, Validation Loss: 7.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9986, Training Loss: 5.112e-01, Validation Loss: 7.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9987, Training Loss: 5.112e-01, Validation Loss: 7.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9988, Training Loss: 5.111e-01, Validation Loss: 7.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9989, Training Loss: 5.111e-01, Validation Loss: 7.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9990, Training Loss: 5.110e-01, Validation Loss: 7.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9991, Training Loss: 5.110e-01, Validation Loss: 7.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9992, Training Loss: 5.109e-01, Validation Loss: 7.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9993, Training Loss: 5.109e-01, Validation Loss: 7.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9994, Training Loss: 5.108e-01, Validation Loss: 7.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9995, Training Loss: 5.108e-01, Validation Loss: 7.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9996, Training Loss: 5.107e-01, Validation Loss: 7.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9997, Training Loss: 5.107e-01, Validation Loss: 7.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9998, Training Loss: 5.106e-01, Validation Loss: 7.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9999, Training Loss: 5.106e-01, Validation Loss: 7.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9999, Training Loss: 5.106e-01, Validation Loss: 7.251e-01, Patience: 0\n"
     ]
    }
   ],
   "source": [
    "error_train, error_val = model_50.train(X_train, y_train, X_val, y_val, epochs=10000, learning_rate=1e-2, optimizer='sgd', generate_new_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_50.plot_training_error(error_train, error_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error : 0.8364855227308367\n",
      "(208, 2500) (208, 15) (208, 15)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_50.test(X_test, y_test)\n",
    "print(X_test.shape, y_test.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8173076923076923\n",
      "Azmira - Precision: 0.9285714285714286, Recall: 1.0, F1 Score: 0.962962962962963\n",
      "David - Precision: 0.8181818181818182, Recall: 1.0, F1 Score: 0.9\n",
      "Dimas - Precision: 0.8, Recall: 0.8888888888888888, F1 Score: 0.8421052631578948\n",
      "Fadhli - Precision: 0.8571428571428571, Recall: 0.9230769230769231, F1 Score: 0.888888888888889\n",
      "Fadlin - Precision: 0.7777777777777778, Recall: 0.9333333333333333, F1 Score: 0.8484848484848485\n",
      "Hafidz - Precision: 0.6, Recall: 0.5454545454545454, F1 Score: 0.5714285714285713\n",
      "Haidar - Precision: 0.6, Recall: 0.6, F1 Score: 0.6\n",
      "Hanna - Precision: 0.7142857142857143, Recall: 0.6666666666666666, F1 Score: 0.689655172413793\n",
      "Keiko - Precision: 0.9, Recall: 1.0, F1 Score: 0.9473684210526316\n",
      "Khansa - Precision: 0.5, Recall: 0.29411764705882354, F1 Score: 0.37037037037037035\n",
      "Mikhael - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Puti - Precision: 0.8888888888888888, Recall: 0.8888888888888888, F1 Score: 0.8888888888888888\n",
      "Raesa - Precision: 0.7857142857142857, Recall: 0.6470588235294118, F1 Score: 0.7096774193548386\n",
      "Satwika - Precision: 0.9166666666666666, Recall: 0.9166666666666666, F1 Score: 0.9166666666666666\n",
      "Toni - Precision: 0.9565217391304348, Recall: 0.9565217391304348, F1 Score: 0.9565217391304348\n",
      "Mean Precision: 0.8029167450906584\n",
      "Mean Recall: 0.8173782748463055\n",
      "Mean F1 Score: 0.8062012808533862\n"
     ]
    }
   ],
   "source": [
    "model_50.add_labels_from_folders(input_directory)\n",
    "model_50.evaluate_metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_50.plot_confusion_matrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_50.save_model(\"./My_Model_50/01_Yi Sang_Rotate.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
