{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_image import *\n",
    "from model_nn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found folders: ['Azmira', 'David', 'Dimas', 'Fadhli', 'Fadlin', 'Hafidz', 'Haidar', 'Hanna', 'Keiko', 'Khansa', 'Mikhael', 'Puti', 'Raesa', 'Satwika', 'Toni']\n",
      "(968, 2500) (968, 15) (208, 2500) (208, 15) (208, 2500) (208, 15)\n"
     ]
    }
   ],
   "source": [
    "input_directory = \"../Dataset/Foto_Resize_Rotate_50x50\" \n",
    "X_train, y_train, X_test, y_test, X_val, y_val, scalerinput = process_all(input_directory)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_50 = FaceRecognitionModel(X_train.shape[1], [64], y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params rewritten\n",
      "Epoch 0, Training Loss: 3.385e+00, Validation Loss: 3.005e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1, Training Loss: 3.009e+00, Validation Loss: 2.835e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2, Training Loss: 2.846e+00, Validation Loss: 2.796e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3, Training Loss: 2.795e+00, Validation Loss: 2.771e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4, Training Loss: 2.762e+00, Validation Loss: 2.753e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5, Training Loss: 2.737e+00, Validation Loss: 2.740e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6, Training Loss: 2.720e+00, Validation Loss: 2.730e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7, Training Loss: 2.706e+00, Validation Loss: 2.723e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8, Training Loss: 2.694e+00, Validation Loss: 2.716e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9, Training Loss: 2.684e+00, Validation Loss: 2.710e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 10, Training Loss: 2.675e+00, Validation Loss: 2.704e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 11, Training Loss: 2.668e+00, Validation Loss: 2.698e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 12, Training Loss: 2.661e+00, Validation Loss: 2.692e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 13, Training Loss: 2.653e+00, Validation Loss: 2.687e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 14, Training Loss: 2.647e+00, Validation Loss: 2.682e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 15, Training Loss: 2.640e+00, Validation Loss: 2.677e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 16, Training Loss: 2.633e+00, Validation Loss: 2.673e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 17, Training Loss: 2.627e+00, Validation Loss: 2.668e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 18, Training Loss: 2.619e+00, Validation Loss: 2.663e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 19, Training Loss: 2.612e+00, Validation Loss: 2.658e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 20, Training Loss: 2.605e+00, Validation Loss: 2.654e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 21, Training Loss: 2.598e+00, Validation Loss: 2.650e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 22, Training Loss: 2.592e+00, Validation Loss: 2.646e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 23, Training Loss: 2.587e+00, Validation Loss: 2.643e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 24, Training Loss: 2.581e+00, Validation Loss: 2.639e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 25, Training Loss: 2.576e+00, Validation Loss: 2.635e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 26, Training Loss: 2.570e+00, Validation Loss: 2.631e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 27, Training Loss: 2.565e+00, Validation Loss: 2.628e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 28, Training Loss: 2.559e+00, Validation Loss: 2.623e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 29, Training Loss: 2.554e+00, Validation Loss: 2.619e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 30, Training Loss: 2.549e+00, Validation Loss: 2.615e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 31, Training Loss: 2.543e+00, Validation Loss: 2.612e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 32, Training Loss: 2.538e+00, Validation Loss: 2.607e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 33, Training Loss: 2.533e+00, Validation Loss: 2.604e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 34, Training Loss: 2.528e+00, Validation Loss: 2.599e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 35, Training Loss: 2.522e+00, Validation Loss: 2.596e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 36, Training Loss: 2.517e+00, Validation Loss: 2.591e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 37, Training Loss: 2.512e+00, Validation Loss: 2.588e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 38, Training Loss: 2.506e+00, Validation Loss: 2.583e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 39, Training Loss: 2.501e+00, Validation Loss: 2.579e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 40, Training Loss: 2.496e+00, Validation Loss: 2.575e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 41, Training Loss: 2.491e+00, Validation Loss: 2.571e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 42, Training Loss: 2.486e+00, Validation Loss: 2.567e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 43, Training Loss: 2.481e+00, Validation Loss: 2.562e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 44, Training Loss: 2.476e+00, Validation Loss: 2.558e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 45, Training Loss: 2.471e+00, Validation Loss: 2.554e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 46, Training Loss: 2.466e+00, Validation Loss: 2.550e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 47, Training Loss: 2.461e+00, Validation Loss: 2.546e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 48, Training Loss: 2.456e+00, Validation Loss: 2.542e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 49, Training Loss: 2.451e+00, Validation Loss: 2.538e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 50, Training Loss: 2.446e+00, Validation Loss: 2.535e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 51, Training Loss: 2.441e+00, Validation Loss: 2.530e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 52, Training Loss: 2.436e+00, Validation Loss: 2.527e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 53, Training Loss: 2.431e+00, Validation Loss: 2.522e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 54, Training Loss: 2.426e+00, Validation Loss: 2.519e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 55, Training Loss: 2.422e+00, Validation Loss: 2.514e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 56, Training Loss: 2.417e+00, Validation Loss: 2.510e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 57, Training Loss: 2.412e+00, Validation Loss: 2.506e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 58, Training Loss: 2.407e+00, Validation Loss: 2.502e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 59, Training Loss: 2.402e+00, Validation Loss: 2.498e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 60, Training Loss: 2.397e+00, Validation Loss: 2.494e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 61, Training Loss: 2.392e+00, Validation Loss: 2.490e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 62, Training Loss: 2.387e+00, Validation Loss: 2.486e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 63, Training Loss: 2.383e+00, Validation Loss: 2.482e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 64, Training Loss: 2.378e+00, Validation Loss: 2.478e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 65, Training Loss: 2.373e+00, Validation Loss: 2.474e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 66, Training Loss: 2.368e+00, Validation Loss: 2.469e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 67, Training Loss: 2.363e+00, Validation Loss: 2.465e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 68, Training Loss: 2.358e+00, Validation Loss: 2.461e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 69, Training Loss: 2.354e+00, Validation Loss: 2.457e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 70, Training Loss: 2.349e+00, Validation Loss: 2.453e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 71, Training Loss: 2.344e+00, Validation Loss: 2.449e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 72, Training Loss: 2.339e+00, Validation Loss: 2.445e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 73, Training Loss: 2.334e+00, Validation Loss: 2.440e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 74, Training Loss: 2.330e+00, Validation Loss: 2.437e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 75, Training Loss: 2.325e+00, Validation Loss: 2.433e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 76, Training Loss: 2.320e+00, Validation Loss: 2.429e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 77, Training Loss: 2.316e+00, Validation Loss: 2.425e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 78, Training Loss: 2.311e+00, Validation Loss: 2.421e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 79, Training Loss: 2.306e+00, Validation Loss: 2.417e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 80, Training Loss: 2.302e+00, Validation Loss: 2.413e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 81, Training Loss: 2.297e+00, Validation Loss: 2.409e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 82, Training Loss: 2.293e+00, Validation Loss: 2.405e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 83, Training Loss: 2.288e+00, Validation Loss: 2.401e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 84, Training Loss: 2.284e+00, Validation Loss: 2.397e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 85, Training Loss: 2.279e+00, Validation Loss: 2.393e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 86, Training Loss: 2.274e+00, Validation Loss: 2.389e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 87, Training Loss: 2.270e+00, Validation Loss: 2.385e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 88, Training Loss: 2.265e+00, Validation Loss: 2.381e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 89, Training Loss: 2.261e+00, Validation Loss: 2.378e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 90, Training Loss: 2.256e+00, Validation Loss: 2.374e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 91, Training Loss: 2.252e+00, Validation Loss: 2.370e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 92, Training Loss: 2.247e+00, Validation Loss: 2.366e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 93, Training Loss: 2.243e+00, Validation Loss: 2.363e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 94, Training Loss: 2.238e+00, Validation Loss: 2.359e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 95, Training Loss: 2.234e+00, Validation Loss: 2.356e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 96, Training Loss: 2.229e+00, Validation Loss: 2.352e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 97, Training Loss: 2.225e+00, Validation Loss: 2.349e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 98, Training Loss: 2.220e+00, Validation Loss: 2.345e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 99, Training Loss: 2.215e+00, Validation Loss: 2.341e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 100, Training Loss: 2.211e+00, Validation Loss: 2.337e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 101, Training Loss: 2.207e+00, Validation Loss: 2.334e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 102, Training Loss: 2.202e+00, Validation Loss: 2.330e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 103, Training Loss: 2.198e+00, Validation Loss: 2.327e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 104, Training Loss: 2.193e+00, Validation Loss: 2.323e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 105, Training Loss: 2.189e+00, Validation Loss: 2.319e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 106, Training Loss: 2.184e+00, Validation Loss: 2.316e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 107, Training Loss: 2.180e+00, Validation Loss: 2.312e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 108, Training Loss: 2.176e+00, Validation Loss: 2.308e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 109, Training Loss: 2.171e+00, Validation Loss: 2.304e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 110, Training Loss: 2.167e+00, Validation Loss: 2.300e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 111, Training Loss: 2.163e+00, Validation Loss: 2.297e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 112, Training Loss: 2.158e+00, Validation Loss: 2.293e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 113, Training Loss: 2.154e+00, Validation Loss: 2.289e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 114, Training Loss: 2.150e+00, Validation Loss: 2.285e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 115, Training Loss: 2.145e+00, Validation Loss: 2.282e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 116, Training Loss: 2.141e+00, Validation Loss: 2.278e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 117, Training Loss: 2.137e+00, Validation Loss: 2.275e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 118, Training Loss: 2.132e+00, Validation Loss: 2.271e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 119, Training Loss: 2.128e+00, Validation Loss: 2.267e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 120, Training Loss: 2.124e+00, Validation Loss: 2.264e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 121, Training Loss: 2.120e+00, Validation Loss: 2.260e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 122, Training Loss: 2.115e+00, Validation Loss: 2.256e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 123, Training Loss: 2.111e+00, Validation Loss: 2.253e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 124, Training Loss: 2.107e+00, Validation Loss: 2.249e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 125, Training Loss: 2.103e+00, Validation Loss: 2.246e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 126, Training Loss: 2.099e+00, Validation Loss: 2.242e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 127, Training Loss: 2.094e+00, Validation Loss: 2.239e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 128, Training Loss: 2.090e+00, Validation Loss: 2.235e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 129, Training Loss: 2.086e+00, Validation Loss: 2.231e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 130, Training Loss: 2.082e+00, Validation Loss: 2.228e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 131, Training Loss: 2.078e+00, Validation Loss: 2.224e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 132, Training Loss: 2.073e+00, Validation Loss: 2.221e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 133, Training Loss: 2.069e+00, Validation Loss: 2.217e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 134, Training Loss: 2.065e+00, Validation Loss: 2.214e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 135, Training Loss: 2.061e+00, Validation Loss: 2.210e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 136, Training Loss: 2.057e+00, Validation Loss: 2.207e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 137, Training Loss: 2.053e+00, Validation Loss: 2.203e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 138, Training Loss: 2.048e+00, Validation Loss: 2.200e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 139, Training Loss: 2.044e+00, Validation Loss: 2.196e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 140, Training Loss: 2.040e+00, Validation Loss: 2.193e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 141, Training Loss: 2.036e+00, Validation Loss: 2.189e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 142, Training Loss: 2.032e+00, Validation Loss: 2.186e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 143, Training Loss: 2.028e+00, Validation Loss: 2.182e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 144, Training Loss: 2.024e+00, Validation Loss: 2.179e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 145, Training Loss: 2.020e+00, Validation Loss: 2.175e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 146, Training Loss: 2.015e+00, Validation Loss: 2.172e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 147, Training Loss: 2.011e+00, Validation Loss: 2.168e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 148, Training Loss: 2.007e+00, Validation Loss: 2.165e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 149, Training Loss: 2.003e+00, Validation Loss: 2.161e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 150, Training Loss: 1.999e+00, Validation Loss: 2.158e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 151, Training Loss: 1.995e+00, Validation Loss: 2.154e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 152, Training Loss: 1.991e+00, Validation Loss: 2.151e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 153, Training Loss: 1.987e+00, Validation Loss: 2.147e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 154, Training Loss: 1.983e+00, Validation Loss: 2.143e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 155, Training Loss: 1.979e+00, Validation Loss: 2.140e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 156, Training Loss: 1.975e+00, Validation Loss: 2.136e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 157, Training Loss: 1.971e+00, Validation Loss: 2.133e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 158, Training Loss: 1.967e+00, Validation Loss: 2.130e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 159, Training Loss: 1.963e+00, Validation Loss: 2.127e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 160, Training Loss: 1.959e+00, Validation Loss: 2.123e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 161, Training Loss: 1.955e+00, Validation Loss: 2.120e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 162, Training Loss: 1.951e+00, Validation Loss: 2.117e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 163, Training Loss: 1.947e+00, Validation Loss: 2.113e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 164, Training Loss: 1.943e+00, Validation Loss: 2.110e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 165, Training Loss: 1.940e+00, Validation Loss: 2.107e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 166, Training Loss: 1.936e+00, Validation Loss: 2.103e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 167, Training Loss: 1.932e+00, Validation Loss: 2.100e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 168, Training Loss: 1.928e+00, Validation Loss: 2.096e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 169, Training Loss: 1.924e+00, Validation Loss: 2.093e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 170, Training Loss: 1.920e+00, Validation Loss: 2.089e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 171, Training Loss: 1.916e+00, Validation Loss: 2.086e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 172, Training Loss: 1.912e+00, Validation Loss: 2.083e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 173, Training Loss: 1.908e+00, Validation Loss: 2.079e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 174, Training Loss: 1.904e+00, Validation Loss: 2.076e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 175, Training Loss: 1.900e+00, Validation Loss: 2.072e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 176, Training Loss: 1.897e+00, Validation Loss: 2.069e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 177, Training Loss: 1.893e+00, Validation Loss: 2.066e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 178, Training Loss: 1.889e+00, Validation Loss: 2.062e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 179, Training Loss: 1.885e+00, Validation Loss: 2.059e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 180, Training Loss: 1.881e+00, Validation Loss: 2.055e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 181, Training Loss: 1.877e+00, Validation Loss: 2.052e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 182, Training Loss: 1.873e+00, Validation Loss: 2.049e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 183, Training Loss: 1.869e+00, Validation Loss: 2.046e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 184, Training Loss: 1.866e+00, Validation Loss: 2.042e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 185, Training Loss: 1.862e+00, Validation Loss: 2.039e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 186, Training Loss: 1.858e+00, Validation Loss: 2.035e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 187, Training Loss: 1.854e+00, Validation Loss: 2.032e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 188, Training Loss: 1.850e+00, Validation Loss: 2.028e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 189, Training Loss: 1.846e+00, Validation Loss: 2.025e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 190, Training Loss: 1.842e+00, Validation Loss: 2.021e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 191, Training Loss: 1.838e+00, Validation Loss: 2.018e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 192, Training Loss: 1.834e+00, Validation Loss: 2.014e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 193, Training Loss: 1.831e+00, Validation Loss: 2.011e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 194, Training Loss: 1.827e+00, Validation Loss: 2.008e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 195, Training Loss: 1.823e+00, Validation Loss: 2.004e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 196, Training Loss: 1.819e+00, Validation Loss: 2.001e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 197, Training Loss: 1.816e+00, Validation Loss: 1.998e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 198, Training Loss: 1.812e+00, Validation Loss: 1.994e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 199, Training Loss: 1.808e+00, Validation Loss: 1.991e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 200, Training Loss: 1.804e+00, Validation Loss: 1.987e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 201, Training Loss: 1.801e+00, Validation Loss: 1.984e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 202, Training Loss: 1.797e+00, Validation Loss: 1.980e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 203, Training Loss: 1.793e+00, Validation Loss: 1.977e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 204, Training Loss: 1.790e+00, Validation Loss: 1.974e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 205, Training Loss: 1.786e+00, Validation Loss: 1.971e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 206, Training Loss: 1.782e+00, Validation Loss: 1.967e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 207, Training Loss: 1.779e+00, Validation Loss: 1.964e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 208, Training Loss: 1.775e+00, Validation Loss: 1.960e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 209, Training Loss: 1.771e+00, Validation Loss: 1.958e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 210, Training Loss: 1.768e+00, Validation Loss: 1.954e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 211, Training Loss: 1.764e+00, Validation Loss: 1.951e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 212, Training Loss: 1.760e+00, Validation Loss: 1.948e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 213, Training Loss: 1.757e+00, Validation Loss: 1.945e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 214, Training Loss: 1.753e+00, Validation Loss: 1.941e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 215, Training Loss: 1.749e+00, Validation Loss: 1.939e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 216, Training Loss: 1.746e+00, Validation Loss: 1.935e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 217, Training Loss: 1.742e+00, Validation Loss: 1.933e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 218, Training Loss: 1.739e+00, Validation Loss: 1.929e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 219, Training Loss: 1.735e+00, Validation Loss: 1.926e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 220, Training Loss: 1.732e+00, Validation Loss: 1.922e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 221, Training Loss: 1.728e+00, Validation Loss: 1.920e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 222, Training Loss: 1.724e+00, Validation Loss: 1.916e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 223, Training Loss: 1.721e+00, Validation Loss: 1.913e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 224, Training Loss: 1.717e+00, Validation Loss: 1.910e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 225, Training Loss: 1.714e+00, Validation Loss: 1.907e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 226, Training Loss: 1.710e+00, Validation Loss: 1.903e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 227, Training Loss: 1.707e+00, Validation Loss: 1.900e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 228, Training Loss: 1.704e+00, Validation Loss: 1.897e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 229, Training Loss: 1.700e+00, Validation Loss: 1.894e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 230, Training Loss: 1.697e+00, Validation Loss: 1.891e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 231, Training Loss: 1.693e+00, Validation Loss: 1.888e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 232, Training Loss: 1.690e+00, Validation Loss: 1.885e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 233, Training Loss: 1.686e+00, Validation Loss: 1.881e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 234, Training Loss: 1.683e+00, Validation Loss: 1.878e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 235, Training Loss: 1.680e+00, Validation Loss: 1.875e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 236, Training Loss: 1.676e+00, Validation Loss: 1.872e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 237, Training Loss: 1.673e+00, Validation Loss: 1.869e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 238, Training Loss: 1.669e+00, Validation Loss: 1.866e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 239, Training Loss: 1.666e+00, Validation Loss: 1.863e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 240, Training Loss: 1.663e+00, Validation Loss: 1.860e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 241, Training Loss: 1.659e+00, Validation Loss: 1.857e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 242, Training Loss: 1.656e+00, Validation Loss: 1.854e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 243, Training Loss: 1.653e+00, Validation Loss: 1.851e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 244, Training Loss: 1.649e+00, Validation Loss: 1.848e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 245, Training Loss: 1.646e+00, Validation Loss: 1.845e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 246, Training Loss: 1.643e+00, Validation Loss: 1.842e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 247, Training Loss: 1.639e+00, Validation Loss: 1.839e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 248, Training Loss: 1.636e+00, Validation Loss: 1.836e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 249, Training Loss: 1.633e+00, Validation Loss: 1.833e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 250, Training Loss: 1.630e+00, Validation Loss: 1.830e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 251, Training Loss: 1.626e+00, Validation Loss: 1.827e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 252, Training Loss: 1.623e+00, Validation Loss: 1.824e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 253, Training Loss: 1.620e+00, Validation Loss: 1.821e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 254, Training Loss: 1.617e+00, Validation Loss: 1.818e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 255, Training Loss: 1.613e+00, Validation Loss: 1.815e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 256, Training Loss: 1.610e+00, Validation Loss: 1.812e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 257, Training Loss: 1.607e+00, Validation Loss: 1.809e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 258, Training Loss: 1.604e+00, Validation Loss: 1.806e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 259, Training Loss: 1.600e+00, Validation Loss: 1.803e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 260, Training Loss: 1.597e+00, Validation Loss: 1.800e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 261, Training Loss: 1.594e+00, Validation Loss: 1.797e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 262, Training Loss: 1.591e+00, Validation Loss: 1.794e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 263, Training Loss: 1.588e+00, Validation Loss: 1.791e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 264, Training Loss: 1.585e+00, Validation Loss: 1.788e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 265, Training Loss: 1.582e+00, Validation Loss: 1.786e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 266, Training Loss: 1.578e+00, Validation Loss: 1.782e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 267, Training Loss: 1.575e+00, Validation Loss: 1.780e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 268, Training Loss: 1.572e+00, Validation Loss: 1.777e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 269, Training Loss: 1.569e+00, Validation Loss: 1.774e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 270, Training Loss: 1.566e+00, Validation Loss: 1.771e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 271, Training Loss: 1.563e+00, Validation Loss: 1.769e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 272, Training Loss: 1.560e+00, Validation Loss: 1.765e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 273, Training Loss: 1.557e+00, Validation Loss: 1.763e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 274, Training Loss: 1.554e+00, Validation Loss: 1.760e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 275, Training Loss: 1.550e+00, Validation Loss: 1.757e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 276, Training Loss: 1.547e+00, Validation Loss: 1.754e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 277, Training Loss: 1.544e+00, Validation Loss: 1.752e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 278, Training Loss: 1.541e+00, Validation Loss: 1.749e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 279, Training Loss: 1.538e+00, Validation Loss: 1.746e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 280, Training Loss: 1.535e+00, Validation Loss: 1.743e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 281, Training Loss: 1.532e+00, Validation Loss: 1.741e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 282, Training Loss: 1.529e+00, Validation Loss: 1.737e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 283, Training Loss: 1.526e+00, Validation Loss: 1.735e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 284, Training Loss: 1.523e+00, Validation Loss: 1.732e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 285, Training Loss: 1.520e+00, Validation Loss: 1.730e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 286, Training Loss: 1.517e+00, Validation Loss: 1.726e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 287, Training Loss: 1.514e+00, Validation Loss: 1.724e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 288, Training Loss: 1.511e+00, Validation Loss: 1.721e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 289, Training Loss: 1.508e+00, Validation Loss: 1.719e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 290, Training Loss: 1.505e+00, Validation Loss: 1.715e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 291, Training Loss: 1.502e+00, Validation Loss: 1.713e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 292, Training Loss: 1.499e+00, Validation Loss: 1.710e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 293, Training Loss: 1.497e+00, Validation Loss: 1.708e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 294, Training Loss: 1.494e+00, Validation Loss: 1.705e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 295, Training Loss: 1.491e+00, Validation Loss: 1.702e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 296, Training Loss: 1.488e+00, Validation Loss: 1.699e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 297, Training Loss: 1.485e+00, Validation Loss: 1.697e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 298, Training Loss: 1.482e+00, Validation Loss: 1.694e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 299, Training Loss: 1.479e+00, Validation Loss: 1.691e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 300, Training Loss: 1.476e+00, Validation Loss: 1.689e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 301, Training Loss: 1.473e+00, Validation Loss: 1.686e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 302, Training Loss: 1.470e+00, Validation Loss: 1.683e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 303, Training Loss: 1.468e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 304, Training Loss: 1.465e+00, Validation Loss: 1.678e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 305, Training Loss: 1.462e+00, Validation Loss: 1.676e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 306, Training Loss: 1.459e+00, Validation Loss: 1.673e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 307, Training Loss: 1.456e+00, Validation Loss: 1.670e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 308, Training Loss: 1.454e+00, Validation Loss: 1.667e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 309, Training Loss: 1.451e+00, Validation Loss: 1.665e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 310, Training Loss: 1.448e+00, Validation Loss: 1.662e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 311, Training Loss: 1.445e+00, Validation Loss: 1.660e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 312, Training Loss: 1.442e+00, Validation Loss: 1.657e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 313, Training Loss: 1.440e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 314, Training Loss: 1.437e+00, Validation Loss: 1.652e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 315, Training Loss: 1.434e+00, Validation Loss: 1.650e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 316, Training Loss: 1.431e+00, Validation Loss: 1.647e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 317, Training Loss: 1.429e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 318, Training Loss: 1.426e+00, Validation Loss: 1.642e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 319, Training Loss: 1.423e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 320, Training Loss: 1.420e+00, Validation Loss: 1.637e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 321, Training Loss: 1.418e+00, Validation Loss: 1.635e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 322, Training Loss: 1.415e+00, Validation Loss: 1.632e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 323, Training Loss: 1.412e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 324, Training Loss: 1.410e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 325, Training Loss: 1.407e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 326, Training Loss: 1.404e+00, Validation Loss: 1.622e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 327, Training Loss: 1.401e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 328, Training Loss: 1.399e+00, Validation Loss: 1.617e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 329, Training Loss: 1.396e+00, Validation Loss: 1.615e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 330, Training Loss: 1.394e+00, Validation Loss: 1.612e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 331, Training Loss: 1.391e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 332, Training Loss: 1.388e+00, Validation Loss: 1.607e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 333, Training Loss: 1.386e+00, Validation Loss: 1.605e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 334, Training Loss: 1.383e+00, Validation Loss: 1.603e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 335, Training Loss: 1.380e+00, Validation Loss: 1.600e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 336, Training Loss: 1.378e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 337, Training Loss: 1.375e+00, Validation Loss: 1.596e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 338, Training Loss: 1.373e+00, Validation Loss: 1.593e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 339, Training Loss: 1.370e+00, Validation Loss: 1.591e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 340, Training Loss: 1.367e+00, Validation Loss: 1.589e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 341, Training Loss: 1.365e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 342, Training Loss: 1.362e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 343, Training Loss: 1.360e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 344, Training Loss: 1.357e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 345, Training Loss: 1.355e+00, Validation Loss: 1.577e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 346, Training Loss: 1.352e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 347, Training Loss: 1.350e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 348, Training Loss: 1.347e+00, Validation Loss: 1.570e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 349, Training Loss: 1.345e+00, Validation Loss: 1.568e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 350, Training Loss: 1.342e+00, Validation Loss: 1.565e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 351, Training Loss: 1.340e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 352, Training Loss: 1.337e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 353, Training Loss: 1.335e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 354, Training Loss: 1.332e+00, Validation Loss: 1.556e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 355, Training Loss: 1.330e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 356, Training Loss: 1.327e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 357, Training Loss: 1.325e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 358, Training Loss: 1.322e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 359, Training Loss: 1.320e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 360, Training Loss: 1.317e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 361, Training Loss: 1.315e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 362, Training Loss: 1.312e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 363, Training Loss: 1.310e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 364, Training Loss: 1.308e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 365, Training Loss: 1.305e+00, Validation Loss: 1.531e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 366, Training Loss: 1.303e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 367, Training Loss: 1.300e+00, Validation Loss: 1.527e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 368, Training Loss: 1.298e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 369, Training Loss: 1.296e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 370, Training Loss: 1.293e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 371, Training Loss: 1.291e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 372, Training Loss: 1.289e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 373, Training Loss: 1.286e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 374, Training Loss: 1.284e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 375, Training Loss: 1.282e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 376, Training Loss: 1.279e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 377, Training Loss: 1.277e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 378, Training Loss: 1.275e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 379, Training Loss: 1.272e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 380, Training Loss: 1.270e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 381, Training Loss: 1.268e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 382, Training Loss: 1.265e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 383, Training Loss: 1.263e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 384, Training Loss: 1.261e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 385, Training Loss: 1.258e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 386, Training Loss: 1.256e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 387, Training Loss: 1.254e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 388, Training Loss: 1.251e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 389, Training Loss: 1.249e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 390, Training Loss: 1.247e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 391, Training Loss: 1.245e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 392, Training Loss: 1.242e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 393, Training Loss: 1.240e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 394, Training Loss: 1.238e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 395, Training Loss: 1.236e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 396, Training Loss: 1.234e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 397, Training Loss: 1.231e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 398, Training Loss: 1.229e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 399, Training Loss: 1.227e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 400, Training Loss: 1.225e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 401, Training Loss: 1.223e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 402, Training Loss: 1.220e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 403, Training Loss: 1.218e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 404, Training Loss: 1.216e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 405, Training Loss: 1.214e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 406, Training Loss: 1.212e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 407, Training Loss: 1.210e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 408, Training Loss: 1.207e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 409, Training Loss: 1.205e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 410, Training Loss: 1.203e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 411, Training Loss: 1.201e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 412, Training Loss: 1.199e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 413, Training Loss: 1.197e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 414, Training Loss: 1.195e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 415, Training Loss: 1.193e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 416, Training Loss: 1.191e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 417, Training Loss: 1.188e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 418, Training Loss: 1.186e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 419, Training Loss: 1.184e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 420, Training Loss: 1.182e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 421, Training Loss: 1.180e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 422, Training Loss: 1.178e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 423, Training Loss: 1.176e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 424, Training Loss: 1.174e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 425, Training Loss: 1.172e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 426, Training Loss: 1.170e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 427, Training Loss: 1.168e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 428, Training Loss: 1.166e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 429, Training Loss: 1.164e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 430, Training Loss: 1.162e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 431, Training Loss: 1.160e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 432, Training Loss: 1.158e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 433, Training Loss: 1.156e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 434, Training Loss: 1.154e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 435, Training Loss: 1.152e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 436, Training Loss: 1.150e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 437, Training Loss: 1.148e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 438, Training Loss: 1.146e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 439, Training Loss: 1.144e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 440, Training Loss: 1.142e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 441, Training Loss: 1.140e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 442, Training Loss: 1.138e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 443, Training Loss: 1.136e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 444, Training Loss: 1.134e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 445, Training Loss: 1.132e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 446, Training Loss: 1.131e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 447, Training Loss: 1.129e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 448, Training Loss: 1.127e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 449, Training Loss: 1.125e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 450, Training Loss: 1.123e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 451, Training Loss: 1.121e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 452, Training Loss: 1.119e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 453, Training Loss: 1.117e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 454, Training Loss: 1.115e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 455, Training Loss: 1.113e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 456, Training Loss: 1.112e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 457, Training Loss: 1.110e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 458, Training Loss: 1.108e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 459, Training Loss: 1.106e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 460, Training Loss: 1.104e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 461, Training Loss: 1.102e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 462, Training Loss: 1.101e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 463, Training Loss: 1.099e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 464, Training Loss: 1.097e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 465, Training Loss: 1.095e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 466, Training Loss: 1.093e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 467, Training Loss: 1.091e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 468, Training Loss: 1.090e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 469, Training Loss: 1.088e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 470, Training Loss: 1.086e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 471, Training Loss: 1.084e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 472, Training Loss: 1.082e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 473, Training Loss: 1.081e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 474, Training Loss: 1.079e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 475, Training Loss: 1.077e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 476, Training Loss: 1.075e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 477, Training Loss: 1.074e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 478, Training Loss: 1.072e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 479, Training Loss: 1.070e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 480, Training Loss: 1.068e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 481, Training Loss: 1.067e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 482, Training Loss: 1.065e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 483, Training Loss: 1.063e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 484, Training Loss: 1.061e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 485, Training Loss: 1.060e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 486, Training Loss: 1.058e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 487, Training Loss: 1.056e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 488, Training Loss: 1.054e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 489, Training Loss: 1.053e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 490, Training Loss: 1.051e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 491, Training Loss: 1.049e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 492, Training Loss: 1.048e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 493, Training Loss: 1.046e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 494, Training Loss: 1.044e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 495, Training Loss: 1.043e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 496, Training Loss: 1.041e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 497, Training Loss: 1.039e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 498, Training Loss: 1.038e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 499, Training Loss: 1.036e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 500, Training Loss: 1.034e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 501, Training Loss: 1.033e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 502, Training Loss: 1.031e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 503, Training Loss: 1.029e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 504, Training Loss: 1.028e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 505, Training Loss: 1.026e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 506, Training Loss: 1.024e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 507, Training Loss: 1.023e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 508, Training Loss: 1.021e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 509, Training Loss: 1.020e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 510, Training Loss: 1.018e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 511, Training Loss: 1.016e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 512, Training Loss: 1.015e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 513, Training Loss: 1.013e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 514, Training Loss: 1.012e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 515, Training Loss: 1.010e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 516, Training Loss: 1.008e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 517, Training Loss: 1.007e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 518, Training Loss: 1.005e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 519, Training Loss: 1.004e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 520, Training Loss: 1.002e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 521, Training Loss: 1.000e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 522, Training Loss: 9.989e-01, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 523, Training Loss: 9.973e-01, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 524, Training Loss: 9.958e-01, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 525, Training Loss: 9.942e-01, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 526, Training Loss: 9.927e-01, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 527, Training Loss: 9.911e-01, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 528, Training Loss: 9.896e-01, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 529, Training Loss: 9.880e-01, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 530, Training Loss: 9.865e-01, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 531, Training Loss: 9.850e-01, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 532, Training Loss: 9.835e-01, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 533, Training Loss: 9.819e-01, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 534, Training Loss: 9.804e-01, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 535, Training Loss: 9.789e-01, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 536, Training Loss: 9.774e-01, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 537, Training Loss: 9.759e-01, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 538, Training Loss: 9.744e-01, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 539, Training Loss: 9.729e-01, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 540, Training Loss: 9.714e-01, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 541, Training Loss: 9.699e-01, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 542, Training Loss: 9.684e-01, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 543, Training Loss: 9.670e-01, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 544, Training Loss: 9.655e-01, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 545, Training Loss: 9.640e-01, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 546, Training Loss: 9.625e-01, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 547, Training Loss: 9.611e-01, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 548, Training Loss: 9.596e-01, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 549, Training Loss: 9.582e-01, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 550, Training Loss: 9.567e-01, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 551, Training Loss: 9.552e-01, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 552, Training Loss: 9.538e-01, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 553, Training Loss: 9.524e-01, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 554, Training Loss: 9.509e-01, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 555, Training Loss: 9.495e-01, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 556, Training Loss: 9.481e-01, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 557, Training Loss: 9.466e-01, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 558, Training Loss: 9.452e-01, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 559, Training Loss: 9.438e-01, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 560, Training Loss: 9.424e-01, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 561, Training Loss: 9.410e-01, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 562, Training Loss: 9.396e-01, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 563, Training Loss: 9.382e-01, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 564, Training Loss: 9.368e-01, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 565, Training Loss: 9.354e-01, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 566, Training Loss: 9.340e-01, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 567, Training Loss: 9.326e-01, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 568, Training Loss: 9.312e-01, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 569, Training Loss: 9.298e-01, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 570, Training Loss: 9.284e-01, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 571, Training Loss: 9.271e-01, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 572, Training Loss: 9.257e-01, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 573, Training Loss: 9.243e-01, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 574, Training Loss: 9.230e-01, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 575, Training Loss: 9.216e-01, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 576, Training Loss: 9.202e-01, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 577, Training Loss: 9.189e-01, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 578, Training Loss: 9.175e-01, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 579, Training Loss: 9.162e-01, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 580, Training Loss: 9.148e-01, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 581, Training Loss: 9.135e-01, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 582, Training Loss: 9.122e-01, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 583, Training Loss: 9.108e-01, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 584, Training Loss: 9.095e-01, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 585, Training Loss: 9.082e-01, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 586, Training Loss: 9.068e-01, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 587, Training Loss: 9.055e-01, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 588, Training Loss: 9.042e-01, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 589, Training Loss: 9.029e-01, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 590, Training Loss: 9.016e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 591, Training Loss: 9.003e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 592, Training Loss: 8.990e-01, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 593, Training Loss: 8.977e-01, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 594, Training Loss: 8.964e-01, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 595, Training Loss: 8.951e-01, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 596, Training Loss: 8.938e-01, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 597, Training Loss: 8.925e-01, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 598, Training Loss: 8.912e-01, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 599, Training Loss: 8.899e-01, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 600, Training Loss: 8.886e-01, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 601, Training Loss: 8.874e-01, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 602, Training Loss: 8.861e-01, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 603, Training Loss: 8.848e-01, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 604, Training Loss: 8.836e-01, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 605, Training Loss: 8.823e-01, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 606, Training Loss: 8.810e-01, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 607, Training Loss: 8.798e-01, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 608, Training Loss: 8.785e-01, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 609, Training Loss: 8.773e-01, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 610, Training Loss: 8.760e-01, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 611, Training Loss: 8.748e-01, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 612, Training Loss: 8.735e-01, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 613, Training Loss: 8.723e-01, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 614, Training Loss: 8.711e-01, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 615, Training Loss: 8.698e-01, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 616, Training Loss: 8.686e-01, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 617, Training Loss: 8.674e-01, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 618, Training Loss: 8.662e-01, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 619, Training Loss: 8.649e-01, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 620, Training Loss: 8.637e-01, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 621, Training Loss: 8.625e-01, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 622, Training Loss: 8.613e-01, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 623, Training Loss: 8.601e-01, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 624, Training Loss: 8.589e-01, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 625, Training Loss: 8.577e-01, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 626, Training Loss: 8.565e-01, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 627, Training Loss: 8.553e-01, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 628, Training Loss: 8.541e-01, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 629, Training Loss: 8.529e-01, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 630, Training Loss: 8.517e-01, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 631, Training Loss: 8.505e-01, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 632, Training Loss: 8.493e-01, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 633, Training Loss: 8.482e-01, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 634, Training Loss: 8.470e-01, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 635, Training Loss: 8.458e-01, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 636, Training Loss: 8.446e-01, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 637, Training Loss: 8.435e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 638, Training Loss: 8.423e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 639, Training Loss: 8.411e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 640, Training Loss: 8.400e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 641, Training Loss: 8.388e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 642, Training Loss: 8.377e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 643, Training Loss: 8.365e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 644, Training Loss: 8.354e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 645, Training Loss: 8.342e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 646, Training Loss: 8.331e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 647, Training Loss: 8.319e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 648, Training Loss: 8.308e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 649, Training Loss: 8.297e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 650, Training Loss: 8.285e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 651, Training Loss: 8.274e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 652, Training Loss: 8.263e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 653, Training Loss: 8.252e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 654, Training Loss: 8.240e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 655, Training Loss: 8.229e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 656, Training Loss: 8.218e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 657, Training Loss: 8.207e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 658, Training Loss: 8.196e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 659, Training Loss: 8.185e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 660, Training Loss: 8.174e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 661, Training Loss: 8.163e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 662, Training Loss: 8.152e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 663, Training Loss: 8.141e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 664, Training Loss: 8.130e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 665, Training Loss: 8.119e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 666, Training Loss: 8.108e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 667, Training Loss: 8.097e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 668, Training Loss: 8.086e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 669, Training Loss: 8.075e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 670, Training Loss: 8.064e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 671, Training Loss: 8.054e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 672, Training Loss: 8.043e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 673, Training Loss: 8.032e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 674, Training Loss: 8.021e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 675, Training Loss: 8.011e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 676, Training Loss: 8.000e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 677, Training Loss: 7.990e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 678, Training Loss: 7.979e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 679, Training Loss: 7.968e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 680, Training Loss: 7.958e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 681, Training Loss: 7.947e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 682, Training Loss: 7.937e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 683, Training Loss: 7.926e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 684, Training Loss: 7.916e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 685, Training Loss: 7.905e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 686, Training Loss: 7.895e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 687, Training Loss: 7.885e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 688, Training Loss: 7.874e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 689, Training Loss: 7.864e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 690, Training Loss: 7.853e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 691, Training Loss: 7.843e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 692, Training Loss: 7.833e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 693, Training Loss: 7.823e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 694, Training Loss: 7.812e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 695, Training Loss: 7.802e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 696, Training Loss: 7.792e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 697, Training Loss: 7.782e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 698, Training Loss: 7.772e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 699, Training Loss: 7.762e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 700, Training Loss: 7.751e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 701, Training Loss: 7.741e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 702, Training Loss: 7.731e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 703, Training Loss: 7.721e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 704, Training Loss: 7.711e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 705, Training Loss: 7.701e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 706, Training Loss: 7.691e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 707, Training Loss: 7.681e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 708, Training Loss: 7.671e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 709, Training Loss: 7.662e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 710, Training Loss: 7.652e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 711, Training Loss: 7.642e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 712, Training Loss: 7.632e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 713, Training Loss: 7.622e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 714, Training Loss: 7.612e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 715, Training Loss: 7.603e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 716, Training Loss: 7.593e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 717, Training Loss: 7.583e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 718, Training Loss: 7.574e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 719, Training Loss: 7.564e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 720, Training Loss: 7.554e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 721, Training Loss: 7.545e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 722, Training Loss: 7.535e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 723, Training Loss: 7.525e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 724, Training Loss: 7.516e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 725, Training Loss: 7.506e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 726, Training Loss: 7.497e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 727, Training Loss: 7.487e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 728, Training Loss: 7.478e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 729, Training Loss: 7.468e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 730, Training Loss: 7.459e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 731, Training Loss: 7.449e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 732, Training Loss: 7.440e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 733, Training Loss: 7.431e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 734, Training Loss: 7.421e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 735, Training Loss: 7.412e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 736, Training Loss: 7.402e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 737, Training Loss: 7.393e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 738, Training Loss: 7.384e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 739, Training Loss: 7.375e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 740, Training Loss: 7.365e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 741, Training Loss: 7.356e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 742, Training Loss: 7.347e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 743, Training Loss: 7.338e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 744, Training Loss: 7.329e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 745, Training Loss: 7.319e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 746, Training Loss: 7.310e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 747, Training Loss: 7.301e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 748, Training Loss: 7.292e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 749, Training Loss: 7.283e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 750, Training Loss: 7.274e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 751, Training Loss: 7.265e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 752, Training Loss: 7.256e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 753, Training Loss: 7.247e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 754, Training Loss: 7.238e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 755, Training Loss: 7.229e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 756, Training Loss: 7.220e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 757, Training Loss: 7.211e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 758, Training Loss: 7.202e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 759, Training Loss: 7.193e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 760, Training Loss: 7.184e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 761, Training Loss: 7.175e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 762, Training Loss: 7.166e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 763, Training Loss: 7.157e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 764, Training Loss: 7.148e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 765, Training Loss: 7.140e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 766, Training Loss: 7.131e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 767, Training Loss: 7.122e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 768, Training Loss: 7.113e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 769, Training Loss: 7.104e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 770, Training Loss: 7.096e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 771, Training Loss: 7.087e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 772, Training Loss: 7.078e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 773, Training Loss: 7.069e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 774, Training Loss: 7.060e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 775, Training Loss: 7.051e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 776, Training Loss: 7.042e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 777, Training Loss: 7.033e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 778, Training Loss: 7.024e-01, Validation Loss: 9.989e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 779, Training Loss: 7.015e-01, Validation Loss: 9.986e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 780, Training Loss: 7.006e-01, Validation Loss: 9.975e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 781, Training Loss: 6.998e-01, Validation Loss: 9.971e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 782, Training Loss: 6.989e-01, Validation Loss: 9.961e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 783, Training Loss: 6.980e-01, Validation Loss: 9.957e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 784, Training Loss: 6.972e-01, Validation Loss: 9.947e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 785, Training Loss: 6.963e-01, Validation Loss: 9.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 786, Training Loss: 6.955e-01, Validation Loss: 9.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 787, Training Loss: 6.946e-01, Validation Loss: 9.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 788, Training Loss: 6.938e-01, Validation Loss: 9.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 789, Training Loss: 6.929e-01, Validation Loss: 9.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 790, Training Loss: 6.921e-01, Validation Loss: 9.906e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 791, Training Loss: 6.912e-01, Validation Loss: 9.902e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 792, Training Loss: 6.904e-01, Validation Loss: 9.893e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 793, Training Loss: 6.896e-01, Validation Loss: 9.888e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 794, Training Loss: 6.887e-01, Validation Loss: 9.879e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 795, Training Loss: 6.879e-01, Validation Loss: 9.875e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 796, Training Loss: 6.871e-01, Validation Loss: 9.865e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 797, Training Loss: 6.862e-01, Validation Loss: 9.861e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 798, Training Loss: 6.854e-01, Validation Loss: 9.852e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 799, Training Loss: 6.846e-01, Validation Loss: 9.848e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 800, Training Loss: 6.838e-01, Validation Loss: 9.838e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 801, Training Loss: 6.829e-01, Validation Loss: 9.835e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 802, Training Loss: 6.821e-01, Validation Loss: 9.825e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 803, Training Loss: 6.813e-01, Validation Loss: 9.821e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 804, Training Loss: 6.805e-01, Validation Loss: 9.812e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 805, Training Loss: 6.796e-01, Validation Loss: 9.807e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 806, Training Loss: 6.788e-01, Validation Loss: 9.799e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 807, Training Loss: 6.780e-01, Validation Loss: 9.796e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 808, Training Loss: 6.772e-01, Validation Loss: 9.785e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 809, Training Loss: 6.764e-01, Validation Loss: 9.782e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 810, Training Loss: 6.756e-01, Validation Loss: 9.772e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 811, Training Loss: 6.748e-01, Validation Loss: 9.769e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 812, Training Loss: 6.740e-01, Validation Loss: 9.759e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 813, Training Loss: 6.732e-01, Validation Loss: 9.756e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 814, Training Loss: 6.724e-01, Validation Loss: 9.747e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 815, Training Loss: 6.716e-01, Validation Loss: 9.743e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 816, Training Loss: 6.708e-01, Validation Loss: 9.734e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 817, Training Loss: 6.700e-01, Validation Loss: 9.729e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 818, Training Loss: 6.692e-01, Validation Loss: 9.721e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 819, Training Loss: 6.684e-01, Validation Loss: 9.717e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 820, Training Loss: 6.676e-01, Validation Loss: 9.707e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 821, Training Loss: 6.668e-01, Validation Loss: 9.704e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 822, Training Loss: 6.660e-01, Validation Loss: 9.695e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 823, Training Loss: 6.652e-01, Validation Loss: 9.691e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 824, Training Loss: 6.645e-01, Validation Loss: 9.682e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 825, Training Loss: 6.637e-01, Validation Loss: 9.677e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 826, Training Loss: 6.629e-01, Validation Loss: 9.670e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 827, Training Loss: 6.621e-01, Validation Loss: 9.665e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 828, Training Loss: 6.613e-01, Validation Loss: 9.656e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 829, Training Loss: 6.605e-01, Validation Loss: 9.652e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 830, Training Loss: 6.598e-01, Validation Loss: 9.644e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 831, Training Loss: 6.590e-01, Validation Loss: 9.640e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 832, Training Loss: 6.582e-01, Validation Loss: 9.631e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 833, Training Loss: 6.574e-01, Validation Loss: 9.628e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 834, Training Loss: 6.567e-01, Validation Loss: 9.618e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 835, Training Loss: 6.559e-01, Validation Loss: 9.615e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 836, Training Loss: 6.551e-01, Validation Loss: 9.606e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 837, Training Loss: 6.544e-01, Validation Loss: 9.603e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 838, Training Loss: 6.536e-01, Validation Loss: 9.593e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 839, Training Loss: 6.528e-01, Validation Loss: 9.590e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 840, Training Loss: 6.521e-01, Validation Loss: 9.581e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 841, Training Loss: 6.513e-01, Validation Loss: 9.578e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 842, Training Loss: 6.505e-01, Validation Loss: 9.568e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 843, Training Loss: 6.498e-01, Validation Loss: 9.566e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 844, Training Loss: 6.490e-01, Validation Loss: 9.556e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 845, Training Loss: 6.483e-01, Validation Loss: 9.553e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 846, Training Loss: 6.475e-01, Validation Loss: 9.544e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 847, Training Loss: 6.468e-01, Validation Loss: 9.540e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 848, Training Loss: 6.460e-01, Validation Loss: 9.532e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 849, Training Loss: 6.453e-01, Validation Loss: 9.528e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 850, Training Loss: 6.445e-01, Validation Loss: 9.520e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 851, Training Loss: 6.438e-01, Validation Loss: 9.516e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 852, Training Loss: 6.430e-01, Validation Loss: 9.507e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 853, Training Loss: 6.423e-01, Validation Loss: 9.505e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 854, Training Loss: 6.415e-01, Validation Loss: 9.495e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 855, Training Loss: 6.408e-01, Validation Loss: 9.493e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 856, Training Loss: 6.401e-01, Validation Loss: 9.483e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 857, Training Loss: 6.393e-01, Validation Loss: 9.480e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 858, Training Loss: 6.386e-01, Validation Loss: 9.471e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 859, Training Loss: 6.379e-01, Validation Loss: 9.469e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 860, Training Loss: 6.371e-01, Validation Loss: 9.460e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 861, Training Loss: 6.364e-01, Validation Loss: 9.456e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 862, Training Loss: 6.357e-01, Validation Loss: 9.448e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 863, Training Loss: 6.349e-01, Validation Loss: 9.443e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 864, Training Loss: 6.342e-01, Validation Loss: 9.437e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 865, Training Loss: 6.335e-01, Validation Loss: 9.432e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 866, Training Loss: 6.327e-01, Validation Loss: 9.425e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 867, Training Loss: 6.320e-01, Validation Loss: 9.421e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 868, Training Loss: 6.313e-01, Validation Loss: 9.413e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 869, Training Loss: 6.306e-01, Validation Loss: 9.409e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 870, Training Loss: 6.299e-01, Validation Loss: 9.402e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 871, Training Loss: 6.291e-01, Validation Loss: 9.399e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 872, Training Loss: 6.284e-01, Validation Loss: 9.389e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 873, Training Loss: 6.277e-01, Validation Loss: 9.387e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 874, Training Loss: 6.270e-01, Validation Loss: 9.378e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 875, Training Loss: 6.263e-01, Validation Loss: 9.375e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 876, Training Loss: 6.256e-01, Validation Loss: 9.367e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 877, Training Loss: 6.249e-01, Validation Loss: 9.364e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 878, Training Loss: 6.242e-01, Validation Loss: 9.355e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 879, Training Loss: 6.235e-01, Validation Loss: 9.353e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 880, Training Loss: 6.228e-01, Validation Loss: 9.344e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 881, Training Loss: 6.220e-01, Validation Loss: 9.341e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 882, Training Loss: 6.213e-01, Validation Loss: 9.334e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 883, Training Loss: 6.206e-01, Validation Loss: 9.330e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 884, Training Loss: 6.199e-01, Validation Loss: 9.320e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 885, Training Loss: 6.192e-01, Validation Loss: 9.319e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 886, Training Loss: 6.185e-01, Validation Loss: 9.310e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 887, Training Loss: 6.178e-01, Validation Loss: 9.308e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 888, Training Loss: 6.172e-01, Validation Loss: 9.298e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 889, Training Loss: 6.165e-01, Validation Loss: 9.296e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 890, Training Loss: 6.158e-01, Validation Loss: 9.288e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 891, Training Loss: 6.151e-01, Validation Loss: 9.285e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 892, Training Loss: 6.144e-01, Validation Loss: 9.276e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 893, Training Loss: 6.137e-01, Validation Loss: 9.274e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 894, Training Loss: 6.130e-01, Validation Loss: 9.264e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 895, Training Loss: 6.123e-01, Validation Loss: 9.263e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 896, Training Loss: 6.116e-01, Validation Loss: 9.253e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 897, Training Loss: 6.109e-01, Validation Loss: 9.252e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 898, Training Loss: 6.103e-01, Validation Loss: 9.243e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 899, Training Loss: 6.096e-01, Validation Loss: 9.241e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 900, Training Loss: 6.089e-01, Validation Loss: 9.231e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 901, Training Loss: 6.082e-01, Validation Loss: 9.230e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 902, Training Loss: 6.076e-01, Validation Loss: 9.220e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 903, Training Loss: 6.069e-01, Validation Loss: 9.218e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 904, Training Loss: 6.062e-01, Validation Loss: 9.210e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 905, Training Loss: 6.055e-01, Validation Loss: 9.208e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 906, Training Loss: 6.049e-01, Validation Loss: 9.200e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 907, Training Loss: 6.042e-01, Validation Loss: 9.197e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 908, Training Loss: 6.035e-01, Validation Loss: 9.189e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 909, Training Loss: 6.028e-01, Validation Loss: 9.187e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 910, Training Loss: 6.022e-01, Validation Loss: 9.178e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 911, Training Loss: 6.015e-01, Validation Loss: 9.175e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 912, Training Loss: 6.008e-01, Validation Loss: 9.168e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 913, Training Loss: 6.002e-01, Validation Loss: 9.164e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 914, Training Loss: 5.995e-01, Validation Loss: 9.158e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 915, Training Loss: 5.989e-01, Validation Loss: 9.153e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 916, Training Loss: 5.982e-01, Validation Loss: 9.147e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 917, Training Loss: 5.975e-01, Validation Loss: 9.143e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 918, Training Loss: 5.969e-01, Validation Loss: 9.136e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 919, Training Loss: 5.962e-01, Validation Loss: 9.133e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 920, Training Loss: 5.956e-01, Validation Loss: 9.126e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 921, Training Loss: 5.949e-01, Validation Loss: 9.122e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 922, Training Loss: 5.943e-01, Validation Loss: 9.116e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 923, Training Loss: 5.936e-01, Validation Loss: 9.112e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 924, Training Loss: 5.930e-01, Validation Loss: 9.106e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 925, Training Loss: 5.923e-01, Validation Loss: 9.102e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 926, Training Loss: 5.917e-01, Validation Loss: 9.094e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 927, Training Loss: 5.910e-01, Validation Loss: 9.093e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 928, Training Loss: 5.904e-01, Validation Loss: 9.084e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 929, Training Loss: 5.897e-01, Validation Loss: 9.081e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 930, Training Loss: 5.891e-01, Validation Loss: 9.074e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 931, Training Loss: 5.885e-01, Validation Loss: 9.071e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 932, Training Loss: 5.878e-01, Validation Loss: 9.064e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 933, Training Loss: 5.872e-01, Validation Loss: 9.061e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 934, Training Loss: 5.865e-01, Validation Loss: 9.053e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 935, Training Loss: 5.859e-01, Validation Loss: 9.051e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 936, Training Loss: 5.853e-01, Validation Loss: 9.042e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 937, Training Loss: 5.846e-01, Validation Loss: 9.042e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 938, Training Loss: 5.840e-01, Validation Loss: 9.032e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 939, Training Loss: 5.834e-01, Validation Loss: 9.031e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 940, Training Loss: 5.827e-01, Validation Loss: 9.024e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 941, Training Loss: 5.821e-01, Validation Loss: 9.021e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 942, Training Loss: 5.815e-01, Validation Loss: 9.012e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 943, Training Loss: 5.808e-01, Validation Loss: 9.012e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 944, Training Loss: 5.802e-01, Validation Loss: 9.002e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 945, Training Loss: 5.796e-01, Validation Loss: 9.001e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 946, Training Loss: 5.790e-01, Validation Loss: 8.993e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 947, Training Loss: 5.783e-01, Validation Loss: 8.991e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 948, Training Loss: 5.777e-01, Validation Loss: 8.983e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 949, Training Loss: 5.771e-01, Validation Loss: 8.982e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 950, Training Loss: 5.765e-01, Validation Loss: 8.972e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 951, Training Loss: 5.758e-01, Validation Loss: 8.972e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 952, Training Loss: 5.752e-01, Validation Loss: 8.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 953, Training Loss: 5.746e-01, Validation Loss: 8.962e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 954, Training Loss: 5.740e-01, Validation Loss: 8.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 955, Training Loss: 5.734e-01, Validation Loss: 8.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 956, Training Loss: 5.728e-01, Validation Loss: 8.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 957, Training Loss: 5.721e-01, Validation Loss: 8.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 958, Training Loss: 5.715e-01, Validation Loss: 8.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 959, Training Loss: 5.709e-01, Validation Loss: 8.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 960, Training Loss: 5.703e-01, Validation Loss: 8.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 961, Training Loss: 5.697e-01, Validation Loss: 8.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 962, Training Loss: 5.691e-01, Validation Loss: 8.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 963, Training Loss: 5.685e-01, Validation Loss: 8.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 964, Training Loss: 5.679e-01, Validation Loss: 8.905e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 965, Training Loss: 5.673e-01, Validation Loss: 8.904e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 966, Training Loss: 5.667e-01, Validation Loss: 8.895e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 967, Training Loss: 5.661e-01, Validation Loss: 8.895e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 968, Training Loss: 5.655e-01, Validation Loss: 8.886e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 969, Training Loss: 5.649e-01, Validation Loss: 8.886e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 970, Training Loss: 5.643e-01, Validation Loss: 8.876e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 971, Training Loss: 5.637e-01, Validation Loss: 8.875e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 972, Training Loss: 5.631e-01, Validation Loss: 8.867e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 973, Training Loss: 5.625e-01, Validation Loss: 8.866e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 974, Training Loss: 5.619e-01, Validation Loss: 8.858e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 975, Training Loss: 5.613e-01, Validation Loss: 8.857e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 976, Training Loss: 5.607e-01, Validation Loss: 8.848e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 977, Training Loss: 5.601e-01, Validation Loss: 8.847e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 978, Training Loss: 5.595e-01, Validation Loss: 8.839e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 979, Training Loss: 5.589e-01, Validation Loss: 8.837e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 980, Training Loss: 5.583e-01, Validation Loss: 8.829e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 981, Training Loss: 5.577e-01, Validation Loss: 8.828e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 982, Training Loss: 5.572e-01, Validation Loss: 8.819e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 983, Training Loss: 5.566e-01, Validation Loss: 8.819e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 984, Training Loss: 5.560e-01, Validation Loss: 8.811e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 985, Training Loss: 5.554e-01, Validation Loss: 8.810e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 986, Training Loss: 5.548e-01, Validation Loss: 8.801e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 987, Training Loss: 5.542e-01, Validation Loss: 8.801e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 988, Training Loss: 5.537e-01, Validation Loss: 8.792e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 989, Training Loss: 5.531e-01, Validation Loss: 8.791e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 990, Training Loss: 5.525e-01, Validation Loss: 8.783e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 991, Training Loss: 5.519e-01, Validation Loss: 8.782e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 992, Training Loss: 5.513e-01, Validation Loss: 8.773e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 993, Training Loss: 5.508e-01, Validation Loss: 8.774e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 994, Training Loss: 5.502e-01, Validation Loss: 8.764e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 995, Training Loss: 5.496e-01, Validation Loss: 8.764e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 996, Training Loss: 5.490e-01, Validation Loss: 8.756e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 997, Training Loss: 5.485e-01, Validation Loss: 8.755e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 998, Training Loss: 5.479e-01, Validation Loss: 8.747e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 999, Training Loss: 5.473e-01, Validation Loss: 8.746e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1000, Training Loss: 5.468e-01, Validation Loss: 8.738e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1001, Training Loss: 5.462e-01, Validation Loss: 8.737e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1002, Training Loss: 5.456e-01, Validation Loss: 8.729e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1003, Training Loss: 5.451e-01, Validation Loss: 8.729e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1004, Training Loss: 5.445e-01, Validation Loss: 8.720e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1005, Training Loss: 5.439e-01, Validation Loss: 8.719e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1006, Training Loss: 5.434e-01, Validation Loss: 8.712e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1007, Training Loss: 5.428e-01, Validation Loss: 8.711e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1008, Training Loss: 5.423e-01, Validation Loss: 8.702e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1009, Training Loss: 5.417e-01, Validation Loss: 8.702e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1010, Training Loss: 5.411e-01, Validation Loss: 8.693e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1011, Training Loss: 5.406e-01, Validation Loss: 8.693e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1012, Training Loss: 5.400e-01, Validation Loss: 8.684e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1013, Training Loss: 5.395e-01, Validation Loss: 8.684e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1014, Training Loss: 5.389e-01, Validation Loss: 8.677e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1015, Training Loss: 5.383e-01, Validation Loss: 8.675e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1016, Training Loss: 5.378e-01, Validation Loss: 8.667e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1017, Training Loss: 5.372e-01, Validation Loss: 8.667e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1018, Training Loss: 5.367e-01, Validation Loss: 8.658e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1019, Training Loss: 5.361e-01, Validation Loss: 8.658e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1020, Training Loss: 5.356e-01, Validation Loss: 8.650e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1021, Training Loss: 5.350e-01, Validation Loss: 8.649e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1022, Training Loss: 5.345e-01, Validation Loss: 8.641e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1023, Training Loss: 5.339e-01, Validation Loss: 8.640e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1024, Training Loss: 5.334e-01, Validation Loss: 8.634e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1025, Training Loss: 5.328e-01, Validation Loss: 8.632e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1026, Training Loss: 5.323e-01, Validation Loss: 8.625e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1027, Training Loss: 5.318e-01, Validation Loss: 8.623e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1028, Training Loss: 5.312e-01, Validation Loss: 8.616e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1029, Training Loss: 5.307e-01, Validation Loss: 8.615e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1030, Training Loss: 5.301e-01, Validation Loss: 8.608e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1031, Training Loss: 5.296e-01, Validation Loss: 8.606e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1032, Training Loss: 5.291e-01, Validation Loss: 8.599e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1033, Training Loss: 5.285e-01, Validation Loss: 8.598e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1034, Training Loss: 5.280e-01, Validation Loss: 8.590e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1035, Training Loss: 5.274e-01, Validation Loss: 8.589e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1036, Training Loss: 5.269e-01, Validation Loss: 8.583e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1037, Training Loss: 5.264e-01, Validation Loss: 8.581e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1038, Training Loss: 5.258e-01, Validation Loss: 8.573e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1039, Training Loss: 5.253e-01, Validation Loss: 8.573e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1040, Training Loss: 5.248e-01, Validation Loss: 8.565e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1041, Training Loss: 5.242e-01, Validation Loss: 8.565e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1042, Training Loss: 5.237e-01, Validation Loss: 8.557e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1043, Training Loss: 5.232e-01, Validation Loss: 8.556e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1044, Training Loss: 5.227e-01, Validation Loss: 8.549e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1045, Training Loss: 5.221e-01, Validation Loss: 8.548e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1046, Training Loss: 5.216e-01, Validation Loss: 8.540e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1047, Training Loss: 5.211e-01, Validation Loss: 8.540e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1048, Training Loss: 5.206e-01, Validation Loss: 8.532e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1049, Training Loss: 5.200e-01, Validation Loss: 8.532e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1050, Training Loss: 5.195e-01, Validation Loss: 8.524e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1051, Training Loss: 5.190e-01, Validation Loss: 8.524e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1052, Training Loss: 5.185e-01, Validation Loss: 8.516e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1053, Training Loss: 5.179e-01, Validation Loss: 8.516e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1054, Training Loss: 5.174e-01, Validation Loss: 8.509e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1055, Training Loss: 5.169e-01, Validation Loss: 8.508e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1056, Training Loss: 5.164e-01, Validation Loss: 8.499e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1057, Training Loss: 5.159e-01, Validation Loss: 8.499e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1058, Training Loss: 5.154e-01, Validation Loss: 8.492e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1059, Training Loss: 5.148e-01, Validation Loss: 8.491e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1060, Training Loss: 5.143e-01, Validation Loss: 8.485e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1061, Training Loss: 5.138e-01, Validation Loss: 8.482e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1062, Training Loss: 5.133e-01, Validation Loss: 8.476e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1063, Training Loss: 5.128e-01, Validation Loss: 8.475e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1064, Training Loss: 5.123e-01, Validation Loss: 8.468e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1065, Training Loss: 5.118e-01, Validation Loss: 8.466e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1066, Training Loss: 5.112e-01, Validation Loss: 8.460e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1067, Training Loss: 5.107e-01, Validation Loss: 8.459e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1068, Training Loss: 5.102e-01, Validation Loss: 8.452e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1069, Training Loss: 5.097e-01, Validation Loss: 8.451e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1070, Training Loss: 5.092e-01, Validation Loss: 8.444e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1071, Training Loss: 5.087e-01, Validation Loss: 8.443e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1072, Training Loss: 5.082e-01, Validation Loss: 8.436e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1073, Training Loss: 5.077e-01, Validation Loss: 8.435e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1074, Training Loss: 5.072e-01, Validation Loss: 8.428e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1075, Training Loss: 5.067e-01, Validation Loss: 8.427e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1076, Training Loss: 5.062e-01, Validation Loss: 8.420e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1077, Training Loss: 5.057e-01, Validation Loss: 8.419e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1078, Training Loss: 5.052e-01, Validation Loss: 8.412e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1079, Training Loss: 5.047e-01, Validation Loss: 8.412e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1080, Training Loss: 5.042e-01, Validation Loss: 8.404e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1081, Training Loss: 5.037e-01, Validation Loss: 8.404e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1082, Training Loss: 5.032e-01, Validation Loss: 8.397e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1083, Training Loss: 5.027e-01, Validation Loss: 8.396e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1084, Training Loss: 5.022e-01, Validation Loss: 8.389e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1085, Training Loss: 5.017e-01, Validation Loss: 8.389e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1086, Training Loss: 5.012e-01, Validation Loss: 8.381e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1087, Training Loss: 5.007e-01, Validation Loss: 8.381e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1088, Training Loss: 5.002e-01, Validation Loss: 8.374e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1089, Training Loss: 4.997e-01, Validation Loss: 8.373e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1090, Training Loss: 4.993e-01, Validation Loss: 8.366e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1091, Training Loss: 4.988e-01, Validation Loss: 8.366e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1092, Training Loss: 4.983e-01, Validation Loss: 8.359e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1093, Training Loss: 4.978e-01, Validation Loss: 8.358e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1094, Training Loss: 4.973e-01, Validation Loss: 8.352e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1095, Training Loss: 4.968e-01, Validation Loss: 8.351e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1096, Training Loss: 4.963e-01, Validation Loss: 8.344e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1097, Training Loss: 4.958e-01, Validation Loss: 8.343e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1098, Training Loss: 4.954e-01, Validation Loss: 8.336e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1099, Training Loss: 4.949e-01, Validation Loss: 8.337e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1100, Training Loss: 4.944e-01, Validation Loss: 8.329e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1101, Training Loss: 4.939e-01, Validation Loss: 8.328e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1102, Training Loss: 4.934e-01, Validation Loss: 8.321e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1103, Training Loss: 4.930e-01, Validation Loss: 8.322e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1104, Training Loss: 4.925e-01, Validation Loss: 8.314e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1105, Training Loss: 4.920e-01, Validation Loss: 8.314e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1106, Training Loss: 4.915e-01, Validation Loss: 8.306e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1107, Training Loss: 4.910e-01, Validation Loss: 8.307e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1108, Training Loss: 4.906e-01, Validation Loss: 8.299e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1109, Training Loss: 4.901e-01, Validation Loss: 8.298e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1110, Training Loss: 4.896e-01, Validation Loss: 8.292e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1111, Training Loss: 4.891e-01, Validation Loss: 8.292e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1112, Training Loss: 4.887e-01, Validation Loss: 8.285e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1113, Training Loss: 4.882e-01, Validation Loss: 8.285e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1114, Training Loss: 4.877e-01, Validation Loss: 8.277e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1115, Training Loss: 4.873e-01, Validation Loss: 8.278e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1116, Training Loss: 4.868e-01, Validation Loss: 8.270e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1117, Training Loss: 4.863e-01, Validation Loss: 8.270e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1118, Training Loss: 4.859e-01, Validation Loss: 8.262e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1119, Training Loss: 4.854e-01, Validation Loss: 8.263e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1120, Training Loss: 4.849e-01, Validation Loss: 8.255e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1121, Training Loss: 4.844e-01, Validation Loss: 8.256e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1122, Training Loss: 4.840e-01, Validation Loss: 8.249e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1123, Training Loss: 4.835e-01, Validation Loss: 8.248e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1124, Training Loss: 4.830e-01, Validation Loss: 8.242e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1125, Training Loss: 4.826e-01, Validation Loss: 8.241e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1126, Training Loss: 4.821e-01, Validation Loss: 8.234e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1127, Training Loss: 4.817e-01, Validation Loss: 8.234e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1128, Training Loss: 4.812e-01, Validation Loss: 8.227e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1129, Training Loss: 4.807e-01, Validation Loss: 8.227e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1130, Training Loss: 4.803e-01, Validation Loss: 8.221e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1131, Training Loss: 4.798e-01, Validation Loss: 8.219e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1132, Training Loss: 4.794e-01, Validation Loss: 8.213e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1133, Training Loss: 4.789e-01, Validation Loss: 8.213e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1134, Training Loss: 4.784e-01, Validation Loss: 8.206e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1135, Training Loss: 4.780e-01, Validation Loss: 8.206e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1136, Training Loss: 4.775e-01, Validation Loss: 8.199e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1137, Training Loss: 4.771e-01, Validation Loss: 8.199e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1138, Training Loss: 4.766e-01, Validation Loss: 8.193e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1139, Training Loss: 4.762e-01, Validation Loss: 8.191e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1140, Training Loss: 4.757e-01, Validation Loss: 8.186e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1141, Training Loss: 4.752e-01, Validation Loss: 8.184e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1142, Training Loss: 4.748e-01, Validation Loss: 8.179e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1143, Training Loss: 4.743e-01, Validation Loss: 8.178e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1144, Training Loss: 4.739e-01, Validation Loss: 8.172e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1145, Training Loss: 4.734e-01, Validation Loss: 8.172e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1146, Training Loss: 4.730e-01, Validation Loss: 8.165e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1147, Training Loss: 4.725e-01, Validation Loss: 8.165e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1148, Training Loss: 4.721e-01, Validation Loss: 8.158e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1149, Training Loss: 4.716e-01, Validation Loss: 8.157e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1150, Training Loss: 4.712e-01, Validation Loss: 8.152e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1151, Training Loss: 4.708e-01, Validation Loss: 8.151e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1152, Training Loss: 4.703e-01, Validation Loss: 8.145e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1153, Training Loss: 4.699e-01, Validation Loss: 8.143e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1154, Training Loss: 4.694e-01, Validation Loss: 8.138e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1155, Training Loss: 4.690e-01, Validation Loss: 8.137e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1156, Training Loss: 4.685e-01, Validation Loss: 8.131e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1157, Training Loss: 4.681e-01, Validation Loss: 8.131e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1158, Training Loss: 4.677e-01, Validation Loss: 8.125e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1159, Training Loss: 4.672e-01, Validation Loss: 8.124e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1160, Training Loss: 4.668e-01, Validation Loss: 8.117e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1161, Training Loss: 4.663e-01, Validation Loss: 8.117e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1162, Training Loss: 4.659e-01, Validation Loss: 8.111e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1163, Training Loss: 4.655e-01, Validation Loss: 8.109e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1164, Training Loss: 4.650e-01, Validation Loss: 8.106e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1165, Training Loss: 4.646e-01, Validation Loss: 8.103e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1166, Training Loss: 4.641e-01, Validation Loss: 8.099e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1167, Training Loss: 4.637e-01, Validation Loss: 8.095e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1168, Training Loss: 4.633e-01, Validation Loss: 8.092e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1169, Training Loss: 4.628e-01, Validation Loss: 8.089e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1170, Training Loss: 4.624e-01, Validation Loss: 8.086e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1171, Training Loss: 4.620e-01, Validation Loss: 8.082e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1172, Training Loss: 4.615e-01, Validation Loss: 8.080e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1173, Training Loss: 4.611e-01, Validation Loss: 8.075e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1174, Training Loss: 4.607e-01, Validation Loss: 8.073e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1175, Training Loss: 4.603e-01, Validation Loss: 8.069e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1176, Training Loss: 4.598e-01, Validation Loss: 8.067e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1177, Training Loss: 4.594e-01, Validation Loss: 8.062e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1178, Training Loss: 4.590e-01, Validation Loss: 8.061e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1179, Training Loss: 4.585e-01, Validation Loss: 8.056e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1180, Training Loss: 4.581e-01, Validation Loss: 8.054e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1181, Training Loss: 4.577e-01, Validation Loss: 8.048e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1182, Training Loss: 4.573e-01, Validation Loss: 8.048e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1183, Training Loss: 4.568e-01, Validation Loss: 8.042e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1184, Training Loss: 4.564e-01, Validation Loss: 8.041e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1185, Training Loss: 4.560e-01, Validation Loss: 8.036e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1186, Training Loss: 4.556e-01, Validation Loss: 8.035e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1187, Training Loss: 4.551e-01, Validation Loss: 8.029e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1188, Training Loss: 4.547e-01, Validation Loss: 8.030e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1189, Training Loss: 4.543e-01, Validation Loss: 8.023e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1190, Training Loss: 4.539e-01, Validation Loss: 8.021e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1191, Training Loss: 4.535e-01, Validation Loss: 8.018e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1192, Training Loss: 4.530e-01, Validation Loss: 8.014e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1193, Training Loss: 4.526e-01, Validation Loss: 8.010e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1194, Training Loss: 4.522e-01, Validation Loss: 8.010e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1195, Training Loss: 4.518e-01, Validation Loss: 8.004e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1196, Training Loss: 4.514e-01, Validation Loss: 8.004e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1197, Training Loss: 4.510e-01, Validation Loss: 7.998e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1198, Training Loss: 4.505e-01, Validation Loss: 7.997e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1199, Training Loss: 4.501e-01, Validation Loss: 7.991e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1200, Training Loss: 4.497e-01, Validation Loss: 7.992e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1201, Training Loss: 4.493e-01, Validation Loss: 7.985e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1202, Training Loss: 4.489e-01, Validation Loss: 7.984e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1203, Training Loss: 4.485e-01, Validation Loss: 7.979e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1204, Training Loss: 4.481e-01, Validation Loss: 7.980e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1205, Training Loss: 4.476e-01, Validation Loss: 7.973e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1206, Training Loss: 4.472e-01, Validation Loss: 7.971e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1207, Training Loss: 4.468e-01, Validation Loss: 7.968e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1208, Training Loss: 4.464e-01, Validation Loss: 7.964e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1209, Training Loss: 4.460e-01, Validation Loss: 7.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1210, Training Loss: 4.456e-01, Validation Loss: 7.958e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1211, Training Loss: 4.452e-01, Validation Loss: 7.956e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1212, Training Loss: 4.448e-01, Validation Loss: 7.952e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1213, Training Loss: 4.444e-01, Validation Loss: 7.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1214, Training Loss: 4.440e-01, Validation Loss: 7.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1215, Training Loss: 4.435e-01, Validation Loss: 7.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1216, Training Loss: 4.431e-01, Validation Loss: 7.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1217, Training Loss: 4.427e-01, Validation Loss: 7.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1218, Training Loss: 4.423e-01, Validation Loss: 7.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1219, Training Loss: 4.419e-01, Validation Loss: 7.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1220, Training Loss: 4.415e-01, Validation Loss: 7.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1221, Training Loss: 4.411e-01, Validation Loss: 7.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1222, Training Loss: 4.407e-01, Validation Loss: 7.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1223, Training Loss: 4.403e-01, Validation Loss: 7.918e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1224, Training Loss: 4.399e-01, Validation Loss: 7.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1225, Training Loss: 4.395e-01, Validation Loss: 7.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1226, Training Loss: 4.391e-01, Validation Loss: 7.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1227, Training Loss: 4.387e-01, Validation Loss: 7.907e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1228, Training Loss: 4.383e-01, Validation Loss: 7.903e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1229, Training Loss: 4.379e-01, Validation Loss: 7.903e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1230, Training Loss: 4.375e-01, Validation Loss: 7.897e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1231, Training Loss: 4.371e-01, Validation Loss: 7.895e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1232, Training Loss: 4.367e-01, Validation Loss: 7.891e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1233, Training Loss: 4.363e-01, Validation Loss: 7.891e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1234, Training Loss: 4.360e-01, Validation Loss: 7.885e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1235, Training Loss: 4.355e-01, Validation Loss: 7.883e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1236, Training Loss: 4.351e-01, Validation Loss: 7.879e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1237, Training Loss: 4.348e-01, Validation Loss: 7.879e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1238, Training Loss: 4.344e-01, Validation Loss: 7.873e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1239, Training Loss: 4.340e-01, Validation Loss: 7.872e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1240, Training Loss: 4.336e-01, Validation Loss: 7.870e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1241, Training Loss: 4.332e-01, Validation Loss: 7.865e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1242, Training Loss: 4.328e-01, Validation Loss: 7.863e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1243, Training Loss: 4.324e-01, Validation Loss: 7.859e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1244, Training Loss: 4.320e-01, Validation Loss: 7.858e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1245, Training Loss: 4.316e-01, Validation Loss: 7.854e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1246, Training Loss: 4.312e-01, Validation Loss: 7.851e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1247, Training Loss: 4.309e-01, Validation Loss: 7.847e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1248, Training Loss: 4.305e-01, Validation Loss: 7.848e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1249, Training Loss: 4.301e-01, Validation Loss: 7.842e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1250, Training Loss: 4.297e-01, Validation Loss: 7.839e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1251, Training Loss: 4.293e-01, Validation Loss: 7.836e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1252, Training Loss: 4.289e-01, Validation Loss: 7.836e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1253, Training Loss: 4.286e-01, Validation Loss: 7.830e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1254, Training Loss: 4.282e-01, Validation Loss: 7.829e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1255, Training Loss: 4.278e-01, Validation Loss: 7.824e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1256, Training Loss: 4.274e-01, Validation Loss: 7.824e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1257, Training Loss: 4.270e-01, Validation Loss: 7.818e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1258, Training Loss: 4.266e-01, Validation Loss: 7.817e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1259, Training Loss: 4.263e-01, Validation Loss: 7.813e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1260, Training Loss: 4.259e-01, Validation Loss: 7.813e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1261, Training Loss: 4.255e-01, Validation Loss: 7.807e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1262, Training Loss: 4.251e-01, Validation Loss: 7.807e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1263, Training Loss: 4.247e-01, Validation Loss: 7.801e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1264, Training Loss: 4.244e-01, Validation Loss: 7.801e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1265, Training Loss: 4.240e-01, Validation Loss: 7.796e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1266, Training Loss: 4.236e-01, Validation Loss: 7.794e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1267, Training Loss: 4.232e-01, Validation Loss: 7.790e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1268, Training Loss: 4.228e-01, Validation Loss: 7.791e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1269, Training Loss: 4.225e-01, Validation Loss: 7.785e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1270, Training Loss: 4.221e-01, Validation Loss: 7.783e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1271, Training Loss: 4.217e-01, Validation Loss: 7.780e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1272, Training Loss: 4.213e-01, Validation Loss: 7.779e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1273, Training Loss: 4.210e-01, Validation Loss: 7.774e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1274, Training Loss: 4.206e-01, Validation Loss: 7.772e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1275, Training Loss: 4.202e-01, Validation Loss: 7.768e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1276, Training Loss: 4.198e-01, Validation Loss: 7.768e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1277, Training Loss: 4.195e-01, Validation Loss: 7.762e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1278, Training Loss: 4.191e-01, Validation Loss: 7.761e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1279, Training Loss: 4.187e-01, Validation Loss: 7.757e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1280, Training Loss: 4.184e-01, Validation Loss: 7.757e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1281, Training Loss: 4.180e-01, Validation Loss: 7.751e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1282, Training Loss: 4.176e-01, Validation Loss: 7.751e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1283, Training Loss: 4.173e-01, Validation Loss: 7.746e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1284, Training Loss: 4.169e-01, Validation Loss: 7.747e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1285, Training Loss: 4.165e-01, Validation Loss: 7.740e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1286, Training Loss: 4.162e-01, Validation Loss: 7.741e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1287, Training Loss: 4.158e-01, Validation Loss: 7.735e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1288, Training Loss: 4.154e-01, Validation Loss: 7.734e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1289, Training Loss: 4.151e-01, Validation Loss: 7.731e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1290, Training Loss: 4.147e-01, Validation Loss: 7.728e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1291, Training Loss: 4.143e-01, Validation Loss: 7.727e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1292, Training Loss: 4.140e-01, Validation Loss: 7.722e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1293, Training Loss: 4.136e-01, Validation Loss: 7.721e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1294, Training Loss: 4.132e-01, Validation Loss: 7.717e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1295, Training Loss: 4.129e-01, Validation Loss: 7.715e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1296, Training Loss: 4.125e-01, Validation Loss: 7.712e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1297, Training Loss: 4.122e-01, Validation Loss: 7.711e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1298, Training Loss: 4.118e-01, Validation Loss: 7.707e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1299, Training Loss: 4.114e-01, Validation Loss: 7.703e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1300, Training Loss: 4.111e-01, Validation Loss: 7.704e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1301, Training Loss: 4.107e-01, Validation Loss: 7.698e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1302, Training Loss: 4.104e-01, Validation Loss: 7.696e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1303, Training Loss: 4.100e-01, Validation Loss: 7.693e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1304, Training Loss: 4.096e-01, Validation Loss: 7.691e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1305, Training Loss: 4.093e-01, Validation Loss: 7.689e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1306, Training Loss: 4.089e-01, Validation Loss: 7.686e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1307, Training Loss: 4.086e-01, Validation Loss: 7.683e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1308, Training Loss: 4.082e-01, Validation Loss: 7.680e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1309, Training Loss: 4.079e-01, Validation Loss: 7.680e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1310, Training Loss: 4.075e-01, Validation Loss: 7.675e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1311, Training Loss: 4.071e-01, Validation Loss: 7.674e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1312, Training Loss: 4.068e-01, Validation Loss: 7.670e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1313, Training Loss: 4.064e-01, Validation Loss: 7.667e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1314, Training Loss: 4.061e-01, Validation Loss: 7.665e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1315, Training Loss: 4.057e-01, Validation Loss: 7.663e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1316, Training Loss: 4.054e-01, Validation Loss: 7.660e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1317, Training Loss: 4.050e-01, Validation Loss: 7.658e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1318, Training Loss: 4.047e-01, Validation Loss: 7.655e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1319, Training Loss: 4.043e-01, Validation Loss: 7.651e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1320, Training Loss: 4.040e-01, Validation Loss: 7.653e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1321, Training Loss: 4.036e-01, Validation Loss: 7.646e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1322, Training Loss: 4.033e-01, Validation Loss: 7.646e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1323, Training Loss: 4.029e-01, Validation Loss: 7.641e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1324, Training Loss: 4.026e-01, Validation Loss: 7.641e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1325, Training Loss: 4.022e-01, Validation Loss: 7.635e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1326, Training Loss: 4.019e-01, Validation Loss: 7.637e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1327, Training Loss: 4.015e-01, Validation Loss: 7.631e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1328, Training Loss: 4.012e-01, Validation Loss: 7.630e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1329, Training Loss: 4.009e-01, Validation Loss: 7.626e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1330, Training Loss: 4.005e-01, Validation Loss: 7.627e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1331, Training Loss: 4.002e-01, Validation Loss: 7.621e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1332, Training Loss: 3.998e-01, Validation Loss: 7.621e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1333, Training Loss: 3.995e-01, Validation Loss: 7.616e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1334, Training Loss: 3.991e-01, Validation Loss: 7.616e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1335, Training Loss: 3.988e-01, Validation Loss: 7.611e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1336, Training Loss: 3.984e-01, Validation Loss: 7.611e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1337, Training Loss: 3.981e-01, Validation Loss: 7.606e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1338, Training Loss: 3.978e-01, Validation Loss: 7.605e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1339, Training Loss: 3.974e-01, Validation Loss: 7.601e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1340, Training Loss: 3.971e-01, Validation Loss: 7.602e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1341, Training Loss: 3.967e-01, Validation Loss: 7.596e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1342, Training Loss: 3.964e-01, Validation Loss: 7.596e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1343, Training Loss: 3.961e-01, Validation Loss: 7.591e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1344, Training Loss: 3.957e-01, Validation Loss: 7.593e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1345, Training Loss: 3.954e-01, Validation Loss: 7.586e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1346, Training Loss: 3.950e-01, Validation Loss: 7.585e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1347, Training Loss: 3.947e-01, Validation Loss: 7.582e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1348, Training Loss: 3.944e-01, Validation Loss: 7.582e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1349, Training Loss: 3.940e-01, Validation Loss: 7.577e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1350, Training Loss: 3.937e-01, Validation Loss: 7.576e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1351, Training Loss: 3.934e-01, Validation Loss: 7.571e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1352, Training Loss: 3.930e-01, Validation Loss: 7.573e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1353, Training Loss: 3.927e-01, Validation Loss: 7.567e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1354, Training Loss: 3.924e-01, Validation Loss: 7.565e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1355, Training Loss: 3.920e-01, Validation Loss: 7.565e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1356, Training Loss: 3.917e-01, Validation Loss: 7.560e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1357, Training Loss: 3.913e-01, Validation Loss: 7.559e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1358, Training Loss: 3.910e-01, Validation Loss: 7.556e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1359, Training Loss: 3.907e-01, Validation Loss: 7.555e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1360, Training Loss: 3.904e-01, Validation Loss: 7.551e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1361, Training Loss: 3.900e-01, Validation Loss: 7.550e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1362, Training Loss: 3.897e-01, Validation Loss: 7.546e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1363, Training Loss: 3.894e-01, Validation Loss: 7.544e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1364, Training Loss: 3.890e-01, Validation Loss: 7.541e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1365, Training Loss: 3.887e-01, Validation Loss: 7.541e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1366, Training Loss: 3.884e-01, Validation Loss: 7.536e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1367, Training Loss: 3.880e-01, Validation Loss: 7.536e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1368, Training Loss: 3.877e-01, Validation Loss: 7.532e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1369, Training Loss: 3.874e-01, Validation Loss: 7.530e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1370, Training Loss: 3.871e-01, Validation Loss: 7.527e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1371, Training Loss: 3.867e-01, Validation Loss: 7.526e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1372, Training Loss: 3.864e-01, Validation Loss: 7.522e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1373, Training Loss: 3.861e-01, Validation Loss: 7.523e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1374, Training Loss: 3.858e-01, Validation Loss: 7.517e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1375, Training Loss: 3.854e-01, Validation Loss: 7.514e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1376, Training Loss: 3.851e-01, Validation Loss: 7.517e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1377, Training Loss: 3.848e-01, Validation Loss: 7.509e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1378, Training Loss: 3.845e-01, Validation Loss: 7.510e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1379, Training Loss: 3.841e-01, Validation Loss: 7.506e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1380, Training Loss: 3.838e-01, Validation Loss: 7.506e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1381, Training Loss: 3.835e-01, Validation Loss: 7.501e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1382, Training Loss: 3.832e-01, Validation Loss: 7.501e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1383, Training Loss: 3.828e-01, Validation Loss: 7.496e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1384, Training Loss: 3.825e-01, Validation Loss: 7.498e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1385, Training Loss: 3.822e-01, Validation Loss: 7.492e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1386, Training Loss: 3.819e-01, Validation Loss: 7.491e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1387, Training Loss: 3.816e-01, Validation Loss: 7.488e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1388, Training Loss: 3.812e-01, Validation Loss: 7.487e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1389, Training Loss: 3.809e-01, Validation Loss: 7.483e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1390, Training Loss: 3.806e-01, Validation Loss: 7.481e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1391, Training Loss: 3.803e-01, Validation Loss: 7.481e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1392, Training Loss: 3.800e-01, Validation Loss: 7.476e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1393, Training Loss: 3.796e-01, Validation Loss: 7.476e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1394, Training Loss: 3.793e-01, Validation Loss: 7.471e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1395, Training Loss: 3.790e-01, Validation Loss: 7.472e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1396, Training Loss: 3.787e-01, Validation Loss: 7.466e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1397, Training Loss: 3.784e-01, Validation Loss: 7.467e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1398, Training Loss: 3.781e-01, Validation Loss: 7.463e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1399, Training Loss: 3.777e-01, Validation Loss: 7.462e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1400, Training Loss: 3.774e-01, Validation Loss: 7.458e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1401, Training Loss: 3.771e-01, Validation Loss: 7.459e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1402, Training Loss: 3.768e-01, Validation Loss: 7.454e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1403, Training Loss: 3.765e-01, Validation Loss: 7.453e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1404, Training Loss: 3.762e-01, Validation Loss: 7.450e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1405, Training Loss: 3.759e-01, Validation Loss: 7.448e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1406, Training Loss: 3.755e-01, Validation Loss: 7.446e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1407, Training Loss: 3.752e-01, Validation Loss: 7.444e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1408, Training Loss: 3.749e-01, Validation Loss: 7.441e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1409, Training Loss: 3.746e-01, Validation Loss: 7.440e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1410, Training Loss: 3.743e-01, Validation Loss: 7.436e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1411, Training Loss: 3.740e-01, Validation Loss: 7.436e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1412, Training Loss: 3.737e-01, Validation Loss: 7.432e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1413, Training Loss: 3.734e-01, Validation Loss: 7.431e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1414, Training Loss: 3.731e-01, Validation Loss: 7.428e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1415, Training Loss: 3.727e-01, Validation Loss: 7.427e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1416, Training Loss: 3.724e-01, Validation Loss: 7.422e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1417, Training Loss: 3.721e-01, Validation Loss: 7.423e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1418, Training Loss: 3.718e-01, Validation Loss: 7.418e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1419, Training Loss: 3.715e-01, Validation Loss: 7.419e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1420, Training Loss: 3.712e-01, Validation Loss: 7.413e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1421, Training Loss: 3.709e-01, Validation Loss: 7.416e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1422, Training Loss: 3.706e-01, Validation Loss: 7.409e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1423, Training Loss: 3.703e-01, Validation Loss: 7.409e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1424, Training Loss: 3.700e-01, Validation Loss: 7.408e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1425, Training Loss: 3.697e-01, Validation Loss: 7.404e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1426, Training Loss: 3.694e-01, Validation Loss: 7.402e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1427, Training Loss: 3.691e-01, Validation Loss: 7.401e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1428, Training Loss: 3.688e-01, Validation Loss: 7.397e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1429, Training Loss: 3.685e-01, Validation Loss: 7.396e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1430, Training Loss: 3.682e-01, Validation Loss: 7.392e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1431, Training Loss: 3.679e-01, Validation Loss: 7.394e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1432, Training Loss: 3.676e-01, Validation Loss: 7.388e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1433, Training Loss: 3.673e-01, Validation Loss: 7.388e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1434, Training Loss: 3.669e-01, Validation Loss: 7.384e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1435, Training Loss: 3.667e-01, Validation Loss: 7.386e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1436, Training Loss: 3.664e-01, Validation Loss: 7.380e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1437, Training Loss: 3.660e-01, Validation Loss: 7.379e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1438, Training Loss: 3.657e-01, Validation Loss: 7.376e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1439, Training Loss: 3.654e-01, Validation Loss: 7.376e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1440, Training Loss: 3.651e-01, Validation Loss: 7.372e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1441, Training Loss: 3.648e-01, Validation Loss: 7.372e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1442, Training Loss: 3.646e-01, Validation Loss: 7.367e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1443, Training Loss: 3.643e-01, Validation Loss: 7.368e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1444, Training Loss: 3.640e-01, Validation Loss: 7.362e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1445, Training Loss: 3.637e-01, Validation Loss: 7.365e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1446, Training Loss: 3.634e-01, Validation Loss: 7.359e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1447, Training Loss: 3.631e-01, Validation Loss: 7.357e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1448, Training Loss: 3.628e-01, Validation Loss: 7.358e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1449, Training Loss: 3.625e-01, Validation Loss: 7.353e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1450, Training Loss: 3.622e-01, Validation Loss: 7.353e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1451, Training Loss: 3.619e-01, Validation Loss: 7.349e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1452, Training Loss: 3.616e-01, Validation Loss: 7.349e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1453, Training Loss: 3.613e-01, Validation Loss: 7.345e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1454, Training Loss: 3.610e-01, Validation Loss: 7.343e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1455, Training Loss: 3.607e-01, Validation Loss: 7.343e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1456, Training Loss: 3.604e-01, Validation Loss: 7.339e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1457, Training Loss: 3.601e-01, Validation Loss: 7.338e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1458, Training Loss: 3.598e-01, Validation Loss: 7.335e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1459, Training Loss: 3.595e-01, Validation Loss: 7.334e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1460, Training Loss: 3.592e-01, Validation Loss: 7.331e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1461, Training Loss: 3.589e-01, Validation Loss: 7.330e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1462, Training Loss: 3.586e-01, Validation Loss: 7.326e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1463, Training Loss: 3.584e-01, Validation Loss: 7.325e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1464, Training Loss: 3.581e-01, Validation Loss: 7.323e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1465, Training Loss: 3.578e-01, Validation Loss: 7.322e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1466, Training Loss: 3.575e-01, Validation Loss: 7.318e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1467, Training Loss: 3.572e-01, Validation Loss: 7.318e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1468, Training Loss: 3.569e-01, Validation Loss: 7.314e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1469, Training Loss: 3.566e-01, Validation Loss: 7.314e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1470, Training Loss: 3.563e-01, Validation Loss: 7.310e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1471, Training Loss: 3.560e-01, Validation Loss: 7.311e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1472, Training Loss: 3.558e-01, Validation Loss: 7.305e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1473, Training Loss: 3.555e-01, Validation Loss: 7.307e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1474, Training Loss: 3.552e-01, Validation Loss: 7.301e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1475, Training Loss: 3.549e-01, Validation Loss: 7.302e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1476, Training Loss: 3.546e-01, Validation Loss: 7.299e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1477, Training Loss: 3.543e-01, Validation Loss: 7.297e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1478, Training Loss: 3.540e-01, Validation Loss: 7.296e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1479, Training Loss: 3.537e-01, Validation Loss: 7.293e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1480, Training Loss: 3.535e-01, Validation Loss: 7.292e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1481, Training Loss: 3.532e-01, Validation Loss: 7.289e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1482, Training Loss: 3.529e-01, Validation Loss: 7.288e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1483, Training Loss: 3.526e-01, Validation Loss: 7.285e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1484, Training Loss: 3.523e-01, Validation Loss: 7.282e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1485, Training Loss: 3.520e-01, Validation Loss: 7.284e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1486, Training Loss: 3.518e-01, Validation Loss: 7.278e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1487, Training Loss: 3.515e-01, Validation Loss: 7.279e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1488, Training Loss: 3.512e-01, Validation Loss: 7.274e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1489, Training Loss: 3.509e-01, Validation Loss: 7.275e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1490, Training Loss: 3.506e-01, Validation Loss: 7.270e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1491, Training Loss: 3.503e-01, Validation Loss: 7.271e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1492, Training Loss: 3.501e-01, Validation Loss: 7.267e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1493, Training Loss: 3.498e-01, Validation Loss: 7.267e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1494, Training Loss: 3.495e-01, Validation Loss: 7.262e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1495, Training Loss: 3.492e-01, Validation Loss: 7.263e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1496, Training Loss: 3.489e-01, Validation Loss: 7.259e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1497, Training Loss: 3.487e-01, Validation Loss: 7.260e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1498, Training Loss: 3.484e-01, Validation Loss: 7.255e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1499, Training Loss: 3.481e-01, Validation Loss: 7.256e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1500, Training Loss: 3.478e-01, Validation Loss: 7.251e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1501, Training Loss: 3.475e-01, Validation Loss: 7.250e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1502, Training Loss: 3.473e-01, Validation Loss: 7.249e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1503, Training Loss: 3.470e-01, Validation Loss: 7.246e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1504, Training Loss: 3.467e-01, Validation Loss: 7.246e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1505, Training Loss: 3.464e-01, Validation Loss: 7.242e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1506, Training Loss: 3.462e-01, Validation Loss: 7.242e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1507, Training Loss: 3.459e-01, Validation Loss: 7.238e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1508, Training Loss: 3.456e-01, Validation Loss: 7.238e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1509, Training Loss: 3.453e-01, Validation Loss: 7.234e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1510, Training Loss: 3.451e-01, Validation Loss: 7.235e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1511, Training Loss: 3.448e-01, Validation Loss: 7.230e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1512, Training Loss: 3.445e-01, Validation Loss: 7.231e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1513, Training Loss: 3.442e-01, Validation Loss: 7.227e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1514, Training Loss: 3.440e-01, Validation Loss: 7.226e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1515, Training Loss: 3.437e-01, Validation Loss: 7.225e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1516, Training Loss: 3.434e-01, Validation Loss: 7.221e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1517, Training Loss: 3.431e-01, Validation Loss: 7.219e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1518, Training Loss: 3.429e-01, Validation Loss: 7.220e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1519, Training Loss: 3.426e-01, Validation Loss: 7.216e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1520, Training Loss: 3.423e-01, Validation Loss: 7.214e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1521, Training Loss: 3.421e-01, Validation Loss: 7.213e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1522, Training Loss: 3.418e-01, Validation Loss: 7.211e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1523, Training Loss: 3.415e-01, Validation Loss: 7.209e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1524, Training Loss: 3.412e-01, Validation Loss: 7.207e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1525, Training Loss: 3.410e-01, Validation Loss: 7.205e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1526, Training Loss: 3.407e-01, Validation Loss: 7.203e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1527, Training Loss: 3.404e-01, Validation Loss: 7.202e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1528, Training Loss: 3.402e-01, Validation Loss: 7.199e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1529, Training Loss: 3.399e-01, Validation Loss: 7.199e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1530, Training Loss: 3.396e-01, Validation Loss: 7.195e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1531, Training Loss: 3.394e-01, Validation Loss: 7.195e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1532, Training Loss: 3.391e-01, Validation Loss: 7.192e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1533, Training Loss: 3.388e-01, Validation Loss: 7.191e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1534, Training Loss: 3.385e-01, Validation Loss: 7.188e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1535, Training Loss: 3.383e-01, Validation Loss: 7.188e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1536, Training Loss: 3.380e-01, Validation Loss: 7.184e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1537, Training Loss: 3.377e-01, Validation Loss: 7.185e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1538, Training Loss: 3.375e-01, Validation Loss: 7.181e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1539, Training Loss: 3.372e-01, Validation Loss: 7.180e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1540, Training Loss: 3.370e-01, Validation Loss: 7.177e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1541, Training Loss: 3.367e-01, Validation Loss: 7.177e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1542, Training Loss: 3.364e-01, Validation Loss: 7.173e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1543, Training Loss: 3.362e-01, Validation Loss: 7.174e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1544, Training Loss: 3.359e-01, Validation Loss: 7.169e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1545, Training Loss: 3.356e-01, Validation Loss: 7.171e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1546, Training Loss: 3.354e-01, Validation Loss: 7.166e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1547, Training Loss: 3.351e-01, Validation Loss: 7.165e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1548, Training Loss: 3.348e-01, Validation Loss: 7.164e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1549, Training Loss: 3.346e-01, Validation Loss: 7.162e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1550, Training Loss: 3.343e-01, Validation Loss: 7.160e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1551, Training Loss: 3.340e-01, Validation Loss: 7.158e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1552, Training Loss: 3.338e-01, Validation Loss: 7.157e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1553, Training Loss: 3.335e-01, Validation Loss: 7.154e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1554, Training Loss: 3.333e-01, Validation Loss: 7.154e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1555, Training Loss: 3.330e-01, Validation Loss: 7.150e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1556, Training Loss: 3.327e-01, Validation Loss: 7.150e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1557, Training Loss: 3.325e-01, Validation Loss: 7.147e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1558, Training Loss: 3.322e-01, Validation Loss: 7.146e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1559, Training Loss: 3.320e-01, Validation Loss: 7.144e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1560, Training Loss: 3.317e-01, Validation Loss: 7.142e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1561, Training Loss: 3.314e-01, Validation Loss: 7.140e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1562, Training Loss: 3.312e-01, Validation Loss: 7.140e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1563, Training Loss: 3.309e-01, Validation Loss: 7.136e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1564, Training Loss: 3.307e-01, Validation Loss: 7.136e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1565, Training Loss: 3.304e-01, Validation Loss: 7.133e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1566, Training Loss: 3.301e-01, Validation Loss: 7.132e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1567, Training Loss: 3.299e-01, Validation Loss: 7.130e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1568, Training Loss: 3.296e-01, Validation Loss: 7.130e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1569, Training Loss: 3.294e-01, Validation Loss: 7.126e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1570, Training Loss: 3.291e-01, Validation Loss: 7.127e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1571, Training Loss: 3.289e-01, Validation Loss: 7.122e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1572, Training Loss: 3.286e-01, Validation Loss: 7.124e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1573, Training Loss: 3.284e-01, Validation Loss: 7.118e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1574, Training Loss: 3.281e-01, Validation Loss: 7.121e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1575, Training Loss: 3.279e-01, Validation Loss: 7.115e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1576, Training Loss: 3.276e-01, Validation Loss: 7.115e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1577, Training Loss: 3.273e-01, Validation Loss: 7.114e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1578, Training Loss: 3.271e-01, Validation Loss: 7.111e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1579, Training Loss: 3.268e-01, Validation Loss: 7.110e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1580, Training Loss: 3.266e-01, Validation Loss: 7.108e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1581, Training Loss: 3.263e-01, Validation Loss: 7.107e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1582, Training Loss: 3.261e-01, Validation Loss: 7.105e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1583, Training Loss: 3.258e-01, Validation Loss: 7.102e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1584, Training Loss: 3.256e-01, Validation Loss: 7.103e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1585, Training Loss: 3.253e-01, Validation Loss: 7.098e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1586, Training Loss: 3.251e-01, Validation Loss: 7.099e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1587, Training Loss: 3.248e-01, Validation Loss: 7.095e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1588, Training Loss: 3.246e-01, Validation Loss: 7.096e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1589, Training Loss: 3.243e-01, Validation Loss: 7.092e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1590, Training Loss: 3.241e-01, Validation Loss: 7.093e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1591, Training Loss: 3.238e-01, Validation Loss: 7.088e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1592, Training Loss: 3.236e-01, Validation Loss: 7.090e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1593, Training Loss: 3.233e-01, Validation Loss: 7.085e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1594, Training Loss: 3.231e-01, Validation Loss: 7.086e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1595, Training Loss: 3.228e-01, Validation Loss: 7.082e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1596, Training Loss: 3.226e-01, Validation Loss: 7.082e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1597, Training Loss: 3.223e-01, Validation Loss: 7.079e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1598, Training Loss: 3.221e-01, Validation Loss: 7.079e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1599, Training Loss: 3.218e-01, Validation Loss: 7.075e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1600, Training Loss: 3.216e-01, Validation Loss: 7.076e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1601, Training Loss: 3.213e-01, Validation Loss: 7.072e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1602, Training Loss: 3.211e-01, Validation Loss: 7.073e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1603, Training Loss: 3.208e-01, Validation Loss: 7.068e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1604, Training Loss: 3.206e-01, Validation Loss: 7.070e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1605, Training Loss: 3.203e-01, Validation Loss: 7.065e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1606, Training Loss: 3.201e-01, Validation Loss: 7.066e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1607, Training Loss: 3.198e-01, Validation Loss: 7.062e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1608, Training Loss: 3.196e-01, Validation Loss: 7.063e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1609, Training Loss: 3.193e-01, Validation Loss: 7.058e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1610, Training Loss: 3.191e-01, Validation Loss: 7.060e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1611, Training Loss: 3.189e-01, Validation Loss: 7.055e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1612, Training Loss: 3.186e-01, Validation Loss: 7.057e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1613, Training Loss: 3.184e-01, Validation Loss: 7.052e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1614, Training Loss: 3.181e-01, Validation Loss: 7.053e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1615, Training Loss: 3.179e-01, Validation Loss: 7.049e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1616, Training Loss: 3.176e-01, Validation Loss: 7.050e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1617, Training Loss: 3.174e-01, Validation Loss: 7.046e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1618, Training Loss: 3.171e-01, Validation Loss: 7.046e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1619, Training Loss: 3.169e-01, Validation Loss: 7.043e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1620, Training Loss: 3.167e-01, Validation Loss: 7.043e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1621, Training Loss: 3.164e-01, Validation Loss: 7.039e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1622, Training Loss: 3.162e-01, Validation Loss: 7.041e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1623, Training Loss: 3.159e-01, Validation Loss: 7.036e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1624, Training Loss: 3.157e-01, Validation Loss: 7.037e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1625, Training Loss: 3.155e-01, Validation Loss: 7.032e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1626, Training Loss: 3.152e-01, Validation Loss: 7.034e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1627, Training Loss: 3.150e-01, Validation Loss: 7.030e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1628, Training Loss: 3.147e-01, Validation Loss: 7.030e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1629, Training Loss: 3.145e-01, Validation Loss: 7.027e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1630, Training Loss: 3.143e-01, Validation Loss: 7.027e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1631, Training Loss: 3.140e-01, Validation Loss: 7.024e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1632, Training Loss: 3.138e-01, Validation Loss: 7.024e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1633, Training Loss: 3.135e-01, Validation Loss: 7.020e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1634, Training Loss: 3.133e-01, Validation Loss: 7.020e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1635, Training Loss: 3.131e-01, Validation Loss: 7.018e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1636, Training Loss: 3.128e-01, Validation Loss: 7.018e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1637, Training Loss: 3.126e-01, Validation Loss: 7.014e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1638, Training Loss: 3.124e-01, Validation Loss: 7.015e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1639, Training Loss: 3.121e-01, Validation Loss: 7.011e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1640, Training Loss: 3.119e-01, Validation Loss: 7.012e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1641, Training Loss: 3.116e-01, Validation Loss: 7.008e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1642, Training Loss: 3.114e-01, Validation Loss: 7.007e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1643, Training Loss: 3.112e-01, Validation Loss: 7.007e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1644, Training Loss: 3.109e-01, Validation Loss: 7.003e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1645, Training Loss: 3.107e-01, Validation Loss: 7.003e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1646, Training Loss: 3.105e-01, Validation Loss: 7.000e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1647, Training Loss: 3.102e-01, Validation Loss: 7.000e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1648, Training Loss: 3.100e-01, Validation Loss: 6.997e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1649, Training Loss: 3.098e-01, Validation Loss: 6.997e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1650, Training Loss: 3.095e-01, Validation Loss: 6.994e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1651, Training Loss: 3.093e-01, Validation Loss: 6.993e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1652, Training Loss: 3.091e-01, Validation Loss: 6.992e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1653, Training Loss: 3.088e-01, Validation Loss: 6.989e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1654, Training Loss: 3.086e-01, Validation Loss: 6.990e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1655, Training Loss: 3.084e-01, Validation Loss: 6.986e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1656, Training Loss: 3.081e-01, Validation Loss: 6.987e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1657, Training Loss: 3.079e-01, Validation Loss: 6.983e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1658, Training Loss: 3.077e-01, Validation Loss: 6.984e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1659, Training Loss: 3.074e-01, Validation Loss: 6.980e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1660, Training Loss: 3.072e-01, Validation Loss: 6.981e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1661, Training Loss: 3.070e-01, Validation Loss: 6.977e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1662, Training Loss: 3.067e-01, Validation Loss: 6.978e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1663, Training Loss: 3.065e-01, Validation Loss: 6.974e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1664, Training Loss: 3.063e-01, Validation Loss: 6.974e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1665, Training Loss: 3.061e-01, Validation Loss: 6.970e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1666, Training Loss: 3.058e-01, Validation Loss: 6.972e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1667, Training Loss: 3.056e-01, Validation Loss: 6.968e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1668, Training Loss: 3.054e-01, Validation Loss: 6.969e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1669, Training Loss: 3.051e-01, Validation Loss: 6.965e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1670, Training Loss: 3.049e-01, Validation Loss: 6.966e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1671, Training Loss: 3.047e-01, Validation Loss: 6.961e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1672, Training Loss: 3.044e-01, Validation Loss: 6.963e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1673, Training Loss: 3.042e-01, Validation Loss: 6.959e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1674, Training Loss: 3.040e-01, Validation Loss: 6.958e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1675, Training Loss: 3.038e-01, Validation Loss: 6.956e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1676, Training Loss: 3.035e-01, Validation Loss: 6.956e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1677, Training Loss: 3.033e-01, Validation Loss: 6.953e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1678, Training Loss: 3.031e-01, Validation Loss: 6.954e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1679, Training Loss: 3.029e-01, Validation Loss: 6.950e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1680, Training Loss: 3.026e-01, Validation Loss: 6.950e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1681, Training Loss: 3.024e-01, Validation Loss: 6.947e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1682, Training Loss: 3.022e-01, Validation Loss: 6.948e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1683, Training Loss: 3.020e-01, Validation Loss: 6.943e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1684, Training Loss: 3.017e-01, Validation Loss: 6.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1685, Training Loss: 3.015e-01, Validation Loss: 6.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1686, Training Loss: 3.013e-01, Validation Loss: 6.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1687, Training Loss: 3.011e-01, Validation Loss: 6.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1688, Training Loss: 3.008e-01, Validation Loss: 6.939e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1689, Training Loss: 3.006e-01, Validation Loss: 6.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1690, Training Loss: 3.004e-01, Validation Loss: 6.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1691, Training Loss: 3.002e-01, Validation Loss: 6.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1692, Training Loss: 2.999e-01, Validation Loss: 6.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1693, Training Loss: 2.997e-01, Validation Loss: 6.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1694, Training Loss: 2.995e-01, Validation Loss: 6.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1695, Training Loss: 2.993e-01, Validation Loss: 6.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1696, Training Loss: 2.990e-01, Validation Loss: 6.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1697, Training Loss: 2.988e-01, Validation Loss: 6.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1698, Training Loss: 2.986e-01, Validation Loss: 6.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1699, Training Loss: 2.984e-01, Validation Loss: 6.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1700, Training Loss: 2.982e-01, Validation Loss: 6.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1701, Training Loss: 2.979e-01, Validation Loss: 6.918e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1702, Training Loss: 2.977e-01, Validation Loss: 6.919e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1703, Training Loss: 2.975e-01, Validation Loss: 6.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1704, Training Loss: 2.973e-01, Validation Loss: 6.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1705, Training Loss: 2.971e-01, Validation Loss: 6.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1706, Training Loss: 2.968e-01, Validation Loss: 6.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1707, Training Loss: 2.966e-01, Validation Loss: 6.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1708, Training Loss: 2.964e-01, Validation Loss: 6.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1709, Training Loss: 2.962e-01, Validation Loss: 6.907e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1710, Training Loss: 2.960e-01, Validation Loss: 6.907e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1711, Training Loss: 2.957e-01, Validation Loss: 6.904e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1712, Training Loss: 2.955e-01, Validation Loss: 6.904e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1713, Training Loss: 2.953e-01, Validation Loss: 6.901e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1714, Training Loss: 2.951e-01, Validation Loss: 6.901e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1715, Training Loss: 2.949e-01, Validation Loss: 6.898e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1716, Training Loss: 2.946e-01, Validation Loss: 6.899e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1717, Training Loss: 2.944e-01, Validation Loss: 6.895e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1718, Training Loss: 2.942e-01, Validation Loss: 6.896e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1719, Training Loss: 2.940e-01, Validation Loss: 6.892e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1720, Training Loss: 2.938e-01, Validation Loss: 6.894e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1721, Training Loss: 2.936e-01, Validation Loss: 6.890e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1722, Training Loss: 2.933e-01, Validation Loss: 6.890e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1723, Training Loss: 2.931e-01, Validation Loss: 6.887e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1724, Training Loss: 2.929e-01, Validation Loss: 6.887e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1725, Training Loss: 2.927e-01, Validation Loss: 6.884e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1726, Training Loss: 2.925e-01, Validation Loss: 6.885e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1727, Training Loss: 2.923e-01, Validation Loss: 6.882e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1728, Training Loss: 2.921e-01, Validation Loss: 6.881e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1729, Training Loss: 2.918e-01, Validation Loss: 6.879e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1730, Training Loss: 2.916e-01, Validation Loss: 6.880e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1731, Training Loss: 2.914e-01, Validation Loss: 6.876e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1732, Training Loss: 2.912e-01, Validation Loss: 6.876e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1733, Training Loss: 2.910e-01, Validation Loss: 6.873e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1734, Training Loss: 2.908e-01, Validation Loss: 6.874e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1735, Training Loss: 2.906e-01, Validation Loss: 6.871e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1736, Training Loss: 2.903e-01, Validation Loss: 6.871e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1737, Training Loss: 2.901e-01, Validation Loss: 6.868e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1738, Training Loss: 2.899e-01, Validation Loss: 6.868e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1739, Training Loss: 2.897e-01, Validation Loss: 6.865e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1740, Training Loss: 2.895e-01, Validation Loss: 6.866e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1741, Training Loss: 2.893e-01, Validation Loss: 6.862e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1742, Training Loss: 2.891e-01, Validation Loss: 6.863e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1743, Training Loss: 2.889e-01, Validation Loss: 6.860e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1744, Training Loss: 2.887e-01, Validation Loss: 6.859e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1745, Training Loss: 2.884e-01, Validation Loss: 6.857e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1746, Training Loss: 2.882e-01, Validation Loss: 6.858e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1747, Training Loss: 2.880e-01, Validation Loss: 6.854e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1748, Training Loss: 2.878e-01, Validation Loss: 6.856e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1749, Training Loss: 2.876e-01, Validation Loss: 6.851e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1750, Training Loss: 2.874e-01, Validation Loss: 6.850e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1751, Training Loss: 2.872e-01, Validation Loss: 6.851e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1752, Training Loss: 2.870e-01, Validation Loss: 6.848e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1753, Training Loss: 2.868e-01, Validation Loss: 6.849e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1754, Training Loss: 2.866e-01, Validation Loss: 6.845e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1755, Training Loss: 2.863e-01, Validation Loss: 6.844e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1756, Training Loss: 2.861e-01, Validation Loss: 6.844e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1757, Training Loss: 2.859e-01, Validation Loss: 6.841e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1758, Training Loss: 2.857e-01, Validation Loss: 6.841e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1759, Training Loss: 2.855e-01, Validation Loss: 6.839e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1760, Training Loss: 2.853e-01, Validation Loss: 6.837e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1761, Training Loss: 2.851e-01, Validation Loss: 6.838e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1762, Training Loss: 2.849e-01, Validation Loss: 6.834e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1763, Training Loss: 2.847e-01, Validation Loss: 6.835e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1764, Training Loss: 2.845e-01, Validation Loss: 6.832e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1765, Training Loss: 2.843e-01, Validation Loss: 6.832e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1766, Training Loss: 2.841e-01, Validation Loss: 6.829e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1767, Training Loss: 2.839e-01, Validation Loss: 6.830e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1768, Training Loss: 2.837e-01, Validation Loss: 6.826e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1769, Training Loss: 2.835e-01, Validation Loss: 6.827e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1770, Training Loss: 2.832e-01, Validation Loss: 6.823e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1771, Training Loss: 2.830e-01, Validation Loss: 6.825e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1772, Training Loss: 2.828e-01, Validation Loss: 6.820e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1773, Training Loss: 2.826e-01, Validation Loss: 6.823e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1774, Training Loss: 2.824e-01, Validation Loss: 6.818e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1775, Training Loss: 2.822e-01, Validation Loss: 6.820e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1776, Training Loss: 2.820e-01, Validation Loss: 6.815e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1777, Training Loss: 2.818e-01, Validation Loss: 6.817e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1778, Training Loss: 2.816e-01, Validation Loss: 6.814e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1779, Training Loss: 2.814e-01, Validation Loss: 6.813e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1780, Training Loss: 2.812e-01, Validation Loss: 6.811e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1781, Training Loss: 2.810e-01, Validation Loss: 6.811e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1782, Training Loss: 2.808e-01, Validation Loss: 6.809e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1783, Training Loss: 2.806e-01, Validation Loss: 6.808e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1784, Training Loss: 2.804e-01, Validation Loss: 6.807e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1785, Training Loss: 2.802e-01, Validation Loss: 6.806e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1786, Training Loss: 2.800e-01, Validation Loss: 6.803e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1787, Training Loss: 2.798e-01, Validation Loss: 6.803e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1788, Training Loss: 2.796e-01, Validation Loss: 6.800e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1789, Training Loss: 2.794e-01, Validation Loss: 6.801e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1790, Training Loss: 2.792e-01, Validation Loss: 6.797e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1791, Training Loss: 2.790e-01, Validation Loss: 6.799e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1792, Training Loss: 2.788e-01, Validation Loss: 6.796e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1793, Training Loss: 2.786e-01, Validation Loss: 6.796e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1794, Training Loss: 2.784e-01, Validation Loss: 6.792e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1795, Training Loss: 2.782e-01, Validation Loss: 6.794e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1796, Training Loss: 2.780e-01, Validation Loss: 6.789e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1797, Training Loss: 2.778e-01, Validation Loss: 6.791e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1798, Training Loss: 2.776e-01, Validation Loss: 6.788e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1799, Training Loss: 2.774e-01, Validation Loss: 6.788e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1800, Training Loss: 2.772e-01, Validation Loss: 6.784e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1801, Training Loss: 2.770e-01, Validation Loss: 6.787e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1802, Training Loss: 2.768e-01, Validation Loss: 6.781e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1803, Training Loss: 2.766e-01, Validation Loss: 6.784e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1804, Training Loss: 2.764e-01, Validation Loss: 6.780e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1805, Training Loss: 2.762e-01, Validation Loss: 6.782e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1806, Training Loss: 2.760e-01, Validation Loss: 6.776e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1807, Training Loss: 2.758e-01, Validation Loss: 6.779e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1808, Training Loss: 2.756e-01, Validation Loss: 6.775e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1809, Training Loss: 2.754e-01, Validation Loss: 6.776e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1810, Training Loss: 2.752e-01, Validation Loss: 6.772e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1811, Training Loss: 2.750e-01, Validation Loss: 6.774e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1812, Training Loss: 2.748e-01, Validation Loss: 6.769e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1813, Training Loss: 2.746e-01, Validation Loss: 6.771e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1814, Training Loss: 2.744e-01, Validation Loss: 6.767e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1815, Training Loss: 2.742e-01, Validation Loss: 6.769e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1816, Training Loss: 2.740e-01, Validation Loss: 6.764e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1817, Training Loss: 2.739e-01, Validation Loss: 6.767e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1818, Training Loss: 2.737e-01, Validation Loss: 6.762e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1819, Training Loss: 2.735e-01, Validation Loss: 6.764e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1820, Training Loss: 2.733e-01, Validation Loss: 6.759e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1821, Training Loss: 2.731e-01, Validation Loss: 6.761e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1822, Training Loss: 2.729e-01, Validation Loss: 6.758e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1823, Training Loss: 2.727e-01, Validation Loss: 6.758e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1824, Training Loss: 2.725e-01, Validation Loss: 6.756e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1825, Training Loss: 2.723e-01, Validation Loss: 6.755e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1826, Training Loss: 2.721e-01, Validation Loss: 6.754e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1827, Training Loss: 2.719e-01, Validation Loss: 6.753e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1828, Training Loss: 2.717e-01, Validation Loss: 6.751e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1829, Training Loss: 2.715e-01, Validation Loss: 6.749e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1830, Training Loss: 2.713e-01, Validation Loss: 6.751e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1831, Training Loss: 2.711e-01, Validation Loss: 6.746e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1832, Training Loss: 2.710e-01, Validation Loss: 6.748e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1833, Training Loss: 2.708e-01, Validation Loss: 6.744e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1834, Training Loss: 2.706e-01, Validation Loss: 6.746e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1835, Training Loss: 2.704e-01, Validation Loss: 6.741e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1836, Training Loss: 2.702e-01, Validation Loss: 6.743e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1837, Training Loss: 2.700e-01, Validation Loss: 6.739e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1838, Training Loss: 2.698e-01, Validation Loss: 6.741e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1839, Training Loss: 2.696e-01, Validation Loss: 6.736e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1840, Training Loss: 2.694e-01, Validation Loss: 6.739e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1841, Training Loss: 2.692e-01, Validation Loss: 6.734e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1842, Training Loss: 2.690e-01, Validation Loss: 6.736e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1843, Training Loss: 2.688e-01, Validation Loss: 6.732e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1844, Training Loss: 2.687e-01, Validation Loss: 6.734e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1845, Training Loss: 2.685e-01, Validation Loss: 6.729e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1846, Training Loss: 2.683e-01, Validation Loss: 6.732e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1847, Training Loss: 2.681e-01, Validation Loss: 6.727e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1848, Training Loss: 2.679e-01, Validation Loss: 6.730e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1849, Training Loss: 2.677e-01, Validation Loss: 6.725e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1850, Training Loss: 2.675e-01, Validation Loss: 6.727e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1851, Training Loss: 2.673e-01, Validation Loss: 6.722e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1852, Training Loss: 2.672e-01, Validation Loss: 6.724e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1853, Training Loss: 2.670e-01, Validation Loss: 6.720e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1854, Training Loss: 2.668e-01, Validation Loss: 6.722e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1855, Training Loss: 2.666e-01, Validation Loss: 6.718e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1856, Training Loss: 2.664e-01, Validation Loss: 6.720e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1857, Training Loss: 2.662e-01, Validation Loss: 6.716e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1858, Training Loss: 2.660e-01, Validation Loss: 6.717e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1859, Training Loss: 2.658e-01, Validation Loss: 6.713e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1860, Training Loss: 2.657e-01, Validation Loss: 6.715e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1861, Training Loss: 2.655e-01, Validation Loss: 6.711e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1862, Training Loss: 2.653e-01, Validation Loss: 6.713e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1863, Training Loss: 2.651e-01, Validation Loss: 6.708e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1864, Training Loss: 2.649e-01, Validation Loss: 6.711e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1865, Training Loss: 2.647e-01, Validation Loss: 6.706e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1866, Training Loss: 2.645e-01, Validation Loss: 6.708e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1867, Training Loss: 2.644e-01, Validation Loss: 6.704e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1868, Training Loss: 2.642e-01, Validation Loss: 6.706e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1869, Training Loss: 2.640e-01, Validation Loss: 6.702e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1870, Training Loss: 2.638e-01, Validation Loss: 6.703e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1871, Training Loss: 2.636e-01, Validation Loss: 6.699e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1872, Training Loss: 2.634e-01, Validation Loss: 6.702e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1873, Training Loss: 2.632e-01, Validation Loss: 6.697e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1874, Training Loss: 2.631e-01, Validation Loss: 6.699e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1875, Training Loss: 2.629e-01, Validation Loss: 6.695e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1876, Training Loss: 2.627e-01, Validation Loss: 6.697e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1877, Training Loss: 2.625e-01, Validation Loss: 6.692e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1878, Training Loss: 2.623e-01, Validation Loss: 6.695e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1879, Training Loss: 2.621e-01, Validation Loss: 6.689e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1880, Training Loss: 2.620e-01, Validation Loss: 6.692e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1881, Training Loss: 2.618e-01, Validation Loss: 6.688e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1882, Training Loss: 2.616e-01, Validation Loss: 6.689e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1883, Training Loss: 2.614e-01, Validation Loss: 6.687e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1884, Training Loss: 2.612e-01, Validation Loss: 6.686e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1885, Training Loss: 2.610e-01, Validation Loss: 6.684e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1886, Training Loss: 2.609e-01, Validation Loss: 6.684e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1887, Training Loss: 2.607e-01, Validation Loss: 6.683e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1888, Training Loss: 2.605e-01, Validation Loss: 6.682e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1889, Training Loss: 2.603e-01, Validation Loss: 6.680e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1890, Training Loss: 2.601e-01, Validation Loss: 6.680e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1891, Training Loss: 2.600e-01, Validation Loss: 6.677e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1892, Training Loss: 2.598e-01, Validation Loss: 6.679e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1893, Training Loss: 2.596e-01, Validation Loss: 6.675e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1894, Training Loss: 2.594e-01, Validation Loss: 6.677e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1895, Training Loss: 2.592e-01, Validation Loss: 6.672e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1896, Training Loss: 2.591e-01, Validation Loss: 6.674e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1897, Training Loss: 2.589e-01, Validation Loss: 6.670e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1898, Training Loss: 2.587e-01, Validation Loss: 6.672e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1899, Training Loss: 2.585e-01, Validation Loss: 6.668e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1900, Training Loss: 2.583e-01, Validation Loss: 6.670e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1901, Training Loss: 2.582e-01, Validation Loss: 6.666e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1902, Training Loss: 2.580e-01, Validation Loss: 6.668e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1903, Training Loss: 2.578e-01, Validation Loss: 6.663e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1904, Training Loss: 2.576e-01, Validation Loss: 6.665e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1905, Training Loss: 2.575e-01, Validation Loss: 6.662e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1906, Training Loss: 2.573e-01, Validation Loss: 6.663e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1907, Training Loss: 2.571e-01, Validation Loss: 6.659e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1908, Training Loss: 2.569e-01, Validation Loss: 6.662e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1909, Training Loss: 2.567e-01, Validation Loss: 6.656e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1910, Training Loss: 2.566e-01, Validation Loss: 6.659e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1911, Training Loss: 2.564e-01, Validation Loss: 6.654e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1912, Training Loss: 2.562e-01, Validation Loss: 6.657e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1913, Training Loss: 2.560e-01, Validation Loss: 6.652e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1914, Training Loss: 2.559e-01, Validation Loss: 6.655e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1915, Training Loss: 2.557e-01, Validation Loss: 6.650e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1916, Training Loss: 2.555e-01, Validation Loss: 6.653e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1917, Training Loss: 2.553e-01, Validation Loss: 6.648e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1918, Training Loss: 2.552e-01, Validation Loss: 6.650e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1919, Training Loss: 2.550e-01, Validation Loss: 6.646e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1920, Training Loss: 2.548e-01, Validation Loss: 6.648e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1921, Training Loss: 2.546e-01, Validation Loss: 6.644e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1922, Training Loss: 2.544e-01, Validation Loss: 6.646e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1923, Training Loss: 2.543e-01, Validation Loss: 6.642e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1924, Training Loss: 2.541e-01, Validation Loss: 6.644e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1925, Training Loss: 2.539e-01, Validation Loss: 6.639e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1926, Training Loss: 2.538e-01, Validation Loss: 6.642e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1927, Training Loss: 2.536e-01, Validation Loss: 6.638e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1928, Training Loss: 2.534e-01, Validation Loss: 6.638e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1929, Training Loss: 2.532e-01, Validation Loss: 6.636e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1930, Training Loss: 2.531e-01, Validation Loss: 6.636e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1931, Training Loss: 2.529e-01, Validation Loss: 6.635e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1932, Training Loss: 2.527e-01, Validation Loss: 6.634e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1933, Training Loss: 2.525e-01, Validation Loss: 6.633e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1934, Training Loss: 2.524e-01, Validation Loss: 6.632e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1935, Training Loss: 2.522e-01, Validation Loss: 6.630e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1936, Training Loss: 2.520e-01, Validation Loss: 6.629e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1937, Training Loss: 2.518e-01, Validation Loss: 6.628e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1938, Training Loss: 2.517e-01, Validation Loss: 6.627e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1939, Training Loss: 2.515e-01, Validation Loss: 6.626e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1940, Training Loss: 2.513e-01, Validation Loss: 6.625e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1941, Training Loss: 2.511e-01, Validation Loss: 6.625e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1942, Training Loss: 2.510e-01, Validation Loss: 6.622e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1943, Training Loss: 2.508e-01, Validation Loss: 6.623e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1944, Training Loss: 2.506e-01, Validation Loss: 6.620e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1945, Training Loss: 2.505e-01, Validation Loss: 6.622e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1946, Training Loss: 2.503e-01, Validation Loss: 6.617e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1947, Training Loss: 2.501e-01, Validation Loss: 6.620e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1948, Training Loss: 2.500e-01, Validation Loss: 6.615e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1949, Training Loss: 2.498e-01, Validation Loss: 6.617e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1950, Training Loss: 2.496e-01, Validation Loss: 6.613e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1951, Training Loss: 2.494e-01, Validation Loss: 6.616e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1952, Training Loss: 2.493e-01, Validation Loss: 6.611e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1953, Training Loss: 2.491e-01, Validation Loss: 6.613e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1954, Training Loss: 2.489e-01, Validation Loss: 6.608e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1955, Training Loss: 2.488e-01, Validation Loss: 6.612e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1956, Training Loss: 2.486e-01, Validation Loss: 6.607e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1957, Training Loss: 2.484e-01, Validation Loss: 6.609e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1958, Training Loss: 2.482e-01, Validation Loss: 6.605e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1959, Training Loss: 2.481e-01, Validation Loss: 6.608e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1960, Training Loss: 2.479e-01, Validation Loss: 6.603e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1961, Training Loss: 2.477e-01, Validation Loss: 6.605e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1962, Training Loss: 2.476e-01, Validation Loss: 6.601e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1963, Training Loss: 2.474e-01, Validation Loss: 6.603e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1964, Training Loss: 2.472e-01, Validation Loss: 6.598e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1965, Training Loss: 2.471e-01, Validation Loss: 6.601e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1966, Training Loss: 2.469e-01, Validation Loss: 6.597e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1967, Training Loss: 2.467e-01, Validation Loss: 6.600e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1968, Training Loss: 2.466e-01, Validation Loss: 6.594e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1969, Training Loss: 2.464e-01, Validation Loss: 6.597e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1970, Training Loss: 2.462e-01, Validation Loss: 6.593e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1971, Training Loss: 2.461e-01, Validation Loss: 6.595e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1972, Training Loss: 2.459e-01, Validation Loss: 6.591e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1973, Training Loss: 2.457e-01, Validation Loss: 6.592e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1974, Training Loss: 2.456e-01, Validation Loss: 6.590e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1975, Training Loss: 2.454e-01, Validation Loss: 6.590e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1976, Training Loss: 2.452e-01, Validation Loss: 6.589e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1977, Training Loss: 2.451e-01, Validation Loss: 6.588e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1978, Training Loss: 2.449e-01, Validation Loss: 6.586e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1979, Training Loss: 2.447e-01, Validation Loss: 6.586e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1980, Training Loss: 2.446e-01, Validation Loss: 6.584e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1981, Training Loss: 2.444e-01, Validation Loss: 6.584e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1982, Training Loss: 2.442e-01, Validation Loss: 6.582e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1983, Training Loss: 2.441e-01, Validation Loss: 6.583e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1984, Training Loss: 2.439e-01, Validation Loss: 6.579e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1985, Training Loss: 2.437e-01, Validation Loss: 6.582e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1986, Training Loss: 2.436e-01, Validation Loss: 6.576e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1987, Training Loss: 2.434e-01, Validation Loss: 6.580e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1988, Training Loss: 2.433e-01, Validation Loss: 6.574e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1989, Training Loss: 2.431e-01, Validation Loss: 6.578e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1990, Training Loss: 2.429e-01, Validation Loss: 6.573e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1991, Training Loss: 2.428e-01, Validation Loss: 6.576e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1992, Training Loss: 2.426e-01, Validation Loss: 6.571e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1993, Training Loss: 2.424e-01, Validation Loss: 6.574e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1994, Training Loss: 2.423e-01, Validation Loss: 6.569e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1995, Training Loss: 2.421e-01, Validation Loss: 6.572e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1996, Training Loss: 2.419e-01, Validation Loss: 6.567e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1997, Training Loss: 2.418e-01, Validation Loss: 6.570e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 1998, Training Loss: 2.416e-01, Validation Loss: 6.565e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 1999, Training Loss: 2.415e-01, Validation Loss: 6.567e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2000, Training Loss: 2.413e-01, Validation Loss: 6.563e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2001, Training Loss: 2.411e-01, Validation Loss: 6.566e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2002, Training Loss: 2.410e-01, Validation Loss: 6.562e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2003, Training Loss: 2.408e-01, Validation Loss: 6.564e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2004, Training Loss: 2.406e-01, Validation Loss: 6.560e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2005, Training Loss: 2.405e-01, Validation Loss: 6.561e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2006, Training Loss: 2.403e-01, Validation Loss: 6.558e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2007, Training Loss: 2.402e-01, Validation Loss: 6.561e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2008, Training Loss: 2.400e-01, Validation Loss: 6.556e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2009, Training Loss: 2.398e-01, Validation Loss: 6.558e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2010, Training Loss: 2.397e-01, Validation Loss: 6.554e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2011, Training Loss: 2.395e-01, Validation Loss: 6.557e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2012, Training Loss: 2.394e-01, Validation Loss: 6.551e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2013, Training Loss: 2.392e-01, Validation Loss: 6.554e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2014, Training Loss: 2.390e-01, Validation Loss: 6.549e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2015, Training Loss: 2.389e-01, Validation Loss: 6.553e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2016, Training Loss: 2.387e-01, Validation Loss: 6.548e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2017, Training Loss: 2.386e-01, Validation Loss: 6.551e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2018, Training Loss: 2.384e-01, Validation Loss: 6.547e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2019, Training Loss: 2.382e-01, Validation Loss: 6.547e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2020, Training Loss: 2.381e-01, Validation Loss: 6.546e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2021, Training Loss: 2.379e-01, Validation Loss: 6.545e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2022, Training Loss: 2.378e-01, Validation Loss: 6.544e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2023, Training Loss: 2.376e-01, Validation Loss: 6.544e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2024, Training Loss: 2.374e-01, Validation Loss: 6.542e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2025, Training Loss: 2.373e-01, Validation Loss: 6.542e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2026, Training Loss: 2.371e-01, Validation Loss: 6.540e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2027, Training Loss: 2.370e-01, Validation Loss: 6.540e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2028, Training Loss: 2.368e-01, Validation Loss: 6.537e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2029, Training Loss: 2.367e-01, Validation Loss: 6.539e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2030, Training Loss: 2.365e-01, Validation Loss: 6.535e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2031, Training Loss: 2.363e-01, Validation Loss: 6.538e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2032, Training Loss: 2.362e-01, Validation Loss: 6.534e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2033, Training Loss: 2.360e-01, Validation Loss: 6.535e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2034, Training Loss: 2.359e-01, Validation Loss: 6.531e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2035, Training Loss: 2.357e-01, Validation Loss: 6.534e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2036, Training Loss: 2.356e-01, Validation Loss: 6.530e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2037, Training Loss: 2.354e-01, Validation Loss: 6.532e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2038, Training Loss: 2.352e-01, Validation Loss: 6.528e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2039, Training Loss: 2.351e-01, Validation Loss: 6.530e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2040, Training Loss: 2.349e-01, Validation Loss: 6.526e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2041, Training Loss: 2.348e-01, Validation Loss: 6.528e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2042, Training Loss: 2.346e-01, Validation Loss: 6.523e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2043, Training Loss: 2.345e-01, Validation Loss: 6.527e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2044, Training Loss: 2.343e-01, Validation Loss: 6.522e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2045, Training Loss: 2.342e-01, Validation Loss: 6.524e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2046, Training Loss: 2.340e-01, Validation Loss: 6.521e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2047, Training Loss: 2.338e-01, Validation Loss: 6.522e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2048, Training Loss: 2.337e-01, Validation Loss: 6.520e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2049, Training Loss: 2.335e-01, Validation Loss: 6.519e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2050, Training Loss: 2.334e-01, Validation Loss: 6.518e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2051, Training Loss: 2.332e-01, Validation Loss: 6.518e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2052, Training Loss: 2.331e-01, Validation Loss: 6.516e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2053, Training Loss: 2.329e-01, Validation Loss: 6.517e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2054, Training Loss: 2.328e-01, Validation Loss: 6.513e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2055, Training Loss: 2.326e-01, Validation Loss: 6.516e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2056, Training Loss: 2.325e-01, Validation Loss: 6.511e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2057, Training Loss: 2.323e-01, Validation Loss: 6.514e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2058, Training Loss: 2.322e-01, Validation Loss: 6.509e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2059, Training Loss: 2.320e-01, Validation Loss: 6.512e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2060, Training Loss: 2.318e-01, Validation Loss: 6.508e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2061, Training Loss: 2.317e-01, Validation Loss: 6.510e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2062, Training Loss: 2.315e-01, Validation Loss: 6.505e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2063, Training Loss: 2.314e-01, Validation Loss: 6.509e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2064, Training Loss: 2.312e-01, Validation Loss: 6.504e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2065, Training Loss: 2.311e-01, Validation Loss: 6.505e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2066, Training Loss: 2.309e-01, Validation Loss: 6.504e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2067, Training Loss: 2.308e-01, Validation Loss: 6.504e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2068, Training Loss: 2.306e-01, Validation Loss: 6.501e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2069, Training Loss: 2.305e-01, Validation Loss: 6.503e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2070, Training Loss: 2.303e-01, Validation Loss: 6.499e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2071, Training Loss: 2.302e-01, Validation Loss: 6.501e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2072, Training Loss: 2.300e-01, Validation Loss: 6.497e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2073, Training Loss: 2.299e-01, Validation Loss: 6.501e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2074, Training Loss: 2.297e-01, Validation Loss: 6.496e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2075, Training Loss: 2.296e-01, Validation Loss: 6.497e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2076, Training Loss: 2.294e-01, Validation Loss: 6.494e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2077, Training Loss: 2.293e-01, Validation Loss: 6.495e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2078, Training Loss: 2.291e-01, Validation Loss: 6.493e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2079, Training Loss: 2.290e-01, Validation Loss: 6.493e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2080, Training Loss: 2.288e-01, Validation Loss: 6.491e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2081, Training Loss: 2.287e-01, Validation Loss: 6.491e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2082, Training Loss: 2.285e-01, Validation Loss: 6.490e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2083, Training Loss: 2.284e-01, Validation Loss: 6.488e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2084, Training Loss: 2.282e-01, Validation Loss: 6.489e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2085, Training Loss: 2.281e-01, Validation Loss: 6.486e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2086, Training Loss: 2.279e-01, Validation Loss: 6.488e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2087, Training Loss: 2.278e-01, Validation Loss: 6.484e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2088, Training Loss: 2.276e-01, Validation Loss: 6.486e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2089, Training Loss: 2.275e-01, Validation Loss: 6.482e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2090, Training Loss: 2.273e-01, Validation Loss: 6.485e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2091, Training Loss: 2.272e-01, Validation Loss: 6.480e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2092, Training Loss: 2.270e-01, Validation Loss: 6.483e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2093, Training Loss: 2.269e-01, Validation Loss: 6.479e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2094, Training Loss: 2.267e-01, Validation Loss: 6.481e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2095, Training Loss: 2.266e-01, Validation Loss: 6.478e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2096, Training Loss: 2.264e-01, Validation Loss: 6.479e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2097, Training Loss: 2.263e-01, Validation Loss: 6.476e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2098, Training Loss: 2.261e-01, Validation Loss: 6.478e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2099, Training Loss: 2.260e-01, Validation Loss: 6.474e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2100, Training Loss: 2.258e-01, Validation Loss: 6.476e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2101, Training Loss: 2.257e-01, Validation Loss: 6.472e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2102, Training Loss: 2.255e-01, Validation Loss: 6.474e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2103, Training Loss: 2.254e-01, Validation Loss: 6.472e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2104, Training Loss: 2.253e-01, Validation Loss: 6.471e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2105, Training Loss: 2.251e-01, Validation Loss: 6.470e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2106, Training Loss: 2.250e-01, Validation Loss: 6.469e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2107, Training Loss: 2.248e-01, Validation Loss: 6.468e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2108, Training Loss: 2.247e-01, Validation Loss: 6.470e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2109, Training Loss: 2.245e-01, Validation Loss: 6.465e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2110, Training Loss: 2.244e-01, Validation Loss: 6.468e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2111, Training Loss: 2.242e-01, Validation Loss: 6.463e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2112, Training Loss: 2.241e-01, Validation Loss: 6.467e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2113, Training Loss: 2.239e-01, Validation Loss: 6.462e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2114, Training Loss: 2.238e-01, Validation Loss: 6.464e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2115, Training Loss: 2.237e-01, Validation Loss: 6.460e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2116, Training Loss: 2.235e-01, Validation Loss: 6.463e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2117, Training Loss: 2.234e-01, Validation Loss: 6.459e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2118, Training Loss: 2.232e-01, Validation Loss: 6.461e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2119, Training Loss: 2.231e-01, Validation Loss: 6.457e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2120, Training Loss: 2.229e-01, Validation Loss: 6.460e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2121, Training Loss: 2.228e-01, Validation Loss: 6.456e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2122, Training Loss: 2.226e-01, Validation Loss: 6.457e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2123, Training Loss: 2.225e-01, Validation Loss: 6.456e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2124, Training Loss: 2.223e-01, Validation Loss: 6.454e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2125, Training Loss: 2.222e-01, Validation Loss: 6.454e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2126, Training Loss: 2.221e-01, Validation Loss: 6.453e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2127, Training Loss: 2.219e-01, Validation Loss: 6.452e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2128, Training Loss: 2.218e-01, Validation Loss: 6.450e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2129, Training Loss: 2.216e-01, Validation Loss: 6.453e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2130, Training Loss: 2.215e-01, Validation Loss: 6.448e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2131, Training Loss: 2.213e-01, Validation Loss: 6.451e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2132, Training Loss: 2.212e-01, Validation Loss: 6.446e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2133, Training Loss: 2.211e-01, Validation Loss: 6.450e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2134, Training Loss: 2.209e-01, Validation Loss: 6.445e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2135, Training Loss: 2.208e-01, Validation Loss: 6.448e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2136, Training Loss: 2.206e-01, Validation Loss: 6.443e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2137, Training Loss: 2.205e-01, Validation Loss: 6.445e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2138, Training Loss: 2.204e-01, Validation Loss: 6.442e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2139, Training Loss: 2.202e-01, Validation Loss: 6.444e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2140, Training Loss: 2.201e-01, Validation Loss: 6.440e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2141, Training Loss: 2.199e-01, Validation Loss: 6.443e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2142, Training Loss: 2.198e-01, Validation Loss: 6.439e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2143, Training Loss: 2.196e-01, Validation Loss: 6.440e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2144, Training Loss: 2.195e-01, Validation Loss: 6.437e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2145, Training Loss: 2.194e-01, Validation Loss: 6.438e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2146, Training Loss: 2.192e-01, Validation Loss: 6.437e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2147, Training Loss: 2.191e-01, Validation Loss: 6.437e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2148, Training Loss: 2.189e-01, Validation Loss: 6.434e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2149, Training Loss: 2.188e-01, Validation Loss: 6.436e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2150, Training Loss: 2.187e-01, Validation Loss: 6.432e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2151, Training Loss: 2.185e-01, Validation Loss: 6.435e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2152, Training Loss: 2.184e-01, Validation Loss: 6.430e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2153, Training Loss: 2.182e-01, Validation Loss: 6.434e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2154, Training Loss: 2.181e-01, Validation Loss: 6.429e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2155, Training Loss: 2.180e-01, Validation Loss: 6.432e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2156, Training Loss: 2.178e-01, Validation Loss: 6.427e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2157, Training Loss: 2.177e-01, Validation Loss: 6.429e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2158, Training Loss: 2.175e-01, Validation Loss: 6.426e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2159, Training Loss: 2.174e-01, Validation Loss: 6.428e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2160, Training Loss: 2.173e-01, Validation Loss: 6.425e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2161, Training Loss: 2.171e-01, Validation Loss: 6.427e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2162, Training Loss: 2.170e-01, Validation Loss: 6.422e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2163, Training Loss: 2.168e-01, Validation Loss: 6.425e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2164, Training Loss: 2.167e-01, Validation Loss: 6.421e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2165, Training Loss: 2.166e-01, Validation Loss: 6.423e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2166, Training Loss: 2.164e-01, Validation Loss: 6.420e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2167, Training Loss: 2.163e-01, Validation Loss: 6.421e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2168, Training Loss: 2.161e-01, Validation Loss: 6.418e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2169, Training Loss: 2.160e-01, Validation Loss: 6.420e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2170, Training Loss: 2.159e-01, Validation Loss: 6.417e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2171, Training Loss: 2.157e-01, Validation Loss: 6.418e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2172, Training Loss: 2.156e-01, Validation Loss: 6.415e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2173, Training Loss: 2.155e-01, Validation Loss: 6.417e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2174, Training Loss: 2.153e-01, Validation Loss: 6.413e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2175, Training Loss: 2.152e-01, Validation Loss: 6.416e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2176, Training Loss: 2.151e-01, Validation Loss: 6.412e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2177, Training Loss: 2.149e-01, Validation Loss: 6.414e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2178, Training Loss: 2.148e-01, Validation Loss: 6.410e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2179, Training Loss: 2.146e-01, Validation Loss: 6.413e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2180, Training Loss: 2.145e-01, Validation Loss: 6.408e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2181, Training Loss: 2.144e-01, Validation Loss: 6.412e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2182, Training Loss: 2.142e-01, Validation Loss: 6.407e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2183, Training Loss: 2.141e-01, Validation Loss: 6.409e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2184, Training Loss: 2.140e-01, Validation Loss: 6.406e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2185, Training Loss: 2.138e-01, Validation Loss: 6.408e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2186, Training Loss: 2.137e-01, Validation Loss: 6.404e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2187, Training Loss: 2.136e-01, Validation Loss: 6.408e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2188, Training Loss: 2.134e-01, Validation Loss: 6.402e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2189, Training Loss: 2.133e-01, Validation Loss: 6.404e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2190, Training Loss: 2.131e-01, Validation Loss: 6.401e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2191, Training Loss: 2.130e-01, Validation Loss: 6.404e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2192, Training Loss: 2.129e-01, Validation Loss: 6.400e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2193, Training Loss: 2.127e-01, Validation Loss: 6.402e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2194, Training Loss: 2.126e-01, Validation Loss: 6.398e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2195, Training Loss: 2.125e-01, Validation Loss: 6.399e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2196, Training Loss: 2.123e-01, Validation Loss: 6.397e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2197, Training Loss: 2.122e-01, Validation Loss: 6.398e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2198, Training Loss: 2.121e-01, Validation Loss: 6.397e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2199, Training Loss: 2.119e-01, Validation Loss: 6.395e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2200, Training Loss: 2.118e-01, Validation Loss: 6.396e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2201, Training Loss: 2.117e-01, Validation Loss: 6.393e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2202, Training Loss: 2.115e-01, Validation Loss: 6.395e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2203, Training Loss: 2.114e-01, Validation Loss: 6.392e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2204, Training Loss: 2.113e-01, Validation Loss: 6.394e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2205, Training Loss: 2.111e-01, Validation Loss: 6.390e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2206, Training Loss: 2.110e-01, Validation Loss: 6.393e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2207, Training Loss: 2.109e-01, Validation Loss: 6.389e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2208, Training Loss: 2.107e-01, Validation Loss: 6.390e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2209, Training Loss: 2.106e-01, Validation Loss: 6.387e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2210, Training Loss: 2.105e-01, Validation Loss: 6.390e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2211, Training Loss: 2.103e-01, Validation Loss: 6.385e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2212, Training Loss: 2.102e-01, Validation Loss: 6.388e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2213, Training Loss: 2.101e-01, Validation Loss: 6.384e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2214, Training Loss: 2.099e-01, Validation Loss: 6.386e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2215, Training Loss: 2.098e-01, Validation Loss: 6.383e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2216, Training Loss: 2.097e-01, Validation Loss: 6.384e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2217, Training Loss: 2.095e-01, Validation Loss: 6.382e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2218, Training Loss: 2.094e-01, Validation Loss: 6.383e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2219, Training Loss: 2.093e-01, Validation Loss: 6.380e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2220, Training Loss: 2.091e-01, Validation Loss: 6.382e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2221, Training Loss: 2.090e-01, Validation Loss: 6.379e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2222, Training Loss: 2.089e-01, Validation Loss: 6.380e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2223, Training Loss: 2.087e-01, Validation Loss: 6.377e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2224, Training Loss: 2.086e-01, Validation Loss: 6.379e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2225, Training Loss: 2.085e-01, Validation Loss: 6.376e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2226, Training Loss: 2.084e-01, Validation Loss: 6.378e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2227, Training Loss: 2.082e-01, Validation Loss: 6.374e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2228, Training Loss: 2.081e-01, Validation Loss: 6.377e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2229, Training Loss: 2.080e-01, Validation Loss: 6.372e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2230, Training Loss: 2.078e-01, Validation Loss: 6.376e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2231, Training Loss: 2.077e-01, Validation Loss: 6.371e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2232, Training Loss: 2.076e-01, Validation Loss: 6.374e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2233, Training Loss: 2.075e-01, Validation Loss: 6.370e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2234, Training Loss: 2.073e-01, Validation Loss: 6.373e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2235, Training Loss: 2.072e-01, Validation Loss: 6.368e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2236, Training Loss: 2.071e-01, Validation Loss: 6.370e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2237, Training Loss: 2.069e-01, Validation Loss: 6.367e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2238, Training Loss: 2.068e-01, Validation Loss: 6.369e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2239, Training Loss: 2.067e-01, Validation Loss: 6.366e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2240, Training Loss: 2.065e-01, Validation Loss: 6.367e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2241, Training Loss: 2.064e-01, Validation Loss: 6.365e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2242, Training Loss: 2.063e-01, Validation Loss: 6.365e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2243, Training Loss: 2.062e-01, Validation Loss: 6.364e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2244, Training Loss: 2.060e-01, Validation Loss: 6.364e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2245, Training Loss: 2.059e-01, Validation Loss: 6.363e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2246, Training Loss: 2.058e-01, Validation Loss: 6.361e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2247, Training Loss: 2.056e-01, Validation Loss: 6.364e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2248, Training Loss: 2.055e-01, Validation Loss: 6.359e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2249, Training Loss: 2.054e-01, Validation Loss: 6.362e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2250, Training Loss: 2.053e-01, Validation Loss: 6.358e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2251, Training Loss: 2.051e-01, Validation Loss: 6.360e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2252, Training Loss: 2.050e-01, Validation Loss: 6.357e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2253, Training Loss: 2.049e-01, Validation Loss: 6.358e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2254, Training Loss: 2.047e-01, Validation Loss: 6.355e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2255, Training Loss: 2.046e-01, Validation Loss: 6.357e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2256, Training Loss: 2.045e-01, Validation Loss: 6.354e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2257, Training Loss: 2.044e-01, Validation Loss: 6.356e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2258, Training Loss: 2.042e-01, Validation Loss: 6.352e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2259, Training Loss: 2.041e-01, Validation Loss: 6.355e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2260, Training Loss: 2.040e-01, Validation Loss: 6.351e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2261, Training Loss: 2.039e-01, Validation Loss: 6.354e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2262, Training Loss: 2.037e-01, Validation Loss: 6.350e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2263, Training Loss: 2.036e-01, Validation Loss: 6.351e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2264, Training Loss: 2.035e-01, Validation Loss: 6.349e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2265, Training Loss: 2.033e-01, Validation Loss: 6.349e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2266, Training Loss: 2.032e-01, Validation Loss: 6.347e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2267, Training Loss: 2.031e-01, Validation Loss: 6.349e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2268, Training Loss: 2.030e-01, Validation Loss: 6.345e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2269, Training Loss: 2.028e-01, Validation Loss: 6.348e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2270, Training Loss: 2.027e-01, Validation Loss: 6.344e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2271, Training Loss: 2.026e-01, Validation Loss: 6.347e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2272, Training Loss: 2.025e-01, Validation Loss: 6.342e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2273, Training Loss: 2.023e-01, Validation Loss: 6.344e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2274, Training Loss: 2.022e-01, Validation Loss: 6.342e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2275, Training Loss: 2.021e-01, Validation Loss: 6.342e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2276, Training Loss: 2.020e-01, Validation Loss: 6.341e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2277, Training Loss: 2.018e-01, Validation Loss: 6.340e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2278, Training Loss: 2.017e-01, Validation Loss: 6.340e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2279, Training Loss: 2.016e-01, Validation Loss: 6.339e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2280, Training Loss: 2.015e-01, Validation Loss: 6.340e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2281, Training Loss: 2.013e-01, Validation Loss: 6.337e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2282, Training Loss: 2.012e-01, Validation Loss: 6.338e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2283, Training Loss: 2.011e-01, Validation Loss: 6.335e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2284, Training Loss: 2.010e-01, Validation Loss: 6.337e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2285, Training Loss: 2.008e-01, Validation Loss: 6.334e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2286, Training Loss: 2.007e-01, Validation Loss: 6.336e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2287, Training Loss: 2.006e-01, Validation Loss: 6.332e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2288, Training Loss: 2.005e-01, Validation Loss: 6.335e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2289, Training Loss: 2.004e-01, Validation Loss: 6.331e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2290, Training Loss: 2.002e-01, Validation Loss: 6.334e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2291, Training Loss: 2.001e-01, Validation Loss: 6.330e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2292, Training Loss: 2.000e-01, Validation Loss: 6.332e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2293, Training Loss: 1.999e-01, Validation Loss: 6.328e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2294, Training Loss: 1.997e-01, Validation Loss: 6.331e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2295, Training Loss: 1.996e-01, Validation Loss: 6.327e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2296, Training Loss: 1.995e-01, Validation Loss: 6.329e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2297, Training Loss: 1.994e-01, Validation Loss: 6.326e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2298, Training Loss: 1.992e-01, Validation Loss: 6.328e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2299, Training Loss: 1.991e-01, Validation Loss: 6.325e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2300, Training Loss: 1.990e-01, Validation Loss: 6.326e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2301, Training Loss: 1.989e-01, Validation Loss: 6.324e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2302, Training Loss: 1.988e-01, Validation Loss: 6.324e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2303, Training Loss: 1.986e-01, Validation Loss: 6.322e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2304, Training Loss: 1.985e-01, Validation Loss: 6.324e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2305, Training Loss: 1.984e-01, Validation Loss: 6.321e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2306, Training Loss: 1.983e-01, Validation Loss: 6.322e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2307, Training Loss: 1.981e-01, Validation Loss: 6.319e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2308, Training Loss: 1.980e-01, Validation Loss: 6.322e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2309, Training Loss: 1.979e-01, Validation Loss: 6.318e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2310, Training Loss: 1.978e-01, Validation Loss: 6.320e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2311, Training Loss: 1.977e-01, Validation Loss: 6.317e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2312, Training Loss: 1.975e-01, Validation Loss: 6.318e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2313, Training Loss: 1.974e-01, Validation Loss: 6.316e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2314, Training Loss: 1.973e-01, Validation Loss: 6.316e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2315, Training Loss: 1.972e-01, Validation Loss: 6.315e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2316, Training Loss: 1.971e-01, Validation Loss: 6.315e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2317, Training Loss: 1.969e-01, Validation Loss: 6.314e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2318, Training Loss: 1.968e-01, Validation Loss: 6.313e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2319, Training Loss: 1.967e-01, Validation Loss: 6.311e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2320, Training Loss: 1.966e-01, Validation Loss: 6.314e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2321, Training Loss: 1.965e-01, Validation Loss: 6.310e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2322, Training Loss: 1.963e-01, Validation Loss: 6.312e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2323, Training Loss: 1.962e-01, Validation Loss: 6.308e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2324, Training Loss: 1.961e-01, Validation Loss: 6.311e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2325, Training Loss: 1.960e-01, Validation Loss: 6.307e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2326, Training Loss: 1.959e-01, Validation Loss: 6.310e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2327, Training Loss: 1.957e-01, Validation Loss: 6.306e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2328, Training Loss: 1.956e-01, Validation Loss: 6.308e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2329, Training Loss: 1.955e-01, Validation Loss: 6.304e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2330, Training Loss: 1.954e-01, Validation Loss: 6.307e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2331, Training Loss: 1.953e-01, Validation Loss: 6.303e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2332, Training Loss: 1.951e-01, Validation Loss: 6.306e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2333, Training Loss: 1.950e-01, Validation Loss: 6.302e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2334, Training Loss: 1.949e-01, Validation Loss: 6.305e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2335, Training Loss: 1.948e-01, Validation Loss: 6.301e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2336, Training Loss: 1.947e-01, Validation Loss: 6.303e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2337, Training Loss: 1.945e-01, Validation Loss: 6.300e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2338, Training Loss: 1.944e-01, Validation Loss: 6.303e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2339, Training Loss: 1.943e-01, Validation Loss: 6.299e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2340, Training Loss: 1.942e-01, Validation Loss: 6.300e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2341, Training Loss: 1.941e-01, Validation Loss: 6.298e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2342, Training Loss: 1.940e-01, Validation Loss: 6.298e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2343, Training Loss: 1.938e-01, Validation Loss: 6.297e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2344, Training Loss: 1.937e-01, Validation Loss: 6.297e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2345, Training Loss: 1.936e-01, Validation Loss: 6.296e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2346, Training Loss: 1.935e-01, Validation Loss: 6.296e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2347, Training Loss: 1.934e-01, Validation Loss: 6.294e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2348, Training Loss: 1.932e-01, Validation Loss: 6.295e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2349, Training Loss: 1.931e-01, Validation Loss: 6.293e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2350, Training Loss: 1.930e-01, Validation Loss: 6.295e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2351, Training Loss: 1.929e-01, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2352, Training Loss: 1.928e-01, Validation Loss: 6.294e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2353, Training Loss: 1.927e-01, Validation Loss: 6.290e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2354, Training Loss: 1.926e-01, Validation Loss: 6.293e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2355, Training Loss: 1.924e-01, Validation Loss: 6.288e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2356, Training Loss: 1.923e-01, Validation Loss: 6.291e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2357, Training Loss: 1.922e-01, Validation Loss: 6.287e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2358, Training Loss: 1.921e-01, Validation Loss: 6.290e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2359, Training Loss: 1.920e-01, Validation Loss: 6.286e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2360, Training Loss: 1.919e-01, Validation Loss: 6.288e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2361, Training Loss: 1.917e-01, Validation Loss: 6.285e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2362, Training Loss: 1.916e-01, Validation Loss: 6.287e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2363, Training Loss: 1.915e-01, Validation Loss: 6.283e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2364, Training Loss: 1.914e-01, Validation Loss: 6.286e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2365, Training Loss: 1.913e-01, Validation Loss: 6.283e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2366, Training Loss: 1.912e-01, Validation Loss: 6.284e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2367, Training Loss: 1.910e-01, Validation Loss: 6.282e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2368, Training Loss: 1.909e-01, Validation Loss: 6.282e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2369, Training Loss: 1.908e-01, Validation Loss: 6.281e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2370, Training Loss: 1.907e-01, Validation Loss: 6.281e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2371, Training Loss: 1.906e-01, Validation Loss: 6.280e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2372, Training Loss: 1.905e-01, Validation Loss: 6.280e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2373, Training Loss: 1.903e-01, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2374, Training Loss: 1.902e-01, Validation Loss: 6.280e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2375, Training Loss: 1.901e-01, Validation Loss: 6.276e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2376, Training Loss: 1.900e-01, Validation Loss: 6.279e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2377, Training Loss: 1.899e-01, Validation Loss: 6.275e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2378, Training Loss: 1.898e-01, Validation Loss: 6.278e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2379, Training Loss: 1.897e-01, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2380, Training Loss: 1.896e-01, Validation Loss: 6.277e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2381, Training Loss: 1.894e-01, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2382, Training Loss: 1.893e-01, Validation Loss: 6.275e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2383, Training Loss: 1.892e-01, Validation Loss: 6.272e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2384, Training Loss: 1.891e-01, Validation Loss: 6.274e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2385, Training Loss: 1.890e-01, Validation Loss: 6.270e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2386, Training Loss: 1.889e-01, Validation Loss: 6.273e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2387, Training Loss: 1.888e-01, Validation Loss: 6.270e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2388, Training Loss: 1.886e-01, Validation Loss: 6.271e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2389, Training Loss: 1.885e-01, Validation Loss: 6.268e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2390, Training Loss: 1.884e-01, Validation Loss: 6.271e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2391, Training Loss: 1.883e-01, Validation Loss: 6.266e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2392, Training Loss: 1.882e-01, Validation Loss: 6.270e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2393, Training Loss: 1.881e-01, Validation Loss: 6.265e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2394, Training Loss: 1.880e-01, Validation Loss: 6.268e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2395, Training Loss: 1.879e-01, Validation Loss: 6.265e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2396, Training Loss: 1.877e-01, Validation Loss: 6.266e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2397, Training Loss: 1.876e-01, Validation Loss: 6.264e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2398, Training Loss: 1.875e-01, Validation Loss: 6.265e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2399, Training Loss: 1.874e-01, Validation Loss: 6.263e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2400, Training Loss: 1.873e-01, Validation Loss: 6.264e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2401, Training Loss: 1.872e-01, Validation Loss: 6.262e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2402, Training Loss: 1.871e-01, Validation Loss: 6.263e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2403, Training Loss: 1.870e-01, Validation Loss: 6.260e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2404, Training Loss: 1.868e-01, Validation Loss: 6.263e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2405, Training Loss: 1.867e-01, Validation Loss: 6.258e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2406, Training Loss: 1.866e-01, Validation Loss: 6.261e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2407, Training Loss: 1.865e-01, Validation Loss: 6.257e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2408, Training Loss: 1.864e-01, Validation Loss: 6.260e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2409, Training Loss: 1.863e-01, Validation Loss: 6.256e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2410, Training Loss: 1.862e-01, Validation Loss: 6.259e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2411, Training Loss: 1.861e-01, Validation Loss: 6.255e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2412, Training Loss: 1.860e-01, Validation Loss: 6.258e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2413, Training Loss: 1.858e-01, Validation Loss: 6.254e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2414, Training Loss: 1.857e-01, Validation Loss: 6.257e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2415, Training Loss: 1.856e-01, Validation Loss: 6.253e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2416, Training Loss: 1.855e-01, Validation Loss: 6.255e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2417, Training Loss: 1.854e-01, Validation Loss: 6.252e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2418, Training Loss: 1.853e-01, Validation Loss: 6.254e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2419, Training Loss: 1.852e-01, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2420, Training Loss: 1.851e-01, Validation Loss: 6.253e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2421, Training Loss: 1.850e-01, Validation Loss: 6.249e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2422, Training Loss: 1.849e-01, Validation Loss: 6.252e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2423, Training Loss: 1.847e-01, Validation Loss: 6.248e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2424, Training Loss: 1.846e-01, Validation Loss: 6.251e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2425, Training Loss: 1.845e-01, Validation Loss: 6.246e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2426, Training Loss: 1.844e-01, Validation Loss: 6.250e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2427, Training Loss: 1.843e-01, Validation Loss: 6.247e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2428, Training Loss: 1.842e-01, Validation Loss: 6.248e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2429, Training Loss: 1.841e-01, Validation Loss: 6.246e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2430, Training Loss: 1.840e-01, Validation Loss: 6.247e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2431, Training Loss: 1.839e-01, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2432, Training Loss: 1.838e-01, Validation Loss: 6.246e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2433, Training Loss: 1.837e-01, Validation Loss: 6.242e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2434, Training Loss: 1.835e-01, Validation Loss: 6.246e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2435, Training Loss: 1.834e-01, Validation Loss: 6.242e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2436, Training Loss: 1.833e-01, Validation Loss: 6.243e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2437, Training Loss: 1.832e-01, Validation Loss: 6.241e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2438, Training Loss: 1.831e-01, Validation Loss: 6.243e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2439, Training Loss: 1.830e-01, Validation Loss: 6.240e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2440, Training Loss: 1.829e-01, Validation Loss: 6.242e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2441, Training Loss: 1.828e-01, Validation Loss: 6.238e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2442, Training Loss: 1.827e-01, Validation Loss: 6.241e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2443, Training Loss: 1.826e-01, Validation Loss: 6.237e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2444, Training Loss: 1.825e-01, Validation Loss: 6.240e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2445, Training Loss: 1.823e-01, Validation Loss: 6.235e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2446, Training Loss: 1.822e-01, Validation Loss: 6.239e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2447, Training Loss: 1.821e-01, Validation Loss: 6.236e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2448, Training Loss: 1.820e-01, Validation Loss: 6.237e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2449, Training Loss: 1.819e-01, Validation Loss: 6.234e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2450, Training Loss: 1.818e-01, Validation Loss: 6.237e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2451, Training Loss: 1.817e-01, Validation Loss: 6.233e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2452, Training Loss: 1.816e-01, Validation Loss: 6.235e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2453, Training Loss: 1.815e-01, Validation Loss: 6.232e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2454, Training Loss: 1.814e-01, Validation Loss: 6.233e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2455, Training Loss: 1.813e-01, Validation Loss: 6.232e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2456, Training Loss: 1.812e-01, Validation Loss: 6.233e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2457, Training Loss: 1.811e-01, Validation Loss: 6.229e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2458, Training Loss: 1.810e-01, Validation Loss: 6.232e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2459, Training Loss: 1.809e-01, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2460, Training Loss: 1.808e-01, Validation Loss: 6.230e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2461, Training Loss: 1.806e-01, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2462, Training Loss: 1.805e-01, Validation Loss: 6.230e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2463, Training Loss: 1.804e-01, Validation Loss: 6.226e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2464, Training Loss: 1.803e-01, Validation Loss: 6.229e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2465, Training Loss: 1.802e-01, Validation Loss: 6.225e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2466, Training Loss: 1.801e-01, Validation Loss: 6.227e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2467, Training Loss: 1.800e-01, Validation Loss: 6.224e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2468, Training Loss: 1.799e-01, Validation Loss: 6.226e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2469, Training Loss: 1.798e-01, Validation Loss: 6.224e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2470, Training Loss: 1.797e-01, Validation Loss: 6.225e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2471, Training Loss: 1.796e-01, Validation Loss: 6.222e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2472, Training Loss: 1.795e-01, Validation Loss: 6.224e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2473, Training Loss: 1.794e-01, Validation Loss: 6.220e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2474, Training Loss: 1.793e-01, Validation Loss: 6.223e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2475, Training Loss: 1.792e-01, Validation Loss: 6.219e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2476, Training Loss: 1.791e-01, Validation Loss: 6.222e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2477, Training Loss: 1.789e-01, Validation Loss: 6.219e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2478, Training Loss: 1.789e-01, Validation Loss: 6.221e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2479, Training Loss: 1.787e-01, Validation Loss: 6.217e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2480, Training Loss: 1.786e-01, Validation Loss: 6.220e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2481, Training Loss: 1.785e-01, Validation Loss: 6.216e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2482, Training Loss: 1.784e-01, Validation Loss: 6.218e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2483, Training Loss: 1.783e-01, Validation Loss: 6.217e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2484, Training Loss: 1.782e-01, Validation Loss: 6.217e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2485, Training Loss: 1.781e-01, Validation Loss: 6.214e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2486, Training Loss: 1.780e-01, Validation Loss: 6.217e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2487, Training Loss: 1.779e-01, Validation Loss: 6.213e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2488, Training Loss: 1.778e-01, Validation Loss: 6.216e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2489, Training Loss: 1.777e-01, Validation Loss: 6.212e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2490, Training Loss: 1.776e-01, Validation Loss: 6.215e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2491, Training Loss: 1.775e-01, Validation Loss: 6.212e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2492, Training Loss: 1.774e-01, Validation Loss: 6.214e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2493, Training Loss: 1.773e-01, Validation Loss: 6.210e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2494, Training Loss: 1.772e-01, Validation Loss: 6.213e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2495, Training Loss: 1.771e-01, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2496, Training Loss: 1.770e-01, Validation Loss: 6.212e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2497, Training Loss: 1.769e-01, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2498, Training Loss: 1.768e-01, Validation Loss: 6.210e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2499, Training Loss: 1.767e-01, Validation Loss: 6.207e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2500, Training Loss: 1.766e-01, Validation Loss: 6.209e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2501, Training Loss: 1.765e-01, Validation Loss: 6.207e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2502, Training Loss: 1.764e-01, Validation Loss: 6.209e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2503, Training Loss: 1.763e-01, Validation Loss: 6.205e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2504, Training Loss: 1.762e-01, Validation Loss: 6.208e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2505, Training Loss: 1.760e-01, Validation Loss: 6.204e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2506, Training Loss: 1.760e-01, Validation Loss: 6.207e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2507, Training Loss: 1.758e-01, Validation Loss: 6.203e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2508, Training Loss: 1.758e-01, Validation Loss: 6.205e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2509, Training Loss: 1.756e-01, Validation Loss: 6.204e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2510, Training Loss: 1.755e-01, Validation Loss: 6.204e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2511, Training Loss: 1.754e-01, Validation Loss: 6.201e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2512, Training Loss: 1.753e-01, Validation Loss: 6.203e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2513, Training Loss: 1.752e-01, Validation Loss: 6.201e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2514, Training Loss: 1.751e-01, Validation Loss: 6.203e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2515, Training Loss: 1.750e-01, Validation Loss: 6.199e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2516, Training Loss: 1.749e-01, Validation Loss: 6.202e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2517, Training Loss: 1.748e-01, Validation Loss: 6.198e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2518, Training Loss: 1.747e-01, Validation Loss: 6.200e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2519, Training Loss: 1.746e-01, Validation Loss: 6.200e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2520, Training Loss: 1.745e-01, Validation Loss: 6.199e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2521, Training Loss: 1.744e-01, Validation Loss: 6.196e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2522, Training Loss: 1.743e-01, Validation Loss: 6.198e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2523, Training Loss: 1.742e-01, Validation Loss: 6.197e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2524, Training Loss: 1.741e-01, Validation Loss: 6.196e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2525, Training Loss: 1.740e-01, Validation Loss: 6.197e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2526, Training Loss: 1.739e-01, Validation Loss: 6.193e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2527, Training Loss: 1.738e-01, Validation Loss: 6.196e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2528, Training Loss: 1.737e-01, Validation Loss: 6.193e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2529, Training Loss: 1.736e-01, Validation Loss: 6.195e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2530, Training Loss: 1.735e-01, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2531, Training Loss: 1.734e-01, Validation Loss: 6.194e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2532, Training Loss: 1.733e-01, Validation Loss: 6.191e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2533, Training Loss: 1.732e-01, Validation Loss: 6.193e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2534, Training Loss: 1.731e-01, Validation Loss: 6.191e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2535, Training Loss: 1.730e-01, Validation Loss: 6.192e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2536, Training Loss: 1.729e-01, Validation Loss: 6.189e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2537, Training Loss: 1.728e-01, Validation Loss: 6.191e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2538, Training Loss: 1.727e-01, Validation Loss: 6.188e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2539, Training Loss: 1.726e-01, Validation Loss: 6.190e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2540, Training Loss: 1.725e-01, Validation Loss: 6.187e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2541, Training Loss: 1.724e-01, Validation Loss: 6.190e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2542, Training Loss: 1.723e-01, Validation Loss: 6.185e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2543, Training Loss: 1.722e-01, Validation Loss: 6.189e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2544, Training Loss: 1.721e-01, Validation Loss: 6.185e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2545, Training Loss: 1.720e-01, Validation Loss: 6.187e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2546, Training Loss: 1.719e-01, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2547, Training Loss: 1.718e-01, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2548, Training Loss: 1.717e-01, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2549, Training Loss: 1.716e-01, Validation Loss: 6.185e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2550, Training Loss: 1.715e-01, Validation Loss: 6.184e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2551, Training Loss: 1.714e-01, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2552, Training Loss: 1.713e-01, Validation Loss: 6.183e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2553, Training Loss: 1.712e-01, Validation Loss: 6.181e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2554, Training Loss: 1.712e-01, Validation Loss: 6.183e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2555, Training Loss: 1.710e-01, Validation Loss: 6.182e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2556, Training Loss: 1.710e-01, Validation Loss: 6.179e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2557, Training Loss: 1.709e-01, Validation Loss: 6.182e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2558, Training Loss: 1.708e-01, Validation Loss: 6.178e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2559, Training Loss: 1.707e-01, Validation Loss: 6.180e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2560, Training Loss: 1.706e-01, Validation Loss: 6.180e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2561, Training Loss: 1.705e-01, Validation Loss: 6.177e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2562, Training Loss: 1.704e-01, Validation Loss: 6.179e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2563, Training Loss: 1.703e-01, Validation Loss: 6.176e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2564, Training Loss: 1.702e-01, Validation Loss: 6.178e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2565, Training Loss: 1.701e-01, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2566, Training Loss: 1.700e-01, Validation Loss: 6.178e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2567, Training Loss: 1.699e-01, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2568, Training Loss: 1.698e-01, Validation Loss: 6.177e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2569, Training Loss: 1.697e-01, Validation Loss: 6.173e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2570, Training Loss: 1.696e-01, Validation Loss: 6.175e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2571, Training Loss: 1.695e-01, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2572, Training Loss: 1.694e-01, Validation Loss: 6.175e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2573, Training Loss: 1.693e-01, Validation Loss: 6.174e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2574, Training Loss: 1.692e-01, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2575, Training Loss: 1.691e-01, Validation Loss: 6.173e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2576, Training Loss: 1.690e-01, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2577, Training Loss: 1.689e-01, Validation Loss: 6.169e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2578, Training Loss: 1.688e-01, Validation Loss: 6.172e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2579, Training Loss: 1.687e-01, Validation Loss: 6.169e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2580, Training Loss: 1.686e-01, Validation Loss: 6.171e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2581, Training Loss: 1.685e-01, Validation Loss: 6.167e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2582, Training Loss: 1.684e-01, Validation Loss: 6.171e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2583, Training Loss: 1.683e-01, Validation Loss: 6.167e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2584, Training Loss: 1.682e-01, Validation Loss: 6.169e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2585, Training Loss: 1.681e-01, Validation Loss: 6.166e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2586, Training Loss: 1.681e-01, Validation Loss: 6.168e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2587, Training Loss: 1.680e-01, Validation Loss: 6.165e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2588, Training Loss: 1.679e-01, Validation Loss: 6.167e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2589, Training Loss: 1.678e-01, Validation Loss: 6.164e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2590, Training Loss: 1.677e-01, Validation Loss: 6.166e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2591, Training Loss: 1.676e-01, Validation Loss: 6.165e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2592, Training Loss: 1.675e-01, Validation Loss: 6.163e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2593, Training Loss: 1.674e-01, Validation Loss: 6.165e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2594, Training Loss: 1.673e-01, Validation Loss: 6.164e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2595, Training Loss: 1.672e-01, Validation Loss: 6.161e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2596, Training Loss: 1.671e-01, Validation Loss: 6.164e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2597, Training Loss: 1.670e-01, Validation Loss: 6.160e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2598, Training Loss: 1.669e-01, Validation Loss: 6.163e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2599, Training Loss: 1.668e-01, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2600, Training Loss: 1.667e-01, Validation Loss: 6.162e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2601, Training Loss: 1.666e-01, Validation Loss: 6.161e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2602, Training Loss: 1.665e-01, Validation Loss: 6.158e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2603, Training Loss: 1.664e-01, Validation Loss: 6.160e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2604, Training Loss: 1.663e-01, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2605, Training Loss: 1.662e-01, Validation Loss: 6.157e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2606, Training Loss: 1.662e-01, Validation Loss: 6.159e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2607, Training Loss: 1.661e-01, Validation Loss: 6.158e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2608, Training Loss: 1.660e-01, Validation Loss: 6.156e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2609, Training Loss: 1.659e-01, Validation Loss: 6.158e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2610, Training Loss: 1.658e-01, Validation Loss: 6.156e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2611, Training Loss: 1.657e-01, Validation Loss: 6.154e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2612, Training Loss: 1.656e-01, Validation Loss: 6.157e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2613, Training Loss: 1.655e-01, Validation Loss: 6.156e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2614, Training Loss: 1.654e-01, Validation Loss: 6.152e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2615, Training Loss: 1.653e-01, Validation Loss: 6.155e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2616, Training Loss: 1.652e-01, Validation Loss: 6.155e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2617, Training Loss: 1.651e-01, Validation Loss: 6.151e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2618, Training Loss: 1.650e-01, Validation Loss: 6.154e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2619, Training Loss: 1.649e-01, Validation Loss: 6.151e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2620, Training Loss: 1.649e-01, Validation Loss: 6.153e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2621, Training Loss: 1.648e-01, Validation Loss: 6.150e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2622, Training Loss: 1.647e-01, Validation Loss: 6.152e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2623, Training Loss: 1.646e-01, Validation Loss: 6.150e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2624, Training Loss: 1.645e-01, Validation Loss: 6.152e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2625, Training Loss: 1.644e-01, Validation Loss: 6.148e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2626, Training Loss: 1.643e-01, Validation Loss: 6.151e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2627, Training Loss: 1.642e-01, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2628, Training Loss: 1.641e-01, Validation Loss: 6.150e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2629, Training Loss: 1.640e-01, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2630, Training Loss: 1.639e-01, Validation Loss: 6.146e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2631, Training Loss: 1.638e-01, Validation Loss: 6.148e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2632, Training Loss: 1.637e-01, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2633, Training Loss: 1.637e-01, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2634, Training Loss: 1.636e-01, Validation Loss: 6.147e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2635, Training Loss: 1.635e-01, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2636, Training Loss: 1.634e-01, Validation Loss: 6.146e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2637, Training Loss: 1.633e-01, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2638, Training Loss: 1.632e-01, Validation Loss: 6.145e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2639, Training Loss: 1.631e-01, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2640, Training Loss: 1.630e-01, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2641, Training Loss: 1.629e-01, Validation Loss: 6.143e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2642, Training Loss: 1.628e-01, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2643, Training Loss: 1.627e-01, Validation Loss: 6.144e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2644, Training Loss: 1.626e-01, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2645, Training Loss: 1.626e-01, Validation Loss: 6.142e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2646, Training Loss: 1.625e-01, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2647, Training Loss: 1.624e-01, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2648, Training Loss: 1.623e-01, Validation Loss: 6.141e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2649, Training Loss: 1.622e-01, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2650, Training Loss: 1.621e-01, Validation Loss: 6.141e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2651, Training Loss: 1.620e-01, Validation Loss: 6.139e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2652, Training Loss: 1.619e-01, Validation Loss: 6.137e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2653, Training Loss: 1.618e-01, Validation Loss: 6.139e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2654, Training Loss: 1.617e-01, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2655, Training Loss: 1.617e-01, Validation Loss: 6.138e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2656, Training Loss: 1.616e-01, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2657, Training Loss: 1.615e-01, Validation Loss: 6.137e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2658, Training Loss: 1.614e-01, Validation Loss: 6.136e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2659, Training Loss: 1.613e-01, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2660, Training Loss: 1.612e-01, Validation Loss: 6.136e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2661, Training Loss: 1.611e-01, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2662, Training Loss: 1.610e-01, Validation Loss: 6.136e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2663, Training Loss: 1.609e-01, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2664, Training Loss: 1.608e-01, Validation Loss: 6.135e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2665, Training Loss: 1.608e-01, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2666, Training Loss: 1.607e-01, Validation Loss: 6.134e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2667, Training Loss: 1.606e-01, Validation Loss: 6.130e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2668, Training Loss: 1.605e-01, Validation Loss: 6.133e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2669, Training Loss: 1.604e-01, Validation Loss: 6.132e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2670, Training Loss: 1.603e-01, Validation Loss: 6.130e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2671, Training Loss: 1.602e-01, Validation Loss: 6.132e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2672, Training Loss: 1.601e-01, Validation Loss: 6.129e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2673, Training Loss: 1.601e-01, Validation Loss: 6.131e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2674, Training Loss: 1.600e-01, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2675, Training Loss: 1.599e-01, Validation Loss: 6.131e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2676, Training Loss: 1.598e-01, Validation Loss: 6.129e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2677, Training Loss: 1.597e-01, Validation Loss: 6.129e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2678, Training Loss: 1.596e-01, Validation Loss: 6.127e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2679, Training Loss: 1.595e-01, Validation Loss: 6.128e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2680, Training Loss: 1.594e-01, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2681, Training Loss: 1.593e-01, Validation Loss: 6.128e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2682, Training Loss: 1.592e-01, Validation Loss: 6.125e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2683, Training Loss: 1.592e-01, Validation Loss: 6.127e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2684, Training Loss: 1.591e-01, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2685, Training Loss: 1.590e-01, Validation Loss: 6.127e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2686, Training Loss: 1.589e-01, Validation Loss: 6.123e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2687, Training Loss: 1.588e-01, Validation Loss: 6.126e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2688, Training Loss: 1.587e-01, Validation Loss: 6.124e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2689, Training Loss: 1.586e-01, Validation Loss: 6.125e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2690, Training Loss: 1.585e-01, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2691, Training Loss: 1.585e-01, Validation Loss: 6.124e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2692, Training Loss: 1.584e-01, Validation Loss: 6.123e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2693, Training Loss: 1.583e-01, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2694, Training Loss: 1.582e-01, Validation Loss: 6.123e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2695, Training Loss: 1.581e-01, Validation Loss: 6.120e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2696, Training Loss: 1.580e-01, Validation Loss: 6.122e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2697, Training Loss: 1.579e-01, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2698, Training Loss: 1.578e-01, Validation Loss: 6.118e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2699, Training Loss: 1.578e-01, Validation Loss: 6.121e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2700, Training Loss: 1.577e-01, Validation Loss: 6.120e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2701, Training Loss: 1.576e-01, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2702, Training Loss: 1.575e-01, Validation Loss: 6.119e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2703, Training Loss: 1.574e-01, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2704, Training Loss: 1.573e-01, Validation Loss: 6.119e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2705, Training Loss: 1.572e-01, Validation Loss: 6.118e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2706, Training Loss: 1.572e-01, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2707, Training Loss: 1.571e-01, Validation Loss: 6.118e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2708, Training Loss: 1.570e-01, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2709, Training Loss: 1.569e-01, Validation Loss: 6.117e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2710, Training Loss: 1.568e-01, Validation Loss: 6.114e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2711, Training Loss: 1.567e-01, Validation Loss: 6.116e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2712, Training Loss: 1.566e-01, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2713, Training Loss: 1.566e-01, Validation Loss: 6.115e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2714, Training Loss: 1.565e-01, Validation Loss: 6.115e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2715, Training Loss: 1.564e-01, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2716, Training Loss: 1.563e-01, Validation Loss: 6.114e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2717, Training Loss: 1.562e-01, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2718, Training Loss: 1.561e-01, Validation Loss: 6.114e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2719, Training Loss: 1.560e-01, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2720, Training Loss: 1.560e-01, Validation Loss: 6.110e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2721, Training Loss: 1.559e-01, Validation Loss: 6.112e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2722, Training Loss: 1.558e-01, Validation Loss: 6.112e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2723, Training Loss: 1.557e-01, Validation Loss: 6.109e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2724, Training Loss: 1.556e-01, Validation Loss: 6.111e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2725, Training Loss: 1.555e-01, Validation Loss: 6.110e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2726, Training Loss: 1.554e-01, Validation Loss: 6.108e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2727, Training Loss: 1.554e-01, Validation Loss: 6.110e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2728, Training Loss: 1.553e-01, Validation Loss: 6.111e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2729, Training Loss: 1.552e-01, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2730, Training Loss: 1.551e-01, Validation Loss: 6.109e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2731, Training Loss: 1.550e-01, Validation Loss: 6.108e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2732, Training Loss: 1.549e-01, Validation Loss: 6.106e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2733, Training Loss: 1.549e-01, Validation Loss: 6.108e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2734, Training Loss: 1.548e-01, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2735, Training Loss: 1.547e-01, Validation Loss: 6.105e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2736, Training Loss: 1.546e-01, Validation Loss: 6.107e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2737, Training Loss: 1.545e-01, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2738, Training Loss: 1.544e-01, Validation Loss: 6.106e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2739, Training Loss: 1.543e-01, Validation Loss: 6.106e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2740, Training Loss: 1.543e-01, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2741, Training Loss: 1.542e-01, Validation Loss: 6.105e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2742, Training Loss: 1.541e-01, Validation Loss: 6.105e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2743, Training Loss: 1.540e-01, Validation Loss: 6.102e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2744, Training Loss: 1.539e-01, Validation Loss: 6.104e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2745, Training Loss: 1.538e-01, Validation Loss: 6.102e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2746, Training Loss: 1.538e-01, Validation Loss: 6.104e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2747, Training Loss: 1.537e-01, Validation Loss: 6.101e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2748, Training Loss: 1.536e-01, Validation Loss: 6.102e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2749, Training Loss: 1.535e-01, Validation Loss: 6.102e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2750, Training Loss: 1.534e-01, Validation Loss: 6.102e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2751, Training Loss: 1.533e-01, Validation Loss: 6.099e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2752, Training Loss: 1.533e-01, Validation Loss: 6.101e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2753, Training Loss: 1.532e-01, Validation Loss: 6.101e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2754, Training Loss: 1.531e-01, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2755, Training Loss: 1.530e-01, Validation Loss: 6.100e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2756, Training Loss: 1.529e-01, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2757, Training Loss: 1.528e-01, Validation Loss: 6.100e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2758, Training Loss: 1.528e-01, Validation Loss: 6.096e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2759, Training Loss: 1.527e-01, Validation Loss: 6.099e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2760, Training Loss: 1.526e-01, Validation Loss: 6.099e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2761, Training Loss: 1.525e-01, Validation Loss: 6.096e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2762, Training Loss: 1.524e-01, Validation Loss: 6.097e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2763, Training Loss: 1.523e-01, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2764, Training Loss: 1.523e-01, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2765, Training Loss: 1.522e-01, Validation Loss: 6.096e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2766, Training Loss: 1.521e-01, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2767, Training Loss: 1.520e-01, Validation Loss: 6.096e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2768, Training Loss: 1.519e-01, Validation Loss: 6.095e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2769, Training Loss: 1.518e-01, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2770, Training Loss: 1.518e-01, Validation Loss: 6.095e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2771, Training Loss: 1.517e-01, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2772, Training Loss: 1.516e-01, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2773, Training Loss: 1.515e-01, Validation Loss: 6.094e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2774, Training Loss: 1.514e-01, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2775, Training Loss: 1.514e-01, Validation Loss: 6.094e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2776, Training Loss: 1.513e-01, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2777, Training Loss: 1.512e-01, Validation Loss: 6.092e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2778, Training Loss: 1.511e-01, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2779, Training Loss: 1.510e-01, Validation Loss: 6.089e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2780, Training Loss: 1.510e-01, Validation Loss: 6.091e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2781, Training Loss: 1.509e-01, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2782, Training Loss: 1.508e-01, Validation Loss: 6.089e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2783, Training Loss: 1.507e-01, Validation Loss: 6.090e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2784, Training Loss: 1.506e-01, Validation Loss: 6.088e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2785, Training Loss: 1.505e-01, Validation Loss: 6.090e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2786, Training Loss: 1.505e-01, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2787, Training Loss: 1.504e-01, Validation Loss: 6.089e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2788, Training Loss: 1.503e-01, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2789, Training Loss: 1.502e-01, Validation Loss: 6.088e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2790, Training Loss: 1.501e-01, Validation Loss: 6.086e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2791, Training Loss: 1.501e-01, Validation Loss: 6.088e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2792, Training Loss: 1.500e-01, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2793, Training Loss: 1.499e-01, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2794, Training Loss: 1.498e-01, Validation Loss: 6.086e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2795, Training Loss: 1.497e-01, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2796, Training Loss: 1.497e-01, Validation Loss: 6.086e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2797, Training Loss: 1.496e-01, Validation Loss: 6.083e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2798, Training Loss: 1.495e-01, Validation Loss: 6.086e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2799, Training Loss: 1.494e-01, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2800, Training Loss: 1.493e-01, Validation Loss: 6.082e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2801, Training Loss: 1.493e-01, Validation Loss: 6.085e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2802, Training Loss: 1.492e-01, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2803, Training Loss: 1.491e-01, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2804, Training Loss: 1.490e-01, Validation Loss: 6.083e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2805, Training Loss: 1.489e-01, Validation Loss: 6.082e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2806, Training Loss: 1.489e-01, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2807, Training Loss: 1.488e-01, Validation Loss: 6.082e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2808, Training Loss: 1.487e-01, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2809, Training Loss: 1.486e-01, Validation Loss: 6.082e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2810, Training Loss: 1.485e-01, Validation Loss: 6.079e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2811, Training Loss: 1.485e-01, Validation Loss: 6.082e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2812, Training Loss: 1.484e-01, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2813, Training Loss: 1.483e-01, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2814, Training Loss: 1.482e-01, Validation Loss: 6.080e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2815, Training Loss: 1.481e-01, Validation Loss: 6.079e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2816, Training Loss: 1.481e-01, Validation Loss: 6.077e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2817, Training Loss: 1.480e-01, Validation Loss: 6.079e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2818, Training Loss: 1.479e-01, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2819, Training Loss: 1.478e-01, Validation Loss: 6.078e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2820, Training Loss: 1.478e-01, Validation Loss: 6.078e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2821, Training Loss: 1.477e-01, Validation Loss: 6.075e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2822, Training Loss: 1.476e-01, Validation Loss: 6.078e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2823, Training Loss: 1.475e-01, Validation Loss: 6.077e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2824, Training Loss: 1.474e-01, Validation Loss: 6.075e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2825, Training Loss: 1.474e-01, Validation Loss: 6.076e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2826, Training Loss: 1.473e-01, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2827, Training Loss: 1.472e-01, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2828, Training Loss: 1.471e-01, Validation Loss: 6.076e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2829, Training Loss: 1.470e-01, Validation Loss: 6.075e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2830, Training Loss: 1.470e-01, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2831, Training Loss: 1.469e-01, Validation Loss: 6.075e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2832, Training Loss: 1.468e-01, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2833, Training Loss: 1.467e-01, Validation Loss: 6.074e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2834, Training Loss: 1.467e-01, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2835, Training Loss: 1.466e-01, Validation Loss: 6.074e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2836, Training Loss: 1.465e-01, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2837, Training Loss: 1.464e-01, Validation Loss: 6.073e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2838, Training Loss: 1.463e-01, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2839, Training Loss: 1.463e-01, Validation Loss: 6.072e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2840, Training Loss: 1.462e-01, Validation Loss: 6.070e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2841, Training Loss: 1.461e-01, Validation Loss: 6.072e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2842, Training Loss: 1.460e-01, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2843, Training Loss: 1.460e-01, Validation Loss: 6.072e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2844, Training Loss: 1.459e-01, Validation Loss: 6.068e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2845, Training Loss: 1.458e-01, Validation Loss: 6.070e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2846, Training Loss: 1.457e-01, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2847, Training Loss: 1.457e-01, Validation Loss: 6.070e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2848, Training Loss: 1.456e-01, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2849, Training Loss: 1.455e-01, Validation Loss: 6.069e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2850, Training Loss: 1.454e-01, Validation Loss: 6.068e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2851, Training Loss: 1.453e-01, Validation Loss: 6.069e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2852, Training Loss: 1.453e-01, Validation Loss: 6.066e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2853, Training Loss: 1.452e-01, Validation Loss: 6.068e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2854, Training Loss: 1.451e-01, Validation Loss: 6.065e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2855, Training Loss: 1.450e-01, Validation Loss: 6.067e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2856, Training Loss: 1.450e-01, Validation Loss: 6.067e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2857, Training Loss: 1.449e-01, Validation Loss: 6.065e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2858, Training Loss: 1.448e-01, Validation Loss: 6.066e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2859, Training Loss: 1.447e-01, Validation Loss: 6.066e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2860, Training Loss: 1.447e-01, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2861, Training Loss: 1.446e-01, Validation Loss: 6.066e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2862, Training Loss: 1.445e-01, Validation Loss: 6.063e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2863, Training Loss: 1.444e-01, Validation Loss: 6.064e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2864, Training Loss: 1.443e-01, Validation Loss: 6.065e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2865, Training Loss: 1.443e-01, Validation Loss: 6.062e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2866, Training Loss: 1.442e-01, Validation Loss: 6.063e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2867, Training Loss: 1.441e-01, Validation Loss: 6.064e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2868, Training Loss: 1.440e-01, Validation Loss: 6.061e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2869, Training Loss: 1.440e-01, Validation Loss: 6.063e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2870, Training Loss: 1.439e-01, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2871, Training Loss: 1.438e-01, Validation Loss: 6.062e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2872, Training Loss: 1.437e-01, Validation Loss: 6.061e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2873, Training Loss: 1.437e-01, Validation Loss: 6.062e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2874, Training Loss: 1.436e-01, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2875, Training Loss: 1.435e-01, Validation Loss: 6.062e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2876, Training Loss: 1.434e-01, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2877, Training Loss: 1.434e-01, Validation Loss: 6.060e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2878, Training Loss: 1.433e-01, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2879, Training Loss: 1.432e-01, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2880, Training Loss: 1.431e-01, Validation Loss: 6.060e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2881, Training Loss: 1.431e-01, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2882, Training Loss: 1.430e-01, Validation Loss: 6.059e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2883, Training Loss: 1.429e-01, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2884, Training Loss: 1.428e-01, Validation Loss: 6.059e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2885, Training Loss: 1.428e-01, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2886, Training Loss: 1.427e-01, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2887, Training Loss: 1.426e-01, Validation Loss: 6.055e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2888, Training Loss: 1.425e-01, Validation Loss: 6.057e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2889, Training Loss: 1.425e-01, Validation Loss: 6.058e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2890, Training Loss: 1.424e-01, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2891, Training Loss: 1.423e-01, Validation Loss: 6.056e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2892, Training Loss: 1.422e-01, Validation Loss: 6.057e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2893, Training Loss: 1.422e-01, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2894, Training Loss: 1.421e-01, Validation Loss: 6.056e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2895, Training Loss: 1.420e-01, Validation Loss: 6.053e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2896, Training Loss: 1.420e-01, Validation Loss: 6.055e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2897, Training Loss: 1.419e-01, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2898, Training Loss: 1.418e-01, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2899, Training Loss: 1.417e-01, Validation Loss: 6.053e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2900, Training Loss: 1.416e-01, Validation Loss: 6.054e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2901, Training Loss: 1.416e-01, Validation Loss: 6.051e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2902, Training Loss: 1.415e-01, Validation Loss: 6.054e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2903, Training Loss: 1.414e-01, Validation Loss: 6.053e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2904, Training Loss: 1.414e-01, Validation Loss: 6.051e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2905, Training Loss: 1.413e-01, Validation Loss: 6.052e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2906, Training Loss: 1.412e-01, Validation Loss: 6.052e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2907, Training Loss: 1.411e-01, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2908, Training Loss: 1.411e-01, Validation Loss: 6.052e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2909, Training Loss: 1.410e-01, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2910, Training Loss: 1.409e-01, Validation Loss: 6.051e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2911, Training Loss: 1.408e-01, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2912, Training Loss: 1.408e-01, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2913, Training Loss: 1.407e-01, Validation Loss: 6.050e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2914, Training Loss: 1.406e-01, Validation Loss: 6.048e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2915, Training Loss: 1.406e-01, Validation Loss: 6.050e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2916, Training Loss: 1.405e-01, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2917, Training Loss: 1.404e-01, Validation Loss: 6.049e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2918, Training Loss: 1.403e-01, Validation Loss: 6.048e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2919, Training Loss: 1.403e-01, Validation Loss: 6.049e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2920, Training Loss: 1.402e-01, Validation Loss: 6.046e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2921, Training Loss: 1.401e-01, Validation Loss: 6.048e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2922, Training Loss: 1.400e-01, Validation Loss: 6.046e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2923, Training Loss: 1.400e-01, Validation Loss: 6.047e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2924, Training Loss: 1.399e-01, Validation Loss: 6.047e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2925, Training Loss: 1.398e-01, Validation Loss: 6.045e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2926, Training Loss: 1.398e-01, Validation Loss: 6.046e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2927, Training Loss: 1.397e-01, Validation Loss: 6.047e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2928, Training Loss: 1.396e-01, Validation Loss: 6.044e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2929, Training Loss: 1.395e-01, Validation Loss: 6.046e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2930, Training Loss: 1.395e-01, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2931, Training Loss: 1.394e-01, Validation Loss: 6.045e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2932, Training Loss: 1.393e-01, Validation Loss: 6.045e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2933, Training Loss: 1.392e-01, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2934, Training Loss: 1.392e-01, Validation Loss: 6.044e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2935, Training Loss: 1.391e-01, Validation Loss: 6.044e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2936, Training Loss: 1.390e-01, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2937, Training Loss: 1.390e-01, Validation Loss: 6.044e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2938, Training Loss: 1.389e-01, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2939, Training Loss: 1.388e-01, Validation Loss: 6.043e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2940, Training Loss: 1.387e-01, Validation Loss: 6.040e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2941, Training Loss: 1.387e-01, Validation Loss: 6.043e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2942, Training Loss: 1.386e-01, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2943, Training Loss: 1.385e-01, Validation Loss: 6.042e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2944, Training Loss: 1.385e-01, Validation Loss: 6.040e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2945, Training Loss: 1.384e-01, Validation Loss: 6.041e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2946, Training Loss: 1.383e-01, Validation Loss: 6.041e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2947, Training Loss: 1.382e-01, Validation Loss: 6.039e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2948, Training Loss: 1.382e-01, Validation Loss: 6.040e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2949, Training Loss: 1.381e-01, Validation Loss: 6.040e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2950, Training Loss: 1.380e-01, Validation Loss: 6.038e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2951, Training Loss: 1.380e-01, Validation Loss: 6.039e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2952, Training Loss: 1.379e-01, Validation Loss: 6.040e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2953, Training Loss: 1.378e-01, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2954, Training Loss: 1.377e-01, Validation Loss: 6.039e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2955, Training Loss: 1.377e-01, Validation Loss: 6.039e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2956, Training Loss: 1.376e-01, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2957, Training Loss: 1.375e-01, Validation Loss: 6.037e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2958, Training Loss: 1.375e-01, Validation Loss: 6.039e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2959, Training Loss: 1.374e-01, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2960, Training Loss: 1.373e-01, Validation Loss: 6.037e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2961, Training Loss: 1.372e-01, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2962, Training Loss: 1.372e-01, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2963, Training Loss: 1.371e-01, Validation Loss: 6.036e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2964, Training Loss: 1.370e-01, Validation Loss: 6.037e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 2965, Training Loss: 1.370e-01, Validation Loss: 6.034e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2966, Training Loss: 1.369e-01, Validation Loss: 6.036e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2967, Training Loss: 1.368e-01, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2968, Training Loss: 1.368e-01, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2969, Training Loss: 1.367e-01, Validation Loss: 6.035e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2970, Training Loss: 1.366e-01, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2971, Training Loss: 1.365e-01, Validation Loss: 6.035e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2972, Training Loss: 1.365e-01, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2973, Training Loss: 1.364e-01, Validation Loss: 6.034e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2974, Training Loss: 1.363e-01, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2975, Training Loss: 1.363e-01, Validation Loss: 6.033e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2976, Training Loss: 1.362e-01, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2977, Training Loss: 1.361e-01, Validation Loss: 6.033e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2978, Training Loss: 1.361e-01, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2979, Training Loss: 1.360e-01, Validation Loss: 6.033e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2980, Training Loss: 1.359e-01, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2981, Training Loss: 1.359e-01, Validation Loss: 6.032e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2982, Training Loss: 1.358e-01, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2983, Training Loss: 1.357e-01, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2984, Training Loss: 1.356e-01, Validation Loss: 6.031e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2985, Training Loss: 1.356e-01, Validation Loss: 6.029e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2986, Training Loss: 1.355e-01, Validation Loss: 6.031e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2987, Training Loss: 1.354e-01, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2988, Training Loss: 1.354e-01, Validation Loss: 6.030e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2989, Training Loss: 1.353e-01, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2990, Training Loss: 1.352e-01, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2991, Training Loss: 1.352e-01, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2992, Training Loss: 1.351e-01, Validation Loss: 6.029e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2993, Training Loss: 1.350e-01, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2994, Training Loss: 1.350e-01, Validation Loss: 6.029e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2995, Training Loss: 1.349e-01, Validation Loss: 6.029e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2996, Training Loss: 1.348e-01, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2997, Training Loss: 1.347e-01, Validation Loss: 6.028e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 2998, Training Loss: 1.347e-01, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 2999, Training Loss: 1.346e-01, Validation Loss: 6.028e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3000, Training Loss: 1.345e-01, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3001, Training Loss: 1.345e-01, Validation Loss: 6.027e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3002, Training Loss: 1.344e-01, Validation Loss: 6.027e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3003, Training Loss: 1.343e-01, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3004, Training Loss: 1.343e-01, Validation Loss: 6.026e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3005, Training Loss: 1.342e-01, Validation Loss: 6.025e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3006, Training Loss: 1.341e-01, Validation Loss: 6.026e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3007, Training Loss: 1.341e-01, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3008, Training Loss: 1.340e-01, Validation Loss: 6.025e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3009, Training Loss: 1.339e-01, Validation Loss: 6.025e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3010, Training Loss: 1.339e-01, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3011, Training Loss: 1.338e-01, Validation Loss: 6.024e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3012, Training Loss: 1.337e-01, Validation Loss: 6.025e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3013, Training Loss: 1.337e-01, Validation Loss: 6.022e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3014, Training Loss: 1.336e-01, Validation Loss: 6.024e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3015, Training Loss: 1.335e-01, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3016, Training Loss: 1.335e-01, Validation Loss: 6.022e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3017, Training Loss: 1.334e-01, Validation Loss: 6.023e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3018, Training Loss: 1.333e-01, Validation Loss: 6.023e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3019, Training Loss: 1.332e-01, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3020, Training Loss: 1.332e-01, Validation Loss: 6.022e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3021, Training Loss: 1.331e-01, Validation Loss: 6.022e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3022, Training Loss: 1.330e-01, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3023, Training Loss: 1.330e-01, Validation Loss: 6.022e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3024, Training Loss: 1.329e-01, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3025, Training Loss: 1.328e-01, Validation Loss: 6.022e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3026, Training Loss: 1.328e-01, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3027, Training Loss: 1.327e-01, Validation Loss: 6.021e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3028, Training Loss: 1.326e-01, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3029, Training Loss: 1.326e-01, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3030, Training Loss: 1.325e-01, Validation Loss: 6.020e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3031, Training Loss: 1.324e-01, Validation Loss: 6.018e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3032, Training Loss: 1.324e-01, Validation Loss: 6.020e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3033, Training Loss: 1.323e-01, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3034, Training Loss: 1.322e-01, Validation Loss: 6.019e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3035, Training Loss: 1.322e-01, Validation Loss: 6.018e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3036, Training Loss: 1.321e-01, Validation Loss: 6.018e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3037, Training Loss: 1.320e-01, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3038, Training Loss: 1.320e-01, Validation Loss: 6.018e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3039, Training Loss: 1.319e-01, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3040, Training Loss: 1.319e-01, Validation Loss: 6.018e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3041, Training Loss: 1.318e-01, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3042, Training Loss: 1.317e-01, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3043, Training Loss: 1.316e-01, Validation Loss: 6.015e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3044, Training Loss: 1.316e-01, Validation Loss: 6.017e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3045, Training Loss: 1.315e-01, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3046, Training Loss: 1.315e-01, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3047, Training Loss: 1.314e-01, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3048, Training Loss: 1.313e-01, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3049, Training Loss: 1.313e-01, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3050, Training Loss: 1.312e-01, Validation Loss: 6.015e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3051, Training Loss: 1.311e-01, Validation Loss: 6.016e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3052, Training Loss: 1.311e-01, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3053, Training Loss: 1.310e-01, Validation Loss: 6.014e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3054, Training Loss: 1.309e-01, Validation Loss: 6.015e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3055, Training Loss: 1.309e-01, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3056, Training Loss: 1.308e-01, Validation Loss: 6.014e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3057, Training Loss: 1.307e-01, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3058, Training Loss: 1.307e-01, Validation Loss: 6.014e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3059, Training Loss: 1.306e-01, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3060, Training Loss: 1.305e-01, Validation Loss: 6.013e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3061, Training Loss: 1.305e-01, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3062, Training Loss: 1.304e-01, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3063, Training Loss: 1.303e-01, Validation Loss: 6.010e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3064, Training Loss: 1.303e-01, Validation Loss: 6.012e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3065, Training Loss: 1.302e-01, Validation Loss: 6.010e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3066, Training Loss: 1.301e-01, Validation Loss: 6.012e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3067, Training Loss: 1.301e-01, Validation Loss: 6.012e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3068, Training Loss: 1.300e-01, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3069, Training Loss: 1.299e-01, Validation Loss: 6.011e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3070, Training Loss: 1.299e-01, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3071, Training Loss: 1.298e-01, Validation Loss: 6.011e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3072, Training Loss: 1.297e-01, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3073, Training Loss: 1.297e-01, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3074, Training Loss: 1.296e-01, Validation Loss: 6.009e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3075, Training Loss: 1.296e-01, Validation Loss: 6.010e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3076, Training Loss: 1.295e-01, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3077, Training Loss: 1.294e-01, Validation Loss: 6.009e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3078, Training Loss: 1.294e-01, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3079, Training Loss: 1.293e-01, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3080, Training Loss: 1.292e-01, Validation Loss: 6.008e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3081, Training Loss: 1.292e-01, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3082, Training Loss: 1.291e-01, Validation Loss: 6.008e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3083, Training Loss: 1.290e-01, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3084, Training Loss: 1.290e-01, Validation Loss: 6.008e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3085, Training Loss: 1.289e-01, Validation Loss: 6.005e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3086, Training Loss: 1.288e-01, Validation Loss: 6.007e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3087, Training Loss: 1.288e-01, Validation Loss: 6.007e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3088, Training Loss: 1.287e-01, Validation Loss: 6.005e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3089, Training Loss: 1.287e-01, Validation Loss: 6.006e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3090, Training Loss: 1.286e-01, Validation Loss: 6.007e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3091, Training Loss: 1.285e-01, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3092, Training Loss: 1.285e-01, Validation Loss: 6.006e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3093, Training Loss: 1.284e-01, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3094, Training Loss: 1.283e-01, Validation Loss: 6.006e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3095, Training Loss: 1.283e-01, Validation Loss: 6.005e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3096, Training Loss: 1.282e-01, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3097, Training Loss: 1.281e-01, Validation Loss: 6.005e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3098, Training Loss: 1.281e-01, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3099, Training Loss: 1.280e-01, Validation Loss: 6.004e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3100, Training Loss: 1.279e-01, Validation Loss: 6.002e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3101, Training Loss: 1.279e-01, Validation Loss: 6.004e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3102, Training Loss: 1.278e-01, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3103, Training Loss: 1.278e-01, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3104, Training Loss: 1.277e-01, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3105, Training Loss: 1.276e-01, Validation Loss: 6.003e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3106, Training Loss: 1.276e-01, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3107, Training Loss: 1.275e-01, Validation Loss: 6.003e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3108, Training Loss: 1.274e-01, Validation Loss: 6.003e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3109, Training Loss: 1.274e-01, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3110, Training Loss: 1.273e-01, Validation Loss: 6.002e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3111, Training Loss: 1.273e-01, Validation Loss: 6.002e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3112, Training Loss: 1.272e-01, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3113, Training Loss: 1.271e-01, Validation Loss: 6.001e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3114, Training Loss: 1.271e-01, Validation Loss: 6.002e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3115, Training Loss: 1.270e-01, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3116, Training Loss: 1.269e-01, Validation Loss: 6.001e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3117, Training Loss: 1.269e-01, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3118, Training Loss: 1.268e-01, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3119, Training Loss: 1.268e-01, Validation Loss: 6.000e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3120, Training Loss: 1.267e-01, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3121, Training Loss: 1.266e-01, Validation Loss: 6.000e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3122, Training Loss: 1.266e-01, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3123, Training Loss: 1.265e-01, Validation Loss: 5.999e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3124, Training Loss: 1.264e-01, Validation Loss: 5.999e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3125, Training Loss: 1.264e-01, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3126, Training Loss: 1.263e-01, Validation Loss: 5.999e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3127, Training Loss: 1.263e-01, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3128, Training Loss: 1.262e-01, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3129, Training Loss: 1.261e-01, Validation Loss: 5.998e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3130, Training Loss: 1.261e-01, Validation Loss: 5.996e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3131, Training Loss: 1.260e-01, Validation Loss: 5.998e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3132, Training Loss: 1.259e-01, Validation Loss: 5.996e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3133, Training Loss: 1.259e-01, Validation Loss: 5.997e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3134, Training Loss: 1.258e-01, Validation Loss: 5.997e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3135, Training Loss: 1.258e-01, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3136, Training Loss: 1.257e-01, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3137, Training Loss: 1.256e-01, Validation Loss: 5.996e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3138, Training Loss: 1.256e-01, Validation Loss: 5.997e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3139, Training Loss: 1.255e-01, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3140, Training Loss: 1.255e-01, Validation Loss: 5.996e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3141, Training Loss: 1.254e-01, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3142, Training Loss: 1.253e-01, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3143, Training Loss: 1.253e-01, Validation Loss: 5.995e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3144, Training Loss: 1.252e-01, Validation Loss: 5.995e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3145, Training Loss: 1.251e-01, Validation Loss: 5.993e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3146, Training Loss: 1.251e-01, Validation Loss: 5.995e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3147, Training Loss: 1.250e-01, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3148, Training Loss: 1.250e-01, Validation Loss: 5.994e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3149, Training Loss: 1.249e-01, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3150, Training Loss: 1.248e-01, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3151, Training Loss: 1.248e-01, Validation Loss: 5.994e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3152, Training Loss: 1.247e-01, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3153, Training Loss: 1.247e-01, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3154, Training Loss: 1.246e-01, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3155, Training Loss: 1.245e-01, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3156, Training Loss: 1.245e-01, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3157, Training Loss: 1.244e-01, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3158, Training Loss: 1.244e-01, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3159, Training Loss: 1.243e-01, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3160, Training Loss: 1.242e-01, Validation Loss: 5.992e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3161, Training Loss: 1.242e-01, Validation Loss: 5.992e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3162, Training Loss: 1.241e-01, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3163, Training Loss: 1.241e-01, Validation Loss: 5.991e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3164, Training Loss: 1.240e-01, Validation Loss: 5.991e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3165, Training Loss: 1.239e-01, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3166, Training Loss: 1.239e-01, Validation Loss: 5.991e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3167, Training Loss: 1.238e-01, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3168, Training Loss: 1.238e-01, Validation Loss: 5.990e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3169, Training Loss: 1.237e-01, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3170, Training Loss: 1.236e-01, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3171, Training Loss: 1.236e-01, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3172, Training Loss: 1.235e-01, Validation Loss: 5.989e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3173, Training Loss: 1.234e-01, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3174, Training Loss: 1.234e-01, Validation Loss: 5.989e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3175, Training Loss: 1.233e-01, Validation Loss: 5.989e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3176, Training Loss: 1.233e-01, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3177, Training Loss: 1.232e-01, Validation Loss: 5.988e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3178, Training Loss: 1.232e-01, Validation Loss: 5.989e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3179, Training Loss: 1.231e-01, Validation Loss: 5.986e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3180, Training Loss: 1.230e-01, Validation Loss: 5.988e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3181, Training Loss: 1.230e-01, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3182, Training Loss: 1.229e-01, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3183, Training Loss: 1.229e-01, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3184, Training Loss: 1.228e-01, Validation Loss: 5.987e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3185, Training Loss: 1.227e-01, Validation Loss: 5.987e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3186, Training Loss: 1.227e-01, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3187, Training Loss: 1.226e-01, Validation Loss: 5.987e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3188, Training Loss: 1.226e-01, Validation Loss: 5.987e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3189, Training Loss: 1.225e-01, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3190, Training Loss: 1.224e-01, Validation Loss: 5.986e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3191, Training Loss: 1.224e-01, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3192, Training Loss: 1.223e-01, Validation Loss: 5.986e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3193, Training Loss: 1.223e-01, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3194, Training Loss: 1.222e-01, Validation Loss: 5.986e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3195, Training Loss: 1.221e-01, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3196, Training Loss: 1.221e-01, Validation Loss: 5.985e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3197, Training Loss: 1.220e-01, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3198, Training Loss: 1.220e-01, Validation Loss: 5.985e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3199, Training Loss: 1.219e-01, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3200, Training Loss: 1.218e-01, Validation Loss: 5.984e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3201, Training Loss: 1.218e-01, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3202, Training Loss: 1.217e-01, Validation Loss: 5.984e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3203, Training Loss: 1.217e-01, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3204, Training Loss: 1.216e-01, Validation Loss: 5.984e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3205, Training Loss: 1.216e-01, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3206, Training Loss: 1.215e-01, Validation Loss: 5.983e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3207, Training Loss: 1.214e-01, Validation Loss: 5.983e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3208, Training Loss: 1.214e-01, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3209, Training Loss: 1.213e-01, Validation Loss: 5.983e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3210, Training Loss: 1.213e-01, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3211, Training Loss: 1.212e-01, Validation Loss: 5.983e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3212, Training Loss: 1.211e-01, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3213, Training Loss: 1.211e-01, Validation Loss: 5.982e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3214, Training Loss: 1.210e-01, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3215, Training Loss: 1.210e-01, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3216, Training Loss: 1.209e-01, Validation Loss: 5.982e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3217, Training Loss: 1.209e-01, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3218, Training Loss: 1.208e-01, Validation Loss: 5.981e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3219, Training Loss: 1.207e-01, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3220, Training Loss: 1.207e-01, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3221, Training Loss: 1.206e-01, Validation Loss: 5.980e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3222, Training Loss: 1.206e-01, Validation Loss: 5.980e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3223, Training Loss: 1.205e-01, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3224, Training Loss: 1.205e-01, Validation Loss: 5.980e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3225, Training Loss: 1.204e-01, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3226, Training Loss: 1.203e-01, Validation Loss: 5.980e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3227, Training Loss: 1.203e-01, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3228, Training Loss: 1.202e-01, Validation Loss: 5.979e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3229, Training Loss: 1.202e-01, Validation Loss: 5.979e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3230, Training Loss: 1.201e-01, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3231, Training Loss: 1.200e-01, Validation Loss: 5.980e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3232, Training Loss: 1.200e-01, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3233, Training Loss: 1.199e-01, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3234, Training Loss: 1.199e-01, Validation Loss: 5.978e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3235, Training Loss: 1.198e-01, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3236, Training Loss: 1.198e-01, Validation Loss: 5.978e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3237, Training Loss: 1.197e-01, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3238, Training Loss: 1.196e-01, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3239, Training Loss: 1.196e-01, Validation Loss: 5.977e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3240, Training Loss: 1.195e-01, Validation Loss: 5.978e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3241, Training Loss: 1.195e-01, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3242, Training Loss: 1.194e-01, Validation Loss: 5.977e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3243, Training Loss: 1.194e-01, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3244, Training Loss: 1.193e-01, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3245, Training Loss: 1.192e-01, Validation Loss: 5.977e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3246, Training Loss: 1.192e-01, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3247, Training Loss: 1.191e-01, Validation Loss: 5.976e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3248, Training Loss: 1.191e-01, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3249, Training Loss: 1.190e-01, Validation Loss: 5.976e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3250, Training Loss: 1.190e-01, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3251, Training Loss: 1.189e-01, Validation Loss: 5.976e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3252, Training Loss: 1.188e-01, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3253, Training Loss: 1.188e-01, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3254, Training Loss: 1.187e-01, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3255, Training Loss: 1.187e-01, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3256, Training Loss: 1.186e-01, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3257, Training Loss: 1.186e-01, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3258, Training Loss: 1.185e-01, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3259, Training Loss: 1.185e-01, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3260, Training Loss: 1.184e-01, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3261, Training Loss: 1.183e-01, Validation Loss: 5.974e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3262, Training Loss: 1.183e-01, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3263, Training Loss: 1.182e-01, Validation Loss: 5.974e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3264, Training Loss: 1.182e-01, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3265, Training Loss: 1.181e-01, Validation Loss: 5.973e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3266, Training Loss: 1.181e-01, Validation Loss: 5.973e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3267, Training Loss: 1.180e-01, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3268, Training Loss: 1.179e-01, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3269, Training Loss: 1.179e-01, Validation Loss: 5.973e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3270, Training Loss: 1.178e-01, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3271, Training Loss: 1.178e-01, Validation Loss: 5.973e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3272, Training Loss: 1.177e-01, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3273, Training Loss: 1.177e-01, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3274, Training Loss: 1.176e-01, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3275, Training Loss: 1.176e-01, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3276, Training Loss: 1.175e-01, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3277, Training Loss: 1.174e-01, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3278, Training Loss: 1.174e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3279, Training Loss: 1.173e-01, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3280, Training Loss: 1.173e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3281, Training Loss: 1.172e-01, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3282, Training Loss: 1.172e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3283, Training Loss: 1.171e-01, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3284, Training Loss: 1.171e-01, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3285, Training Loss: 1.170e-01, Validation Loss: 5.970e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3286, Training Loss: 1.169e-01, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3287, Training Loss: 1.169e-01, Validation Loss: 5.970e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3288, Training Loss: 1.168e-01, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3289, Training Loss: 1.168e-01, Validation Loss: 5.970e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3290, Training Loss: 1.167e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3291, Training Loss: 1.167e-01, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3292, Training Loss: 1.166e-01, Validation Loss: 5.969e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3293, Training Loss: 1.166e-01, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3294, Training Loss: 1.165e-01, Validation Loss: 5.969e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3295, Training Loss: 1.164e-01, Validation Loss: 5.969e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3296, Training Loss: 1.164e-01, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3297, Training Loss: 1.163e-01, Validation Loss: 5.968e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3298, Training Loss: 1.163e-01, Validation Loss: 5.969e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3299, Training Loss: 1.162e-01, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3300, Training Loss: 1.162e-01, Validation Loss: 5.968e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3301, Training Loss: 1.161e-01, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3302, Training Loss: 1.161e-01, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3303, Training Loss: 1.160e-01, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3304, Training Loss: 1.160e-01, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3305, Training Loss: 1.159e-01, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3306, Training Loss: 1.158e-01, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3307, Training Loss: 1.158e-01, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3308, Training Loss: 1.157e-01, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3309, Training Loss: 1.157e-01, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3310, Training Loss: 1.156e-01, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3311, Training Loss: 1.156e-01, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3312, Training Loss: 1.155e-01, Validation Loss: 5.966e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3313, Training Loss: 1.155e-01, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3314, Training Loss: 1.154e-01, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3315, Training Loss: 1.154e-01, Validation Loss: 5.965e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3316, Training Loss: 1.153e-01, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3317, Training Loss: 1.152e-01, Validation Loss: 5.966e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3318, Training Loss: 1.152e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3319, Training Loss: 1.151e-01, Validation Loss: 5.965e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3320, Training Loss: 1.151e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3321, Training Loss: 1.150e-01, Validation Loss: 5.965e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3322, Training Loss: 1.150e-01, Validation Loss: 5.965e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3323, Training Loss: 1.149e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3324, Training Loss: 1.149e-01, Validation Loss: 5.964e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3325, Training Loss: 1.148e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3326, Training Loss: 1.148e-01, Validation Loss: 5.964e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3327, Training Loss: 1.147e-01, Validation Loss: 5.964e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3328, Training Loss: 1.147e-01, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3329, Training Loss: 1.146e-01, Validation Loss: 5.963e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3330, Training Loss: 1.145e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3331, Training Loss: 1.145e-01, Validation Loss: 5.964e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3332, Training Loss: 1.144e-01, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3333, Training Loss: 1.144e-01, Validation Loss: 5.963e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3334, Training Loss: 1.143e-01, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3335, Training Loss: 1.143e-01, Validation Loss: 5.963e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3336, Training Loss: 1.142e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3337, Training Loss: 1.142e-01, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3338, Training Loss: 1.141e-01, Validation Loss: 5.963e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3339, Training Loss: 1.141e-01, Validation Loss: 5.963e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3340, Training Loss: 1.140e-01, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3341, Training Loss: 1.140e-01, Validation Loss: 5.962e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3342, Training Loss: 1.139e-01, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3343, Training Loss: 1.139e-01, Validation Loss: 5.962e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3344, Training Loss: 1.138e-01, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3345, Training Loss: 1.138e-01, Validation Loss: 5.961e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3346, Training Loss: 1.137e-01, Validation Loss: 5.962e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3347, Training Loss: 1.136e-01, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3348, Training Loss: 1.136e-01, Validation Loss: 5.961e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3349, Training Loss: 1.135e-01, Validation Loss: 5.961e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3350, Training Loss: 1.135e-01, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3351, Training Loss: 1.134e-01, Validation Loss: 5.961e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3352, Training Loss: 1.134e-01, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3353, Training Loss: 1.133e-01, Validation Loss: 5.960e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3354, Training Loss: 1.133e-01, Validation Loss: 5.958e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3355, Training Loss: 1.132e-01, Validation Loss: 5.960e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3356, Training Loss: 1.132e-01, Validation Loss: 5.961e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3357, Training Loss: 1.131e-01, Validation Loss: 5.958e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3358, Training Loss: 1.131e-01, Validation Loss: 5.959e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3359, Training Loss: 1.130e-01, Validation Loss: 5.960e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3360, Training Loss: 1.130e-01, Validation Loss: 5.958e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3361, Training Loss: 1.129e-01, Validation Loss: 5.959e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3362, Training Loss: 1.129e-01, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3363, Training Loss: 1.128e-01, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3364, Training Loss: 1.128e-01, Validation Loss: 5.959e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3365, Training Loss: 1.127e-01, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3366, Training Loss: 1.126e-01, Validation Loss: 5.958e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3367, Training Loss: 1.126e-01, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3368, Training Loss: 1.125e-01, Validation Loss: 5.959e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3369, Training Loss: 1.125e-01, Validation Loss: 5.958e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3370, Training Loss: 1.124e-01, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3371, Training Loss: 1.124e-01, Validation Loss: 5.957e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3372, Training Loss: 1.123e-01, Validation Loss: 5.958e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3373, Training Loss: 1.123e-01, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3374, Training Loss: 1.122e-01, Validation Loss: 5.957e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3375, Training Loss: 1.122e-01, Validation Loss: 5.957e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3376, Training Loss: 1.121e-01, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3377, Training Loss: 1.121e-01, Validation Loss: 5.957e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3378, Training Loss: 1.120e-01, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3379, Training Loss: 1.120e-01, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3380, Training Loss: 1.119e-01, Validation Loss: 5.957e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3381, Training Loss: 1.119e-01, Validation Loss: 5.957e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3382, Training Loss: 1.118e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3383, Training Loss: 1.118e-01, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3384, Training Loss: 1.117e-01, Validation Loss: 5.956e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3385, Training Loss: 1.117e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3386, Training Loss: 1.116e-01, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3387, Training Loss: 1.116e-01, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3388, Training Loss: 1.115e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3389, Training Loss: 1.115e-01, Validation Loss: 5.955e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3390, Training Loss: 1.114e-01, Validation Loss: 5.955e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3391, Training Loss: 1.114e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3392, Training Loss: 1.113e-01, Validation Loss: 5.955e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3393, Training Loss: 1.113e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3394, Training Loss: 1.112e-01, Validation Loss: 5.955e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3395, Training Loss: 1.112e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3396, Training Loss: 1.111e-01, Validation Loss: 5.955e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3397, Training Loss: 1.111e-01, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3398, Training Loss: 1.110e-01, Validation Loss: 5.954e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3399, Training Loss: 1.109e-01, Validation Loss: 5.954e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3400, Training Loss: 1.109e-01, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3401, Training Loss: 1.108e-01, Validation Loss: 5.954e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3402, Training Loss: 1.108e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3403, Training Loss: 1.107e-01, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3404, Training Loss: 1.107e-01, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3405, Training Loss: 1.106e-01, Validation Loss: 5.954e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3406, Training Loss: 1.106e-01, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3407, Training Loss: 1.105e-01, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3408, Training Loss: 1.105e-01, Validation Loss: 5.953e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3409, Training Loss: 1.104e-01, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3410, Training Loss: 1.104e-01, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3411, Training Loss: 1.103e-01, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3412, Training Loss: 1.103e-01, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3413, Training Loss: 1.102e-01, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3414, Training Loss: 1.102e-01, Validation Loss: 5.952e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3415, Training Loss: 1.101e-01, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3416, Training Loss: 1.101e-01, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3417, Training Loss: 1.100e-01, Validation Loss: 5.952e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3418, Training Loss: 1.100e-01, Validation Loss: 5.952e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3419, Training Loss: 1.099e-01, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3420, Training Loss: 1.099e-01, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3421, Training Loss: 1.098e-01, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3422, Training Loss: 1.098e-01, Validation Loss: 5.952e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3423, Training Loss: 1.097e-01, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3424, Training Loss: 1.097e-01, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3425, Training Loss: 1.096e-01, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3426, Training Loss: 1.096e-01, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3427, Training Loss: 1.095e-01, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3428, Training Loss: 1.095e-01, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3429, Training Loss: 1.094e-01, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3430, Training Loss: 1.094e-01, Validation Loss: 5.950e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3431, Training Loss: 1.093e-01, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3432, Training Loss: 1.093e-01, Validation Loss: 5.950e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3433, Training Loss: 1.092e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3434, Training Loss: 1.092e-01, Validation Loss: 5.950e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3435, Training Loss: 1.091e-01, Validation Loss: 5.950e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3436, Training Loss: 1.091e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3437, Training Loss: 1.090e-01, Validation Loss: 5.950e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3438, Training Loss: 1.090e-01, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3439, Training Loss: 1.089e-01, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3440, Training Loss: 1.089e-01, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3441, Training Loss: 1.088e-01, Validation Loss: 5.950e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3442, Training Loss: 1.088e-01, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3443, Training Loss: 1.087e-01, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3444, Training Loss: 1.087e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3445, Training Loss: 1.086e-01, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3446, Training Loss: 1.086e-01, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3447, Training Loss: 1.085e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3448, Training Loss: 1.085e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3449, Training Loss: 1.084e-01, Validation Loss: 5.948e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3450, Training Loss: 1.084e-01, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3451, Training Loss: 1.083e-01, Validation Loss: 5.948e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3452, Training Loss: 1.083e-01, Validation Loss: 5.949e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3453, Training Loss: 1.083e-01, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3454, Training Loss: 1.082e-01, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3455, Training Loss: 1.081e-01, Validation Loss: 5.948e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3456, Training Loss: 1.081e-01, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3457, Training Loss: 1.081e-01, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3458, Training Loss: 1.080e-01, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3459, Training Loss: 1.080e-01, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3460, Training Loss: 1.079e-01, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3461, Training Loss: 1.079e-01, Validation Loss: 5.948e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3462, Training Loss: 1.078e-01, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3463, Training Loss: 1.078e-01, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3464, Training Loss: 1.077e-01, Validation Loss: 5.947e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3465, Training Loss: 1.077e-01, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3466, Training Loss: 1.076e-01, Validation Loss: 5.946e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3467, Training Loss: 1.076e-01, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3468, Training Loss: 1.075e-01, Validation Loss: 5.946e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3469, Training Loss: 1.075e-01, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3470, Training Loss: 1.074e-01, Validation Loss: 5.946e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3471, Training Loss: 1.074e-01, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3472, Training Loss: 1.073e-01, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3473, Training Loss: 1.073e-01, Validation Loss: 5.946e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3474, Training Loss: 1.072e-01, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3475, Training Loss: 1.072e-01, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3476, Training Loss: 1.071e-01, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3477, Training Loss: 1.071e-01, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3478, Training Loss: 1.070e-01, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3479, Training Loss: 1.070e-01, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3480, Training Loss: 1.069e-01, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3481, Training Loss: 1.069e-01, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3482, Training Loss: 1.068e-01, Validation Loss: 5.945e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3483, Training Loss: 1.068e-01, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3484, Training Loss: 1.067e-01, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3485, Training Loss: 1.067e-01, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3486, Training Loss: 1.067e-01, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3487, Training Loss: 1.066e-01, Validation Loss: 5.945e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3488, Training Loss: 1.066e-01, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3489, Training Loss: 1.065e-01, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3490, Training Loss: 1.065e-01, Validation Loss: 5.944e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3491, Training Loss: 1.064e-01, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3492, Training Loss: 1.064e-01, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3493, Training Loss: 1.063e-01, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3494, Training Loss: 1.063e-01, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3495, Training Loss: 1.062e-01, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3496, Training Loss: 1.062e-01, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3497, Training Loss: 1.061e-01, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3498, Training Loss: 1.061e-01, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3499, Training Loss: 1.060e-01, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3500, Training Loss: 1.060e-01, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3501, Training Loss: 1.059e-01, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3502, Training Loss: 1.059e-01, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3503, Training Loss: 1.058e-01, Validation Loss: 5.943e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3504, Training Loss: 1.058e-01, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3505, Training Loss: 1.057e-01, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3506, Training Loss: 1.057e-01, Validation Loss: 5.942e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3507, Training Loss: 1.057e-01, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3508, Training Loss: 1.056e-01, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3509, Training Loss: 1.056e-01, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3510, Training Loss: 1.055e-01, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3511, Training Loss: 1.055e-01, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3512, Training Loss: 1.054e-01, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3513, Training Loss: 1.054e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3514, Training Loss: 1.053e-01, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3515, Training Loss: 1.053e-01, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3516, Training Loss: 1.052e-01, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3517, Training Loss: 1.052e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3518, Training Loss: 1.051e-01, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3519, Training Loss: 1.051e-01, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3520, Training Loss: 1.050e-01, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3521, Training Loss: 1.050e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3522, Training Loss: 1.050e-01, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3523, Training Loss: 1.049e-01, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3524, Training Loss: 1.049e-01, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3525, Training Loss: 1.048e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3526, Training Loss: 1.048e-01, Validation Loss: 5.940e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3527, Training Loss: 1.047e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3528, Training Loss: 1.047e-01, Validation Loss: 5.940e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3529, Training Loss: 1.046e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3530, Training Loss: 1.046e-01, Validation Loss: 5.940e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3531, Training Loss: 1.045e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3532, Training Loss: 1.045e-01, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3533, Training Loss: 1.044e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3534, Training Loss: 1.044e-01, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3535, Training Loss: 1.043e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3536, Training Loss: 1.043e-01, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3537, Training Loss: 1.042e-01, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3538, Training Loss: 1.042e-01, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3539, Training Loss: 1.042e-01, Validation Loss: 5.939e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3540, Training Loss: 1.041e-01, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3541, Training Loss: 1.041e-01, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3542, Training Loss: 1.040e-01, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3543, Training Loss: 1.040e-01, Validation Loss: 5.938e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3544, Training Loss: 1.039e-01, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3545, Training Loss: 1.039e-01, Validation Loss: 5.938e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3546, Training Loss: 1.038e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3547, Training Loss: 1.038e-01, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3548, Training Loss: 1.037e-01, Validation Loss: 5.938e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3549, Training Loss: 1.037e-01, Validation Loss: 5.938e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3550, Training Loss: 1.037e-01, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3551, Training Loss: 1.036e-01, Validation Loss: 5.938e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3552, Training Loss: 1.036e-01, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3553, Training Loss: 1.035e-01, Validation Loss: 5.938e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3554, Training Loss: 1.035e-01, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3555, Training Loss: 1.034e-01, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3556, Training Loss: 1.034e-01, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3557, Training Loss: 1.033e-01, Validation Loss: 5.937e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3558, Training Loss: 1.033e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3559, Training Loss: 1.032e-01, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3560, Training Loss: 1.032e-01, Validation Loss: 5.937e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3561, Training Loss: 1.031e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3562, Training Loss: 1.031e-01, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3563, Training Loss: 1.031e-01, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3564, Training Loss: 1.030e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3565, Training Loss: 1.030e-01, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3566, Training Loss: 1.029e-01, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3567, Training Loss: 1.029e-01, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3568, Training Loss: 1.028e-01, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3569, Training Loss: 1.028e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3570, Training Loss: 1.027e-01, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3571, Training Loss: 1.027e-01, Validation Loss: 5.936e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3572, Training Loss: 1.026e-01, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3573, Training Loss: 1.026e-01, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3574, Training Loss: 1.026e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3575, Training Loss: 1.025e-01, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3576, Training Loss: 1.025e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3577, Training Loss: 1.024e-01, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3578, Training Loss: 1.024e-01, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3579, Training Loss: 1.023e-01, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3580, Training Loss: 1.023e-01, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3581, Training Loss: 1.022e-01, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3582, Training Loss: 1.022e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3583, Training Loss: 1.022e-01, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3584, Training Loss: 1.021e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3585, Training Loss: 1.021e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3586, Training Loss: 1.020e-01, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3587, Training Loss: 1.020e-01, Validation Loss: 5.935e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3588, Training Loss: 1.019e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3589, Training Loss: 1.019e-01, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3590, Training Loss: 1.018e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3591, Training Loss: 1.018e-01, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3592, Training Loss: 1.017e-01, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3593, Training Loss: 1.017e-01, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3594, Training Loss: 1.017e-01, Validation Loss: 5.934e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3595, Training Loss: 1.016e-01, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3596, Training Loss: 1.016e-01, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3597, Training Loss: 1.015e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3598, Training Loss: 1.015e-01, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3599, Training Loss: 1.014e-01, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3600, Training Loss: 1.014e-01, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3601, Training Loss: 1.013e-01, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3602, Training Loss: 1.013e-01, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3603, Training Loss: 1.013e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3604, Training Loss: 1.012e-01, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3605, Training Loss: 1.012e-01, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3606, Training Loss: 1.011e-01, Validation Loss: 5.933e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3607, Training Loss: 1.011e-01, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3608, Training Loss: 1.010e-01, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3609, Training Loss: 1.010e-01, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3610, Training Loss: 1.009e-01, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3611, Training Loss: 1.009e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3612, Training Loss: 1.009e-01, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3613, Training Loss: 1.008e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3614, Training Loss: 1.008e-01, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3615, Training Loss: 1.007e-01, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3616, Training Loss: 1.007e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3617, Training Loss: 1.006e-01, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3618, Training Loss: 1.006e-01, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3619, Training Loss: 1.005e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3620, Training Loss: 1.005e-01, Validation Loss: 5.931e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3621, Training Loss: 1.005e-01, Validation Loss: 5.932e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3622, Training Loss: 1.004e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3623, Training Loss: 1.004e-01, Validation Loss: 5.931e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3624, Training Loss: 1.003e-01, Validation Loss: 5.931e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3625, Training Loss: 1.003e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3626, Training Loss: 1.002e-01, Validation Loss: 5.931e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3627, Training Loss: 1.002e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3628, Training Loss: 1.002e-01, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3629, Training Loss: 1.001e-01, Validation Loss: 5.931e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3630, Training Loss: 1.001e-01, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3631, Training Loss: 1.000e-01, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3632, Training Loss: 9.998e-02, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3633, Training Loss: 9.994e-02, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3634, Training Loss: 9.990e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3635, Training Loss: 9.985e-02, Validation Loss: 5.931e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3636, Training Loss: 9.981e-02, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3637, Training Loss: 9.977e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3638, Training Loss: 9.973e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3639, Training Loss: 9.968e-02, Validation Loss: 5.931e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3640, Training Loss: 9.964e-02, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3641, Training Loss: 9.959e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3642, Training Loss: 9.955e-02, Validation Loss: 5.931e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3643, Training Loss: 9.951e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3644, Training Loss: 9.947e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3645, Training Loss: 9.942e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3646, Training Loss: 9.938e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3647, Training Loss: 9.934e-02, Validation Loss: 5.930e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3648, Training Loss: 9.929e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3649, Training Loss: 9.925e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3650, Training Loss: 9.921e-02, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3651, Training Loss: 9.917e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3652, Training Loss: 9.912e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3653, Training Loss: 9.908e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3654, Training Loss: 9.903e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3655, Training Loss: 9.900e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3656, Training Loss: 9.895e-02, Validation Loss: 5.929e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3657, Training Loss: 9.891e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3658, Training Loss: 9.886e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3659, Training Loss: 9.882e-02, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3660, Training Loss: 9.878e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3661, Training Loss: 9.874e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3662, Training Loss: 9.869e-02, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3663, Training Loss: 9.866e-02, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3664, Training Loss: 9.861e-02, Validation Loss: 5.929e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3665, Training Loss: 9.857e-02, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3666, Training Loss: 9.853e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3667, Training Loss: 9.848e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3668, Training Loss: 9.844e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3669, Training Loss: 9.840e-02, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3670, Training Loss: 9.835e-02, Validation Loss: 5.928e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3671, Training Loss: 9.831e-02, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3672, Training Loss: 9.827e-02, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3673, Training Loss: 9.823e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3674, Training Loss: 9.819e-02, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3675, Training Loss: 9.814e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3676, Training Loss: 9.811e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3677, Training Loss: 9.806e-02, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3678, Training Loss: 9.802e-02, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3679, Training Loss: 9.798e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3680, Training Loss: 9.794e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3681, Training Loss: 9.789e-02, Validation Loss: 5.928e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3682, Training Loss: 9.785e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3683, Training Loss: 9.781e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3684, Training Loss: 9.777e-02, Validation Loss: 5.927e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3685, Training Loss: 9.773e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3686, Training Loss: 9.768e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3687, Training Loss: 9.764e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3688, Training Loss: 9.760e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3689, Training Loss: 9.756e-02, Validation Loss: 5.927e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3690, Training Loss: 9.752e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3691, Training Loss: 9.747e-02, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3692, Training Loss: 9.743e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3693, Training Loss: 9.739e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3694, Training Loss: 9.735e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3695, Training Loss: 9.731e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3696, Training Loss: 9.726e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3697, Training Loss: 9.722e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3698, Training Loss: 9.718e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3699, Training Loss: 9.714e-02, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3700, Training Loss: 9.710e-02, Validation Loss: 5.926e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3701, Training Loss: 9.706e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3702, Training Loss: 9.702e-02, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3703, Training Loss: 9.697e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3704, Training Loss: 9.694e-02, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3705, Training Loss: 9.689e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3706, Training Loss: 9.685e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3707, Training Loss: 9.681e-02, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3708, Training Loss: 9.677e-02, Validation Loss: 5.926e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3709, Training Loss: 9.673e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3710, Training Loss: 9.669e-02, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3711, Training Loss: 9.664e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3712, Training Loss: 9.661e-02, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3713, Training Loss: 9.656e-02, Validation Loss: 5.926e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3714, Training Loss: 9.653e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3715, Training Loss: 9.648e-02, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3716, Training Loss: 9.644e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3717, Training Loss: 9.640e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3718, Training Loss: 9.636e-02, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3719, Training Loss: 9.632e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3720, Training Loss: 9.628e-02, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3721, Training Loss: 9.623e-02, Validation Loss: 5.925e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3722, Training Loss: 9.620e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3723, Training Loss: 9.615e-02, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3724, Training Loss: 9.611e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3725, Training Loss: 9.607e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3726, Training Loss: 9.603e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3727, Training Loss: 9.599e-02, Validation Loss: 5.925e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3728, Training Loss: 9.595e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3729, Training Loss: 9.591e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3730, Training Loss: 9.587e-02, Validation Loss: 5.925e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3731, Training Loss: 9.583e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3732, Training Loss: 9.579e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3733, Training Loss: 9.575e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3734, Training Loss: 9.571e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3735, Training Loss: 9.567e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3736, Training Loss: 9.562e-02, Validation Loss: 5.924e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3737, Training Loss: 9.559e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3738, Training Loss: 9.555e-02, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3739, Training Loss: 9.550e-02, Validation Loss: 5.924e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3740, Training Loss: 9.546e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3741, Training Loss: 9.543e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3742, Training Loss: 9.539e-02, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3743, Training Loss: 9.534e-02, Validation Loss: 5.924e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3744, Training Loss: 9.530e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3745, Training Loss: 9.526e-02, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3746, Training Loss: 9.522e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3747, Training Loss: 9.518e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3748, Training Loss: 9.514e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3749, Training Loss: 9.510e-02, Validation Loss: 5.924e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3750, Training Loss: 9.507e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3751, Training Loss: 9.502e-02, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3752, Training Loss: 9.498e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3753, Training Loss: 9.494e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3754, Training Loss: 9.490e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3755, Training Loss: 9.486e-02, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3756, Training Loss: 9.482e-02, Validation Loss: 5.923e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3757, Training Loss: 9.478e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3758, Training Loss: 9.474e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3759, Training Loss: 9.470e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3760, Training Loss: 9.466e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3761, Training Loss: 9.462e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3762, Training Loss: 9.458e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3763, Training Loss: 9.454e-02, Validation Loss: 5.923e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3764, Training Loss: 9.450e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3765, Training Loss: 9.446e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3766, Training Loss: 9.442e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3767, Training Loss: 9.438e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3768, Training Loss: 9.435e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3769, Training Loss: 9.430e-02, Validation Loss: 5.923e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3770, Training Loss: 9.427e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3771, Training Loss: 9.423e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3772, Training Loss: 9.418e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3773, Training Loss: 9.415e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3774, Training Loss: 9.411e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3775, Training Loss: 9.406e-02, Validation Loss: 5.922e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3776, Training Loss: 9.403e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3777, Training Loss: 9.399e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3778, Training Loss: 9.395e-02, Validation Loss: 5.921e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3779, Training Loss: 9.391e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3780, Training Loss: 9.387e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3781, Training Loss: 9.383e-02, Validation Loss: 5.922e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3782, Training Loss: 9.379e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3783, Training Loss: 9.375e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3784, Training Loss: 9.371e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3785, Training Loss: 9.367e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3786, Training Loss: 9.364e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3787, Training Loss: 9.359e-02, Validation Loss: 5.921e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3788, Training Loss: 9.356e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3789, Training Loss: 9.352e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3790, Training Loss: 9.348e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3791, Training Loss: 9.344e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3792, Training Loss: 9.340e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3793, Training Loss: 9.336e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3794, Training Loss: 9.332e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3795, Training Loss: 9.328e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3796, Training Loss: 9.325e-02, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3797, Training Loss: 9.320e-02, Validation Loss: 5.920e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3798, Training Loss: 9.317e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3799, Training Loss: 9.313e-02, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3800, Training Loss: 9.309e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3801, Training Loss: 9.305e-02, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3802, Training Loss: 9.301e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3803, Training Loss: 9.297e-02, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3804, Training Loss: 9.293e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3805, Training Loss: 9.290e-02, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3806, Training Loss: 9.285e-02, Validation Loss: 5.921e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3807, Training Loss: 9.282e-02, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3808, Training Loss: 9.278e-02, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3809, Training Loss: 9.274e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3810, Training Loss: 9.270e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3811, Training Loss: 9.266e-02, Validation Loss: 5.919e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3812, Training Loss: 9.262e-02, Validation Loss: 5.920e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3813, Training Loss: 9.259e-02, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3814, Training Loss: 9.255e-02, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3815, Training Loss: 9.251e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3816, Training Loss: 9.247e-02, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3817, Training Loss: 9.243e-02, Validation Loss: 5.919e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3818, Training Loss: 9.239e-02, Validation Loss: 5.920e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3819, Training Loss: 9.235e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3820, Training Loss: 9.232e-02, Validation Loss: 5.919e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3821, Training Loss: 9.228e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3822, Training Loss: 9.224e-02, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3823, Training Loss: 9.220e-02, Validation Loss: 5.919e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3824, Training Loss: 9.216e-02, Validation Loss: 5.919e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3825, Training Loss: 9.212e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3826, Training Loss: 9.209e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3827, Training Loss: 9.205e-02, Validation Loss: 5.920e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3828, Training Loss: 9.201e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3829, Training Loss: 9.197e-02, Validation Loss: 5.919e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3830, Training Loss: 9.193e-02, Validation Loss: 5.919e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3831, Training Loss: 9.190e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3832, Training Loss: 9.186e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3833, Training Loss: 9.182e-02, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3834, Training Loss: 9.178e-02, Validation Loss: 5.919e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3835, Training Loss: 9.175e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3836, Training Loss: 9.171e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3837, Training Loss: 9.167e-02, Validation Loss: 5.919e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3838, Training Loss: 9.163e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3839, Training Loss: 9.159e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3840, Training Loss: 9.155e-02, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3841, Training Loss: 9.152e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3842, Training Loss: 9.148e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3843, Training Loss: 9.144e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3844, Training Loss: 9.140e-02, Validation Loss: 5.918e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3845, Training Loss: 9.137e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3846, Training Loss: 9.133e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3847, Training Loss: 9.129e-02, Validation Loss: 5.918e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3848, Training Loss: 9.125e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3849, Training Loss: 9.122e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3850, Training Loss: 9.118e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3851, Training Loss: 9.114e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3852, Training Loss: 9.110e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3853, Training Loss: 9.107e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3854, Training Loss: 9.103e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3855, Training Loss: 9.099e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3856, Training Loss: 9.095e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3857, Training Loss: 9.092e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3858, Training Loss: 9.088e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3859, Training Loss: 9.084e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3860, Training Loss: 9.080e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3861, Training Loss: 9.077e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3862, Training Loss: 9.073e-02, Validation Loss: 5.918e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3863, Training Loss: 9.069e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3864, Training Loss: 9.066e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3865, Training Loss: 9.062e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3866, Training Loss: 9.058e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3867, Training Loss: 9.054e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3868, Training Loss: 9.051e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3869, Training Loss: 9.047e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3870, Training Loss: 9.043e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3871, Training Loss: 9.039e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3872, Training Loss: 9.035e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3873, Training Loss: 9.032e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3874, Training Loss: 9.028e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3875, Training Loss: 9.025e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3876, Training Loss: 9.021e-02, Validation Loss: 5.917e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3877, Training Loss: 9.017e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3878, Training Loss: 9.014e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3879, Training Loss: 9.010e-02, Validation Loss: 5.916e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3880, Training Loss: 9.006e-02, Validation Loss: 5.917e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 3881, Training Loss: 9.002e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3882, Training Loss: 8.999e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3883, Training Loss: 8.995e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3884, Training Loss: 8.991e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3885, Training Loss: 8.988e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3886, Training Loss: 8.984e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3887, Training Loss: 8.980e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3888, Training Loss: 8.977e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3889, Training Loss: 8.973e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3890, Training Loss: 8.969e-02, Validation Loss: 5.916e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3891, Training Loss: 8.966e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3892, Training Loss: 8.962e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3893, Training Loss: 8.958e-02, Validation Loss: 5.916e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3894, Training Loss: 8.955e-02, Validation Loss: 5.916e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 3895, Training Loss: 8.951e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3896, Training Loss: 8.948e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3897, Training Loss: 8.944e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3898, Training Loss: 8.940e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3899, Training Loss: 8.937e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3900, Training Loss: 8.933e-02, Validation Loss: 5.916e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3901, Training Loss: 8.929e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3902, Training Loss: 8.926e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3903, Training Loss: 8.922e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3904, Training Loss: 8.918e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3905, Training Loss: 8.915e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3906, Training Loss: 8.911e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3907, Training Loss: 8.907e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3908, Training Loss: 8.904e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3909, Training Loss: 8.900e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3910, Training Loss: 8.896e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3911, Training Loss: 8.893e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3912, Training Loss: 8.889e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3913, Training Loss: 8.886e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3914, Training Loss: 8.882e-02, Validation Loss: 5.915e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3915, Training Loss: 8.879e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3916, Training Loss: 8.875e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3917, Training Loss: 8.871e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3918, Training Loss: 8.868e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3919, Training Loss: 8.864e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3920, Training Loss: 8.861e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3921, Training Loss: 8.857e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3922, Training Loss: 8.853e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3923, Training Loss: 8.850e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3924, Training Loss: 8.846e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3925, Training Loss: 8.842e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3926, Training Loss: 8.839e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3927, Training Loss: 8.835e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3928, Training Loss: 8.832e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3929, Training Loss: 8.828e-02, Validation Loss: 5.915e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3930, Training Loss: 8.825e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3931, Training Loss: 8.821e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3932, Training Loss: 8.817e-02, Validation Loss: 5.915e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3933, Training Loss: 8.814e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3934, Training Loss: 8.811e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3935, Training Loss: 8.807e-02, Validation Loss: 5.915e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3936, Training Loss: 8.803e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3937, Training Loss: 8.800e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3938, Training Loss: 8.796e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3939, Training Loss: 8.793e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3940, Training Loss: 8.789e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3941, Training Loss: 8.785e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3942, Training Loss: 8.782e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3943, Training Loss: 8.778e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3944, Training Loss: 8.775e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3945, Training Loss: 8.771e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3946, Training Loss: 8.768e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3947, Training Loss: 8.764e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3948, Training Loss: 8.761e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3949, Training Loss: 8.757e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3950, Training Loss: 8.754e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3951, Training Loss: 8.750e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3952, Training Loss: 8.746e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3953, Training Loss: 8.743e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3954, Training Loss: 8.740e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3955, Training Loss: 8.736e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3956, Training Loss: 8.733e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3957, Training Loss: 8.729e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3958, Training Loss: 8.725e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3959, Training Loss: 8.722e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3960, Training Loss: 8.719e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3961, Training Loss: 8.715e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3962, Training Loss: 8.711e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3963, Training Loss: 8.708e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3964, Training Loss: 8.705e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3965, Training Loss: 8.701e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3966, Training Loss: 8.698e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3967, Training Loss: 8.694e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3968, Training Loss: 8.691e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3969, Training Loss: 8.687e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3970, Training Loss: 8.684e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3971, Training Loss: 8.680e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3972, Training Loss: 8.677e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3973, Training Loss: 8.673e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3974, Training Loss: 8.670e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3975, Training Loss: 8.666e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3976, Training Loss: 8.663e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3977, Training Loss: 8.659e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3978, Training Loss: 8.656e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3979, Training Loss: 8.652e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3980, Training Loss: 8.649e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3981, Training Loss: 8.645e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3982, Training Loss: 8.642e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3983, Training Loss: 8.638e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3984, Training Loss: 8.635e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3985, Training Loss: 8.632e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3986, Training Loss: 8.628e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3987, Training Loss: 8.624e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3988, Training Loss: 8.621e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3989, Training Loss: 8.618e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3990, Training Loss: 8.614e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3991, Training Loss: 8.611e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3992, Training Loss: 8.608e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3993, Training Loss: 8.604e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3994, Training Loss: 8.600e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3995, Training Loss: 8.597e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3996, Training Loss: 8.594e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 3997, Training Loss: 8.590e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 3998, Training Loss: 8.587e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 3999, Training Loss: 8.584e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4000, Training Loss: 8.580e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4001, Training Loss: 8.577e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4002, Training Loss: 8.573e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4003, Training Loss: 8.570e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4004, Training Loss: 8.566e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4005, Training Loss: 8.563e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4006, Training Loss: 8.560e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4007, Training Loss: 8.556e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4008, Training Loss: 8.553e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4009, Training Loss: 8.549e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4010, Training Loss: 8.546e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4011, Training Loss: 8.543e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4012, Training Loss: 8.539e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4013, Training Loss: 8.536e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4014, Training Loss: 8.532e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4015, Training Loss: 8.529e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4016, Training Loss: 8.526e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4017, Training Loss: 8.522e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4018, Training Loss: 8.519e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4019, Training Loss: 8.516e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4020, Training Loss: 8.512e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4021, Training Loss: 8.509e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4022, Training Loss: 8.506e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4023, Training Loss: 8.502e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4024, Training Loss: 8.499e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4025, Training Loss: 8.495e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4026, Training Loss: 8.492e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4027, Training Loss: 8.488e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4028, Training Loss: 8.485e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4029, Training Loss: 8.482e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4030, Training Loss: 8.478e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4031, Training Loss: 8.475e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4032, Training Loss: 8.472e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4033, Training Loss: 8.468e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4034, Training Loss: 8.465e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4035, Training Loss: 8.462e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4036, Training Loss: 8.459e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4037, Training Loss: 8.455e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4038, Training Loss: 8.452e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4039, Training Loss: 8.448e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4040, Training Loss: 8.445e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4041, Training Loss: 8.442e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4042, Training Loss: 8.438e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4043, Training Loss: 8.435e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4044, Training Loss: 8.432e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4045, Training Loss: 8.428e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4046, Training Loss: 8.425e-02, Validation Loss: 5.912e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 4047, Training Loss: 8.422e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4048, Training Loss: 8.419e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4049, Training Loss: 8.415e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4050, Training Loss: 8.412e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4051, Training Loss: 8.409e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4052, Training Loss: 8.405e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4053, Training Loss: 8.402e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4054, Training Loss: 8.399e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4055, Training Loss: 8.395e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4056, Training Loss: 8.392e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4057, Training Loss: 8.389e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4058, Training Loss: 8.386e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4059, Training Loss: 8.382e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4060, Training Loss: 8.379e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4061, Training Loss: 8.376e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4062, Training Loss: 8.372e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4063, Training Loss: 8.369e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4064, Training Loss: 8.366e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4065, Training Loss: 8.362e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4066, Training Loss: 8.359e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4067, Training Loss: 8.356e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4068, Training Loss: 8.352e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4069, Training Loss: 8.349e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4070, Training Loss: 8.346e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4071, Training Loss: 8.343e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4072, Training Loss: 8.339e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4073, Training Loss: 8.336e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4074, Training Loss: 8.333e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4075, Training Loss: 8.330e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4076, Training Loss: 8.327e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4077, Training Loss: 8.323e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4078, Training Loss: 8.320e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4079, Training Loss: 8.317e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4080, Training Loss: 8.313e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4081, Training Loss: 8.310e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4082, Training Loss: 8.307e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4083, Training Loss: 8.303e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4084, Training Loss: 8.300e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4085, Training Loss: 8.297e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4086, Training Loss: 8.294e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4087, Training Loss: 8.290e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4088, Training Loss: 8.287e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4089, Training Loss: 8.284e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4090, Training Loss: 8.281e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4091, Training Loss: 8.277e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4092, Training Loss: 8.275e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4093, Training Loss: 8.271e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4094, Training Loss: 8.268e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4095, Training Loss: 8.265e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4096, Training Loss: 8.261e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4097, Training Loss: 8.258e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4098, Training Loss: 8.255e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4099, Training Loss: 8.252e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4100, Training Loss: 8.249e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4101, Training Loss: 8.246e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4102, Training Loss: 8.242e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4103, Training Loss: 8.239e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4104, Training Loss: 8.236e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4105, Training Loss: 8.232e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4106, Training Loss: 8.230e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4107, Training Loss: 8.226e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4108, Training Loss: 8.223e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4109, Training Loss: 8.220e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4110, Training Loss: 8.217e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4111, Training Loss: 8.214e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4112, Training Loss: 8.210e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4113, Training Loss: 8.207e-02, Validation Loss: 5.911e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 4114, Training Loss: 8.204e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4115, Training Loss: 8.201e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4116, Training Loss: 8.197e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4117, Training Loss: 8.194e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4118, Training Loss: 8.191e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4119, Training Loss: 8.188e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4120, Training Loss: 8.185e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4121, Training Loss: 8.182e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4122, Training Loss: 8.179e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4123, Training Loss: 8.175e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4124, Training Loss: 8.172e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4125, Training Loss: 8.169e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4126, Training Loss: 8.166e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4127, Training Loss: 8.163e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4128, Training Loss: 8.160e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4129, Training Loss: 8.156e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4130, Training Loss: 8.153e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4131, Training Loss: 8.150e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4132, Training Loss: 8.147e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4133, Training Loss: 8.144e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4134, Training Loss: 8.141e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4135, Training Loss: 8.137e-02, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4136, Training Loss: 8.134e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4137, Training Loss: 8.131e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4138, Training Loss: 8.128e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4139, Training Loss: 8.125e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4140, Training Loss: 8.121e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4141, Training Loss: 8.119e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4142, Training Loss: 8.115e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4143, Training Loss: 8.112e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4144, Training Loss: 8.109e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4145, Training Loss: 8.106e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4146, Training Loss: 8.103e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4147, Training Loss: 8.100e-02, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4148, Training Loss: 8.097e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4149, Training Loss: 8.093e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4150, Training Loss: 8.090e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4151, Training Loss: 8.087e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4152, Training Loss: 8.084e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4153, Training Loss: 8.081e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4154, Training Loss: 8.078e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4155, Training Loss: 8.075e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4156, Training Loss: 8.072e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4157, Training Loss: 8.069e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4158, Training Loss: 8.066e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4159, Training Loss: 8.062e-02, Validation Loss: 5.910e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4160, Training Loss: 8.059e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4161, Training Loss: 8.056e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4162, Training Loss: 8.053e-02, Validation Loss: 5.910e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4163, Training Loss: 8.050e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4164, Training Loss: 8.047e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4165, Training Loss: 8.044e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4166, Training Loss: 8.041e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4167, Training Loss: 8.037e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4168, Training Loss: 8.034e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4169, Training Loss: 8.031e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4170, Training Loss: 8.028e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4171, Training Loss: 8.025e-02, Validation Loss: 5.910e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4172, Training Loss: 8.022e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4173, Training Loss: 8.019e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4174, Training Loss: 8.016e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4175, Training Loss: 8.013e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4176, Training Loss: 8.010e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4177, Training Loss: 8.007e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4178, Training Loss: 8.004e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4179, Training Loss: 8.001e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4180, Training Loss: 7.998e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4181, Training Loss: 7.994e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4182, Training Loss: 7.991e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4183, Training Loss: 7.988e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4184, Training Loss: 7.986e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4185, Training Loss: 7.982e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4186, Training Loss: 7.979e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4187, Training Loss: 7.976e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4188, Training Loss: 7.973e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4189, Training Loss: 7.970e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4190, Training Loss: 7.967e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4191, Training Loss: 7.964e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4192, Training Loss: 7.961e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4193, Training Loss: 7.958e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4194, Training Loss: 7.955e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4195, Training Loss: 7.952e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4196, Training Loss: 7.949e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4197, Training Loss: 7.946e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4198, Training Loss: 7.943e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4199, Training Loss: 7.939e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4200, Training Loss: 7.937e-02, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4201, Training Loss: 7.934e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4202, Training Loss: 7.931e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4203, Training Loss: 7.927e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4204, Training Loss: 7.925e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4205, Training Loss: 7.922e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4206, Training Loss: 7.918e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4207, Training Loss: 7.915e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4208, Training Loss: 7.913e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4209, Training Loss: 7.909e-02, Validation Loss: 5.910e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4210, Training Loss: 7.906e-02, Validation Loss: 5.910e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 4211, Training Loss: 7.904e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4212, Training Loss: 7.901e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4213, Training Loss: 7.897e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4214, Training Loss: 7.894e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4215, Training Loss: 7.891e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4216, Training Loss: 7.889e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4217, Training Loss: 7.885e-02, Validation Loss: 5.910e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4218, Training Loss: 7.882e-02, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4219, Training Loss: 7.880e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4220, Training Loss: 7.876e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4221, Training Loss: 7.873e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4222, Training Loss: 7.871e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4223, Training Loss: 7.867e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4224, Training Loss: 7.865e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4225, Training Loss: 7.861e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4226, Training Loss: 7.858e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4227, Training Loss: 7.855e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4228, Training Loss: 7.853e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4229, Training Loss: 7.849e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4230, Training Loss: 7.847e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4231, Training Loss: 7.844e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4232, Training Loss: 7.840e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4233, Training Loss: 7.838e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4234, Training Loss: 7.835e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4235, Training Loss: 7.831e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4236, Training Loss: 7.829e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4237, Training Loss: 7.826e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4238, Training Loss: 7.823e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4239, Training Loss: 7.820e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4240, Training Loss: 7.817e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4241, Training Loss: 7.814e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4242, Training Loss: 7.811e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4243, Training Loss: 7.808e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4244, Training Loss: 7.805e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4245, Training Loss: 7.802e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4246, Training Loss: 7.799e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4247, Training Loss: 7.796e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4248, Training Loss: 7.793e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4249, Training Loss: 7.790e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4250, Training Loss: 7.787e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4251, Training Loss: 7.784e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4252, Training Loss: 7.782e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4253, Training Loss: 7.778e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4254, Training Loss: 7.775e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4255, Training Loss: 7.773e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4256, Training Loss: 7.770e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4257, Training Loss: 7.767e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4258, Training Loss: 7.764e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4259, Training Loss: 7.761e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4260, Training Loss: 7.758e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4261, Training Loss: 7.755e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4262, Training Loss: 7.752e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4263, Training Loss: 7.749e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4264, Training Loss: 7.746e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4265, Training Loss: 7.744e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4266, Training Loss: 7.741e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4267, Training Loss: 7.737e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4268, Training Loss: 7.735e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4269, Training Loss: 7.732e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4270, Training Loss: 7.729e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4271, Training Loss: 7.726e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4272, Training Loss: 7.723e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4273, Training Loss: 7.720e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4274, Training Loss: 7.717e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4275, Training Loss: 7.714e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4276, Training Loss: 7.712e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4277, Training Loss: 7.708e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4278, Training Loss: 7.706e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4279, Training Loss: 7.703e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4280, Training Loss: 7.700e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4281, Training Loss: 7.697e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4282, Training Loss: 7.694e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4283, Training Loss: 7.691e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4284, Training Loss: 7.688e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4285, Training Loss: 7.686e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4286, Training Loss: 7.682e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4287, Training Loss: 7.680e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4288, Training Loss: 7.677e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4289, Training Loss: 7.674e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4290, Training Loss: 7.671e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4291, Training Loss: 7.668e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4292, Training Loss: 7.665e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4293, Training Loss: 7.662e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4294, Training Loss: 7.660e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4295, Training Loss: 7.657e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4296, Training Loss: 7.654e-02, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4297, Training Loss: 7.651e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4298, Training Loss: 7.648e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4299, Training Loss: 7.645e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4300, Training Loss: 7.642e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4301, Training Loss: 7.640e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4302, Training Loss: 7.637e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4303, Training Loss: 7.634e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4304, Training Loss: 7.631e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4305, Training Loss: 7.628e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4306, Training Loss: 7.625e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4307, Training Loss: 7.622e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4308, Training Loss: 7.620e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4309, Training Loss: 7.617e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4310, Training Loss: 7.614e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4311, Training Loss: 7.611e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4312, Training Loss: 7.608e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4313, Training Loss: 7.605e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4314, Training Loss: 7.603e-02, Validation Loss: 5.911e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 4315, Training Loss: 7.600e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4316, Training Loss: 7.597e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4317, Training Loss: 7.594e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4318, Training Loss: 7.591e-02, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4319, Training Loss: 7.589e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4320, Training Loss: 7.585e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4321, Training Loss: 7.583e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4322, Training Loss: 7.580e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4323, Training Loss: 7.577e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4324, Training Loss: 7.574e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4325, Training Loss: 7.571e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4326, Training Loss: 7.569e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4327, Training Loss: 7.566e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4328, Training Loss: 7.563e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4329, Training Loss: 7.560e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4330, Training Loss: 7.558e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4331, Training Loss: 7.555e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4332, Training Loss: 7.552e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4333, Training Loss: 7.549e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4334, Training Loss: 7.547e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4335, Training Loss: 7.543e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4336, Training Loss: 7.541e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4337, Training Loss: 7.538e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4338, Training Loss: 7.535e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4339, Training Loss: 7.532e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4340, Training Loss: 7.529e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4341, Training Loss: 7.527e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4342, Training Loss: 7.524e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4343, Training Loss: 7.521e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4344, Training Loss: 7.519e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4345, Training Loss: 7.515e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4346, Training Loss: 7.513e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4347, Training Loss: 7.510e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4348, Training Loss: 7.507e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4349, Training Loss: 7.505e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4350, Training Loss: 7.502e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4351, Training Loss: 7.499e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4352, Training Loss: 7.496e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4353, Training Loss: 7.493e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4354, Training Loss: 7.491e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4355, Training Loss: 7.488e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4356, Training Loss: 7.485e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4357, Training Loss: 7.482e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4358, Training Loss: 7.480e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4359, Training Loss: 7.477e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4360, Training Loss: 7.474e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4361, Training Loss: 7.471e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4362, Training Loss: 7.469e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4363, Training Loss: 7.466e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4364, Training Loss: 7.463e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4365, Training Loss: 7.460e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4366, Training Loss: 7.458e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4367, Training Loss: 7.455e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4368, Training Loss: 7.452e-02, Validation Loss: 5.911e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4369, Training Loss: 7.449e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4370, Training Loss: 7.446e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4371, Training Loss: 7.444e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4372, Training Loss: 7.441e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4373, Training Loss: 7.438e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4374, Training Loss: 7.436e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4375, Training Loss: 7.433e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4376, Training Loss: 7.430e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4377, Training Loss: 7.428e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4378, Training Loss: 7.425e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4379, Training Loss: 7.422e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4380, Training Loss: 7.419e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4381, Training Loss: 7.416e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4382, Training Loss: 7.414e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4383, Training Loss: 7.411e-02, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4384, Training Loss: 7.408e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4385, Training Loss: 7.406e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4386, Training Loss: 7.403e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4387, Training Loss: 7.400e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4388, Training Loss: 7.397e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4389, Training Loss: 7.395e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4390, Training Loss: 7.392e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4391, Training Loss: 7.389e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4392, Training Loss: 7.387e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4393, Training Loss: 7.384e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4394, Training Loss: 7.381e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4395, Training Loss: 7.378e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4396, Training Loss: 7.376e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4397, Training Loss: 7.373e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4398, Training Loss: 7.371e-02, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4399, Training Loss: 7.368e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4400, Training Loss: 7.365e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4401, Training Loss: 7.362e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4402, Training Loss: 7.360e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4403, Training Loss: 7.357e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4404, Training Loss: 7.354e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4405, Training Loss: 7.351e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4406, Training Loss: 7.349e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4407, Training Loss: 7.346e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4408, Training Loss: 7.344e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4409, Training Loss: 7.341e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4410, Training Loss: 7.338e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4411, Training Loss: 7.336e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4412, Training Loss: 7.333e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4413, Training Loss: 7.330e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4414, Training Loss: 7.328e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4415, Training Loss: 7.325e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4416, Training Loss: 7.322e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4417, Training Loss: 7.320e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4418, Training Loss: 7.317e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4419, Training Loss: 7.314e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4420, Training Loss: 7.312e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4421, Training Loss: 7.309e-02, Validation Loss: 5.912e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4422, Training Loss: 7.306e-02, Validation Loss: 5.912e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 4423, Training Loss: 7.303e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4424, Training Loss: 7.301e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4425, Training Loss: 7.298e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4426, Training Loss: 7.295e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4427, Training Loss: 7.293e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4428, Training Loss: 7.290e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4429, Training Loss: 7.288e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4430, Training Loss: 7.285e-02, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4431, Training Loss: 7.282e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4432, Training Loss: 7.280e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4433, Training Loss: 7.277e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4434, Training Loss: 7.274e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4435, Training Loss: 7.272e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4436, Training Loss: 7.269e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4437, Training Loss: 7.266e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4438, Training Loss: 7.264e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4439, Training Loss: 7.261e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4440, Training Loss: 7.259e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4441, Training Loss: 7.256e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4442, Training Loss: 7.253e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4443, Training Loss: 7.251e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4444, Training Loss: 7.248e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4445, Training Loss: 7.245e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4446, Training Loss: 7.243e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4447, Training Loss: 7.240e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4448, Training Loss: 7.237e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4449, Training Loss: 7.235e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4450, Training Loss: 7.232e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4451, Training Loss: 7.230e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4452, Training Loss: 7.227e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4453, Training Loss: 7.224e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4454, Training Loss: 7.222e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4455, Training Loss: 7.219e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4456, Training Loss: 7.216e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4457, Training Loss: 7.214e-02, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4458, Training Loss: 7.211e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4459, Training Loss: 7.209e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4460, Training Loss: 7.206e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4461, Training Loss: 7.204e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4462, Training Loss: 7.201e-02, Validation Loss: 5.913e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4463, Training Loss: 7.198e-02, Validation Loss: 5.913e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 4464, Training Loss: 7.196e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4465, Training Loss: 7.193e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4466, Training Loss: 7.190e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4467, Training Loss: 7.188e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4468, Training Loss: 7.185e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4469, Training Loss: 7.183e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4470, Training Loss: 7.180e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4471, Training Loss: 7.178e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4472, Training Loss: 7.175e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4473, Training Loss: 7.172e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4474, Training Loss: 7.170e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4475, Training Loss: 7.167e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4476, Training Loss: 7.164e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4477, Training Loss: 7.162e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4478, Training Loss: 7.160e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4479, Training Loss: 7.157e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4480, Training Loss: 7.154e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4481, Training Loss: 7.152e-02, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4482, Training Loss: 7.149e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4483, Training Loss: 7.147e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4484, Training Loss: 7.144e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4485, Training Loss: 7.141e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4486, Training Loss: 7.139e-02, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4487, Training Loss: 7.137e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4488, Training Loss: 7.134e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4489, Training Loss: 7.131e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4490, Training Loss: 7.129e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4491, Training Loss: 7.126e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4492, Training Loss: 7.123e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4493, Training Loss: 7.121e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4494, Training Loss: 7.119e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4495, Training Loss: 7.116e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4496, Training Loss: 7.113e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4497, Training Loss: 7.111e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4498, Training Loss: 7.108e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4499, Training Loss: 7.106e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4500, Training Loss: 7.103e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4501, Training Loss: 7.101e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4502, Training Loss: 7.098e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4503, Training Loss: 7.096e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4504, Training Loss: 7.093e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4505, Training Loss: 7.091e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4506, Training Loss: 7.088e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4507, Training Loss: 7.085e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4508, Training Loss: 7.083e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4509, Training Loss: 7.080e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4510, Training Loss: 7.078e-02, Validation Loss: 5.915e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4511, Training Loss: 7.075e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4512, Training Loss: 7.073e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4513, Training Loss: 7.070e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4514, Training Loss: 7.068e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4515, Training Loss: 7.065e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4516, Training Loss: 7.062e-02, Validation Loss: 5.915e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4517, Training Loss: 7.060e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4518, Training Loss: 7.058e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4519, Training Loss: 7.055e-02, Validation Loss: 5.914e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4520, Training Loss: 7.052e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4521, Training Loss: 7.050e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4522, Training Loss: 7.048e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4523, Training Loss: 7.045e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4524, Training Loss: 7.042e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4525, Training Loss: 7.040e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4526, Training Loss: 7.038e-02, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4527, Training Loss: 7.035e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4528, Training Loss: 7.032e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4529, Training Loss: 7.030e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4530, Training Loss: 7.028e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4531, Training Loss: 7.025e-02, Validation Loss: 5.915e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4532, Training Loss: 7.022e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4533, Training Loss: 7.020e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4534, Training Loss: 7.017e-02, Validation Loss: 5.915e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4535, Training Loss: 7.015e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4536, Training Loss: 7.012e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4537, Training Loss: 7.010e-02, Validation Loss: 5.915e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4538, Training Loss: 7.007e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4539, Training Loss: 7.005e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4540, Training Loss: 7.002e-02, Validation Loss: 5.916e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4541, Training Loss: 7.000e-02, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4542, Training Loss: 6.998e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4543, Training Loss: 6.995e-02, Validation Loss: 5.915e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4544, Training Loss: 6.992e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4545, Training Loss: 6.990e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4546, Training Loss: 6.987e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4547, Training Loss: 6.985e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4548, Training Loss: 6.983e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4549, Training Loss: 6.980e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4550, Training Loss: 6.978e-02, Validation Loss: 5.916e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4551, Training Loss: 6.975e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4552, Training Loss: 6.973e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4553, Training Loss: 6.970e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4554, Training Loss: 6.968e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4555, Training Loss: 6.966e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4556, Training Loss: 6.963e-02, Validation Loss: 5.916e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4557, Training Loss: 6.960e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4558, Training Loss: 6.958e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4559, Training Loss: 6.955e-02, Validation Loss: 5.916e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4560, Training Loss: 6.953e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4561, Training Loss: 6.951e-02, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4562, Training Loss: 6.948e-02, Validation Loss: 5.916e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4563, Training Loss: 6.946e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4564, Training Loss: 6.943e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4565, Training Loss: 6.941e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4566, Training Loss: 6.938e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4567, Training Loss: 6.936e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4568, Training Loss: 6.934e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4569, Training Loss: 6.931e-02, Validation Loss: 5.916e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4570, Training Loss: 6.929e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4571, Training Loss: 6.926e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4572, Training Loss: 6.923e-02, Validation Loss: 5.916e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4573, Training Loss: 6.921e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4574, Training Loss: 6.919e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4575, Training Loss: 6.916e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4576, Training Loss: 6.914e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4577, Training Loss: 6.911e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4578, Training Loss: 6.909e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4579, Training Loss: 6.907e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4580, Training Loss: 6.904e-02, Validation Loss: 5.917e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4581, Training Loss: 6.902e-02, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4582, Training Loss: 6.899e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4583, Training Loss: 6.897e-02, Validation Loss: 5.917e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4584, Training Loss: 6.894e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4585, Training Loss: 6.892e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4586, Training Loss: 6.889e-02, Validation Loss: 5.916e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4587, Training Loss: 6.887e-02, Validation Loss: 5.916e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 4588, Training Loss: 6.885e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4589, Training Loss: 6.882e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4590, Training Loss: 6.880e-02, Validation Loss: 5.916e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4591, Training Loss: 6.877e-02, Validation Loss: 5.916e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 4592, Training Loss: 6.875e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4593, Training Loss: 6.873e-02, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4594, Training Loss: 6.870e-02, Validation Loss: 5.917e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4595, Training Loss: 6.868e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4596, Training Loss: 6.865e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4597, Training Loss: 6.863e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4598, Training Loss: 6.860e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4599, Training Loss: 6.858e-02, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4600, Training Loss: 6.856e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4601, Training Loss: 6.853e-02, Validation Loss: 5.917e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4602, Training Loss: 6.851e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4603, Training Loss: 6.849e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4604, Training Loss: 6.846e-02, Validation Loss: 5.917e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4605, Training Loss: 6.844e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4606, Training Loss: 6.841e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4607, Training Loss: 6.839e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4608, Training Loss: 6.836e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4609, Training Loss: 6.834e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4610, Training Loss: 6.832e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4611, Training Loss: 6.829e-02, Validation Loss: 5.917e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4612, Training Loss: 6.827e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4613, Training Loss: 6.825e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4614, Training Loss: 6.822e-02, Validation Loss: 5.918e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4615, Training Loss: 6.820e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4616, Training Loss: 6.817e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4617, Training Loss: 6.815e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4618, Training Loss: 6.812e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4619, Training Loss: 6.810e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4620, Training Loss: 6.808e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4621, Training Loss: 6.805e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4622, Training Loss: 6.803e-02, Validation Loss: 5.918e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4623, Training Loss: 6.801e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4624, Training Loss: 6.798e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4625, Training Loss: 6.796e-02, Validation Loss: 5.918e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4626, Training Loss: 6.793e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4627, Training Loss: 6.791e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4628, Training Loss: 6.789e-02, Validation Loss: 5.918e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4629, Training Loss: 6.786e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4630, Training Loss: 6.784e-02, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4631, Training Loss: 6.782e-02, Validation Loss: 5.918e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4632, Training Loss: 6.779e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4633, Training Loss: 6.777e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4634, Training Loss: 6.775e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4635, Training Loss: 6.772e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4636, Training Loss: 6.770e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4637, Training Loss: 6.767e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4638, Training Loss: 6.765e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4639, Training Loss: 6.763e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4640, Training Loss: 6.760e-02, Validation Loss: 5.918e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4641, Training Loss: 6.758e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4642, Training Loss: 6.756e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4643, Training Loss: 6.753e-02, Validation Loss: 5.919e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4644, Training Loss: 6.751e-02, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4645, Training Loss: 6.749e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4646, Training Loss: 6.746e-02, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4647, Training Loss: 6.744e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4648, Training Loss: 6.742e-02, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4649, Training Loss: 6.739e-02, Validation Loss: 5.919e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4650, Training Loss: 6.737e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4651, Training Loss: 6.735e-02, Validation Loss: 5.919e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4652, Training Loss: 6.732e-02, Validation Loss: 5.919e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4653, Training Loss: 6.730e-02, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4654, Training Loss: 6.727e-02, Validation Loss: 5.919e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4655, Training Loss: 6.725e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4656, Training Loss: 6.722e-02, Validation Loss: 5.919e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4657, Training Loss: 6.720e-02, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4658, Training Loss: 6.718e-02, Validation Loss: 5.919e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4659, Training Loss: 6.715e-02, Validation Loss: 5.919e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4660, Training Loss: 6.713e-02, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4661, Training Loss: 6.711e-02, Validation Loss: 5.919e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4662, Training Loss: 6.708e-02, Validation Loss: 5.920e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4663, Training Loss: 6.706e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4664, Training Loss: 6.703e-02, Validation Loss: 5.919e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4665, Training Loss: 6.701e-02, Validation Loss: 5.920e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4666, Training Loss: 6.698e-02, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4667, Training Loss: 6.696e-02, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4668, Training Loss: 6.693e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4669, Training Loss: 6.691e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4670, Training Loss: 6.689e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4671, Training Loss: 6.686e-02, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4672, Training Loss: 6.684e-02, Validation Loss: 5.921e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4673, Training Loss: 6.681e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4674, Training Loss: 6.679e-02, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4675, Training Loss: 6.677e-02, Validation Loss: 5.921e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4676, Training Loss: 6.674e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4677, Training Loss: 6.672e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4678, Training Loss: 6.669e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4679, Training Loss: 6.667e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4680, Training Loss: 6.665e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4681, Training Loss: 6.663e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4682, Training Loss: 6.660e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4683, Training Loss: 6.658e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4684, Training Loss: 6.655e-02, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4685, Training Loss: 6.653e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4686, Training Loss: 6.651e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4687, Training Loss: 6.649e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4688, Training Loss: 6.646e-02, Validation Loss: 5.921e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4689, Training Loss: 6.644e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4690, Training Loss: 6.642e-02, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4691, Training Loss: 6.639e-02, Validation Loss: 5.922e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4692, Training Loss: 6.637e-02, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4693, Training Loss: 6.635e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4694, Training Loss: 6.632e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4695, Training Loss: 6.630e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4696, Training Loss: 6.628e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4697, Training Loss: 6.625e-02, Validation Loss: 5.923e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4698, Training Loss: 6.623e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4699, Training Loss: 6.621e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4700, Training Loss: 6.619e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4701, Training Loss: 6.617e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4702, Training Loss: 6.614e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4703, Training Loss: 6.612e-02, Validation Loss: 5.923e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4704, Training Loss: 6.610e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4705, Training Loss: 6.607e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4706, Training Loss: 6.605e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4707, Training Loss: 6.603e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4708, Training Loss: 6.601e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4709, Training Loss: 6.598e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4710, Training Loss: 6.596e-02, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4711, Training Loss: 6.594e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4712, Training Loss: 6.592e-02, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4713, Training Loss: 6.589e-02, Validation Loss: 5.923e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4714, Training Loss: 6.587e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4715, Training Loss: 6.585e-02, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4716, Training Loss: 6.582e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4717, Training Loss: 6.580e-02, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4718, Training Loss: 6.578e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4719, Training Loss: 6.576e-02, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4720, Training Loss: 6.573e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4721, Training Loss: 6.571e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4722, Training Loss: 6.569e-02, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4723, Training Loss: 6.567e-02, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4724, Training Loss: 6.564e-02, Validation Loss: 5.924e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4725, Training Loss: 6.562e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4726, Training Loss: 6.560e-02, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4727, Training Loss: 6.557e-02, Validation Loss: 5.924e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4728, Training Loss: 6.555e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4729, Training Loss: 6.553e-02, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4730, Training Loss: 6.551e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4731, Training Loss: 6.548e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4732, Training Loss: 6.546e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4733, Training Loss: 6.544e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4734, Training Loss: 6.542e-02, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4735, Training Loss: 6.539e-02, Validation Loss: 5.924e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4736, Training Loss: 6.537e-02, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4737, Training Loss: 6.535e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4738, Training Loss: 6.533e-02, Validation Loss: 5.924e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4739, Training Loss: 6.531e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4740, Training Loss: 6.528e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4741, Training Loss: 6.526e-02, Validation Loss: 5.924e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4742, Training Loss: 6.524e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4743, Training Loss: 6.522e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4744, Training Loss: 6.519e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4745, Training Loss: 6.517e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4746, Training Loss: 6.515e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4747, Training Loss: 6.513e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4748, Training Loss: 6.511e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4749, Training Loss: 6.508e-02, Validation Loss: 5.925e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4750, Training Loss: 6.506e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4751, Training Loss: 6.504e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4752, Training Loss: 6.501e-02, Validation Loss: 5.925e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4753, Training Loss: 6.499e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4754, Training Loss: 6.497e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4755, Training Loss: 6.495e-02, Validation Loss: 5.925e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4756, Training Loss: 6.493e-02, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4757, Training Loss: 6.491e-02, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4758, Training Loss: 6.488e-02, Validation Loss: 5.925e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4759, Training Loss: 6.486e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4760, Training Loss: 6.484e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4761, Training Loss: 6.481e-02, Validation Loss: 5.925e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4762, Training Loss: 6.480e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4763, Training Loss: 6.477e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4764, Training Loss: 6.475e-02, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4765, Training Loss: 6.473e-02, Validation Loss: 5.925e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4766, Training Loss: 6.471e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4767, Training Loss: 6.468e-02, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4768, Training Loss: 6.466e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4769, Training Loss: 6.464e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4770, Training Loss: 6.462e-02, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4771, Training Loss: 6.460e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4772, Training Loss: 6.458e-02, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4773, Training Loss: 6.455e-02, Validation Loss: 5.926e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4774, Training Loss: 6.453e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4775, Training Loss: 6.451e-02, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4776, Training Loss: 6.449e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4777, Training Loss: 6.446e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4778, Training Loss: 6.444e-02, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4779, Training Loss: 6.442e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4780, Training Loss: 6.440e-02, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4781, Training Loss: 6.438e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4782, Training Loss: 6.436e-02, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4783, Training Loss: 6.433e-02, Validation Loss: 5.926e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4784, Training Loss: 6.431e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4785, Training Loss: 6.429e-02, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4786, Training Loss: 6.427e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4787, Training Loss: 6.425e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4788, Training Loss: 6.423e-02, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4789, Training Loss: 6.420e-02, Validation Loss: 5.927e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4790, Training Loss: 6.418e-02, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4791, Training Loss: 6.416e-02, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4792, Training Loss: 6.413e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4793, Training Loss: 6.412e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4794, Training Loss: 6.409e-02, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4795, Training Loss: 6.407e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4796, Training Loss: 6.405e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4797, Training Loss: 6.403e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4798, Training Loss: 6.401e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4799, Training Loss: 6.399e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4800, Training Loss: 6.396e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4801, Training Loss: 6.394e-02, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4802, Training Loss: 6.392e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4803, Training Loss: 6.390e-02, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4804, Training Loss: 6.388e-02, Validation Loss: 5.927e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4805, Training Loss: 6.386e-02, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4806, Training Loss: 6.383e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4807, Training Loss: 6.381e-02, Validation Loss: 5.927e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4808, Training Loss: 6.379e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4809, Training Loss: 6.377e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4810, Training Loss: 6.375e-02, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4811, Training Loss: 6.372e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4812, Training Loss: 6.370e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4813, Training Loss: 6.368e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4814, Training Loss: 6.366e-02, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4815, Training Loss: 6.364e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4816, Training Loss: 6.362e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4817, Training Loss: 6.360e-02, Validation Loss: 5.928e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4818, Training Loss: 6.357e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4819, Training Loss: 6.356e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4820, Training Loss: 6.353e-02, Validation Loss: 5.928e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4821, Training Loss: 6.351e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4822, Training Loss: 6.349e-02, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4823, Training Loss: 6.347e-02, Validation Loss: 5.928e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4824, Training Loss: 6.345e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4825, Training Loss: 6.343e-02, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4826, Training Loss: 6.340e-02, Validation Loss: 5.928e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4827, Training Loss: 6.338e-02, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4828, Training Loss: 6.336e-02, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4829, Training Loss: 6.334e-02, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4830, Training Loss: 6.332e-02, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4831, Training Loss: 6.330e-02, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4832, Training Loss: 6.328e-02, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4833, Training Loss: 6.325e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4834, Training Loss: 6.323e-02, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4835, Training Loss: 6.321e-02, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4836, Training Loss: 6.319e-02, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4837, Training Loss: 6.317e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4838, Training Loss: 6.315e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4839, Training Loss: 6.313e-02, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4840, Training Loss: 6.311e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4841, Training Loss: 6.308e-02, Validation Loss: 5.929e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4842, Training Loss: 6.306e-02, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4843, Training Loss: 6.304e-02, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4844, Training Loss: 6.302e-02, Validation Loss: 5.929e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4845, Training Loss: 6.300e-02, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4846, Training Loss: 6.298e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4847, Training Loss: 6.296e-02, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4848, Training Loss: 6.294e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4849, Training Loss: 6.292e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4850, Training Loss: 6.289e-02, Validation Loss: 5.929e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4851, Training Loss: 6.287e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4852, Training Loss: 6.285e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4853, Training Loss: 6.283e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4854, Training Loss: 6.281e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4855, Training Loss: 6.279e-02, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4856, Training Loss: 6.277e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4857, Training Loss: 6.275e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4858, Training Loss: 6.273e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4859, Training Loss: 6.270e-02, Validation Loss: 5.930e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4860, Training Loss: 6.268e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4861, Training Loss: 6.266e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4862, Training Loss: 6.264e-02, Validation Loss: 5.930e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4863, Training Loss: 6.262e-02, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4864, Training Loss: 6.260e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4865, Training Loss: 6.258e-02, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4866, Training Loss: 6.256e-02, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4867, Training Loss: 6.254e-02, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4868, Training Loss: 6.252e-02, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4869, Training Loss: 6.250e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4870, Training Loss: 6.247e-02, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4871, Training Loss: 6.245e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4872, Training Loss: 6.243e-02, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4873, Training Loss: 6.241e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4874, Training Loss: 6.239e-02, Validation Loss: 5.930e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4875, Training Loss: 6.237e-02, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4876, Training Loss: 6.235e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4877, Training Loss: 6.233e-02, Validation Loss: 5.931e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4878, Training Loss: 6.231e-02, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4879, Training Loss: 6.229e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4880, Training Loss: 6.227e-02, Validation Loss: 5.931e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4881, Training Loss: 6.225e-02, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4882, Training Loss: 6.223e-02, Validation Loss: 5.930e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4883, Training Loss: 6.220e-02, Validation Loss: 5.931e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4884, Training Loss: 6.218e-02, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4885, Training Loss: 6.216e-02, Validation Loss: 5.931e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4886, Training Loss: 6.214e-02, Validation Loss: 5.931e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4887, Training Loss: 6.212e-02, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4888, Training Loss: 6.210e-02, Validation Loss: 5.931e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4889, Training Loss: 6.208e-02, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4890, Training Loss: 6.206e-02, Validation Loss: 5.931e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4891, Training Loss: 6.204e-02, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4892, Training Loss: 6.202e-02, Validation Loss: 5.931e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4893, Training Loss: 6.200e-02, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4894, Training Loss: 6.198e-02, Validation Loss: 5.931e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4895, Training Loss: 6.196e-02, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4896, Training Loss: 6.194e-02, Validation Loss: 5.931e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4897, Training Loss: 6.191e-02, Validation Loss: 5.932e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4898, Training Loss: 6.190e-02, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4899, Training Loss: 6.188e-02, Validation Loss: 5.931e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4900, Training Loss: 6.185e-02, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4901, Training Loss: 6.183e-02, Validation Loss: 5.931e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4902, Training Loss: 6.181e-02, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4903, Training Loss: 6.179e-02, Validation Loss: 5.931e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4904, Training Loss: 6.177e-02, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4905, Training Loss: 6.175e-02, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4906, Training Loss: 6.173e-02, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4907, Training Loss: 6.171e-02, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4908, Training Loss: 6.169e-02, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4909, Training Loss: 6.167e-02, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4910, Training Loss: 6.165e-02, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4911, Training Loss: 6.163e-02, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4912, Training Loss: 6.161e-02, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4913, Training Loss: 6.159e-02, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4914, Training Loss: 6.157e-02, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4915, Training Loss: 6.155e-02, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4916, Training Loss: 6.153e-02, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4917, Training Loss: 6.151e-02, Validation Loss: 5.933e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4918, Training Loss: 6.149e-02, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4919, Training Loss: 6.147e-02, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4920, Training Loss: 6.145e-02, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4921, Training Loss: 6.143e-02, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4922, Training Loss: 6.140e-02, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4923, Training Loss: 6.139e-02, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4924, Training Loss: 6.136e-02, Validation Loss: 5.933e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4925, Training Loss: 6.134e-02, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4926, Training Loss: 6.133e-02, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4927, Training Loss: 6.130e-02, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4928, Training Loss: 6.128e-02, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4929, Training Loss: 6.126e-02, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4930, Training Loss: 6.124e-02, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4931, Training Loss: 6.122e-02, Validation Loss: 5.933e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4932, Training Loss: 6.120e-02, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4933, Training Loss: 6.119e-02, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4934, Training Loss: 6.116e-02, Validation Loss: 5.933e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4935, Training Loss: 6.114e-02, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4936, Training Loss: 6.112e-02, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4937, Training Loss: 6.110e-02, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4938, Training Loss: 6.108e-02, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4939, Training Loss: 6.106e-02, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4940, Training Loss: 6.104e-02, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4941, Training Loss: 6.102e-02, Validation Loss: 5.933e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4942, Training Loss: 6.100e-02, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4943, Training Loss: 6.098e-02, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4944, Training Loss: 6.096e-02, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4945, Training Loss: 6.094e-02, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4946, Training Loss: 6.092e-02, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4947, Training Loss: 6.090e-02, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4948, Training Loss: 6.088e-02, Validation Loss: 5.934e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4949, Training Loss: 6.086e-02, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4950, Training Loss: 6.084e-02, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4951, Training Loss: 6.082e-02, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4952, Training Loss: 6.080e-02, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4953, Training Loss: 6.078e-02, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4954, Training Loss: 6.076e-02, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4955, Training Loss: 6.074e-02, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4956, Training Loss: 6.072e-02, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4957, Training Loss: 6.070e-02, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4958, Training Loss: 6.068e-02, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4959, Training Loss: 6.066e-02, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4960, Training Loss: 6.064e-02, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4961, Training Loss: 6.062e-02, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4962, Training Loss: 6.060e-02, Validation Loss: 5.935e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4963, Training Loss: 6.058e-02, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4964, Training Loss: 6.056e-02, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4965, Training Loss: 6.054e-02, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4966, Training Loss: 6.052e-02, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4967, Training Loss: 6.050e-02, Validation Loss: 5.935e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4968, Training Loss: 6.048e-02, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4969, Training Loss: 6.047e-02, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4970, Training Loss: 6.044e-02, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4971, Training Loss: 6.042e-02, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4972, Training Loss: 6.041e-02, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4973, Training Loss: 6.038e-02, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4974, Training Loss: 6.036e-02, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4975, Training Loss: 6.035e-02, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4976, Training Loss: 6.033e-02, Validation Loss: 5.935e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4977, Training Loss: 6.030e-02, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4978, Training Loss: 6.029e-02, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4979, Training Loss: 6.027e-02, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4980, Training Loss: 6.025e-02, Validation Loss: 5.936e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4981, Training Loss: 6.023e-02, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4982, Training Loss: 6.021e-02, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4983, Training Loss: 6.019e-02, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4984, Training Loss: 6.017e-02, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4985, Training Loss: 6.015e-02, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4986, Training Loss: 6.013e-02, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4987, Training Loss: 6.011e-02, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4988, Training Loss: 6.009e-02, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4989, Training Loss: 6.007e-02, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4990, Training Loss: 6.005e-02, Validation Loss: 5.936e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4991, Training Loss: 6.003e-02, Validation Loss: 5.936e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 4992, Training Loss: 6.001e-02, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4993, Training Loss: 5.999e-02, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4994, Training Loss: 5.997e-02, Validation Loss: 5.936e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 4995, Training Loss: 5.995e-02, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4996, Training Loss: 5.993e-02, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4997, Training Loss: 5.991e-02, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 4998, Training Loss: 5.989e-02, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 4999, Training Loss: 5.988e-02, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5000, Training Loss: 5.986e-02, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5001, Training Loss: 5.983e-02, Validation Loss: 5.937e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5002, Training Loss: 5.982e-02, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5003, Training Loss: 5.980e-02, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5004, Training Loss: 5.978e-02, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5005, Training Loss: 5.976e-02, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5006, Training Loss: 5.974e-02, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5007, Training Loss: 5.972e-02, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5008, Training Loss: 5.970e-02, Validation Loss: 5.937e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5009, Training Loss: 5.968e-02, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5010, Training Loss: 5.966e-02, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5011, Training Loss: 5.964e-02, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5012, Training Loss: 5.962e-02, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5013, Training Loss: 5.960e-02, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5014, Training Loss: 5.958e-02, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5015, Training Loss: 5.956e-02, Validation Loss: 5.937e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5016, Training Loss: 5.955e-02, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5017, Training Loss: 5.953e-02, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5018, Training Loss: 5.951e-02, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5019, Training Loss: 5.949e-02, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5020, Training Loss: 5.947e-02, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5021, Training Loss: 5.945e-02, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5022, Training Loss: 5.943e-02, Validation Loss: 5.937e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5023, Training Loss: 5.941e-02, Validation Loss: 5.937e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 5024, Training Loss: 5.939e-02, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5025, Training Loss: 5.937e-02, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5026, Training Loss: 5.935e-02, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5027, Training Loss: 5.933e-02, Validation Loss: 5.938e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5028, Training Loss: 5.931e-02, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5029, Training Loss: 5.930e-02, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5030, Training Loss: 5.927e-02, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5031, Training Loss: 5.926e-02, Validation Loss: 5.938e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5032, Training Loss: 5.924e-02, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5033, Training Loss: 5.922e-02, Validation Loss: 5.938e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5034, Training Loss: 5.920e-02, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5035, Training Loss: 5.918e-02, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5036, Training Loss: 5.916e-02, Validation Loss: 5.938e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5037, Training Loss: 5.914e-02, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5038, Training Loss: 5.912e-02, Validation Loss: 5.938e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5039, Training Loss: 5.910e-02, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5040, Training Loss: 5.909e-02, Validation Loss: 5.938e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5041, Training Loss: 5.906e-02, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5042, Training Loss: 5.905e-02, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5043, Training Loss: 5.903e-02, Validation Loss: 5.938e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5044, Training Loss: 5.901e-02, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5045, Training Loss: 5.899e-02, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5046, Training Loss: 5.897e-02, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5047, Training Loss: 5.895e-02, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5048, Training Loss: 5.893e-02, Validation Loss: 5.939e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5049, Training Loss: 5.891e-02, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5050, Training Loss: 5.890e-02, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5051, Training Loss: 5.887e-02, Validation Loss: 5.939e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5052, Training Loss: 5.886e-02, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5053, Training Loss: 5.884e-02, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5054, Training Loss: 5.882e-02, Validation Loss: 5.939e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5055, Training Loss: 5.880e-02, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5056, Training Loss: 5.878e-02, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5057, Training Loss: 5.876e-02, Validation Loss: 5.939e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5058, Training Loss: 5.874e-02, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5059, Training Loss: 5.872e-02, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5060, Training Loss: 5.870e-02, Validation Loss: 5.939e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5061, Training Loss: 5.869e-02, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5062, Training Loss: 5.867e-02, Validation Loss: 5.940e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5063, Training Loss: 5.865e-02, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5064, Training Loss: 5.863e-02, Validation Loss: 5.940e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5065, Training Loss: 5.861e-02, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5066, Training Loss: 5.859e-02, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5067, Training Loss: 5.858e-02, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5068, Training Loss: 5.855e-02, Validation Loss: 5.940e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5069, Training Loss: 5.854e-02, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5070, Training Loss: 5.852e-02, Validation Loss: 5.940e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5071, Training Loss: 5.850e-02, Validation Loss: 5.940e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5072, Training Loss: 5.848e-02, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5073, Training Loss: 5.846e-02, Validation Loss: 5.940e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5074, Training Loss: 5.844e-02, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5075, Training Loss: 5.842e-02, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5076, Training Loss: 5.840e-02, Validation Loss: 5.940e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5077, Training Loss: 5.838e-02, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5078, Training Loss: 5.837e-02, Validation Loss: 5.940e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5079, Training Loss: 5.835e-02, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5080, Training Loss: 5.833e-02, Validation Loss: 5.940e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5081, Training Loss: 5.831e-02, Validation Loss: 5.941e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5082, Training Loss: 5.829e-02, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5083, Training Loss: 5.828e-02, Validation Loss: 5.940e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5084, Training Loss: 5.825e-02, Validation Loss: 5.941e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5085, Training Loss: 5.824e-02, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5086, Training Loss: 5.822e-02, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5087, Training Loss: 5.820e-02, Validation Loss: 5.941e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5088, Training Loss: 5.818e-02, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5089, Training Loss: 5.816e-02, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5090, Training Loss: 5.814e-02, Validation Loss: 5.941e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5091, Training Loss: 5.812e-02, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5092, Training Loss: 5.811e-02, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5093, Training Loss: 5.809e-02, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5094, Training Loss: 5.807e-02, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5095, Training Loss: 5.805e-02, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5096, Training Loss: 5.803e-02, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5097, Training Loss: 5.801e-02, Validation Loss: 5.941e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5098, Training Loss: 5.799e-02, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5099, Training Loss: 5.798e-02, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5100, Training Loss: 5.796e-02, Validation Loss: 5.942e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5101, Training Loss: 5.794e-02, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5102, Training Loss: 5.792e-02, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5103, Training Loss: 5.790e-02, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5104, Training Loss: 5.788e-02, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5105, Training Loss: 5.787e-02, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5106, Training Loss: 5.785e-02, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5107, Training Loss: 5.783e-02, Validation Loss: 5.942e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5108, Training Loss: 5.781e-02, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5109, Training Loss: 5.779e-02, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5110, Training Loss: 5.777e-02, Validation Loss: 5.942e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5111, Training Loss: 5.775e-02, Validation Loss: 5.942e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 5112, Training Loss: 5.774e-02, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5113, Training Loss: 5.772e-02, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5114, Training Loss: 5.770e-02, Validation Loss: 5.942e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5115, Training Loss: 5.768e-02, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5116, Training Loss: 5.766e-02, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5117, Training Loss: 5.764e-02, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5118, Training Loss: 5.763e-02, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5119, Training Loss: 5.761e-02, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5120, Training Loss: 5.759e-02, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5121, Training Loss: 5.757e-02, Validation Loss: 5.943e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5122, Training Loss: 5.755e-02, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5123, Training Loss: 5.754e-02, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5124, Training Loss: 5.752e-02, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5125, Training Loss: 5.750e-02, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5126, Training Loss: 5.748e-02, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5127, Training Loss: 5.746e-02, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5128, Training Loss: 5.744e-02, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5129, Training Loss: 5.743e-02, Validation Loss: 5.943e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5130, Training Loss: 5.741e-02, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5131, Training Loss: 5.739e-02, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5132, Training Loss: 5.737e-02, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5133, Training Loss: 5.735e-02, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5134, Training Loss: 5.733e-02, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5135, Training Loss: 5.732e-02, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5136, Training Loss: 5.730e-02, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5137, Training Loss: 5.728e-02, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5138, Training Loss: 5.726e-02, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5139, Training Loss: 5.724e-02, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5140, Training Loss: 5.723e-02, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5141, Training Loss: 5.721e-02, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5142, Training Loss: 5.719e-02, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5143, Training Loss: 5.717e-02, Validation Loss: 5.944e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5144, Training Loss: 5.715e-02, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5145, Training Loss: 5.714e-02, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5146, Training Loss: 5.712e-02, Validation Loss: 5.944e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5147, Training Loss: 5.710e-02, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5148, Training Loss: 5.708e-02, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5149, Training Loss: 5.706e-02, Validation Loss: 5.944e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5150, Training Loss: 5.705e-02, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5151, Training Loss: 5.703e-02, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5152, Training Loss: 5.701e-02, Validation Loss: 5.944e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5153, Training Loss: 5.699e-02, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5154, Training Loss: 5.697e-02, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5155, Training Loss: 5.695e-02, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5156, Training Loss: 5.694e-02, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5157, Training Loss: 5.692e-02, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5158, Training Loss: 5.690e-02, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5159, Training Loss: 5.688e-02, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5160, Training Loss: 5.686e-02, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5161, Training Loss: 5.685e-02, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5162, Training Loss: 5.683e-02, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5163, Training Loss: 5.681e-02, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5164, Training Loss: 5.679e-02, Validation Loss: 5.945e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5165, Training Loss: 5.678e-02, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5166, Training Loss: 5.676e-02, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5167, Training Loss: 5.674e-02, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5168, Training Loss: 5.672e-02, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5169, Training Loss: 5.670e-02, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5170, Training Loss: 5.669e-02, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5171, Training Loss: 5.667e-02, Validation Loss: 5.945e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5172, Training Loss: 5.665e-02, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5173, Training Loss: 5.664e-02, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5174, Training Loss: 5.661e-02, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5175, Training Loss: 5.660e-02, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5176, Training Loss: 5.658e-02, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5177, Training Loss: 5.656e-02, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5178, Training Loss: 5.654e-02, Validation Loss: 5.946e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5179, Training Loss: 5.653e-02, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5180, Training Loss: 5.651e-02, Validation Loss: 5.946e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5181, Training Loss: 5.649e-02, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5182, Training Loss: 5.647e-02, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5183, Training Loss: 5.646e-02, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5184, Training Loss: 5.644e-02, Validation Loss: 5.946e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5185, Training Loss: 5.642e-02, Validation Loss: 5.946e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 5186, Training Loss: 5.640e-02, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5187, Training Loss: 5.639e-02, Validation Loss: 5.946e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5188, Training Loss: 5.637e-02, Validation Loss: 5.946e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5189, Training Loss: 5.635e-02, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5190, Training Loss: 5.633e-02, Validation Loss: 5.946e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5191, Training Loss: 5.631e-02, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5192, Training Loss: 5.630e-02, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5193, Training Loss: 5.628e-02, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5194, Training Loss: 5.626e-02, Validation Loss: 5.946e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5195, Training Loss: 5.624e-02, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5196, Training Loss: 5.623e-02, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5197, Training Loss: 5.621e-02, Validation Loss: 5.946e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5198, Training Loss: 5.619e-02, Validation Loss: 5.947e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5199, Training Loss: 5.617e-02, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5200, Training Loss: 5.616e-02, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5201, Training Loss: 5.614e-02, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5202, Training Loss: 5.612e-02, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5203, Training Loss: 5.610e-02, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5204, Training Loss: 5.609e-02, Validation Loss: 5.948e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5205, Training Loss: 5.607e-02, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5206, Training Loss: 5.605e-02, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5207, Training Loss: 5.603e-02, Validation Loss: 5.947e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5208, Training Loss: 5.602e-02, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5209, Training Loss: 5.600e-02, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5210, Training Loss: 5.598e-02, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5211, Training Loss: 5.596e-02, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5212, Training Loss: 5.595e-02, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5213, Training Loss: 5.593e-02, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5214, Training Loss: 5.591e-02, Validation Loss: 5.947e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5215, Training Loss: 5.589e-02, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5216, Training Loss: 5.588e-02, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5217, Training Loss: 5.586e-02, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5218, Training Loss: 5.584e-02, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5219, Training Loss: 5.582e-02, Validation Loss: 5.948e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5220, Training Loss: 5.581e-02, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5221, Training Loss: 5.579e-02, Validation Loss: 5.948e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5222, Training Loss: 5.577e-02, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5223, Training Loss: 5.575e-02, Validation Loss: 5.948e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5224, Training Loss: 5.574e-02, Validation Loss: 5.948e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5225, Training Loss: 5.572e-02, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5226, Training Loss: 5.570e-02, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5227, Training Loss: 5.569e-02, Validation Loss: 5.949e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5228, Training Loss: 5.567e-02, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5229, Training Loss: 5.565e-02, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5230, Training Loss: 5.563e-02, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5231, Training Loss: 5.562e-02, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5232, Training Loss: 5.560e-02, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5233, Training Loss: 5.558e-02, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5234, Training Loss: 5.556e-02, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5235, Training Loss: 5.555e-02, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5236, Training Loss: 5.553e-02, Validation Loss: 5.948e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5237, Training Loss: 5.551e-02, Validation Loss: 5.949e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5238, Training Loss: 5.549e-02, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5239, Training Loss: 5.548e-02, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5240, Training Loss: 5.546e-02, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5241, Training Loss: 5.544e-02, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5242, Training Loss: 5.543e-02, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5243, Training Loss: 5.541e-02, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5244, Training Loss: 5.539e-02, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5245, Training Loss: 5.538e-02, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5246, Training Loss: 5.536e-02, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5247, Training Loss: 5.534e-02, Validation Loss: 5.950e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5248, Training Loss: 5.532e-02, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5249, Training Loss: 5.531e-02, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5250, Training Loss: 5.529e-02, Validation Loss: 5.950e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5251, Training Loss: 5.527e-02, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5252, Training Loss: 5.526e-02, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5253, Training Loss: 5.524e-02, Validation Loss: 5.950e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5254, Training Loss: 5.522e-02, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5255, Training Loss: 5.520e-02, Validation Loss: 5.950e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5256, Training Loss: 5.519e-02, Validation Loss: 5.950e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5257, Training Loss: 5.517e-02, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5258, Training Loss: 5.515e-02, Validation Loss: 5.950e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5259, Training Loss: 5.514e-02, Validation Loss: 5.950e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5260, Training Loss: 5.512e-02, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5261, Training Loss: 5.510e-02, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5262, Training Loss: 5.508e-02, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5263, Training Loss: 5.507e-02, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5264, Training Loss: 5.505e-02, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5265, Training Loss: 5.503e-02, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5266, Training Loss: 5.502e-02, Validation Loss: 5.950e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5267, Training Loss: 5.500e-02, Validation Loss: 5.951e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5268, Training Loss: 5.498e-02, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5269, Training Loss: 5.497e-02, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5270, Training Loss: 5.495e-02, Validation Loss: 5.951e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5271, Training Loss: 5.493e-02, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5272, Training Loss: 5.492e-02, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5273, Training Loss: 5.490e-02, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5274, Training Loss: 5.488e-02, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5275, Training Loss: 5.486e-02, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5276, Training Loss: 5.485e-02, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5277, Training Loss: 5.483e-02, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5278, Training Loss: 5.481e-02, Validation Loss: 5.952e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5279, Training Loss: 5.480e-02, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5280, Training Loss: 5.478e-02, Validation Loss: 5.952e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5281, Training Loss: 5.476e-02, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5282, Training Loss: 5.474e-02, Validation Loss: 5.952e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5283, Training Loss: 5.473e-02, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5284, Training Loss: 5.471e-02, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5285, Training Loss: 5.470e-02, Validation Loss: 5.952e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5286, Training Loss: 5.468e-02, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5287, Training Loss: 5.466e-02, Validation Loss: 5.952e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5288, Training Loss: 5.464e-02, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5289, Training Loss: 5.463e-02, Validation Loss: 5.952e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5290, Training Loss: 5.461e-02, Validation Loss: 5.952e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5291, Training Loss: 5.459e-02, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5292, Training Loss: 5.458e-02, Validation Loss: 5.952e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5293, Training Loss: 5.456e-02, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5294, Training Loss: 5.454e-02, Validation Loss: 5.952e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5295, Training Loss: 5.453e-02, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5296, Training Loss: 5.451e-02, Validation Loss: 5.952e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5297, Training Loss: 5.449e-02, Validation Loss: 5.952e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5298, Training Loss: 5.448e-02, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5299, Training Loss: 5.446e-02, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5300, Training Loss: 5.444e-02, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5301, Training Loss: 5.443e-02, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5302, Training Loss: 5.441e-02, Validation Loss: 5.952e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5303, Training Loss: 5.439e-02, Validation Loss: 5.953e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5304, Training Loss: 5.438e-02, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5305, Training Loss: 5.436e-02, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5306, Training Loss: 5.434e-02, Validation Loss: 5.953e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5307, Training Loss: 5.433e-02, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5308, Training Loss: 5.431e-02, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5309, Training Loss: 5.429e-02, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5310, Training Loss: 5.428e-02, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5311, Training Loss: 5.426e-02, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5312, Training Loss: 5.424e-02, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5313, Training Loss: 5.423e-02, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5314, Training Loss: 5.421e-02, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5315, Training Loss: 5.420e-02, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5316, Training Loss: 5.418e-02, Validation Loss: 5.954e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5317, Training Loss: 5.416e-02, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5318, Training Loss: 5.415e-02, Validation Loss: 5.954e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5319, Training Loss: 5.413e-02, Validation Loss: 5.954e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5320, Training Loss: 5.411e-02, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5321, Training Loss: 5.410e-02, Validation Loss: 5.954e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5322, Training Loss: 5.408e-02, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5323, Training Loss: 5.406e-02, Validation Loss: 5.954e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5324, Training Loss: 5.404e-02, Validation Loss: 5.954e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5325, Training Loss: 5.403e-02, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5326, Training Loss: 5.401e-02, Validation Loss: 5.954e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5327, Training Loss: 5.399e-02, Validation Loss: 5.954e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5328, Training Loss: 5.398e-02, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5329, Training Loss: 5.396e-02, Validation Loss: 5.954e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5330, Training Loss: 5.395e-02, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5331, Training Loss: 5.393e-02, Validation Loss: 5.954e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5332, Training Loss: 5.391e-02, Validation Loss: 5.955e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5333, Training Loss: 5.390e-02, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5334, Training Loss: 5.388e-02, Validation Loss: 5.955e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5335, Training Loss: 5.386e-02, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5336, Training Loss: 5.385e-02, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5337, Training Loss: 5.383e-02, Validation Loss: 5.955e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5338, Training Loss: 5.381e-02, Validation Loss: 5.955e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5339, Training Loss: 5.380e-02, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5340, Training Loss: 5.378e-02, Validation Loss: 5.955e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5341, Training Loss: 5.377e-02, Validation Loss: 5.955e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5342, Training Loss: 5.375e-02, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5343, Training Loss: 5.373e-02, Validation Loss: 5.955e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5344, Training Loss: 5.372e-02, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5345, Training Loss: 5.370e-02, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5346, Training Loss: 5.368e-02, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5347, Training Loss: 5.367e-02, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5348, Training Loss: 5.365e-02, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5349, Training Loss: 5.363e-02, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5350, Training Loss: 5.362e-02, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5351, Training Loss: 5.360e-02, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5352, Training Loss: 5.359e-02, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5353, Training Loss: 5.357e-02, Validation Loss: 5.956e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5354, Training Loss: 5.355e-02, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5355, Training Loss: 5.354e-02, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5356, Training Loss: 5.352e-02, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5357, Training Loss: 5.350e-02, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5358, Training Loss: 5.349e-02, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5359, Training Loss: 5.347e-02, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5360, Training Loss: 5.346e-02, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5361, Training Loss: 5.344e-02, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5362, Training Loss: 5.342e-02, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5363, Training Loss: 5.341e-02, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5364, Training Loss: 5.339e-02, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5365, Training Loss: 5.337e-02, Validation Loss: 5.957e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5366, Training Loss: 5.336e-02, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5367, Training Loss: 5.334e-02, Validation Loss: 5.957e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5368, Training Loss: 5.333e-02, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5369, Training Loss: 5.331e-02, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5370, Training Loss: 5.329e-02, Validation Loss: 5.957e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5371, Training Loss: 5.328e-02, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5372, Training Loss: 5.326e-02, Validation Loss: 5.957e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5373, Training Loss: 5.324e-02, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5374, Training Loss: 5.323e-02, Validation Loss: 5.957e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5375, Training Loss: 5.321e-02, Validation Loss: 5.957e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5376, Training Loss: 5.320e-02, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5377, Training Loss: 5.318e-02, Validation Loss: 5.957e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5378, Training Loss: 5.316e-02, Validation Loss: 5.957e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5379, Training Loss: 5.315e-02, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5380, Training Loss: 5.313e-02, Validation Loss: 5.958e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5381, Training Loss: 5.312e-02, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5382, Training Loss: 5.310e-02, Validation Loss: 5.958e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5383, Training Loss: 5.308e-02, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5384, Training Loss: 5.307e-02, Validation Loss: 5.958e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5385, Training Loss: 5.305e-02, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5386, Training Loss: 5.304e-02, Validation Loss: 5.958e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5387, Training Loss: 5.302e-02, Validation Loss: 5.959e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5388, Training Loss: 5.300e-02, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5389, Training Loss: 5.299e-02, Validation Loss: 5.958e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5390, Training Loss: 5.297e-02, Validation Loss: 5.958e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5391, Training Loss: 5.296e-02, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5392, Training Loss: 5.294e-02, Validation Loss: 5.958e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5393, Training Loss: 5.292e-02, Validation Loss: 5.959e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5394, Training Loss: 5.291e-02, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5395, Training Loss: 5.289e-02, Validation Loss: 5.958e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5396, Training Loss: 5.288e-02, Validation Loss: 5.959e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5397, Training Loss: 5.286e-02, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5398, Training Loss: 5.285e-02, Validation Loss: 5.959e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5399, Training Loss: 5.283e-02, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5400, Training Loss: 5.281e-02, Validation Loss: 5.958e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5401, Training Loss: 5.280e-02, Validation Loss: 5.959e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5402, Training Loss: 5.278e-02, Validation Loss: 5.959e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5403, Training Loss: 5.276e-02, Validation Loss: 5.958e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5404, Training Loss: 5.275e-02, Validation Loss: 5.959e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5405, Training Loss: 5.273e-02, Validation Loss: 5.960e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5406, Training Loss: 5.272e-02, Validation Loss: 5.958e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5407, Training Loss: 5.270e-02, Validation Loss: 5.959e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5408, Training Loss: 5.269e-02, Validation Loss: 5.960e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5409, Training Loss: 5.267e-02, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5410, Training Loss: 5.265e-02, Validation Loss: 5.960e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5411, Training Loss: 5.264e-02, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5412, Training Loss: 5.262e-02, Validation Loss: 5.960e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5413, Training Loss: 5.261e-02, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5414, Training Loss: 5.259e-02, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5415, Training Loss: 5.258e-02, Validation Loss: 5.960e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5416, Training Loss: 5.256e-02, Validation Loss: 5.960e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5417, Training Loss: 5.254e-02, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5418, Training Loss: 5.253e-02, Validation Loss: 5.960e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5419, Training Loss: 5.251e-02, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5420, Training Loss: 5.250e-02, Validation Loss: 5.960e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5421, Training Loss: 5.248e-02, Validation Loss: 5.960e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5422, Training Loss: 5.246e-02, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5423, Training Loss: 5.245e-02, Validation Loss: 5.960e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5424, Training Loss: 5.243e-02, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5425, Training Loss: 5.242e-02, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5426, Training Loss: 5.240e-02, Validation Loss: 5.960e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5427, Training Loss: 5.239e-02, Validation Loss: 5.961e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5428, Training Loss: 5.237e-02, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5429, Training Loss: 5.235e-02, Validation Loss: 5.961e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5430, Training Loss: 5.234e-02, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5431, Training Loss: 5.232e-02, Validation Loss: 5.961e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5432, Training Loss: 5.231e-02, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5433, Training Loss: 5.229e-02, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5434, Training Loss: 5.228e-02, Validation Loss: 5.961e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5435, Training Loss: 5.226e-02, Validation Loss: 5.961e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5436, Training Loss: 5.224e-02, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5437, Training Loss: 5.223e-02, Validation Loss: 5.961e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5438, Training Loss: 5.221e-02, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5439, Training Loss: 5.220e-02, Validation Loss: 5.961e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5440, Training Loss: 5.218e-02, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5441, Training Loss: 5.217e-02, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5442, Training Loss: 5.215e-02, Validation Loss: 5.961e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5443, Training Loss: 5.214e-02, Validation Loss: 5.962e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5444, Training Loss: 5.212e-02, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5445, Training Loss: 5.211e-02, Validation Loss: 5.962e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5446, Training Loss: 5.209e-02, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5447, Training Loss: 5.207e-02, Validation Loss: 5.962e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5448, Training Loss: 5.206e-02, Validation Loss: 5.962e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5449, Training Loss: 5.204e-02, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5450, Training Loss: 5.203e-02, Validation Loss: 5.962e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5451, Training Loss: 5.201e-02, Validation Loss: 5.962e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5452, Training Loss: 5.200e-02, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5453, Training Loss: 5.198e-02, Validation Loss: 5.962e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5454, Training Loss: 5.196e-02, Validation Loss: 5.962e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5455, Training Loss: 5.195e-02, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5456, Training Loss: 5.193e-02, Validation Loss: 5.962e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5457, Training Loss: 5.192e-02, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5458, Training Loss: 5.190e-02, Validation Loss: 5.962e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5459, Training Loss: 5.189e-02, Validation Loss: 5.963e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5460, Training Loss: 5.187e-02, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5461, Training Loss: 5.186e-02, Validation Loss: 5.963e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5462, Training Loss: 5.184e-02, Validation Loss: 5.963e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5463, Training Loss: 5.183e-02, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5464, Training Loss: 5.181e-02, Validation Loss: 5.963e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5465, Training Loss: 5.179e-02, Validation Loss: 5.963e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5466, Training Loss: 5.178e-02, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5467, Training Loss: 5.176e-02, Validation Loss: 5.963e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5468, Training Loss: 5.175e-02, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5469, Training Loss: 5.173e-02, Validation Loss: 5.964e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5470, Training Loss: 5.172e-02, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5471, Training Loss: 5.170e-02, Validation Loss: 5.964e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5472, Training Loss: 5.169e-02, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5473, Training Loss: 5.167e-02, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5474, Training Loss: 5.166e-02, Validation Loss: 5.963e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5475, Training Loss: 5.164e-02, Validation Loss: 5.964e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5476, Training Loss: 5.163e-02, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5477, Training Loss: 5.161e-02, Validation Loss: 5.964e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5478, Training Loss: 5.159e-02, Validation Loss: 5.964e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5479, Training Loss: 5.158e-02, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5480, Training Loss: 5.156e-02, Validation Loss: 5.964e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5481, Training Loss: 5.155e-02, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5482, Training Loss: 5.153e-02, Validation Loss: 5.964e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5483, Training Loss: 5.152e-02, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5484, Training Loss: 5.150e-02, Validation Loss: 5.964e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5485, Training Loss: 5.149e-02, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5486, Training Loss: 5.147e-02, Validation Loss: 5.964e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5487, Training Loss: 5.146e-02, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5488, Training Loss: 5.144e-02, Validation Loss: 5.964e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5489, Training Loss: 5.142e-02, Validation Loss: 5.965e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5490, Training Loss: 5.141e-02, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5491, Training Loss: 5.140e-02, Validation Loss: 5.965e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5492, Training Loss: 5.138e-02, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5493, Training Loss: 5.136e-02, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5494, Training Loss: 5.135e-02, Validation Loss: 5.965e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5495, Training Loss: 5.133e-02, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5496, Training Loss: 5.132e-02, Validation Loss: 5.965e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5497, Training Loss: 5.130e-02, Validation Loss: 5.965e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5498, Training Loss: 5.129e-02, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5499, Training Loss: 5.127e-02, Validation Loss: 5.965e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5500, Training Loss: 5.126e-02, Validation Loss: 5.965e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5501, Training Loss: 5.124e-02, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5502, Training Loss: 5.123e-02, Validation Loss: 5.965e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5503, Training Loss: 5.121e-02, Validation Loss: 5.965e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5504, Training Loss: 5.120e-02, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5505, Training Loss: 5.118e-02, Validation Loss: 5.966e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5506, Training Loss: 5.117e-02, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5507, Training Loss: 5.115e-02, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5508, Training Loss: 5.114e-02, Validation Loss: 5.966e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5509, Training Loss: 5.112e-02, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5510, Training Loss: 5.111e-02, Validation Loss: 5.966e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5511, Training Loss: 5.109e-02, Validation Loss: 5.966e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5512, Training Loss: 5.108e-02, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5513, Training Loss: 5.106e-02, Validation Loss: 5.966e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5514, Training Loss: 5.105e-02, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5515, Training Loss: 5.103e-02, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5516, Training Loss: 5.102e-02, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5517, Training Loss: 5.100e-02, Validation Loss: 5.966e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5518, Training Loss: 5.099e-02, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5519, Training Loss: 5.097e-02, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5520, Training Loss: 5.095e-02, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5521, Training Loss: 5.094e-02, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5522, Training Loss: 5.093e-02, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5523, Training Loss: 5.091e-02, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5524, Training Loss: 5.090e-02, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5525, Training Loss: 5.088e-02, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5526, Training Loss: 5.087e-02, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5527, Training Loss: 5.085e-02, Validation Loss: 5.967e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5528, Training Loss: 5.084e-02, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5529, Training Loss: 5.082e-02, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5530, Training Loss: 5.080e-02, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5531, Training Loss: 5.079e-02, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5532, Training Loss: 5.078e-02, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5533, Training Loss: 5.076e-02, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5534, Training Loss: 5.074e-02, Validation Loss: 5.968e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5535, Training Loss: 5.073e-02, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5536, Training Loss: 5.072e-02, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5537, Training Loss: 5.070e-02, Validation Loss: 5.967e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5538, Training Loss: 5.069e-02, Validation Loss: 5.968e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 5539, Training Loss: 5.067e-02, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5540, Training Loss: 5.066e-02, Validation Loss: 5.968e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5541, Training Loss: 5.064e-02, Validation Loss: 5.968e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5542, Training Loss: 5.063e-02, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5543, Training Loss: 5.061e-02, Validation Loss: 5.968e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5544, Training Loss: 5.060e-02, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5545, Training Loss: 5.058e-02, Validation Loss: 5.968e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5546, Training Loss: 5.057e-02, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5547, Training Loss: 5.055e-02, Validation Loss: 5.968e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5548, Training Loss: 5.054e-02, Validation Loss: 5.969e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5549, Training Loss: 5.052e-02, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5550, Training Loss: 5.051e-02, Validation Loss: 5.968e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5551, Training Loss: 5.049e-02, Validation Loss: 5.969e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5552, Training Loss: 5.048e-02, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5553, Training Loss: 5.046e-02, Validation Loss: 5.968e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5554, Training Loss: 5.045e-02, Validation Loss: 5.969e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5555, Training Loss: 5.043e-02, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5556, Training Loss: 5.042e-02, Validation Loss: 5.969e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5557, Training Loss: 5.040e-02, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5558, Training Loss: 5.039e-02, Validation Loss: 5.969e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5559, Training Loss: 5.037e-02, Validation Loss: 5.969e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5560, Training Loss: 5.036e-02, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5561, Training Loss: 5.035e-02, Validation Loss: 5.969e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5562, Training Loss: 5.033e-02, Validation Loss: 5.969e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5563, Training Loss: 5.031e-02, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5564, Training Loss: 5.030e-02, Validation Loss: 5.969e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5565, Training Loss: 5.029e-02, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5566, Training Loss: 5.027e-02, Validation Loss: 5.970e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5567, Training Loss: 5.026e-02, Validation Loss: 5.970e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5568, Training Loss: 5.024e-02, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5569, Training Loss: 5.023e-02, Validation Loss: 5.970e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5570, Training Loss: 5.021e-02, Validation Loss: 5.970e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5571, Training Loss: 5.020e-02, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5572, Training Loss: 5.018e-02, Validation Loss: 5.970e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5573, Training Loss: 5.017e-02, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5574, Training Loss: 5.015e-02, Validation Loss: 5.970e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5575, Training Loss: 5.014e-02, Validation Loss: 5.970e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5576, Training Loss: 5.012e-02, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5577, Training Loss: 5.011e-02, Validation Loss: 5.970e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5578, Training Loss: 5.009e-02, Validation Loss: 5.970e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5579, Training Loss: 5.008e-02, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5580, Training Loss: 5.007e-02, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5581, Training Loss: 5.005e-02, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5582, Training Loss: 5.004e-02, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5583, Training Loss: 5.002e-02, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5584, Training Loss: 5.001e-02, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5585, Training Loss: 4.999e-02, Validation Loss: 5.971e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5586, Training Loss: 4.998e-02, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5587, Training Loss: 4.996e-02, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5588, Training Loss: 4.995e-02, Validation Loss: 5.971e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5589, Training Loss: 4.993e-02, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5590, Training Loss: 4.992e-02, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5591, Training Loss: 4.991e-02, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5592, Training Loss: 4.989e-02, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5593, Training Loss: 4.988e-02, Validation Loss: 5.972e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5594, Training Loss: 4.986e-02, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5595, Training Loss: 4.985e-02, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5596, Training Loss: 4.983e-02, Validation Loss: 5.972e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5597, Training Loss: 4.982e-02, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5598, Training Loss: 4.981e-02, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5599, Training Loss: 4.979e-02, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5600, Training Loss: 4.978e-02, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5601, Training Loss: 4.976e-02, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5602, Training Loss: 4.975e-02, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5603, Training Loss: 4.973e-02, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5604, Training Loss: 4.972e-02, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5605, Training Loss: 4.970e-02, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5606, Training Loss: 4.969e-02, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5607, Training Loss: 4.967e-02, Validation Loss: 5.973e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5608, Training Loss: 4.966e-02, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5609, Training Loss: 4.965e-02, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5610, Training Loss: 4.963e-02, Validation Loss: 5.973e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5611, Training Loss: 4.962e-02, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5612, Training Loss: 4.960e-02, Validation Loss: 5.973e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5613, Training Loss: 4.959e-02, Validation Loss: 5.973e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5614, Training Loss: 4.957e-02, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5615, Training Loss: 4.956e-02, Validation Loss: 5.973e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5616, Training Loss: 4.954e-02, Validation Loss: 5.973e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5617, Training Loss: 4.953e-02, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5618, Training Loss: 4.952e-02, Validation Loss: 5.973e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5619, Training Loss: 4.950e-02, Validation Loss: 5.973e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5620, Training Loss: 4.949e-02, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5621, Training Loss: 4.947e-02, Validation Loss: 5.973e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5622, Training Loss: 4.946e-02, Validation Loss: 5.974e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5623, Training Loss: 4.944e-02, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5624, Training Loss: 4.943e-02, Validation Loss: 5.974e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5625, Training Loss: 4.941e-02, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5626, Training Loss: 4.940e-02, Validation Loss: 5.973e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5627, Training Loss: 4.939e-02, Validation Loss: 5.974e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5628, Training Loss: 4.937e-02, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5629, Training Loss: 4.936e-02, Validation Loss: 5.974e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5630, Training Loss: 4.934e-02, Validation Loss: 5.974e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5631, Training Loss: 4.933e-02, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5632, Training Loss: 4.932e-02, Validation Loss: 5.974e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5633, Training Loss: 4.930e-02, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5634, Training Loss: 4.929e-02, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5635, Training Loss: 4.927e-02, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5636, Training Loss: 4.926e-02, Validation Loss: 5.974e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5637, Training Loss: 4.924e-02, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5638, Training Loss: 4.923e-02, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5639, Training Loss: 4.921e-02, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5640, Training Loss: 4.920e-02, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5641, Training Loss: 4.919e-02, Validation Loss: 5.975e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5642, Training Loss: 4.917e-02, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5643, Training Loss: 4.916e-02, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5644, Training Loss: 4.914e-02, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5645, Training Loss: 4.913e-02, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5646, Training Loss: 4.912e-02, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5647, Training Loss: 4.910e-02, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5648, Training Loss: 4.909e-02, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5649, Training Loss: 4.907e-02, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5650, Training Loss: 4.906e-02, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5651, Training Loss: 4.904e-02, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5652, Training Loss: 4.903e-02, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5653, Training Loss: 4.902e-02, Validation Loss: 5.976e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5654, Training Loss: 4.900e-02, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5655, Training Loss: 4.899e-02, Validation Loss: 5.976e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5656, Training Loss: 4.897e-02, Validation Loss: 5.976e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5657, Training Loss: 4.896e-02, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5658, Training Loss: 4.895e-02, Validation Loss: 5.976e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5659, Training Loss: 4.893e-02, Validation Loss: 5.976e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5660, Training Loss: 4.892e-02, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5661, Training Loss: 4.890e-02, Validation Loss: 5.976e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5662, Training Loss: 4.889e-02, Validation Loss: 5.976e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5663, Training Loss: 4.888e-02, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5664, Training Loss: 4.886e-02, Validation Loss: 5.976e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5665, Training Loss: 4.885e-02, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5666, Training Loss: 4.883e-02, Validation Loss: 5.976e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5667, Training Loss: 4.882e-02, Validation Loss: 5.977e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5668, Training Loss: 4.881e-02, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5669, Training Loss: 4.879e-02, Validation Loss: 5.977e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5670, Training Loss: 4.878e-02, Validation Loss: 5.977e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5671, Training Loss: 4.876e-02, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5672, Training Loss: 4.875e-02, Validation Loss: 5.977e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5673, Training Loss: 4.874e-02, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5674, Training Loss: 4.872e-02, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5675, Training Loss: 4.871e-02, Validation Loss: 5.977e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5676, Training Loss: 4.869e-02, Validation Loss: 5.978e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5677, Training Loss: 4.868e-02, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5678, Training Loss: 4.867e-02, Validation Loss: 5.977e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5679, Training Loss: 4.865e-02, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5680, Training Loss: 4.864e-02, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5681, Training Loss: 4.862e-02, Validation Loss: 5.978e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5682, Training Loss: 4.861e-02, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5683, Training Loss: 4.860e-02, Validation Loss: 5.978e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5684, Training Loss: 4.858e-02, Validation Loss: 5.978e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5685, Training Loss: 4.857e-02, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5686, Training Loss: 4.856e-02, Validation Loss: 5.978e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5687, Training Loss: 4.854e-02, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5688, Training Loss: 4.853e-02, Validation Loss: 5.978e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5689, Training Loss: 4.851e-02, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5690, Training Loss: 4.850e-02, Validation Loss: 5.978e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5691, Training Loss: 4.848e-02, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5692, Training Loss: 4.847e-02, Validation Loss: 5.978e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5693, Training Loss: 4.846e-02, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5694, Training Loss: 4.844e-02, Validation Loss: 5.978e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5695, Training Loss: 4.843e-02, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5696, Training Loss: 4.842e-02, Validation Loss: 5.978e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5697, Training Loss: 4.840e-02, Validation Loss: 5.979e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5698, Training Loss: 4.839e-02, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5699, Training Loss: 4.838e-02, Validation Loss: 5.979e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5700, Training Loss: 4.836e-02, Validation Loss: 5.979e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5701, Training Loss: 4.835e-02, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5702, Training Loss: 4.833e-02, Validation Loss: 5.979e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5703, Training Loss: 4.832e-02, Validation Loss: 5.979e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5704, Training Loss: 4.831e-02, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5705, Training Loss: 4.829e-02, Validation Loss: 5.979e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5706, Training Loss: 4.828e-02, Validation Loss: 5.980e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5707, Training Loss: 4.826e-02, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5708, Training Loss: 4.825e-02, Validation Loss: 5.979e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5709, Training Loss: 4.824e-02, Validation Loss: 5.980e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5710, Training Loss: 4.822e-02, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5711, Training Loss: 4.821e-02, Validation Loss: 5.980e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5712, Training Loss: 4.819e-02, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5713, Training Loss: 4.818e-02, Validation Loss: 5.980e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5714, Training Loss: 4.817e-02, Validation Loss: 5.980e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5715, Training Loss: 4.815e-02, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5716, Training Loss: 4.814e-02, Validation Loss: 5.980e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5717, Training Loss: 4.813e-02, Validation Loss: 5.980e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5718, Training Loss: 4.811e-02, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5719, Training Loss: 4.810e-02, Validation Loss: 5.980e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5720, Training Loss: 4.809e-02, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5721, Training Loss: 4.807e-02, Validation Loss: 5.981e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5722, Training Loss: 4.806e-02, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5723, Training Loss: 4.805e-02, Validation Loss: 5.980e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5724, Training Loss: 4.803e-02, Validation Loss: 5.980e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5725, Training Loss: 4.802e-02, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5726, Training Loss: 4.800e-02, Validation Loss: 5.981e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5727, Training Loss: 4.799e-02, Validation Loss: 5.981e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5728, Training Loss: 4.798e-02, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5729, Training Loss: 4.796e-02, Validation Loss: 5.981e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5730, Training Loss: 4.795e-02, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5731, Training Loss: 4.794e-02, Validation Loss: 5.981e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5732, Training Loss: 4.792e-02, Validation Loss: 5.981e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5733, Training Loss: 4.791e-02, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5734, Training Loss: 4.790e-02, Validation Loss: 5.981e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5735, Training Loss: 4.788e-02, Validation Loss: 5.982e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5736, Training Loss: 4.787e-02, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5737, Training Loss: 4.785e-02, Validation Loss: 5.982e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5738, Training Loss: 4.784e-02, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5739, Training Loss: 4.783e-02, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5740, Training Loss: 4.781e-02, Validation Loss: 5.981e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5741, Training Loss: 4.780e-02, Validation Loss: 5.982e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5742, Training Loss: 4.779e-02, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5743, Training Loss: 4.777e-02, Validation Loss: 5.982e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5744, Training Loss: 4.776e-02, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5745, Training Loss: 4.775e-02, Validation Loss: 5.982e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5746, Training Loss: 4.773e-02, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5747, Training Loss: 4.772e-02, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5748, Training Loss: 4.771e-02, Validation Loss: 5.982e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5749, Training Loss: 4.769e-02, Validation Loss: 5.983e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5750, Training Loss: 4.768e-02, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5751, Training Loss: 4.766e-02, Validation Loss: 5.982e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5752, Training Loss: 4.765e-02, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5753, Training Loss: 4.764e-02, Validation Loss: 5.983e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5754, Training Loss: 4.762e-02, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5755, Training Loss: 4.761e-02, Validation Loss: 5.983e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5756, Training Loss: 4.760e-02, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5757, Training Loss: 4.758e-02, Validation Loss: 5.983e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5758, Training Loss: 4.757e-02, Validation Loss: 5.983e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5759, Training Loss: 4.756e-02, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5760, Training Loss: 4.754e-02, Validation Loss: 5.983e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5761, Training Loss: 4.753e-02, Validation Loss: 5.983e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5762, Training Loss: 4.752e-02, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5763, Training Loss: 4.750e-02, Validation Loss: 5.983e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5764, Training Loss: 4.749e-02, Validation Loss: 5.984e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5765, Training Loss: 4.748e-02, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5766, Training Loss: 4.746e-02, Validation Loss: 5.983e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5767, Training Loss: 4.745e-02, Validation Loss: 5.984e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5768, Training Loss: 4.744e-02, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5769, Training Loss: 4.742e-02, Validation Loss: 5.984e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5770, Training Loss: 4.741e-02, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5771, Training Loss: 4.740e-02, Validation Loss: 5.984e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5772, Training Loss: 4.738e-02, Validation Loss: 5.984e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5773, Training Loss: 4.737e-02, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5774, Training Loss: 4.736e-02, Validation Loss: 5.984e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5775, Training Loss: 4.734e-02, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5776, Training Loss: 4.733e-02, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5777, Training Loss: 4.732e-02, Validation Loss: 5.984e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5778, Training Loss: 4.730e-02, Validation Loss: 5.984e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5779, Training Loss: 4.729e-02, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5780, Training Loss: 4.728e-02, Validation Loss: 5.984e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5781, Training Loss: 4.726e-02, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5782, Training Loss: 4.725e-02, Validation Loss: 5.985e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5783, Training Loss: 4.724e-02, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5784, Training Loss: 4.722e-02, Validation Loss: 5.985e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5785, Training Loss: 4.721e-02, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5786, Training Loss: 4.720e-02, Validation Loss: 5.985e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5787, Training Loss: 4.718e-02, Validation Loss: 5.985e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5788, Training Loss: 4.717e-02, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5789, Training Loss: 4.716e-02, Validation Loss: 5.985e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5790, Training Loss: 4.714e-02, Validation Loss: 5.985e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5791, Training Loss: 4.713e-02, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5792, Training Loss: 4.712e-02, Validation Loss: 5.985e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5793, Training Loss: 4.710e-02, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5794, Training Loss: 4.709e-02, Validation Loss: 5.985e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5795, Training Loss: 4.708e-02, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5796, Training Loss: 4.707e-02, Validation Loss: 5.986e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5797, Training Loss: 4.705e-02, Validation Loss: 5.986e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5798, Training Loss: 4.704e-02, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5799, Training Loss: 4.703e-02, Validation Loss: 5.985e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5800, Training Loss: 4.701e-02, Validation Loss: 5.986e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5801, Training Loss: 4.700e-02, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5802, Training Loss: 4.699e-02, Validation Loss: 5.986e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5803, Training Loss: 4.697e-02, Validation Loss: 5.986e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5804, Training Loss: 4.696e-02, Validation Loss: 5.986e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5805, Training Loss: 4.695e-02, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5806, Training Loss: 4.693e-02, Validation Loss: 5.986e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5807, Training Loss: 4.692e-02, Validation Loss: 5.986e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5808, Training Loss: 4.691e-02, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5809, Training Loss: 4.689e-02, Validation Loss: 5.987e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5810, Training Loss: 4.688e-02, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5811, Training Loss: 4.687e-02, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5812, Training Loss: 4.685e-02, Validation Loss: 5.986e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5813, Training Loss: 4.684e-02, Validation Loss: 5.987e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5814, Training Loss: 4.683e-02, Validation Loss: 5.986e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5815, Training Loss: 4.681e-02, Validation Loss: 5.987e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5816, Training Loss: 4.680e-02, Validation Loss: 5.987e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5817, Training Loss: 4.679e-02, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5818, Training Loss: 4.678e-02, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5819, Training Loss: 4.676e-02, Validation Loss: 5.987e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5820, Training Loss: 4.675e-02, Validation Loss: 5.986e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5821, Training Loss: 4.674e-02, Validation Loss: 5.987e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5822, Training Loss: 4.672e-02, Validation Loss: 5.988e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5823, Training Loss: 4.671e-02, Validation Loss: 5.986e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5824, Training Loss: 4.670e-02, Validation Loss: 5.988e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5825, Training Loss: 4.668e-02, Validation Loss: 5.988e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5826, Training Loss: 4.667e-02, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5827, Training Loss: 4.666e-02, Validation Loss: 5.988e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5828, Training Loss: 4.664e-02, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5829, Training Loss: 4.663e-02, Validation Loss: 5.988e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5830, Training Loss: 4.662e-02, Validation Loss: 5.988e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5831, Training Loss: 4.661e-02, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5832, Training Loss: 4.659e-02, Validation Loss: 5.988e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5833, Training Loss: 4.658e-02, Validation Loss: 5.988e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5834, Training Loss: 4.657e-02, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5835, Training Loss: 4.655e-02, Validation Loss: 5.988e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5836, Training Loss: 4.654e-02, Validation Loss: 5.988e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5837, Training Loss: 4.653e-02, Validation Loss: 5.988e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5838, Training Loss: 4.652e-02, Validation Loss: 5.988e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5839, Training Loss: 4.650e-02, Validation Loss: 5.989e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5840, Training Loss: 4.649e-02, Validation Loss: 5.988e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5841, Training Loss: 4.648e-02, Validation Loss: 5.989e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5842, Training Loss: 4.646e-02, Validation Loss: 5.989e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5843, Training Loss: 4.645e-02, Validation Loss: 5.988e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5844, Training Loss: 4.644e-02, Validation Loss: 5.989e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5845, Training Loss: 4.642e-02, Validation Loss: 5.988e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5846, Training Loss: 4.641e-02, Validation Loss: 5.989e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5847, Training Loss: 4.640e-02, Validation Loss: 5.989e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5848, Training Loss: 4.639e-02, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5849, Training Loss: 4.637e-02, Validation Loss: 5.989e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5850, Training Loss: 4.636e-02, Validation Loss: 5.989e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5851, Training Loss: 4.635e-02, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5852, Training Loss: 4.634e-02, Validation Loss: 5.990e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5853, Training Loss: 4.632e-02, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5854, Training Loss: 4.631e-02, Validation Loss: 5.990e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5855, Training Loss: 4.630e-02, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5856, Training Loss: 4.628e-02, Validation Loss: 5.990e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5857, Training Loss: 4.627e-02, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5858, Training Loss: 4.626e-02, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5859, Training Loss: 4.625e-02, Validation Loss: 5.990e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5860, Training Loss: 4.623e-02, Validation Loss: 5.990e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5861, Training Loss: 4.622e-02, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5862, Training Loss: 4.621e-02, Validation Loss: 5.990e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5863, Training Loss: 4.619e-02, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5864, Training Loss: 4.618e-02, Validation Loss: 5.991e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5865, Training Loss: 4.617e-02, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5866, Training Loss: 4.616e-02, Validation Loss: 5.990e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5867, Training Loss: 4.614e-02, Validation Loss: 5.991e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5868, Training Loss: 4.613e-02, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5869, Training Loss: 4.612e-02, Validation Loss: 5.991e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5870, Training Loss: 4.610e-02, Validation Loss: 5.991e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5871, Training Loss: 4.609e-02, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5872, Training Loss: 4.608e-02, Validation Loss: 5.991e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5873, Training Loss: 4.606e-02, Validation Loss: 5.991e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5874, Training Loss: 4.605e-02, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5875, Training Loss: 4.604e-02, Validation Loss: 5.991e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5876, Training Loss: 4.603e-02, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5877, Training Loss: 4.602e-02, Validation Loss: 5.991e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5878, Training Loss: 4.600e-02, Validation Loss: 5.992e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5879, Training Loss: 4.599e-02, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5880, Training Loss: 4.598e-02, Validation Loss: 5.992e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5881, Training Loss: 4.596e-02, Validation Loss: 5.992e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5882, Training Loss: 4.595e-02, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5883, Training Loss: 4.594e-02, Validation Loss: 5.992e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5884, Training Loss: 4.593e-02, Validation Loss: 5.992e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5885, Training Loss: 4.591e-02, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5886, Training Loss: 4.590e-02, Validation Loss: 5.992e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5887, Training Loss: 4.589e-02, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5888, Training Loss: 4.588e-02, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5889, Training Loss: 4.586e-02, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5890, Training Loss: 4.585e-02, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5891, Training Loss: 4.584e-02, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5892, Training Loss: 4.582e-02, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5893, Training Loss: 4.581e-02, Validation Loss: 5.992e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5894, Training Loss: 4.580e-02, Validation Loss: 5.993e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5895, Training Loss: 4.579e-02, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5896, Training Loss: 4.577e-02, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5897, Training Loss: 4.576e-02, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5898, Training Loss: 4.575e-02, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5899, Training Loss: 4.574e-02, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5900, Training Loss: 4.572e-02, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5901, Training Loss: 4.571e-02, Validation Loss: 5.993e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5902, Training Loss: 4.570e-02, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5903, Training Loss: 4.569e-02, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5904, Training Loss: 4.567e-02, Validation Loss: 5.993e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5905, Training Loss: 4.566e-02, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5906, Training Loss: 4.565e-02, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5907, Training Loss: 4.564e-02, Validation Loss: 5.994e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5908, Training Loss: 4.562e-02, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5909, Training Loss: 4.561e-02, Validation Loss: 5.994e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5910, Training Loss: 4.560e-02, Validation Loss: 5.993e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5911, Training Loss: 4.559e-02, Validation Loss: 5.994e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5912, Training Loss: 4.557e-02, Validation Loss: 5.993e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5913, Training Loss: 4.556e-02, Validation Loss: 5.994e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5914, Training Loss: 4.555e-02, Validation Loss: 5.993e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5915, Training Loss: 4.554e-02, Validation Loss: 5.994e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5916, Training Loss: 4.552e-02, Validation Loss: 5.994e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5917, Training Loss: 4.551e-02, Validation Loss: 5.993e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5918, Training Loss: 4.550e-02, Validation Loss: 5.994e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5919, Training Loss: 4.548e-02, Validation Loss: 5.994e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5920, Training Loss: 4.547e-02, Validation Loss: 5.993e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5921, Training Loss: 4.546e-02, Validation Loss: 5.995e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5922, Training Loss: 4.545e-02, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5923, Training Loss: 4.543e-02, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5924, Training Loss: 4.542e-02, Validation Loss: 5.995e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5925, Training Loss: 4.541e-02, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5926, Training Loss: 4.540e-02, Validation Loss: 5.995e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5927, Training Loss: 4.539e-02, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5928, Training Loss: 4.537e-02, Validation Loss: 5.995e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5929, Training Loss: 4.536e-02, Validation Loss: 5.995e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5930, Training Loss: 4.535e-02, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5931, Training Loss: 4.534e-02, Validation Loss: 5.995e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5932, Training Loss: 4.532e-02, Validation Loss: 5.996e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5933, Training Loss: 4.531e-02, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5934, Training Loss: 4.530e-02, Validation Loss: 5.995e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5935, Training Loss: 4.529e-02, Validation Loss: 5.996e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5936, Training Loss: 4.527e-02, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5937, Training Loss: 4.526e-02, Validation Loss: 5.996e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5938, Training Loss: 4.525e-02, Validation Loss: 5.996e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5939, Training Loss: 4.524e-02, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5940, Training Loss: 4.522e-02, Validation Loss: 5.995e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5941, Training Loss: 4.521e-02, Validation Loss: 5.996e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5942, Training Loss: 4.520e-02, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5943, Training Loss: 4.519e-02, Validation Loss: 5.996e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5944, Training Loss: 4.517e-02, Validation Loss: 5.996e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5945, Training Loss: 4.516e-02, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5946, Training Loss: 4.515e-02, Validation Loss: 5.996e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5947, Training Loss: 4.514e-02, Validation Loss: 5.997e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5948, Training Loss: 4.512e-02, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5949, Training Loss: 4.511e-02, Validation Loss: 5.997e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5950, Training Loss: 4.510e-02, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5951, Training Loss: 4.509e-02, Validation Loss: 5.997e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5952, Training Loss: 4.508e-02, Validation Loss: 5.996e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5953, Training Loss: 4.506e-02, Validation Loss: 5.997e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5954, Training Loss: 4.505e-02, Validation Loss: 5.997e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5955, Training Loss: 4.504e-02, Validation Loss: 5.996e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5956, Training Loss: 4.503e-02, Validation Loss: 5.997e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5957, Training Loss: 4.501e-02, Validation Loss: 5.997e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5958, Training Loss: 4.500e-02, Validation Loss: 5.996e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5959, Training Loss: 4.499e-02, Validation Loss: 5.997e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5960, Training Loss: 4.498e-02, Validation Loss: 5.998e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5961, Training Loss: 4.497e-02, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5962, Training Loss: 4.495e-02, Validation Loss: 5.998e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5963, Training Loss: 4.494e-02, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5964, Training Loss: 4.493e-02, Validation Loss: 5.998e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5965, Training Loss: 4.492e-02, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5966, Training Loss: 4.491e-02, Validation Loss: 5.998e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5967, Training Loss: 4.489e-02, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5968, Training Loss: 4.488e-02, Validation Loss: 5.998e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5969, Training Loss: 4.487e-02, Validation Loss: 5.998e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5970, Training Loss: 4.486e-02, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5971, Training Loss: 4.484e-02, Validation Loss: 5.998e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5972, Training Loss: 4.483e-02, Validation Loss: 5.998e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5973, Training Loss: 4.482e-02, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5974, Training Loss: 4.481e-02, Validation Loss: 5.998e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5975, Training Loss: 4.479e-02, Validation Loss: 5.999e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5976, Training Loss: 4.478e-02, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5977, Training Loss: 4.477e-02, Validation Loss: 5.999e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5978, Training Loss: 4.476e-02, Validation Loss: 5.999e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5979, Training Loss: 4.475e-02, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5980, Training Loss: 4.474e-02, Validation Loss: 5.999e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5981, Training Loss: 4.472e-02, Validation Loss: 5.999e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5982, Training Loss: 4.471e-02, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5983, Training Loss: 4.470e-02, Validation Loss: 5.999e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5984, Training Loss: 4.469e-02, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5985, Training Loss: 4.467e-02, Validation Loss: 6.000e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5986, Training Loss: 4.466e-02, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5987, Training Loss: 4.465e-02, Validation Loss: 5.999e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5988, Training Loss: 4.464e-02, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5989, Training Loss: 4.463e-02, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5990, Training Loss: 4.461e-02, Validation Loss: 6.000e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5991, Training Loss: 4.460e-02, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5992, Training Loss: 4.459e-02, Validation Loss: 5.999e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5993, Training Loss: 4.458e-02, Validation Loss: 6.000e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5994, Training Loss: 4.456e-02, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5995, Training Loss: 4.455e-02, Validation Loss: 6.000e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5996, Training Loss: 4.454e-02, Validation Loss: 6.000e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 5997, Training Loss: 4.453e-02, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 5998, Training Loss: 4.452e-02, Validation Loss: 6.000e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 5999, Training Loss: 4.450e-02, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6000, Training Loss: 4.449e-02, Validation Loss: 6.000e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6001, Training Loss: 4.448e-02, Validation Loss: 6.000e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6002, Training Loss: 4.447e-02, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6003, Training Loss: 4.446e-02, Validation Loss: 6.000e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6004, Training Loss: 4.444e-02, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6005, Training Loss: 4.443e-02, Validation Loss: 6.000e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6006, Training Loss: 4.442e-02, Validation Loss: 6.001e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6007, Training Loss: 4.441e-02, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6008, Training Loss: 4.440e-02, Validation Loss: 6.001e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6009, Training Loss: 4.438e-02, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6010, Training Loss: 4.437e-02, Validation Loss: 6.001e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6011, Training Loss: 4.436e-02, Validation Loss: 6.001e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6012, Training Loss: 4.435e-02, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6013, Training Loss: 4.434e-02, Validation Loss: 6.001e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6014, Training Loss: 4.432e-02, Validation Loss: 6.001e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6015, Training Loss: 4.431e-02, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6016, Training Loss: 4.430e-02, Validation Loss: 6.001e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6017, Training Loss: 4.429e-02, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6018, Training Loss: 4.428e-02, Validation Loss: 6.002e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6019, Training Loss: 4.426e-02, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6020, Training Loss: 4.425e-02, Validation Loss: 6.002e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6021, Training Loss: 4.424e-02, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6022, Training Loss: 4.423e-02, Validation Loss: 6.002e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6023, Training Loss: 4.422e-02, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6024, Training Loss: 4.421e-02, Validation Loss: 6.002e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6025, Training Loss: 4.419e-02, Validation Loss: 6.002e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6026, Training Loss: 4.418e-02, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6027, Training Loss: 4.417e-02, Validation Loss: 6.002e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6028, Training Loss: 4.416e-02, Validation Loss: 6.002e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6029, Training Loss: 4.415e-02, Validation Loss: 6.002e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6030, Training Loss: 4.413e-02, Validation Loss: 6.002e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6031, Training Loss: 4.412e-02, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6032, Training Loss: 4.411e-02, Validation Loss: 6.002e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6033, Training Loss: 4.410e-02, Validation Loss: 6.003e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6034, Training Loss: 4.409e-02, Validation Loss: 6.002e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6035, Training Loss: 4.407e-02, Validation Loss: 6.003e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6036, Training Loss: 4.406e-02, Validation Loss: 6.002e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6037, Training Loss: 4.405e-02, Validation Loss: 6.002e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6038, Training Loss: 4.404e-02, Validation Loss: 6.003e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6039, Training Loss: 4.403e-02, Validation Loss: 6.002e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6040, Training Loss: 4.402e-02, Validation Loss: 6.003e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6041, Training Loss: 4.400e-02, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6042, Training Loss: 4.399e-02, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6043, Training Loss: 4.398e-02, Validation Loss: 6.003e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6044, Training Loss: 4.397e-02, Validation Loss: 6.002e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6045, Training Loss: 4.396e-02, Validation Loss: 6.003e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6046, Training Loss: 4.394e-02, Validation Loss: 6.004e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6047, Training Loss: 4.393e-02, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6048, Training Loss: 4.392e-02, Validation Loss: 6.003e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6049, Training Loss: 4.391e-02, Validation Loss: 6.004e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6050, Training Loss: 4.390e-02, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6051, Training Loss: 4.389e-02, Validation Loss: 6.004e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6052, Training Loss: 4.387e-02, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6053, Training Loss: 4.386e-02, Validation Loss: 6.004e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6054, Training Loss: 4.385e-02, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6055, Training Loss: 4.384e-02, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6056, Training Loss: 4.383e-02, Validation Loss: 6.004e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6057, Training Loss: 4.381e-02, Validation Loss: 6.004e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6058, Training Loss: 4.380e-02, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6059, Training Loss: 4.379e-02, Validation Loss: 6.004e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6060, Training Loss: 4.378e-02, Validation Loss: 6.005e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6061, Training Loss: 4.377e-02, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6062, Training Loss: 4.376e-02, Validation Loss: 6.005e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6063, Training Loss: 4.374e-02, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6064, Training Loss: 4.373e-02, Validation Loss: 6.005e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6065, Training Loss: 4.372e-02, Validation Loss: 6.005e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6066, Training Loss: 4.371e-02, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6067, Training Loss: 4.370e-02, Validation Loss: 6.005e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6068, Training Loss: 4.369e-02, Validation Loss: 6.005e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6069, Training Loss: 4.367e-02, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6070, Training Loss: 4.366e-02, Validation Loss: 6.005e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6071, Training Loss: 4.365e-02, Validation Loss: 6.006e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6072, Training Loss: 4.364e-02, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6073, Training Loss: 4.363e-02, Validation Loss: 6.005e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6074, Training Loss: 4.362e-02, Validation Loss: 6.006e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6075, Training Loss: 4.360e-02, Validation Loss: 6.005e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6076, Training Loss: 4.359e-02, Validation Loss: 6.006e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6077, Training Loss: 4.358e-02, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6078, Training Loss: 4.357e-02, Validation Loss: 6.006e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6079, Training Loss: 4.356e-02, Validation Loss: 6.006e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6080, Training Loss: 4.355e-02, Validation Loss: 6.005e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6081, Training Loss: 4.354e-02, Validation Loss: 6.006e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6082, Training Loss: 4.352e-02, Validation Loss: 6.006e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6083, Training Loss: 4.351e-02, Validation Loss: 6.005e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6084, Training Loss: 4.350e-02, Validation Loss: 6.006e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6085, Training Loss: 4.349e-02, Validation Loss: 6.007e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6086, Training Loss: 4.348e-02, Validation Loss: 6.005e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6087, Training Loss: 4.347e-02, Validation Loss: 6.006e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6088, Training Loss: 4.345e-02, Validation Loss: 6.006e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6089, Training Loss: 4.344e-02, Validation Loss: 6.007e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6090, Training Loss: 4.343e-02, Validation Loss: 6.006e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6091, Training Loss: 4.342e-02, Validation Loss: 6.007e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6092, Training Loss: 4.341e-02, Validation Loss: 6.007e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6093, Training Loss: 4.340e-02, Validation Loss: 6.006e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6094, Training Loss: 4.338e-02, Validation Loss: 6.007e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6095, Training Loss: 4.337e-02, Validation Loss: 6.006e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6096, Training Loss: 4.336e-02, Validation Loss: 6.007e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6097, Training Loss: 4.335e-02, Validation Loss: 6.008e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6098, Training Loss: 4.334e-02, Validation Loss: 6.006e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6099, Training Loss: 4.333e-02, Validation Loss: 6.007e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6100, Training Loss: 4.332e-02, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6101, Training Loss: 4.330e-02, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6102, Training Loss: 4.329e-02, Validation Loss: 6.007e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6103, Training Loss: 4.328e-02, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6104, Training Loss: 4.327e-02, Validation Loss: 6.008e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6105, Training Loss: 4.326e-02, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6106, Training Loss: 4.325e-02, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6107, Training Loss: 4.323e-02, Validation Loss: 6.008e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6108, Training Loss: 4.322e-02, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6109, Training Loss: 4.321e-02, Validation Loss: 6.008e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6110, Training Loss: 4.320e-02, Validation Loss: 6.008e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6111, Training Loss: 4.319e-02, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6112, Training Loss: 4.318e-02, Validation Loss: 6.008e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6113, Training Loss: 4.317e-02, Validation Loss: 6.008e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6114, Training Loss: 4.315e-02, Validation Loss: 6.008e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 6115, Training Loss: 4.314e-02, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6116, Training Loss: 4.313e-02, Validation Loss: 6.008e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6117, Training Loss: 4.312e-02, Validation Loss: 6.008e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6118, Training Loss: 4.311e-02, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6119, Training Loss: 4.310e-02, Validation Loss: 6.008e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6120, Training Loss: 4.309e-02, Validation Loss: 6.009e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6121, Training Loss: 4.307e-02, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6122, Training Loss: 4.306e-02, Validation Loss: 6.009e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6123, Training Loss: 4.305e-02, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6124, Training Loss: 4.304e-02, Validation Loss: 6.009e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6125, Training Loss: 4.303e-02, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6126, Training Loss: 4.302e-02, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6127, Training Loss: 4.301e-02, Validation Loss: 6.009e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6128, Training Loss: 4.299e-02, Validation Loss: 6.009e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6129, Training Loss: 4.298e-02, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6130, Training Loss: 4.297e-02, Validation Loss: 6.009e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6131, Training Loss: 4.296e-02, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6132, Training Loss: 4.295e-02, Validation Loss: 6.010e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6133, Training Loss: 4.294e-02, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6134, Training Loss: 4.293e-02, Validation Loss: 6.009e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6135, Training Loss: 4.291e-02, Validation Loss: 6.010e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6136, Training Loss: 4.290e-02, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6137, Training Loss: 4.289e-02, Validation Loss: 6.010e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6138, Training Loss: 4.288e-02, Validation Loss: 6.010e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6139, Training Loss: 4.287e-02, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6140, Training Loss: 4.286e-02, Validation Loss: 6.010e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6141, Training Loss: 4.285e-02, Validation Loss: 6.010e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6142, Training Loss: 4.284e-02, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6143, Training Loss: 4.283e-02, Validation Loss: 6.010e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6144, Training Loss: 4.281e-02, Validation Loss: 6.011e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6145, Training Loss: 4.280e-02, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6146, Training Loss: 4.279e-02, Validation Loss: 6.010e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6147, Training Loss: 4.278e-02, Validation Loss: 6.010e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6148, Training Loss: 4.277e-02, Validation Loss: 6.011e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6149, Training Loss: 4.276e-02, Validation Loss: 6.010e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6150, Training Loss: 4.275e-02, Validation Loss: 6.010e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6151, Training Loss: 4.273e-02, Validation Loss: 6.011e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6152, Training Loss: 4.272e-02, Validation Loss: 6.010e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6153, Training Loss: 4.271e-02, Validation Loss: 6.011e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6154, Training Loss: 4.270e-02, Validation Loss: 6.011e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6155, Training Loss: 4.269e-02, Validation Loss: 6.010e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6156, Training Loss: 4.268e-02, Validation Loss: 6.011e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6157, Training Loss: 4.267e-02, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6158, Training Loss: 4.266e-02, Validation Loss: 6.011e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6159, Training Loss: 4.264e-02, Validation Loss: 6.010e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6160, Training Loss: 4.263e-02, Validation Loss: 6.011e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6161, Training Loss: 4.262e-02, Validation Loss: 6.012e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6162, Training Loss: 4.261e-02, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6163, Training Loss: 4.260e-02, Validation Loss: 6.012e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6164, Training Loss: 4.259e-02, Validation Loss: 6.012e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6165, Training Loss: 4.258e-02, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6166, Training Loss: 4.257e-02, Validation Loss: 6.012e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6167, Training Loss: 4.255e-02, Validation Loss: 6.012e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6168, Training Loss: 4.254e-02, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6169, Training Loss: 4.253e-02, Validation Loss: 6.012e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6170, Training Loss: 4.252e-02, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6171, Training Loss: 4.251e-02, Validation Loss: 6.012e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6172, Training Loss: 4.250e-02, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6173, Training Loss: 4.249e-02, Validation Loss: 6.012e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6174, Training Loss: 4.248e-02, Validation Loss: 6.013e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6175, Training Loss: 4.247e-02, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6176, Training Loss: 4.246e-02, Validation Loss: 6.013e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6177, Training Loss: 4.244e-02, Validation Loss: 6.013e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6178, Training Loss: 4.243e-02, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6179, Training Loss: 4.242e-02, Validation Loss: 6.013e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6180, Training Loss: 4.241e-02, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6181, Training Loss: 4.240e-02, Validation Loss: 6.013e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6182, Training Loss: 4.239e-02, Validation Loss: 6.013e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6183, Training Loss: 4.238e-02, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6184, Training Loss: 4.237e-02, Validation Loss: 6.013e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6185, Training Loss: 4.235e-02, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6186, Training Loss: 4.234e-02, Validation Loss: 6.013e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6187, Training Loss: 4.233e-02, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6188, Training Loss: 4.232e-02, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6189, Training Loss: 4.231e-02, Validation Loss: 6.014e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6190, Training Loss: 4.230e-02, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6191, Training Loss: 4.229e-02, Validation Loss: 6.014e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6192, Training Loss: 4.228e-02, Validation Loss: 6.014e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6193, Training Loss: 4.227e-02, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6194, Training Loss: 4.226e-02, Validation Loss: 6.014e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6195, Training Loss: 4.224e-02, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6196, Training Loss: 4.223e-02, Validation Loss: 6.015e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6197, Training Loss: 4.222e-02, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6198, Training Loss: 4.221e-02, Validation Loss: 6.014e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6199, Training Loss: 4.220e-02, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6200, Training Loss: 4.219e-02, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6201, Training Loss: 4.218e-02, Validation Loss: 6.014e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6202, Training Loss: 4.217e-02, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6203, Training Loss: 4.216e-02, Validation Loss: 6.015e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6204, Training Loss: 4.214e-02, Validation Loss: 6.015e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6205, Training Loss: 4.213e-02, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6206, Training Loss: 4.212e-02, Validation Loss: 6.015e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6207, Training Loss: 4.211e-02, Validation Loss: 6.015e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6208, Training Loss: 4.210e-02, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6209, Training Loss: 4.209e-02, Validation Loss: 6.015e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6210, Training Loss: 4.208e-02, Validation Loss: 6.016e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6211, Training Loss: 4.207e-02, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6212, Training Loss: 4.206e-02, Validation Loss: 6.015e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6213, Training Loss: 4.205e-02, Validation Loss: 6.015e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6214, Training Loss: 4.203e-02, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6215, Training Loss: 4.202e-02, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6216, Training Loss: 4.201e-02, Validation Loss: 6.015e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6217, Training Loss: 4.200e-02, Validation Loss: 6.016e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6218, Training Loss: 4.199e-02, Validation Loss: 6.015e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6219, Training Loss: 4.198e-02, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6220, Training Loss: 4.197e-02, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6221, Training Loss: 4.196e-02, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6222, Training Loss: 4.195e-02, Validation Loss: 6.015e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6223, Training Loss: 4.194e-02, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6224, Training Loss: 4.192e-02, Validation Loss: 6.015e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6225, Training Loss: 4.191e-02, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6226, Training Loss: 4.190e-02, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6227, Training Loss: 4.189e-02, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6228, Training Loss: 4.188e-02, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6229, Training Loss: 4.187e-02, Validation Loss: 6.017e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6230, Training Loss: 4.186e-02, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6231, Training Loss: 4.185e-02, Validation Loss: 6.017e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6232, Training Loss: 4.184e-02, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6233, Training Loss: 4.183e-02, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6234, Training Loss: 4.182e-02, Validation Loss: 6.017e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6235, Training Loss: 4.181e-02, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6236, Training Loss: 4.180e-02, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6237, Training Loss: 4.178e-02, Validation Loss: 6.017e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6238, Training Loss: 4.177e-02, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6239, Training Loss: 4.176e-02, Validation Loss: 6.017e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6240, Training Loss: 4.175e-02, Validation Loss: 6.017e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6241, Training Loss: 4.174e-02, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6242, Training Loss: 4.173e-02, Validation Loss: 6.017e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6243, Training Loss: 4.172e-02, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6244, Training Loss: 4.171e-02, Validation Loss: 6.017e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6245, Training Loss: 4.170e-02, Validation Loss: 6.018e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6246, Training Loss: 4.169e-02, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6247, Training Loss: 4.168e-02, Validation Loss: 6.018e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6248, Training Loss: 4.166e-02, Validation Loss: 6.018e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6249, Training Loss: 4.165e-02, Validation Loss: 6.018e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6250, Training Loss: 4.164e-02, Validation Loss: 6.018e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6251, Training Loss: 4.163e-02, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6252, Training Loss: 4.162e-02, Validation Loss: 6.018e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6253, Training Loss: 4.161e-02, Validation Loss: 6.018e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6254, Training Loss: 4.160e-02, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6255, Training Loss: 4.159e-02, Validation Loss: 6.018e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6256, Training Loss: 4.158e-02, Validation Loss: 6.019e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6257, Training Loss: 4.157e-02, Validation Loss: 6.018e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6258, Training Loss: 4.156e-02, Validation Loss: 6.019e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6259, Training Loss: 4.155e-02, Validation Loss: 6.019e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6260, Training Loss: 4.153e-02, Validation Loss: 6.019e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 6261, Training Loss: 4.153e-02, Validation Loss: 6.018e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6262, Training Loss: 4.152e-02, Validation Loss: 6.019e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6263, Training Loss: 4.150e-02, Validation Loss: 6.019e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6264, Training Loss: 4.149e-02, Validation Loss: 6.018e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6265, Training Loss: 4.148e-02, Validation Loss: 6.019e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6266, Training Loss: 4.147e-02, Validation Loss: 6.018e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6267, Training Loss: 4.146e-02, Validation Loss: 6.019e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6268, Training Loss: 4.145e-02, Validation Loss: 6.019e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6269, Training Loss: 4.144e-02, Validation Loss: 6.018e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6270, Training Loss: 4.143e-02, Validation Loss: 6.019e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6271, Training Loss: 4.142e-02, Validation Loss: 6.020e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6272, Training Loss: 4.141e-02, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6273, Training Loss: 4.140e-02, Validation Loss: 6.020e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6274, Training Loss: 4.139e-02, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6275, Training Loss: 4.137e-02, Validation Loss: 6.020e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6276, Training Loss: 4.137e-02, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6277, Training Loss: 4.135e-02, Validation Loss: 6.020e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6278, Training Loss: 4.134e-02, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6279, Training Loss: 4.133e-02, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6280, Training Loss: 4.132e-02, Validation Loss: 6.020e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6281, Training Loss: 4.131e-02, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6282, Training Loss: 4.130e-02, Validation Loss: 6.020e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6283, Training Loss: 4.129e-02, Validation Loss: 6.020e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6284, Training Loss: 4.128e-02, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6285, Training Loss: 4.127e-02, Validation Loss: 6.021e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6286, Training Loss: 4.126e-02, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6287, Training Loss: 4.125e-02, Validation Loss: 6.021e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6288, Training Loss: 4.124e-02, Validation Loss: 6.021e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6289, Training Loss: 4.123e-02, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6290, Training Loss: 4.122e-02, Validation Loss: 6.021e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6291, Training Loss: 4.120e-02, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6292, Training Loss: 4.120e-02, Validation Loss: 6.021e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6293, Training Loss: 4.118e-02, Validation Loss: 6.021e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6294, Training Loss: 4.117e-02, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6295, Training Loss: 4.116e-02, Validation Loss: 6.021e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6296, Training Loss: 4.115e-02, Validation Loss: 6.021e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6297, Training Loss: 4.114e-02, Validation Loss: 6.022e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 6298, Training Loss: 4.113e-02, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6299, Training Loss: 4.112e-02, Validation Loss: 6.022e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6300, Training Loss: 4.111e-02, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6301, Training Loss: 4.110e-02, Validation Loss: 6.022e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6302, Training Loss: 4.109e-02, Validation Loss: 6.022e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6303, Training Loss: 4.108e-02, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6304, Training Loss: 4.107e-02, Validation Loss: 6.022e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6305, Training Loss: 4.106e-02, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6306, Training Loss: 4.105e-02, Validation Loss: 6.022e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6307, Training Loss: 4.104e-02, Validation Loss: 6.023e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6308, Training Loss: 4.103e-02, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6309, Training Loss: 4.102e-02, Validation Loss: 6.023e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6310, Training Loss: 4.100e-02, Validation Loss: 6.022e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6311, Training Loss: 4.099e-02, Validation Loss: 6.022e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6312, Training Loss: 4.098e-02, Validation Loss: 6.022e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6313, Training Loss: 4.097e-02, Validation Loss: 6.023e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6314, Training Loss: 4.096e-02, Validation Loss: 6.022e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6315, Training Loss: 4.095e-02, Validation Loss: 6.023e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6316, Training Loss: 4.094e-02, Validation Loss: 6.023e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6317, Training Loss: 4.093e-02, Validation Loss: 6.022e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6318, Training Loss: 4.092e-02, Validation Loss: 6.023e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6319, Training Loss: 4.091e-02, Validation Loss: 6.023e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6320, Training Loss: 4.090e-02, Validation Loss: 6.022e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6321, Training Loss: 4.089e-02, Validation Loss: 6.023e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6322, Training Loss: 4.088e-02, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6323, Training Loss: 4.087e-02, Validation Loss: 6.024e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6324, Training Loss: 4.086e-02, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6325, Training Loss: 4.085e-02, Validation Loss: 6.023e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6326, Training Loss: 4.084e-02, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6327, Training Loss: 4.083e-02, Validation Loss: 6.024e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6328, Training Loss: 4.082e-02, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6329, Training Loss: 4.081e-02, Validation Loss: 6.024e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6330, Training Loss: 4.079e-02, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6331, Training Loss: 4.079e-02, Validation Loss: 6.024e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6332, Training Loss: 4.077e-02, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6333, Training Loss: 4.076e-02, Validation Loss: 6.024e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6334, Training Loss: 4.075e-02, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6335, Training Loss: 4.074e-02, Validation Loss: 6.024e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6336, Training Loss: 4.073e-02, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6337, Training Loss: 4.072e-02, Validation Loss: 6.024e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6338, Training Loss: 4.071e-02, Validation Loss: 6.025e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6339, Training Loss: 4.070e-02, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6340, Training Loss: 4.069e-02, Validation Loss: 6.025e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6341, Training Loss: 4.068e-02, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6342, Training Loss: 4.067e-02, Validation Loss: 6.025e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6343, Training Loss: 4.066e-02, Validation Loss: 6.025e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6344, Training Loss: 4.065e-02, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6345, Training Loss: 4.064e-02, Validation Loss: 6.025e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6346, Training Loss: 4.063e-02, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6347, Training Loss: 4.062e-02, Validation Loss: 6.025e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6348, Training Loss: 4.061e-02, Validation Loss: 6.026e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6349, Training Loss: 4.060e-02, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6350, Training Loss: 4.059e-02, Validation Loss: 6.026e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6351, Training Loss: 4.058e-02, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6352, Training Loss: 4.057e-02, Validation Loss: 6.026e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6353, Training Loss: 4.056e-02, Validation Loss: 6.026e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6354, Training Loss: 4.055e-02, Validation Loss: 6.025e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6355, Training Loss: 4.054e-02, Validation Loss: 6.026e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6356, Training Loss: 4.052e-02, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6357, Training Loss: 4.052e-02, Validation Loss: 6.025e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6358, Training Loss: 4.051e-02, Validation Loss: 6.026e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6359, Training Loss: 4.049e-02, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6360, Training Loss: 4.048e-02, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6361, Training Loss: 4.047e-02, Validation Loss: 6.026e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6362, Training Loss: 4.046e-02, Validation Loss: 6.025e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6363, Training Loss: 4.045e-02, Validation Loss: 6.026e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6364, Training Loss: 4.044e-02, Validation Loss: 6.027e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6365, Training Loss: 4.043e-02, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6366, Training Loss: 4.042e-02, Validation Loss: 6.027e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6367, Training Loss: 4.041e-02, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6368, Training Loss: 4.040e-02, Validation Loss: 6.027e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6369, Training Loss: 4.039e-02, Validation Loss: 6.027e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6370, Training Loss: 4.038e-02, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6371, Training Loss: 4.037e-02, Validation Loss: 6.027e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6372, Training Loss: 4.036e-02, Validation Loss: 6.027e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6373, Training Loss: 4.035e-02, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6374, Training Loss: 4.034e-02, Validation Loss: 6.028e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6375, Training Loss: 4.033e-02, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6376, Training Loss: 4.032e-02, Validation Loss: 6.027e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6377, Training Loss: 4.031e-02, Validation Loss: 6.028e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6378, Training Loss: 4.030e-02, Validation Loss: 6.027e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6379, Training Loss: 4.029e-02, Validation Loss: 6.028e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6380, Training Loss: 4.028e-02, Validation Loss: 6.027e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6381, Training Loss: 4.027e-02, Validation Loss: 6.028e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6382, Training Loss: 4.026e-02, Validation Loss: 6.028e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6383, Training Loss: 4.025e-02, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6384, Training Loss: 4.024e-02, Validation Loss: 6.028e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6385, Training Loss: 4.023e-02, Validation Loss: 6.027e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6386, Training Loss: 4.022e-02, Validation Loss: 6.028e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6387, Training Loss: 4.021e-02, Validation Loss: 6.028e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6388, Training Loss: 4.020e-02, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6389, Training Loss: 4.019e-02, Validation Loss: 6.028e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6390, Training Loss: 4.018e-02, Validation Loss: 6.028e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6391, Training Loss: 4.017e-02, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6392, Training Loss: 4.016e-02, Validation Loss: 6.028e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6393, Training Loss: 4.015e-02, Validation Loss: 6.029e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6394, Training Loss: 4.014e-02, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6395, Training Loss: 4.013e-02, Validation Loss: 6.029e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6396, Training Loss: 4.012e-02, Validation Loss: 6.029e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6397, Training Loss: 4.011e-02, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6398, Training Loss: 4.010e-02, Validation Loss: 6.029e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6399, Training Loss: 4.009e-02, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6400, Training Loss: 4.008e-02, Validation Loss: 6.029e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6401, Training Loss: 4.007e-02, Validation Loss: 6.030e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6402, Training Loss: 4.006e-02, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6403, Training Loss: 4.005e-02, Validation Loss: 6.030e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6404, Training Loss: 4.004e-02, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6405, Training Loss: 4.003e-02, Validation Loss: 6.029e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6406, Training Loss: 4.002e-02, Validation Loss: 6.030e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6407, Training Loss: 4.000e-02, Validation Loss: 6.029e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6408, Training Loss: 4.000e-02, Validation Loss: 6.030e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6409, Training Loss: 3.998e-02, Validation Loss: 6.030e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6410, Training Loss: 3.997e-02, Validation Loss: 6.029e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6411, Training Loss: 3.996e-02, Validation Loss: 6.030e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6412, Training Loss: 3.995e-02, Validation Loss: 6.029e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6413, Training Loss: 3.995e-02, Validation Loss: 6.030e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6414, Training Loss: 3.993e-02, Validation Loss: 6.031e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6415, Training Loss: 3.992e-02, Validation Loss: 6.029e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6416, Training Loss: 3.992e-02, Validation Loss: 6.030e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6417, Training Loss: 3.990e-02, Validation Loss: 6.031e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6418, Training Loss: 3.989e-02, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6419, Training Loss: 3.988e-02, Validation Loss: 6.031e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6420, Training Loss: 3.987e-02, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6421, Training Loss: 3.987e-02, Validation Loss: 6.031e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6422, Training Loss: 3.985e-02, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6423, Training Loss: 3.984e-02, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6424, Training Loss: 3.983e-02, Validation Loss: 6.031e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6425, Training Loss: 3.982e-02, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6426, Training Loss: 3.981e-02, Validation Loss: 6.031e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6427, Training Loss: 3.980e-02, Validation Loss: 6.031e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6428, Training Loss: 3.979e-02, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6429, Training Loss: 3.978e-02, Validation Loss: 6.032e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6430, Training Loss: 3.977e-02, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6431, Training Loss: 3.976e-02, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6432, Training Loss: 3.975e-02, Validation Loss: 6.032e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6433, Training Loss: 3.974e-02, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6434, Training Loss: 3.973e-02, Validation Loss: 6.032e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6435, Training Loss: 3.972e-02, Validation Loss: 6.032e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6436, Training Loss: 3.971e-02, Validation Loss: 6.032e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 6437, Training Loss: 3.970e-02, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6438, Training Loss: 3.969e-02, Validation Loss: 6.032e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6439, Training Loss: 3.968e-02, Validation Loss: 6.032e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6440, Training Loss: 3.967e-02, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6441, Training Loss: 3.967e-02, Validation Loss: 6.032e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6442, Training Loss: 3.965e-02, Validation Loss: 6.033e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6443, Training Loss: 3.964e-02, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6444, Training Loss: 3.964e-02, Validation Loss: 6.032e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6445, Training Loss: 3.962e-02, Validation Loss: 6.033e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6446, Training Loss: 3.961e-02, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6447, Training Loss: 3.961e-02, Validation Loss: 6.033e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6448, Training Loss: 3.959e-02, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6449, Training Loss: 3.959e-02, Validation Loss: 6.033e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6450, Training Loss: 3.957e-02, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6451, Training Loss: 3.956e-02, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6452, Training Loss: 3.956e-02, Validation Loss: 6.033e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6453, Training Loss: 3.954e-02, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6454, Training Loss: 3.954e-02, Validation Loss: 6.033e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6455, Training Loss: 3.952e-02, Validation Loss: 6.034e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6456, Training Loss: 3.952e-02, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6457, Training Loss: 3.951e-02, Validation Loss: 6.034e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6458, Training Loss: 3.950e-02, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6459, Training Loss: 3.949e-02, Validation Loss: 6.034e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6460, Training Loss: 3.948e-02, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6461, Training Loss: 3.947e-02, Validation Loss: 6.034e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6462, Training Loss: 3.946e-02, Validation Loss: 6.034e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6463, Training Loss: 3.945e-02, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6464, Training Loss: 3.944e-02, Validation Loss: 6.034e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6465, Training Loss: 3.943e-02, Validation Loss: 6.034e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6466, Training Loss: 3.942e-02, Validation Loss: 6.034e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6467, Training Loss: 3.941e-02, Validation Loss: 6.034e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6468, Training Loss: 3.940e-02, Validation Loss: 6.034e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6469, Training Loss: 3.939e-02, Validation Loss: 6.034e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6470, Training Loss: 3.938e-02, Validation Loss: 6.034e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6471, Training Loss: 3.937e-02, Validation Loss: 6.034e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6472, Training Loss: 3.936e-02, Validation Loss: 6.035e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6473, Training Loss: 3.935e-02, Validation Loss: 6.034e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6474, Training Loss: 3.934e-02, Validation Loss: 6.035e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6475, Training Loss: 3.933e-02, Validation Loss: 6.035e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6476, Training Loss: 3.932e-02, Validation Loss: 6.034e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6477, Training Loss: 3.931e-02, Validation Loss: 6.035e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6478, Training Loss: 3.930e-02, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6479, Training Loss: 3.929e-02, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6480, Training Loss: 3.928e-02, Validation Loss: 6.035e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6481, Training Loss: 3.927e-02, Validation Loss: 6.034e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6482, Training Loss: 3.926e-02, Validation Loss: 6.035e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6483, Training Loss: 3.925e-02, Validation Loss: 6.036e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6484, Training Loss: 3.924e-02, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6485, Training Loss: 3.923e-02, Validation Loss: 6.036e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6486, Training Loss: 3.922e-02, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6487, Training Loss: 3.921e-02, Validation Loss: 6.036e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6488, Training Loss: 3.920e-02, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6489, Training Loss: 3.919e-02, Validation Loss: 6.036e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6490, Training Loss: 3.918e-02, Validation Loss: 6.036e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6491, Training Loss: 3.917e-02, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6492, Training Loss: 3.916e-02, Validation Loss: 6.036e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6493, Training Loss: 3.915e-02, Validation Loss: 6.036e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6494, Training Loss: 3.914e-02, Validation Loss: 6.036e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6495, Training Loss: 3.913e-02, Validation Loss: 6.036e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6496, Training Loss: 3.912e-02, Validation Loss: 6.036e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6497, Training Loss: 3.911e-02, Validation Loss: 6.037e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6498, Training Loss: 3.910e-02, Validation Loss: 6.037e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6499, Training Loss: 3.909e-02, Validation Loss: 6.036e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6500, Training Loss: 3.908e-02, Validation Loss: 6.037e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6501, Training Loss: 3.907e-02, Validation Loss: 6.036e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6502, Training Loss: 3.907e-02, Validation Loss: 6.037e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6503, Training Loss: 3.905e-02, Validation Loss: 6.037e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6504, Training Loss: 3.905e-02, Validation Loss: 6.036e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6505, Training Loss: 3.904e-02, Validation Loss: 6.037e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6506, Training Loss: 3.903e-02, Validation Loss: 6.037e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6507, Training Loss: 3.902e-02, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6508, Training Loss: 3.901e-02, Validation Loss: 6.038e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6509, Training Loss: 3.900e-02, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6510, Training Loss: 3.899e-02, Validation Loss: 6.038e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6511, Training Loss: 3.898e-02, Validation Loss: 6.038e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6512, Training Loss: 3.897e-02, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6513, Training Loss: 3.896e-02, Validation Loss: 6.038e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6514, Training Loss: 3.895e-02, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6515, Training Loss: 3.894e-02, Validation Loss: 6.038e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6516, Training Loss: 3.893e-02, Validation Loss: 6.038e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6517, Training Loss: 3.892e-02, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6518, Training Loss: 3.891e-02, Validation Loss: 6.038e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6519, Training Loss: 3.890e-02, Validation Loss: 6.038e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6520, Training Loss: 3.889e-02, Validation Loss: 6.038e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6521, Training Loss: 3.888e-02, Validation Loss: 6.038e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6522, Training Loss: 3.887e-02, Validation Loss: 6.039e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6523, Training Loss: 3.886e-02, Validation Loss: 6.039e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6524, Training Loss: 3.885e-02, Validation Loss: 6.038e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6525, Training Loss: 3.884e-02, Validation Loss: 6.038e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6526, Training Loss: 3.883e-02, Validation Loss: 6.039e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6527, Training Loss: 3.882e-02, Validation Loss: 6.038e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6528, Training Loss: 3.881e-02, Validation Loss: 6.039e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6529, Training Loss: 3.880e-02, Validation Loss: 6.039e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6530, Training Loss: 3.879e-02, Validation Loss: 6.038e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6531, Training Loss: 3.878e-02, Validation Loss: 6.040e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6532, Training Loss: 3.877e-02, Validation Loss: 6.038e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6533, Training Loss: 3.877e-02, Validation Loss: 6.039e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6534, Training Loss: 3.876e-02, Validation Loss: 6.039e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6535, Training Loss: 3.875e-02, Validation Loss: 6.039e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6536, Training Loss: 3.874e-02, Validation Loss: 6.040e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6537, Training Loss: 3.873e-02, Validation Loss: 6.039e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6538, Training Loss: 3.872e-02, Validation Loss: 6.040e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6539, Training Loss: 3.871e-02, Validation Loss: 6.040e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6540, Training Loss: 3.870e-02, Validation Loss: 6.039e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6541, Training Loss: 3.869e-02, Validation Loss: 6.040e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6542, Training Loss: 3.868e-02, Validation Loss: 6.040e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6543, Training Loss: 3.867e-02, Validation Loss: 6.039e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6544, Training Loss: 3.866e-02, Validation Loss: 6.040e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6545, Training Loss: 3.865e-02, Validation Loss: 6.039e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6546, Training Loss: 3.864e-02, Validation Loss: 6.040e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6547, Training Loss: 3.863e-02, Validation Loss: 6.040e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6548, Training Loss: 3.862e-02, Validation Loss: 6.040e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6549, Training Loss: 3.861e-02, Validation Loss: 6.041e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6550, Training Loss: 3.860e-02, Validation Loss: 6.040e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6551, Training Loss: 3.859e-02, Validation Loss: 6.041e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6552, Training Loss: 3.858e-02, Validation Loss: 6.041e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6553, Training Loss: 3.857e-02, Validation Loss: 6.040e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6554, Training Loss: 3.857e-02, Validation Loss: 6.041e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6555, Training Loss: 3.856e-02, Validation Loss: 6.041e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6556, Training Loss: 3.855e-02, Validation Loss: 6.040e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6557, Training Loss: 3.854e-02, Validation Loss: 6.041e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6558, Training Loss: 3.853e-02, Validation Loss: 6.041e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6559, Training Loss: 3.852e-02, Validation Loss: 6.041e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6560, Training Loss: 3.851e-02, Validation Loss: 6.041e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6561, Training Loss: 3.850e-02, Validation Loss: 6.041e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6562, Training Loss: 3.849e-02, Validation Loss: 6.041e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6563, Training Loss: 3.848e-02, Validation Loss: 6.042e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6564, Training Loss: 3.847e-02, Validation Loss: 6.041e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6565, Training Loss: 3.846e-02, Validation Loss: 6.042e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6566, Training Loss: 3.845e-02, Validation Loss: 6.042e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6567, Training Loss: 3.844e-02, Validation Loss: 6.041e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6568, Training Loss: 3.843e-02, Validation Loss: 6.042e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6569, Training Loss: 3.842e-02, Validation Loss: 6.042e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6570, Training Loss: 3.841e-02, Validation Loss: 6.041e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6571, Training Loss: 3.840e-02, Validation Loss: 6.042e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6572, Training Loss: 3.839e-02, Validation Loss: 6.042e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6573, Training Loss: 3.838e-02, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6574, Training Loss: 3.838e-02, Validation Loss: 6.043e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6575, Training Loss: 3.837e-02, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6576, Training Loss: 3.836e-02, Validation Loss: 6.043e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6577, Training Loss: 3.835e-02, Validation Loss: 6.043e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6578, Training Loss: 3.834e-02, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6579, Training Loss: 3.833e-02, Validation Loss: 6.043e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6580, Training Loss: 3.832e-02, Validation Loss: 6.043e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6581, Training Loss: 3.831e-02, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6582, Training Loss: 3.830e-02, Validation Loss: 6.043e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6583, Training Loss: 3.829e-02, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6584, Training Loss: 3.828e-02, Validation Loss: 6.043e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6585, Training Loss: 3.827e-02, Validation Loss: 6.044e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6586, Training Loss: 3.826e-02, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6587, Training Loss: 3.825e-02, Validation Loss: 6.044e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6588, Training Loss: 3.824e-02, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6589, Training Loss: 3.823e-02, Validation Loss: 6.044e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6590, Training Loss: 3.823e-02, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6591, Training Loss: 3.822e-02, Validation Loss: 6.044e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6592, Training Loss: 3.821e-02, Validation Loss: 6.044e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6593, Training Loss: 3.820e-02, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6594, Training Loss: 3.819e-02, Validation Loss: 6.045e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6595, Training Loss: 3.818e-02, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6596, Training Loss: 3.817e-02, Validation Loss: 6.044e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6597, Training Loss: 3.816e-02, Validation Loss: 6.045e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6598, Training Loss: 3.815e-02, Validation Loss: 6.044e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6599, Training Loss: 3.814e-02, Validation Loss: 6.044e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6600, Training Loss: 3.813e-02, Validation Loss: 6.045e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6601, Training Loss: 3.812e-02, Validation Loss: 6.044e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6602, Training Loss: 3.811e-02, Validation Loss: 6.045e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6603, Training Loss: 3.810e-02, Validation Loss: 6.044e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6604, Training Loss: 3.809e-02, Validation Loss: 6.045e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6605, Training Loss: 3.809e-02, Validation Loss: 6.044e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6606, Training Loss: 3.808e-02, Validation Loss: 6.045e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6607, Training Loss: 3.807e-02, Validation Loss: 6.045e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6608, Training Loss: 3.806e-02, Validation Loss: 6.045e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6609, Training Loss: 3.805e-02, Validation Loss: 6.045e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6610, Training Loss: 3.804e-02, Validation Loss: 6.045e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6611, Training Loss: 3.803e-02, Validation Loss: 6.045e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6612, Training Loss: 3.802e-02, Validation Loss: 6.045e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6613, Training Loss: 3.801e-02, Validation Loss: 6.045e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6614, Training Loss: 3.800e-02, Validation Loss: 6.046e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6615, Training Loss: 3.799e-02, Validation Loss: 6.046e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6616, Training Loss: 3.798e-02, Validation Loss: 6.045e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6617, Training Loss: 3.797e-02, Validation Loss: 6.046e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6618, Training Loss: 3.796e-02, Validation Loss: 6.046e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6619, Training Loss: 3.796e-02, Validation Loss: 6.046e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6620, Training Loss: 3.795e-02, Validation Loss: 6.046e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6621, Training Loss: 3.794e-02, Validation Loss: 6.046e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6622, Training Loss: 3.793e-02, Validation Loss: 6.046e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6623, Training Loss: 3.792e-02, Validation Loss: 6.045e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6624, Training Loss: 3.791e-02, Validation Loss: 6.046e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6625, Training Loss: 3.790e-02, Validation Loss: 6.047e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6626, Training Loss: 3.789e-02, Validation Loss: 6.046e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6627, Training Loss: 3.788e-02, Validation Loss: 6.046e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6628, Training Loss: 3.787e-02, Validation Loss: 6.046e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6629, Training Loss: 3.786e-02, Validation Loss: 6.047e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6630, Training Loss: 3.785e-02, Validation Loss: 6.046e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6631, Training Loss: 3.785e-02, Validation Loss: 6.047e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6632, Training Loss: 3.783e-02, Validation Loss: 6.047e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6633, Training Loss: 3.783e-02, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6634, Training Loss: 3.782e-02, Validation Loss: 6.047e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6635, Training Loss: 3.781e-02, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6636, Training Loss: 3.780e-02, Validation Loss: 6.047e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6637, Training Loss: 3.779e-02, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6638, Training Loss: 3.778e-02, Validation Loss: 6.047e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6639, Training Loss: 3.777e-02, Validation Loss: 6.047e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6640, Training Loss: 3.776e-02, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6641, Training Loss: 3.775e-02, Validation Loss: 6.048e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6642, Training Loss: 3.774e-02, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6643, Training Loss: 3.773e-02, Validation Loss: 6.048e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6644, Training Loss: 3.772e-02, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6645, Training Loss: 3.772e-02, Validation Loss: 6.047e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6646, Training Loss: 3.771e-02, Validation Loss: 6.048e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6647, Training Loss: 3.770e-02, Validation Loss: 6.048e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6648, Training Loss: 3.769e-02, Validation Loss: 6.048e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6649, Training Loss: 3.768e-02, Validation Loss: 6.048e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6650, Training Loss: 3.767e-02, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6651, Training Loss: 3.766e-02, Validation Loss: 6.048e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6652, Training Loss: 3.765e-02, Validation Loss: 6.049e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6653, Training Loss: 3.764e-02, Validation Loss: 6.048e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6654, Training Loss: 3.763e-02, Validation Loss: 6.049e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6655, Training Loss: 3.762e-02, Validation Loss: 6.049e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6656, Training Loss: 3.762e-02, Validation Loss: 6.048e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6657, Training Loss: 3.761e-02, Validation Loss: 6.049e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6658, Training Loss: 3.760e-02, Validation Loss: 6.048e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6659, Training Loss: 3.759e-02, Validation Loss: 6.049e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6660, Training Loss: 3.758e-02, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6661, Training Loss: 3.757e-02, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6662, Training Loss: 3.756e-02, Validation Loss: 6.049e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6663, Training Loss: 3.755e-02, Validation Loss: 6.049e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6664, Training Loss: 3.754e-02, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6665, Training Loss: 3.753e-02, Validation Loss: 6.049e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6666, Training Loss: 3.752e-02, Validation Loss: 6.050e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6667, Training Loss: 3.751e-02, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6668, Training Loss: 3.751e-02, Validation Loss: 6.050e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6669, Training Loss: 3.750e-02, Validation Loss: 6.050e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6670, Training Loss: 3.749e-02, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6671, Training Loss: 3.748e-02, Validation Loss: 6.050e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6672, Training Loss: 3.747e-02, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6673, Training Loss: 3.746e-02, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6674, Training Loss: 3.745e-02, Validation Loss: 6.050e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6675, Training Loss: 3.744e-02, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6676, Training Loss: 3.743e-02, Validation Loss: 6.051e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6677, Training Loss: 3.742e-02, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6678, Training Loss: 3.742e-02, Validation Loss: 6.050e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6679, Training Loss: 3.741e-02, Validation Loss: 6.051e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6680, Training Loss: 3.740e-02, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6681, Training Loss: 3.739e-02, Validation Loss: 6.051e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6682, Training Loss: 3.738e-02, Validation Loss: 6.051e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6683, Training Loss: 3.737e-02, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6684, Training Loss: 3.736e-02, Validation Loss: 6.051e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6685, Training Loss: 3.735e-02, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6686, Training Loss: 3.734e-02, Validation Loss: 6.051e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6687, Training Loss: 3.733e-02, Validation Loss: 6.051e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6688, Training Loss: 3.733e-02, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6689, Training Loss: 3.732e-02, Validation Loss: 6.051e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6690, Training Loss: 3.731e-02, Validation Loss: 6.052e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6691, Training Loss: 3.730e-02, Validation Loss: 6.051e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6692, Training Loss: 3.729e-02, Validation Loss: 6.052e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6693, Training Loss: 3.728e-02, Validation Loss: 6.051e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6694, Training Loss: 3.727e-02, Validation Loss: 6.051e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6695, Training Loss: 3.726e-02, Validation Loss: 6.052e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6696, Training Loss: 3.725e-02, Validation Loss: 6.051e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6697, Training Loss: 3.725e-02, Validation Loss: 6.052e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6698, Training Loss: 3.724e-02, Validation Loss: 6.052e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6699, Training Loss: 3.723e-02, Validation Loss: 6.051e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6700, Training Loss: 3.722e-02, Validation Loss: 6.052e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6701, Training Loss: 3.721e-02, Validation Loss: 6.052e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6702, Training Loss: 3.720e-02, Validation Loss: 6.052e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6703, Training Loss: 3.719e-02, Validation Loss: 6.052e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6704, Training Loss: 3.718e-02, Validation Loss: 6.053e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6705, Training Loss: 3.717e-02, Validation Loss: 6.052e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6706, Training Loss: 3.716e-02, Validation Loss: 6.052e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6707, Training Loss: 3.715e-02, Validation Loss: 6.053e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6708, Training Loss: 3.715e-02, Validation Loss: 6.052e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6709, Training Loss: 3.714e-02, Validation Loss: 6.053e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6710, Training Loss: 3.713e-02, Validation Loss: 6.053e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6711, Training Loss: 3.712e-02, Validation Loss: 6.052e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6712, Training Loss: 3.711e-02, Validation Loss: 6.053e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6713, Training Loss: 3.710e-02, Validation Loss: 6.053e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6714, Training Loss: 3.709e-02, Validation Loss: 6.053e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6715, Training Loss: 3.708e-02, Validation Loss: 6.053e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6716, Training Loss: 3.707e-02, Validation Loss: 6.054e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6717, Training Loss: 3.707e-02, Validation Loss: 6.053e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6718, Training Loss: 3.706e-02, Validation Loss: 6.053e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6719, Training Loss: 3.705e-02, Validation Loss: 6.053e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6720, Training Loss: 3.704e-02, Validation Loss: 6.053e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6721, Training Loss: 3.703e-02, Validation Loss: 6.054e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6722, Training Loss: 3.702e-02, Validation Loss: 6.053e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6723, Training Loss: 3.701e-02, Validation Loss: 6.054e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6724, Training Loss: 3.700e-02, Validation Loss: 6.054e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6725, Training Loss: 3.699e-02, Validation Loss: 6.053e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6726, Training Loss: 3.699e-02, Validation Loss: 6.054e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6727, Training Loss: 3.698e-02, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6728, Training Loss: 3.697e-02, Validation Loss: 6.054e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6729, Training Loss: 3.696e-02, Validation Loss: 6.055e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6730, Training Loss: 3.695e-02, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6731, Training Loss: 3.694e-02, Validation Loss: 6.054e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6732, Training Loss: 3.693e-02, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6733, Training Loss: 3.692e-02, Validation Loss: 6.055e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6734, Training Loss: 3.691e-02, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6735, Training Loss: 3.691e-02, Validation Loss: 6.055e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6736, Training Loss: 3.690e-02, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6737, Training Loss: 3.689e-02, Validation Loss: 6.055e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6738, Training Loss: 3.688e-02, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6739, Training Loss: 3.687e-02, Validation Loss: 6.055e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6740, Training Loss: 3.686e-02, Validation Loss: 6.055e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6741, Training Loss: 3.685e-02, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6742, Training Loss: 3.684e-02, Validation Loss: 6.055e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6743, Training Loss: 3.684e-02, Validation Loss: 6.055e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6744, Training Loss: 3.683e-02, Validation Loss: 6.056e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 6745, Training Loss: 3.682e-02, Validation Loss: 6.055e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6746, Training Loss: 3.681e-02, Validation Loss: 6.055e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6747, Training Loss: 3.680e-02, Validation Loss: 6.056e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6748, Training Loss: 3.679e-02, Validation Loss: 6.055e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6749, Training Loss: 3.678e-02, Validation Loss: 6.056e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6750, Training Loss: 3.677e-02, Validation Loss: 6.056e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6751, Training Loss: 3.677e-02, Validation Loss: 6.055e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6752, Training Loss: 3.676e-02, Validation Loss: 6.056e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6753, Training Loss: 3.675e-02, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6754, Training Loss: 3.674e-02, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6755, Training Loss: 3.673e-02, Validation Loss: 6.056e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6756, Training Loss: 3.672e-02, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6757, Training Loss: 3.671e-02, Validation Loss: 6.056e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6758, Training Loss: 3.670e-02, Validation Loss: 6.056e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6759, Training Loss: 3.669e-02, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6760, Training Loss: 3.669e-02, Validation Loss: 6.057e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6761, Training Loss: 3.668e-02, Validation Loss: 6.057e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6762, Training Loss: 3.667e-02, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6763, Training Loss: 3.666e-02, Validation Loss: 6.057e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6764, Training Loss: 3.665e-02, Validation Loss: 6.057e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6765, Training Loss: 3.664e-02, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6766, Training Loss: 3.663e-02, Validation Loss: 6.057e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6767, Training Loss: 3.663e-02, Validation Loss: 6.057e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6768, Training Loss: 3.662e-02, Validation Loss: 6.057e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6769, Training Loss: 3.661e-02, Validation Loss: 6.057e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6770, Training Loss: 3.660e-02, Validation Loss: 6.057e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6771, Training Loss: 3.659e-02, Validation Loss: 6.058e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6772, Training Loss: 3.658e-02, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6773, Training Loss: 3.657e-02, Validation Loss: 6.057e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6774, Training Loss: 3.656e-02, Validation Loss: 6.058e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6775, Training Loss: 3.656e-02, Validation Loss: 6.058e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6776, Training Loss: 3.655e-02, Validation Loss: 6.057e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6777, Training Loss: 3.654e-02, Validation Loss: 6.058e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6778, Training Loss: 3.653e-02, Validation Loss: 6.058e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6779, Training Loss: 3.652e-02, Validation Loss: 6.057e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6780, Training Loss: 3.651e-02, Validation Loss: 6.058e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6781, Training Loss: 3.650e-02, Validation Loss: 6.058e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6782, Training Loss: 3.649e-02, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6783, Training Loss: 3.649e-02, Validation Loss: 6.058e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6784, Training Loss: 3.648e-02, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6785, Training Loss: 3.647e-02, Validation Loss: 6.059e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6786, Training Loss: 3.646e-02, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6787, Training Loss: 3.645e-02, Validation Loss: 6.058e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6788, Training Loss: 3.644e-02, Validation Loss: 6.059e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6789, Training Loss: 3.643e-02, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6790, Training Loss: 3.643e-02, Validation Loss: 6.059e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6791, Training Loss: 3.642e-02, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6792, Training Loss: 3.641e-02, Validation Loss: 6.059e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6793, Training Loss: 3.640e-02, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6794, Training Loss: 3.639e-02, Validation Loss: 6.059e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6795, Training Loss: 3.638e-02, Validation Loss: 6.059e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6796, Training Loss: 3.637e-02, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6797, Training Loss: 3.637e-02, Validation Loss: 6.059e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6798, Training Loss: 3.636e-02, Validation Loss: 6.060e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6799, Training Loss: 3.635e-02, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6800, Training Loss: 3.634e-02, Validation Loss: 6.059e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6801, Training Loss: 3.633e-02, Validation Loss: 6.060e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6802, Training Loss: 3.632e-02, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6803, Training Loss: 3.631e-02, Validation Loss: 6.060e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6804, Training Loss: 3.630e-02, Validation Loss: 6.060e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6805, Training Loss: 3.630e-02, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6806, Training Loss: 3.629e-02, Validation Loss: 6.060e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6807, Training Loss: 3.628e-02, Validation Loss: 6.060e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6808, Training Loss: 3.627e-02, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6809, Training Loss: 3.626e-02, Validation Loss: 6.060e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6810, Training Loss: 3.625e-02, Validation Loss: 6.061e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6811, Training Loss: 3.624e-02, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6812, Training Loss: 3.624e-02, Validation Loss: 6.061e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6813, Training Loss: 3.623e-02, Validation Loss: 6.061e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6814, Training Loss: 3.622e-02, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6815, Training Loss: 3.621e-02, Validation Loss: 6.061e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6816, Training Loss: 3.620e-02, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6817, Training Loss: 3.619e-02, Validation Loss: 6.061e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6818, Training Loss: 3.618e-02, Validation Loss: 6.061e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6819, Training Loss: 3.618e-02, Validation Loss: 6.061e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6820, Training Loss: 3.617e-02, Validation Loss: 6.061e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6821, Training Loss: 3.616e-02, Validation Loss: 6.062e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6822, Training Loss: 3.615e-02, Validation Loss: 6.061e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6823, Training Loss: 3.614e-02, Validation Loss: 6.061e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6824, Training Loss: 3.613e-02, Validation Loss: 6.062e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6825, Training Loss: 3.613e-02, Validation Loss: 6.061e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6826, Training Loss: 3.612e-02, Validation Loss: 6.062e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6827, Training Loss: 3.611e-02, Validation Loss: 6.062e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6828, Training Loss: 3.610e-02, Validation Loss: 6.061e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6829, Training Loss: 3.609e-02, Validation Loss: 6.062e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6830, Training Loss: 3.608e-02, Validation Loss: 6.062e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6831, Training Loss: 3.607e-02, Validation Loss: 6.061e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6832, Training Loss: 3.607e-02, Validation Loss: 6.062e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6833, Training Loss: 3.606e-02, Validation Loss: 6.062e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6834, Training Loss: 3.605e-02, Validation Loss: 6.062e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6835, Training Loss: 3.604e-02, Validation Loss: 6.062e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6836, Training Loss: 3.603e-02, Validation Loss: 6.063e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6837, Training Loss: 3.602e-02, Validation Loss: 6.062e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6838, Training Loss: 3.601e-02, Validation Loss: 6.063e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6839, Training Loss: 3.601e-02, Validation Loss: 6.062e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6840, Training Loss: 3.600e-02, Validation Loss: 6.062e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6841, Training Loss: 3.599e-02, Validation Loss: 6.063e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6842, Training Loss: 3.598e-02, Validation Loss: 6.062e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6843, Training Loss: 3.597e-02, Validation Loss: 6.063e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6844, Training Loss: 3.596e-02, Validation Loss: 6.062e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6845, Training Loss: 3.596e-02, Validation Loss: 6.063e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6846, Training Loss: 3.595e-02, Validation Loss: 6.063e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6847, Training Loss: 3.594e-02, Validation Loss: 6.063e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6848, Training Loss: 3.593e-02, Validation Loss: 6.063e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6849, Training Loss: 3.592e-02, Validation Loss: 6.063e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6850, Training Loss: 3.591e-02, Validation Loss: 6.063e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6851, Training Loss: 3.590e-02, Validation Loss: 6.064e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6852, Training Loss: 3.590e-02, Validation Loss: 6.063e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6853, Training Loss: 3.589e-02, Validation Loss: 6.064e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6854, Training Loss: 3.588e-02, Validation Loss: 6.064e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6855, Training Loss: 3.587e-02, Validation Loss: 6.063e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6856, Training Loss: 3.586e-02, Validation Loss: 6.064e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6857, Training Loss: 3.585e-02, Validation Loss: 6.064e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6858, Training Loss: 3.585e-02, Validation Loss: 6.063e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6859, Training Loss: 3.584e-02, Validation Loss: 6.064e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6860, Training Loss: 3.583e-02, Validation Loss: 6.064e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6861, Training Loss: 3.582e-02, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6862, Training Loss: 3.581e-02, Validation Loss: 6.065e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6863, Training Loss: 3.580e-02, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6864, Training Loss: 3.580e-02, Validation Loss: 6.065e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6865, Training Loss: 3.579e-02, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6866, Training Loss: 3.578e-02, Validation Loss: 6.065e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6867, Training Loss: 3.577e-02, Validation Loss: 6.065e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6868, Training Loss: 3.576e-02, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6869, Training Loss: 3.575e-02, Validation Loss: 6.065e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6870, Training Loss: 3.574e-02, Validation Loss: 6.065e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6871, Training Loss: 3.574e-02, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6872, Training Loss: 3.573e-02, Validation Loss: 6.065e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6873, Training Loss: 3.572e-02, Validation Loss: 6.065e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6874, Training Loss: 3.571e-02, Validation Loss: 6.065e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6875, Training Loss: 3.570e-02, Validation Loss: 6.065e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6876, Training Loss: 3.569e-02, Validation Loss: 6.066e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6877, Training Loss: 3.569e-02, Validation Loss: 6.065e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6878, Training Loss: 3.568e-02, Validation Loss: 6.066e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6879, Training Loss: 3.567e-02, Validation Loss: 6.066e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6880, Training Loss: 3.566e-02, Validation Loss: 6.065e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6881, Training Loss: 3.565e-02, Validation Loss: 6.066e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6882, Training Loss: 3.564e-02, Validation Loss: 6.066e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6883, Training Loss: 3.564e-02, Validation Loss: 6.065e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6884, Training Loss: 3.563e-02, Validation Loss: 6.066e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6885, Training Loss: 3.562e-02, Validation Loss: 6.066e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6886, Training Loss: 3.561e-02, Validation Loss: 6.066e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6887, Training Loss: 3.560e-02, Validation Loss: 6.065e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6888, Training Loss: 3.560e-02, Validation Loss: 6.066e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6889, Training Loss: 3.559e-02, Validation Loss: 6.067e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6890, Training Loss: 3.558e-02, Validation Loss: 6.066e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6891, Training Loss: 3.557e-02, Validation Loss: 6.067e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6892, Training Loss: 3.556e-02, Validation Loss: 6.067e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6893, Training Loss: 3.555e-02, Validation Loss: 6.066e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6894, Training Loss: 3.555e-02, Validation Loss: 6.067e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6895, Training Loss: 3.554e-02, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6896, Training Loss: 3.553e-02, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6897, Training Loss: 3.552e-02, Validation Loss: 6.067e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6898, Training Loss: 3.551e-02, Validation Loss: 6.066e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6899, Training Loss: 3.550e-02, Validation Loss: 6.067e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6900, Training Loss: 3.550e-02, Validation Loss: 6.067e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6901, Training Loss: 3.549e-02, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6902, Training Loss: 3.548e-02, Validation Loss: 6.068e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6903, Training Loss: 3.547e-02, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6904, Training Loss: 3.546e-02, Validation Loss: 6.068e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6905, Training Loss: 3.545e-02, Validation Loss: 6.068e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6906, Training Loss: 3.545e-02, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6907, Training Loss: 3.544e-02, Validation Loss: 6.068e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6908, Training Loss: 3.543e-02, Validation Loss: 6.068e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6909, Training Loss: 3.542e-02, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6910, Training Loss: 3.541e-02, Validation Loss: 6.068e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6911, Training Loss: 3.540e-02, Validation Loss: 6.068e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6912, Training Loss: 3.540e-02, Validation Loss: 6.068e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 6913, Training Loss: 3.539e-02, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6914, Training Loss: 3.538e-02, Validation Loss: 6.068e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6915, Training Loss: 3.537e-02, Validation Loss: 6.069e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6916, Training Loss: 3.536e-02, Validation Loss: 6.068e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6917, Training Loss: 3.535e-02, Validation Loss: 6.069e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6918, Training Loss: 3.535e-02, Validation Loss: 6.068e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6919, Training Loss: 3.534e-02, Validation Loss: 6.069e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6920, Training Loss: 3.533e-02, Validation Loss: 6.068e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6921, Training Loss: 3.532e-02, Validation Loss: 6.069e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6922, Training Loss: 3.531e-02, Validation Loss: 6.069e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6923, Training Loss: 3.531e-02, Validation Loss: 6.069e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6924, Training Loss: 3.530e-02, Validation Loss: 6.069e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6925, Training Loss: 3.529e-02, Validation Loss: 6.069e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6926, Training Loss: 3.528e-02, Validation Loss: 6.069e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6927, Training Loss: 3.527e-02, Validation Loss: 6.069e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6928, Training Loss: 3.526e-02, Validation Loss: 6.069e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6929, Training Loss: 3.526e-02, Validation Loss: 6.069e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6930, Training Loss: 3.525e-02, Validation Loss: 6.070e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6931, Training Loss: 3.524e-02, Validation Loss: 6.070e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6932, Training Loss: 3.523e-02, Validation Loss: 6.069e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6933, Training Loss: 3.522e-02, Validation Loss: 6.069e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6934, Training Loss: 3.522e-02, Validation Loss: 6.070e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6935, Training Loss: 3.521e-02, Validation Loss: 6.069e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6936, Training Loss: 3.520e-02, Validation Loss: 6.070e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6937, Training Loss: 3.519e-02, Validation Loss: 6.070e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6938, Training Loss: 3.518e-02, Validation Loss: 6.069e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6939, Training Loss: 3.518e-02, Validation Loss: 6.070e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6940, Training Loss: 3.517e-02, Validation Loss: 6.070e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6941, Training Loss: 3.516e-02, Validation Loss: 6.070e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6942, Training Loss: 3.515e-02, Validation Loss: 6.070e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6943, Training Loss: 3.514e-02, Validation Loss: 6.071e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6944, Training Loss: 3.513e-02, Validation Loss: 6.071e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6945, Training Loss: 3.513e-02, Validation Loss: 6.070e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6946, Training Loss: 3.512e-02, Validation Loss: 6.071e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6947, Training Loss: 3.511e-02, Validation Loss: 6.071e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6948, Training Loss: 3.510e-02, Validation Loss: 6.070e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6949, Training Loss: 3.509e-02, Validation Loss: 6.071e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6950, Training Loss: 3.509e-02, Validation Loss: 6.071e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6951, Training Loss: 3.508e-02, Validation Loss: 6.070e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6952, Training Loss: 3.507e-02, Validation Loss: 6.071e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6953, Training Loss: 3.506e-02, Validation Loss: 6.071e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6954, Training Loss: 3.505e-02, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6955, Training Loss: 3.505e-02, Validation Loss: 6.071e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6956, Training Loss: 3.504e-02, Validation Loss: 6.072e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6957, Training Loss: 3.503e-02, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6958, Training Loss: 3.502e-02, Validation Loss: 6.072e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6959, Training Loss: 3.501e-02, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6960, Training Loss: 3.500e-02, Validation Loss: 6.072e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6961, Training Loss: 3.500e-02, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6962, Training Loss: 3.499e-02, Validation Loss: 6.072e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6963, Training Loss: 3.498e-02, Validation Loss: 6.072e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6964, Training Loss: 3.497e-02, Validation Loss: 6.072e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6965, Training Loss: 3.496e-02, Validation Loss: 6.072e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6966, Training Loss: 3.496e-02, Validation Loss: 6.072e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6967, Training Loss: 3.495e-02, Validation Loss: 6.072e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6968, Training Loss: 3.494e-02, Validation Loss: 6.073e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6969, Training Loss: 3.493e-02, Validation Loss: 6.072e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6970, Training Loss: 3.492e-02, Validation Loss: 6.072e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6971, Training Loss: 3.492e-02, Validation Loss: 6.073e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6972, Training Loss: 3.491e-02, Validation Loss: 6.072e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6973, Training Loss: 3.490e-02, Validation Loss: 6.073e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6974, Training Loss: 3.489e-02, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6975, Training Loss: 3.488e-02, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6976, Training Loss: 3.488e-02, Validation Loss: 6.073e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6977, Training Loss: 3.487e-02, Validation Loss: 6.072e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6978, Training Loss: 3.486e-02, Validation Loss: 6.073e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6979, Training Loss: 3.485e-02, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6980, Training Loss: 3.484e-02, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6981, Training Loss: 3.484e-02, Validation Loss: 6.073e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6982, Training Loss: 3.483e-02, Validation Loss: 6.074e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6983, Training Loss: 3.482e-02, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6984, Training Loss: 3.481e-02, Validation Loss: 6.073e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6985, Training Loss: 3.480e-02, Validation Loss: 6.074e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6986, Training Loss: 3.480e-02, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6987, Training Loss: 3.479e-02, Validation Loss: 6.074e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6988, Training Loss: 3.478e-02, Validation Loss: 6.074e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6989, Training Loss: 3.477e-02, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6990, Training Loss: 3.476e-02, Validation Loss: 6.074e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6991, Training Loss: 3.476e-02, Validation Loss: 6.074e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6992, Training Loss: 3.475e-02, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6993, Training Loss: 3.474e-02, Validation Loss: 6.074e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6994, Training Loss: 3.473e-02, Validation Loss: 6.075e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 6995, Training Loss: 3.472e-02, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6996, Training Loss: 3.472e-02, Validation Loss: 6.075e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6997, Training Loss: 3.471e-02, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 6998, Training Loss: 3.470e-02, Validation Loss: 6.075e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 6999, Training Loss: 3.469e-02, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7000, Training Loss: 3.468e-02, Validation Loss: 6.075e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7001, Training Loss: 3.468e-02, Validation Loss: 6.075e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7002, Training Loss: 3.467e-02, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7003, Training Loss: 3.466e-02, Validation Loss: 6.075e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7004, Training Loss: 3.465e-02, Validation Loss: 6.075e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7005, Training Loss: 3.464e-02, Validation Loss: 6.075e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7006, Training Loss: 3.464e-02, Validation Loss: 6.075e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7007, Training Loss: 3.463e-02, Validation Loss: 6.076e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7008, Training Loss: 3.462e-02, Validation Loss: 6.075e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7009, Training Loss: 3.461e-02, Validation Loss: 6.075e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7010, Training Loss: 3.460e-02, Validation Loss: 6.076e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7011, Training Loss: 3.460e-02, Validation Loss: 6.075e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7012, Training Loss: 3.459e-02, Validation Loss: 6.076e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7013, Training Loss: 3.458e-02, Validation Loss: 6.076e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7014, Training Loss: 3.457e-02, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7015, Training Loss: 3.456e-02, Validation Loss: 6.076e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7016, Training Loss: 3.456e-02, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7017, Training Loss: 3.455e-02, Validation Loss: 6.076e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7018, Training Loss: 3.454e-02, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7019, Training Loss: 3.453e-02, Validation Loss: 6.076e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7020, Training Loss: 3.452e-02, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7021, Training Loss: 3.452e-02, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7022, Training Loss: 3.451e-02, Validation Loss: 6.076e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7023, Training Loss: 3.450e-02, Validation Loss: 6.077e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7024, Training Loss: 3.449e-02, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7025, Training Loss: 3.449e-02, Validation Loss: 6.077e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7026, Training Loss: 3.448e-02, Validation Loss: 6.077e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7027, Training Loss: 3.447e-02, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7028, Training Loss: 3.446e-02, Validation Loss: 6.077e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7029, Training Loss: 3.445e-02, Validation Loss: 6.077e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7030, Training Loss: 3.445e-02, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7031, Training Loss: 3.444e-02, Validation Loss: 6.077e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7032, Training Loss: 3.443e-02, Validation Loss: 6.078e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7033, Training Loss: 3.442e-02, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7034, Training Loss: 3.442e-02, Validation Loss: 6.077e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7035, Training Loss: 3.441e-02, Validation Loss: 6.078e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7036, Training Loss: 3.440e-02, Validation Loss: 6.077e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7037, Training Loss: 3.439e-02, Validation Loss: 6.078e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7038, Training Loss: 3.438e-02, Validation Loss: 6.078e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7039, Training Loss: 3.438e-02, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7040, Training Loss: 3.437e-02, Validation Loss: 6.077e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7041, Training Loss: 3.436e-02, Validation Loss: 6.078e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7042, Training Loss: 3.435e-02, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7043, Training Loss: 3.434e-02, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7044, Training Loss: 3.434e-02, Validation Loss: 6.078e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7045, Training Loss: 3.433e-02, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7046, Training Loss: 3.432e-02, Validation Loss: 6.078e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7047, Training Loss: 3.431e-02, Validation Loss: 6.078e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7048, Training Loss: 3.430e-02, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7049, Training Loss: 3.430e-02, Validation Loss: 6.079e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7050, Training Loss: 3.429e-02, Validation Loss: 6.079e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7051, Training Loss: 3.428e-02, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7052, Training Loss: 3.427e-02, Validation Loss: 6.079e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7053, Training Loss: 3.427e-02, Validation Loss: 6.079e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7054, Training Loss: 3.426e-02, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7055, Training Loss: 3.425e-02, Validation Loss: 6.079e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7056, Training Loss: 3.424e-02, Validation Loss: 6.079e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7057, Training Loss: 3.423e-02, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7058, Training Loss: 3.423e-02, Validation Loss: 6.079e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7059, Training Loss: 3.422e-02, Validation Loss: 6.079e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7060, Training Loss: 3.421e-02, Validation Loss: 6.079e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7061, Training Loss: 3.420e-02, Validation Loss: 6.079e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7062, Training Loss: 3.420e-02, Validation Loss: 6.080e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7063, Training Loss: 3.419e-02, Validation Loss: 6.080e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 7064, Training Loss: 3.418e-02, Validation Loss: 6.079e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7065, Training Loss: 3.417e-02, Validation Loss: 6.080e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7066, Training Loss: 3.416e-02, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7067, Training Loss: 3.416e-02, Validation Loss: 6.080e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7068, Training Loss: 3.415e-02, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7069, Training Loss: 3.414e-02, Validation Loss: 6.080e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7070, Training Loss: 3.413e-02, Validation Loss: 6.081e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7071, Training Loss: 3.413e-02, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7072, Training Loss: 3.412e-02, Validation Loss: 6.080e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7073, Training Loss: 3.411e-02, Validation Loss: 6.081e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7074, Training Loss: 3.410e-02, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7075, Training Loss: 3.410e-02, Validation Loss: 6.080e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7076, Training Loss: 3.409e-02, Validation Loss: 6.081e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7077, Training Loss: 3.408e-02, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7078, Training Loss: 3.407e-02, Validation Loss: 6.081e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7079, Training Loss: 3.406e-02, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7080, Training Loss: 3.406e-02, Validation Loss: 6.081e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7081, Training Loss: 3.405e-02, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7082, Training Loss: 3.404e-02, Validation Loss: 6.081e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7083, Training Loss: 3.403e-02, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7084, Training Loss: 3.403e-02, Validation Loss: 6.081e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7085, Training Loss: 3.402e-02, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7086, Training Loss: 3.401e-02, Validation Loss: 6.081e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7087, Training Loss: 3.400e-02, Validation Loss: 6.082e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7088, Training Loss: 3.399e-02, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7089, Training Loss: 3.399e-02, Validation Loss: 6.082e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7090, Training Loss: 3.398e-02, Validation Loss: 6.082e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7091, Training Loss: 3.397e-02, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7092, Training Loss: 3.396e-02, Validation Loss: 6.082e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7093, Training Loss: 3.396e-02, Validation Loss: 6.082e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7094, Training Loss: 3.395e-02, Validation Loss: 6.082e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7095, Training Loss: 3.394e-02, Validation Loss: 6.082e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7096, Training Loss: 3.393e-02, Validation Loss: 6.082e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7097, Training Loss: 3.393e-02, Validation Loss: 6.082e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7098, Training Loss: 3.392e-02, Validation Loss: 6.082e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7099, Training Loss: 3.391e-02, Validation Loss: 6.082e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7100, Training Loss: 3.390e-02, Validation Loss: 6.083e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7101, Training Loss: 3.389e-02, Validation Loss: 6.082e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7102, Training Loss: 3.389e-02, Validation Loss: 6.083e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7103, Training Loss: 3.388e-02, Validation Loss: 6.083e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7104, Training Loss: 3.387e-02, Validation Loss: 6.082e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7105, Training Loss: 3.386e-02, Validation Loss: 6.083e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7106, Training Loss: 3.386e-02, Validation Loss: 6.083e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7107, Training Loss: 3.385e-02, Validation Loss: 6.082e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7108, Training Loss: 3.384e-02, Validation Loss: 6.083e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7109, Training Loss: 3.383e-02, Validation Loss: 6.083e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7110, Training Loss: 3.383e-02, Validation Loss: 6.083e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7111, Training Loss: 3.382e-02, Validation Loss: 6.083e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7112, Training Loss: 3.381e-02, Validation Loss: 6.083e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7113, Training Loss: 3.380e-02, Validation Loss: 6.083e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7114, Training Loss: 3.380e-02, Validation Loss: 6.084e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7115, Training Loss: 3.379e-02, Validation Loss: 6.083e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7116, Training Loss: 3.378e-02, Validation Loss: 6.084e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7117, Training Loss: 3.377e-02, Validation Loss: 6.084e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7118, Training Loss: 3.376e-02, Validation Loss: 6.083e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7119, Training Loss: 3.376e-02, Validation Loss: 6.084e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7120, Training Loss: 3.375e-02, Validation Loss: 6.084e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7121, Training Loss: 3.374e-02, Validation Loss: 6.083e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7122, Training Loss: 3.374e-02, Validation Loss: 6.084e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7123, Training Loss: 3.373e-02, Validation Loss: 6.085e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7124, Training Loss: 3.372e-02, Validation Loss: 6.084e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7125, Training Loss: 3.371e-02, Validation Loss: 6.084e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7126, Training Loss: 3.370e-02, Validation Loss: 6.084e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7127, Training Loss: 3.370e-02, Validation Loss: 6.085e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 7128, Training Loss: 3.369e-02, Validation Loss: 6.084e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7129, Training Loss: 3.368e-02, Validation Loss: 6.085e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7130, Training Loss: 3.367e-02, Validation Loss: 6.085e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7131, Training Loss: 3.367e-02, Validation Loss: 6.084e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7132, Training Loss: 3.366e-02, Validation Loss: 6.085e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7133, Training Loss: 3.365e-02, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7134, Training Loss: 3.364e-02, Validation Loss: 6.085e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7135, Training Loss: 3.364e-02, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7136, Training Loss: 3.363e-02, Validation Loss: 6.085e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7137, Training Loss: 3.362e-02, Validation Loss: 6.085e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7138, Training Loss: 3.361e-02, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7139, Training Loss: 3.361e-02, Validation Loss: 6.085e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7140, Training Loss: 3.360e-02, Validation Loss: 6.086e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7141, Training Loss: 3.359e-02, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7142, Training Loss: 3.358e-02, Validation Loss: 6.086e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7143, Training Loss: 3.358e-02, Validation Loss: 6.086e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7144, Training Loss: 3.357e-02, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7145, Training Loss: 3.356e-02, Validation Loss: 6.086e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7146, Training Loss: 3.355e-02, Validation Loss: 6.086e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7147, Training Loss: 3.355e-02, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7148, Training Loss: 3.354e-02, Validation Loss: 6.086e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7149, Training Loss: 3.353e-02, Validation Loss: 6.086e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7150, Training Loss: 3.352e-02, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7151, Training Loss: 3.352e-02, Validation Loss: 6.086e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7152, Training Loss: 3.351e-02, Validation Loss: 6.087e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7153, Training Loss: 3.350e-02, Validation Loss: 6.086e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7154, Training Loss: 3.349e-02, Validation Loss: 6.087e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7155, Training Loss: 3.349e-02, Validation Loss: 6.086e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7156, Training Loss: 3.348e-02, Validation Loss: 6.087e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7157, Training Loss: 3.347e-02, Validation Loss: 6.086e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7158, Training Loss: 3.346e-02, Validation Loss: 6.087e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7159, Training Loss: 3.346e-02, Validation Loss: 6.087e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7160, Training Loss: 3.345e-02, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7161, Training Loss: 3.344e-02, Validation Loss: 6.087e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7162, Training Loss: 3.343e-02, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7163, Training Loss: 3.343e-02, Validation Loss: 6.087e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7164, Training Loss: 3.342e-02, Validation Loss: 6.088e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7165, Training Loss: 3.341e-02, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7166, Training Loss: 3.340e-02, Validation Loss: 6.088e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7167, Training Loss: 3.340e-02, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7168, Training Loss: 3.339e-02, Validation Loss: 6.088e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7169, Training Loss: 3.338e-02, Validation Loss: 6.088e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7170, Training Loss: 3.337e-02, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7171, Training Loss: 3.337e-02, Validation Loss: 6.088e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7172, Training Loss: 3.336e-02, Validation Loss: 6.088e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7173, Training Loss: 3.335e-02, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7174, Training Loss: 3.334e-02, Validation Loss: 6.088e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7175, Training Loss: 3.334e-02, Validation Loss: 6.088e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7176, Training Loss: 3.333e-02, Validation Loss: 6.088e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7177, Training Loss: 3.332e-02, Validation Loss: 6.088e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7178, Training Loss: 3.331e-02, Validation Loss: 6.089e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7179, Training Loss: 3.331e-02, Validation Loss: 6.088e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7180, Training Loss: 3.330e-02, Validation Loss: 6.088e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7181, Training Loss: 3.329e-02, Validation Loss: 6.089e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7182, Training Loss: 3.328e-02, Validation Loss: 6.088e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7183, Training Loss: 3.328e-02, Validation Loss: 6.089e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7184, Training Loss: 3.327e-02, Validation Loss: 6.089e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7185, Training Loss: 3.326e-02, Validation Loss: 6.089e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7186, Training Loss: 3.325e-02, Validation Loss: 6.089e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7187, Training Loss: 3.325e-02, Validation Loss: 6.089e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7188, Training Loss: 3.324e-02, Validation Loss: 6.089e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7189, Training Loss: 3.323e-02, Validation Loss: 6.089e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7190, Training Loss: 3.322e-02, Validation Loss: 6.089e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7191, Training Loss: 3.322e-02, Validation Loss: 6.090e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7192, Training Loss: 3.321e-02, Validation Loss: 6.089e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7193, Training Loss: 3.320e-02, Validation Loss: 6.090e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7194, Training Loss: 3.319e-02, Validation Loss: 6.090e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7195, Training Loss: 3.319e-02, Validation Loss: 6.089e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7196, Training Loss: 3.318e-02, Validation Loss: 6.090e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7197, Training Loss: 3.317e-02, Validation Loss: 6.090e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7198, Training Loss: 3.317e-02, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7199, Training Loss: 3.316e-02, Validation Loss: 6.090e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7200, Training Loss: 3.315e-02, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7201, Training Loss: 3.314e-02, Validation Loss: 6.091e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7202, Training Loss: 3.314e-02, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7203, Training Loss: 3.313e-02, Validation Loss: 6.090e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7204, Training Loss: 3.312e-02, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7205, Training Loss: 3.311e-02, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7206, Training Loss: 3.311e-02, Validation Loss: 6.090e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7207, Training Loss: 3.310e-02, Validation Loss: 6.091e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7208, Training Loss: 3.309e-02, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7209, Training Loss: 3.308e-02, Validation Loss: 6.091e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7210, Training Loss: 3.308e-02, Validation Loss: 6.091e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7211, Training Loss: 3.307e-02, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7212, Training Loss: 3.306e-02, Validation Loss: 6.091e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7213, Training Loss: 3.305e-02, Validation Loss: 6.091e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7214, Training Loss: 3.305e-02, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7215, Training Loss: 3.304e-02, Validation Loss: 6.091e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7216, Training Loss: 3.303e-02, Validation Loss: 6.091e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7217, Training Loss: 3.303e-02, Validation Loss: 6.091e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7218, Training Loss: 3.302e-02, Validation Loss: 6.092e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7219, Training Loss: 3.301e-02, Validation Loss: 6.092e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7220, Training Loss: 3.300e-02, Validation Loss: 6.091e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7221, Training Loss: 3.300e-02, Validation Loss: 6.092e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7222, Training Loss: 3.299e-02, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7223, Training Loss: 3.298e-02, Validation Loss: 6.091e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7224, Training Loss: 3.297e-02, Validation Loss: 6.092e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7225, Training Loss: 3.297e-02, Validation Loss: 6.093e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7226, Training Loss: 3.296e-02, Validation Loss: 6.091e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7227, Training Loss: 3.295e-02, Validation Loss: 6.092e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7228, Training Loss: 3.295e-02, Validation Loss: 6.092e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7229, Training Loss: 3.294e-02, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7230, Training Loss: 3.293e-02, Validation Loss: 6.092e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7231, Training Loss: 3.292e-02, Validation Loss: 6.093e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7232, Training Loss: 3.292e-02, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7233, Training Loss: 3.291e-02, Validation Loss: 6.093e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7234, Training Loss: 3.290e-02, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7235, Training Loss: 3.289e-02, Validation Loss: 6.093e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7236, Training Loss: 3.289e-02, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7237, Training Loss: 3.288e-02, Validation Loss: 6.093e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7238, Training Loss: 3.287e-02, Validation Loss: 6.093e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7239, Training Loss: 3.287e-02, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7240, Training Loss: 3.286e-02, Validation Loss: 6.093e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7241, Training Loss: 3.285e-02, Validation Loss: 6.093e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7242, Training Loss: 3.284e-02, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7243, Training Loss: 3.284e-02, Validation Loss: 6.093e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7244, Training Loss: 3.283e-02, Validation Loss: 6.094e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7245, Training Loss: 3.282e-02, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7246, Training Loss: 3.281e-02, Validation Loss: 6.094e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7247, Training Loss: 3.281e-02, Validation Loss: 6.094e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7248, Training Loss: 3.280e-02, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7249, Training Loss: 3.279e-02, Validation Loss: 6.094e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7250, Training Loss: 3.279e-02, Validation Loss: 6.094e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7251, Training Loss: 3.278e-02, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7252, Training Loss: 3.277e-02, Validation Loss: 6.094e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7253, Training Loss: 3.276e-02, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7254, Training Loss: 3.276e-02, Validation Loss: 6.095e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7255, Training Loss: 3.275e-02, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7256, Training Loss: 3.274e-02, Validation Loss: 6.095e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7257, Training Loss: 3.273e-02, Validation Loss: 6.095e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7258, Training Loss: 3.273e-02, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7259, Training Loss: 3.272e-02, Validation Loss: 6.095e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7260, Training Loss: 3.271e-02, Validation Loss: 6.095e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7261, Training Loss: 3.271e-02, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7262, Training Loss: 3.270e-02, Validation Loss: 6.095e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7263, Training Loss: 3.269e-02, Validation Loss: 6.095e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7264, Training Loss: 3.268e-02, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7265, Training Loss: 3.268e-02, Validation Loss: 6.095e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7266, Training Loss: 3.267e-02, Validation Loss: 6.096e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7267, Training Loss: 3.266e-02, Validation Loss: 6.095e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7268, Training Loss: 3.266e-02, Validation Loss: 6.095e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7269, Training Loss: 3.265e-02, Validation Loss: 6.096e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7270, Training Loss: 3.264e-02, Validation Loss: 6.095e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7271, Training Loss: 3.263e-02, Validation Loss: 6.096e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7272, Training Loss: 3.263e-02, Validation Loss: 6.095e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7273, Training Loss: 3.262e-02, Validation Loss: 6.096e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7274, Training Loss: 3.261e-02, Validation Loss: 6.095e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7275, Training Loss: 3.261e-02, Validation Loss: 6.096e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7276, Training Loss: 3.260e-02, Validation Loss: 6.096e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7277, Training Loss: 3.259e-02, Validation Loss: 6.096e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7278, Training Loss: 3.258e-02, Validation Loss: 6.096e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7279, Training Loss: 3.258e-02, Validation Loss: 6.096e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7280, Training Loss: 3.257e-02, Validation Loss: 6.096e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7281, Training Loss: 3.256e-02, Validation Loss: 6.096e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7282, Training Loss: 3.256e-02, Validation Loss: 6.096e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7283, Training Loss: 3.255e-02, Validation Loss: 6.097e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7284, Training Loss: 3.254e-02, Validation Loss: 6.096e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7285, Training Loss: 3.253e-02, Validation Loss: 6.097e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7286, Training Loss: 3.253e-02, Validation Loss: 6.097e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7287, Training Loss: 3.252e-02, Validation Loss: 6.096e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7288, Training Loss: 3.251e-02, Validation Loss: 6.097e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7289, Training Loss: 3.251e-02, Validation Loss: 6.097e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7290, Training Loss: 3.250e-02, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7291, Training Loss: 3.249e-02, Validation Loss: 6.097e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7292, Training Loss: 3.248e-02, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7293, Training Loss: 3.248e-02, Validation Loss: 6.097e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7294, Training Loss: 3.247e-02, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7295, Training Loss: 3.246e-02, Validation Loss: 6.098e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7296, Training Loss: 3.245e-02, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7297, Training Loss: 3.245e-02, Validation Loss: 6.098e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7298, Training Loss: 3.244e-02, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7299, Training Loss: 3.243e-02, Validation Loss: 6.098e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7300, Training Loss: 3.243e-02, Validation Loss: 6.098e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7301, Training Loss: 3.242e-02, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7302, Training Loss: 3.241e-02, Validation Loss: 6.098e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7303, Training Loss: 3.241e-02, Validation Loss: 6.098e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7304, Training Loss: 3.240e-02, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7305, Training Loss: 3.239e-02, Validation Loss: 6.098e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7306, Training Loss: 3.238e-02, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7307, Training Loss: 3.238e-02, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7308, Training Loss: 3.237e-02, Validation Loss: 6.098e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7309, Training Loss: 3.236e-02, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7310, Training Loss: 3.236e-02, Validation Loss: 6.099e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7311, Training Loss: 3.235e-02, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7312, Training Loss: 3.234e-02, Validation Loss: 6.099e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7313, Training Loss: 3.233e-02, Validation Loss: 6.099e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7314, Training Loss: 3.233e-02, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7315, Training Loss: 3.232e-02, Validation Loss: 6.099e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7316, Training Loss: 3.231e-02, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7317, Training Loss: 3.231e-02, Validation Loss: 6.099e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7318, Training Loss: 3.230e-02, Validation Loss: 6.099e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7319, Training Loss: 3.229e-02, Validation Loss: 6.099e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7320, Training Loss: 3.229e-02, Validation Loss: 6.099e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7321, Training Loss: 3.228e-02, Validation Loss: 6.100e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7322, Training Loss: 3.227e-02, Validation Loss: 6.099e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7323, Training Loss: 3.226e-02, Validation Loss: 6.100e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7324, Training Loss: 3.226e-02, Validation Loss: 6.100e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7325, Training Loss: 3.225e-02, Validation Loss: 6.099e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7326, Training Loss: 3.224e-02, Validation Loss: 6.099e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7327, Training Loss: 3.224e-02, Validation Loss: 6.100e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7328, Training Loss: 3.223e-02, Validation Loss: 6.100e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7329, Training Loss: 3.222e-02, Validation Loss: 6.099e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7330, Training Loss: 3.222e-02, Validation Loss: 6.100e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7331, Training Loss: 3.221e-02, Validation Loss: 6.100e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7332, Training Loss: 3.220e-02, Validation Loss: 6.100e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7333, Training Loss: 3.219e-02, Validation Loss: 6.100e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7334, Training Loss: 3.219e-02, Validation Loss: 6.100e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7335, Training Loss: 3.218e-02, Validation Loss: 6.100e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7336, Training Loss: 3.217e-02, Validation Loss: 6.100e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7337, Training Loss: 3.217e-02, Validation Loss: 6.101e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7338, Training Loss: 3.216e-02, Validation Loss: 6.100e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7339, Training Loss: 3.215e-02, Validation Loss: 6.101e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7340, Training Loss: 3.214e-02, Validation Loss: 6.101e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7341, Training Loss: 3.214e-02, Validation Loss: 6.101e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7342, Training Loss: 3.213e-02, Validation Loss: 6.101e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7343, Training Loss: 3.212e-02, Validation Loss: 6.101e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7344, Training Loss: 3.212e-02, Validation Loss: 6.101e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7345, Training Loss: 3.211e-02, Validation Loss: 6.100e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7346, Training Loss: 3.210e-02, Validation Loss: 6.101e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7347, Training Loss: 3.210e-02, Validation Loss: 6.102e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7348, Training Loss: 3.209e-02, Validation Loss: 6.101e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7349, Training Loss: 3.208e-02, Validation Loss: 6.101e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7350, Training Loss: 3.208e-02, Validation Loss: 6.102e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7351, Training Loss: 3.207e-02, Validation Loss: 6.101e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7352, Training Loss: 3.206e-02, Validation Loss: 6.102e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7353, Training Loss: 3.205e-02, Validation Loss: 6.102e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7354, Training Loss: 3.205e-02, Validation Loss: 6.101e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7355, Training Loss: 3.204e-02, Validation Loss: 6.102e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7356, Training Loss: 3.203e-02, Validation Loss: 6.102e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7357, Training Loss: 3.203e-02, Validation Loss: 6.101e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7358, Training Loss: 3.202e-02, Validation Loss: 6.102e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7359, Training Loss: 3.201e-02, Validation Loss: 6.103e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7360, Training Loss: 3.201e-02, Validation Loss: 6.102e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7361, Training Loss: 3.200e-02, Validation Loss: 6.103e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7362, Training Loss: 3.199e-02, Validation Loss: 6.103e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7363, Training Loss: 3.198e-02, Validation Loss: 6.102e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7364, Training Loss: 3.198e-02, Validation Loss: 6.103e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7365, Training Loss: 3.197e-02, Validation Loss: 6.103e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7366, Training Loss: 3.196e-02, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7367, Training Loss: 3.196e-02, Validation Loss: 6.103e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7368, Training Loss: 3.195e-02, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7369, Training Loss: 3.194e-02, Validation Loss: 6.103e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7370, Training Loss: 3.194e-02, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7371, Training Loss: 3.193e-02, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7372, Training Loss: 3.192e-02, Validation Loss: 6.103e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7373, Training Loss: 3.192e-02, Validation Loss: 6.104e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7374, Training Loss: 3.191e-02, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7375, Training Loss: 3.190e-02, Validation Loss: 6.103e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7376, Training Loss: 3.190e-02, Validation Loss: 6.104e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7377, Training Loss: 3.189e-02, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7378, Training Loss: 3.188e-02, Validation Loss: 6.104e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7379, Training Loss: 3.187e-02, Validation Loss: 6.104e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7380, Training Loss: 3.187e-02, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7381, Training Loss: 3.186e-02, Validation Loss: 6.104e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7382, Training Loss: 3.185e-02, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7383, Training Loss: 3.185e-02, Validation Loss: 6.104e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7384, Training Loss: 3.184e-02, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7385, Training Loss: 3.183e-02, Validation Loss: 6.105e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7386, Training Loss: 3.183e-02, Validation Loss: 6.105e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7387, Training Loss: 3.182e-02, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7388, Training Loss: 3.181e-02, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7389, Training Loss: 3.181e-02, Validation Loss: 6.105e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7390, Training Loss: 3.180e-02, Validation Loss: 6.105e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7391, Training Loss: 3.179e-02, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7392, Training Loss: 3.179e-02, Validation Loss: 6.105e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7393, Training Loss: 3.178e-02, Validation Loss: 6.105e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7394, Training Loss: 3.177e-02, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7395, Training Loss: 3.176e-02, Validation Loss: 6.105e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7396, Training Loss: 3.176e-02, Validation Loss: 6.106e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7397, Training Loss: 3.175e-02, Validation Loss: 6.105e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7398, Training Loss: 3.174e-02, Validation Loss: 6.105e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7399, Training Loss: 3.174e-02, Validation Loss: 6.105e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7400, Training Loss: 3.173e-02, Validation Loss: 6.106e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7401, Training Loss: 3.172e-02, Validation Loss: 6.106e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7402, Training Loss: 3.172e-02, Validation Loss: 6.105e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7403, Training Loss: 3.171e-02, Validation Loss: 6.105e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7404, Training Loss: 3.170e-02, Validation Loss: 6.106e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7405, Training Loss: 3.170e-02, Validation Loss: 6.106e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7406, Training Loss: 3.169e-02, Validation Loss: 6.106e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7407, Training Loss: 3.168e-02, Validation Loss: 6.106e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7408, Training Loss: 3.168e-02, Validation Loss: 6.107e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7409, Training Loss: 3.167e-02, Validation Loss: 6.105e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7410, Training Loss: 3.166e-02, Validation Loss: 6.106e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7411, Training Loss: 3.165e-02, Validation Loss: 6.106e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7412, Training Loss: 3.165e-02, Validation Loss: 6.106e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7413, Training Loss: 3.164e-02, Validation Loss: 6.107e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7414, Training Loss: 3.163e-02, Validation Loss: 6.107e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7415, Training Loss: 3.163e-02, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7416, Training Loss: 3.162e-02, Validation Loss: 6.107e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7417, Training Loss: 3.161e-02, Validation Loss: 6.106e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7418, Training Loss: 3.161e-02, Validation Loss: 6.107e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7419, Training Loss: 3.160e-02, Validation Loss: 6.107e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7420, Training Loss: 3.159e-02, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7421, Training Loss: 3.159e-02, Validation Loss: 6.107e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7422, Training Loss: 3.158e-02, Validation Loss: 6.108e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7423, Training Loss: 3.157e-02, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7424, Training Loss: 3.157e-02, Validation Loss: 6.107e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7425, Training Loss: 3.156e-02, Validation Loss: 6.108e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7426, Training Loss: 3.155e-02, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7427, Training Loss: 3.155e-02, Validation Loss: 6.107e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7428, Training Loss: 3.154e-02, Validation Loss: 6.108e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7429, Training Loss: 3.153e-02, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7430, Training Loss: 3.153e-02, Validation Loss: 6.108e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7431, Training Loss: 3.152e-02, Validation Loss: 6.108e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7432, Training Loss: 3.151e-02, Validation Loss: 6.108e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7433, Training Loss: 3.151e-02, Validation Loss: 6.108e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7434, Training Loss: 3.150e-02, Validation Loss: 6.108e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7435, Training Loss: 3.149e-02, Validation Loss: 6.108e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7436, Training Loss: 3.149e-02, Validation Loss: 6.108e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7437, Training Loss: 3.148e-02, Validation Loss: 6.108e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7438, Training Loss: 3.147e-02, Validation Loss: 6.109e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7439, Training Loss: 3.147e-02, Validation Loss: 6.108e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7440, Training Loss: 3.146e-02, Validation Loss: 6.109e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7441, Training Loss: 3.145e-02, Validation Loss: 6.109e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7442, Training Loss: 3.144e-02, Validation Loss: 6.108e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7443, Training Loss: 3.144e-02, Validation Loss: 6.109e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7444, Training Loss: 3.143e-02, Validation Loss: 6.109e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7445, Training Loss: 3.142e-02, Validation Loss: 6.108e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7446, Training Loss: 3.142e-02, Validation Loss: 6.109e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7447, Training Loss: 3.141e-02, Validation Loss: 6.110e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7448, Training Loss: 3.140e-02, Validation Loss: 6.108e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7449, Training Loss: 3.140e-02, Validation Loss: 6.109e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7450, Training Loss: 3.139e-02, Validation Loss: 6.110e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7451, Training Loss: 3.138e-02, Validation Loss: 6.109e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7452, Training Loss: 3.138e-02, Validation Loss: 6.110e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7453, Training Loss: 3.137e-02, Validation Loss: 6.110e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7454, Training Loss: 3.136e-02, Validation Loss: 6.109e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7455, Training Loss: 3.136e-02, Validation Loss: 6.110e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7456, Training Loss: 3.135e-02, Validation Loss: 6.110e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7457, Training Loss: 3.134e-02, Validation Loss: 6.109e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7458, Training Loss: 3.134e-02, Validation Loss: 6.110e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7459, Training Loss: 3.133e-02, Validation Loss: 6.110e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7460, Training Loss: 3.132e-02, Validation Loss: 6.109e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7461, Training Loss: 3.132e-02, Validation Loss: 6.110e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7462, Training Loss: 3.131e-02, Validation Loss: 6.111e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7463, Training Loss: 3.130e-02, Validation Loss: 6.110e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7464, Training Loss: 3.130e-02, Validation Loss: 6.111e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7465, Training Loss: 3.129e-02, Validation Loss: 6.110e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7466, Training Loss: 3.128e-02, Validation Loss: 6.110e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7467, Training Loss: 3.128e-02, Validation Loss: 6.111e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7468, Training Loss: 3.127e-02, Validation Loss: 6.111e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7469, Training Loss: 3.126e-02, Validation Loss: 6.111e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7470, Training Loss: 3.126e-02, Validation Loss: 6.111e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7471, Training Loss: 3.125e-02, Validation Loss: 6.111e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7472, Training Loss: 3.124e-02, Validation Loss: 6.111e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7473, Training Loss: 3.124e-02, Validation Loss: 6.110e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7474, Training Loss: 3.123e-02, Validation Loss: 6.111e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7475, Training Loss: 3.122e-02, Validation Loss: 6.111e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7476, Training Loss: 3.122e-02, Validation Loss: 6.111e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7477, Training Loss: 3.121e-02, Validation Loss: 6.112e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7478, Training Loss: 3.120e-02, Validation Loss: 6.111e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7479, Training Loss: 3.120e-02, Validation Loss: 6.112e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7480, Training Loss: 3.119e-02, Validation Loss: 6.112e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7481, Training Loss: 3.118e-02, Validation Loss: 6.111e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7482, Training Loss: 3.118e-02, Validation Loss: 6.112e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7483, Training Loss: 3.117e-02, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7484, Training Loss: 3.116e-02, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7485, Training Loss: 3.116e-02, Validation Loss: 6.112e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7486, Training Loss: 3.115e-02, Validation Loss: 6.112e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7487, Training Loss: 3.114e-02, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7488, Training Loss: 3.114e-02, Validation Loss: 6.112e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7489, Training Loss: 3.113e-02, Validation Loss: 6.113e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7490, Training Loss: 3.112e-02, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7491, Training Loss: 3.112e-02, Validation Loss: 6.113e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7492, Training Loss: 3.111e-02, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7493, Training Loss: 3.110e-02, Validation Loss: 6.113e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7494, Training Loss: 3.110e-02, Validation Loss: 6.113e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7495, Training Loss: 3.109e-02, Validation Loss: 6.113e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 7496, Training Loss: 3.108e-02, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7497, Training Loss: 3.108e-02, Validation Loss: 6.113e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7498, Training Loss: 3.107e-02, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7499, Training Loss: 3.106e-02, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7500, Training Loss: 3.106e-02, Validation Loss: 6.113e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7501, Training Loss: 3.105e-02, Validation Loss: 6.114e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7502, Training Loss: 3.105e-02, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7503, Training Loss: 3.104e-02, Validation Loss: 6.113e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7504, Training Loss: 3.103e-02, Validation Loss: 6.114e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7505, Training Loss: 3.103e-02, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7506, Training Loss: 3.102e-02, Validation Loss: 6.114e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7507, Training Loss: 3.101e-02, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7508, Training Loss: 3.101e-02, Validation Loss: 6.114e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7509, Training Loss: 3.100e-02, Validation Loss: 6.114e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7510, Training Loss: 3.099e-02, Validation Loss: 6.114e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7511, Training Loss: 3.099e-02, Validation Loss: 6.114e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7512, Training Loss: 3.098e-02, Validation Loss: 6.114e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7513, Training Loss: 3.097e-02, Validation Loss: 6.114e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7514, Training Loss: 3.097e-02, Validation Loss: 6.114e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7515, Training Loss: 3.096e-02, Validation Loss: 6.115e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7516, Training Loss: 3.095e-02, Validation Loss: 6.114e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7517, Training Loss: 3.095e-02, Validation Loss: 6.114e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7518, Training Loss: 3.094e-02, Validation Loss: 6.115e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7519, Training Loss: 3.093e-02, Validation Loss: 6.114e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7520, Training Loss: 3.093e-02, Validation Loss: 6.115e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7521, Training Loss: 3.092e-02, Validation Loss: 6.115e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7522, Training Loss: 3.091e-02, Validation Loss: 6.115e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7523, Training Loss: 3.091e-02, Validation Loss: 6.115e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7524, Training Loss: 3.090e-02, Validation Loss: 6.115e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7525, Training Loss: 3.089e-02, Validation Loss: 6.115e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7526, Training Loss: 3.089e-02, Validation Loss: 6.115e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 7527, Training Loss: 3.088e-02, Validation Loss: 6.115e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7528, Training Loss: 3.087e-02, Validation Loss: 6.116e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7529, Training Loss: 3.087e-02, Validation Loss: 6.116e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7530, Training Loss: 3.086e-02, Validation Loss: 6.115e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7531, Training Loss: 3.085e-02, Validation Loss: 6.116e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7532, Training Loss: 3.085e-02, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7533, Training Loss: 3.084e-02, Validation Loss: 6.115e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7534, Training Loss: 3.084e-02, Validation Loss: 6.116e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7535, Training Loss: 3.083e-02, Validation Loss: 6.116e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7536, Training Loss: 3.082e-02, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7537, Training Loss: 3.082e-02, Validation Loss: 6.116e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7538, Training Loss: 3.081e-02, Validation Loss: 6.116e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7539, Training Loss: 3.080e-02, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7540, Training Loss: 3.080e-02, Validation Loss: 6.117e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7541, Training Loss: 3.079e-02, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7542, Training Loss: 3.078e-02, Validation Loss: 6.116e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7543, Training Loss: 3.078e-02, Validation Loss: 6.116e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7544, Training Loss: 3.077e-02, Validation Loss: 6.117e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 7545, Training Loss: 3.076e-02, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7546, Training Loss: 3.076e-02, Validation Loss: 6.117e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7547, Training Loss: 3.075e-02, Validation Loss: 6.117e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7548, Training Loss: 3.074e-02, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7549, Training Loss: 3.074e-02, Validation Loss: 6.117e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7550, Training Loss: 3.073e-02, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7551, Training Loss: 3.072e-02, Validation Loss: 6.117e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7552, Training Loss: 3.072e-02, Validation Loss: 6.118e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7553, Training Loss: 3.071e-02, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7554, Training Loss: 3.071e-02, Validation Loss: 6.117e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7555, Training Loss: 3.070e-02, Validation Loss: 6.118e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7556, Training Loss: 3.069e-02, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7557, Training Loss: 3.069e-02, Validation Loss: 6.118e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7558, Training Loss: 3.068e-02, Validation Loss: 6.118e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7559, Training Loss: 3.067e-02, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7560, Training Loss: 3.067e-02, Validation Loss: 6.118e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7561, Training Loss: 3.066e-02, Validation Loss: 6.118e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7562, Training Loss: 3.065e-02, Validation Loss: 6.118e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7563, Training Loss: 3.065e-02, Validation Loss: 6.118e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7564, Training Loss: 3.064e-02, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7565, Training Loss: 3.063e-02, Validation Loss: 6.119e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7566, Training Loss: 3.063e-02, Validation Loss: 6.118e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7567, Training Loss: 3.062e-02, Validation Loss: 6.118e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7568, Training Loss: 3.062e-02, Validation Loss: 6.118e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7569, Training Loss: 3.061e-02, Validation Loss: 6.119e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7570, Training Loss: 3.060e-02, Validation Loss: 6.118e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7571, Training Loss: 3.060e-02, Validation Loss: 6.119e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7572, Training Loss: 3.059e-02, Validation Loss: 6.119e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7573, Training Loss: 3.058e-02, Validation Loss: 6.119e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7574, Training Loss: 3.058e-02, Validation Loss: 6.118e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7575, Training Loss: 3.057e-02, Validation Loss: 6.119e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7576, Training Loss: 3.056e-02, Validation Loss: 6.119e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7577, Training Loss: 3.056e-02, Validation Loss: 6.119e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 7578, Training Loss: 3.055e-02, Validation Loss: 6.119e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7579, Training Loss: 3.054e-02, Validation Loss: 6.119e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7580, Training Loss: 3.054e-02, Validation Loss: 6.120e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7581, Training Loss: 3.053e-02, Validation Loss: 6.119e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7582, Training Loss: 3.053e-02, Validation Loss: 6.119e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7583, Training Loss: 3.052e-02, Validation Loss: 6.120e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7584, Training Loss: 3.051e-02, Validation Loss: 6.119e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7585, Training Loss: 3.051e-02, Validation Loss: 6.119e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7586, Training Loss: 3.050e-02, Validation Loss: 6.120e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7587, Training Loss: 3.049e-02, Validation Loss: 6.120e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7588, Training Loss: 3.049e-02, Validation Loss: 6.120e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7589, Training Loss: 3.048e-02, Validation Loss: 6.120e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7590, Training Loss: 3.047e-02, Validation Loss: 6.120e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7591, Training Loss: 3.047e-02, Validation Loss: 6.121e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7592, Training Loss: 3.046e-02, Validation Loss: 6.120e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7593, Training Loss: 3.045e-02, Validation Loss: 6.121e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7594, Training Loss: 3.045e-02, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7595, Training Loss: 3.044e-02, Validation Loss: 6.120e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7596, Training Loss: 3.044e-02, Validation Loss: 6.121e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7597, Training Loss: 3.043e-02, Validation Loss: 6.120e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7598, Training Loss: 3.042e-02, Validation Loss: 6.121e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7599, Training Loss: 3.042e-02, Validation Loss: 6.121e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7600, Training Loss: 3.041e-02, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7601, Training Loss: 3.040e-02, Validation Loss: 6.121e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7602, Training Loss: 3.040e-02, Validation Loss: 6.120e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7603, Training Loss: 3.039e-02, Validation Loss: 6.121e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7604, Training Loss: 3.038e-02, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7605, Training Loss: 3.038e-02, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7606, Training Loss: 3.037e-02, Validation Loss: 6.121e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7607, Training Loss: 3.037e-02, Validation Loss: 6.122e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7608, Training Loss: 3.036e-02, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7609, Training Loss: 3.035e-02, Validation Loss: 6.121e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7610, Training Loss: 3.035e-02, Validation Loss: 6.122e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7611, Training Loss: 3.034e-02, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7612, Training Loss: 3.033e-02, Validation Loss: 6.122e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7613, Training Loss: 3.033e-02, Validation Loss: 6.122e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7614, Training Loss: 3.032e-02, Validation Loss: 6.122e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7615, Training Loss: 3.032e-02, Validation Loss: 6.122e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7616, Training Loss: 3.031e-02, Validation Loss: 6.122e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7617, Training Loss: 3.030e-02, Validation Loss: 6.122e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 7618, Training Loss: 3.030e-02, Validation Loss: 6.122e-01, Patience: 4, Learning Rate: 0.01\n",
      "Epoch 7619, Training Loss: 3.029e-02, Validation Loss: 6.122e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7620, Training Loss: 3.028e-02, Validation Loss: 6.123e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7621, Training Loss: 3.028e-02, Validation Loss: 6.123e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7622, Training Loss: 3.027e-02, Validation Loss: 6.122e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7623, Training Loss: 3.026e-02, Validation Loss: 6.123e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7624, Training Loss: 3.026e-02, Validation Loss: 6.123e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7625, Training Loss: 3.025e-02, Validation Loss: 6.122e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7626, Training Loss: 3.025e-02, Validation Loss: 6.123e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7627, Training Loss: 3.024e-02, Validation Loss: 6.123e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7628, Training Loss: 3.023e-02, Validation Loss: 6.122e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7629, Training Loss: 3.023e-02, Validation Loss: 6.123e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7630, Training Loss: 3.022e-02, Validation Loss: 6.123e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7631, Training Loss: 3.021e-02, Validation Loss: 6.123e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7632, Training Loss: 3.021e-02, Validation Loss: 6.123e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7633, Training Loss: 3.020e-02, Validation Loss: 6.124e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7634, Training Loss: 3.020e-02, Validation Loss: 6.123e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7635, Training Loss: 3.019e-02, Validation Loss: 6.124e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7636, Training Loss: 3.018e-02, Validation Loss: 6.124e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7637, Training Loss: 3.018e-02, Validation Loss: 6.123e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7638, Training Loss: 3.017e-02, Validation Loss: 6.124e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7639, Training Loss: 3.016e-02, Validation Loss: 6.124e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7640, Training Loss: 3.016e-02, Validation Loss: 6.124e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7641, Training Loss: 3.015e-02, Validation Loss: 6.124e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7642, Training Loss: 3.014e-02, Validation Loss: 6.124e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7643, Training Loss: 3.014e-02, Validation Loss: 6.124e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7644, Training Loss: 3.013e-02, Validation Loss: 6.124e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7645, Training Loss: 3.013e-02, Validation Loss: 6.124e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7646, Training Loss: 3.012e-02, Validation Loss: 6.125e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7647, Training Loss: 3.011e-02, Validation Loss: 6.125e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 7648, Training Loss: 3.011e-02, Validation Loss: 6.124e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7649, Training Loss: 3.010e-02, Validation Loss: 6.125e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7650, Training Loss: 3.009e-02, Validation Loss: 6.125e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7651, Training Loss: 3.009e-02, Validation Loss: 6.124e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7652, Training Loss: 3.008e-02, Validation Loss: 6.125e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7653, Training Loss: 3.008e-02, Validation Loss: 6.125e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7654, Training Loss: 3.007e-02, Validation Loss: 6.125e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7655, Training Loss: 3.006e-02, Validation Loss: 6.125e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7656, Training Loss: 3.006e-02, Validation Loss: 6.125e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7657, Training Loss: 3.005e-02, Validation Loss: 6.125e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7658, Training Loss: 3.005e-02, Validation Loss: 6.125e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7659, Training Loss: 3.004e-02, Validation Loss: 6.126e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7660, Training Loss: 3.003e-02, Validation Loss: 6.125e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7661, Training Loss: 3.003e-02, Validation Loss: 6.126e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7662, Training Loss: 3.002e-02, Validation Loss: 6.126e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7663, Training Loss: 3.001e-02, Validation Loss: 6.125e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7664, Training Loss: 3.001e-02, Validation Loss: 6.126e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7665, Training Loss: 3.000e-02, Validation Loss: 6.126e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7666, Training Loss: 3.000e-02, Validation Loss: 6.125e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7667, Training Loss: 2.999e-02, Validation Loss: 6.126e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7668, Training Loss: 2.998e-02, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7669, Training Loss: 2.998e-02, Validation Loss: 6.126e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7670, Training Loss: 2.997e-02, Validation Loss: 6.127e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7671, Training Loss: 2.996e-02, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7672, Training Loss: 2.996e-02, Validation Loss: 6.127e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7673, Training Loss: 2.995e-02, Validation Loss: 6.127e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7674, Training Loss: 2.995e-02, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7675, Training Loss: 2.994e-02, Validation Loss: 6.127e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7676, Training Loss: 2.993e-02, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7677, Training Loss: 2.993e-02, Validation Loss: 6.127e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7678, Training Loss: 2.992e-02, Validation Loss: 6.127e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7679, Training Loss: 2.991e-02, Validation Loss: 6.127e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7680, Training Loss: 2.991e-02, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7681, Training Loss: 2.990e-02, Validation Loss: 6.127e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7682, Training Loss: 2.990e-02, Validation Loss: 6.127e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7683, Training Loss: 2.989e-02, Validation Loss: 6.127e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7684, Training Loss: 2.988e-02, Validation Loss: 6.128e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7685, Training Loss: 2.988e-02, Validation Loss: 6.128e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7686, Training Loss: 2.987e-02, Validation Loss: 6.127e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7687, Training Loss: 2.986e-02, Validation Loss: 6.128e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7688, Training Loss: 2.986e-02, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7689, Training Loss: 2.985e-02, Validation Loss: 6.127e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7690, Training Loss: 2.985e-02, Validation Loss: 6.128e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7691, Training Loss: 2.984e-02, Validation Loss: 6.128e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7692, Training Loss: 2.983e-02, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7693, Training Loss: 2.983e-02, Validation Loss: 6.128e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7694, Training Loss: 2.982e-02, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7695, Training Loss: 2.982e-02, Validation Loss: 6.129e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7696, Training Loss: 2.981e-02, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7697, Training Loss: 2.980e-02, Validation Loss: 6.128e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7698, Training Loss: 2.980e-02, Validation Loss: 6.129e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7699, Training Loss: 2.979e-02, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7700, Training Loss: 2.978e-02, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7701, Training Loss: 2.978e-02, Validation Loss: 6.129e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7702, Training Loss: 2.977e-02, Validation Loss: 6.129e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7703, Training Loss: 2.977e-02, Validation Loss: 6.129e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7704, Training Loss: 2.976e-02, Validation Loss: 6.129e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7705, Training Loss: 2.975e-02, Validation Loss: 6.129e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7706, Training Loss: 2.975e-02, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7707, Training Loss: 2.974e-02, Validation Loss: 6.129e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7708, Training Loss: 2.974e-02, Validation Loss: 6.129e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7709, Training Loss: 2.973e-02, Validation Loss: 6.129e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7710, Training Loss: 2.972e-02, Validation Loss: 6.129e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7711, Training Loss: 2.972e-02, Validation Loss: 6.130e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7712, Training Loss: 2.971e-02, Validation Loss: 6.129e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7713, Training Loss: 2.971e-02, Validation Loss: 6.130e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7714, Training Loss: 2.970e-02, Validation Loss: 6.129e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7715, Training Loss: 2.969e-02, Validation Loss: 6.130e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7716, Training Loss: 2.969e-02, Validation Loss: 6.130e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7717, Training Loss: 2.968e-02, Validation Loss: 6.129e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7718, Training Loss: 2.967e-02, Validation Loss: 6.130e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7719, Training Loss: 2.967e-02, Validation Loss: 6.130e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7720, Training Loss: 2.966e-02, Validation Loss: 6.130e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7721, Training Loss: 2.966e-02, Validation Loss: 6.130e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7722, Training Loss: 2.965e-02, Validation Loss: 6.130e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7723, Training Loss: 2.964e-02, Validation Loss: 6.130e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7724, Training Loss: 2.964e-02, Validation Loss: 6.130e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7725, Training Loss: 2.963e-02, Validation Loss: 6.131e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7726, Training Loss: 2.963e-02, Validation Loss: 6.130e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7727, Training Loss: 2.962e-02, Validation Loss: 6.131e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7728, Training Loss: 2.961e-02, Validation Loss: 6.131e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7729, Training Loss: 2.961e-02, Validation Loss: 6.130e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7730, Training Loss: 2.960e-02, Validation Loss: 6.131e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7731, Training Loss: 2.960e-02, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7732, Training Loss: 2.959e-02, Validation Loss: 6.131e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7733, Training Loss: 2.958e-02, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7734, Training Loss: 2.958e-02, Validation Loss: 6.131e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7735, Training Loss: 2.957e-02, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7736, Training Loss: 2.957e-02, Validation Loss: 6.131e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7737, Training Loss: 2.956e-02, Validation Loss: 6.132e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7738, Training Loss: 2.955e-02, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7739, Training Loss: 2.955e-02, Validation Loss: 6.132e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7740, Training Loss: 2.954e-02, Validation Loss: 6.132e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7741, Training Loss: 2.953e-02, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7742, Training Loss: 2.953e-02, Validation Loss: 6.132e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7743, Training Loss: 2.952e-02, Validation Loss: 6.132e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7744, Training Loss: 2.952e-02, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7745, Training Loss: 2.951e-02, Validation Loss: 6.132e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7746, Training Loss: 2.950e-02, Validation Loss: 6.132e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7747, Training Loss: 2.950e-02, Validation Loss: 6.132e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7748, Training Loss: 2.949e-02, Validation Loss: 6.132e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7749, Training Loss: 2.949e-02, Validation Loss: 6.133e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7750, Training Loss: 2.948e-02, Validation Loss: 6.132e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7751, Training Loss: 2.947e-02, Validation Loss: 6.132e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7752, Training Loss: 2.947e-02, Validation Loss: 6.133e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7753, Training Loss: 2.946e-02, Validation Loss: 6.132e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7754, Training Loss: 2.946e-02, Validation Loss: 6.133e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7755, Training Loss: 2.945e-02, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7756, Training Loss: 2.944e-02, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7757, Training Loss: 2.944e-02, Validation Loss: 6.133e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7758, Training Loss: 2.943e-02, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7759, Training Loss: 2.943e-02, Validation Loss: 6.134e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7760, Training Loss: 2.942e-02, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7761, Training Loss: 2.941e-02, Validation Loss: 6.134e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7762, Training Loss: 2.941e-02, Validation Loss: 6.134e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7763, Training Loss: 2.940e-02, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7764, Training Loss: 2.940e-02, Validation Loss: 6.134e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7765, Training Loss: 2.939e-02, Validation Loss: 6.134e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7766, Training Loss: 2.938e-02, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7767, Training Loss: 2.938e-02, Validation Loss: 6.134e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7768, Training Loss: 2.937e-02, Validation Loss: 6.134e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7769, Training Loss: 2.937e-02, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7770, Training Loss: 2.936e-02, Validation Loss: 6.134e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7771, Training Loss: 2.935e-02, Validation Loss: 6.135e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7772, Training Loss: 2.935e-02, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7773, Training Loss: 2.934e-02, Validation Loss: 6.134e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7774, Training Loss: 2.934e-02, Validation Loss: 6.135e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7775, Training Loss: 2.933e-02, Validation Loss: 6.134e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7776, Training Loss: 2.932e-02, Validation Loss: 6.135e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7777, Training Loss: 2.932e-02, Validation Loss: 6.135e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7778, Training Loss: 2.931e-02, Validation Loss: 6.134e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7779, Training Loss: 2.931e-02, Validation Loss: 6.135e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7780, Training Loss: 2.930e-02, Validation Loss: 6.135e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7781, Training Loss: 2.929e-02, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7782, Training Loss: 2.929e-02, Validation Loss: 6.135e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7783, Training Loss: 2.928e-02, Validation Loss: 6.136e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7784, Training Loss: 2.928e-02, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7785, Training Loss: 2.927e-02, Validation Loss: 6.135e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7786, Training Loss: 2.926e-02, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7787, Training Loss: 2.926e-02, Validation Loss: 6.136e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7788, Training Loss: 2.925e-02, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7789, Training Loss: 2.925e-02, Validation Loss: 6.136e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7790, Training Loss: 2.924e-02, Validation Loss: 6.136e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7791, Training Loss: 2.923e-02, Validation Loss: 6.136e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 7792, Training Loss: 2.923e-02, Validation Loss: 6.136e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7793, Training Loss: 2.922e-02, Validation Loss: 6.136e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7794, Training Loss: 2.922e-02, Validation Loss: 6.136e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7795, Training Loss: 2.921e-02, Validation Loss: 6.136e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 7796, Training Loss: 2.921e-02, Validation Loss: 6.136e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7797, Training Loss: 2.920e-02, Validation Loss: 6.136e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7798, Training Loss: 2.919e-02, Validation Loss: 6.137e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7799, Training Loss: 2.919e-02, Validation Loss: 6.136e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7800, Training Loss: 2.918e-02, Validation Loss: 6.136e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7801, Training Loss: 2.917e-02, Validation Loss: 6.137e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7802, Training Loss: 2.917e-02, Validation Loss: 6.136e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7803, Training Loss: 2.916e-02, Validation Loss: 6.137e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7804, Training Loss: 2.916e-02, Validation Loss: 6.137e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7805, Training Loss: 2.915e-02, Validation Loss: 6.136e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7806, Training Loss: 2.915e-02, Validation Loss: 6.137e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7807, Training Loss: 2.914e-02, Validation Loss: 6.137e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7808, Training Loss: 2.913e-02, Validation Loss: 6.136e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7809, Training Loss: 2.913e-02, Validation Loss: 6.137e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7810, Training Loss: 2.912e-02, Validation Loss: 6.137e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7811, Training Loss: 2.912e-02, Validation Loss: 6.137e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7812, Training Loss: 2.911e-02, Validation Loss: 6.137e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7813, Training Loss: 2.910e-02, Validation Loss: 6.137e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7814, Training Loss: 2.910e-02, Validation Loss: 6.137e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7815, Training Loss: 2.909e-02, Validation Loss: 6.138e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7816, Training Loss: 2.909e-02, Validation Loss: 6.137e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7817, Training Loss: 2.908e-02, Validation Loss: 6.138e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7818, Training Loss: 2.907e-02, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7819, Training Loss: 2.907e-02, Validation Loss: 6.137e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7820, Training Loss: 2.906e-02, Validation Loss: 6.138e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7821, Training Loss: 2.906e-02, Validation Loss: 6.138e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7822, Training Loss: 2.905e-02, Validation Loss: 6.137e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7823, Training Loss: 2.905e-02, Validation Loss: 6.138e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7824, Training Loss: 2.904e-02, Validation Loss: 6.139e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7825, Training Loss: 2.903e-02, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7826, Training Loss: 2.903e-02, Validation Loss: 6.138e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7827, Training Loss: 2.902e-02, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7828, Training Loss: 2.902e-02, Validation Loss: 6.139e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7829, Training Loss: 2.901e-02, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7830, Training Loss: 2.900e-02, Validation Loss: 6.139e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7831, Training Loss: 2.900e-02, Validation Loss: 6.139e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7832, Training Loss: 2.899e-02, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7833, Training Loss: 2.899e-02, Validation Loss: 6.139e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7834, Training Loss: 2.898e-02, Validation Loss: 6.139e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7835, Training Loss: 2.897e-02, Validation Loss: 6.139e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7836, Training Loss: 2.897e-02, Validation Loss: 6.139e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7837, Training Loss: 2.896e-02, Validation Loss: 6.140e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7838, Training Loss: 2.896e-02, Validation Loss: 6.139e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7839, Training Loss: 2.895e-02, Validation Loss: 6.139e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7840, Training Loss: 2.895e-02, Validation Loss: 6.140e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7841, Training Loss: 2.894e-02, Validation Loss: 6.139e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7842, Training Loss: 2.893e-02, Validation Loss: 6.140e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7843, Training Loss: 2.893e-02, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7844, Training Loss: 2.892e-02, Validation Loss: 6.140e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7845, Training Loss: 2.892e-02, Validation Loss: 6.139e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7846, Training Loss: 2.891e-02, Validation Loss: 6.140e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7847, Training Loss: 2.890e-02, Validation Loss: 6.140e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7848, Training Loss: 2.890e-02, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7849, Training Loss: 2.889e-02, Validation Loss: 6.140e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7850, Training Loss: 2.889e-02, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7851, Training Loss: 2.888e-02, Validation Loss: 6.141e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7852, Training Loss: 2.888e-02, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7853, Training Loss: 2.887e-02, Validation Loss: 6.141e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7854, Training Loss: 2.886e-02, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7855, Training Loss: 2.886e-02, Validation Loss: 6.141e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7856, Training Loss: 2.885e-02, Validation Loss: 6.141e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7857, Training Loss: 2.885e-02, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7858, Training Loss: 2.884e-02, Validation Loss: 6.141e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7859, Training Loss: 2.883e-02, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7860, Training Loss: 2.883e-02, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7861, Training Loss: 2.882e-02, Validation Loss: 6.141e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7862, Training Loss: 2.882e-02, Validation Loss: 6.141e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7863, Training Loss: 2.881e-02, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7864, Training Loss: 2.881e-02, Validation Loss: 6.142e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7865, Training Loss: 2.880e-02, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7866, Training Loss: 2.879e-02, Validation Loss: 6.142e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7867, Training Loss: 2.879e-02, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7868, Training Loss: 2.878e-02, Validation Loss: 6.142e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7869, Training Loss: 2.878e-02, Validation Loss: 6.142e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7870, Training Loss: 2.877e-02, Validation Loss: 6.142e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7871, Training Loss: 2.877e-02, Validation Loss: 6.142e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7872, Training Loss: 2.876e-02, Validation Loss: 6.142e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7873, Training Loss: 2.875e-02, Validation Loss: 6.142e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7874, Training Loss: 2.875e-02, Validation Loss: 6.143e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 7875, Training Loss: 2.874e-02, Validation Loss: 6.142e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7876, Training Loss: 2.874e-02, Validation Loss: 6.142e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7877, Training Loss: 2.873e-02, Validation Loss: 6.143e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7878, Training Loss: 2.872e-02, Validation Loss: 6.142e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7879, Training Loss: 2.872e-02, Validation Loss: 6.142e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7880, Training Loss: 2.871e-02, Validation Loss: 6.143e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7881, Training Loss: 2.871e-02, Validation Loss: 6.142e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7882, Training Loss: 2.870e-02, Validation Loss: 6.143e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7883, Training Loss: 2.870e-02, Validation Loss: 6.142e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7884, Training Loss: 2.869e-02, Validation Loss: 6.143e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7885, Training Loss: 2.868e-02, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7886, Training Loss: 2.868e-02, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7887, Training Loss: 2.867e-02, Validation Loss: 6.143e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7888, Training Loss: 2.867e-02, Validation Loss: 6.144e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7889, Training Loss: 2.866e-02, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7890, Training Loss: 2.866e-02, Validation Loss: 6.143e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7891, Training Loss: 2.865e-02, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7892, Training Loss: 2.864e-02, Validation Loss: 6.144e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7893, Training Loss: 2.864e-02, Validation Loss: 6.144e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7894, Training Loss: 2.863e-02, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7895, Training Loss: 2.863e-02, Validation Loss: 6.144e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7896, Training Loss: 2.862e-02, Validation Loss: 6.144e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7897, Training Loss: 2.862e-02, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7898, Training Loss: 2.861e-02, Validation Loss: 6.144e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7899, Training Loss: 2.860e-02, Validation Loss: 6.144e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7900, Training Loss: 2.860e-02, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7901, Training Loss: 2.859e-02, Validation Loss: 6.145e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7902, Training Loss: 2.859e-02, Validation Loss: 6.144e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7903, Training Loss: 2.858e-02, Validation Loss: 6.144e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7904, Training Loss: 2.858e-02, Validation Loss: 6.144e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7905, Training Loss: 2.857e-02, Validation Loss: 6.144e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7906, Training Loss: 2.856e-02, Validation Loss: 6.145e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 7907, Training Loss: 2.856e-02, Validation Loss: 6.145e-01, Patience: 4, Learning Rate: 0.01\n",
      "Epoch 7908, Training Loss: 2.855e-02, Validation Loss: 6.144e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7909, Training Loss: 2.855e-02, Validation Loss: 6.145e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7910, Training Loss: 2.854e-02, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7911, Training Loss: 2.854e-02, Validation Loss: 6.145e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7912, Training Loss: 2.853e-02, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7913, Training Loss: 2.852e-02, Validation Loss: 6.145e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7914, Training Loss: 2.852e-02, Validation Loss: 6.145e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7915, Training Loss: 2.851e-02, Validation Loss: 6.145e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 7916, Training Loss: 2.851e-02, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7917, Training Loss: 2.850e-02, Validation Loss: 6.145e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7918, Training Loss: 2.850e-02, Validation Loss: 6.146e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7919, Training Loss: 2.849e-02, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7920, Training Loss: 2.848e-02, Validation Loss: 6.146e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7921, Training Loss: 2.848e-02, Validation Loss: 6.146e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7922, Training Loss: 2.847e-02, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7923, Training Loss: 2.847e-02, Validation Loss: 6.146e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7924, Training Loss: 2.846e-02, Validation Loss: 6.146e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7925, Training Loss: 2.846e-02, Validation Loss: 6.146e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7926, Training Loss: 2.845e-02, Validation Loss: 6.146e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7927, Training Loss: 2.844e-02, Validation Loss: 6.147e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7928, Training Loss: 2.844e-02, Validation Loss: 6.146e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7929, Training Loss: 2.843e-02, Validation Loss: 6.146e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7930, Training Loss: 2.843e-02, Validation Loss: 6.147e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7931, Training Loss: 2.842e-02, Validation Loss: 6.146e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7932, Training Loss: 2.842e-02, Validation Loss: 6.147e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7933, Training Loss: 2.841e-02, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7934, Training Loss: 2.840e-02, Validation Loss: 6.147e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7935, Training Loss: 2.840e-02, Validation Loss: 6.146e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7936, Training Loss: 2.839e-02, Validation Loss: 6.147e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7937, Training Loss: 2.839e-02, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7938, Training Loss: 2.838e-02, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7939, Training Loss: 2.838e-02, Validation Loss: 6.147e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7940, Training Loss: 2.837e-02, Validation Loss: 6.148e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7941, Training Loss: 2.836e-02, Validation Loss: 6.146e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7942, Training Loss: 2.836e-02, Validation Loss: 6.148e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7943, Training Loss: 2.835e-02, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7944, Training Loss: 2.835e-02, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7945, Training Loss: 2.834e-02, Validation Loss: 6.148e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7946, Training Loss: 2.834e-02, Validation Loss: 6.148e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7947, Training Loss: 2.833e-02, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7948, Training Loss: 2.833e-02, Validation Loss: 6.148e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7949, Training Loss: 2.832e-02, Validation Loss: 6.148e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7950, Training Loss: 2.831e-02, Validation Loss: 6.148e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7951, Training Loss: 2.831e-02, Validation Loss: 6.148e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7952, Training Loss: 2.830e-02, Validation Loss: 6.148e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7953, Training Loss: 2.830e-02, Validation Loss: 6.148e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7954, Training Loss: 2.829e-02, Validation Loss: 6.148e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7955, Training Loss: 2.829e-02, Validation Loss: 6.149e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7956, Training Loss: 2.828e-02, Validation Loss: 6.149e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7957, Training Loss: 2.827e-02, Validation Loss: 6.148e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7958, Training Loss: 2.827e-02, Validation Loss: 6.149e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7959, Training Loss: 2.826e-02, Validation Loss: 6.149e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7960, Training Loss: 2.826e-02, Validation Loss: 6.148e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7961, Training Loss: 2.825e-02, Validation Loss: 6.149e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7962, Training Loss: 2.825e-02, Validation Loss: 6.149e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7963, Training Loss: 2.824e-02, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7964, Training Loss: 2.824e-02, Validation Loss: 6.149e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7965, Training Loss: 2.823e-02, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7966, Training Loss: 2.822e-02, Validation Loss: 6.149e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7967, Training Loss: 2.822e-02, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7968, Training Loss: 2.821e-02, Validation Loss: 6.149e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7969, Training Loss: 2.821e-02, Validation Loss: 6.149e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7970, Training Loss: 2.820e-02, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7971, Training Loss: 2.820e-02, Validation Loss: 6.150e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7972, Training Loss: 2.819e-02, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7973, Training Loss: 2.818e-02, Validation Loss: 6.150e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7974, Training Loss: 2.818e-02, Validation Loss: 6.150e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7975, Training Loss: 2.817e-02, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7976, Training Loss: 2.817e-02, Validation Loss: 6.150e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7977, Training Loss: 2.816e-02, Validation Loss: 6.150e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7978, Training Loss: 2.816e-02, Validation Loss: 6.150e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7979, Training Loss: 2.815e-02, Validation Loss: 6.150e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7980, Training Loss: 2.815e-02, Validation Loss: 6.150e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7981, Training Loss: 2.814e-02, Validation Loss: 6.150e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7982, Training Loss: 2.813e-02, Validation Loss: 6.151e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7983, Training Loss: 2.813e-02, Validation Loss: 6.150e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7984, Training Loss: 2.812e-02, Validation Loss: 6.151e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7985, Training Loss: 2.812e-02, Validation Loss: 6.151e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7986, Training Loss: 2.811e-02, Validation Loss: 6.150e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7987, Training Loss: 2.811e-02, Validation Loss: 6.151e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7988, Training Loss: 2.810e-02, Validation Loss: 6.151e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7989, Training Loss: 2.810e-02, Validation Loss: 6.150e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7990, Training Loss: 2.809e-02, Validation Loss: 6.151e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7991, Training Loss: 2.808e-02, Validation Loss: 6.151e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7992, Training Loss: 2.808e-02, Validation Loss: 6.151e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7993, Training Loss: 2.807e-02, Validation Loss: 6.151e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7994, Training Loss: 2.807e-02, Validation Loss: 6.152e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 7995, Training Loss: 2.806e-02, Validation Loss: 6.151e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7996, Training Loss: 2.806e-02, Validation Loss: 6.152e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7997, Training Loss: 2.805e-02, Validation Loss: 6.152e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 7998, Training Loss: 2.805e-02, Validation Loss: 6.152e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 7999, Training Loss: 2.804e-02, Validation Loss: 6.151e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8000, Training Loss: 2.803e-02, Validation Loss: 6.152e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8001, Training Loss: 2.803e-02, Validation Loss: 6.152e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8002, Training Loss: 2.802e-02, Validation Loss: 6.152e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8003, Training Loss: 2.802e-02, Validation Loss: 6.152e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8004, Training Loss: 2.801e-02, Validation Loss: 6.152e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8005, Training Loss: 2.801e-02, Validation Loss: 6.152e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8006, Training Loss: 2.800e-02, Validation Loss: 6.152e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8007, Training Loss: 2.800e-02, Validation Loss: 6.152e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8008, Training Loss: 2.799e-02, Validation Loss: 6.152e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8009, Training Loss: 2.798e-02, Validation Loss: 6.153e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8010, Training Loss: 2.798e-02, Validation Loss: 6.152e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8011, Training Loss: 2.797e-02, Validation Loss: 6.153e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8012, Training Loss: 2.797e-02, Validation Loss: 6.152e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8013, Training Loss: 2.796e-02, Validation Loss: 6.153e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8014, Training Loss: 2.796e-02, Validation Loss: 6.153e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8015, Training Loss: 2.795e-02, Validation Loss: 6.153e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8016, Training Loss: 2.795e-02, Validation Loss: 6.153e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8017, Training Loss: 2.794e-02, Validation Loss: 6.153e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8018, Training Loss: 2.793e-02, Validation Loss: 6.153e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8019, Training Loss: 2.793e-02, Validation Loss: 6.153e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8020, Training Loss: 2.792e-02, Validation Loss: 6.154e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8021, Training Loss: 2.792e-02, Validation Loss: 6.154e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8022, Training Loss: 2.791e-02, Validation Loss: 6.153e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8023, Training Loss: 2.791e-02, Validation Loss: 6.154e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8024, Training Loss: 2.790e-02, Validation Loss: 6.154e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8025, Training Loss: 2.790e-02, Validation Loss: 6.153e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8026, Training Loss: 2.789e-02, Validation Loss: 6.154e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8027, Training Loss: 2.789e-02, Validation Loss: 6.154e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8028, Training Loss: 2.788e-02, Validation Loss: 6.153e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8029, Training Loss: 2.787e-02, Validation Loss: 6.154e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8030, Training Loss: 2.787e-02, Validation Loss: 6.155e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8031, Training Loss: 2.786e-02, Validation Loss: 6.154e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8032, Training Loss: 2.786e-02, Validation Loss: 6.154e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8033, Training Loss: 2.785e-02, Validation Loss: 6.154e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8034, Training Loss: 2.785e-02, Validation Loss: 6.154e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8035, Training Loss: 2.784e-02, Validation Loss: 6.155e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8036, Training Loss: 2.784e-02, Validation Loss: 6.154e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8037, Training Loss: 2.783e-02, Validation Loss: 6.155e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8038, Training Loss: 2.783e-02, Validation Loss: 6.155e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8039, Training Loss: 2.782e-02, Validation Loss: 6.155e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8040, Training Loss: 2.781e-02, Validation Loss: 6.155e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8041, Training Loss: 2.781e-02, Validation Loss: 6.155e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8042, Training Loss: 2.780e-02, Validation Loss: 6.155e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8043, Training Loss: 2.780e-02, Validation Loss: 6.155e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8044, Training Loss: 2.779e-02, Validation Loss: 6.155e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8045, Training Loss: 2.779e-02, Validation Loss: 6.156e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8046, Training Loss: 2.778e-02, Validation Loss: 6.155e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8047, Training Loss: 2.778e-02, Validation Loss: 6.156e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8048, Training Loss: 2.777e-02, Validation Loss: 6.156e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8049, Training Loss: 2.777e-02, Validation Loss: 6.156e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8050, Training Loss: 2.776e-02, Validation Loss: 6.155e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8051, Training Loss: 2.775e-02, Validation Loss: 6.156e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8052, Training Loss: 2.775e-02, Validation Loss: 6.156e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8053, Training Loss: 2.774e-02, Validation Loss: 6.156e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8054, Training Loss: 2.774e-02, Validation Loss: 6.156e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8055, Training Loss: 2.773e-02, Validation Loss: 6.156e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8056, Training Loss: 2.773e-02, Validation Loss: 6.156e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8057, Training Loss: 2.772e-02, Validation Loss: 6.157e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8058, Training Loss: 2.772e-02, Validation Loss: 6.156e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8059, Training Loss: 2.771e-02, Validation Loss: 6.156e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8060, Training Loss: 2.771e-02, Validation Loss: 6.157e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8061, Training Loss: 2.770e-02, Validation Loss: 6.156e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8062, Training Loss: 2.769e-02, Validation Loss: 6.157e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8063, Training Loss: 2.769e-02, Validation Loss: 6.157e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8064, Training Loss: 2.768e-02, Validation Loss: 6.157e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8065, Training Loss: 2.768e-02, Validation Loss: 6.157e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8066, Training Loss: 2.767e-02, Validation Loss: 6.157e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8067, Training Loss: 2.767e-02, Validation Loss: 6.157e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8068, Training Loss: 2.766e-02, Validation Loss: 6.157e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8069, Training Loss: 2.766e-02, Validation Loss: 6.157e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8070, Training Loss: 2.765e-02, Validation Loss: 6.157e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8071, Training Loss: 2.765e-02, Validation Loss: 6.157e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8072, Training Loss: 2.764e-02, Validation Loss: 6.157e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8073, Training Loss: 2.764e-02, Validation Loss: 6.158e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8074, Training Loss: 2.763e-02, Validation Loss: 6.157e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8075, Training Loss: 2.762e-02, Validation Loss: 6.158e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8076, Training Loss: 2.762e-02, Validation Loss: 6.158e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8077, Training Loss: 2.761e-02, Validation Loss: 6.158e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8078, Training Loss: 2.761e-02, Validation Loss: 6.157e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8079, Training Loss: 2.760e-02, Validation Loss: 6.158e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8080, Training Loss: 2.760e-02, Validation Loss: 6.158e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8081, Training Loss: 2.759e-02, Validation Loss: 6.158e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8082, Training Loss: 2.759e-02, Validation Loss: 6.158e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8083, Training Loss: 2.758e-02, Validation Loss: 6.159e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8084, Training Loss: 2.758e-02, Validation Loss: 6.158e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8085, Training Loss: 2.757e-02, Validation Loss: 6.158e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8086, Training Loss: 2.756e-02, Validation Loss: 6.159e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8087, Training Loss: 2.756e-02, Validation Loss: 6.158e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8088, Training Loss: 2.755e-02, Validation Loss: 6.159e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8089, Training Loss: 2.755e-02, Validation Loss: 6.159e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8090, Training Loss: 2.754e-02, Validation Loss: 6.158e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8091, Training Loss: 2.754e-02, Validation Loss: 6.159e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8092, Training Loss: 2.753e-02, Validation Loss: 6.159e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8093, Training Loss: 2.753e-02, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8094, Training Loss: 2.752e-02, Validation Loss: 6.159e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8095, Training Loss: 2.752e-02, Validation Loss: 6.160e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8096, Training Loss: 2.751e-02, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8097, Training Loss: 2.751e-02, Validation Loss: 6.160e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8098, Training Loss: 2.750e-02, Validation Loss: 6.160e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8099, Training Loss: 2.750e-02, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8100, Training Loss: 2.749e-02, Validation Loss: 6.159e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8101, Training Loss: 2.748e-02, Validation Loss: 6.160e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8102, Training Loss: 2.748e-02, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8103, Training Loss: 2.747e-02, Validation Loss: 6.160e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8104, Training Loss: 2.747e-02, Validation Loss: 6.160e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8105, Training Loss: 2.746e-02, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8106, Training Loss: 2.746e-02, Validation Loss: 6.160e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8107, Training Loss: 2.745e-02, Validation Loss: 6.161e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8108, Training Loss: 2.745e-02, Validation Loss: 6.160e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8109, Training Loss: 2.744e-02, Validation Loss: 6.160e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8110, Training Loss: 2.744e-02, Validation Loss: 6.161e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8111, Training Loss: 2.743e-02, Validation Loss: 6.160e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8112, Training Loss: 2.743e-02, Validation Loss: 6.161e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8113, Training Loss: 2.742e-02, Validation Loss: 6.160e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8114, Training Loss: 2.741e-02, Validation Loss: 6.161e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8115, Training Loss: 2.741e-02, Validation Loss: 6.160e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8116, Training Loss: 2.740e-02, Validation Loss: 6.161e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8117, Training Loss: 2.740e-02, Validation Loss: 6.161e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8118, Training Loss: 2.739e-02, Validation Loss: 6.161e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8119, Training Loss: 2.739e-02, Validation Loss: 6.161e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8120, Training Loss: 2.738e-02, Validation Loss: 6.161e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8121, Training Loss: 2.738e-02, Validation Loss: 6.161e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8122, Training Loss: 2.737e-02, Validation Loss: 6.161e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8123, Training Loss: 2.737e-02, Validation Loss: 6.161e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8124, Training Loss: 2.736e-02, Validation Loss: 6.162e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8125, Training Loss: 2.736e-02, Validation Loss: 6.161e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8126, Training Loss: 2.735e-02, Validation Loss: 6.162e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8127, Training Loss: 2.735e-02, Validation Loss: 6.162e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8128, Training Loss: 2.734e-02, Validation Loss: 6.161e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8129, Training Loss: 2.733e-02, Validation Loss: 6.162e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8130, Training Loss: 2.733e-02, Validation Loss: 6.162e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8131, Training Loss: 2.732e-02, Validation Loss: 6.162e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8132, Training Loss: 2.732e-02, Validation Loss: 6.162e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8133, Training Loss: 2.731e-02, Validation Loss: 6.162e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8134, Training Loss: 2.731e-02, Validation Loss: 6.162e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8135, Training Loss: 2.730e-02, Validation Loss: 6.163e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8136, Training Loss: 2.730e-02, Validation Loss: 6.162e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8137, Training Loss: 2.729e-02, Validation Loss: 6.162e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8138, Training Loss: 2.729e-02, Validation Loss: 6.163e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8139, Training Loss: 2.728e-02, Validation Loss: 6.162e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8140, Training Loss: 2.728e-02, Validation Loss: 6.163e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8141, Training Loss: 2.727e-02, Validation Loss: 6.163e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8142, Training Loss: 2.727e-02, Validation Loss: 6.163e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8143, Training Loss: 2.726e-02, Validation Loss: 6.163e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8144, Training Loss: 2.726e-02, Validation Loss: 6.163e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8145, Training Loss: 2.725e-02, Validation Loss: 6.163e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8146, Training Loss: 2.724e-02, Validation Loss: 6.163e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8147, Training Loss: 2.724e-02, Validation Loss: 6.163e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8148, Training Loss: 2.723e-02, Validation Loss: 6.164e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8149, Training Loss: 2.723e-02, Validation Loss: 6.163e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8150, Training Loss: 2.722e-02, Validation Loss: 6.164e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8151, Training Loss: 2.722e-02, Validation Loss: 6.164e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8152, Training Loss: 2.721e-02, Validation Loss: 6.163e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8153, Training Loss: 2.721e-02, Validation Loss: 6.164e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8154, Training Loss: 2.720e-02, Validation Loss: 6.164e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8155, Training Loss: 2.720e-02, Validation Loss: 6.163e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8156, Training Loss: 2.719e-02, Validation Loss: 6.164e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8157, Training Loss: 2.719e-02, Validation Loss: 6.164e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8158, Training Loss: 2.718e-02, Validation Loss: 6.164e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8159, Training Loss: 2.718e-02, Validation Loss: 6.164e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8160, Training Loss: 2.717e-02, Validation Loss: 6.164e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8161, Training Loss: 2.717e-02, Validation Loss: 6.164e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8162, Training Loss: 2.716e-02, Validation Loss: 6.164e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8163, Training Loss: 2.716e-02, Validation Loss: 6.164e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8164, Training Loss: 2.715e-02, Validation Loss: 6.165e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8165, Training Loss: 2.715e-02, Validation Loss: 6.164e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8166, Training Loss: 2.714e-02, Validation Loss: 6.165e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8167, Training Loss: 2.713e-02, Validation Loss: 6.165e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8168, Training Loss: 2.713e-02, Validation Loss: 6.164e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8169, Training Loss: 2.712e-02, Validation Loss: 6.165e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8170, Training Loss: 2.712e-02, Validation Loss: 6.165e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8171, Training Loss: 2.711e-02, Validation Loss: 6.165e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8172, Training Loss: 2.711e-02, Validation Loss: 6.165e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8173, Training Loss: 2.710e-02, Validation Loss: 6.166e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8174, Training Loss: 2.710e-02, Validation Loss: 6.165e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8175, Training Loss: 2.709e-02, Validation Loss: 6.165e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8176, Training Loss: 2.709e-02, Validation Loss: 6.166e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8177, Training Loss: 2.708e-02, Validation Loss: 6.165e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8178, Training Loss: 2.708e-02, Validation Loss: 6.166e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8179, Training Loss: 2.707e-02, Validation Loss: 6.165e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8180, Training Loss: 2.707e-02, Validation Loss: 6.166e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8181, Training Loss: 2.706e-02, Validation Loss: 6.165e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8182, Training Loss: 2.706e-02, Validation Loss: 6.166e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8183, Training Loss: 2.705e-02, Validation Loss: 6.166e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8184, Training Loss: 2.705e-02, Validation Loss: 6.166e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8185, Training Loss: 2.704e-02, Validation Loss: 6.166e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8186, Training Loss: 2.704e-02, Validation Loss: 6.166e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8187, Training Loss: 2.703e-02, Validation Loss: 6.166e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8188, Training Loss: 2.702e-02, Validation Loss: 6.167e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8189, Training Loss: 2.702e-02, Validation Loss: 6.166e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8190, Training Loss: 2.701e-02, Validation Loss: 6.167e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8191, Training Loss: 2.701e-02, Validation Loss: 6.167e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8192, Training Loss: 2.700e-02, Validation Loss: 6.166e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8193, Training Loss: 2.700e-02, Validation Loss: 6.167e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8194, Training Loss: 2.699e-02, Validation Loss: 6.167e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8195, Training Loss: 2.699e-02, Validation Loss: 6.166e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8196, Training Loss: 2.698e-02, Validation Loss: 6.167e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8197, Training Loss: 2.698e-02, Validation Loss: 6.167e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8198, Training Loss: 2.697e-02, Validation Loss: 6.167e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8199, Training Loss: 2.697e-02, Validation Loss: 6.167e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8200, Training Loss: 2.696e-02, Validation Loss: 6.167e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8201, Training Loss: 2.696e-02, Validation Loss: 6.168e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8202, Training Loss: 2.695e-02, Validation Loss: 6.167e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8203, Training Loss: 2.695e-02, Validation Loss: 6.168e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8204, Training Loss: 2.694e-02, Validation Loss: 6.168e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8205, Training Loss: 2.694e-02, Validation Loss: 6.167e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8206, Training Loss: 2.693e-02, Validation Loss: 6.168e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8207, Training Loss: 2.693e-02, Validation Loss: 6.168e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8208, Training Loss: 2.692e-02, Validation Loss: 6.168e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8209, Training Loss: 2.692e-02, Validation Loss: 6.168e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8210, Training Loss: 2.691e-02, Validation Loss: 6.168e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8211, Training Loss: 2.691e-02, Validation Loss: 6.169e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8212, Training Loss: 2.690e-02, Validation Loss: 6.168e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8213, Training Loss: 2.690e-02, Validation Loss: 6.169e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8214, Training Loss: 2.689e-02, Validation Loss: 6.169e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8215, Training Loss: 2.689e-02, Validation Loss: 6.169e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8216, Training Loss: 2.688e-02, Validation Loss: 6.168e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8217, Training Loss: 2.688e-02, Validation Loss: 6.169e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8218, Training Loss: 2.687e-02, Validation Loss: 6.169e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8219, Training Loss: 2.686e-02, Validation Loss: 6.168e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8220, Training Loss: 2.686e-02, Validation Loss: 6.169e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8221, Training Loss: 2.685e-02, Validation Loss: 6.169e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8222, Training Loss: 2.685e-02, Validation Loss: 6.169e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8223, Training Loss: 2.684e-02, Validation Loss: 6.169e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8224, Training Loss: 2.684e-02, Validation Loss: 6.169e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8225, Training Loss: 2.683e-02, Validation Loss: 6.169e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8226, Training Loss: 2.683e-02, Validation Loss: 6.169e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8227, Training Loss: 2.682e-02, Validation Loss: 6.169e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8228, Training Loss: 2.682e-02, Validation Loss: 6.170e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8229, Training Loss: 2.681e-02, Validation Loss: 6.169e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8230, Training Loss: 2.681e-02, Validation Loss: 6.170e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8231, Training Loss: 2.680e-02, Validation Loss: 6.170e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8232, Training Loss: 2.680e-02, Validation Loss: 6.169e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8233, Training Loss: 2.679e-02, Validation Loss: 6.170e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8234, Training Loss: 2.679e-02, Validation Loss: 6.170e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8235, Training Loss: 2.678e-02, Validation Loss: 6.170e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8236, Training Loss: 2.678e-02, Validation Loss: 6.170e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8237, Training Loss: 2.677e-02, Validation Loss: 6.170e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8238, Training Loss: 2.677e-02, Validation Loss: 6.171e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8239, Training Loss: 2.676e-02, Validation Loss: 6.170e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8240, Training Loss: 2.676e-02, Validation Loss: 6.171e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8241, Training Loss: 2.675e-02, Validation Loss: 6.171e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8242, Training Loss: 2.675e-02, Validation Loss: 6.170e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8243, Training Loss: 2.674e-02, Validation Loss: 6.171e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8244, Training Loss: 2.674e-02, Validation Loss: 6.171e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8245, Training Loss: 2.673e-02, Validation Loss: 6.170e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8246, Training Loss: 2.673e-02, Validation Loss: 6.171e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8247, Training Loss: 2.672e-02, Validation Loss: 6.171e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8248, Training Loss: 2.672e-02, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8249, Training Loss: 2.671e-02, Validation Loss: 6.171e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8250, Training Loss: 2.671e-02, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8251, Training Loss: 2.670e-02, Validation Loss: 6.172e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8252, Training Loss: 2.670e-02, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8253, Training Loss: 2.669e-02, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8254, Training Loss: 2.669e-02, Validation Loss: 6.172e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8255, Training Loss: 2.668e-02, Validation Loss: 6.172e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8256, Training Loss: 2.668e-02, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8257, Training Loss: 2.667e-02, Validation Loss: 6.172e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8258, Training Loss: 2.666e-02, Validation Loss: 6.172e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8259, Training Loss: 2.666e-02, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8260, Training Loss: 2.665e-02, Validation Loss: 6.172e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8261, Training Loss: 2.665e-02, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8262, Training Loss: 2.664e-02, Validation Loss: 6.172e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8263, Training Loss: 2.664e-02, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8264, Training Loss: 2.663e-02, Validation Loss: 6.173e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8265, Training Loss: 2.663e-02, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8266, Training Loss: 2.662e-02, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8267, Training Loss: 2.662e-02, Validation Loss: 6.173e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8268, Training Loss: 2.661e-02, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8269, Training Loss: 2.661e-02, Validation Loss: 6.173e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8270, Training Loss: 2.660e-02, Validation Loss: 6.173e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8271, Training Loss: 2.660e-02, Validation Loss: 6.173e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8272, Training Loss: 2.659e-02, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8273, Training Loss: 2.659e-02, Validation Loss: 6.173e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8274, Training Loss: 2.658e-02, Validation Loss: 6.173e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8275, Training Loss: 2.658e-02, Validation Loss: 6.173e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8276, Training Loss: 2.657e-02, Validation Loss: 6.173e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8277, Training Loss: 2.657e-02, Validation Loss: 6.173e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8278, Training Loss: 2.656e-02, Validation Loss: 6.173e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8279, Training Loss: 2.656e-02, Validation Loss: 6.174e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8280, Training Loss: 2.655e-02, Validation Loss: 6.173e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8281, Training Loss: 2.655e-02, Validation Loss: 6.174e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8282, Training Loss: 2.654e-02, Validation Loss: 6.173e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8283, Training Loss: 2.654e-02, Validation Loss: 6.174e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8284, Training Loss: 2.653e-02, Validation Loss: 6.174e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8285, Training Loss: 2.653e-02, Validation Loss: 6.174e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8286, Training Loss: 2.652e-02, Validation Loss: 6.174e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8287, Training Loss: 2.652e-02, Validation Loss: 6.174e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8288, Training Loss: 2.651e-02, Validation Loss: 6.174e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8289, Training Loss: 2.651e-02, Validation Loss: 6.174e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8290, Training Loss: 2.650e-02, Validation Loss: 6.175e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8291, Training Loss: 2.650e-02, Validation Loss: 6.174e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8292, Training Loss: 2.649e-02, Validation Loss: 6.174e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8293, Training Loss: 2.649e-02, Validation Loss: 6.175e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8294, Training Loss: 2.648e-02, Validation Loss: 6.175e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8295, Training Loss: 2.648e-02, Validation Loss: 6.174e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8296, Training Loss: 2.647e-02, Validation Loss: 6.175e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8297, Training Loss: 2.647e-02, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8298, Training Loss: 2.646e-02, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8299, Training Loss: 2.646e-02, Validation Loss: 6.175e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8300, Training Loss: 2.645e-02, Validation Loss: 6.175e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8301, Training Loss: 2.645e-02, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8302, Training Loss: 2.644e-02, Validation Loss: 6.176e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8303, Training Loss: 2.644e-02, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8304, Training Loss: 2.643e-02, Validation Loss: 6.176e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8305, Training Loss: 2.643e-02, Validation Loss: 6.176e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8306, Training Loss: 2.642e-02, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8307, Training Loss: 2.642e-02, Validation Loss: 6.176e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8308, Training Loss: 2.641e-02, Validation Loss: 6.176e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8309, Training Loss: 2.641e-02, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8310, Training Loss: 2.640e-02, Validation Loss: 6.176e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8311, Training Loss: 2.640e-02, Validation Loss: 6.176e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8312, Training Loss: 2.639e-02, Validation Loss: 6.176e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8313, Training Loss: 2.639e-02, Validation Loss: 6.176e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8314, Training Loss: 2.638e-02, Validation Loss: 6.176e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8315, Training Loss: 2.638e-02, Validation Loss: 6.176e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8316, Training Loss: 2.637e-02, Validation Loss: 6.177e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8317, Training Loss: 2.637e-02, Validation Loss: 6.177e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8318, Training Loss: 2.636e-02, Validation Loss: 6.176e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8319, Training Loss: 2.636e-02, Validation Loss: 6.176e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8320, Training Loss: 2.635e-02, Validation Loss: 6.177e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8321, Training Loss: 2.635e-02, Validation Loss: 6.176e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8322, Training Loss: 2.634e-02, Validation Loss: 6.177e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8323, Training Loss: 2.634e-02, Validation Loss: 6.177e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8324, Training Loss: 2.633e-02, Validation Loss: 6.177e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8325, Training Loss: 2.633e-02, Validation Loss: 6.177e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8326, Training Loss: 2.632e-02, Validation Loss: 6.177e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8327, Training Loss: 2.632e-02, Validation Loss: 6.177e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8328, Training Loss: 2.631e-02, Validation Loss: 6.178e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8329, Training Loss: 2.631e-02, Validation Loss: 6.177e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8330, Training Loss: 2.630e-02, Validation Loss: 6.177e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8331, Training Loss: 2.630e-02, Validation Loss: 6.178e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8332, Training Loss: 2.629e-02, Validation Loss: 6.177e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8333, Training Loss: 2.629e-02, Validation Loss: 6.178e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8334, Training Loss: 2.628e-02, Validation Loss: 6.178e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8335, Training Loss: 2.628e-02, Validation Loss: 6.178e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8336, Training Loss: 2.627e-02, Validation Loss: 6.178e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8337, Training Loss: 2.627e-02, Validation Loss: 6.178e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8338, Training Loss: 2.626e-02, Validation Loss: 6.178e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8339, Training Loss: 2.626e-02, Validation Loss: 6.178e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8340, Training Loss: 2.625e-02, Validation Loss: 6.178e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8341, Training Loss: 2.625e-02, Validation Loss: 6.178e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8342, Training Loss: 2.624e-02, Validation Loss: 6.178e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8343, Training Loss: 2.624e-02, Validation Loss: 6.179e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8344, Training Loss: 2.623e-02, Validation Loss: 6.179e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8345, Training Loss: 2.623e-02, Validation Loss: 6.178e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8346, Training Loss: 2.622e-02, Validation Loss: 6.179e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8347, Training Loss: 2.622e-02, Validation Loss: 6.179e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8348, Training Loss: 2.621e-02, Validation Loss: 6.179e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8349, Training Loss: 2.621e-02, Validation Loss: 6.179e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8350, Training Loss: 2.620e-02, Validation Loss: 6.178e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8351, Training Loss: 2.620e-02, Validation Loss: 6.179e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8352, Training Loss: 2.619e-02, Validation Loss: 6.179e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8353, Training Loss: 2.619e-02, Validation Loss: 6.179e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8354, Training Loss: 2.618e-02, Validation Loss: 6.179e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8355, Training Loss: 2.618e-02, Validation Loss: 6.179e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8356, Training Loss: 2.617e-02, Validation Loss: 6.180e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8357, Training Loss: 2.617e-02, Validation Loss: 6.179e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8358, Training Loss: 2.617e-02, Validation Loss: 6.180e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8359, Training Loss: 2.616e-02, Validation Loss: 6.180e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8360, Training Loss: 2.616e-02, Validation Loss: 6.179e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8361, Training Loss: 2.615e-02, Validation Loss: 6.180e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8362, Training Loss: 2.615e-02, Validation Loss: 6.180e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8363, Training Loss: 2.614e-02, Validation Loss: 6.180e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8364, Training Loss: 2.614e-02, Validation Loss: 6.180e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8365, Training Loss: 2.613e-02, Validation Loss: 6.180e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8366, Training Loss: 2.613e-02, Validation Loss: 6.180e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8367, Training Loss: 2.612e-02, Validation Loss: 6.180e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8368, Training Loss: 2.612e-02, Validation Loss: 6.181e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8369, Training Loss: 2.611e-02, Validation Loss: 6.180e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8370, Training Loss: 2.611e-02, Validation Loss: 6.180e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8371, Training Loss: 2.610e-02, Validation Loss: 6.181e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8372, Training Loss: 2.610e-02, Validation Loss: 6.180e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8373, Training Loss: 2.609e-02, Validation Loss: 6.181e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8374, Training Loss: 2.609e-02, Validation Loss: 6.181e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8375, Training Loss: 2.608e-02, Validation Loss: 6.181e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8376, Training Loss: 2.608e-02, Validation Loss: 6.181e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8377, Training Loss: 2.607e-02, Validation Loss: 6.181e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8378, Training Loss: 2.607e-02, Validation Loss: 6.181e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8379, Training Loss: 2.606e-02, Validation Loss: 6.181e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8380, Training Loss: 2.606e-02, Validation Loss: 6.181e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8381, Training Loss: 2.605e-02, Validation Loss: 6.182e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8382, Training Loss: 2.605e-02, Validation Loss: 6.181e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8383, Training Loss: 2.604e-02, Validation Loss: 6.181e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8384, Training Loss: 2.604e-02, Validation Loss: 6.182e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8385, Training Loss: 2.603e-02, Validation Loss: 6.181e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8386, Training Loss: 2.603e-02, Validation Loss: 6.182e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8387, Training Loss: 2.602e-02, Validation Loss: 6.182e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8388, Training Loss: 2.602e-02, Validation Loss: 6.182e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8389, Training Loss: 2.601e-02, Validation Loss: 6.182e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8390, Training Loss: 2.601e-02, Validation Loss: 6.182e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8391, Training Loss: 2.600e-02, Validation Loss: 6.182e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8392, Training Loss: 2.600e-02, Validation Loss: 6.182e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8393, Training Loss: 2.599e-02, Validation Loss: 6.182e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8394, Training Loss: 2.599e-02, Validation Loss: 6.182e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8395, Training Loss: 2.598e-02, Validation Loss: 6.183e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8396, Training Loss: 2.598e-02, Validation Loss: 6.182e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8397, Training Loss: 2.597e-02, Validation Loss: 6.183e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8398, Training Loss: 2.597e-02, Validation Loss: 6.183e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8399, Training Loss: 2.596e-02, Validation Loss: 6.183e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8400, Training Loss: 2.596e-02, Validation Loss: 6.182e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8401, Training Loss: 2.595e-02, Validation Loss: 6.183e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8402, Training Loss: 2.595e-02, Validation Loss: 6.183e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8403, Training Loss: 2.595e-02, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8404, Training Loss: 2.594e-02, Validation Loss: 6.183e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8405, Training Loss: 2.594e-02, Validation Loss: 6.184e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8406, Training Loss: 2.593e-02, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8407, Training Loss: 2.593e-02, Validation Loss: 6.184e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8408, Training Loss: 2.592e-02, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8409, Training Loss: 2.592e-02, Validation Loss: 6.184e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8410, Training Loss: 2.591e-02, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8411, Training Loss: 2.591e-02, Validation Loss: 6.184e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8412, Training Loss: 2.590e-02, Validation Loss: 6.184e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8413, Training Loss: 2.590e-02, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8414, Training Loss: 2.589e-02, Validation Loss: 6.184e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8415, Training Loss: 2.589e-02, Validation Loss: 6.184e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8416, Training Loss: 2.588e-02, Validation Loss: 6.184e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8417, Training Loss: 2.588e-02, Validation Loss: 6.184e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8418, Training Loss: 2.587e-02, Validation Loss: 6.184e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8419, Training Loss: 2.587e-02, Validation Loss: 6.185e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8420, Training Loss: 2.586e-02, Validation Loss: 6.184e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8421, Training Loss: 2.586e-02, Validation Loss: 6.185e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8422, Training Loss: 2.585e-02, Validation Loss: 6.185e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8423, Training Loss: 2.585e-02, Validation Loss: 6.184e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8424, Training Loss: 2.584e-02, Validation Loss: 6.185e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8425, Training Loss: 2.584e-02, Validation Loss: 6.185e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8426, Training Loss: 2.583e-02, Validation Loss: 6.185e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8427, Training Loss: 2.583e-02, Validation Loss: 6.185e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8428, Training Loss: 2.582e-02, Validation Loss: 6.184e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8429, Training Loss: 2.582e-02, Validation Loss: 6.185e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8430, Training Loss: 2.581e-02, Validation Loss: 6.185e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8431, Training Loss: 2.581e-02, Validation Loss: 6.186e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8432, Training Loss: 2.581e-02, Validation Loss: 6.185e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8433, Training Loss: 2.580e-02, Validation Loss: 6.186e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8434, Training Loss: 2.580e-02, Validation Loss: 6.186e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8435, Training Loss: 2.579e-02, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8436, Training Loss: 2.579e-02, Validation Loss: 6.186e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8437, Training Loss: 2.578e-02, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8438, Training Loss: 2.578e-02, Validation Loss: 6.186e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8439, Training Loss: 2.577e-02, Validation Loss: 6.186e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8440, Training Loss: 2.577e-02, Validation Loss: 6.186e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8441, Training Loss: 2.576e-02, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8442, Training Loss: 2.576e-02, Validation Loss: 6.186e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8443, Training Loss: 2.575e-02, Validation Loss: 6.186e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8444, Training Loss: 2.575e-02, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8445, Training Loss: 2.574e-02, Validation Loss: 6.187e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8446, Training Loss: 2.574e-02, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8447, Training Loss: 2.573e-02, Validation Loss: 6.187e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8448, Training Loss: 2.573e-02, Validation Loss: 6.187e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8449, Training Loss: 2.572e-02, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8450, Training Loss: 2.572e-02, Validation Loss: 6.187e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8451, Training Loss: 2.571e-02, Validation Loss: 6.187e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8452, Training Loss: 2.571e-02, Validation Loss: 6.187e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8453, Training Loss: 2.570e-02, Validation Loss: 6.187e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8454, Training Loss: 2.570e-02, Validation Loss: 6.188e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8455, Training Loss: 2.569e-02, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8456, Training Loss: 2.569e-02, Validation Loss: 6.187e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8457, Training Loss: 2.569e-02, Validation Loss: 6.188e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8458, Training Loss: 2.568e-02, Validation Loss: 6.187e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8459, Training Loss: 2.568e-02, Validation Loss: 6.187e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8460, Training Loss: 2.567e-02, Validation Loss: 6.187e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8461, Training Loss: 2.567e-02, Validation Loss: 6.188e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8462, Training Loss: 2.566e-02, Validation Loss: 6.188e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8463, Training Loss: 2.566e-02, Validation Loss: 6.187e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8464, Training Loss: 2.565e-02, Validation Loss: 6.188e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8465, Training Loss: 2.565e-02, Validation Loss: 6.188e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8466, Training Loss: 2.564e-02, Validation Loss: 6.188e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8467, Training Loss: 2.564e-02, Validation Loss: 6.188e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8468, Training Loss: 2.563e-02, Validation Loss: 6.188e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8469, Training Loss: 2.563e-02, Validation Loss: 6.188e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8470, Training Loss: 2.562e-02, Validation Loss: 6.189e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8471, Training Loss: 2.562e-02, Validation Loss: 6.188e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8472, Training Loss: 2.561e-02, Validation Loss: 6.189e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8473, Training Loss: 2.561e-02, Validation Loss: 6.188e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8474, Training Loss: 2.560e-02, Validation Loss: 6.189e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8475, Training Loss: 2.560e-02, Validation Loss: 6.188e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8476, Training Loss: 2.559e-02, Validation Loss: 6.189e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8477, Training Loss: 2.559e-02, Validation Loss: 6.188e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8478, Training Loss: 2.559e-02, Validation Loss: 6.189e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8479, Training Loss: 2.558e-02, Validation Loss: 6.189e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8480, Training Loss: 2.558e-02, Validation Loss: 6.189e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8481, Training Loss: 2.557e-02, Validation Loss: 6.189e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8482, Training Loss: 2.557e-02, Validation Loss: 6.190e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8483, Training Loss: 2.556e-02, Validation Loss: 6.189e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8484, Training Loss: 2.556e-02, Validation Loss: 6.190e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8485, Training Loss: 2.555e-02, Validation Loss: 6.189e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8486, Training Loss: 2.555e-02, Validation Loss: 6.190e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8487, Training Loss: 2.554e-02, Validation Loss: 6.189e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8488, Training Loss: 2.554e-02, Validation Loss: 6.190e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8489, Training Loss: 2.553e-02, Validation Loss: 6.190e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8490, Training Loss: 2.553e-02, Validation Loss: 6.190e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8491, Training Loss: 2.552e-02, Validation Loss: 6.190e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8492, Training Loss: 2.552e-02, Validation Loss: 6.190e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8493, Training Loss: 2.551e-02, Validation Loss: 6.190e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8494, Training Loss: 2.551e-02, Validation Loss: 6.190e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8495, Training Loss: 2.551e-02, Validation Loss: 6.190e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8496, Training Loss: 2.550e-02, Validation Loss: 6.191e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8497, Training Loss: 2.550e-02, Validation Loss: 6.190e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8498, Training Loss: 2.549e-02, Validation Loss: 6.190e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8499, Training Loss: 2.549e-02, Validation Loss: 6.191e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8500, Training Loss: 2.548e-02, Validation Loss: 6.190e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8501, Training Loss: 2.548e-02, Validation Loss: 6.191e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8502, Training Loss: 2.547e-02, Validation Loss: 6.191e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8503, Training Loss: 2.547e-02, Validation Loss: 6.190e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8504, Training Loss: 2.546e-02, Validation Loss: 6.191e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8505, Training Loss: 2.546e-02, Validation Loss: 6.191e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8506, Training Loss: 2.545e-02, Validation Loss: 6.191e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8507, Training Loss: 2.545e-02, Validation Loss: 6.191e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8508, Training Loss: 2.544e-02, Validation Loss: 6.191e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8509, Training Loss: 2.544e-02, Validation Loss: 6.192e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8510, Training Loss: 2.543e-02, Validation Loss: 6.191e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8511, Training Loss: 2.543e-02, Validation Loss: 6.191e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8512, Training Loss: 2.543e-02, Validation Loss: 6.192e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8513, Training Loss: 2.542e-02, Validation Loss: 6.191e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8514, Training Loss: 2.542e-02, Validation Loss: 6.192e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8515, Training Loss: 2.541e-02, Validation Loss: 6.192e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8516, Training Loss: 2.541e-02, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8517, Training Loss: 2.540e-02, Validation Loss: 6.192e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8518, Training Loss: 2.540e-02, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8519, Training Loss: 2.539e-02, Validation Loss: 6.192e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8520, Training Loss: 2.539e-02, Validation Loss: 6.193e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8521, Training Loss: 2.538e-02, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8522, Training Loss: 2.538e-02, Validation Loss: 6.192e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8523, Training Loss: 2.537e-02, Validation Loss: 6.193e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8524, Training Loss: 2.537e-02, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8525, Training Loss: 2.536e-02, Validation Loss: 6.192e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8526, Training Loss: 2.536e-02, Validation Loss: 6.193e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8527, Training Loss: 2.536e-02, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8528, Training Loss: 2.535e-02, Validation Loss: 6.193e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8529, Training Loss: 2.535e-02, Validation Loss: 6.193e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8530, Training Loss: 2.534e-02, Validation Loss: 6.193e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8531, Training Loss: 2.534e-02, Validation Loss: 6.193e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8532, Training Loss: 2.533e-02, Validation Loss: 6.193e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8533, Training Loss: 2.533e-02, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8534, Training Loss: 2.532e-02, Validation Loss: 6.194e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8535, Training Loss: 2.532e-02, Validation Loss: 6.194e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8536, Training Loss: 2.531e-02, Validation Loss: 6.193e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8537, Training Loss: 2.531e-02, Validation Loss: 6.194e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8538, Training Loss: 2.530e-02, Validation Loss: 6.194e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8539, Training Loss: 2.530e-02, Validation Loss: 6.193e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8540, Training Loss: 2.530e-02, Validation Loss: 6.194e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8541, Training Loss: 2.529e-02, Validation Loss: 6.194e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8542, Training Loss: 2.529e-02, Validation Loss: 6.194e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8543, Training Loss: 2.528e-02, Validation Loss: 6.194e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8544, Training Loss: 2.528e-02, Validation Loss: 6.194e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8545, Training Loss: 2.527e-02, Validation Loss: 6.194e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8546, Training Loss: 2.527e-02, Validation Loss: 6.194e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8547, Training Loss: 2.526e-02, Validation Loss: 6.194e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8548, Training Loss: 2.526e-02, Validation Loss: 6.195e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8549, Training Loss: 2.525e-02, Validation Loss: 6.194e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8550, Training Loss: 2.525e-02, Validation Loss: 6.195e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8551, Training Loss: 2.524e-02, Validation Loss: 6.194e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8552, Training Loss: 2.524e-02, Validation Loss: 6.195e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8553, Training Loss: 2.523e-02, Validation Loss: 6.195e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8554, Training Loss: 2.523e-02, Validation Loss: 6.194e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8555, Training Loss: 2.523e-02, Validation Loss: 6.195e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8556, Training Loss: 2.522e-02, Validation Loss: 6.195e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8557, Training Loss: 2.522e-02, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8558, Training Loss: 2.521e-02, Validation Loss: 6.195e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8559, Training Loss: 2.521e-02, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8560, Training Loss: 2.520e-02, Validation Loss: 6.195e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8561, Training Loss: 2.520e-02, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8562, Training Loss: 2.519e-02, Validation Loss: 6.196e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8563, Training Loss: 2.519e-02, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8564, Training Loss: 2.518e-02, Validation Loss: 6.196e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8565, Training Loss: 2.518e-02, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8566, Training Loss: 2.517e-02, Validation Loss: 6.196e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8567, Training Loss: 2.517e-02, Validation Loss: 6.196e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8568, Training Loss: 2.517e-02, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8569, Training Loss: 2.516e-02, Validation Loss: 6.196e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8570, Training Loss: 2.516e-02, Validation Loss: 6.196e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8571, Training Loss: 2.515e-02, Validation Loss: 6.196e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8572, Training Loss: 2.515e-02, Validation Loss: 6.196e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8573, Training Loss: 2.514e-02, Validation Loss: 6.197e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8574, Training Loss: 2.514e-02, Validation Loss: 6.196e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8575, Training Loss: 2.513e-02, Validation Loss: 6.197e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8576, Training Loss: 2.513e-02, Validation Loss: 6.196e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8577, Training Loss: 2.512e-02, Validation Loss: 6.197e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8578, Training Loss: 2.512e-02, Validation Loss: 6.197e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8579, Training Loss: 2.512e-02, Validation Loss: 6.196e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8580, Training Loss: 2.511e-02, Validation Loss: 6.197e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8581, Training Loss: 2.511e-02, Validation Loss: 6.197e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8582, Training Loss: 2.510e-02, Validation Loss: 6.197e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8583, Training Loss: 2.510e-02, Validation Loss: 6.197e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8584, Training Loss: 2.509e-02, Validation Loss: 6.197e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8585, Training Loss: 2.509e-02, Validation Loss: 6.197e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8586, Training Loss: 2.508e-02, Validation Loss: 6.197e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8587, Training Loss: 2.508e-02, Validation Loss: 6.197e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8588, Training Loss: 2.507e-02, Validation Loss: 6.198e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8589, Training Loss: 2.507e-02, Validation Loss: 6.197e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8590, Training Loss: 2.506e-02, Validation Loss: 6.198e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8591, Training Loss: 2.506e-02, Validation Loss: 6.198e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8592, Training Loss: 2.506e-02, Validation Loss: 6.197e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8593, Training Loss: 2.505e-02, Validation Loss: 6.198e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8594, Training Loss: 2.505e-02, Validation Loss: 6.198e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8595, Training Loss: 2.504e-02, Validation Loss: 6.198e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8596, Training Loss: 2.504e-02, Validation Loss: 6.198e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8597, Training Loss: 2.503e-02, Validation Loss: 6.198e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8598, Training Loss: 2.503e-02, Validation Loss: 6.198e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8599, Training Loss: 2.502e-02, Validation Loss: 6.198e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8600, Training Loss: 2.502e-02, Validation Loss: 6.198e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8601, Training Loss: 2.501e-02, Validation Loss: 6.199e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8602, Training Loss: 2.501e-02, Validation Loss: 6.198e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8603, Training Loss: 2.501e-02, Validation Loss: 6.199e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8604, Training Loss: 2.500e-02, Validation Loss: 6.199e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8605, Training Loss: 2.500e-02, Validation Loss: 6.199e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8606, Training Loss: 2.499e-02, Validation Loss: 6.199e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8607, Training Loss: 2.499e-02, Validation Loss: 6.199e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8608, Training Loss: 2.498e-02, Validation Loss: 6.199e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8609, Training Loss: 2.498e-02, Validation Loss: 6.199e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8610, Training Loss: 2.497e-02, Validation Loss: 6.199e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8611, Training Loss: 2.497e-02, Validation Loss: 6.199e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8612, Training Loss: 2.496e-02, Validation Loss: 6.199e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8613, Training Loss: 2.496e-02, Validation Loss: 6.199e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8614, Training Loss: 2.496e-02, Validation Loss: 6.200e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8615, Training Loss: 2.495e-02, Validation Loss: 6.199e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8616, Training Loss: 2.495e-02, Validation Loss: 6.200e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8617, Training Loss: 2.494e-02, Validation Loss: 6.199e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8618, Training Loss: 2.494e-02, Validation Loss: 6.200e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8619, Training Loss: 2.493e-02, Validation Loss: 6.199e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8620, Training Loss: 2.493e-02, Validation Loss: 6.200e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8621, Training Loss: 2.492e-02, Validation Loss: 6.200e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8622, Training Loss: 2.492e-02, Validation Loss: 6.200e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8623, Training Loss: 2.491e-02, Validation Loss: 6.200e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8624, Training Loss: 2.491e-02, Validation Loss: 6.200e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8625, Training Loss: 2.491e-02, Validation Loss: 6.200e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8626, Training Loss: 2.490e-02, Validation Loss: 6.201e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8627, Training Loss: 2.490e-02, Validation Loss: 6.200e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8628, Training Loss: 2.489e-02, Validation Loss: 6.200e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8629, Training Loss: 2.489e-02, Validation Loss: 6.201e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8630, Training Loss: 2.488e-02, Validation Loss: 6.200e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8631, Training Loss: 2.488e-02, Validation Loss: 6.201e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8632, Training Loss: 2.487e-02, Validation Loss: 6.201e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8633, Training Loss: 2.487e-02, Validation Loss: 6.201e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8634, Training Loss: 2.486e-02, Validation Loss: 6.201e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8635, Training Loss: 2.486e-02, Validation Loss: 6.201e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8636, Training Loss: 2.486e-02, Validation Loss: 6.202e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8637, Training Loss: 2.485e-02, Validation Loss: 6.201e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8638, Training Loss: 2.485e-02, Validation Loss: 6.201e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8639, Training Loss: 2.484e-02, Validation Loss: 6.202e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8640, Training Loss: 2.484e-02, Validation Loss: 6.201e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8641, Training Loss: 2.483e-02, Validation Loss: 6.201e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8642, Training Loss: 2.483e-02, Validation Loss: 6.202e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8643, Training Loss: 2.482e-02, Validation Loss: 6.201e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8644, Training Loss: 2.482e-02, Validation Loss: 6.202e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8645, Training Loss: 2.482e-02, Validation Loss: 6.201e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8646, Training Loss: 2.481e-02, Validation Loss: 6.202e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8647, Training Loss: 2.481e-02, Validation Loss: 6.202e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8648, Training Loss: 2.480e-02, Validation Loss: 6.202e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8649, Training Loss: 2.480e-02, Validation Loss: 6.202e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8650, Training Loss: 2.479e-02, Validation Loss: 6.202e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8651, Training Loss: 2.479e-02, Validation Loss: 6.203e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8652, Training Loss: 2.478e-02, Validation Loss: 6.202e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8653, Training Loss: 2.478e-02, Validation Loss: 6.202e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8654, Training Loss: 2.478e-02, Validation Loss: 6.203e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8655, Training Loss: 2.477e-02, Validation Loss: 6.202e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8656, Training Loss: 2.477e-02, Validation Loss: 6.203e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8657, Training Loss: 2.476e-02, Validation Loss: 6.202e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8658, Training Loss: 2.476e-02, Validation Loss: 6.203e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8659, Training Loss: 2.475e-02, Validation Loss: 6.203e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8660, Training Loss: 2.475e-02, Validation Loss: 6.202e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8661, Training Loss: 2.474e-02, Validation Loss: 6.203e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8662, Training Loss: 2.474e-02, Validation Loss: 6.203e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8663, Training Loss: 2.473e-02, Validation Loss: 6.203e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8664, Training Loss: 2.473e-02, Validation Loss: 6.203e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8665, Training Loss: 2.473e-02, Validation Loss: 6.203e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8666, Training Loss: 2.472e-02, Validation Loss: 6.203e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8667, Training Loss: 2.472e-02, Validation Loss: 6.204e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8668, Training Loss: 2.471e-02, Validation Loss: 6.204e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8669, Training Loss: 2.471e-02, Validation Loss: 6.203e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8670, Training Loss: 2.470e-02, Validation Loss: 6.204e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8671, Training Loss: 2.470e-02, Validation Loss: 6.204e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8672, Training Loss: 2.469e-02, Validation Loss: 6.204e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8673, Training Loss: 2.469e-02, Validation Loss: 6.204e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8674, Training Loss: 2.469e-02, Validation Loss: 6.204e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8675, Training Loss: 2.468e-02, Validation Loss: 6.204e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8676, Training Loss: 2.468e-02, Validation Loss: 6.204e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8677, Training Loss: 2.467e-02, Validation Loss: 6.204e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8678, Training Loss: 2.467e-02, Validation Loss: 6.204e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8679, Training Loss: 2.466e-02, Validation Loss: 6.205e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8680, Training Loss: 2.466e-02, Validation Loss: 6.204e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8681, Training Loss: 2.465e-02, Validation Loss: 6.204e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8682, Training Loss: 2.465e-02, Validation Loss: 6.205e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8683, Training Loss: 2.465e-02, Validation Loss: 6.204e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8684, Training Loss: 2.464e-02, Validation Loss: 6.205e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8685, Training Loss: 2.464e-02, Validation Loss: 6.205e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8686, Training Loss: 2.463e-02, Validation Loss: 6.205e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8687, Training Loss: 2.463e-02, Validation Loss: 6.205e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8688, Training Loss: 2.462e-02, Validation Loss: 6.205e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8689, Training Loss: 2.462e-02, Validation Loss: 6.205e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8690, Training Loss: 2.461e-02, Validation Loss: 6.206e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8691, Training Loss: 2.461e-02, Validation Loss: 6.205e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8692, Training Loss: 2.461e-02, Validation Loss: 6.205e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8693, Training Loss: 2.460e-02, Validation Loss: 6.206e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8694, Training Loss: 2.460e-02, Validation Loss: 6.205e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8695, Training Loss: 2.459e-02, Validation Loss: 6.206e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8696, Training Loss: 2.459e-02, Validation Loss: 6.206e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8697, Training Loss: 2.458e-02, Validation Loss: 6.205e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8698, Training Loss: 2.458e-02, Validation Loss: 6.206e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8699, Training Loss: 2.457e-02, Validation Loss: 6.206e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8700, Training Loss: 2.457e-02, Validation Loss: 6.206e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8701, Training Loss: 2.457e-02, Validation Loss: 6.206e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8702, Training Loss: 2.456e-02, Validation Loss: 6.206e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8703, Training Loss: 2.456e-02, Validation Loss: 6.206e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8704, Training Loss: 2.455e-02, Validation Loss: 6.206e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8705, Training Loss: 2.455e-02, Validation Loss: 6.206e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8706, Training Loss: 2.454e-02, Validation Loss: 6.207e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8707, Training Loss: 2.454e-02, Validation Loss: 6.206e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8708, Training Loss: 2.454e-02, Validation Loss: 6.206e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8709, Training Loss: 2.453e-02, Validation Loss: 6.207e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8710, Training Loss: 2.453e-02, Validation Loss: 6.206e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8711, Training Loss: 2.452e-02, Validation Loss: 6.207e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8712, Training Loss: 2.452e-02, Validation Loss: 6.207e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8713, Training Loss: 2.451e-02, Validation Loss: 6.207e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8714, Training Loss: 2.451e-02, Validation Loss: 6.207e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8715, Training Loss: 2.450e-02, Validation Loss: 6.207e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8716, Training Loss: 2.450e-02, Validation Loss: 6.208e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8717, Training Loss: 2.450e-02, Validation Loss: 6.207e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8718, Training Loss: 2.449e-02, Validation Loss: 6.207e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8719, Training Loss: 2.449e-02, Validation Loss: 6.208e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8720, Training Loss: 2.448e-02, Validation Loss: 6.207e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8721, Training Loss: 2.448e-02, Validation Loss: 6.208e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8722, Training Loss: 2.447e-02, Validation Loss: 6.208e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8723, Training Loss: 2.447e-02, Validation Loss: 6.207e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8724, Training Loss: 2.447e-02, Validation Loss: 6.208e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8725, Training Loss: 2.446e-02, Validation Loss: 6.208e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8726, Training Loss: 2.446e-02, Validation Loss: 6.208e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8727, Training Loss: 2.445e-02, Validation Loss: 6.208e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8728, Training Loss: 2.445e-02, Validation Loss: 6.208e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8729, Training Loss: 2.444e-02, Validation Loss: 6.209e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8730, Training Loss: 2.444e-02, Validation Loss: 6.208e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8731, Training Loss: 2.443e-02, Validation Loss: 6.208e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8732, Training Loss: 2.443e-02, Validation Loss: 6.209e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8733, Training Loss: 2.443e-02, Validation Loss: 6.208e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8734, Training Loss: 2.442e-02, Validation Loss: 6.209e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8735, Training Loss: 2.442e-02, Validation Loss: 6.209e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8736, Training Loss: 2.441e-02, Validation Loss: 6.208e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8737, Training Loss: 2.441e-02, Validation Loss: 6.209e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8738, Training Loss: 2.440e-02, Validation Loss: 6.209e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8739, Training Loss: 2.440e-02, Validation Loss: 6.209e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8740, Training Loss: 2.439e-02, Validation Loss: 6.209e-01, Patience: 4, Learning Rate: 0.01\n",
      "Epoch 8741, Training Loss: 2.439e-02, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8742, Training Loss: 2.439e-02, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8743, Training Loss: 2.438e-02, Validation Loss: 6.210e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8744, Training Loss: 2.438e-02, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8745, Training Loss: 2.437e-02, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8746, Training Loss: 2.437e-02, Validation Loss: 6.209e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8747, Training Loss: 2.436e-02, Validation Loss: 6.210e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8748, Training Loss: 2.436e-02, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8749, Training Loss: 2.436e-02, Validation Loss: 6.210e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8750, Training Loss: 2.435e-02, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8751, Training Loss: 2.435e-02, Validation Loss: 6.210e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8752, Training Loss: 2.434e-02, Validation Loss: 6.210e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8753, Training Loss: 2.434e-02, Validation Loss: 6.210e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8754, Training Loss: 2.433e-02, Validation Loss: 6.210e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8755, Training Loss: 2.433e-02, Validation Loss: 6.210e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8756, Training Loss: 2.433e-02, Validation Loss: 6.210e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8757, Training Loss: 2.432e-02, Validation Loss: 6.210e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8758, Training Loss: 2.432e-02, Validation Loss: 6.210e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8759, Training Loss: 2.431e-02, Validation Loss: 6.210e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8760, Training Loss: 2.431e-02, Validation Loss: 6.210e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8761, Training Loss: 2.430e-02, Validation Loss: 6.211e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8762, Training Loss: 2.430e-02, Validation Loss: 6.211e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8763, Training Loss: 2.430e-02, Validation Loss: 6.210e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8764, Training Loss: 2.429e-02, Validation Loss: 6.211e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8765, Training Loss: 2.429e-02, Validation Loss: 6.211e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8766, Training Loss: 2.428e-02, Validation Loss: 6.211e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8767, Training Loss: 2.428e-02, Validation Loss: 6.211e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8768, Training Loss: 2.427e-02, Validation Loss: 6.211e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8769, Training Loss: 2.427e-02, Validation Loss: 6.211e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8770, Training Loss: 2.426e-02, Validation Loss: 6.212e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8771, Training Loss: 2.426e-02, Validation Loss: 6.211e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8772, Training Loss: 2.426e-02, Validation Loss: 6.212e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8773, Training Loss: 2.425e-02, Validation Loss: 6.212e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8774, Training Loss: 2.425e-02, Validation Loss: 6.211e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8775, Training Loss: 2.424e-02, Validation Loss: 6.212e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8776, Training Loss: 2.424e-02, Validation Loss: 6.212e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8777, Training Loss: 2.423e-02, Validation Loss: 6.212e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8778, Training Loss: 2.423e-02, Validation Loss: 6.212e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8779, Training Loss: 2.423e-02, Validation Loss: 6.212e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8780, Training Loss: 2.422e-02, Validation Loss: 6.212e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8781, Training Loss: 2.422e-02, Validation Loss: 6.212e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8782, Training Loss: 2.421e-02, Validation Loss: 6.212e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8783, Training Loss: 2.421e-02, Validation Loss: 6.213e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8784, Training Loss: 2.420e-02, Validation Loss: 6.212e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8785, Training Loss: 2.420e-02, Validation Loss: 6.213e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8786, Training Loss: 2.420e-02, Validation Loss: 6.213e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8787, Training Loss: 2.419e-02, Validation Loss: 6.212e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8788, Training Loss: 2.419e-02, Validation Loss: 6.213e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8789, Training Loss: 2.418e-02, Validation Loss: 6.213e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8790, Training Loss: 2.418e-02, Validation Loss: 6.212e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8791, Training Loss: 2.417e-02, Validation Loss: 6.213e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8792, Training Loss: 2.417e-02, Validation Loss: 6.213e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8793, Training Loss: 2.417e-02, Validation Loss: 6.213e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8794, Training Loss: 2.416e-02, Validation Loss: 6.213e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8795, Training Loss: 2.416e-02, Validation Loss: 6.213e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8796, Training Loss: 2.415e-02, Validation Loss: 6.213e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8797, Training Loss: 2.415e-02, Validation Loss: 6.213e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8798, Training Loss: 2.414e-02, Validation Loss: 6.213e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8799, Training Loss: 2.414e-02, Validation Loss: 6.214e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8800, Training Loss: 2.414e-02, Validation Loss: 6.213e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8801, Training Loss: 2.413e-02, Validation Loss: 6.214e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8802, Training Loss: 2.413e-02, Validation Loss: 6.214e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8803, Training Loss: 2.412e-02, Validation Loss: 6.214e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8804, Training Loss: 2.412e-02, Validation Loss: 6.214e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8805, Training Loss: 2.411e-02, Validation Loss: 6.214e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8806, Training Loss: 2.411e-02, Validation Loss: 6.214e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8807, Training Loss: 2.411e-02, Validation Loss: 6.214e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8808, Training Loss: 2.410e-02, Validation Loss: 6.215e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8809, Training Loss: 2.410e-02, Validation Loss: 6.214e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8810, Training Loss: 2.409e-02, Validation Loss: 6.214e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8811, Training Loss: 2.409e-02, Validation Loss: 6.215e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8812, Training Loss: 2.408e-02, Validation Loss: 6.214e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8813, Training Loss: 2.408e-02, Validation Loss: 6.214e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8814, Training Loss: 2.408e-02, Validation Loss: 6.215e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8815, Training Loss: 2.407e-02, Validation Loss: 6.215e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8816, Training Loss: 2.407e-02, Validation Loss: 6.215e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8817, Training Loss: 2.406e-02, Validation Loss: 6.215e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8818, Training Loss: 2.406e-02, Validation Loss: 6.215e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8819, Training Loss: 2.405e-02, Validation Loss: 6.214e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8820, Training Loss: 2.405e-02, Validation Loss: 6.215e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8821, Training Loss: 2.405e-02, Validation Loss: 6.215e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8822, Training Loss: 2.404e-02, Validation Loss: 6.215e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8823, Training Loss: 2.404e-02, Validation Loss: 6.215e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8824, Training Loss: 2.403e-02, Validation Loss: 6.216e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8825, Training Loss: 2.403e-02, Validation Loss: 6.215e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8826, Training Loss: 2.402e-02, Validation Loss: 6.216e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8827, Training Loss: 2.402e-02, Validation Loss: 6.215e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8828, Training Loss: 2.402e-02, Validation Loss: 6.216e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8829, Training Loss: 2.401e-02, Validation Loss: 6.216e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8830, Training Loss: 2.401e-02, Validation Loss: 6.216e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8831, Training Loss: 2.400e-02, Validation Loss: 6.216e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8832, Training Loss: 2.400e-02, Validation Loss: 6.216e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8833, Training Loss: 2.400e-02, Validation Loss: 6.216e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8834, Training Loss: 2.399e-02, Validation Loss: 6.216e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8835, Training Loss: 2.399e-02, Validation Loss: 6.216e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8836, Training Loss: 2.398e-02, Validation Loss: 6.216e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8837, Training Loss: 2.398e-02, Validation Loss: 6.216e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8838, Training Loss: 2.397e-02, Validation Loss: 6.216e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8839, Training Loss: 2.397e-02, Validation Loss: 6.216e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8840, Training Loss: 2.397e-02, Validation Loss: 6.217e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8841, Training Loss: 2.396e-02, Validation Loss: 6.217e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8842, Training Loss: 2.396e-02, Validation Loss: 6.216e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8843, Training Loss: 2.395e-02, Validation Loss: 6.217e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8844, Training Loss: 2.395e-02, Validation Loss: 6.217e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8845, Training Loss: 2.394e-02, Validation Loss: 6.217e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8846, Training Loss: 2.394e-02, Validation Loss: 6.217e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8847, Training Loss: 2.394e-02, Validation Loss: 6.217e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8848, Training Loss: 2.393e-02, Validation Loss: 6.217e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8849, Training Loss: 2.393e-02, Validation Loss: 6.217e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8850, Training Loss: 2.392e-02, Validation Loss: 6.218e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8851, Training Loss: 2.392e-02, Validation Loss: 6.217e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8852, Training Loss: 2.392e-02, Validation Loss: 6.218e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8853, Training Loss: 2.391e-02, Validation Loss: 6.218e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8854, Training Loss: 2.391e-02, Validation Loss: 6.217e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8855, Training Loss: 2.390e-02, Validation Loss: 6.218e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8856, Training Loss: 2.390e-02, Validation Loss: 6.218e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8857, Training Loss: 2.389e-02, Validation Loss: 6.218e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8858, Training Loss: 2.389e-02, Validation Loss: 6.218e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8859, Training Loss: 2.389e-02, Validation Loss: 6.218e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8860, Training Loss: 2.388e-02, Validation Loss: 6.218e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8861, Training Loss: 2.388e-02, Validation Loss: 6.218e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8862, Training Loss: 2.387e-02, Validation Loss: 6.218e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8863, Training Loss: 2.387e-02, Validation Loss: 6.218e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8864, Training Loss: 2.386e-02, Validation Loss: 6.219e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8865, Training Loss: 2.386e-02, Validation Loss: 6.218e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8866, Training Loss: 2.386e-02, Validation Loss: 6.219e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8867, Training Loss: 2.385e-02, Validation Loss: 6.219e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8868, Training Loss: 2.385e-02, Validation Loss: 6.219e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8869, Training Loss: 2.384e-02, Validation Loss: 6.219e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8870, Training Loss: 2.384e-02, Validation Loss: 6.219e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8871, Training Loss: 2.384e-02, Validation Loss: 6.219e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8872, Training Loss: 2.383e-02, Validation Loss: 6.219e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8873, Training Loss: 2.383e-02, Validation Loss: 6.219e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8874, Training Loss: 2.382e-02, Validation Loss: 6.220e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8875, Training Loss: 2.382e-02, Validation Loss: 6.219e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8876, Training Loss: 2.381e-02, Validation Loss: 6.219e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8877, Training Loss: 2.381e-02, Validation Loss: 6.220e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8878, Training Loss: 2.381e-02, Validation Loss: 6.219e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8879, Training Loss: 2.380e-02, Validation Loss: 6.220e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8880, Training Loss: 2.380e-02, Validation Loss: 6.220e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8881, Training Loss: 2.379e-02, Validation Loss: 6.220e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8882, Training Loss: 2.379e-02, Validation Loss: 6.219e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8883, Training Loss: 2.379e-02, Validation Loss: 6.220e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8884, Training Loss: 2.378e-02, Validation Loss: 6.220e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8885, Training Loss: 2.378e-02, Validation Loss: 6.220e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8886, Training Loss: 2.377e-02, Validation Loss: 6.220e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8887, Training Loss: 2.377e-02, Validation Loss: 6.220e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8888, Training Loss: 2.376e-02, Validation Loss: 6.220e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8889, Training Loss: 2.376e-02, Validation Loss: 6.220e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8890, Training Loss: 2.376e-02, Validation Loss: 6.221e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8891, Training Loss: 2.375e-02, Validation Loss: 6.220e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8892, Training Loss: 2.375e-02, Validation Loss: 6.221e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8893, Training Loss: 2.374e-02, Validation Loss: 6.220e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8894, Training Loss: 2.374e-02, Validation Loss: 6.221e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8895, Training Loss: 2.373e-02, Validation Loss: 6.221e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8896, Training Loss: 2.373e-02, Validation Loss: 6.221e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8897, Training Loss: 2.373e-02, Validation Loss: 6.221e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8898, Training Loss: 2.372e-02, Validation Loss: 6.221e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8899, Training Loss: 2.372e-02, Validation Loss: 6.221e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8900, Training Loss: 2.371e-02, Validation Loss: 6.221e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8901, Training Loss: 2.371e-02, Validation Loss: 6.221e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8902, Training Loss: 2.371e-02, Validation Loss: 6.221e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8903, Training Loss: 2.370e-02, Validation Loss: 6.221e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8904, Training Loss: 2.370e-02, Validation Loss: 6.222e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8905, Training Loss: 2.369e-02, Validation Loss: 6.221e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8906, Training Loss: 2.369e-02, Validation Loss: 6.222e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8907, Training Loss: 2.369e-02, Validation Loss: 6.222e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8908, Training Loss: 2.368e-02, Validation Loss: 6.222e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8909, Training Loss: 2.368e-02, Validation Loss: 6.222e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8910, Training Loss: 2.367e-02, Validation Loss: 6.222e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8911, Training Loss: 2.367e-02, Validation Loss: 6.222e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8912, Training Loss: 2.366e-02, Validation Loss: 6.222e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8913, Training Loss: 2.366e-02, Validation Loss: 6.222e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8914, Training Loss: 2.366e-02, Validation Loss: 6.223e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8915, Training Loss: 2.365e-02, Validation Loss: 6.222e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8916, Training Loss: 2.365e-02, Validation Loss: 6.223e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8917, Training Loss: 2.364e-02, Validation Loss: 6.222e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8918, Training Loss: 2.364e-02, Validation Loss: 6.223e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8919, Training Loss: 2.364e-02, Validation Loss: 6.223e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8920, Training Loss: 2.363e-02, Validation Loss: 6.222e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8921, Training Loss: 2.363e-02, Validation Loss: 6.223e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8922, Training Loss: 2.362e-02, Validation Loss: 6.223e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8923, Training Loss: 2.362e-02, Validation Loss: 6.223e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8924, Training Loss: 2.361e-02, Validation Loss: 6.223e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8925, Training Loss: 2.361e-02, Validation Loss: 6.223e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8926, Training Loss: 2.361e-02, Validation Loss: 6.223e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8927, Training Loss: 2.360e-02, Validation Loss: 6.223e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8928, Training Loss: 2.360e-02, Validation Loss: 6.223e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8929, Training Loss: 2.359e-02, Validation Loss: 6.224e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8930, Training Loss: 2.359e-02, Validation Loss: 6.223e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8931, Training Loss: 2.359e-02, Validation Loss: 6.224e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8932, Training Loss: 2.358e-02, Validation Loss: 6.224e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8933, Training Loss: 2.358e-02, Validation Loss: 6.224e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8934, Training Loss: 2.357e-02, Validation Loss: 6.224e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8935, Training Loss: 2.357e-02, Validation Loss: 6.224e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8936, Training Loss: 2.357e-02, Validation Loss: 6.224e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8937, Training Loss: 2.356e-02, Validation Loss: 6.224e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8938, Training Loss: 2.356e-02, Validation Loss: 6.224e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8939, Training Loss: 2.355e-02, Validation Loss: 6.224e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8940, Training Loss: 2.355e-02, Validation Loss: 6.224e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8941, Training Loss: 2.355e-02, Validation Loss: 6.224e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8942, Training Loss: 2.354e-02, Validation Loss: 6.225e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8943, Training Loss: 2.354e-02, Validation Loss: 6.224e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8944, Training Loss: 2.353e-02, Validation Loss: 6.225e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8945, Training Loss: 2.353e-02, Validation Loss: 6.224e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8946, Training Loss: 2.352e-02, Validation Loss: 6.225e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8947, Training Loss: 2.352e-02, Validation Loss: 6.225e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8948, Training Loss: 2.352e-02, Validation Loss: 6.225e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8949, Training Loss: 2.351e-02, Validation Loss: 6.225e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8950, Training Loss: 2.351e-02, Validation Loss: 6.225e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8951, Training Loss: 2.350e-02, Validation Loss: 6.225e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8952, Training Loss: 2.350e-02, Validation Loss: 6.225e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8953, Training Loss: 2.350e-02, Validation Loss: 6.225e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8954, Training Loss: 2.349e-02, Validation Loss: 6.225e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8955, Training Loss: 2.349e-02, Validation Loss: 6.225e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8956, Training Loss: 2.348e-02, Validation Loss: 6.226e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8957, Training Loss: 2.348e-02, Validation Loss: 6.226e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 8958, Training Loss: 2.348e-02, Validation Loss: 6.225e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8959, Training Loss: 2.347e-02, Validation Loss: 6.226e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8960, Training Loss: 2.347e-02, Validation Loss: 6.226e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8961, Training Loss: 2.346e-02, Validation Loss: 6.225e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8962, Training Loss: 2.346e-02, Validation Loss: 6.226e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8963, Training Loss: 2.345e-02, Validation Loss: 6.226e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8964, Training Loss: 2.345e-02, Validation Loss: 6.226e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8965, Training Loss: 2.345e-02, Validation Loss: 6.226e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8966, Training Loss: 2.344e-02, Validation Loss: 6.226e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8967, Training Loss: 2.344e-02, Validation Loss: 6.226e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8968, Training Loss: 2.343e-02, Validation Loss: 6.226e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8969, Training Loss: 2.343e-02, Validation Loss: 6.226e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8970, Training Loss: 2.343e-02, Validation Loss: 6.226e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8971, Training Loss: 2.342e-02, Validation Loss: 6.226e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8972, Training Loss: 2.342e-02, Validation Loss: 6.227e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8973, Training Loss: 2.341e-02, Validation Loss: 6.226e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8974, Training Loss: 2.341e-02, Validation Loss: 6.227e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8975, Training Loss: 2.341e-02, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8976, Training Loss: 2.340e-02, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8977, Training Loss: 2.340e-02, Validation Loss: 6.227e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8978, Training Loss: 2.339e-02, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8979, Training Loss: 2.339e-02, Validation Loss: 6.227e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8980, Training Loss: 2.339e-02, Validation Loss: 6.227e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8981, Training Loss: 2.338e-02, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8982, Training Loss: 2.338e-02, Validation Loss: 6.227e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8983, Training Loss: 2.337e-02, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8984, Training Loss: 2.337e-02, Validation Loss: 6.228e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8985, Training Loss: 2.337e-02, Validation Loss: 6.228e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8986, Training Loss: 2.336e-02, Validation Loss: 6.228e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8987, Training Loss: 2.336e-02, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8988, Training Loss: 2.335e-02, Validation Loss: 6.228e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8989, Training Loss: 2.335e-02, Validation Loss: 6.228e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8990, Training Loss: 2.335e-02, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8991, Training Loss: 2.334e-02, Validation Loss: 6.228e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8992, Training Loss: 2.334e-02, Validation Loss: 6.228e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 8993, Training Loss: 2.333e-02, Validation Loss: 6.228e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8994, Training Loss: 2.333e-02, Validation Loss: 6.228e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8995, Training Loss: 2.333e-02, Validation Loss: 6.228e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8996, Training Loss: 2.332e-02, Validation Loss: 6.229e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8997, Training Loss: 2.332e-02, Validation Loss: 6.228e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 8998, Training Loss: 2.331e-02, Validation Loss: 6.229e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 8999, Training Loss: 2.331e-02, Validation Loss: 6.229e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9000, Training Loss: 2.331e-02, Validation Loss: 6.228e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9001, Training Loss: 2.330e-02, Validation Loss: 6.229e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9002, Training Loss: 2.330e-02, Validation Loss: 6.229e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9003, Training Loss: 2.329e-02, Validation Loss: 6.229e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9004, Training Loss: 2.329e-02, Validation Loss: 6.229e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9005, Training Loss: 2.328e-02, Validation Loss: 6.229e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9006, Training Loss: 2.328e-02, Validation Loss: 6.229e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9007, Training Loss: 2.328e-02, Validation Loss: 6.229e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9008, Training Loss: 2.327e-02, Validation Loss: 6.229e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9009, Training Loss: 2.327e-02, Validation Loss: 6.230e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9010, Training Loss: 2.327e-02, Validation Loss: 6.229e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9011, Training Loss: 2.326e-02, Validation Loss: 6.230e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9012, Training Loss: 2.326e-02, Validation Loss: 6.230e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9013, Training Loss: 2.325e-02, Validation Loss: 6.229e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9014, Training Loss: 2.325e-02, Validation Loss: 6.230e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9015, Training Loss: 2.324e-02, Validation Loss: 6.229e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9016, Training Loss: 2.324e-02, Validation Loss: 6.230e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9017, Training Loss: 2.324e-02, Validation Loss: 6.230e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9018, Training Loss: 2.323e-02, Validation Loss: 6.230e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9019, Training Loss: 2.323e-02, Validation Loss: 6.230e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9020, Training Loss: 2.322e-02, Validation Loss: 6.231e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9021, Training Loss: 2.322e-02, Validation Loss: 6.230e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9022, Training Loss: 2.322e-02, Validation Loss: 6.230e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9023, Training Loss: 2.321e-02, Validation Loss: 6.231e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9024, Training Loss: 2.321e-02, Validation Loss: 6.230e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9025, Training Loss: 2.320e-02, Validation Loss: 6.231e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9026, Training Loss: 2.320e-02, Validation Loss: 6.231e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9027, Training Loss: 2.320e-02, Validation Loss: 6.231e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9028, Training Loss: 2.319e-02, Validation Loss: 6.231e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9029, Training Loss: 2.319e-02, Validation Loss: 6.231e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9030, Training Loss: 2.318e-02, Validation Loss: 6.231e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9031, Training Loss: 2.318e-02, Validation Loss: 6.231e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9032, Training Loss: 2.318e-02, Validation Loss: 6.231e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9033, Training Loss: 2.317e-02, Validation Loss: 6.231e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9034, Training Loss: 2.317e-02, Validation Loss: 6.231e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9035, Training Loss: 2.316e-02, Validation Loss: 6.232e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9036, Training Loss: 2.316e-02, Validation Loss: 6.231e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9037, Training Loss: 2.316e-02, Validation Loss: 6.232e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9038, Training Loss: 2.315e-02, Validation Loss: 6.231e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9039, Training Loss: 2.315e-02, Validation Loss: 6.232e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9040, Training Loss: 2.314e-02, Validation Loss: 6.231e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9041, Training Loss: 2.314e-02, Validation Loss: 6.232e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9042, Training Loss: 2.314e-02, Validation Loss: 6.232e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9043, Training Loss: 2.313e-02, Validation Loss: 6.232e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9044, Training Loss: 2.313e-02, Validation Loss: 6.232e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9045, Training Loss: 2.312e-02, Validation Loss: 6.233e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9046, Training Loss: 2.312e-02, Validation Loss: 6.232e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9047, Training Loss: 2.312e-02, Validation Loss: 6.232e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9048, Training Loss: 2.311e-02, Validation Loss: 6.232e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9049, Training Loss: 2.311e-02, Validation Loss: 6.233e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9050, Training Loss: 2.311e-02, Validation Loss: 6.232e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9051, Training Loss: 2.310e-02, Validation Loss: 6.232e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9052, Training Loss: 2.310e-02, Validation Loss: 6.233e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9053, Training Loss: 2.309e-02, Validation Loss: 6.233e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9054, Training Loss: 2.309e-02, Validation Loss: 6.233e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9055, Training Loss: 2.309e-02, Validation Loss: 6.233e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9056, Training Loss: 2.308e-02, Validation Loss: 6.233e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9057, Training Loss: 2.308e-02, Validation Loss: 6.233e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9058, Training Loss: 2.307e-02, Validation Loss: 6.233e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9059, Training Loss: 2.307e-02, Validation Loss: 6.233e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9060, Training Loss: 2.307e-02, Validation Loss: 6.233e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9061, Training Loss: 2.306e-02, Validation Loss: 6.234e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9062, Training Loss: 2.306e-02, Validation Loss: 6.233e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9063, Training Loss: 2.305e-02, Validation Loss: 6.234e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9064, Training Loss: 2.305e-02, Validation Loss: 6.234e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9065, Training Loss: 2.305e-02, Validation Loss: 6.233e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9066, Training Loss: 2.304e-02, Validation Loss: 6.234e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9067, Training Loss: 2.304e-02, Validation Loss: 6.234e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9068, Training Loss: 2.303e-02, Validation Loss: 6.234e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9069, Training Loss: 2.303e-02, Validation Loss: 6.234e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9070, Training Loss: 2.303e-02, Validation Loss: 6.234e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9071, Training Loss: 2.302e-02, Validation Loss: 6.234e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9072, Training Loss: 2.302e-02, Validation Loss: 6.234e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9073, Training Loss: 2.301e-02, Validation Loss: 6.234e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9074, Training Loss: 2.301e-02, Validation Loss: 6.234e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9075, Training Loss: 2.301e-02, Validation Loss: 6.235e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9076, Training Loss: 2.300e-02, Validation Loss: 6.234e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9077, Training Loss: 2.300e-02, Validation Loss: 6.235e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9078, Training Loss: 2.299e-02, Validation Loss: 6.235e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9079, Training Loss: 2.299e-02, Validation Loss: 6.235e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9080, Training Loss: 2.299e-02, Validation Loss: 6.235e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9081, Training Loss: 2.298e-02, Validation Loss: 6.235e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9082, Training Loss: 2.298e-02, Validation Loss: 6.235e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9083, Training Loss: 2.297e-02, Validation Loss: 6.235e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9084, Training Loss: 2.297e-02, Validation Loss: 6.235e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9085, Training Loss: 2.297e-02, Validation Loss: 6.235e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9086, Training Loss: 2.296e-02, Validation Loss: 6.235e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9087, Training Loss: 2.296e-02, Validation Loss: 6.235e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9088, Training Loss: 2.296e-02, Validation Loss: 6.235e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9089, Training Loss: 2.295e-02, Validation Loss: 6.236e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9090, Training Loss: 2.295e-02, Validation Loss: 6.235e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9091, Training Loss: 2.294e-02, Validation Loss: 6.236e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9092, Training Loss: 2.294e-02, Validation Loss: 6.235e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9093, Training Loss: 2.294e-02, Validation Loss: 6.236e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9094, Training Loss: 2.293e-02, Validation Loss: 6.236e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9095, Training Loss: 2.293e-02, Validation Loss: 6.236e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9096, Training Loss: 2.292e-02, Validation Loss: 6.236e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9097, Training Loss: 2.292e-02, Validation Loss: 6.237e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9098, Training Loss: 2.292e-02, Validation Loss: 6.236e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9099, Training Loss: 2.291e-02, Validation Loss: 6.237e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9100, Training Loss: 2.291e-02, Validation Loss: 6.236e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9101, Training Loss: 2.290e-02, Validation Loss: 6.237e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9102, Training Loss: 2.290e-02, Validation Loss: 6.237e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9103, Training Loss: 2.290e-02, Validation Loss: 6.236e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9104, Training Loss: 2.289e-02, Validation Loss: 6.237e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9105, Training Loss: 2.289e-02, Validation Loss: 6.237e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9106, Training Loss: 2.288e-02, Validation Loss: 6.236e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9107, Training Loss: 2.288e-02, Validation Loss: 6.237e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9108, Training Loss: 2.288e-02, Validation Loss: 6.237e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9109, Training Loss: 2.287e-02, Validation Loss: 6.237e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9110, Training Loss: 2.287e-02, Validation Loss: 6.237e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9111, Training Loss: 2.287e-02, Validation Loss: 6.237e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9112, Training Loss: 2.286e-02, Validation Loss: 6.237e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9113, Training Loss: 2.286e-02, Validation Loss: 6.237e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9114, Training Loss: 2.285e-02, Validation Loss: 6.237e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9115, Training Loss: 2.285e-02, Validation Loss: 6.237e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9116, Training Loss: 2.285e-02, Validation Loss: 6.238e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9117, Training Loss: 2.284e-02, Validation Loss: 6.237e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9118, Training Loss: 2.284e-02, Validation Loss: 6.238e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9119, Training Loss: 2.283e-02, Validation Loss: 6.238e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9120, Training Loss: 2.283e-02, Validation Loss: 6.238e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9121, Training Loss: 2.283e-02, Validation Loss: 6.238e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9122, Training Loss: 2.282e-02, Validation Loss: 6.238e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9123, Training Loss: 2.282e-02, Validation Loss: 6.238e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9124, Training Loss: 2.281e-02, Validation Loss: 6.238e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9125, Training Loss: 2.281e-02, Validation Loss: 6.238e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9126, Training Loss: 2.281e-02, Validation Loss: 6.238e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9127, Training Loss: 2.280e-02, Validation Loss: 6.239e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9128, Training Loss: 2.280e-02, Validation Loss: 6.238e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9129, Training Loss: 2.280e-02, Validation Loss: 6.239e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9130, Training Loss: 2.279e-02, Validation Loss: 6.238e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9131, Training Loss: 2.279e-02, Validation Loss: 6.239e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9132, Training Loss: 2.278e-02, Validation Loss: 6.239e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9133, Training Loss: 2.278e-02, Validation Loss: 6.239e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9134, Training Loss: 2.278e-02, Validation Loss: 6.239e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9135, Training Loss: 2.277e-02, Validation Loss: 6.239e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9136, Training Loss: 2.277e-02, Validation Loss: 6.239e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9137, Training Loss: 2.276e-02, Validation Loss: 6.239e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9138, Training Loss: 2.276e-02, Validation Loss: 6.239e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9139, Training Loss: 2.276e-02, Validation Loss: 6.239e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9140, Training Loss: 2.275e-02, Validation Loss: 6.239e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9141, Training Loss: 2.275e-02, Validation Loss: 6.240e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9142, Training Loss: 2.275e-02, Validation Loss: 6.239e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9143, Training Loss: 2.274e-02, Validation Loss: 6.240e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9144, Training Loss: 2.274e-02, Validation Loss: 6.239e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9145, Training Loss: 2.273e-02, Validation Loss: 6.240e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9146, Training Loss: 2.273e-02, Validation Loss: 6.240e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9147, Training Loss: 2.273e-02, Validation Loss: 6.239e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9148, Training Loss: 2.272e-02, Validation Loss: 6.240e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9149, Training Loss: 2.272e-02, Validation Loss: 6.240e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9150, Training Loss: 2.271e-02, Validation Loss: 6.240e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9151, Training Loss: 2.271e-02, Validation Loss: 6.240e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9152, Training Loss: 2.271e-02, Validation Loss: 6.241e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9153, Training Loss: 2.270e-02, Validation Loss: 6.240e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9154, Training Loss: 2.270e-02, Validation Loss: 6.241e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9155, Training Loss: 2.269e-02, Validation Loss: 6.240e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9156, Training Loss: 2.269e-02, Validation Loss: 6.241e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9157, Training Loss: 2.269e-02, Validation Loss: 6.241e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9158, Training Loss: 2.268e-02, Validation Loss: 6.240e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9159, Training Loss: 2.268e-02, Validation Loss: 6.241e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9160, Training Loss: 2.268e-02, Validation Loss: 6.241e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9161, Training Loss: 2.267e-02, Validation Loss: 6.240e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9162, Training Loss: 2.267e-02, Validation Loss: 6.241e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9163, Training Loss: 2.266e-02, Validation Loss: 6.241e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9164, Training Loss: 2.266e-02, Validation Loss: 6.241e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9165, Training Loss: 2.266e-02, Validation Loss: 6.241e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9166, Training Loss: 2.265e-02, Validation Loss: 6.242e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9167, Training Loss: 2.265e-02, Validation Loss: 6.241e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9168, Training Loss: 2.265e-02, Validation Loss: 6.242e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9169, Training Loss: 2.264e-02, Validation Loss: 6.241e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9170, Training Loss: 2.264e-02, Validation Loss: 6.242e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9171, Training Loss: 2.263e-02, Validation Loss: 6.242e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9172, Training Loss: 2.263e-02, Validation Loss: 6.242e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9173, Training Loss: 2.263e-02, Validation Loss: 6.242e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9174, Training Loss: 2.262e-02, Validation Loss: 6.242e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9175, Training Loss: 2.262e-02, Validation Loss: 6.242e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9176, Training Loss: 2.261e-02, Validation Loss: 6.242e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9177, Training Loss: 2.261e-02, Validation Loss: 6.242e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9178, Training Loss: 2.261e-02, Validation Loss: 6.242e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9179, Training Loss: 2.260e-02, Validation Loss: 6.242e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9180, Training Loss: 2.260e-02, Validation Loss: 6.242e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9181, Training Loss: 2.260e-02, Validation Loss: 6.243e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9182, Training Loss: 2.259e-02, Validation Loss: 6.243e-01, Patience: 4, Learning Rate: 0.01\n",
      "Epoch 9183, Training Loss: 2.259e-02, Validation Loss: 6.243e-01, Patience: 5, Learning Rate: 0.01\n",
      "Epoch 9184, Training Loss: 2.258e-02, Validation Loss: 6.242e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9185, Training Loss: 2.258e-02, Validation Loss: 6.243e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9186, Training Loss: 2.258e-02, Validation Loss: 6.243e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9187, Training Loss: 2.257e-02, Validation Loss: 6.243e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9188, Training Loss: 2.257e-02, Validation Loss: 6.243e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9189, Training Loss: 2.256e-02, Validation Loss: 6.243e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9190, Training Loss: 2.256e-02, Validation Loss: 6.243e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9191, Training Loss: 2.256e-02, Validation Loss: 6.243e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9192, Training Loss: 2.255e-02, Validation Loss: 6.244e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9193, Training Loss: 2.255e-02, Validation Loss: 6.243e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9194, Training Loss: 2.255e-02, Validation Loss: 6.243e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9195, Training Loss: 2.254e-02, Validation Loss: 6.244e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9196, Training Loss: 2.254e-02, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9197, Training Loss: 2.253e-02, Validation Loss: 6.244e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9198, Training Loss: 2.253e-02, Validation Loss: 6.244e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9199, Training Loss: 2.253e-02, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9200, Training Loss: 2.252e-02, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9201, Training Loss: 2.252e-02, Validation Loss: 6.244e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9202, Training Loss: 2.252e-02, Validation Loss: 6.245e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9203, Training Loss: 2.251e-02, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9204, Training Loss: 2.251e-02, Validation Loss: 6.244e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9205, Training Loss: 2.250e-02, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9206, Training Loss: 2.250e-02, Validation Loss: 6.245e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9207, Training Loss: 2.250e-02, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9208, Training Loss: 2.249e-02, Validation Loss: 6.245e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9209, Training Loss: 2.249e-02, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9210, Training Loss: 2.249e-02, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9211, Training Loss: 2.248e-02, Validation Loss: 6.245e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9212, Training Loss: 2.248e-02, Validation Loss: 6.245e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9213, Training Loss: 2.247e-02, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9214, Training Loss: 2.247e-02, Validation Loss: 6.245e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9215, Training Loss: 2.247e-02, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9216, Training Loss: 2.246e-02, Validation Loss: 6.245e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9217, Training Loss: 2.246e-02, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9218, Training Loss: 2.245e-02, Validation Loss: 6.246e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9219, Training Loss: 2.245e-02, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9220, Training Loss: 2.245e-02, Validation Loss: 6.246e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9221, Training Loss: 2.244e-02, Validation Loss: 6.246e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9222, Training Loss: 2.244e-02, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9223, Training Loss: 2.244e-02, Validation Loss: 6.245e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9224, Training Loss: 2.243e-02, Validation Loss: 6.246e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9225, Training Loss: 2.243e-02, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9226, Training Loss: 2.242e-02, Validation Loss: 6.246e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9227, Training Loss: 2.242e-02, Validation Loss: 6.246e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9228, Training Loss: 2.242e-02, Validation Loss: 6.246e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9229, Training Loss: 2.241e-02, Validation Loss: 6.246e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9230, Training Loss: 2.241e-02, Validation Loss: 6.246e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9231, Training Loss: 2.241e-02, Validation Loss: 6.246e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9232, Training Loss: 2.240e-02, Validation Loss: 6.247e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9233, Training Loss: 2.240e-02, Validation Loss: 6.246e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9234, Training Loss: 2.239e-02, Validation Loss: 6.247e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9235, Training Loss: 2.239e-02, Validation Loss: 6.247e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9236, Training Loss: 2.239e-02, Validation Loss: 6.247e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9237, Training Loss: 2.238e-02, Validation Loss: 6.247e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9238, Training Loss: 2.238e-02, Validation Loss: 6.247e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9239, Training Loss: 2.238e-02, Validation Loss: 6.247e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9240, Training Loss: 2.237e-02, Validation Loss: 6.247e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9241, Training Loss: 2.237e-02, Validation Loss: 6.246e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9242, Training Loss: 2.236e-02, Validation Loss: 6.247e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9243, Training Loss: 2.236e-02, Validation Loss: 6.247e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9244, Training Loss: 2.236e-02, Validation Loss: 6.247e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9245, Training Loss: 2.235e-02, Validation Loss: 6.247e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9246, Training Loss: 2.235e-02, Validation Loss: 6.248e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9247, Training Loss: 2.235e-02, Validation Loss: 6.247e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9248, Training Loss: 2.234e-02, Validation Loss: 6.248e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9249, Training Loss: 2.234e-02, Validation Loss: 6.248e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9250, Training Loss: 2.233e-02, Validation Loss: 6.248e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9251, Training Loss: 2.233e-02, Validation Loss: 6.248e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9252, Training Loss: 2.233e-02, Validation Loss: 6.248e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9253, Training Loss: 2.232e-02, Validation Loss: 6.248e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9254, Training Loss: 2.232e-02, Validation Loss: 6.248e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9255, Training Loss: 2.232e-02, Validation Loss: 6.248e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9256, Training Loss: 2.231e-02, Validation Loss: 6.249e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9257, Training Loss: 2.231e-02, Validation Loss: 6.248e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9258, Training Loss: 2.230e-02, Validation Loss: 6.248e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9259, Training Loss: 2.230e-02, Validation Loss: 6.249e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9260, Training Loss: 2.230e-02, Validation Loss: 6.248e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9261, Training Loss: 2.229e-02, Validation Loss: 6.249e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9262, Training Loss: 2.229e-02, Validation Loss: 6.249e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9263, Training Loss: 2.229e-02, Validation Loss: 6.248e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9264, Training Loss: 2.228e-02, Validation Loss: 6.249e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9265, Training Loss: 2.228e-02, Validation Loss: 6.249e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9266, Training Loss: 2.227e-02, Validation Loss: 6.249e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9267, Training Loss: 2.227e-02, Validation Loss: 6.249e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9268, Training Loss: 2.227e-02, Validation Loss: 6.249e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9269, Training Loss: 2.226e-02, Validation Loss: 6.249e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9270, Training Loss: 2.226e-02, Validation Loss: 6.249e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9271, Training Loss: 2.226e-02, Validation Loss: 6.249e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9272, Training Loss: 2.225e-02, Validation Loss: 6.249e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9273, Training Loss: 2.225e-02, Validation Loss: 6.249e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9274, Training Loss: 2.224e-02, Validation Loss: 6.250e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9275, Training Loss: 2.224e-02, Validation Loss: 6.249e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9276, Training Loss: 2.224e-02, Validation Loss: 6.250e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9277, Training Loss: 2.223e-02, Validation Loss: 6.249e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9278, Training Loss: 2.223e-02, Validation Loss: 6.250e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9279, Training Loss: 2.223e-02, Validation Loss: 6.250e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9280, Training Loss: 2.222e-02, Validation Loss: 6.250e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9281, Training Loss: 2.222e-02, Validation Loss: 6.250e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9282, Training Loss: 2.222e-02, Validation Loss: 6.250e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9283, Training Loss: 2.221e-02, Validation Loss: 6.250e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9284, Training Loss: 2.221e-02, Validation Loss: 6.250e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9285, Training Loss: 2.220e-02, Validation Loss: 6.251e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9286, Training Loss: 2.220e-02, Validation Loss: 6.250e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9287, Training Loss: 2.220e-02, Validation Loss: 6.250e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9288, Training Loss: 2.219e-02, Validation Loss: 6.251e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9289, Training Loss: 2.219e-02, Validation Loss: 6.251e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9290, Training Loss: 2.219e-02, Validation Loss: 6.250e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9291, Training Loss: 2.218e-02, Validation Loss: 6.251e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9292, Training Loss: 2.218e-02, Validation Loss: 6.251e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9293, Training Loss: 2.217e-02, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9294, Training Loss: 2.217e-02, Validation Loss: 6.251e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9295, Training Loss: 2.217e-02, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9296, Training Loss: 2.216e-02, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9297, Training Loss: 2.216e-02, Validation Loss: 6.251e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9298, Training Loss: 2.216e-02, Validation Loss: 6.251e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9299, Training Loss: 2.215e-02, Validation Loss: 6.252e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9300, Training Loss: 2.215e-02, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9301, Training Loss: 2.215e-02, Validation Loss: 6.251e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9302, Training Loss: 2.214e-02, Validation Loss: 6.252e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9303, Training Loss: 2.214e-02, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9304, Training Loss: 2.213e-02, Validation Loss: 6.252e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9305, Training Loss: 2.213e-02, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9306, Training Loss: 2.213e-02, Validation Loss: 6.252e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9307, Training Loss: 2.212e-02, Validation Loss: 6.252e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9308, Training Loss: 2.212e-02, Validation Loss: 6.252e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9309, Training Loss: 2.212e-02, Validation Loss: 6.252e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9310, Training Loss: 2.211e-02, Validation Loss: 6.253e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9311, Training Loss: 2.211e-02, Validation Loss: 6.252e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9312, Training Loss: 2.210e-02, Validation Loss: 6.253e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9313, Training Loss: 2.210e-02, Validation Loss: 6.252e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9314, Training Loss: 2.210e-02, Validation Loss: 6.253e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9315, Training Loss: 2.209e-02, Validation Loss: 6.253e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9316, Training Loss: 2.209e-02, Validation Loss: 6.252e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9317, Training Loss: 2.209e-02, Validation Loss: 6.253e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9318, Training Loss: 2.208e-02, Validation Loss: 6.253e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9319, Training Loss: 2.208e-02, Validation Loss: 6.253e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9320, Training Loss: 2.208e-02, Validation Loss: 6.253e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9321, Training Loss: 2.207e-02, Validation Loss: 6.253e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9322, Training Loss: 2.207e-02, Validation Loss: 6.253e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9323, Training Loss: 2.206e-02, Validation Loss: 6.253e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9324, Training Loss: 2.206e-02, Validation Loss: 6.254e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9325, Training Loss: 2.206e-02, Validation Loss: 6.253e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9326, Training Loss: 2.205e-02, Validation Loss: 6.254e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9327, Training Loss: 2.205e-02, Validation Loss: 6.253e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9328, Training Loss: 2.205e-02, Validation Loss: 6.254e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9329, Training Loss: 2.204e-02, Validation Loss: 6.253e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9330, Training Loss: 2.204e-02, Validation Loss: 6.254e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9331, Training Loss: 2.203e-02, Validation Loss: 6.254e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9332, Training Loss: 2.203e-02, Validation Loss: 6.254e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9333, Training Loss: 2.203e-02, Validation Loss: 6.254e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9334, Training Loss: 2.202e-02, Validation Loss: 6.254e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9335, Training Loss: 2.202e-02, Validation Loss: 6.254e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9336, Training Loss: 2.202e-02, Validation Loss: 6.254e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9337, Training Loss: 2.201e-02, Validation Loss: 6.254e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9338, Training Loss: 2.201e-02, Validation Loss: 6.254e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9339, Training Loss: 2.201e-02, Validation Loss: 6.254e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9340, Training Loss: 2.200e-02, Validation Loss: 6.254e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9341, Training Loss: 2.200e-02, Validation Loss: 6.254e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9342, Training Loss: 2.199e-02, Validation Loss: 6.255e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9343, Training Loss: 2.199e-02, Validation Loss: 6.254e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9344, Training Loss: 2.199e-02, Validation Loss: 6.255e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9345, Training Loss: 2.198e-02, Validation Loss: 6.255e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9346, Training Loss: 2.198e-02, Validation Loss: 6.255e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9347, Training Loss: 2.198e-02, Validation Loss: 6.255e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9348, Training Loss: 2.197e-02, Validation Loss: 6.255e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9349, Training Loss: 2.197e-02, Validation Loss: 6.255e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9350, Training Loss: 2.197e-02, Validation Loss: 6.255e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9351, Training Loss: 2.196e-02, Validation Loss: 6.255e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9352, Training Loss: 2.196e-02, Validation Loss: 6.256e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9353, Training Loss: 2.195e-02, Validation Loss: 6.255e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9354, Training Loss: 2.195e-02, Validation Loss: 6.256e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9355, Training Loss: 2.195e-02, Validation Loss: 6.256e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9356, Training Loss: 2.194e-02, Validation Loss: 6.255e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9357, Training Loss: 2.194e-02, Validation Loss: 6.256e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9358, Training Loss: 2.194e-02, Validation Loss: 6.256e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9359, Training Loss: 2.193e-02, Validation Loss: 6.255e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9360, Training Loss: 2.193e-02, Validation Loss: 6.256e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9361, Training Loss: 2.193e-02, Validation Loss: 6.256e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9362, Training Loss: 2.192e-02, Validation Loss: 6.256e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9363, Training Loss: 2.192e-02, Validation Loss: 6.256e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9364, Training Loss: 2.191e-02, Validation Loss: 6.257e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9365, Training Loss: 2.191e-02, Validation Loss: 6.256e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9366, Training Loss: 2.191e-02, Validation Loss: 6.257e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9367, Training Loss: 2.190e-02, Validation Loss: 6.256e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9368, Training Loss: 2.190e-02, Validation Loss: 6.257e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9369, Training Loss: 2.190e-02, Validation Loss: 6.256e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9370, Training Loss: 2.189e-02, Validation Loss: 6.257e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9371, Training Loss: 2.189e-02, Validation Loss: 6.257e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9372, Training Loss: 2.189e-02, Validation Loss: 6.257e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9373, Training Loss: 2.188e-02, Validation Loss: 6.257e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9374, Training Loss: 2.188e-02, Validation Loss: 6.257e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9375, Training Loss: 2.188e-02, Validation Loss: 6.257e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9376, Training Loss: 2.187e-02, Validation Loss: 6.257e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9377, Training Loss: 2.187e-02, Validation Loss: 6.258e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9378, Training Loss: 2.186e-02, Validation Loss: 6.257e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9379, Training Loss: 2.186e-02, Validation Loss: 6.257e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9380, Training Loss: 2.186e-02, Validation Loss: 6.258e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9381, Training Loss: 2.185e-02, Validation Loss: 6.257e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9382, Training Loss: 2.185e-02, Validation Loss: 6.258e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9383, Training Loss: 2.185e-02, Validation Loss: 6.258e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9384, Training Loss: 2.184e-02, Validation Loss: 6.257e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9385, Training Loss: 2.184e-02, Validation Loss: 6.258e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9386, Training Loss: 2.184e-02, Validation Loss: 6.258e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9387, Training Loss: 2.183e-02, Validation Loss: 6.258e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9388, Training Loss: 2.183e-02, Validation Loss: 6.258e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9389, Training Loss: 2.182e-02, Validation Loss: 6.259e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9390, Training Loss: 2.182e-02, Validation Loss: 6.258e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9391, Training Loss: 2.182e-02, Validation Loss: 6.258e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9392, Training Loss: 2.181e-02, Validation Loss: 6.259e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9393, Training Loss: 2.181e-02, Validation Loss: 6.258e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9394, Training Loss: 2.181e-02, Validation Loss: 6.259e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9395, Training Loss: 2.180e-02, Validation Loss: 6.259e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9396, Training Loss: 2.180e-02, Validation Loss: 6.259e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9397, Training Loss: 2.180e-02, Validation Loss: 6.259e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9398, Training Loss: 2.179e-02, Validation Loss: 6.259e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9399, Training Loss: 2.179e-02, Validation Loss: 6.259e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9400, Training Loss: 2.179e-02, Validation Loss: 6.258e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9401, Training Loss: 2.178e-02, Validation Loss: 6.259e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9402, Training Loss: 2.178e-02, Validation Loss: 6.259e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9403, Training Loss: 2.177e-02, Validation Loss: 6.259e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9404, Training Loss: 2.177e-02, Validation Loss: 6.259e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9405, Training Loss: 2.177e-02, Validation Loss: 6.259e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9406, Training Loss: 2.176e-02, Validation Loss: 6.260e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9407, Training Loss: 2.176e-02, Validation Loss: 6.259e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9408, Training Loss: 2.176e-02, Validation Loss: 6.260e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9409, Training Loss: 2.175e-02, Validation Loss: 6.260e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9410, Training Loss: 2.175e-02, Validation Loss: 6.260e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9411, Training Loss: 2.175e-02, Validation Loss: 6.260e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9412, Training Loss: 2.174e-02, Validation Loss: 6.260e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9413, Training Loss: 2.174e-02, Validation Loss: 6.260e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9414, Training Loss: 2.173e-02, Validation Loss: 6.260e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9415, Training Loss: 2.173e-02, Validation Loss: 6.260e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9416, Training Loss: 2.173e-02, Validation Loss: 6.260e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9417, Training Loss: 2.172e-02, Validation Loss: 6.261e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9418, Training Loss: 2.172e-02, Validation Loss: 6.260e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9419, Training Loss: 2.172e-02, Validation Loss: 6.260e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9420, Training Loss: 2.171e-02, Validation Loss: 6.261e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9421, Training Loss: 2.171e-02, Validation Loss: 6.260e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9422, Training Loss: 2.171e-02, Validation Loss: 6.261e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9423, Training Loss: 2.170e-02, Validation Loss: 6.261e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9424, Training Loss: 2.170e-02, Validation Loss: 6.261e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9425, Training Loss: 2.170e-02, Validation Loss: 6.261e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9426, Training Loss: 2.169e-02, Validation Loss: 6.261e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9427, Training Loss: 2.169e-02, Validation Loss: 6.261e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9428, Training Loss: 2.168e-02, Validation Loss: 6.261e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9429, Training Loss: 2.168e-02, Validation Loss: 6.261e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9430, Training Loss: 2.168e-02, Validation Loss: 6.262e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9431, Training Loss: 2.167e-02, Validation Loss: 6.261e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9432, Training Loss: 2.167e-02, Validation Loss: 6.262e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9433, Training Loss: 2.167e-02, Validation Loss: 6.262e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9434, Training Loss: 2.166e-02, Validation Loss: 6.261e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9435, Training Loss: 2.166e-02, Validation Loss: 6.262e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9436, Training Loss: 2.166e-02, Validation Loss: 6.261e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9437, Training Loss: 2.165e-02, Validation Loss: 6.262e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9438, Training Loss: 2.165e-02, Validation Loss: 6.262e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9439, Training Loss: 2.165e-02, Validation Loss: 6.262e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9440, Training Loss: 2.164e-02, Validation Loss: 6.262e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9441, Training Loss: 2.164e-02, Validation Loss: 6.262e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9442, Training Loss: 2.164e-02, Validation Loss: 6.262e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9443, Training Loss: 2.163e-02, Validation Loss: 6.262e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9444, Training Loss: 2.163e-02, Validation Loss: 6.262e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9445, Training Loss: 2.162e-02, Validation Loss: 6.262e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9446, Training Loss: 2.162e-02, Validation Loss: 6.263e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9447, Training Loss: 2.162e-02, Validation Loss: 6.262e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9448, Training Loss: 2.161e-02, Validation Loss: 6.263e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9449, Training Loss: 2.161e-02, Validation Loss: 6.263e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9450, Training Loss: 2.161e-02, Validation Loss: 6.263e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9451, Training Loss: 2.160e-02, Validation Loss: 6.263e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9452, Training Loss: 2.160e-02, Validation Loss: 6.263e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9453, Training Loss: 2.160e-02, Validation Loss: 6.263e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9454, Training Loss: 2.159e-02, Validation Loss: 6.263e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9455, Training Loss: 2.159e-02, Validation Loss: 6.263e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9456, Training Loss: 2.159e-02, Validation Loss: 6.264e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9457, Training Loss: 2.158e-02, Validation Loss: 6.263e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9458, Training Loss: 2.158e-02, Validation Loss: 6.264e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9459, Training Loss: 2.158e-02, Validation Loss: 6.264e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9460, Training Loss: 2.157e-02, Validation Loss: 6.263e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9461, Training Loss: 2.157e-02, Validation Loss: 6.264e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9462, Training Loss: 2.156e-02, Validation Loss: 6.264e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9463, Training Loss: 2.156e-02, Validation Loss: 6.264e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9464, Training Loss: 2.156e-02, Validation Loss: 6.264e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9465, Training Loss: 2.155e-02, Validation Loss: 6.263e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9466, Training Loss: 2.155e-02, Validation Loss: 6.264e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9467, Training Loss: 2.155e-02, Validation Loss: 6.264e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9468, Training Loss: 2.154e-02, Validation Loss: 6.264e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9469, Training Loss: 2.154e-02, Validation Loss: 6.264e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9470, Training Loss: 2.154e-02, Validation Loss: 6.264e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9471, Training Loss: 2.153e-02, Validation Loss: 6.264e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9472, Training Loss: 2.153e-02, Validation Loss: 6.264e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9473, Training Loss: 2.153e-02, Validation Loss: 6.265e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9474, Training Loss: 2.152e-02, Validation Loss: 6.264e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9475, Training Loss: 2.152e-02, Validation Loss: 6.265e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9476, Training Loss: 2.151e-02, Validation Loss: 6.265e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9477, Training Loss: 2.151e-02, Validation Loss: 6.264e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9478, Training Loss: 2.151e-02, Validation Loss: 6.265e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9479, Training Loss: 2.150e-02, Validation Loss: 6.265e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9480, Training Loss: 2.150e-02, Validation Loss: 6.265e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9481, Training Loss: 2.150e-02, Validation Loss: 6.265e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9482, Training Loss: 2.149e-02, Validation Loss: 6.265e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9483, Training Loss: 2.149e-02, Validation Loss: 6.265e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9484, Training Loss: 2.149e-02, Validation Loss: 6.265e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9485, Training Loss: 2.148e-02, Validation Loss: 6.265e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9486, Training Loss: 2.148e-02, Validation Loss: 6.266e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9487, Training Loss: 2.148e-02, Validation Loss: 6.265e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9488, Training Loss: 2.147e-02, Validation Loss: 6.266e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9489, Training Loss: 2.147e-02, Validation Loss: 6.266e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9490, Training Loss: 2.147e-02, Validation Loss: 6.265e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9491, Training Loss: 2.146e-02, Validation Loss: 6.266e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9492, Training Loss: 2.146e-02, Validation Loss: 6.266e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9493, Training Loss: 2.146e-02, Validation Loss: 6.266e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9494, Training Loss: 2.145e-02, Validation Loss: 6.266e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9495, Training Loss: 2.145e-02, Validation Loss: 6.266e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9496, Training Loss: 2.144e-02, Validation Loss: 6.266e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9497, Training Loss: 2.144e-02, Validation Loss: 6.266e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9498, Training Loss: 2.144e-02, Validation Loss: 6.266e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9499, Training Loss: 2.143e-02, Validation Loss: 6.267e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9500, Training Loss: 2.143e-02, Validation Loss: 6.266e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9501, Training Loss: 2.143e-02, Validation Loss: 6.266e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9502, Training Loss: 2.142e-02, Validation Loss: 6.267e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9503, Training Loss: 2.142e-02, Validation Loss: 6.266e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9504, Training Loss: 2.142e-02, Validation Loss: 6.267e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9505, Training Loss: 2.141e-02, Validation Loss: 6.267e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9506, Training Loss: 2.141e-02, Validation Loss: 6.267e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9507, Training Loss: 2.141e-02, Validation Loss: 6.267e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9508, Training Loss: 2.140e-02, Validation Loss: 6.267e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9509, Training Loss: 2.140e-02, Validation Loss: 6.267e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9510, Training Loss: 2.140e-02, Validation Loss: 6.267e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9511, Training Loss: 2.139e-02, Validation Loss: 6.267e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9512, Training Loss: 2.139e-02, Validation Loss: 6.268e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9513, Training Loss: 2.139e-02, Validation Loss: 6.267e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9514, Training Loss: 2.138e-02, Validation Loss: 6.268e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9515, Training Loss: 2.138e-02, Validation Loss: 6.268e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9516, Training Loss: 2.138e-02, Validation Loss: 6.267e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9517, Training Loss: 2.137e-02, Validation Loss: 6.268e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9518, Training Loss: 2.137e-02, Validation Loss: 6.268e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9519, Training Loss: 2.136e-02, Validation Loss: 6.268e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9520, Training Loss: 2.136e-02, Validation Loss: 6.268e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9521, Training Loss: 2.136e-02, Validation Loss: 6.268e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9522, Training Loss: 2.135e-02, Validation Loss: 6.268e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9523, Training Loss: 2.135e-02, Validation Loss: 6.268e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9524, Training Loss: 2.135e-02, Validation Loss: 6.268e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9525, Training Loss: 2.134e-02, Validation Loss: 6.268e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9526, Training Loss: 2.134e-02, Validation Loss: 6.268e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9527, Training Loss: 2.134e-02, Validation Loss: 6.269e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9528, Training Loss: 2.133e-02, Validation Loss: 6.268e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9529, Training Loss: 2.133e-02, Validation Loss: 6.269e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9530, Training Loss: 2.133e-02, Validation Loss: 6.268e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9531, Training Loss: 2.132e-02, Validation Loss: 6.269e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9532, Training Loss: 2.132e-02, Validation Loss: 6.269e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9533, Training Loss: 2.132e-02, Validation Loss: 6.268e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9534, Training Loss: 2.131e-02, Validation Loss: 6.269e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9535, Training Loss: 2.131e-02, Validation Loss: 6.269e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9536, Training Loss: 2.131e-02, Validation Loss: 6.269e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9537, Training Loss: 2.130e-02, Validation Loss: 6.269e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9538, Training Loss: 2.130e-02, Validation Loss: 6.269e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9539, Training Loss: 2.130e-02, Validation Loss: 6.269e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9540, Training Loss: 2.129e-02, Validation Loss: 6.269e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9541, Training Loss: 2.129e-02, Validation Loss: 6.270e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9542, Training Loss: 2.129e-02, Validation Loss: 6.270e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9543, Training Loss: 2.128e-02, Validation Loss: 6.269e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9544, Training Loss: 2.128e-02, Validation Loss: 6.270e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9545, Training Loss: 2.127e-02, Validation Loss: 6.270e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9546, Training Loss: 2.127e-02, Validation Loss: 6.270e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9547, Training Loss: 2.127e-02, Validation Loss: 6.270e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9548, Training Loss: 2.126e-02, Validation Loss: 6.270e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9549, Training Loss: 2.126e-02, Validation Loss: 6.270e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9550, Training Loss: 2.126e-02, Validation Loss: 6.270e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9551, Training Loss: 2.125e-02, Validation Loss: 6.270e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9552, Training Loss: 2.125e-02, Validation Loss: 6.270e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9553, Training Loss: 2.125e-02, Validation Loss: 6.270e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9554, Training Loss: 2.124e-02, Validation Loss: 6.270e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9555, Training Loss: 2.124e-02, Validation Loss: 6.271e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9556, Training Loss: 2.124e-02, Validation Loss: 6.270e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9557, Training Loss: 2.123e-02, Validation Loss: 6.271e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9558, Training Loss: 2.123e-02, Validation Loss: 6.271e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9559, Training Loss: 2.123e-02, Validation Loss: 6.270e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9560, Training Loss: 2.122e-02, Validation Loss: 6.271e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9561, Training Loss: 2.122e-02, Validation Loss: 6.271e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9562, Training Loss: 2.122e-02, Validation Loss: 6.271e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9563, Training Loss: 2.121e-02, Validation Loss: 6.271e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9564, Training Loss: 2.121e-02, Validation Loss: 6.271e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9565, Training Loss: 2.121e-02, Validation Loss: 6.272e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9566, Training Loss: 2.120e-02, Validation Loss: 6.271e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9567, Training Loss: 2.120e-02, Validation Loss: 6.272e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9568, Training Loss: 2.120e-02, Validation Loss: 6.272e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9569, Training Loss: 2.119e-02, Validation Loss: 6.271e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9570, Training Loss: 2.119e-02, Validation Loss: 6.271e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9571, Training Loss: 2.119e-02, Validation Loss: 6.272e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9572, Training Loss: 2.118e-02, Validation Loss: 6.271e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9573, Training Loss: 2.118e-02, Validation Loss: 6.272e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9574, Training Loss: 2.118e-02, Validation Loss: 6.272e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9575, Training Loss: 2.117e-02, Validation Loss: 6.272e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9576, Training Loss: 2.117e-02, Validation Loss: 6.272e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9577, Training Loss: 2.117e-02, Validation Loss: 6.272e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9578, Training Loss: 2.116e-02, Validation Loss: 6.272e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9579, Training Loss: 2.116e-02, Validation Loss: 6.272e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9580, Training Loss: 2.115e-02, Validation Loss: 6.272e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9581, Training Loss: 2.115e-02, Validation Loss: 6.273e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9582, Training Loss: 2.115e-02, Validation Loss: 6.272e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9583, Training Loss: 2.114e-02, Validation Loss: 6.273e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9584, Training Loss: 2.114e-02, Validation Loss: 6.273e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9585, Training Loss: 2.114e-02, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9586, Training Loss: 2.113e-02, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9587, Training Loss: 2.113e-02, Validation Loss: 6.273e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9588, Training Loss: 2.113e-02, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9589, Training Loss: 2.112e-02, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9590, Training Loss: 2.112e-02, Validation Loss: 6.273e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9591, Training Loss: 2.112e-02, Validation Loss: 6.273e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9592, Training Loss: 2.111e-02, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9593, Training Loss: 2.111e-02, Validation Loss: 6.273e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9594, Training Loss: 2.111e-02, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9595, Training Loss: 2.110e-02, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9596, Training Loss: 2.110e-02, Validation Loss: 6.274e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9597, Training Loss: 2.110e-02, Validation Loss: 6.274e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9598, Training Loss: 2.109e-02, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9599, Training Loss: 2.109e-02, Validation Loss: 6.274e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9600, Training Loss: 2.109e-02, Validation Loss: 6.274e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9601, Training Loss: 2.108e-02, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9602, Training Loss: 2.108e-02, Validation Loss: 6.274e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9603, Training Loss: 2.108e-02, Validation Loss: 6.275e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9604, Training Loss: 2.107e-02, Validation Loss: 6.274e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9605, Training Loss: 2.107e-02, Validation Loss: 6.274e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9606, Training Loss: 2.107e-02, Validation Loss: 6.274e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9607, Training Loss: 2.106e-02, Validation Loss: 6.274e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9608, Training Loss: 2.106e-02, Validation Loss: 6.274e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9609, Training Loss: 2.106e-02, Validation Loss: 6.275e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9610, Training Loss: 2.105e-02, Validation Loss: 6.275e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9611, Training Loss: 2.105e-02, Validation Loss: 6.274e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9612, Training Loss: 2.105e-02, Validation Loss: 6.275e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9613, Training Loss: 2.104e-02, Validation Loss: 6.275e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9614, Training Loss: 2.104e-02, Validation Loss: 6.274e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9615, Training Loss: 2.104e-02, Validation Loss: 6.275e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9616, Training Loss: 2.103e-02, Validation Loss: 6.275e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9617, Training Loss: 2.103e-02, Validation Loss: 6.275e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9618, Training Loss: 2.103e-02, Validation Loss: 6.275e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9619, Training Loss: 2.102e-02, Validation Loss: 6.275e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9620, Training Loss: 2.102e-02, Validation Loss: 6.275e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9621, Training Loss: 2.102e-02, Validation Loss: 6.275e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9622, Training Loss: 2.101e-02, Validation Loss: 6.275e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9623, Training Loss: 2.101e-02, Validation Loss: 6.276e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9624, Training Loss: 2.101e-02, Validation Loss: 6.275e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9625, Training Loss: 2.100e-02, Validation Loss: 6.276e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9626, Training Loss: 2.100e-02, Validation Loss: 6.276e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9627, Training Loss: 2.100e-02, Validation Loss: 6.276e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9628, Training Loss: 2.099e-02, Validation Loss: 6.276e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9629, Training Loss: 2.099e-02, Validation Loss: 6.276e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9630, Training Loss: 2.099e-02, Validation Loss: 6.276e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9631, Training Loss: 2.098e-02, Validation Loss: 6.276e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9632, Training Loss: 2.098e-02, Validation Loss: 6.276e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9633, Training Loss: 2.098e-02, Validation Loss: 6.276e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9634, Training Loss: 2.097e-02, Validation Loss: 6.276e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9635, Training Loss: 2.097e-02, Validation Loss: 6.276e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9636, Training Loss: 2.097e-02, Validation Loss: 6.277e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9637, Training Loss: 2.096e-02, Validation Loss: 6.276e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9638, Training Loss: 2.096e-02, Validation Loss: 6.276e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9639, Training Loss: 2.096e-02, Validation Loss: 6.277e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9640, Training Loss: 2.095e-02, Validation Loss: 6.277e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9641, Training Loss: 2.095e-02, Validation Loss: 6.277e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9642, Training Loss: 2.095e-02, Validation Loss: 6.277e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9643, Training Loss: 2.094e-02, Validation Loss: 6.277e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9644, Training Loss: 2.094e-02, Validation Loss: 6.277e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9645, Training Loss: 2.094e-02, Validation Loss: 6.277e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9646, Training Loss: 2.093e-02, Validation Loss: 6.277e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9647, Training Loss: 2.093e-02, Validation Loss: 6.277e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9648, Training Loss: 2.093e-02, Validation Loss: 6.277e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9649, Training Loss: 2.092e-02, Validation Loss: 6.277e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9650, Training Loss: 2.092e-02, Validation Loss: 6.278e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9651, Training Loss: 2.092e-02, Validation Loss: 6.277e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9652, Training Loss: 2.091e-02, Validation Loss: 6.278e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9653, Training Loss: 2.091e-02, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9654, Training Loss: 2.091e-02, Validation Loss: 6.277e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9655, Training Loss: 2.090e-02, Validation Loss: 6.278e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9656, Training Loss: 2.090e-02, Validation Loss: 6.278e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9657, Training Loss: 2.090e-02, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9658, Training Loss: 2.089e-02, Validation Loss: 6.278e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9659, Training Loss: 2.089e-02, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9660, Training Loss: 2.089e-02, Validation Loss: 6.278e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9661, Training Loss: 2.088e-02, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9662, Training Loss: 2.088e-02, Validation Loss: 6.278e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9663, Training Loss: 2.088e-02, Validation Loss: 6.279e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9664, Training Loss: 2.087e-02, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9665, Training Loss: 2.087e-02, Validation Loss: 6.279e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9666, Training Loss: 2.086e-02, Validation Loss: 6.279e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9667, Training Loss: 2.086e-02, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9668, Training Loss: 2.086e-02, Validation Loss: 6.279e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9669, Training Loss: 2.086e-02, Validation Loss: 6.279e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9670, Training Loss: 2.085e-02, Validation Loss: 6.279e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9671, Training Loss: 2.085e-02, Validation Loss: 6.279e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9672, Training Loss: 2.085e-02, Validation Loss: 6.279e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9673, Training Loss: 2.084e-02, Validation Loss: 6.280e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9674, Training Loss: 2.084e-02, Validation Loss: 6.279e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9675, Training Loss: 2.084e-02, Validation Loss: 6.279e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9676, Training Loss: 2.083e-02, Validation Loss: 6.280e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9677, Training Loss: 2.083e-02, Validation Loss: 6.279e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9678, Training Loss: 2.083e-02, Validation Loss: 6.280e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9679, Training Loss: 2.082e-02, Validation Loss: 6.280e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9680, Training Loss: 2.082e-02, Validation Loss: 6.280e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9681, Training Loss: 2.082e-02, Validation Loss: 6.280e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9682, Training Loss: 2.081e-02, Validation Loss: 6.280e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9683, Training Loss: 2.081e-02, Validation Loss: 6.280e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9684, Training Loss: 2.081e-02, Validation Loss: 6.280e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9685, Training Loss: 2.080e-02, Validation Loss: 6.280e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9686, Training Loss: 2.080e-02, Validation Loss: 6.280e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9687, Training Loss: 2.080e-02, Validation Loss: 6.280e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9688, Training Loss: 2.079e-02, Validation Loss: 6.281e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9689, Training Loss: 2.079e-02, Validation Loss: 6.280e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9690, Training Loss: 2.079e-02, Validation Loss: 6.281e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9691, Training Loss: 2.078e-02, Validation Loss: 6.280e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9692, Training Loss: 2.078e-02, Validation Loss: 6.281e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9693, Training Loss: 2.078e-02, Validation Loss: 6.281e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9694, Training Loss: 2.077e-02, Validation Loss: 6.281e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9695, Training Loss: 2.077e-02, Validation Loss: 6.281e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9696, Training Loss: 2.077e-02, Validation Loss: 6.281e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9697, Training Loss: 2.076e-02, Validation Loss: 6.281e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9698, Training Loss: 2.076e-02, Validation Loss: 6.281e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9699, Training Loss: 2.076e-02, Validation Loss: 6.281e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9700, Training Loss: 2.075e-02, Validation Loss: 6.281e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9701, Training Loss: 2.075e-02, Validation Loss: 6.281e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9702, Training Loss: 2.075e-02, Validation Loss: 6.281e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9703, Training Loss: 2.074e-02, Validation Loss: 6.282e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9704, Training Loss: 2.074e-02, Validation Loss: 6.282e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9705, Training Loss: 2.074e-02, Validation Loss: 6.281e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9706, Training Loss: 2.073e-02, Validation Loss: 6.282e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9707, Training Loss: 2.073e-02, Validation Loss: 6.282e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9708, Training Loss: 2.073e-02, Validation Loss: 6.282e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9709, Training Loss: 2.072e-02, Validation Loss: 6.282e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9710, Training Loss: 2.072e-02, Validation Loss: 6.282e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9711, Training Loss: 2.072e-02, Validation Loss: 6.282e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9712, Training Loss: 2.071e-02, Validation Loss: 6.282e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9713, Training Loss: 2.071e-02, Validation Loss: 6.282e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9714, Training Loss: 2.071e-02, Validation Loss: 6.282e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9715, Training Loss: 2.070e-02, Validation Loss: 6.282e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9716, Training Loss: 2.070e-02, Validation Loss: 6.282e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9717, Training Loss: 2.070e-02, Validation Loss: 6.282e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9718, Training Loss: 2.069e-02, Validation Loss: 6.283e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9719, Training Loss: 2.069e-02, Validation Loss: 6.282e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9720, Training Loss: 2.069e-02, Validation Loss: 6.283e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9721, Training Loss: 2.068e-02, Validation Loss: 6.283e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9722, Training Loss: 2.068e-02, Validation Loss: 6.283e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9723, Training Loss: 2.068e-02, Validation Loss: 6.283e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9724, Training Loss: 2.067e-02, Validation Loss: 6.283e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9725, Training Loss: 2.067e-02, Validation Loss: 6.283e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9726, Training Loss: 2.067e-02, Validation Loss: 6.283e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9727, Training Loss: 2.066e-02, Validation Loss: 6.283e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9728, Training Loss: 2.066e-02, Validation Loss: 6.283e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9729, Training Loss: 2.066e-02, Validation Loss: 6.284e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9730, Training Loss: 2.065e-02, Validation Loss: 6.283e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9731, Training Loss: 2.065e-02, Validation Loss: 6.284e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9732, Training Loss: 2.065e-02, Validation Loss: 6.284e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9733, Training Loss: 2.064e-02, Validation Loss: 6.283e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9734, Training Loss: 2.064e-02, Validation Loss: 6.284e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9735, Training Loss: 2.064e-02, Validation Loss: 6.284e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9736, Training Loss: 2.063e-02, Validation Loss: 6.284e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9737, Training Loss: 2.063e-02, Validation Loss: 6.284e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9738, Training Loss: 2.063e-02, Validation Loss: 6.284e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9739, Training Loss: 2.062e-02, Validation Loss: 6.284e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9740, Training Loss: 2.062e-02, Validation Loss: 6.284e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9741, Training Loss: 2.062e-02, Validation Loss: 6.284e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9742, Training Loss: 2.061e-02, Validation Loss: 6.285e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9743, Training Loss: 2.061e-02, Validation Loss: 6.284e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9744, Training Loss: 2.061e-02, Validation Loss: 6.285e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9745, Training Loss: 2.060e-02, Validation Loss: 6.284e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9746, Training Loss: 2.060e-02, Validation Loss: 6.285e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9747, Training Loss: 2.060e-02, Validation Loss: 6.284e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9748, Training Loss: 2.060e-02, Validation Loss: 6.285e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9749, Training Loss: 2.059e-02, Validation Loss: 6.285e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9750, Training Loss: 2.059e-02, Validation Loss: 6.285e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9751, Training Loss: 2.059e-02, Validation Loss: 6.285e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9752, Training Loss: 2.058e-02, Validation Loss: 6.285e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9753, Training Loss: 2.058e-02, Validation Loss: 6.285e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9754, Training Loss: 2.058e-02, Validation Loss: 6.285e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9755, Training Loss: 2.057e-02, Validation Loss: 6.286e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9756, Training Loss: 2.057e-02, Validation Loss: 6.285e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9757, Training Loss: 2.057e-02, Validation Loss: 6.286e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9758, Training Loss: 2.056e-02, Validation Loss: 6.286e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9759, Training Loss: 2.056e-02, Validation Loss: 6.285e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9760, Training Loss: 2.056e-02, Validation Loss: 6.285e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9761, Training Loss: 2.055e-02, Validation Loss: 6.286e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9762, Training Loss: 2.055e-02, Validation Loss: 6.286e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9763, Training Loss: 2.055e-02, Validation Loss: 6.286e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9764, Training Loss: 2.054e-02, Validation Loss: 6.286e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9765, Training Loss: 2.054e-02, Validation Loss: 6.286e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9766, Training Loss: 2.054e-02, Validation Loss: 6.286e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9767, Training Loss: 2.053e-02, Validation Loss: 6.286e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9768, Training Loss: 2.053e-02, Validation Loss: 6.287e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9769, Training Loss: 2.053e-02, Validation Loss: 6.286e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9770, Training Loss: 2.052e-02, Validation Loss: 6.287e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9771, Training Loss: 2.052e-02, Validation Loss: 6.287e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9772, Training Loss: 2.052e-02, Validation Loss: 6.286e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9773, Training Loss: 2.051e-02, Validation Loss: 6.287e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9774, Training Loss: 2.051e-02, Validation Loss: 6.287e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9775, Training Loss: 2.051e-02, Validation Loss: 6.286e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9776, Training Loss: 2.050e-02, Validation Loss: 6.287e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9777, Training Loss: 2.050e-02, Validation Loss: 6.287e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9778, Training Loss: 2.050e-02, Validation Loss: 6.287e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9779, Training Loss: 2.049e-02, Validation Loss: 6.287e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9780, Training Loss: 2.049e-02, Validation Loss: 6.287e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9781, Training Loss: 2.049e-02, Validation Loss: 6.287e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9782, Training Loss: 2.048e-02, Validation Loss: 6.287e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9783, Training Loss: 2.048e-02, Validation Loss: 6.287e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9784, Training Loss: 2.048e-02, Validation Loss: 6.288e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9785, Training Loss: 2.048e-02, Validation Loss: 6.287e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9786, Training Loss: 2.047e-02, Validation Loss: 6.288e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9787, Training Loss: 2.047e-02, Validation Loss: 6.288e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9788, Training Loss: 2.047e-02, Validation Loss: 6.287e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9789, Training Loss: 2.046e-02, Validation Loss: 6.288e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9790, Training Loss: 2.046e-02, Validation Loss: 6.288e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9791, Training Loss: 2.046e-02, Validation Loss: 6.288e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9792, Training Loss: 2.045e-02, Validation Loss: 6.288e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9793, Training Loss: 2.045e-02, Validation Loss: 6.288e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9794, Training Loss: 2.045e-02, Validation Loss: 6.288e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9795, Training Loss: 2.044e-02, Validation Loss: 6.288e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9796, Training Loss: 2.044e-02, Validation Loss: 6.289e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9797, Training Loss: 2.044e-02, Validation Loss: 6.288e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9798, Training Loss: 2.043e-02, Validation Loss: 6.288e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9799, Training Loss: 2.043e-02, Validation Loss: 6.289e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9800, Training Loss: 2.043e-02, Validation Loss: 6.289e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9801, Training Loss: 2.042e-02, Validation Loss: 6.289e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9802, Training Loss: 2.042e-02, Validation Loss: 6.289e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9803, Training Loss: 2.042e-02, Validation Loss: 6.289e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9804, Training Loss: 2.041e-02, Validation Loss: 6.289e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9805, Training Loss: 2.041e-02, Validation Loss: 6.289e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9806, Training Loss: 2.041e-02, Validation Loss: 6.289e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9807, Training Loss: 2.040e-02, Validation Loss: 6.290e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9808, Training Loss: 2.040e-02, Validation Loss: 6.289e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9809, Training Loss: 2.040e-02, Validation Loss: 6.289e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9810, Training Loss: 2.039e-02, Validation Loss: 6.290e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9811, Training Loss: 2.039e-02, Validation Loss: 6.289e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9812, Training Loss: 2.039e-02, Validation Loss: 6.289e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9813, Training Loss: 2.039e-02, Validation Loss: 6.290e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9814, Training Loss: 2.038e-02, Validation Loss: 6.289e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9815, Training Loss: 2.038e-02, Validation Loss: 6.290e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9816, Training Loss: 2.038e-02, Validation Loss: 6.290e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9817, Training Loss: 2.037e-02, Validation Loss: 6.290e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9818, Training Loss: 2.037e-02, Validation Loss: 6.290e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9819, Training Loss: 2.037e-02, Validation Loss: 6.290e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9820, Training Loss: 2.036e-02, Validation Loss: 6.290e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9821, Training Loss: 2.036e-02, Validation Loss: 6.290e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9822, Training Loss: 2.036e-02, Validation Loss: 6.290e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9823, Training Loss: 2.035e-02, Validation Loss: 6.291e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9824, Training Loss: 2.035e-02, Validation Loss: 6.290e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9825, Training Loss: 2.035e-02, Validation Loss: 6.291e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9826, Training Loss: 2.034e-02, Validation Loss: 6.291e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9827, Training Loss: 2.034e-02, Validation Loss: 6.290e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9828, Training Loss: 2.034e-02, Validation Loss: 6.291e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9829, Training Loss: 2.033e-02, Validation Loss: 6.291e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9830, Training Loss: 2.033e-02, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9831, Training Loss: 2.033e-02, Validation Loss: 6.291e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9832, Training Loss: 2.032e-02, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9833, Training Loss: 2.032e-02, Validation Loss: 6.291e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9834, Training Loss: 2.032e-02, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9835, Training Loss: 2.032e-02, Validation Loss: 6.291e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9836, Training Loss: 2.031e-02, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9837, Training Loss: 2.031e-02, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9838, Training Loss: 2.031e-02, Validation Loss: 6.291e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9839, Training Loss: 2.030e-02, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9840, Training Loss: 2.030e-02, Validation Loss: 6.291e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9841, Training Loss: 2.030e-02, Validation Loss: 6.292e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9842, Training Loss: 2.029e-02, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9843, Training Loss: 2.029e-02, Validation Loss: 6.292e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9844, Training Loss: 2.029e-02, Validation Loss: 6.292e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9845, Training Loss: 2.028e-02, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9846, Training Loss: 2.028e-02, Validation Loss: 6.292e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9847, Training Loss: 2.028e-02, Validation Loss: 6.292e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9848, Training Loss: 2.027e-02, Validation Loss: 6.292e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9849, Training Loss: 2.027e-02, Validation Loss: 6.292e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9850, Training Loss: 2.027e-02, Validation Loss: 6.292e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9851, Training Loss: 2.026e-02, Validation Loss: 6.292e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9852, Training Loss: 2.026e-02, Validation Loss: 6.292e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9853, Training Loss: 2.026e-02, Validation Loss: 6.292e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9854, Training Loss: 2.025e-02, Validation Loss: 6.293e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9855, Training Loss: 2.025e-02, Validation Loss: 6.292e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9856, Training Loss: 2.025e-02, Validation Loss: 6.293e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9857, Training Loss: 2.025e-02, Validation Loss: 6.293e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9858, Training Loss: 2.024e-02, Validation Loss: 6.293e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9859, Training Loss: 2.024e-02, Validation Loss: 6.293e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9860, Training Loss: 2.024e-02, Validation Loss: 6.293e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9861, Training Loss: 2.023e-02, Validation Loss: 6.293e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9862, Training Loss: 2.023e-02, Validation Loss: 6.293e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9863, Training Loss: 2.023e-02, Validation Loss: 6.293e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9864, Training Loss: 2.022e-02, Validation Loss: 6.294e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9865, Training Loss: 2.022e-02, Validation Loss: 6.293e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9866, Training Loss: 2.022e-02, Validation Loss: 6.293e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9867, Training Loss: 2.021e-02, Validation Loss: 6.294e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9868, Training Loss: 2.021e-02, Validation Loss: 6.293e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9869, Training Loss: 2.021e-02, Validation Loss: 6.294e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9870, Training Loss: 2.020e-02, Validation Loss: 6.294e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9871, Training Loss: 2.020e-02, Validation Loss: 6.293e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9872, Training Loss: 2.020e-02, Validation Loss: 6.294e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9873, Training Loss: 2.019e-02, Validation Loss: 6.294e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9874, Training Loss: 2.019e-02, Validation Loss: 6.294e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9875, Training Loss: 2.019e-02, Validation Loss: 6.294e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9876, Training Loss: 2.019e-02, Validation Loss: 6.294e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9877, Training Loss: 2.018e-02, Validation Loss: 6.294e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9878, Training Loss: 2.018e-02, Validation Loss: 6.294e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9879, Training Loss: 2.018e-02, Validation Loss: 6.294e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9880, Training Loss: 2.017e-02, Validation Loss: 6.294e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9881, Training Loss: 2.017e-02, Validation Loss: 6.294e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9882, Training Loss: 2.017e-02, Validation Loss: 6.294e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9883, Training Loss: 2.016e-02, Validation Loss: 6.295e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9884, Training Loss: 2.016e-02, Validation Loss: 6.294e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9885, Training Loss: 2.016e-02, Validation Loss: 6.295e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9886, Training Loss: 2.015e-02, Validation Loss: 6.295e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9887, Training Loss: 2.015e-02, Validation Loss: 6.295e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9888, Training Loss: 2.015e-02, Validation Loss: 6.295e-01, Patience: 4, Learning Rate: 0.01\n",
      "Epoch 9889, Training Loss: 2.014e-02, Validation Loss: 6.295e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9890, Training Loss: 2.014e-02, Validation Loss: 6.295e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9891, Training Loss: 2.014e-02, Validation Loss: 6.296e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9892, Training Loss: 2.014e-02, Validation Loss: 6.295e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9893, Training Loss: 2.013e-02, Validation Loss: 6.295e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9894, Training Loss: 2.013e-02, Validation Loss: 6.296e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9895, Training Loss: 2.013e-02, Validation Loss: 6.295e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9896, Training Loss: 2.012e-02, Validation Loss: 6.295e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9897, Training Loss: 2.012e-02, Validation Loss: 6.296e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9898, Training Loss: 2.012e-02, Validation Loss: 6.295e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9899, Training Loss: 2.011e-02, Validation Loss: 6.296e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9900, Training Loss: 2.011e-02, Validation Loss: 6.296e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9901, Training Loss: 2.011e-02, Validation Loss: 6.296e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9902, Training Loss: 2.010e-02, Validation Loss: 6.296e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9903, Training Loss: 2.010e-02, Validation Loss: 6.296e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9904, Training Loss: 2.010e-02, Validation Loss: 6.296e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9905, Training Loss: 2.009e-02, Validation Loss: 6.296e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9906, Training Loss: 2.009e-02, Validation Loss: 6.296e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9907, Training Loss: 2.009e-02, Validation Loss: 6.297e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9908, Training Loss: 2.009e-02, Validation Loss: 6.296e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9909, Training Loss: 2.008e-02, Validation Loss: 6.297e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9910, Training Loss: 2.008e-02, Validation Loss: 6.296e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9911, Training Loss: 2.008e-02, Validation Loss: 6.297e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9912, Training Loss: 2.007e-02, Validation Loss: 6.296e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9913, Training Loss: 2.007e-02, Validation Loss: 6.297e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9914, Training Loss: 2.007e-02, Validation Loss: 6.296e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9915, Training Loss: 2.006e-02, Validation Loss: 6.297e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9916, Training Loss: 2.006e-02, Validation Loss: 6.297e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9917, Training Loss: 2.006e-02, Validation Loss: 6.297e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9918, Training Loss: 2.005e-02, Validation Loss: 6.297e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9919, Training Loss: 2.005e-02, Validation Loss: 6.298e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9920, Training Loss: 2.005e-02, Validation Loss: 6.297e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9921, Training Loss: 2.005e-02, Validation Loss: 6.297e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9922, Training Loss: 2.004e-02, Validation Loss: 6.298e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9923, Training Loss: 2.004e-02, Validation Loss: 6.297e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9924, Training Loss: 2.004e-02, Validation Loss: 6.298e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9925, Training Loss: 2.003e-02, Validation Loss: 6.297e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9926, Training Loss: 2.003e-02, Validation Loss: 6.298e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9927, Training Loss: 2.003e-02, Validation Loss: 6.298e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9928, Training Loss: 2.002e-02, Validation Loss: 6.297e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9929, Training Loss: 2.002e-02, Validation Loss: 6.298e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9930, Training Loss: 2.002e-02, Validation Loss: 6.298e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9931, Training Loss: 2.001e-02, Validation Loss: 6.298e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9932, Training Loss: 2.001e-02, Validation Loss: 6.298e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9933, Training Loss: 2.001e-02, Validation Loss: 6.298e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9934, Training Loss: 2.000e-02, Validation Loss: 6.298e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9935, Training Loss: 2.000e-02, Validation Loss: 6.299e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9936, Training Loss: 2.000e-02, Validation Loss: 6.298e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9937, Training Loss: 2.000e-02, Validation Loss: 6.299e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9938, Training Loss: 1.999e-02, Validation Loss: 6.298e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9939, Training Loss: 1.999e-02, Validation Loss: 6.299e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9940, Training Loss: 1.999e-02, Validation Loss: 6.299e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9941, Training Loss: 1.998e-02, Validation Loss: 6.299e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9942, Training Loss: 1.998e-02, Validation Loss: 6.299e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9943, Training Loss: 1.998e-02, Validation Loss: 6.299e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9944, Training Loss: 1.997e-02, Validation Loss: 6.299e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9945, Training Loss: 1.997e-02, Validation Loss: 6.299e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9946, Training Loss: 1.997e-02, Validation Loss: 6.299e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9947, Training Loss: 1.996e-02, Validation Loss: 6.299e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9948, Training Loss: 1.996e-02, Validation Loss: 6.299e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9949, Training Loss: 1.996e-02, Validation Loss: 6.299e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9950, Training Loss: 1.996e-02, Validation Loss: 6.299e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9951, Training Loss: 1.995e-02, Validation Loss: 6.299e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9952, Training Loss: 1.995e-02, Validation Loss: 6.300e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9953, Training Loss: 1.995e-02, Validation Loss: 6.300e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9954, Training Loss: 1.994e-02, Validation Loss: 6.299e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9955, Training Loss: 1.994e-02, Validation Loss: 6.300e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9956, Training Loss: 1.994e-02, Validation Loss: 6.299e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9957, Training Loss: 1.993e-02, Validation Loss: 6.300e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9958, Training Loss: 1.993e-02, Validation Loss: 6.300e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9959, Training Loss: 1.993e-02, Validation Loss: 6.300e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9960, Training Loss: 1.992e-02, Validation Loss: 6.300e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9961, Training Loss: 1.992e-02, Validation Loss: 6.300e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9962, Training Loss: 1.992e-02, Validation Loss: 6.300e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9963, Training Loss: 1.992e-02, Validation Loss: 6.300e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9964, Training Loss: 1.991e-02, Validation Loss: 6.301e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9965, Training Loss: 1.991e-02, Validation Loss: 6.300e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9966, Training Loss: 1.991e-02, Validation Loss: 6.301e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9967, Training Loss: 1.990e-02, Validation Loss: 6.301e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9968, Training Loss: 1.990e-02, Validation Loss: 6.301e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9969, Training Loss: 1.990e-02, Validation Loss: 6.301e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9970, Training Loss: 1.989e-02, Validation Loss: 6.301e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9971, Training Loss: 1.989e-02, Validation Loss: 6.301e-01, Patience: 3, Learning Rate: 0.01\n",
      "Epoch 9972, Training Loss: 1.989e-02, Validation Loss: 6.301e-01, Patience: 4, Learning Rate: 0.01\n",
      "Epoch 9973, Training Loss: 1.988e-02, Validation Loss: 6.301e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9974, Training Loss: 1.988e-02, Validation Loss: 6.301e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9975, Training Loss: 1.988e-02, Validation Loss: 6.301e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9976, Training Loss: 1.988e-02, Validation Loss: 6.301e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9977, Training Loss: 1.987e-02, Validation Loss: 6.301e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9978, Training Loss: 1.987e-02, Validation Loss: 6.302e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9979, Training Loss: 1.987e-02, Validation Loss: 6.301e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9980, Training Loss: 1.986e-02, Validation Loss: 6.302e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9981, Training Loss: 1.986e-02, Validation Loss: 6.301e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9982, Training Loss: 1.986e-02, Validation Loss: 6.302e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9983, Training Loss: 1.985e-02, Validation Loss: 6.302e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9984, Training Loss: 1.985e-02, Validation Loss: 6.302e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9985, Training Loss: 1.985e-02, Validation Loss: 6.302e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9986, Training Loss: 1.984e-02, Validation Loss: 6.302e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9987, Training Loss: 1.984e-02, Validation Loss: 6.302e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9988, Training Loss: 1.984e-02, Validation Loss: 6.302e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9989, Training Loss: 1.984e-02, Validation Loss: 6.303e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9990, Training Loss: 1.983e-02, Validation Loss: 6.302e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9991, Training Loss: 1.983e-02, Validation Loss: 6.302e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9992, Training Loss: 1.983e-02, Validation Loss: 6.303e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9993, Training Loss: 1.982e-02, Validation Loss: 6.302e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9994, Training Loss: 1.982e-02, Validation Loss: 6.303e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9995, Training Loss: 1.982e-02, Validation Loss: 6.303e-01, Patience: 2, Learning Rate: 0.01\n",
      "Epoch 9996, Training Loss: 1.981e-02, Validation Loss: 6.302e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9997, Training Loss: 1.981e-02, Validation Loss: 6.303e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9998, Training Loss: 1.981e-02, Validation Loss: 6.303e-01, Patience: 0, Learning Rate: 0.01\n",
      "Epoch 9999, Training Loss: 1.980e-02, Validation Loss: 6.303e-01, Patience: 1, Learning Rate: 0.01\n",
      "Epoch 9999, Training Loss: 1.980e-02, Validation Loss: 6.303e-01, Patience: 1\n"
     ]
    }
   ],
   "source": [
    "error_train, error_val = model_50.train(X_train, y_train, X_val, y_val, epochs=10000, learning_rate=1e-2, optimizer='sgd', generate_new_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_50.plot_training_error(error_train, error_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error : 0.44986086936217135\n",
      "(208, 2500) (208, 15) (208, 15)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_50.test(X_test, y_test)\n",
    "print(X_test.shape, y_test.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8653846153846154\n",
      "Azmira - Precision: 0.8235294117647058, Recall: 0.9333333333333333, F1 Score: 0.8749999999999999\n",
      "David - Precision: 1.0, Recall: 0.8823529411764706, F1 Score: 0.9375\n",
      "Dimas - Precision: 0.8235294117647058, Recall: 1.0, F1 Score: 0.9032258064516129\n",
      "Fadhli - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Fadlin - Precision: 1.0, Recall: 0.6666666666666666, F1 Score: 0.8\n",
      "Hafidz - Precision: 0.8666666666666667, Recall: 0.9285714285714286, F1 Score: 0.896551724137931\n",
      "Haidar - Precision: 0.46153846153846156, Recall: 0.8571428571428571, F1 Score: 0.6\n",
      "Hanna - Precision: 0.7272727272727273, Recall: 0.8888888888888888, F1 Score: 0.7999999999999999\n",
      "Keiko - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Khansa - Precision: 0.5, Recall: 0.2727272727272727, F1 Score: 0.3529411764705882\n",
      "Mikhael - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Puti - Precision: 0.8333333333333334, Recall: 0.9375, F1 Score: 0.8823529411764706\n",
      "Raesa - Precision: 0.625, Recall: 0.45454545454545453, F1 Score: 0.5263157894736842\n",
      "Satwika - Precision: 1.0, Recall: 0.9166666666666666, F1 Score: 0.9565217391304348\n",
      "Toni - Precision: 0.9615384615384616, Recall: 0.9615384615384616, F1 Score: 0.9615384615384616\n",
      "Mean Precision: 0.8414938982586041\n",
      "Mean Recall: 0.8466622647505001\n",
      "Mean F1 Score: 0.832796509225279\n"
     ]
    }
   ],
   "source": [
    "model_50.add_labels_from_folders(input_directory)\n",
    "model_50.evaluate_metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_50.plot_confusion_matrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_50.save_model(\"./My_Model_50/01_Yi Sang_Rotate.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
