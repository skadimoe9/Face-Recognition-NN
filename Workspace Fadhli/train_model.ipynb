{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_image import *\n",
    "from model_nn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found folders: ['Azmira', 'David', 'Dimas', 'Fadhli', 'Fadlin', 'Hafidz', 'Haidar', 'Hanna', 'Keiko', 'Khansa', 'Mikhael', 'Puti', 'Raesa', 'Satwika', 'Toni']\n",
      "(968, 4900) (968, 15) (208, 4900) (208, 15) (208, 4900) (208, 15)\n"
     ]
    }
   ],
   "source": [
    "input_directory = \"../Dataset/Foto_Resize_Rotate_70x70\" \n",
    "X_train, y_train, X_test, y_test, X_val, y_val, scalerinput = process_all(input_directory)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_50 = FaceRecognitionModel(X_train.shape[1], [64], y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params rewritten\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training Loss: 3.118e+00, Validation Loss: 2.951e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1, Training Loss: 2.960e+00, Validation Loss: 2.879e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2, Training Loss: 2.887e+00, Validation Loss: 2.837e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3, Training Loss: 2.844e+00, Validation Loss: 2.808e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4, Training Loss: 2.814e+00, Validation Loss: 2.785e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5, Training Loss: 2.791e+00, Validation Loss: 2.768e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6, Training Loss: 2.773e+00, Validation Loss: 2.753e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7, Training Loss: 2.758e+00, Validation Loss: 2.741e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8, Training Loss: 2.745e+00, Validation Loss: 2.731e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9, Training Loss: 2.735e+00, Validation Loss: 2.722e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10, Training Loss: 2.725e+00, Validation Loss: 2.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11, Training Loss: 2.717e+00, Validation Loss: 2.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12, Training Loss: 2.709e+00, Validation Loss: 2.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13, Training Loss: 2.702e+00, Validation Loss: 2.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14, Training Loss: 2.696e+00, Validation Loss: 2.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15, Training Loss: 2.691e+00, Validation Loss: 2.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16, Training Loss: 2.685e+00, Validation Loss: 2.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17, Training Loss: 2.680e+00, Validation Loss: 2.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18, Training Loss: 2.676e+00, Validation Loss: 2.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19, Training Loss: 2.671e+00, Validation Loss: 2.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 20, Training Loss: 2.667e+00, Validation Loss: 2.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 21, Training Loss: 2.663e+00, Validation Loss: 2.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 22, Training Loss: 2.660e+00, Validation Loss: 2.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 23, Training Loss: 2.657e+00, Validation Loss: 2.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 24, Training Loss: 2.654e+00, Validation Loss: 2.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 25, Training Loss: 2.651e+00, Validation Loss: 2.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 26, Training Loss: 2.648e+00, Validation Loss: 2.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 27, Training Loss: 2.646e+00, Validation Loss: 2.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 28, Training Loss: 2.643e+00, Validation Loss: 2.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 29, Training Loss: 2.641e+00, Validation Loss: 2.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 30, Training Loss: 2.639e+00, Validation Loss: 2.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 31, Training Loss: 2.636e+00, Validation Loss: 2.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 32, Training Loss: 2.634e+00, Validation Loss: 2.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 33, Training Loss: 2.632e+00, Validation Loss: 2.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 34, Training Loss: 2.630e+00, Validation Loss: 2.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 35, Training Loss: 2.628e+00, Validation Loss: 2.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 36, Training Loss: 2.626e+00, Validation Loss: 2.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 37, Training Loss: 2.624e+00, Validation Loss: 2.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 38, Training Loss: 2.622e+00, Validation Loss: 2.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 39, Training Loss: 2.620e+00, Validation Loss: 2.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 40, Training Loss: 2.618e+00, Validation Loss: 2.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 41, Training Loss: 2.616e+00, Validation Loss: 2.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 42, Training Loss: 2.614e+00, Validation Loss: 2.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 43, Training Loss: 2.612e+00, Validation Loss: 2.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 44, Training Loss: 2.610e+00, Validation Loss: 2.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 45, Training Loss: 2.608e+00, Validation Loss: 2.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 46, Training Loss: 2.606e+00, Validation Loss: 2.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 47, Training Loss: 2.604e+00, Validation Loss: 2.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 48, Training Loss: 2.602e+00, Validation Loss: 2.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 49, Training Loss: 2.601e+00, Validation Loss: 2.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 50, Training Loss: 2.599e+00, Validation Loss: 2.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 51, Training Loss: 2.597e+00, Validation Loss: 2.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 52, Training Loss: 2.595e+00, Validation Loss: 2.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 53, Training Loss: 2.594e+00, Validation Loss: 2.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 54, Training Loss: 2.592e+00, Validation Loss: 2.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 55, Training Loss: 2.591e+00, Validation Loss: 2.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 56, Training Loss: 2.589e+00, Validation Loss: 2.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 57, Training Loss: 2.587e+00, Validation Loss: 2.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 58, Training Loss: 2.586e+00, Validation Loss: 2.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 59, Training Loss: 2.584e+00, Validation Loss: 2.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 60, Training Loss: 2.583e+00, Validation Loss: 2.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 61, Training Loss: 2.581e+00, Validation Loss: 2.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 62, Training Loss: 2.580e+00, Validation Loss: 2.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 63, Training Loss: 2.578e+00, Validation Loss: 2.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 64, Training Loss: 2.577e+00, Validation Loss: 2.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 65, Training Loss: 2.575e+00, Validation Loss: 2.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 66, Training Loss: 2.574e+00, Validation Loss: 2.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 67, Training Loss: 2.572e+00, Validation Loss: 2.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 68, Training Loss: 2.571e+00, Validation Loss: 2.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 69, Training Loss: 2.569e+00, Validation Loss: 2.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 70, Training Loss: 2.568e+00, Validation Loss: 2.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 71, Training Loss: 2.566e+00, Validation Loss: 2.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 72, Training Loss: 2.565e+00, Validation Loss: 2.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 73, Training Loss: 2.563e+00, Validation Loss: 2.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 74, Training Loss: 2.562e+00, Validation Loss: 2.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 75, Training Loss: 2.560e+00, Validation Loss: 2.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 76, Training Loss: 2.559e+00, Validation Loss: 2.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 77, Training Loss: 2.557e+00, Validation Loss: 2.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 78, Training Loss: 2.556e+00, Validation Loss: 2.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 79, Training Loss: 2.554e+00, Validation Loss: 2.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 80, Training Loss: 2.553e+00, Validation Loss: 2.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 81, Training Loss: 2.551e+00, Validation Loss: 2.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 82, Training Loss: 2.550e+00, Validation Loss: 2.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 83, Training Loss: 2.549e+00, Validation Loss: 2.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 84, Training Loss: 2.547e+00, Validation Loss: 2.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 85, Training Loss: 2.546e+00, Validation Loss: 2.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 86, Training Loss: 2.544e+00, Validation Loss: 2.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 87, Training Loss: 2.543e+00, Validation Loss: 2.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 88, Training Loss: 2.542e+00, Validation Loss: 2.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 89, Training Loss: 2.540e+00, Validation Loss: 2.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 90, Training Loss: 2.539e+00, Validation Loss: 2.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 91, Training Loss: 2.538e+00, Validation Loss: 2.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 92, Training Loss: 2.536e+00, Validation Loss: 2.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 93, Training Loss: 2.535e+00, Validation Loss: 2.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 94, Training Loss: 2.534e+00, Validation Loss: 2.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 95, Training Loss: 2.532e+00, Validation Loss: 2.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 96, Training Loss: 2.531e+00, Validation Loss: 2.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 97, Training Loss: 2.529e+00, Validation Loss: 2.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 98, Training Loss: 2.528e+00, Validation Loss: 2.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 99, Training Loss: 2.527e+00, Validation Loss: 2.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 100, Training Loss: 2.525e+00, Validation Loss: 2.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 101, Training Loss: 2.524e+00, Validation Loss: 2.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 102, Training Loss: 2.523e+00, Validation Loss: 2.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 103, Training Loss: 2.522e+00, Validation Loss: 2.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 104, Training Loss: 2.520e+00, Validation Loss: 2.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 105, Training Loss: 2.519e+00, Validation Loss: 2.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 106, Training Loss: 2.518e+00, Validation Loss: 2.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 107, Training Loss: 2.516e+00, Validation Loss: 2.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 108, Training Loss: 2.515e+00, Validation Loss: 2.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 109, Training Loss: 2.514e+00, Validation Loss: 2.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 110, Training Loss: 2.512e+00, Validation Loss: 2.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 111, Training Loss: 2.511e+00, Validation Loss: 2.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 112, Training Loss: 2.510e+00, Validation Loss: 2.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 113, Training Loss: 2.508e+00, Validation Loss: 2.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 114, Training Loss: 2.507e+00, Validation Loss: 2.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 115, Training Loss: 2.506e+00, Validation Loss: 2.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 116, Training Loss: 2.505e+00, Validation Loss: 2.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 117, Training Loss: 2.503e+00, Validation Loss: 2.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 118, Training Loss: 2.502e+00, Validation Loss: 2.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 119, Training Loss: 2.501e+00, Validation Loss: 2.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 120, Training Loss: 2.499e+00, Validation Loss: 2.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 121, Training Loss: 2.498e+00, Validation Loss: 2.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 122, Training Loss: 2.497e+00, Validation Loss: 2.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 123, Training Loss: 2.496e+00, Validation Loss: 2.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 124, Training Loss: 2.494e+00, Validation Loss: 2.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 125, Training Loss: 2.493e+00, Validation Loss: 2.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 126, Training Loss: 2.492e+00, Validation Loss: 2.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 127, Training Loss: 2.490e+00, Validation Loss: 2.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 128, Training Loss: 2.489e+00, Validation Loss: 2.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 129, Training Loss: 2.488e+00, Validation Loss: 2.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 130, Training Loss: 2.487e+00, Validation Loss: 2.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 131, Training Loss: 2.485e+00, Validation Loss: 2.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 132, Training Loss: 2.484e+00, Validation Loss: 2.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 133, Training Loss: 2.483e+00, Validation Loss: 2.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 134, Training Loss: 2.481e+00, Validation Loss: 2.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 135, Training Loss: 2.480e+00, Validation Loss: 2.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 136, Training Loss: 2.479e+00, Validation Loss: 2.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 137, Training Loss: 2.477e+00, Validation Loss: 2.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 138, Training Loss: 2.476e+00, Validation Loss: 2.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 139, Training Loss: 2.475e+00, Validation Loss: 2.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 140, Training Loss: 2.474e+00, Validation Loss: 2.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 141, Training Loss: 2.472e+00, Validation Loss: 2.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 142, Training Loss: 2.471e+00, Validation Loss: 2.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 143, Training Loss: 2.470e+00, Validation Loss: 2.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 144, Training Loss: 2.468e+00, Validation Loss: 2.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 145, Training Loss: 2.467e+00, Validation Loss: 2.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 146, Training Loss: 2.466e+00, Validation Loss: 2.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 147, Training Loss: 2.465e+00, Validation Loss: 2.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 148, Training Loss: 2.463e+00, Validation Loss: 2.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 149, Training Loss: 2.462e+00, Validation Loss: 2.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 150, Training Loss: 2.461e+00, Validation Loss: 2.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 151, Training Loss: 2.459e+00, Validation Loss: 2.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 152, Training Loss: 2.458e+00, Validation Loss: 2.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 153, Training Loss: 2.457e+00, Validation Loss: 2.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 154, Training Loss: 2.456e+00, Validation Loss: 2.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 155, Training Loss: 2.454e+00, Validation Loss: 2.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 156, Training Loss: 2.453e+00, Validation Loss: 2.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 157, Training Loss: 2.452e+00, Validation Loss: 2.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 158, Training Loss: 2.451e+00, Validation Loss: 2.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 159, Training Loss: 2.449e+00, Validation Loss: 2.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 160, Training Loss: 2.448e+00, Validation Loss: 2.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 161, Training Loss: 2.447e+00, Validation Loss: 2.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 162, Training Loss: 2.446e+00, Validation Loss: 2.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 163, Training Loss: 2.445e+00, Validation Loss: 2.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 164, Training Loss: 2.443e+00, Validation Loss: 2.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 165, Training Loss: 2.442e+00, Validation Loss: 2.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 166, Training Loss: 2.441e+00, Validation Loss: 2.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 167, Training Loss: 2.440e+00, Validation Loss: 2.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 168, Training Loss: 2.438e+00, Validation Loss: 2.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 169, Training Loss: 2.437e+00, Validation Loss: 2.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 170, Training Loss: 2.436e+00, Validation Loss: 2.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 171, Training Loss: 2.435e+00, Validation Loss: 2.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 172, Training Loss: 2.434e+00, Validation Loss: 2.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 173, Training Loss: 2.432e+00, Validation Loss: 2.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 174, Training Loss: 2.431e+00, Validation Loss: 2.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 175, Training Loss: 2.430e+00, Validation Loss: 2.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 176, Training Loss: 2.429e+00, Validation Loss: 2.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 177, Training Loss: 2.427e+00, Validation Loss: 2.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 178, Training Loss: 2.426e+00, Validation Loss: 2.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 179, Training Loss: 2.425e+00, Validation Loss: 2.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 180, Training Loss: 2.424e+00, Validation Loss: 2.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 181, Training Loss: 2.423e+00, Validation Loss: 2.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 182, Training Loss: 2.421e+00, Validation Loss: 2.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 183, Training Loss: 2.420e+00, Validation Loss: 2.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 184, Training Loss: 2.419e+00, Validation Loss: 2.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 185, Training Loss: 2.418e+00, Validation Loss: 2.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 186, Training Loss: 2.417e+00, Validation Loss: 2.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 187, Training Loss: 2.415e+00, Validation Loss: 2.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 188, Training Loss: 2.414e+00, Validation Loss: 2.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 189, Training Loss: 2.413e+00, Validation Loss: 2.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 190, Training Loss: 2.412e+00, Validation Loss: 2.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 191, Training Loss: 2.411e+00, Validation Loss: 2.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 192, Training Loss: 2.410e+00, Validation Loss: 2.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 193, Training Loss: 2.408e+00, Validation Loss: 2.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 194, Training Loss: 2.407e+00, Validation Loss: 2.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 195, Training Loss: 2.406e+00, Validation Loss: 2.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 196, Training Loss: 2.405e+00, Validation Loss: 2.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 197, Training Loss: 2.404e+00, Validation Loss: 2.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 198, Training Loss: 2.402e+00, Validation Loss: 2.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 199, Training Loss: 2.401e+00, Validation Loss: 2.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 200, Training Loss: 2.400e+00, Validation Loss: 2.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 201, Training Loss: 2.399e+00, Validation Loss: 2.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 202, Training Loss: 2.398e+00, Validation Loss: 2.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 203, Training Loss: 2.396e+00, Validation Loss: 2.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 204, Training Loss: 2.395e+00, Validation Loss: 2.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 205, Training Loss: 2.394e+00, Validation Loss: 2.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 206, Training Loss: 2.393e+00, Validation Loss: 2.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 207, Training Loss: 2.392e+00, Validation Loss: 2.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 208, Training Loss: 2.391e+00, Validation Loss: 2.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 209, Training Loss: 2.389e+00, Validation Loss: 2.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 210, Training Loss: 2.388e+00, Validation Loss: 2.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 211, Training Loss: 2.387e+00, Validation Loss: 2.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 212, Training Loss: 2.386e+00, Validation Loss: 2.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 213, Training Loss: 2.385e+00, Validation Loss: 2.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 214, Training Loss: 2.384e+00, Validation Loss: 2.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 215, Training Loss: 2.382e+00, Validation Loss: 2.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 216, Training Loss: 2.381e+00, Validation Loss: 2.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 217, Training Loss: 2.380e+00, Validation Loss: 2.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 218, Training Loss: 2.379e+00, Validation Loss: 2.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 219, Training Loss: 2.378e+00, Validation Loss: 2.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 220, Training Loss: 2.377e+00, Validation Loss: 2.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 221, Training Loss: 2.375e+00, Validation Loss: 2.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 222, Training Loss: 2.374e+00, Validation Loss: 2.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 223, Training Loss: 2.373e+00, Validation Loss: 2.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 224, Training Loss: 2.372e+00, Validation Loss: 2.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 225, Training Loss: 2.371e+00, Validation Loss: 2.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 226, Training Loss: 2.370e+00, Validation Loss: 2.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 227, Training Loss: 2.369e+00, Validation Loss: 2.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 228, Training Loss: 2.367e+00, Validation Loss: 2.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 229, Training Loss: 2.366e+00, Validation Loss: 2.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 230, Training Loss: 2.365e+00, Validation Loss: 2.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 231, Training Loss: 2.364e+00, Validation Loss: 2.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 232, Training Loss: 2.363e+00, Validation Loss: 2.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 233, Training Loss: 2.362e+00, Validation Loss: 2.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 234, Training Loss: 2.360e+00, Validation Loss: 2.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 235, Training Loss: 2.359e+00, Validation Loss: 2.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 236, Training Loss: 2.358e+00, Validation Loss: 2.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 237, Training Loss: 2.357e+00, Validation Loss: 2.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 238, Training Loss: 2.356e+00, Validation Loss: 2.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 239, Training Loss: 2.355e+00, Validation Loss: 2.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 240, Training Loss: 2.354e+00, Validation Loss: 2.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 241, Training Loss: 2.353e+00, Validation Loss: 2.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 242, Training Loss: 2.351e+00, Validation Loss: 2.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 243, Training Loss: 2.350e+00, Validation Loss: 2.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 244, Training Loss: 2.349e+00, Validation Loss: 2.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 245, Training Loss: 2.348e+00, Validation Loss: 2.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 246, Training Loss: 2.347e+00, Validation Loss: 2.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 247, Training Loss: 2.346e+00, Validation Loss: 2.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 248, Training Loss: 2.345e+00, Validation Loss: 2.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 249, Training Loss: 2.344e+00, Validation Loss: 2.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 250, Training Loss: 2.342e+00, Validation Loss: 2.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 251, Training Loss: 2.341e+00, Validation Loss: 2.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 252, Training Loss: 2.340e+00, Validation Loss: 2.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 253, Training Loss: 2.339e+00, Validation Loss: 2.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 254, Training Loss: 2.338e+00, Validation Loss: 2.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 255, Training Loss: 2.337e+00, Validation Loss: 2.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 256, Training Loss: 2.336e+00, Validation Loss: 2.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 257, Training Loss: 2.335e+00, Validation Loss: 2.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 258, Training Loss: 2.333e+00, Validation Loss: 2.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 259, Training Loss: 2.332e+00, Validation Loss: 2.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 260, Training Loss: 2.331e+00, Validation Loss: 2.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 261, Training Loss: 2.330e+00, Validation Loss: 2.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 262, Training Loss: 2.329e+00, Validation Loss: 2.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 263, Training Loss: 2.328e+00, Validation Loss: 2.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 264, Training Loss: 2.327e+00, Validation Loss: 2.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 265, Training Loss: 2.326e+00, Validation Loss: 2.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 266, Training Loss: 2.324e+00, Validation Loss: 2.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 267, Training Loss: 2.323e+00, Validation Loss: 2.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 268, Training Loss: 2.322e+00, Validation Loss: 2.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 269, Training Loss: 2.321e+00, Validation Loss: 2.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 270, Training Loss: 2.320e+00, Validation Loss: 2.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 271, Training Loss: 2.319e+00, Validation Loss: 2.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 272, Training Loss: 2.318e+00, Validation Loss: 2.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 273, Training Loss: 2.317e+00, Validation Loss: 2.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 274, Training Loss: 2.315e+00, Validation Loss: 2.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 275, Training Loss: 2.314e+00, Validation Loss: 2.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 276, Training Loss: 2.313e+00, Validation Loss: 2.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 277, Training Loss: 2.312e+00, Validation Loss: 2.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 278, Training Loss: 2.311e+00, Validation Loss: 2.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 279, Training Loss: 2.310e+00, Validation Loss: 2.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 280, Training Loss: 2.309e+00, Validation Loss: 2.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 281, Training Loss: 2.308e+00, Validation Loss: 2.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 282, Training Loss: 2.307e+00, Validation Loss: 2.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 283, Training Loss: 2.306e+00, Validation Loss: 2.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 284, Training Loss: 2.304e+00, Validation Loss: 2.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 285, Training Loss: 2.303e+00, Validation Loss: 2.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 286, Training Loss: 2.302e+00, Validation Loss: 2.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 287, Training Loss: 2.301e+00, Validation Loss: 2.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 288, Training Loss: 2.300e+00, Validation Loss: 2.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 289, Training Loss: 2.299e+00, Validation Loss: 2.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 290, Training Loss: 2.298e+00, Validation Loss: 2.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 291, Training Loss: 2.297e+00, Validation Loss: 2.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 292, Training Loss: 2.296e+00, Validation Loss: 2.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 293, Training Loss: 2.295e+00, Validation Loss: 2.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 294, Training Loss: 2.293e+00, Validation Loss: 2.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 295, Training Loss: 2.292e+00, Validation Loss: 2.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 296, Training Loss: 2.291e+00, Validation Loss: 2.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 297, Training Loss: 2.290e+00, Validation Loss: 2.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 298, Training Loss: 2.289e+00, Validation Loss: 2.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 299, Training Loss: 2.288e+00, Validation Loss: 2.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 300, Training Loss: 2.287e+00, Validation Loss: 2.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 301, Training Loss: 2.286e+00, Validation Loss: 2.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 302, Training Loss: 2.285e+00, Validation Loss: 2.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 303, Training Loss: 2.284e+00, Validation Loss: 2.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 304, Training Loss: 2.283e+00, Validation Loss: 2.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 305, Training Loss: 2.282e+00, Validation Loss: 2.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 306, Training Loss: 2.281e+00, Validation Loss: 2.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 307, Training Loss: 2.279e+00, Validation Loss: 2.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 308, Training Loss: 2.278e+00, Validation Loss: 2.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 309, Training Loss: 2.277e+00, Validation Loss: 2.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 310, Training Loss: 2.276e+00, Validation Loss: 2.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 311, Training Loss: 2.275e+00, Validation Loss: 2.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 312, Training Loss: 2.274e+00, Validation Loss: 2.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 313, Training Loss: 2.273e+00, Validation Loss: 2.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 314, Training Loss: 2.272e+00, Validation Loss: 2.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 315, Training Loss: 2.271e+00, Validation Loss: 2.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 316, Training Loss: 2.270e+00, Validation Loss: 2.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 317, Training Loss: 2.269e+00, Validation Loss: 2.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 318, Training Loss: 2.268e+00, Validation Loss: 2.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 319, Training Loss: 2.266e+00, Validation Loss: 2.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 320, Training Loss: 2.265e+00, Validation Loss: 2.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 321, Training Loss: 2.264e+00, Validation Loss: 2.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 322, Training Loss: 2.263e+00, Validation Loss: 2.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 323, Training Loss: 2.262e+00, Validation Loss: 2.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 324, Training Loss: 2.261e+00, Validation Loss: 2.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 325, Training Loss: 2.260e+00, Validation Loss: 2.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 326, Training Loss: 2.259e+00, Validation Loss: 2.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 327, Training Loss: 2.258e+00, Validation Loss: 2.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 328, Training Loss: 2.257e+00, Validation Loss: 2.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 329, Training Loss: 2.256e+00, Validation Loss: 2.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 330, Training Loss: 2.255e+00, Validation Loss: 2.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 331, Training Loss: 2.253e+00, Validation Loss: 2.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 332, Training Loss: 2.252e+00, Validation Loss: 2.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 333, Training Loss: 2.251e+00, Validation Loss: 2.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 334, Training Loss: 2.250e+00, Validation Loss: 2.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 335, Training Loss: 2.249e+00, Validation Loss: 2.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 336, Training Loss: 2.248e+00, Validation Loss: 2.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 337, Training Loss: 2.247e+00, Validation Loss: 2.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 338, Training Loss: 2.246e+00, Validation Loss: 2.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 339, Training Loss: 2.245e+00, Validation Loss: 2.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 340, Training Loss: 2.244e+00, Validation Loss: 2.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 341, Training Loss: 2.243e+00, Validation Loss: 2.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 342, Training Loss: 2.242e+00, Validation Loss: 2.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 343, Training Loss: 2.241e+00, Validation Loss: 2.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 344, Training Loss: 2.240e+00, Validation Loss: 2.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 345, Training Loss: 2.238e+00, Validation Loss: 2.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 346, Training Loss: 2.237e+00, Validation Loss: 2.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 347, Training Loss: 2.236e+00, Validation Loss: 2.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 348, Training Loss: 2.235e+00, Validation Loss: 2.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 349, Training Loss: 2.234e+00, Validation Loss: 2.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 350, Training Loss: 2.233e+00, Validation Loss: 2.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 351, Training Loss: 2.232e+00, Validation Loss: 2.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 352, Training Loss: 2.231e+00, Validation Loss: 2.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 353, Training Loss: 2.230e+00, Validation Loss: 2.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 354, Training Loss: 2.229e+00, Validation Loss: 2.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 355, Training Loss: 2.228e+00, Validation Loss: 2.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 356, Training Loss: 2.227e+00, Validation Loss: 2.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 357, Training Loss: 2.226e+00, Validation Loss: 2.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 358, Training Loss: 2.225e+00, Validation Loss: 2.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 359, Training Loss: 2.224e+00, Validation Loss: 2.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 360, Training Loss: 2.223e+00, Validation Loss: 2.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 361, Training Loss: 2.222e+00, Validation Loss: 2.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 362, Training Loss: 2.221e+00, Validation Loss: 2.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 363, Training Loss: 2.219e+00, Validation Loss: 2.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 364, Training Loss: 2.218e+00, Validation Loss: 2.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 365, Training Loss: 2.217e+00, Validation Loss: 2.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 366, Training Loss: 2.216e+00, Validation Loss: 2.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 367, Training Loss: 2.215e+00, Validation Loss: 2.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 368, Training Loss: 2.214e+00, Validation Loss: 2.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 369, Training Loss: 2.213e+00, Validation Loss: 2.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 370, Training Loss: 2.212e+00, Validation Loss: 2.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 371, Training Loss: 2.211e+00, Validation Loss: 2.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 372, Training Loss: 2.210e+00, Validation Loss: 2.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 373, Training Loss: 2.209e+00, Validation Loss: 2.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 374, Training Loss: 2.208e+00, Validation Loss: 2.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 375, Training Loss: 2.207e+00, Validation Loss: 2.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 376, Training Loss: 2.206e+00, Validation Loss: 2.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 377, Training Loss: 2.205e+00, Validation Loss: 2.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 378, Training Loss: 2.204e+00, Validation Loss: 2.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 379, Training Loss: 2.203e+00, Validation Loss: 2.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 380, Training Loss: 2.202e+00, Validation Loss: 2.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 381, Training Loss: 2.201e+00, Validation Loss: 2.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 382, Training Loss: 2.200e+00, Validation Loss: 2.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 383, Training Loss: 2.199e+00, Validation Loss: 2.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 384, Training Loss: 2.197e+00, Validation Loss: 2.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 385, Training Loss: 2.196e+00, Validation Loss: 2.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 386, Training Loss: 2.195e+00, Validation Loss: 2.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 387, Training Loss: 2.194e+00, Validation Loss: 2.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 388, Training Loss: 2.193e+00, Validation Loss: 2.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 389, Training Loss: 2.192e+00, Validation Loss: 2.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 390, Training Loss: 2.191e+00, Validation Loss: 2.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 391, Training Loss: 2.190e+00, Validation Loss: 2.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 392, Training Loss: 2.189e+00, Validation Loss: 2.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 393, Training Loss: 2.188e+00, Validation Loss: 2.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 394, Training Loss: 2.187e+00, Validation Loss: 2.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 395, Training Loss: 2.186e+00, Validation Loss: 2.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 396, Training Loss: 2.185e+00, Validation Loss: 2.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 397, Training Loss: 2.184e+00, Validation Loss: 2.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 398, Training Loss: 2.183e+00, Validation Loss: 2.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 399, Training Loss: 2.182e+00, Validation Loss: 2.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 400, Training Loss: 2.181e+00, Validation Loss: 2.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 401, Training Loss: 2.180e+00, Validation Loss: 2.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 402, Training Loss: 2.179e+00, Validation Loss: 2.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 403, Training Loss: 2.177e+00, Validation Loss: 2.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 404, Training Loss: 2.176e+00, Validation Loss: 2.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 405, Training Loss: 2.175e+00, Validation Loss: 2.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 406, Training Loss: 2.174e+00, Validation Loss: 2.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 407, Training Loss: 2.173e+00, Validation Loss: 2.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 408, Training Loss: 2.172e+00, Validation Loss: 2.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 409, Training Loss: 2.171e+00, Validation Loss: 2.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 410, Training Loss: 2.170e+00, Validation Loss: 2.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 411, Training Loss: 2.169e+00, Validation Loss: 2.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 412, Training Loss: 2.168e+00, Validation Loss: 2.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 413, Training Loss: 2.167e+00, Validation Loss: 2.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 414, Training Loss: 2.166e+00, Validation Loss: 2.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 415, Training Loss: 2.165e+00, Validation Loss: 2.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 416, Training Loss: 2.164e+00, Validation Loss: 2.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 417, Training Loss: 2.163e+00, Validation Loss: 2.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 418, Training Loss: 2.162e+00, Validation Loss: 2.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 419, Training Loss: 2.161e+00, Validation Loss: 2.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 420, Training Loss: 2.160e+00, Validation Loss: 2.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 421, Training Loss: 2.159e+00, Validation Loss: 2.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 422, Training Loss: 2.158e+00, Validation Loss: 2.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 423, Training Loss: 2.157e+00, Validation Loss: 2.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 424, Training Loss: 2.156e+00, Validation Loss: 2.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 425, Training Loss: 2.155e+00, Validation Loss: 2.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 426, Training Loss: 2.154e+00, Validation Loss: 2.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 427, Training Loss: 2.153e+00, Validation Loss: 2.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 428, Training Loss: 2.152e+00, Validation Loss: 2.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 429, Training Loss: 2.151e+00, Validation Loss: 2.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 430, Training Loss: 2.150e+00, Validation Loss: 2.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 431, Training Loss: 2.149e+00, Validation Loss: 2.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 432, Training Loss: 2.148e+00, Validation Loss: 2.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 433, Training Loss: 2.147e+00, Validation Loss: 2.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 434, Training Loss: 2.146e+00, Validation Loss: 2.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 435, Training Loss: 2.145e+00, Validation Loss: 2.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 436, Training Loss: 2.144e+00, Validation Loss: 2.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 437, Training Loss: 2.143e+00, Validation Loss: 2.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 438, Training Loss: 2.142e+00, Validation Loss: 2.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 439, Training Loss: 2.141e+00, Validation Loss: 2.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 440, Training Loss: 2.140e+00, Validation Loss: 2.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 441, Training Loss: 2.139e+00, Validation Loss: 2.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 442, Training Loss: 2.138e+00, Validation Loss: 2.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 443, Training Loss: 2.137e+00, Validation Loss: 2.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 444, Training Loss: 2.136e+00, Validation Loss: 2.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 445, Training Loss: 2.135e+00, Validation Loss: 2.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 446, Training Loss: 2.134e+00, Validation Loss: 2.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 447, Training Loss: 2.133e+00, Validation Loss: 2.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 448, Training Loss: 2.132e+00, Validation Loss: 2.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 449, Training Loss: 2.131e+00, Validation Loss: 2.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 450, Training Loss: 2.130e+00, Validation Loss: 2.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 451, Training Loss: 2.129e+00, Validation Loss: 2.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 452, Training Loss: 2.128e+00, Validation Loss: 2.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 453, Training Loss: 2.127e+00, Validation Loss: 2.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 454, Training Loss: 2.126e+00, Validation Loss: 2.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 455, Training Loss: 2.125e+00, Validation Loss: 2.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 456, Training Loss: 2.124e+00, Validation Loss: 2.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 457, Training Loss: 2.123e+00, Validation Loss: 2.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 458, Training Loss: 2.122e+00, Validation Loss: 2.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 459, Training Loss: 2.121e+00, Validation Loss: 2.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 460, Training Loss: 2.120e+00, Validation Loss: 2.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 461, Training Loss: 2.119e+00, Validation Loss: 2.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 462, Training Loss: 2.118e+00, Validation Loss: 2.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 463, Training Loss: 2.117e+00, Validation Loss: 2.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 464, Training Loss: 2.116e+00, Validation Loss: 2.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 465, Training Loss: 2.115e+00, Validation Loss: 2.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 466, Training Loss: 2.114e+00, Validation Loss: 2.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 467, Training Loss: 2.113e+00, Validation Loss: 2.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 468, Training Loss: 2.112e+00, Validation Loss: 2.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 469, Training Loss: 2.111e+00, Validation Loss: 2.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 470, Training Loss: 2.110e+00, Validation Loss: 2.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 471, Training Loss: 2.109e+00, Validation Loss: 2.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 472, Training Loss: 2.108e+00, Validation Loss: 2.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 473, Training Loss: 2.107e+00, Validation Loss: 2.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 474, Training Loss: 2.106e+00, Validation Loss: 2.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 475, Training Loss: 2.104e+00, Validation Loss: 2.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 476, Training Loss: 2.103e+00, Validation Loss: 2.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 477, Training Loss: 2.102e+00, Validation Loss: 2.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 478, Training Loss: 2.101e+00, Validation Loss: 2.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 479, Training Loss: 2.100e+00, Validation Loss: 2.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 480, Training Loss: 2.099e+00, Validation Loss: 2.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 481, Training Loss: 2.098e+00, Validation Loss: 2.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 482, Training Loss: 2.097e+00, Validation Loss: 2.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 483, Training Loss: 2.096e+00, Validation Loss: 2.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 484, Training Loss: 2.095e+00, Validation Loss: 2.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 485, Training Loss: 2.094e+00, Validation Loss: 2.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 486, Training Loss: 2.093e+00, Validation Loss: 2.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 487, Training Loss: 2.092e+00, Validation Loss: 2.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 488, Training Loss: 2.091e+00, Validation Loss: 2.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 489, Training Loss: 2.090e+00, Validation Loss: 2.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 490, Training Loss: 2.089e+00, Validation Loss: 2.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 491, Training Loss: 2.088e+00, Validation Loss: 2.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 492, Training Loss: 2.087e+00, Validation Loss: 2.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 493, Training Loss: 2.086e+00, Validation Loss: 2.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 494, Training Loss: 2.085e+00, Validation Loss: 2.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 495, Training Loss: 2.084e+00, Validation Loss: 2.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 496, Training Loss: 2.083e+00, Validation Loss: 2.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 497, Training Loss: 2.082e+00, Validation Loss: 2.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 498, Training Loss: 2.081e+00, Validation Loss: 2.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 499, Training Loss: 2.080e+00, Validation Loss: 2.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 500, Training Loss: 2.079e+00, Validation Loss: 2.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 501, Training Loss: 2.078e+00, Validation Loss: 2.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 502, Training Loss: 2.077e+00, Validation Loss: 2.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 503, Training Loss: 2.076e+00, Validation Loss: 2.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 504, Training Loss: 2.075e+00, Validation Loss: 2.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 505, Training Loss: 2.074e+00, Validation Loss: 2.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 506, Training Loss: 2.073e+00, Validation Loss: 2.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 507, Training Loss: 2.072e+00, Validation Loss: 2.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 508, Training Loss: 2.071e+00, Validation Loss: 2.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 509, Training Loss: 2.070e+00, Validation Loss: 2.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 510, Training Loss: 2.069e+00, Validation Loss: 2.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 511, Training Loss: 2.068e+00, Validation Loss: 2.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 512, Training Loss: 2.067e+00, Validation Loss: 2.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 513, Training Loss: 2.066e+00, Validation Loss: 2.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 514, Training Loss: 2.065e+00, Validation Loss: 2.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 515, Training Loss: 2.064e+00, Validation Loss: 2.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 516, Training Loss: 2.063e+00, Validation Loss: 2.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 517, Training Loss: 2.062e+00, Validation Loss: 2.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 518, Training Loss: 2.061e+00, Validation Loss: 2.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 519, Training Loss: 2.060e+00, Validation Loss: 2.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 520, Training Loss: 2.059e+00, Validation Loss: 2.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 521, Training Loss: 2.058e+00, Validation Loss: 2.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 522, Training Loss: 2.057e+00, Validation Loss: 2.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 523, Training Loss: 2.056e+00, Validation Loss: 2.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 524, Training Loss: 2.055e+00, Validation Loss: 2.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 525, Training Loss: 2.054e+00, Validation Loss: 2.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 526, Training Loss: 2.053e+00, Validation Loss: 2.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 527, Training Loss: 2.052e+00, Validation Loss: 2.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 528, Training Loss: 2.051e+00, Validation Loss: 2.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 529, Training Loss: 2.050e+00, Validation Loss: 2.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 530, Training Loss: 2.049e+00, Validation Loss: 2.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 531, Training Loss: 2.048e+00, Validation Loss: 2.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 532, Training Loss: 2.047e+00, Validation Loss: 2.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 533, Training Loss: 2.046e+00, Validation Loss: 2.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 534, Training Loss: 2.045e+00, Validation Loss: 2.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 535, Training Loss: 2.044e+00, Validation Loss: 2.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 536, Training Loss: 2.043e+00, Validation Loss: 2.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 537, Training Loss: 2.042e+00, Validation Loss: 2.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 538, Training Loss: 2.041e+00, Validation Loss: 2.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 539, Training Loss: 2.040e+00, Validation Loss: 2.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 540, Training Loss: 2.039e+00, Validation Loss: 2.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 541, Training Loss: 2.038e+00, Validation Loss: 2.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 542, Training Loss: 2.037e+00, Validation Loss: 2.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 543, Training Loss: 2.036e+00, Validation Loss: 2.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 544, Training Loss: 2.035e+00, Validation Loss: 2.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 545, Training Loss: 2.034e+00, Validation Loss: 2.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 546, Training Loss: 2.033e+00, Validation Loss: 2.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 547, Training Loss: 2.032e+00, Validation Loss: 2.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 548, Training Loss: 2.031e+00, Validation Loss: 2.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 549, Training Loss: 2.030e+00, Validation Loss: 2.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 550, Training Loss: 2.029e+00, Validation Loss: 2.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 551, Training Loss: 2.028e+00, Validation Loss: 2.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 552, Training Loss: 2.027e+00, Validation Loss: 2.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 553, Training Loss: 2.026e+00, Validation Loss: 2.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 554, Training Loss: 2.025e+00, Validation Loss: 2.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 555, Training Loss: 2.024e+00, Validation Loss: 2.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 556, Training Loss: 2.023e+00, Validation Loss: 2.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 557, Training Loss: 2.022e+00, Validation Loss: 2.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 558, Training Loss: 2.021e+00, Validation Loss: 2.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 559, Training Loss: 2.020e+00, Validation Loss: 2.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 560, Training Loss: 2.019e+00, Validation Loss: 2.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 561, Training Loss: 2.019e+00, Validation Loss: 2.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 562, Training Loss: 2.018e+00, Validation Loss: 2.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 563, Training Loss: 2.017e+00, Validation Loss: 2.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 564, Training Loss: 2.016e+00, Validation Loss: 2.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 565, Training Loss: 2.015e+00, Validation Loss: 2.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 566, Training Loss: 2.014e+00, Validation Loss: 2.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 567, Training Loss: 2.013e+00, Validation Loss: 2.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 568, Training Loss: 2.012e+00, Validation Loss: 2.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 569, Training Loss: 2.011e+00, Validation Loss: 2.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 570, Training Loss: 2.010e+00, Validation Loss: 2.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 571, Training Loss: 2.009e+00, Validation Loss: 2.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 572, Training Loss: 2.008e+00, Validation Loss: 2.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 573, Training Loss: 2.007e+00, Validation Loss: 2.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 574, Training Loss: 2.006e+00, Validation Loss: 2.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 575, Training Loss: 2.005e+00, Validation Loss: 2.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 576, Training Loss: 2.004e+00, Validation Loss: 2.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 577, Training Loss: 2.003e+00, Validation Loss: 2.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 578, Training Loss: 2.003e+00, Validation Loss: 2.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 579, Training Loss: 2.002e+00, Validation Loss: 2.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 580, Training Loss: 2.001e+00, Validation Loss: 2.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 581, Training Loss: 2.000e+00, Validation Loss: 2.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 582, Training Loss: 1.999e+00, Validation Loss: 2.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 583, Training Loss: 1.998e+00, Validation Loss: 2.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 584, Training Loss: 1.997e+00, Validation Loss: 2.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 585, Training Loss: 1.996e+00, Validation Loss: 2.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 586, Training Loss: 1.995e+00, Validation Loss: 2.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 587, Training Loss: 1.994e+00, Validation Loss: 2.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 588, Training Loss: 1.993e+00, Validation Loss: 2.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 589, Training Loss: 1.992e+00, Validation Loss: 2.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 590, Training Loss: 1.991e+00, Validation Loss: 2.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 591, Training Loss: 1.990e+00, Validation Loss: 2.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 592, Training Loss: 1.989e+00, Validation Loss: 2.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 593, Training Loss: 1.989e+00, Validation Loss: 2.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 594, Training Loss: 1.988e+00, Validation Loss: 2.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 595, Training Loss: 1.987e+00, Validation Loss: 2.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 596, Training Loss: 1.986e+00, Validation Loss: 2.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 597, Training Loss: 1.985e+00, Validation Loss: 2.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 598, Training Loss: 1.984e+00, Validation Loss: 2.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 599, Training Loss: 1.983e+00, Validation Loss: 2.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 600, Training Loss: 1.982e+00, Validation Loss: 2.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 601, Training Loss: 1.981e+00, Validation Loss: 2.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 602, Training Loss: 1.980e+00, Validation Loss: 2.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 603, Training Loss: 1.979e+00, Validation Loss: 2.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 604, Training Loss: 1.978e+00, Validation Loss: 2.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 605, Training Loss: 1.977e+00, Validation Loss: 2.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 606, Training Loss: 1.977e+00, Validation Loss: 2.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 607, Training Loss: 1.976e+00, Validation Loss: 2.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 608, Training Loss: 1.975e+00, Validation Loss: 2.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 609, Training Loss: 1.974e+00, Validation Loss: 2.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 610, Training Loss: 1.973e+00, Validation Loss: 2.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 611, Training Loss: 1.972e+00, Validation Loss: 2.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 612, Training Loss: 1.971e+00, Validation Loss: 2.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 613, Training Loss: 1.970e+00, Validation Loss: 2.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 614, Training Loss: 1.969e+00, Validation Loss: 2.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 615, Training Loss: 1.968e+00, Validation Loss: 2.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 616, Training Loss: 1.967e+00, Validation Loss: 2.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 617, Training Loss: 1.966e+00, Validation Loss: 2.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 618, Training Loss: 1.966e+00, Validation Loss: 2.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 619, Training Loss: 1.965e+00, Validation Loss: 2.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 620, Training Loss: 1.964e+00, Validation Loss: 2.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 621, Training Loss: 1.963e+00, Validation Loss: 2.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 622, Training Loss: 1.962e+00, Validation Loss: 2.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 623, Training Loss: 1.961e+00, Validation Loss: 2.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 624, Training Loss: 1.960e+00, Validation Loss: 2.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 625, Training Loss: 1.959e+00, Validation Loss: 2.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 626, Training Loss: 1.958e+00, Validation Loss: 2.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 627, Training Loss: 1.957e+00, Validation Loss: 2.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 628, Training Loss: 1.956e+00, Validation Loss: 2.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 629, Training Loss: 1.956e+00, Validation Loss: 2.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 630, Training Loss: 1.955e+00, Validation Loss: 2.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 631, Training Loss: 1.954e+00, Validation Loss: 2.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 632, Training Loss: 1.953e+00, Validation Loss: 2.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 633, Training Loss: 1.952e+00, Validation Loss: 2.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 634, Training Loss: 1.951e+00, Validation Loss: 2.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 635, Training Loss: 1.950e+00, Validation Loss: 2.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 636, Training Loss: 1.949e+00, Validation Loss: 2.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 637, Training Loss: 1.948e+00, Validation Loss: 2.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 638, Training Loss: 1.947e+00, Validation Loss: 2.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 639, Training Loss: 1.947e+00, Validation Loss: 2.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 640, Training Loss: 1.946e+00, Validation Loss: 2.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 641, Training Loss: 1.945e+00, Validation Loss: 2.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 642, Training Loss: 1.944e+00, Validation Loss: 2.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 643, Training Loss: 1.943e+00, Validation Loss: 2.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 644, Training Loss: 1.942e+00, Validation Loss: 2.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 645, Training Loss: 1.941e+00, Validation Loss: 2.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 646, Training Loss: 1.940e+00, Validation Loss: 2.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 647, Training Loss: 1.939e+00, Validation Loss: 2.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 648, Training Loss: 1.939e+00, Validation Loss: 2.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 649, Training Loss: 1.938e+00, Validation Loss: 2.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 650, Training Loss: 1.937e+00, Validation Loss: 2.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 651, Training Loss: 1.936e+00, Validation Loss: 2.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 652, Training Loss: 1.935e+00, Validation Loss: 2.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 653, Training Loss: 1.934e+00, Validation Loss: 2.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 654, Training Loss: 1.933e+00, Validation Loss: 2.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 655, Training Loss: 1.932e+00, Validation Loss: 2.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 656, Training Loss: 1.931e+00, Validation Loss: 2.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 657, Training Loss: 1.931e+00, Validation Loss: 2.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 658, Training Loss: 1.930e+00, Validation Loss: 2.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 659, Training Loss: 1.929e+00, Validation Loss: 2.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 660, Training Loss: 1.928e+00, Validation Loss: 2.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 661, Training Loss: 1.927e+00, Validation Loss: 2.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 662, Training Loss: 1.926e+00, Validation Loss: 2.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 663, Training Loss: 1.925e+00, Validation Loss: 2.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 664, Training Loss: 1.924e+00, Validation Loss: 2.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 665, Training Loss: 1.923e+00, Validation Loss: 2.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 666, Training Loss: 1.923e+00, Validation Loss: 2.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 667, Training Loss: 1.922e+00, Validation Loss: 2.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 668, Training Loss: 1.921e+00, Validation Loss: 2.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 669, Training Loss: 1.920e+00, Validation Loss: 2.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 670, Training Loss: 1.919e+00, Validation Loss: 2.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 671, Training Loss: 1.918e+00, Validation Loss: 1.999e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 672, Training Loss: 1.917e+00, Validation Loss: 1.999e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 673, Training Loss: 1.916e+00, Validation Loss: 1.998e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 674, Training Loss: 1.916e+00, Validation Loss: 1.997e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 675, Training Loss: 1.915e+00, Validation Loss: 1.996e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 676, Training Loss: 1.914e+00, Validation Loss: 1.995e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 677, Training Loss: 1.913e+00, Validation Loss: 1.995e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 678, Training Loss: 1.912e+00, Validation Loss: 1.994e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 679, Training Loss: 1.911e+00, Validation Loss: 1.993e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 680, Training Loss: 1.910e+00, Validation Loss: 1.992e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 681, Training Loss: 1.909e+00, Validation Loss: 1.992e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 682, Training Loss: 1.909e+00, Validation Loss: 1.991e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 683, Training Loss: 1.908e+00, Validation Loss: 1.990e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 684, Training Loss: 1.907e+00, Validation Loss: 1.989e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 685, Training Loss: 1.906e+00, Validation Loss: 1.989e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 686, Training Loss: 1.905e+00, Validation Loss: 1.988e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 687, Training Loss: 1.904e+00, Validation Loss: 1.987e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 688, Training Loss: 1.903e+00, Validation Loss: 1.986e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 689, Training Loss: 1.903e+00, Validation Loss: 1.985e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 690, Training Loss: 1.902e+00, Validation Loss: 1.985e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 691, Training Loss: 1.901e+00, Validation Loss: 1.984e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 692, Training Loss: 1.900e+00, Validation Loss: 1.983e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 693, Training Loss: 1.899e+00, Validation Loss: 1.982e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 694, Training Loss: 1.898e+00, Validation Loss: 1.982e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 695, Training Loss: 1.897e+00, Validation Loss: 1.981e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 696, Training Loss: 1.897e+00, Validation Loss: 1.980e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 697, Training Loss: 1.896e+00, Validation Loss: 1.979e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 698, Training Loss: 1.895e+00, Validation Loss: 1.979e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 699, Training Loss: 1.894e+00, Validation Loss: 1.978e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 700, Training Loss: 1.893e+00, Validation Loss: 1.977e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 701, Training Loss: 1.892e+00, Validation Loss: 1.976e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 702, Training Loss: 1.891e+00, Validation Loss: 1.976e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 703, Training Loss: 1.891e+00, Validation Loss: 1.975e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 704, Training Loss: 1.890e+00, Validation Loss: 1.974e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 705, Training Loss: 1.889e+00, Validation Loss: 1.973e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 706, Training Loss: 1.888e+00, Validation Loss: 1.973e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 707, Training Loss: 1.887e+00, Validation Loss: 1.972e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 708, Training Loss: 1.886e+00, Validation Loss: 1.971e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 709, Training Loss: 1.885e+00, Validation Loss: 1.970e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 710, Training Loss: 1.885e+00, Validation Loss: 1.970e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 711, Training Loss: 1.884e+00, Validation Loss: 1.969e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 712, Training Loss: 1.883e+00, Validation Loss: 1.968e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 713, Training Loss: 1.882e+00, Validation Loss: 1.967e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 714, Training Loss: 1.881e+00, Validation Loss: 1.967e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 715, Training Loss: 1.880e+00, Validation Loss: 1.966e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 716, Training Loss: 1.879e+00, Validation Loss: 1.965e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 717, Training Loss: 1.879e+00, Validation Loss: 1.964e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 718, Training Loss: 1.878e+00, Validation Loss: 1.964e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 719, Training Loss: 1.877e+00, Validation Loss: 1.963e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 720, Training Loss: 1.876e+00, Validation Loss: 1.962e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 721, Training Loss: 1.875e+00, Validation Loss: 1.961e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 722, Training Loss: 1.874e+00, Validation Loss: 1.961e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 723, Training Loss: 1.874e+00, Validation Loss: 1.960e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 724, Training Loss: 1.873e+00, Validation Loss: 1.959e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 725, Training Loss: 1.872e+00, Validation Loss: 1.958e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 726, Training Loss: 1.871e+00, Validation Loss: 1.958e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 727, Training Loss: 1.870e+00, Validation Loss: 1.957e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 728, Training Loss: 1.869e+00, Validation Loss: 1.956e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 729, Training Loss: 1.868e+00, Validation Loss: 1.955e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 730, Training Loss: 1.868e+00, Validation Loss: 1.955e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 731, Training Loss: 1.867e+00, Validation Loss: 1.954e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 732, Training Loss: 1.866e+00, Validation Loss: 1.953e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 733, Training Loss: 1.865e+00, Validation Loss: 1.952e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 734, Training Loss: 1.864e+00, Validation Loss: 1.952e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 735, Training Loss: 1.863e+00, Validation Loss: 1.951e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 736, Training Loss: 1.863e+00, Validation Loss: 1.950e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 737, Training Loss: 1.862e+00, Validation Loss: 1.949e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 738, Training Loss: 1.861e+00, Validation Loss: 1.949e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 739, Training Loss: 1.860e+00, Validation Loss: 1.948e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 740, Training Loss: 1.859e+00, Validation Loss: 1.947e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 741, Training Loss: 1.858e+00, Validation Loss: 1.946e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 742, Training Loss: 1.857e+00, Validation Loss: 1.945e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 743, Training Loss: 1.857e+00, Validation Loss: 1.945e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 744, Training Loss: 1.856e+00, Validation Loss: 1.944e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 745, Training Loss: 1.855e+00, Validation Loss: 1.943e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 746, Training Loss: 1.854e+00, Validation Loss: 1.943e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 747, Training Loss: 1.853e+00, Validation Loss: 1.942e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 748, Training Loss: 1.852e+00, Validation Loss: 1.941e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 749, Training Loss: 1.852e+00, Validation Loss: 1.940e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 750, Training Loss: 1.851e+00, Validation Loss: 1.940e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 751, Training Loss: 1.850e+00, Validation Loss: 1.939e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 752, Training Loss: 1.849e+00, Validation Loss: 1.938e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 753, Training Loss: 1.848e+00, Validation Loss: 1.937e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 754, Training Loss: 1.847e+00, Validation Loss: 1.937e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 755, Training Loss: 1.847e+00, Validation Loss: 1.936e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 756, Training Loss: 1.846e+00, Validation Loss: 1.935e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 757, Training Loss: 1.845e+00, Validation Loss: 1.934e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 758, Training Loss: 1.844e+00, Validation Loss: 1.934e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 759, Training Loss: 1.843e+00, Validation Loss: 1.933e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 760, Training Loss: 1.842e+00, Validation Loss: 1.932e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 761, Training Loss: 1.842e+00, Validation Loss: 1.931e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 762, Training Loss: 1.841e+00, Validation Loss: 1.931e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 763, Training Loss: 1.840e+00, Validation Loss: 1.930e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 764, Training Loss: 1.839e+00, Validation Loss: 1.929e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 765, Training Loss: 1.838e+00, Validation Loss: 1.929e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 766, Training Loss: 1.837e+00, Validation Loss: 1.928e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 767, Training Loss: 1.837e+00, Validation Loss: 1.927e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 768, Training Loss: 1.836e+00, Validation Loss: 1.926e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 769, Training Loss: 1.835e+00, Validation Loss: 1.926e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 770, Training Loss: 1.834e+00, Validation Loss: 1.925e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 771, Training Loss: 1.833e+00, Validation Loss: 1.924e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 772, Training Loss: 1.832e+00, Validation Loss: 1.923e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 773, Training Loss: 1.832e+00, Validation Loss: 1.923e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 774, Training Loss: 1.831e+00, Validation Loss: 1.922e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 775, Training Loss: 1.830e+00, Validation Loss: 1.921e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 776, Training Loss: 1.829e+00, Validation Loss: 1.921e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 777, Training Loss: 1.828e+00, Validation Loss: 1.920e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 778, Training Loss: 1.827e+00, Validation Loss: 1.919e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 779, Training Loss: 1.827e+00, Validation Loss: 1.918e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 780, Training Loss: 1.826e+00, Validation Loss: 1.918e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 781, Training Loss: 1.825e+00, Validation Loss: 1.917e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 782, Training Loss: 1.824e+00, Validation Loss: 1.916e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 783, Training Loss: 1.823e+00, Validation Loss: 1.915e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 784, Training Loss: 1.822e+00, Validation Loss: 1.915e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 785, Training Loss: 1.822e+00, Validation Loss: 1.914e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 786, Training Loss: 1.821e+00, Validation Loss: 1.913e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 787, Training Loss: 1.820e+00, Validation Loss: 1.913e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 788, Training Loss: 1.819e+00, Validation Loss: 1.912e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 789, Training Loss: 1.818e+00, Validation Loss: 1.911e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 790, Training Loss: 1.818e+00, Validation Loss: 1.910e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 791, Training Loss: 1.817e+00, Validation Loss: 1.910e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 792, Training Loss: 1.816e+00, Validation Loss: 1.909e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 793, Training Loss: 1.815e+00, Validation Loss: 1.908e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 794, Training Loss: 1.814e+00, Validation Loss: 1.908e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 795, Training Loss: 1.813e+00, Validation Loss: 1.907e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 796, Training Loss: 1.813e+00, Validation Loss: 1.906e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 797, Training Loss: 1.812e+00, Validation Loss: 1.905e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 798, Training Loss: 1.811e+00, Validation Loss: 1.905e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 799, Training Loss: 1.810e+00, Validation Loss: 1.904e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 800, Training Loss: 1.809e+00, Validation Loss: 1.903e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 801, Training Loss: 1.809e+00, Validation Loss: 1.903e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 802, Training Loss: 1.808e+00, Validation Loss: 1.902e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 803, Training Loss: 1.807e+00, Validation Loss: 1.901e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 804, Training Loss: 1.806e+00, Validation Loss: 1.900e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 805, Training Loss: 1.805e+00, Validation Loss: 1.900e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 806, Training Loss: 1.804e+00, Validation Loss: 1.899e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 807, Training Loss: 1.804e+00, Validation Loss: 1.898e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 808, Training Loss: 1.803e+00, Validation Loss: 1.898e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 809, Training Loss: 1.802e+00, Validation Loss: 1.897e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 810, Training Loss: 1.801e+00, Validation Loss: 1.896e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 811, Training Loss: 1.800e+00, Validation Loss: 1.895e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 812, Training Loss: 1.800e+00, Validation Loss: 1.895e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 813, Training Loss: 1.799e+00, Validation Loss: 1.894e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 814, Training Loss: 1.798e+00, Validation Loss: 1.893e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 815, Training Loss: 1.797e+00, Validation Loss: 1.893e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 816, Training Loss: 1.796e+00, Validation Loss: 1.892e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 817, Training Loss: 1.796e+00, Validation Loss: 1.891e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 818, Training Loss: 1.795e+00, Validation Loss: 1.890e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 819, Training Loss: 1.794e+00, Validation Loss: 1.890e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 820, Training Loss: 1.793e+00, Validation Loss: 1.889e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 821, Training Loss: 1.792e+00, Validation Loss: 1.888e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 822, Training Loss: 1.792e+00, Validation Loss: 1.888e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 823, Training Loss: 1.791e+00, Validation Loss: 1.887e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 824, Training Loss: 1.790e+00, Validation Loss: 1.886e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 825, Training Loss: 1.789e+00, Validation Loss: 1.885e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 826, Training Loss: 1.788e+00, Validation Loss: 1.885e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 827, Training Loss: 1.787e+00, Validation Loss: 1.884e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 828, Training Loss: 1.787e+00, Validation Loss: 1.883e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 829, Training Loss: 1.786e+00, Validation Loss: 1.883e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 830, Training Loss: 1.785e+00, Validation Loss: 1.882e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 831, Training Loss: 1.784e+00, Validation Loss: 1.881e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 832, Training Loss: 1.783e+00, Validation Loss: 1.881e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 833, Training Loss: 1.783e+00, Validation Loss: 1.880e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 834, Training Loss: 1.782e+00, Validation Loss: 1.879e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 835, Training Loss: 1.781e+00, Validation Loss: 1.878e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 836, Training Loss: 1.780e+00, Validation Loss: 1.878e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 837, Training Loss: 1.779e+00, Validation Loss: 1.877e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 838, Training Loss: 1.779e+00, Validation Loss: 1.876e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 839, Training Loss: 1.778e+00, Validation Loss: 1.876e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 840, Training Loss: 1.777e+00, Validation Loss: 1.875e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 841, Training Loss: 1.776e+00, Validation Loss: 1.874e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 842, Training Loss: 1.775e+00, Validation Loss: 1.873e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 843, Training Loss: 1.775e+00, Validation Loss: 1.873e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 844, Training Loss: 1.774e+00, Validation Loss: 1.872e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 845, Training Loss: 1.773e+00, Validation Loss: 1.871e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 846, Training Loss: 1.772e+00, Validation Loss: 1.871e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 847, Training Loss: 1.772e+00, Validation Loss: 1.870e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 848, Training Loss: 1.771e+00, Validation Loss: 1.869e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 849, Training Loss: 1.770e+00, Validation Loss: 1.869e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 850, Training Loss: 1.769e+00, Validation Loss: 1.868e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 851, Training Loss: 1.768e+00, Validation Loss: 1.867e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 852, Training Loss: 1.768e+00, Validation Loss: 1.867e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 853, Training Loss: 1.767e+00, Validation Loss: 1.866e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 854, Training Loss: 1.766e+00, Validation Loss: 1.865e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 855, Training Loss: 1.765e+00, Validation Loss: 1.865e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 856, Training Loss: 1.764e+00, Validation Loss: 1.864e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 857, Training Loss: 1.764e+00, Validation Loss: 1.863e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 858, Training Loss: 1.763e+00, Validation Loss: 1.862e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 859, Training Loss: 1.762e+00, Validation Loss: 1.862e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 860, Training Loss: 1.761e+00, Validation Loss: 1.861e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 861, Training Loss: 1.760e+00, Validation Loss: 1.860e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 862, Training Loss: 1.760e+00, Validation Loss: 1.860e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 863, Training Loss: 1.759e+00, Validation Loss: 1.859e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 864, Training Loss: 1.758e+00, Validation Loss: 1.858e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 865, Training Loss: 1.757e+00, Validation Loss: 1.858e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 866, Training Loss: 1.756e+00, Validation Loss: 1.857e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 867, Training Loss: 1.756e+00, Validation Loss: 1.856e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 868, Training Loss: 1.755e+00, Validation Loss: 1.855e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 869, Training Loss: 1.754e+00, Validation Loss: 1.855e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 870, Training Loss: 1.753e+00, Validation Loss: 1.854e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 871, Training Loss: 1.753e+00, Validation Loss: 1.853e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 872, Training Loss: 1.752e+00, Validation Loss: 1.853e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 873, Training Loss: 1.751e+00, Validation Loss: 1.852e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 874, Training Loss: 1.750e+00, Validation Loss: 1.851e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 875, Training Loss: 1.749e+00, Validation Loss: 1.851e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 876, Training Loss: 1.749e+00, Validation Loss: 1.850e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 877, Training Loss: 1.748e+00, Validation Loss: 1.849e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 878, Training Loss: 1.747e+00, Validation Loss: 1.849e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 879, Training Loss: 1.746e+00, Validation Loss: 1.848e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 880, Training Loss: 1.745e+00, Validation Loss: 1.847e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 881, Training Loss: 1.745e+00, Validation Loss: 1.846e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 882, Training Loss: 1.744e+00, Validation Loss: 1.846e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 883, Training Loss: 1.743e+00, Validation Loss: 1.845e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 884, Training Loss: 1.742e+00, Validation Loss: 1.844e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 885, Training Loss: 1.741e+00, Validation Loss: 1.844e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 886, Training Loss: 1.741e+00, Validation Loss: 1.843e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 887, Training Loss: 1.740e+00, Validation Loss: 1.842e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 888, Training Loss: 1.739e+00, Validation Loss: 1.841e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 889, Training Loss: 1.738e+00, Validation Loss: 1.841e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 890, Training Loss: 1.737e+00, Validation Loss: 1.840e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 891, Training Loss: 1.737e+00, Validation Loss: 1.839e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 892, Training Loss: 1.736e+00, Validation Loss: 1.839e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 893, Training Loss: 1.735e+00, Validation Loss: 1.838e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 894, Training Loss: 1.734e+00, Validation Loss: 1.837e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 895, Training Loss: 1.734e+00, Validation Loss: 1.836e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 896, Training Loss: 1.733e+00, Validation Loss: 1.836e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 897, Training Loss: 1.732e+00, Validation Loss: 1.835e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 898, Training Loss: 1.731e+00, Validation Loss: 1.834e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 899, Training Loss: 1.730e+00, Validation Loss: 1.834e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 900, Training Loss: 1.730e+00, Validation Loss: 1.833e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 901, Training Loss: 1.729e+00, Validation Loss: 1.832e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 902, Training Loss: 1.728e+00, Validation Loss: 1.831e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 903, Training Loss: 1.727e+00, Validation Loss: 1.831e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 904, Training Loss: 1.726e+00, Validation Loss: 1.830e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 905, Training Loss: 1.726e+00, Validation Loss: 1.829e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 906, Training Loss: 1.725e+00, Validation Loss: 1.829e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 907, Training Loss: 1.724e+00, Validation Loss: 1.828e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 908, Training Loss: 1.723e+00, Validation Loss: 1.827e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 909, Training Loss: 1.723e+00, Validation Loss: 1.827e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 910, Training Loss: 1.722e+00, Validation Loss: 1.826e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 911, Training Loss: 1.721e+00, Validation Loss: 1.825e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 912, Training Loss: 1.720e+00, Validation Loss: 1.824e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 913, Training Loss: 1.719e+00, Validation Loss: 1.824e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 914, Training Loss: 1.719e+00, Validation Loss: 1.823e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 915, Training Loss: 1.718e+00, Validation Loss: 1.822e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 916, Training Loss: 1.717e+00, Validation Loss: 1.822e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 917, Training Loss: 1.716e+00, Validation Loss: 1.821e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 918, Training Loss: 1.716e+00, Validation Loss: 1.820e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 919, Training Loss: 1.715e+00, Validation Loss: 1.820e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 920, Training Loss: 1.714e+00, Validation Loss: 1.819e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 921, Training Loss: 1.713e+00, Validation Loss: 1.818e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 922, Training Loss: 1.712e+00, Validation Loss: 1.817e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 923, Training Loss: 1.712e+00, Validation Loss: 1.817e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 924, Training Loss: 1.711e+00, Validation Loss: 1.816e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 925, Training Loss: 1.710e+00, Validation Loss: 1.815e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 926, Training Loss: 1.709e+00, Validation Loss: 1.815e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 927, Training Loss: 1.709e+00, Validation Loss: 1.814e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 928, Training Loss: 1.708e+00, Validation Loss: 1.813e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 929, Training Loss: 1.707e+00, Validation Loss: 1.813e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 930, Training Loss: 1.706e+00, Validation Loss: 1.812e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 931, Training Loss: 1.705e+00, Validation Loss: 1.811e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 932, Training Loss: 1.705e+00, Validation Loss: 1.811e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 933, Training Loss: 1.704e+00, Validation Loss: 1.810e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 934, Training Loss: 1.703e+00, Validation Loss: 1.809e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 935, Training Loss: 1.702e+00, Validation Loss: 1.809e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 936, Training Loss: 1.702e+00, Validation Loss: 1.808e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 937, Training Loss: 1.701e+00, Validation Loss: 1.807e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 938, Training Loss: 1.700e+00, Validation Loss: 1.806e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 939, Training Loss: 1.699e+00, Validation Loss: 1.806e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 940, Training Loss: 1.699e+00, Validation Loss: 1.805e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 941, Training Loss: 1.698e+00, Validation Loss: 1.804e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 942, Training Loss: 1.697e+00, Validation Loss: 1.804e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 943, Training Loss: 1.696e+00, Validation Loss: 1.803e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 944, Training Loss: 1.695e+00, Validation Loss: 1.802e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 945, Training Loss: 1.695e+00, Validation Loss: 1.802e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 946, Training Loss: 1.694e+00, Validation Loss: 1.801e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 947, Training Loss: 1.693e+00, Validation Loss: 1.800e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 948, Training Loss: 1.692e+00, Validation Loss: 1.800e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 949, Training Loss: 1.692e+00, Validation Loss: 1.799e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 950, Training Loss: 1.691e+00, Validation Loss: 1.798e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 951, Training Loss: 1.690e+00, Validation Loss: 1.798e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 952, Training Loss: 1.689e+00, Validation Loss: 1.797e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 953, Training Loss: 1.689e+00, Validation Loss: 1.796e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 954, Training Loss: 1.688e+00, Validation Loss: 1.796e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 955, Training Loss: 1.687e+00, Validation Loss: 1.795e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 956, Training Loss: 1.686e+00, Validation Loss: 1.794e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 957, Training Loss: 1.686e+00, Validation Loss: 1.794e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 958, Training Loss: 1.685e+00, Validation Loss: 1.793e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 959, Training Loss: 1.684e+00, Validation Loss: 1.792e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 960, Training Loss: 1.683e+00, Validation Loss: 1.792e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 961, Training Loss: 1.683e+00, Validation Loss: 1.791e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 962, Training Loss: 1.682e+00, Validation Loss: 1.790e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 963, Training Loss: 1.681e+00, Validation Loss: 1.790e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 964, Training Loss: 1.680e+00, Validation Loss: 1.789e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 965, Training Loss: 1.680e+00, Validation Loss: 1.788e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 966, Training Loss: 1.679e+00, Validation Loss: 1.788e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 967, Training Loss: 1.678e+00, Validation Loss: 1.787e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 968, Training Loss: 1.677e+00, Validation Loss: 1.786e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 969, Training Loss: 1.677e+00, Validation Loss: 1.786e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 970, Training Loss: 1.676e+00, Validation Loss: 1.785e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 971, Training Loss: 1.675e+00, Validation Loss: 1.785e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 972, Training Loss: 1.674e+00, Validation Loss: 1.784e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 973, Training Loss: 1.674e+00, Validation Loss: 1.783e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 974, Training Loss: 1.673e+00, Validation Loss: 1.783e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 975, Training Loss: 1.672e+00, Validation Loss: 1.782e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 976, Training Loss: 1.671e+00, Validation Loss: 1.781e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 977, Training Loss: 1.671e+00, Validation Loss: 1.781e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 978, Training Loss: 1.670e+00, Validation Loss: 1.780e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 979, Training Loss: 1.669e+00, Validation Loss: 1.779e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 980, Training Loss: 1.668e+00, Validation Loss: 1.779e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 981, Training Loss: 1.668e+00, Validation Loss: 1.778e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 982, Training Loss: 1.667e+00, Validation Loss: 1.777e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 983, Training Loss: 1.666e+00, Validation Loss: 1.777e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 984, Training Loss: 1.665e+00, Validation Loss: 1.776e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 985, Training Loss: 1.665e+00, Validation Loss: 1.775e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 986, Training Loss: 1.664e+00, Validation Loss: 1.775e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 987, Training Loss: 1.663e+00, Validation Loss: 1.774e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 988, Training Loss: 1.662e+00, Validation Loss: 1.773e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 989, Training Loss: 1.662e+00, Validation Loss: 1.773e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 990, Training Loss: 1.661e+00, Validation Loss: 1.772e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 991, Training Loss: 1.660e+00, Validation Loss: 1.772e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 992, Training Loss: 1.659e+00, Validation Loss: 1.771e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 993, Training Loss: 1.659e+00, Validation Loss: 1.770e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 994, Training Loss: 1.658e+00, Validation Loss: 1.770e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 995, Training Loss: 1.657e+00, Validation Loss: 1.769e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 996, Training Loss: 1.657e+00, Validation Loss: 1.768e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 997, Training Loss: 1.656e+00, Validation Loss: 1.768e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 998, Training Loss: 1.655e+00, Validation Loss: 1.767e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 999, Training Loss: 1.654e+00, Validation Loss: 1.766e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1000, Training Loss: 1.654e+00, Validation Loss: 1.766e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1001, Training Loss: 1.653e+00, Validation Loss: 1.765e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1002, Training Loss: 1.652e+00, Validation Loss: 1.764e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1003, Training Loss: 1.651e+00, Validation Loss: 1.764e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1004, Training Loss: 1.651e+00, Validation Loss: 1.763e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1005, Training Loss: 1.650e+00, Validation Loss: 1.763e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1006, Training Loss: 1.649e+00, Validation Loss: 1.762e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1007, Training Loss: 1.649e+00, Validation Loss: 1.761e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1008, Training Loss: 1.648e+00, Validation Loss: 1.761e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1009, Training Loss: 1.647e+00, Validation Loss: 1.760e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1010, Training Loss: 1.646e+00, Validation Loss: 1.759e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1011, Training Loss: 1.646e+00, Validation Loss: 1.759e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1012, Training Loss: 1.645e+00, Validation Loss: 1.758e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1013, Training Loss: 1.644e+00, Validation Loss: 1.758e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1014, Training Loss: 1.643e+00, Validation Loss: 1.757e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1015, Training Loss: 1.643e+00, Validation Loss: 1.756e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1016, Training Loss: 1.642e+00, Validation Loss: 1.756e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1017, Training Loss: 1.641e+00, Validation Loss: 1.755e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1018, Training Loss: 1.641e+00, Validation Loss: 1.754e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1019, Training Loss: 1.640e+00, Validation Loss: 1.754e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1020, Training Loss: 1.639e+00, Validation Loss: 1.753e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1021, Training Loss: 1.638e+00, Validation Loss: 1.752e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1022, Training Loss: 1.638e+00, Validation Loss: 1.752e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1023, Training Loss: 1.637e+00, Validation Loss: 1.751e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1024, Training Loss: 1.636e+00, Validation Loss: 1.751e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1025, Training Loss: 1.635e+00, Validation Loss: 1.750e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1026, Training Loss: 1.635e+00, Validation Loss: 1.749e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1027, Training Loss: 1.634e+00, Validation Loss: 1.749e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1028, Training Loss: 1.633e+00, Validation Loss: 1.748e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1029, Training Loss: 1.633e+00, Validation Loss: 1.748e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1030, Training Loss: 1.632e+00, Validation Loss: 1.747e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1031, Training Loss: 1.631e+00, Validation Loss: 1.746e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1032, Training Loss: 1.630e+00, Validation Loss: 1.746e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1033, Training Loss: 1.630e+00, Validation Loss: 1.745e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1034, Training Loss: 1.629e+00, Validation Loss: 1.744e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1035, Training Loss: 1.628e+00, Validation Loss: 1.744e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1036, Training Loss: 1.628e+00, Validation Loss: 1.743e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1037, Training Loss: 1.627e+00, Validation Loss: 1.743e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1038, Training Loss: 1.626e+00, Validation Loss: 1.742e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1039, Training Loss: 1.625e+00, Validation Loss: 1.741e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1040, Training Loss: 1.625e+00, Validation Loss: 1.741e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1041, Training Loss: 1.624e+00, Validation Loss: 1.740e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1042, Training Loss: 1.623e+00, Validation Loss: 1.739e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1043, Training Loss: 1.623e+00, Validation Loss: 1.739e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1044, Training Loss: 1.622e+00, Validation Loss: 1.738e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1045, Training Loss: 1.621e+00, Validation Loss: 1.738e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1046, Training Loss: 1.620e+00, Validation Loss: 1.737e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1047, Training Loss: 1.620e+00, Validation Loss: 1.736e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1048, Training Loss: 1.619e+00, Validation Loss: 1.736e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1049, Training Loss: 1.618e+00, Validation Loss: 1.735e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1050, Training Loss: 1.618e+00, Validation Loss: 1.735e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1051, Training Loss: 1.617e+00, Validation Loss: 1.734e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1052, Training Loss: 1.616e+00, Validation Loss: 1.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1053, Training Loss: 1.616e+00, Validation Loss: 1.733e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1054, Training Loss: 1.615e+00, Validation Loss: 1.732e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1055, Training Loss: 1.614e+00, Validation Loss: 1.731e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1056, Training Loss: 1.613e+00, Validation Loss: 1.731e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1057, Training Loss: 1.613e+00, Validation Loss: 1.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1058, Training Loss: 1.612e+00, Validation Loss: 1.730e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1059, Training Loss: 1.611e+00, Validation Loss: 1.729e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1060, Training Loss: 1.611e+00, Validation Loss: 1.728e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1061, Training Loss: 1.610e+00, Validation Loss: 1.728e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1062, Training Loss: 1.609e+00, Validation Loss: 1.727e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1063, Training Loss: 1.609e+00, Validation Loss: 1.727e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1064, Training Loss: 1.608e+00, Validation Loss: 1.726e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1065, Training Loss: 1.607e+00, Validation Loss: 1.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1066, Training Loss: 1.606e+00, Validation Loss: 1.725e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1067, Training Loss: 1.606e+00, Validation Loss: 1.724e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1068, Training Loss: 1.605e+00, Validation Loss: 1.724e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1069, Training Loss: 1.604e+00, Validation Loss: 1.723e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1070, Training Loss: 1.604e+00, Validation Loss: 1.722e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1071, Training Loss: 1.603e+00, Validation Loss: 1.722e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1072, Training Loss: 1.602e+00, Validation Loss: 1.721e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1073, Training Loss: 1.602e+00, Validation Loss: 1.721e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1074, Training Loss: 1.601e+00, Validation Loss: 1.720e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1075, Training Loss: 1.600e+00, Validation Loss: 1.719e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1076, Training Loss: 1.599e+00, Validation Loss: 1.719e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1077, Training Loss: 1.599e+00, Validation Loss: 1.718e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1078, Training Loss: 1.598e+00, Validation Loss: 1.718e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1079, Training Loss: 1.597e+00, Validation Loss: 1.717e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1080, Training Loss: 1.597e+00, Validation Loss: 1.716e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1081, Training Loss: 1.596e+00, Validation Loss: 1.716e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1082, Training Loss: 1.595e+00, Validation Loss: 1.715e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1083, Training Loss: 1.595e+00, Validation Loss: 1.715e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1084, Training Loss: 1.594e+00, Validation Loss: 1.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1085, Training Loss: 1.593e+00, Validation Loss: 1.714e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1086, Training Loss: 1.593e+00, Validation Loss: 1.713e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1087, Training Loss: 1.592e+00, Validation Loss: 1.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1088, Training Loss: 1.591e+00, Validation Loss: 1.712e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1089, Training Loss: 1.591e+00, Validation Loss: 1.711e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1090, Training Loss: 1.590e+00, Validation Loss: 1.711e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1091, Training Loss: 1.589e+00, Validation Loss: 1.710e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1092, Training Loss: 1.588e+00, Validation Loss: 1.709e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1093, Training Loss: 1.588e+00, Validation Loss: 1.709e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1094, Training Loss: 1.587e+00, Validation Loss: 1.708e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1095, Training Loss: 1.586e+00, Validation Loss: 1.708e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1096, Training Loss: 1.586e+00, Validation Loss: 1.707e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1097, Training Loss: 1.585e+00, Validation Loss: 1.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1098, Training Loss: 1.584e+00, Validation Loss: 1.706e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1099, Training Loss: 1.584e+00, Validation Loss: 1.705e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1100, Training Loss: 1.583e+00, Validation Loss: 1.705e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1101, Training Loss: 1.582e+00, Validation Loss: 1.704e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1102, Training Loss: 1.582e+00, Validation Loss: 1.703e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1103, Training Loss: 1.581e+00, Validation Loss: 1.703e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1104, Training Loss: 1.580e+00, Validation Loss: 1.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1105, Training Loss: 1.580e+00, Validation Loss: 1.702e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1106, Training Loss: 1.579e+00, Validation Loss: 1.701e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1107, Training Loss: 1.578e+00, Validation Loss: 1.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1108, Training Loss: 1.578e+00, Validation Loss: 1.700e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1109, Training Loss: 1.577e+00, Validation Loss: 1.699e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1110, Training Loss: 1.576e+00, Validation Loss: 1.699e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1111, Training Loss: 1.576e+00, Validation Loss: 1.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1112, Training Loss: 1.575e+00, Validation Loss: 1.698e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1113, Training Loss: 1.574e+00, Validation Loss: 1.697e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1114, Training Loss: 1.574e+00, Validation Loss: 1.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1115, Training Loss: 1.573e+00, Validation Loss: 1.696e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1116, Training Loss: 1.572e+00, Validation Loss: 1.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1117, Training Loss: 1.572e+00, Validation Loss: 1.695e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1118, Training Loss: 1.571e+00, Validation Loss: 1.694e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1119, Training Loss: 1.570e+00, Validation Loss: 1.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1120, Training Loss: 1.570e+00, Validation Loss: 1.693e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1121, Training Loss: 1.569e+00, Validation Loss: 1.692e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1122, Training Loss: 1.568e+00, Validation Loss: 1.692e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1123, Training Loss: 1.567e+00, Validation Loss: 1.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1124, Training Loss: 1.567e+00, Validation Loss: 1.691e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1125, Training Loss: 1.566e+00, Validation Loss: 1.690e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1126, Training Loss: 1.565e+00, Validation Loss: 1.689e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1127, Training Loss: 1.565e+00, Validation Loss: 1.689e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1128, Training Loss: 1.564e+00, Validation Loss: 1.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1129, Training Loss: 1.563e+00, Validation Loss: 1.688e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1130, Training Loss: 1.563e+00, Validation Loss: 1.687e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1131, Training Loss: 1.562e+00, Validation Loss: 1.686e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1132, Training Loss: 1.561e+00, Validation Loss: 1.686e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1133, Training Loss: 1.561e+00, Validation Loss: 1.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1134, Training Loss: 1.560e+00, Validation Loss: 1.685e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1135, Training Loss: 1.559e+00, Validation Loss: 1.684e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1136, Training Loss: 1.559e+00, Validation Loss: 1.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1137, Training Loss: 1.558e+00, Validation Loss: 1.683e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1138, Training Loss: 1.557e+00, Validation Loss: 1.682e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1139, Training Loss: 1.557e+00, Validation Loss: 1.682e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1140, Training Loss: 1.556e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1141, Training Loss: 1.556e+00, Validation Loss: 1.681e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1142, Training Loss: 1.555e+00, Validation Loss: 1.680e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1143, Training Loss: 1.554e+00, Validation Loss: 1.679e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1144, Training Loss: 1.554e+00, Validation Loss: 1.679e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1145, Training Loss: 1.553e+00, Validation Loss: 1.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1146, Training Loss: 1.552e+00, Validation Loss: 1.678e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1147, Training Loss: 1.552e+00, Validation Loss: 1.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1148, Training Loss: 1.551e+00, Validation Loss: 1.677e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1149, Training Loss: 1.550e+00, Validation Loss: 1.676e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1150, Training Loss: 1.550e+00, Validation Loss: 1.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1151, Training Loss: 1.549e+00, Validation Loss: 1.675e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1152, Training Loss: 1.548e+00, Validation Loss: 1.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1153, Training Loss: 1.548e+00, Validation Loss: 1.674e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1154, Training Loss: 1.547e+00, Validation Loss: 1.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1155, Training Loss: 1.546e+00, Validation Loss: 1.673e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1156, Training Loss: 1.546e+00, Validation Loss: 1.672e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1157, Training Loss: 1.545e+00, Validation Loss: 1.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1158, Training Loss: 1.544e+00, Validation Loss: 1.671e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1159, Training Loss: 1.544e+00, Validation Loss: 1.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1160, Training Loss: 1.543e+00, Validation Loss: 1.670e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1161, Training Loss: 1.542e+00, Validation Loss: 1.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1162, Training Loss: 1.542e+00, Validation Loss: 1.669e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1163, Training Loss: 1.541e+00, Validation Loss: 1.668e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1164, Training Loss: 1.540e+00, Validation Loss: 1.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1165, Training Loss: 1.540e+00, Validation Loss: 1.667e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1166, Training Loss: 1.539e+00, Validation Loss: 1.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1167, Training Loss: 1.538e+00, Validation Loss: 1.666e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1168, Training Loss: 1.538e+00, Validation Loss: 1.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1169, Training Loss: 1.537e+00, Validation Loss: 1.665e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1170, Training Loss: 1.537e+00, Validation Loss: 1.664e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1171, Training Loss: 1.536e+00, Validation Loss: 1.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1172, Training Loss: 1.535e+00, Validation Loss: 1.663e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1173, Training Loss: 1.535e+00, Validation Loss: 1.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1174, Training Loss: 1.534e+00, Validation Loss: 1.662e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1175, Training Loss: 1.533e+00, Validation Loss: 1.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1176, Training Loss: 1.533e+00, Validation Loss: 1.661e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1177, Training Loss: 1.532e+00, Validation Loss: 1.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1178, Training Loss: 1.531e+00, Validation Loss: 1.660e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1179, Training Loss: 1.531e+00, Validation Loss: 1.659e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1180, Training Loss: 1.530e+00, Validation Loss: 1.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1181, Training Loss: 1.529e+00, Validation Loss: 1.658e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1182, Training Loss: 1.529e+00, Validation Loss: 1.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1183, Training Loss: 1.528e+00, Validation Loss: 1.657e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1184, Training Loss: 1.527e+00, Validation Loss: 1.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1185, Training Loss: 1.527e+00, Validation Loss: 1.656e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1186, Training Loss: 1.526e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1187, Training Loss: 1.526e+00, Validation Loss: 1.655e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1188, Training Loss: 1.525e+00, Validation Loss: 1.654e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1189, Training Loss: 1.524e+00, Validation Loss: 1.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1190, Training Loss: 1.524e+00, Validation Loss: 1.653e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1191, Training Loss: 1.523e+00, Validation Loss: 1.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1192, Training Loss: 1.522e+00, Validation Loss: 1.652e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1193, Training Loss: 1.522e+00, Validation Loss: 1.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1194, Training Loss: 1.521e+00, Validation Loss: 1.651e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1195, Training Loss: 1.520e+00, Validation Loss: 1.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1196, Training Loss: 1.520e+00, Validation Loss: 1.650e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1197, Training Loss: 1.519e+00, Validation Loss: 1.649e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1198, Training Loss: 1.519e+00, Validation Loss: 1.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1199, Training Loss: 1.518e+00, Validation Loss: 1.648e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1200, Training Loss: 1.517e+00, Validation Loss: 1.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1201, Training Loss: 1.517e+00, Validation Loss: 1.647e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1202, Training Loss: 1.516e+00, Validation Loss: 1.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1203, Training Loss: 1.515e+00, Validation Loss: 1.646e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1204, Training Loss: 1.515e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1205, Training Loss: 1.514e+00, Validation Loss: 1.645e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1206, Training Loss: 1.513e+00, Validation Loss: 1.644e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1207, Training Loss: 1.513e+00, Validation Loss: 1.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1208, Training Loss: 1.512e+00, Validation Loss: 1.643e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1209, Training Loss: 1.512e+00, Validation Loss: 1.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1210, Training Loss: 1.511e+00, Validation Loss: 1.642e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1211, Training Loss: 1.510e+00, Validation Loss: 1.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1212, Training Loss: 1.510e+00, Validation Loss: 1.641e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1213, Training Loss: 1.509e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1214, Training Loss: 1.508e+00, Validation Loss: 1.640e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1215, Training Loss: 1.508e+00, Validation Loss: 1.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1216, Training Loss: 1.507e+00, Validation Loss: 1.639e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1217, Training Loss: 1.507e+00, Validation Loss: 1.638e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1218, Training Loss: 1.506e+00, Validation Loss: 1.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1219, Training Loss: 1.505e+00, Validation Loss: 1.637e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1220, Training Loss: 1.505e+00, Validation Loss: 1.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1221, Training Loss: 1.504e+00, Validation Loss: 1.636e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1222, Training Loss: 1.503e+00, Validation Loss: 1.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1223, Training Loss: 1.503e+00, Validation Loss: 1.635e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1224, Training Loss: 1.502e+00, Validation Loss: 1.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1225, Training Loss: 1.501e+00, Validation Loss: 1.634e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1226, Training Loss: 1.501e+00, Validation Loss: 1.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1227, Training Loss: 1.500e+00, Validation Loss: 1.633e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1228, Training Loss: 1.500e+00, Validation Loss: 1.632e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1229, Training Loss: 1.499e+00, Validation Loss: 1.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1230, Training Loss: 1.498e+00, Validation Loss: 1.631e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1231, Training Loss: 1.498e+00, Validation Loss: 1.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1232, Training Loss: 1.497e+00, Validation Loss: 1.630e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1233, Training Loss: 1.496e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1234, Training Loss: 1.496e+00, Validation Loss: 1.629e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1235, Training Loss: 1.495e+00, Validation Loss: 1.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1236, Training Loss: 1.495e+00, Validation Loss: 1.628e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1237, Training Loss: 1.494e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1238, Training Loss: 1.493e+00, Validation Loss: 1.627e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1239, Training Loss: 1.493e+00, Validation Loss: 1.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1240, Training Loss: 1.492e+00, Validation Loss: 1.626e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1241, Training Loss: 1.491e+00, Validation Loss: 1.625e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1242, Training Loss: 1.491e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1243, Training Loss: 1.490e+00, Validation Loss: 1.624e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1244, Training Loss: 1.490e+00, Validation Loss: 1.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1245, Training Loss: 1.489e+00, Validation Loss: 1.623e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1246, Training Loss: 1.488e+00, Validation Loss: 1.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1247, Training Loss: 1.488e+00, Validation Loss: 1.622e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1248, Training Loss: 1.487e+00, Validation Loss: 1.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1249, Training Loss: 1.486e+00, Validation Loss: 1.621e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1250, Training Loss: 1.486e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1251, Training Loss: 1.485e+00, Validation Loss: 1.620e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1252, Training Loss: 1.485e+00, Validation Loss: 1.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1253, Training Loss: 1.484e+00, Validation Loss: 1.619e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1254, Training Loss: 1.483e+00, Validation Loss: 1.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1255, Training Loss: 1.483e+00, Validation Loss: 1.618e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1256, Training Loss: 1.482e+00, Validation Loss: 1.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1257, Training Loss: 1.482e+00, Validation Loss: 1.617e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1258, Training Loss: 1.481e+00, Validation Loss: 1.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1259, Training Loss: 1.480e+00, Validation Loss: 1.616e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1260, Training Loss: 1.480e+00, Validation Loss: 1.615e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1261, Training Loss: 1.479e+00, Validation Loss: 1.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1262, Training Loss: 1.478e+00, Validation Loss: 1.614e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1263, Training Loss: 1.478e+00, Validation Loss: 1.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1264, Training Loss: 1.477e+00, Validation Loss: 1.613e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1265, Training Loss: 1.477e+00, Validation Loss: 1.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1266, Training Loss: 1.476e+00, Validation Loss: 1.612e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1267, Training Loss: 1.475e+00, Validation Loss: 1.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1268, Training Loss: 1.475e+00, Validation Loss: 1.611e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1269, Training Loss: 1.474e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1270, Training Loss: 1.474e+00, Validation Loss: 1.610e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1271, Training Loss: 1.473e+00, Validation Loss: 1.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1272, Training Loss: 1.472e+00, Validation Loss: 1.609e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1273, Training Loss: 1.472e+00, Validation Loss: 1.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1274, Training Loss: 1.471e+00, Validation Loss: 1.608e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1275, Training Loss: 1.471e+00, Validation Loss: 1.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1276, Training Loss: 1.470e+00, Validation Loss: 1.607e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1277, Training Loss: 1.469e+00, Validation Loss: 1.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1278, Training Loss: 1.469e+00, Validation Loss: 1.606e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1279, Training Loss: 1.468e+00, Validation Loss: 1.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1280, Training Loss: 1.468e+00, Validation Loss: 1.605e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1281, Training Loss: 1.467e+00, Validation Loss: 1.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1282, Training Loss: 1.466e+00, Validation Loss: 1.604e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1283, Training Loss: 1.466e+00, Validation Loss: 1.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1284, Training Loss: 1.465e+00, Validation Loss: 1.603e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1285, Training Loss: 1.464e+00, Validation Loss: 1.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1286, Training Loss: 1.464e+00, Validation Loss: 1.602e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1287, Training Loss: 1.463e+00, Validation Loss: 1.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1288, Training Loss: 1.463e+00, Validation Loss: 1.601e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1289, Training Loss: 1.462e+00, Validation Loss: 1.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1290, Training Loss: 1.461e+00, Validation Loss: 1.600e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1291, Training Loss: 1.461e+00, Validation Loss: 1.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1292, Training Loss: 1.460e+00, Validation Loss: 1.599e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1293, Training Loss: 1.460e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1294, Training Loss: 1.459e+00, Validation Loss: 1.598e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1295, Training Loss: 1.458e+00, Validation Loss: 1.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1296, Training Loss: 1.458e+00, Validation Loss: 1.597e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1297, Training Loss: 1.457e+00, Validation Loss: 1.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1298, Training Loss: 1.457e+00, Validation Loss: 1.596e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1299, Training Loss: 1.456e+00, Validation Loss: 1.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1300, Training Loss: 1.455e+00, Validation Loss: 1.595e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1301, Training Loss: 1.455e+00, Validation Loss: 1.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1302, Training Loss: 1.454e+00, Validation Loss: 1.594e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1303, Training Loss: 1.454e+00, Validation Loss: 1.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1304, Training Loss: 1.453e+00, Validation Loss: 1.593e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1305, Training Loss: 1.452e+00, Validation Loss: 1.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1306, Training Loss: 1.452e+00, Validation Loss: 1.592e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1307, Training Loss: 1.451e+00, Validation Loss: 1.591e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1308, Training Loss: 1.451e+00, Validation Loss: 1.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1309, Training Loss: 1.450e+00, Validation Loss: 1.590e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1310, Training Loss: 1.449e+00, Validation Loss: 1.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1311, Training Loss: 1.449e+00, Validation Loss: 1.589e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1312, Training Loss: 1.448e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1313, Training Loss: 1.448e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1314, Training Loss: 1.447e+00, Validation Loss: 1.588e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1315, Training Loss: 1.446e+00, Validation Loss: 1.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1316, Training Loss: 1.446e+00, Validation Loss: 1.587e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1317, Training Loss: 1.445e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1318, Training Loss: 1.445e+00, Validation Loss: 1.586e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1319, Training Loss: 1.444e+00, Validation Loss: 1.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1320, Training Loss: 1.443e+00, Validation Loss: 1.585e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1321, Training Loss: 1.443e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1322, Training Loss: 1.442e+00, Validation Loss: 1.584e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1323, Training Loss: 1.442e+00, Validation Loss: 1.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1324, Training Loss: 1.441e+00, Validation Loss: 1.583e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1325, Training Loss: 1.440e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1326, Training Loss: 1.440e+00, Validation Loss: 1.582e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1327, Training Loss: 1.439e+00, Validation Loss: 1.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1328, Training Loss: 1.439e+00, Validation Loss: 1.581e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1329, Training Loss: 1.438e+00, Validation Loss: 1.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1330, Training Loss: 1.438e+00, Validation Loss: 1.580e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1331, Training Loss: 1.437e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1332, Training Loss: 1.436e+00, Validation Loss: 1.579e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1333, Training Loss: 1.436e+00, Validation Loss: 1.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1334, Training Loss: 1.435e+00, Validation Loss: 1.578e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1335, Training Loss: 1.435e+00, Validation Loss: 1.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1336, Training Loss: 1.434e+00, Validation Loss: 1.577e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1337, Training Loss: 1.433e+00, Validation Loss: 1.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1338, Training Loss: 1.433e+00, Validation Loss: 1.576e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1339, Training Loss: 1.432e+00, Validation Loss: 1.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1340, Training Loss: 1.432e+00, Validation Loss: 1.575e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1341, Training Loss: 1.431e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1342, Training Loss: 1.431e+00, Validation Loss: 1.574e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1343, Training Loss: 1.430e+00, Validation Loss: 1.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1344, Training Loss: 1.429e+00, Validation Loss: 1.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1345, Training Loss: 1.429e+00, Validation Loss: 1.573e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1346, Training Loss: 1.428e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1347, Training Loss: 1.428e+00, Validation Loss: 1.572e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1348, Training Loss: 1.427e+00, Validation Loss: 1.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1349, Training Loss: 1.426e+00, Validation Loss: 1.571e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1350, Training Loss: 1.426e+00, Validation Loss: 1.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1351, Training Loss: 1.425e+00, Validation Loss: 1.570e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1352, Training Loss: 1.425e+00, Validation Loss: 1.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1353, Training Loss: 1.424e+00, Validation Loss: 1.569e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1354, Training Loss: 1.424e+00, Validation Loss: 1.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1355, Training Loss: 1.423e+00, Validation Loss: 1.568e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1356, Training Loss: 1.422e+00, Validation Loss: 1.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1357, Training Loss: 1.422e+00, Validation Loss: 1.567e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1358, Training Loss: 1.421e+00, Validation Loss: 1.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1359, Training Loss: 1.421e+00, Validation Loss: 1.566e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1360, Training Loss: 1.420e+00, Validation Loss: 1.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1361, Training Loss: 1.420e+00, Validation Loss: 1.565e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1362, Training Loss: 1.419e+00, Validation Loss: 1.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1363, Training Loss: 1.419e+00, Validation Loss: 1.564e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1364, Training Loss: 1.418e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1365, Training Loss: 1.417e+00, Validation Loss: 1.563e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1366, Training Loss: 1.417e+00, Validation Loss: 1.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1367, Training Loss: 1.416e+00, Validation Loss: 1.562e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1368, Training Loss: 1.416e+00, Validation Loss: 1.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1369, Training Loss: 1.415e+00, Validation Loss: 1.561e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1370, Training Loss: 1.415e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1371, Training Loss: 1.414e+00, Validation Loss: 1.560e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1372, Training Loss: 1.413e+00, Validation Loss: 1.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1373, Training Loss: 1.413e+00, Validation Loss: 1.559e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1374, Training Loss: 1.412e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1375, Training Loss: 1.412e+00, Validation Loss: 1.558e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1376, Training Loss: 1.411e+00, Validation Loss: 1.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1377, Training Loss: 1.411e+00, Validation Loss: 1.557e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1378, Training Loss: 1.410e+00, Validation Loss: 1.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1379, Training Loss: 1.410e+00, Validation Loss: 1.556e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1380, Training Loss: 1.409e+00, Validation Loss: 1.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1381, Training Loss: 1.408e+00, Validation Loss: 1.555e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1382, Training Loss: 1.408e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1383, Training Loss: 1.407e+00, Validation Loss: 1.554e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1384, Training Loss: 1.407e+00, Validation Loss: 1.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1385, Training Loss: 1.406e+00, Validation Loss: 1.553e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1386, Training Loss: 1.406e+00, Validation Loss: 1.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1387, Training Loss: 1.405e+00, Validation Loss: 1.552e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1388, Training Loss: 1.404e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1389, Training Loss: 1.404e+00, Validation Loss: 1.551e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1390, Training Loss: 1.403e+00, Validation Loss: 1.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1391, Training Loss: 1.403e+00, Validation Loss: 1.550e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1392, Training Loss: 1.402e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1393, Training Loss: 1.402e+00, Validation Loss: 1.549e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1394, Training Loss: 1.401e+00, Validation Loss: 1.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1395, Training Loss: 1.401e+00, Validation Loss: 1.548e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1396, Training Loss: 1.400e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1397, Training Loss: 1.399e+00, Validation Loss: 1.547e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1398, Training Loss: 1.399e+00, Validation Loss: 1.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1399, Training Loss: 1.398e+00, Validation Loss: 1.546e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1400, Training Loss: 1.398e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1401, Training Loss: 1.397e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1402, Training Loss: 1.397e+00, Validation Loss: 1.545e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1403, Training Loss: 1.396e+00, Validation Loss: 1.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1404, Training Loss: 1.396e+00, Validation Loss: 1.544e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1405, Training Loss: 1.395e+00, Validation Loss: 1.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1406, Training Loss: 1.394e+00, Validation Loss: 1.543e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1407, Training Loss: 1.394e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1408, Training Loss: 1.393e+00, Validation Loss: 1.542e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1409, Training Loss: 1.393e+00, Validation Loss: 1.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1410, Training Loss: 1.392e+00, Validation Loss: 1.541e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1411, Training Loss: 1.392e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1412, Training Loss: 1.391e+00, Validation Loss: 1.540e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1413, Training Loss: 1.391e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1414, Training Loss: 1.390e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1415, Training Loss: 1.390e+00, Validation Loss: 1.539e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1416, Training Loss: 1.389e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1417, Training Loss: 1.388e+00, Validation Loss: 1.538e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1418, Training Loss: 1.388e+00, Validation Loss: 1.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1419, Training Loss: 1.387e+00, Validation Loss: 1.537e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1420, Training Loss: 1.387e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1421, Training Loss: 1.386e+00, Validation Loss: 1.536e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1422, Training Loss: 1.386e+00, Validation Loss: 1.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1423, Training Loss: 1.385e+00, Validation Loss: 1.535e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1424, Training Loss: 1.385e+00, Validation Loss: 1.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1425, Training Loss: 1.384e+00, Validation Loss: 1.534e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1426, Training Loss: 1.384e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1427, Training Loss: 1.383e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1428, Training Loss: 1.382e+00, Validation Loss: 1.533e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1429, Training Loss: 1.382e+00, Validation Loss: 1.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1430, Training Loss: 1.381e+00, Validation Loss: 1.532e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1431, Training Loss: 1.381e+00, Validation Loss: 1.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1432, Training Loss: 1.380e+00, Validation Loss: 1.531e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1433, Training Loss: 1.380e+00, Validation Loss: 1.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1434, Training Loss: 1.379e+00, Validation Loss: 1.530e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1435, Training Loss: 1.379e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1436, Training Loss: 1.378e+00, Validation Loss: 1.529e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1437, Training Loss: 1.378e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1438, Training Loss: 1.377e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1439, Training Loss: 1.376e+00, Validation Loss: 1.528e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1440, Training Loss: 1.376e+00, Validation Loss: 1.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1441, Training Loss: 1.375e+00, Validation Loss: 1.527e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1442, Training Loss: 1.375e+00, Validation Loss: 1.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1443, Training Loss: 1.374e+00, Validation Loss: 1.526e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1444, Training Loss: 1.374e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1445, Training Loss: 1.373e+00, Validation Loss: 1.525e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1446, Training Loss: 1.373e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1447, Training Loss: 1.372e+00, Validation Loss: 1.524e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1448, Training Loss: 1.372e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1449, Training Loss: 1.371e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1450, Training Loss: 1.371e+00, Validation Loss: 1.523e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1451, Training Loss: 1.370e+00, Validation Loss: 1.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1452, Training Loss: 1.369e+00, Validation Loss: 1.522e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1453, Training Loss: 1.369e+00, Validation Loss: 1.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1454, Training Loss: 1.368e+00, Validation Loss: 1.521e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1455, Training Loss: 1.368e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1456, Training Loss: 1.367e+00, Validation Loss: 1.520e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1457, Training Loss: 1.367e+00, Validation Loss: 1.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1458, Training Loss: 1.366e+00, Validation Loss: 1.519e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1459, Training Loss: 1.366e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1460, Training Loss: 1.365e+00, Validation Loss: 1.518e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1461, Training Loss: 1.365e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1462, Training Loss: 1.364e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1463, Training Loss: 1.364e+00, Validation Loss: 1.517e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1464, Training Loss: 1.363e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1465, Training Loss: 1.363e+00, Validation Loss: 1.516e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1466, Training Loss: 1.362e+00, Validation Loss: 1.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1467, Training Loss: 1.362e+00, Validation Loss: 1.515e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1468, Training Loss: 1.361e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1469, Training Loss: 1.360e+00, Validation Loss: 1.514e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1470, Training Loss: 1.360e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1471, Training Loss: 1.359e+00, Validation Loss: 1.513e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1472, Training Loss: 1.359e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1473, Training Loss: 1.358e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1474, Training Loss: 1.358e+00, Validation Loss: 1.512e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1475, Training Loss: 1.357e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1476, Training Loss: 1.357e+00, Validation Loss: 1.511e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1477, Training Loss: 1.356e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1478, Training Loss: 1.356e+00, Validation Loss: 1.510e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1479, Training Loss: 1.355e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1480, Training Loss: 1.355e+00, Validation Loss: 1.509e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1481, Training Loss: 1.354e+00, Validation Loss: 1.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1482, Training Loss: 1.354e+00, Validation Loss: 1.508e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1483, Training Loss: 1.353e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1484, Training Loss: 1.353e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1485, Training Loss: 1.352e+00, Validation Loss: 1.507e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1486, Training Loss: 1.352e+00, Validation Loss: 1.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1487, Training Loss: 1.351e+00, Validation Loss: 1.506e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1488, Training Loss: 1.350e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1489, Training Loss: 1.350e+00, Validation Loss: 1.505e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1490, Training Loss: 1.349e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1491, Training Loss: 1.349e+00, Validation Loss: 1.504e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1492, Training Loss: 1.348e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1493, Training Loss: 1.348e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1494, Training Loss: 1.347e+00, Validation Loss: 1.503e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1495, Training Loss: 1.347e+00, Validation Loss: 1.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1496, Training Loss: 1.346e+00, Validation Loss: 1.502e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1497, Training Loss: 1.346e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1498, Training Loss: 1.345e+00, Validation Loss: 1.501e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1499, Training Loss: 1.345e+00, Validation Loss: 1.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1500, Training Loss: 1.344e+00, Validation Loss: 1.500e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1501, Training Loss: 1.344e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1502, Training Loss: 1.343e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1503, Training Loss: 1.343e+00, Validation Loss: 1.499e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1504, Training Loss: 1.342e+00, Validation Loss: 1.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1505, Training Loss: 1.342e+00, Validation Loss: 1.498e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1506, Training Loss: 1.341e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1507, Training Loss: 1.341e+00, Validation Loss: 1.497e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1508, Training Loss: 1.340e+00, Validation Loss: 1.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1509, Training Loss: 1.340e+00, Validation Loss: 1.496e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1510, Training Loss: 1.339e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1511, Training Loss: 1.339e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1512, Training Loss: 1.338e+00, Validation Loss: 1.495e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1513, Training Loss: 1.338e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1514, Training Loss: 1.337e+00, Validation Loss: 1.494e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1515, Training Loss: 1.337e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1516, Training Loss: 1.336e+00, Validation Loss: 1.493e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1517, Training Loss: 1.336e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1518, Training Loss: 1.335e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1519, Training Loss: 1.335e+00, Validation Loss: 1.492e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1520, Training Loss: 1.334e+00, Validation Loss: 1.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1521, Training Loss: 1.334e+00, Validation Loss: 1.491e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1522, Training Loss: 1.333e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1523, Training Loss: 1.332e+00, Validation Loss: 1.490e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1524, Training Loss: 1.332e+00, Validation Loss: 1.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1525, Training Loss: 1.331e+00, Validation Loss: 1.489e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1526, Training Loss: 1.331e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1527, Training Loss: 1.330e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1528, Training Loss: 1.330e+00, Validation Loss: 1.488e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1529, Training Loss: 1.329e+00, Validation Loss: 1.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1530, Training Loss: 1.329e+00, Validation Loss: 1.487e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1531, Training Loss: 1.328e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1532, Training Loss: 1.328e+00, Validation Loss: 1.486e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1533, Training Loss: 1.327e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1534, Training Loss: 1.327e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1535, Training Loss: 1.326e+00, Validation Loss: 1.485e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1536, Training Loss: 1.326e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1537, Training Loss: 1.325e+00, Validation Loss: 1.484e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1538, Training Loss: 1.325e+00, Validation Loss: 1.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1539, Training Loss: 1.324e+00, Validation Loss: 1.483e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1540, Training Loss: 1.324e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1541, Training Loss: 1.323e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1542, Training Loss: 1.323e+00, Validation Loss: 1.482e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1543, Training Loss: 1.322e+00, Validation Loss: 1.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1544, Training Loss: 1.322e+00, Validation Loss: 1.481e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1545, Training Loss: 1.321e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1546, Training Loss: 1.321e+00, Validation Loss: 1.480e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1547, Training Loss: 1.320e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1548, Training Loss: 1.320e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1549, Training Loss: 1.319e+00, Validation Loss: 1.479e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1550, Training Loss: 1.319e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1551, Training Loss: 1.318e+00, Validation Loss: 1.478e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1552, Training Loss: 1.318e+00, Validation Loss: 1.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1553, Training Loss: 1.317e+00, Validation Loss: 1.477e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1554, Training Loss: 1.317e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1555, Training Loss: 1.316e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1556, Training Loss: 1.316e+00, Validation Loss: 1.476e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1557, Training Loss: 1.315e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1558, Training Loss: 1.315e+00, Validation Loss: 1.475e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1559, Training Loss: 1.314e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1560, Training Loss: 1.314e+00, Validation Loss: 1.474e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1561, Training Loss: 1.313e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1562, Training Loss: 1.313e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1563, Training Loss: 1.312e+00, Validation Loss: 1.473e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1564, Training Loss: 1.312e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1565, Training Loss: 1.311e+00, Validation Loss: 1.472e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1566, Training Loss: 1.311e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1567, Training Loss: 1.310e+00, Validation Loss: 1.471e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1568, Training Loss: 1.310e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1569, Training Loss: 1.309e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1570, Training Loss: 1.309e+00, Validation Loss: 1.470e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1571, Training Loss: 1.309e+00, Validation Loss: 1.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1572, Training Loss: 1.308e+00, Validation Loss: 1.469e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1573, Training Loss: 1.308e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1574, Training Loss: 1.307e+00, Validation Loss: 1.468e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1575, Training Loss: 1.307e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1576, Training Loss: 1.306e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1577, Training Loss: 1.306e+00, Validation Loss: 1.467e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1578, Training Loss: 1.305e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1579, Training Loss: 1.305e+00, Validation Loss: 1.466e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1580, Training Loss: 1.304e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1581, Training Loss: 1.304e+00, Validation Loss: 1.465e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1582, Training Loss: 1.303e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1583, Training Loss: 1.303e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1584, Training Loss: 1.302e+00, Validation Loss: 1.464e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1585, Training Loss: 1.302e+00, Validation Loss: 1.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1586, Training Loss: 1.301e+00, Validation Loss: 1.463e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1587, Training Loss: 1.301e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1588, Training Loss: 1.300e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1589, Training Loss: 1.300e+00, Validation Loss: 1.462e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1590, Training Loss: 1.299e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1591, Training Loss: 1.299e+00, Validation Loss: 1.461e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1592, Training Loss: 1.298e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1593, Training Loss: 1.298e+00, Validation Loss: 1.460e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1594, Training Loss: 1.297e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1595, Training Loss: 1.297e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1596, Training Loss: 1.296e+00, Validation Loss: 1.459e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1597, Training Loss: 1.296e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1598, Training Loss: 1.295e+00, Validation Loss: 1.458e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1599, Training Loss: 1.295e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1600, Training Loss: 1.294e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1601, Training Loss: 1.294e+00, Validation Loss: 1.457e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1602, Training Loss: 1.293e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1603, Training Loss: 1.293e+00, Validation Loss: 1.456e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1604, Training Loss: 1.292e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1605, Training Loss: 1.292e+00, Validation Loss: 1.455e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1606, Training Loss: 1.292e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1607, Training Loss: 1.291e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1608, Training Loss: 1.291e+00, Validation Loss: 1.454e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1609, Training Loss: 1.290e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1610, Training Loss: 1.290e+00, Validation Loss: 1.453e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1611, Training Loss: 1.289e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1612, Training Loss: 1.289e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1613, Training Loss: 1.288e+00, Validation Loss: 1.452e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1614, Training Loss: 1.288e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1615, Training Loss: 1.287e+00, Validation Loss: 1.451e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1616, Training Loss: 1.287e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1617, Training Loss: 1.286e+00, Validation Loss: 1.450e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1618, Training Loss: 1.286e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1619, Training Loss: 1.285e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1620, Training Loss: 1.285e+00, Validation Loss: 1.449e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1621, Training Loss: 1.284e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1622, Training Loss: 1.284e+00, Validation Loss: 1.448e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1623, Training Loss: 1.283e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1624, Training Loss: 1.283e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1625, Training Loss: 1.282e+00, Validation Loss: 1.447e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1626, Training Loss: 1.282e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1627, Training Loss: 1.282e+00, Validation Loss: 1.446e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1628, Training Loss: 1.281e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1629, Training Loss: 1.281e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1630, Training Loss: 1.280e+00, Validation Loss: 1.445e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1631, Training Loss: 1.280e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1632, Training Loss: 1.279e+00, Validation Loss: 1.444e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1633, Training Loss: 1.279e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1634, Training Loss: 1.278e+00, Validation Loss: 1.443e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1635, Training Loss: 1.278e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1636, Training Loss: 1.277e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1637, Training Loss: 1.277e+00, Validation Loss: 1.442e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1638, Training Loss: 1.276e+00, Validation Loss: 1.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1639, Training Loss: 1.276e+00, Validation Loss: 1.441e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1640, Training Loss: 1.275e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1641, Training Loss: 1.275e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1642, Training Loss: 1.274e+00, Validation Loss: 1.440e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1643, Training Loss: 1.274e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1644, Training Loss: 1.274e+00, Validation Loss: 1.439e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1645, Training Loss: 1.273e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1646, Training Loss: 1.273e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1647, Training Loss: 1.272e+00, Validation Loss: 1.438e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1648, Training Loss: 1.272e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1649, Training Loss: 1.271e+00, Validation Loss: 1.437e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1650, Training Loss: 1.271e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1651, Training Loss: 1.270e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1652, Training Loss: 1.270e+00, Validation Loss: 1.436e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1653, Training Loss: 1.269e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1654, Training Loss: 1.269e+00, Validation Loss: 1.435e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1655, Training Loss: 1.268e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1656, Training Loss: 1.268e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1657, Training Loss: 1.267e+00, Validation Loss: 1.434e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1658, Training Loss: 1.267e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1659, Training Loss: 1.267e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1660, Training Loss: 1.266e+00, Validation Loss: 1.433e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1661, Training Loss: 1.266e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1662, Training Loss: 1.265e+00, Validation Loss: 1.432e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1663, Training Loss: 1.265e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1664, Training Loss: 1.264e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1665, Training Loss: 1.264e+00, Validation Loss: 1.431e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1666, Training Loss: 1.263e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1667, Training Loss: 1.263e+00, Validation Loss: 1.430e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1668, Training Loss: 1.262e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1669, Training Loss: 1.262e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1670, Training Loss: 1.261e+00, Validation Loss: 1.429e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1671, Training Loss: 1.261e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1672, Training Loss: 1.261e+00, Validation Loss: 1.428e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1673, Training Loss: 1.260e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1674, Training Loss: 1.260e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1675, Training Loss: 1.259e+00, Validation Loss: 1.427e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1676, Training Loss: 1.259e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1677, Training Loss: 1.258e+00, Validation Loss: 1.426e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1678, Training Loss: 1.258e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1679, Training Loss: 1.257e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1680, Training Loss: 1.257e+00, Validation Loss: 1.425e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1681, Training Loss: 1.256e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1682, Training Loss: 1.256e+00, Validation Loss: 1.424e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1683, Training Loss: 1.256e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1684, Training Loss: 1.255e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1685, Training Loss: 1.255e+00, Validation Loss: 1.423e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1686, Training Loss: 1.254e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1687, Training Loss: 1.254e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1688, Training Loss: 1.253e+00, Validation Loss: 1.422e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1689, Training Loss: 1.253e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1690, Training Loss: 1.252e+00, Validation Loss: 1.421e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1691, Training Loss: 1.252e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1692, Training Loss: 1.251e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1693, Training Loss: 1.251e+00, Validation Loss: 1.420e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1694, Training Loss: 1.251e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1695, Training Loss: 1.250e+00, Validation Loss: 1.419e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1696, Training Loss: 1.250e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1697, Training Loss: 1.249e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1698, Training Loss: 1.249e+00, Validation Loss: 1.418e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1699, Training Loss: 1.248e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1700, Training Loss: 1.248e+00, Validation Loss: 1.417e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1701, Training Loss: 1.247e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1702, Training Loss: 1.247e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1703, Training Loss: 1.246e+00, Validation Loss: 1.416e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1704, Training Loss: 1.246e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1705, Training Loss: 1.246e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1706, Training Loss: 1.245e+00, Validation Loss: 1.415e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1707, Training Loss: 1.245e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1708, Training Loss: 1.244e+00, Validation Loss: 1.414e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1709, Training Loss: 1.244e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1710, Training Loss: 1.243e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1711, Training Loss: 1.243e+00, Validation Loss: 1.413e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1712, Training Loss: 1.242e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1713, Training Loss: 1.242e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1714, Training Loss: 1.242e+00, Validation Loss: 1.412e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1715, Training Loss: 1.241e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1716, Training Loss: 1.241e+00, Validation Loss: 1.411e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1717, Training Loss: 1.240e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1718, Training Loss: 1.240e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1719, Training Loss: 1.239e+00, Validation Loss: 1.410e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1720, Training Loss: 1.239e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1721, Training Loss: 1.238e+00, Validation Loss: 1.409e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1722, Training Loss: 1.238e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1723, Training Loss: 1.238e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1724, Training Loss: 1.237e+00, Validation Loss: 1.408e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1725, Training Loss: 1.237e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1726, Training Loss: 1.236e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1727, Training Loss: 1.236e+00, Validation Loss: 1.407e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1728, Training Loss: 1.235e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1729, Training Loss: 1.235e+00, Validation Loss: 1.406e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1730, Training Loss: 1.234e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1731, Training Loss: 1.234e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1732, Training Loss: 1.234e+00, Validation Loss: 1.405e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1733, Training Loss: 1.233e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1734, Training Loss: 1.233e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1735, Training Loss: 1.232e+00, Validation Loss: 1.404e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1736, Training Loss: 1.232e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1737, Training Loss: 1.231e+00, Validation Loss: 1.403e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1738, Training Loss: 1.231e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1739, Training Loss: 1.230e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1740, Training Loss: 1.230e+00, Validation Loss: 1.402e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1741, Training Loss: 1.230e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1742, Training Loss: 1.229e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1743, Training Loss: 1.229e+00, Validation Loss: 1.401e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1744, Training Loss: 1.228e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1745, Training Loss: 1.228e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1746, Training Loss: 1.227e+00, Validation Loss: 1.400e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1747, Training Loss: 1.227e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1748, Training Loss: 1.227e+00, Validation Loss: 1.399e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1749, Training Loss: 1.226e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1750, Training Loss: 1.226e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1751, Training Loss: 1.225e+00, Validation Loss: 1.398e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1752, Training Loss: 1.225e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1753, Training Loss: 1.224e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1754, Training Loss: 1.224e+00, Validation Loss: 1.397e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1755, Training Loss: 1.223e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1756, Training Loss: 1.223e+00, Validation Loss: 1.396e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1757, Training Loss: 1.223e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1758, Training Loss: 1.222e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1759, Training Loss: 1.222e+00, Validation Loss: 1.395e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1760, Training Loss: 1.221e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1761, Training Loss: 1.221e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1762, Training Loss: 1.220e+00, Validation Loss: 1.394e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1763, Training Loss: 1.220e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1764, Training Loss: 1.220e+00, Validation Loss: 1.393e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1765, Training Loss: 1.219e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1766, Training Loss: 1.219e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1767, Training Loss: 1.218e+00, Validation Loss: 1.392e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1768, Training Loss: 1.218e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1769, Training Loss: 1.217e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1770, Training Loss: 1.217e+00, Validation Loss: 1.391e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1771, Training Loss: 1.217e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1772, Training Loss: 1.216e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1773, Training Loss: 1.216e+00, Validation Loss: 1.390e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1774, Training Loss: 1.215e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1775, Training Loss: 1.215e+00, Validation Loss: 1.389e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1776, Training Loss: 1.214e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1777, Training Loss: 1.214e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1778, Training Loss: 1.214e+00, Validation Loss: 1.388e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1779, Training Loss: 1.213e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1780, Training Loss: 1.213e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1781, Training Loss: 1.212e+00, Validation Loss: 1.387e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1782, Training Loss: 1.212e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1783, Training Loss: 1.211e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1784, Training Loss: 1.211e+00, Validation Loss: 1.386e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1785, Training Loss: 1.211e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1786, Training Loss: 1.210e+00, Validation Loss: 1.385e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1787, Training Loss: 1.210e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1788, Training Loss: 1.209e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1789, Training Loss: 1.209e+00, Validation Loss: 1.384e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1790, Training Loss: 1.208e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1791, Training Loss: 1.208e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1792, Training Loss: 1.208e+00, Validation Loss: 1.383e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1793, Training Loss: 1.207e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1794, Training Loss: 1.207e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1795, Training Loss: 1.206e+00, Validation Loss: 1.382e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1796, Training Loss: 1.206e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1797, Training Loss: 1.205e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1798, Training Loss: 1.205e+00, Validation Loss: 1.381e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1799, Training Loss: 1.205e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1800, Training Loss: 1.204e+00, Validation Loss: 1.380e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1801, Training Loss: 1.204e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1802, Training Loss: 1.203e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1803, Training Loss: 1.203e+00, Validation Loss: 1.379e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1804, Training Loss: 1.203e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1805, Training Loss: 1.202e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1806, Training Loss: 1.202e+00, Validation Loss: 1.378e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1807, Training Loss: 1.201e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1808, Training Loss: 1.201e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1809, Training Loss: 1.200e+00, Validation Loss: 1.377e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1810, Training Loss: 1.200e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1811, Training Loss: 1.200e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1812, Training Loss: 1.199e+00, Validation Loss: 1.376e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1813, Training Loss: 1.199e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1814, Training Loss: 1.198e+00, Validation Loss: 1.375e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1815, Training Loss: 1.198e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1816, Training Loss: 1.198e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1817, Training Loss: 1.197e+00, Validation Loss: 1.374e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1818, Training Loss: 1.197e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1819, Training Loss: 1.196e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1820, Training Loss: 1.196e+00, Validation Loss: 1.373e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1821, Training Loss: 1.195e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1822, Training Loss: 1.195e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1823, Training Loss: 1.195e+00, Validation Loss: 1.372e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1824, Training Loss: 1.194e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1825, Training Loss: 1.194e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1826, Training Loss: 1.193e+00, Validation Loss: 1.371e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1827, Training Loss: 1.193e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1828, Training Loss: 1.193e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1829, Training Loss: 1.192e+00, Validation Loss: 1.370e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1830, Training Loss: 1.192e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1831, Training Loss: 1.191e+00, Validation Loss: 1.369e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1832, Training Loss: 1.191e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1833, Training Loss: 1.190e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1834, Training Loss: 1.190e+00, Validation Loss: 1.368e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1835, Training Loss: 1.190e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1836, Training Loss: 1.189e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1837, Training Loss: 1.189e+00, Validation Loss: 1.367e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1838, Training Loss: 1.188e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1839, Training Loss: 1.188e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1840, Training Loss: 1.188e+00, Validation Loss: 1.366e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1841, Training Loss: 1.187e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1842, Training Loss: 1.187e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1843, Training Loss: 1.186e+00, Validation Loss: 1.365e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1844, Training Loss: 1.186e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1845, Training Loss: 1.185e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1846, Training Loss: 1.185e+00, Validation Loss: 1.364e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1847, Training Loss: 1.185e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1848, Training Loss: 1.184e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1849, Training Loss: 1.184e+00, Validation Loss: 1.363e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1850, Training Loss: 1.183e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1851, Training Loss: 1.183e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1852, Training Loss: 1.183e+00, Validation Loss: 1.362e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1853, Training Loss: 1.182e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1854, Training Loss: 1.182e+00, Validation Loss: 1.361e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1855, Training Loss: 1.181e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1856, Training Loss: 1.181e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1857, Training Loss: 1.181e+00, Validation Loss: 1.360e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1858, Training Loss: 1.180e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1859, Training Loss: 1.180e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1860, Training Loss: 1.179e+00, Validation Loss: 1.359e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1861, Training Loss: 1.179e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1862, Training Loss: 1.179e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1863, Training Loss: 1.178e+00, Validation Loss: 1.358e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1864, Training Loss: 1.178e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1865, Training Loss: 1.177e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1866, Training Loss: 1.177e+00, Validation Loss: 1.357e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1867, Training Loss: 1.177e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1868, Training Loss: 1.176e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1869, Training Loss: 1.176e+00, Validation Loss: 1.356e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1870, Training Loss: 1.175e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1871, Training Loss: 1.175e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1872, Training Loss: 1.175e+00, Validation Loss: 1.355e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1873, Training Loss: 1.174e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1874, Training Loss: 1.174e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1875, Training Loss: 1.173e+00, Validation Loss: 1.354e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1876, Training Loss: 1.173e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1877, Training Loss: 1.173e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1878, Training Loss: 1.172e+00, Validation Loss: 1.353e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1879, Training Loss: 1.172e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1880, Training Loss: 1.171e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1881, Training Loss: 1.171e+00, Validation Loss: 1.352e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1882, Training Loss: 1.171e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1883, Training Loss: 1.170e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1884, Training Loss: 1.170e+00, Validation Loss: 1.351e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1885, Training Loss: 1.169e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1886, Training Loss: 1.169e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1887, Training Loss: 1.169e+00, Validation Loss: 1.350e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1888, Training Loss: 1.168e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1889, Training Loss: 1.168e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1890, Training Loss: 1.167e+00, Validation Loss: 1.349e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1891, Training Loss: 1.167e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1892, Training Loss: 1.167e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1893, Training Loss: 1.166e+00, Validation Loss: 1.348e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1894, Training Loss: 1.166e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1895, Training Loss: 1.165e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1896, Training Loss: 1.165e+00, Validation Loss: 1.347e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1897, Training Loss: 1.165e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1898, Training Loss: 1.164e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1899, Training Loss: 1.164e+00, Validation Loss: 1.346e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1900, Training Loss: 1.163e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1901, Training Loss: 1.163e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1902, Training Loss: 1.163e+00, Validation Loss: 1.345e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1903, Training Loss: 1.162e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1904, Training Loss: 1.162e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1905, Training Loss: 1.161e+00, Validation Loss: 1.344e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1906, Training Loss: 1.161e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1907, Training Loss: 1.161e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1908, Training Loss: 1.160e+00, Validation Loss: 1.343e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1909, Training Loss: 1.160e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1910, Training Loss: 1.159e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1911, Training Loss: 1.159e+00, Validation Loss: 1.342e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1912, Training Loss: 1.159e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1913, Training Loss: 1.158e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1914, Training Loss: 1.158e+00, Validation Loss: 1.341e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1915, Training Loss: 1.157e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1916, Training Loss: 1.157e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1917, Training Loss: 1.157e+00, Validation Loss: 1.340e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1918, Training Loss: 1.156e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1919, Training Loss: 1.156e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1920, Training Loss: 1.155e+00, Validation Loss: 1.339e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1921, Training Loss: 1.155e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1922, Training Loss: 1.155e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1923, Training Loss: 1.154e+00, Validation Loss: 1.338e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1924, Training Loss: 1.154e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1925, Training Loss: 1.154e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1926, Training Loss: 1.153e+00, Validation Loss: 1.337e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1927, Training Loss: 1.153e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1928, Training Loss: 1.152e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1929, Training Loss: 1.152e+00, Validation Loss: 1.336e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1930, Training Loss: 1.152e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1931, Training Loss: 1.151e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1932, Training Loss: 1.151e+00, Validation Loss: 1.335e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1933, Training Loss: 1.150e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1934, Training Loss: 1.150e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1935, Training Loss: 1.150e+00, Validation Loss: 1.334e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1936, Training Loss: 1.149e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1937, Training Loss: 1.149e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1938, Training Loss: 1.148e+00, Validation Loss: 1.333e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1939, Training Loss: 1.148e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1940, Training Loss: 1.148e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1941, Training Loss: 1.147e+00, Validation Loss: 1.332e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1942, Training Loss: 1.147e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1943, Training Loss: 1.147e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1944, Training Loss: 1.146e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1945, Training Loss: 1.146e+00, Validation Loss: 1.331e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1946, Training Loss: 1.145e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1947, Training Loss: 1.145e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1948, Training Loss: 1.145e+00, Validation Loss: 1.330e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1949, Training Loss: 1.144e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1950, Training Loss: 1.144e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1951, Training Loss: 1.143e+00, Validation Loss: 1.329e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1952, Training Loss: 1.143e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1953, Training Loss: 1.143e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1954, Training Loss: 1.142e+00, Validation Loss: 1.328e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1955, Training Loss: 1.142e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1956, Training Loss: 1.142e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1957, Training Loss: 1.141e+00, Validation Loss: 1.327e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1958, Training Loss: 1.141e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1959, Training Loss: 1.140e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1960, Training Loss: 1.140e+00, Validation Loss: 1.326e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1961, Training Loss: 1.140e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1962, Training Loss: 1.139e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1963, Training Loss: 1.139e+00, Validation Loss: 1.325e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1964, Training Loss: 1.138e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1965, Training Loss: 1.138e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1966, Training Loss: 1.138e+00, Validation Loss: 1.324e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1967, Training Loss: 1.137e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1968, Training Loss: 1.137e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1969, Training Loss: 1.137e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1970, Training Loss: 1.136e+00, Validation Loss: 1.323e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1971, Training Loss: 1.136e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1972, Training Loss: 1.135e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1973, Training Loss: 1.135e+00, Validation Loss: 1.322e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1974, Training Loss: 1.135e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1975, Training Loss: 1.134e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1976, Training Loss: 1.134e+00, Validation Loss: 1.321e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1977, Training Loss: 1.134e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1978, Training Loss: 1.133e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1979, Training Loss: 1.133e+00, Validation Loss: 1.320e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1980, Training Loss: 1.132e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1981, Training Loss: 1.132e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1982, Training Loss: 1.132e+00, Validation Loss: 1.319e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1983, Training Loss: 1.131e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1984, Training Loss: 1.131e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1985, Training Loss: 1.131e+00, Validation Loss: 1.318e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1986, Training Loss: 1.130e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1987, Training Loss: 1.130e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1988, Training Loss: 1.129e+00, Validation Loss: 1.317e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1989, Training Loss: 1.129e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1990, Training Loss: 1.129e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1991, Training Loss: 1.128e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1992, Training Loss: 1.128e+00, Validation Loss: 1.316e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1993, Training Loss: 1.128e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1994, Training Loss: 1.127e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1995, Training Loss: 1.127e+00, Validation Loss: 1.315e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1996, Training Loss: 1.126e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1997, Training Loss: 1.126e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1998, Training Loss: 1.126e+00, Validation Loss: 1.314e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 1999, Training Loss: 1.125e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2000, Training Loss: 1.125e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2001, Training Loss: 1.125e+00, Validation Loss: 1.313e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2002, Training Loss: 1.124e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2003, Training Loss: 1.124e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2004, Training Loss: 1.123e+00, Validation Loss: 1.312e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2005, Training Loss: 1.123e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2006, Training Loss: 1.123e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2007, Training Loss: 1.122e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2008, Training Loss: 1.122e+00, Validation Loss: 1.311e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2009, Training Loss: 1.122e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2010, Training Loss: 1.121e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2011, Training Loss: 1.121e+00, Validation Loss: 1.310e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2012, Training Loss: 1.120e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2013, Training Loss: 1.120e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2014, Training Loss: 1.120e+00, Validation Loss: 1.309e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2015, Training Loss: 1.119e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2016, Training Loss: 1.119e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2017, Training Loss: 1.119e+00, Validation Loss: 1.308e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2018, Training Loss: 1.118e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2019, Training Loss: 1.118e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2020, Training Loss: 1.118e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2021, Training Loss: 1.117e+00, Validation Loss: 1.307e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2022, Training Loss: 1.117e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2023, Training Loss: 1.116e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2024, Training Loss: 1.116e+00, Validation Loss: 1.306e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2025, Training Loss: 1.116e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2026, Training Loss: 1.115e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2027, Training Loss: 1.115e+00, Validation Loss: 1.305e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2028, Training Loss: 1.115e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2029, Training Loss: 1.114e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2030, Training Loss: 1.114e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2031, Training Loss: 1.113e+00, Validation Loss: 1.304e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2032, Training Loss: 1.113e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2033, Training Loss: 1.113e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2034, Training Loss: 1.112e+00, Validation Loss: 1.303e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2035, Training Loss: 1.112e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2036, Training Loss: 1.112e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2037, Training Loss: 1.111e+00, Validation Loss: 1.302e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2038, Training Loss: 1.111e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2039, Training Loss: 1.111e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2040, Training Loss: 1.110e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2041, Training Loss: 1.110e+00, Validation Loss: 1.301e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2042, Training Loss: 1.109e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2043, Training Loss: 1.109e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2044, Training Loss: 1.109e+00, Validation Loss: 1.300e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2045, Training Loss: 1.108e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2046, Training Loss: 1.108e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2047, Training Loss: 1.108e+00, Validation Loss: 1.299e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2048, Training Loss: 1.107e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2049, Training Loss: 1.107e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2050, Training Loss: 1.106e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2051, Training Loss: 1.106e+00, Validation Loss: 1.298e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2052, Training Loss: 1.106e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2053, Training Loss: 1.105e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2054, Training Loss: 1.105e+00, Validation Loss: 1.297e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2055, Training Loss: 1.105e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2056, Training Loss: 1.104e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2057, Training Loss: 1.104e+00, Validation Loss: 1.296e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2058, Training Loss: 1.104e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2059, Training Loss: 1.103e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2060, Training Loss: 1.103e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2061, Training Loss: 1.102e+00, Validation Loss: 1.295e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2062, Training Loss: 1.102e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2063, Training Loss: 1.102e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2064, Training Loss: 1.101e+00, Validation Loss: 1.294e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2065, Training Loss: 1.101e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2066, Training Loss: 1.101e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2067, Training Loss: 1.100e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2068, Training Loss: 1.100e+00, Validation Loss: 1.293e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2069, Training Loss: 1.100e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2070, Training Loss: 1.099e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2071, Training Loss: 1.099e+00, Validation Loss: 1.292e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2072, Training Loss: 1.099e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2073, Training Loss: 1.098e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2074, Training Loss: 1.098e+00, Validation Loss: 1.291e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2075, Training Loss: 1.097e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2076, Training Loss: 1.097e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2077, Training Loss: 1.097e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2078, Training Loss: 1.096e+00, Validation Loss: 1.290e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2079, Training Loss: 1.096e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2080, Training Loss: 1.096e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2081, Training Loss: 1.095e+00, Validation Loss: 1.289e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2082, Training Loss: 1.095e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2083, Training Loss: 1.095e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2084, Training Loss: 1.094e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2085, Training Loss: 1.094e+00, Validation Loss: 1.288e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2086, Training Loss: 1.093e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2087, Training Loss: 1.093e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2088, Training Loss: 1.093e+00, Validation Loss: 1.287e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2089, Training Loss: 1.092e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2090, Training Loss: 1.092e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2091, Training Loss: 1.092e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2092, Training Loss: 1.091e+00, Validation Loss: 1.286e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2093, Training Loss: 1.091e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2094, Training Loss: 1.091e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2095, Training Loss: 1.090e+00, Validation Loss: 1.285e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2096, Training Loss: 1.090e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2097, Training Loss: 1.090e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2098, Training Loss: 1.089e+00, Validation Loss: 1.284e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2099, Training Loss: 1.089e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2100, Training Loss: 1.089e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2101, Training Loss: 1.088e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2102, Training Loss: 1.088e+00, Validation Loss: 1.283e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2103, Training Loss: 1.087e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2104, Training Loss: 1.087e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2105, Training Loss: 1.087e+00, Validation Loss: 1.282e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2106, Training Loss: 1.086e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2107, Training Loss: 1.086e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2108, Training Loss: 1.086e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2109, Training Loss: 1.085e+00, Validation Loss: 1.281e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2110, Training Loss: 1.085e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2111, Training Loss: 1.085e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2112, Training Loss: 1.084e+00, Validation Loss: 1.280e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2113, Training Loss: 1.084e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2114, Training Loss: 1.084e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2115, Training Loss: 1.083e+00, Validation Loss: 1.279e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2116, Training Loss: 1.083e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2117, Training Loss: 1.083e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2118, Training Loss: 1.082e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2119, Training Loss: 1.082e+00, Validation Loss: 1.278e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2120, Training Loss: 1.082e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2121, Training Loss: 1.081e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2122, Training Loss: 1.081e+00, Validation Loss: 1.277e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2123, Training Loss: 1.081e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2124, Training Loss: 1.080e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2125, Training Loss: 1.080e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2126, Training Loss: 1.079e+00, Validation Loss: 1.276e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2127, Training Loss: 1.079e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2128, Training Loss: 1.079e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2129, Training Loss: 1.078e+00, Validation Loss: 1.275e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2130, Training Loss: 1.078e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2131, Training Loss: 1.078e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2132, Training Loss: 1.077e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2133, Training Loss: 1.077e+00, Validation Loss: 1.274e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2134, Training Loss: 1.077e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2135, Training Loss: 1.076e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2136, Training Loss: 1.076e+00, Validation Loss: 1.273e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2137, Training Loss: 1.076e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2138, Training Loss: 1.075e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2139, Training Loss: 1.075e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2140, Training Loss: 1.075e+00, Validation Loss: 1.272e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2141, Training Loss: 1.074e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2142, Training Loss: 1.074e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2143, Training Loss: 1.074e+00, Validation Loss: 1.271e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2144, Training Loss: 1.073e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2145, Training Loss: 1.073e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2146, Training Loss: 1.073e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2147, Training Loss: 1.072e+00, Validation Loss: 1.270e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2148, Training Loss: 1.072e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2149, Training Loss: 1.072e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2150, Training Loss: 1.071e+00, Validation Loss: 1.269e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2151, Training Loss: 1.071e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2152, Training Loss: 1.071e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2153, Training Loss: 1.070e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2154, Training Loss: 1.070e+00, Validation Loss: 1.268e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2155, Training Loss: 1.069e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2156, Training Loss: 1.069e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2157, Training Loss: 1.069e+00, Validation Loss: 1.267e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2158, Training Loss: 1.068e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2159, Training Loss: 1.068e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2160, Training Loss: 1.068e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2161, Training Loss: 1.067e+00, Validation Loss: 1.266e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2162, Training Loss: 1.067e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2163, Training Loss: 1.067e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2164, Training Loss: 1.066e+00, Validation Loss: 1.265e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2165, Training Loss: 1.066e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2166, Training Loss: 1.066e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2167, Training Loss: 1.065e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2168, Training Loss: 1.065e+00, Validation Loss: 1.264e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2169, Training Loss: 1.065e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2170, Training Loss: 1.064e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2171, Training Loss: 1.064e+00, Validation Loss: 1.263e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2172, Training Loss: 1.064e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2173, Training Loss: 1.063e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2174, Training Loss: 1.063e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2175, Training Loss: 1.063e+00, Validation Loss: 1.262e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2176, Training Loss: 1.062e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2177, Training Loss: 1.062e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2178, Training Loss: 1.062e+00, Validation Loss: 1.261e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2179, Training Loss: 1.061e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2180, Training Loss: 1.061e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2181, Training Loss: 1.061e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2182, Training Loss: 1.060e+00, Validation Loss: 1.260e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2183, Training Loss: 1.060e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2184, Training Loss: 1.060e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2185, Training Loss: 1.059e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2186, Training Loss: 1.059e+00, Validation Loss: 1.259e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2187, Training Loss: 1.059e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2188, Training Loss: 1.058e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2189, Training Loss: 1.058e+00, Validation Loss: 1.258e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2190, Training Loss: 1.058e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2191, Training Loss: 1.057e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2192, Training Loss: 1.057e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2193, Training Loss: 1.057e+00, Validation Loss: 1.257e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2194, Training Loss: 1.056e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2195, Training Loss: 1.056e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2196, Training Loss: 1.056e+00, Validation Loss: 1.256e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2197, Training Loss: 1.055e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2198, Training Loss: 1.055e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2199, Training Loss: 1.055e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2200, Training Loss: 1.054e+00, Validation Loss: 1.255e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2201, Training Loss: 1.054e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2202, Training Loss: 1.054e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2203, Training Loss: 1.053e+00, Validation Loss: 1.254e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2204, Training Loss: 1.053e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2205, Training Loss: 1.053e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2206, Training Loss: 1.052e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2207, Training Loss: 1.052e+00, Validation Loss: 1.253e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2208, Training Loss: 1.052e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2209, Training Loss: 1.051e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2210, Training Loss: 1.051e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2211, Training Loss: 1.051e+00, Validation Loss: 1.252e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2212, Training Loss: 1.050e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2213, Training Loss: 1.050e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2214, Training Loss: 1.050e+00, Validation Loss: 1.251e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2215, Training Loss: 1.049e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2216, Training Loss: 1.049e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2217, Training Loss: 1.049e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2218, Training Loss: 1.048e+00, Validation Loss: 1.250e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2219, Training Loss: 1.048e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2220, Training Loss: 1.048e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2221, Training Loss: 1.047e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2222, Training Loss: 1.047e+00, Validation Loss: 1.249e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2223, Training Loss: 1.047e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2224, Training Loss: 1.046e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2225, Training Loss: 1.046e+00, Validation Loss: 1.248e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2226, Training Loss: 1.046e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2227, Training Loss: 1.045e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2228, Training Loss: 1.045e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2229, Training Loss: 1.045e+00, Validation Loss: 1.247e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2230, Training Loss: 1.044e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2231, Training Loss: 1.044e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2232, Training Loss: 1.044e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2233, Training Loss: 1.043e+00, Validation Loss: 1.246e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2234, Training Loss: 1.043e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2235, Training Loss: 1.043e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2236, Training Loss: 1.043e+00, Validation Loss: 1.245e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2237, Training Loss: 1.042e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2238, Training Loss: 1.042e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2239, Training Loss: 1.042e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2240, Training Loss: 1.041e+00, Validation Loss: 1.244e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2241, Training Loss: 1.041e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2242, Training Loss: 1.041e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2243, Training Loss: 1.040e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2244, Training Loss: 1.040e+00, Validation Loss: 1.243e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2245, Training Loss: 1.040e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2246, Training Loss: 1.039e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2247, Training Loss: 1.039e+00, Validation Loss: 1.242e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2248, Training Loss: 1.039e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2249, Training Loss: 1.038e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2250, Training Loss: 1.038e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2251, Training Loss: 1.038e+00, Validation Loss: 1.241e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2252, Training Loss: 1.037e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2253, Training Loss: 1.037e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2254, Training Loss: 1.037e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2255, Training Loss: 1.036e+00, Validation Loss: 1.240e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2256, Training Loss: 1.036e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2257, Training Loss: 1.036e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2258, Training Loss: 1.035e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2259, Training Loss: 1.035e+00, Validation Loss: 1.239e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2260, Training Loss: 1.035e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2261, Training Loss: 1.034e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2262, Training Loss: 1.034e+00, Validation Loss: 1.238e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2263, Training Loss: 1.034e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2264, Training Loss: 1.033e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2265, Training Loss: 1.033e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2266, Training Loss: 1.033e+00, Validation Loss: 1.237e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2267, Training Loss: 1.033e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2268, Training Loss: 1.032e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2269, Training Loss: 1.032e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2270, Training Loss: 1.032e+00, Validation Loss: 1.236e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2271, Training Loss: 1.031e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2272, Training Loss: 1.031e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2273, Training Loss: 1.031e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2274, Training Loss: 1.030e+00, Validation Loss: 1.235e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2275, Training Loss: 1.030e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2276, Training Loss: 1.030e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2277, Training Loss: 1.029e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2278, Training Loss: 1.029e+00, Validation Loss: 1.234e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2279, Training Loss: 1.029e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2280, Training Loss: 1.028e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2281, Training Loss: 1.028e+00, Validation Loss: 1.233e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2282, Training Loss: 1.028e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2283, Training Loss: 1.027e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2284, Training Loss: 1.027e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2285, Training Loss: 1.027e+00, Validation Loss: 1.232e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2286, Training Loss: 1.026e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2287, Training Loss: 1.026e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2288, Training Loss: 1.026e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2289, Training Loss: 1.026e+00, Validation Loss: 1.231e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2290, Training Loss: 1.025e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2291, Training Loss: 1.025e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2292, Training Loss: 1.025e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2293, Training Loss: 1.024e+00, Validation Loss: 1.230e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2294, Training Loss: 1.024e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2295, Training Loss: 1.024e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2296, Training Loss: 1.023e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2297, Training Loss: 1.023e+00, Validation Loss: 1.229e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2298, Training Loss: 1.023e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2299, Training Loss: 1.022e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2300, Training Loss: 1.022e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2301, Training Loss: 1.022e+00, Validation Loss: 1.228e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2302, Training Loss: 1.021e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2303, Training Loss: 1.021e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2304, Training Loss: 1.021e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2305, Training Loss: 1.021e+00, Validation Loss: 1.227e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2306, Training Loss: 1.020e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2307, Training Loss: 1.020e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2308, Training Loss: 1.020e+00, Validation Loss: 1.226e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2309, Training Loss: 1.019e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2310, Training Loss: 1.019e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2311, Training Loss: 1.019e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2312, Training Loss: 1.018e+00, Validation Loss: 1.225e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2313, Training Loss: 1.018e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2314, Training Loss: 1.018e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2315, Training Loss: 1.017e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2316, Training Loss: 1.017e+00, Validation Loss: 1.224e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2317, Training Loss: 1.017e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2318, Training Loss: 1.016e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2319, Training Loss: 1.016e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2320, Training Loss: 1.016e+00, Validation Loss: 1.223e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2321, Training Loss: 1.016e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2322, Training Loss: 1.015e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2323, Training Loss: 1.015e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2324, Training Loss: 1.015e+00, Validation Loss: 1.222e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2325, Training Loss: 1.014e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2326, Training Loss: 1.014e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2327, Training Loss: 1.014e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2328, Training Loss: 1.013e+00, Validation Loss: 1.221e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2329, Training Loss: 1.013e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2330, Training Loss: 1.013e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2331, Training Loss: 1.012e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2332, Training Loss: 1.012e+00, Validation Loss: 1.220e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2333, Training Loss: 1.012e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2334, Training Loss: 1.012e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2335, Training Loss: 1.011e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2336, Training Loss: 1.011e+00, Validation Loss: 1.219e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2337, Training Loss: 1.011e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2338, Training Loss: 1.010e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2339, Training Loss: 1.010e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2340, Training Loss: 1.010e+00, Validation Loss: 1.218e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2341, Training Loss: 1.009e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2342, Training Loss: 1.009e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2343, Training Loss: 1.009e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2344, Training Loss: 1.008e+00, Validation Loss: 1.217e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2345, Training Loss: 1.008e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2346, Training Loss: 1.008e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2347, Training Loss: 1.008e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2348, Training Loss: 1.007e+00, Validation Loss: 1.216e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2349, Training Loss: 1.007e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2350, Training Loss: 1.007e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2351, Training Loss: 1.006e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2352, Training Loss: 1.006e+00, Validation Loss: 1.215e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2353, Training Loss: 1.006e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2354, Training Loss: 1.005e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2355, Training Loss: 1.005e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2356, Training Loss: 1.005e+00, Validation Loss: 1.214e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2357, Training Loss: 1.005e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2358, Training Loss: 1.004e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2359, Training Loss: 1.004e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2360, Training Loss: 1.004e+00, Validation Loss: 1.213e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2361, Training Loss: 1.003e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2362, Training Loss: 1.003e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2363, Training Loss: 1.003e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2364, Training Loss: 1.002e+00, Validation Loss: 1.212e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2365, Training Loss: 1.002e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2366, Training Loss: 1.002e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2367, Training Loss: 1.002e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2368, Training Loss: 1.001e+00, Validation Loss: 1.211e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2369, Training Loss: 1.001e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2370, Training Loss: 1.001e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2371, Training Loss: 1.000e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2372, Training Loss: 1.000e+00, Validation Loss: 1.210e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2373, Training Loss: 9.997e-01, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2374, Training Loss: 9.994e-01, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2375, Training Loss: 9.991e-01, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2376, Training Loss: 9.988e-01, Validation Loss: 1.209e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2377, Training Loss: 9.985e-01, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2378, Training Loss: 9.982e-01, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2379, Training Loss: 9.979e-01, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2380, Training Loss: 9.976e-01, Validation Loss: 1.208e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2381, Training Loss: 9.973e-01, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2382, Training Loss: 9.970e-01, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2383, Training Loss: 9.967e-01, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2384, Training Loss: 9.964e-01, Validation Loss: 1.207e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2385, Training Loss: 9.961e-01, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2386, Training Loss: 9.958e-01, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2387, Training Loss: 9.955e-01, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2388, Training Loss: 9.952e-01, Validation Loss: 1.206e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2389, Training Loss: 9.949e-01, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2390, Training Loss: 9.946e-01, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2391, Training Loss: 9.943e-01, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2392, Training Loss: 9.940e-01, Validation Loss: 1.205e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2393, Training Loss: 9.937e-01, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2394, Training Loss: 9.934e-01, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2395, Training Loss: 9.931e-01, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2396, Training Loss: 9.928e-01, Validation Loss: 1.204e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2397, Training Loss: 9.926e-01, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2398, Training Loss: 9.923e-01, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2399, Training Loss: 9.920e-01, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2400, Training Loss: 9.917e-01, Validation Loss: 1.203e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2401, Training Loss: 9.914e-01, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2402, Training Loss: 9.911e-01, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2403, Training Loss: 9.908e-01, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2404, Training Loss: 9.905e-01, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2405, Training Loss: 9.902e-01, Validation Loss: 1.202e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2406, Training Loss: 9.899e-01, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2407, Training Loss: 9.896e-01, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2408, Training Loss: 9.893e-01, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2409, Training Loss: 9.890e-01, Validation Loss: 1.201e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2410, Training Loss: 9.887e-01, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2411, Training Loss: 9.884e-01, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2412, Training Loss: 9.881e-01, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2413, Training Loss: 9.878e-01, Validation Loss: 1.200e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2414, Training Loss: 9.875e-01, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2415, Training Loss: 9.873e-01, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2416, Training Loss: 9.870e-01, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2417, Training Loss: 9.867e-01, Validation Loss: 1.199e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2418, Training Loss: 9.864e-01, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2419, Training Loss: 9.861e-01, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2420, Training Loss: 9.858e-01, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2421, Training Loss: 9.855e-01, Validation Loss: 1.198e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2422, Training Loss: 9.852e-01, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2423, Training Loss: 9.849e-01, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2424, Training Loss: 9.846e-01, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2425, Training Loss: 9.843e-01, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2426, Training Loss: 9.840e-01, Validation Loss: 1.197e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2427, Training Loss: 9.837e-01, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2428, Training Loss: 9.834e-01, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2429, Training Loss: 9.832e-01, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2430, Training Loss: 9.829e-01, Validation Loss: 1.196e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2431, Training Loss: 9.826e-01, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2432, Training Loss: 9.823e-01, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2433, Training Loss: 9.820e-01, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2434, Training Loss: 9.817e-01, Validation Loss: 1.195e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2435, Training Loss: 9.814e-01, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2436, Training Loss: 9.811e-01, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2437, Training Loss: 9.808e-01, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2438, Training Loss: 9.805e-01, Validation Loss: 1.194e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2439, Training Loss: 9.802e-01, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2440, Training Loss: 9.800e-01, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2441, Training Loss: 9.797e-01, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2442, Training Loss: 9.794e-01, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2443, Training Loss: 9.791e-01, Validation Loss: 1.193e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2444, Training Loss: 9.788e-01, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2445, Training Loss: 9.785e-01, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2446, Training Loss: 9.782e-01, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2447, Training Loss: 9.779e-01, Validation Loss: 1.192e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2448, Training Loss: 9.776e-01, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2449, Training Loss: 9.774e-01, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2450, Training Loss: 9.771e-01, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2451, Training Loss: 9.768e-01, Validation Loss: 1.191e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2452, Training Loss: 9.765e-01, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2453, Training Loss: 9.762e-01, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2454, Training Loss: 9.759e-01, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2455, Training Loss: 9.756e-01, Validation Loss: 1.190e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2456, Training Loss: 9.753e-01, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2457, Training Loss: 9.750e-01, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2458, Training Loss: 9.748e-01, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2459, Training Loss: 9.745e-01, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2460, Training Loss: 9.742e-01, Validation Loss: 1.189e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2461, Training Loss: 9.739e-01, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2462, Training Loss: 9.736e-01, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2463, Training Loss: 9.733e-01, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2464, Training Loss: 9.730e-01, Validation Loss: 1.188e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2465, Training Loss: 9.727e-01, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2466, Training Loss: 9.725e-01, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2467, Training Loss: 9.722e-01, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2468, Training Loss: 9.719e-01, Validation Loss: 1.187e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2469, Training Loss: 9.716e-01, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2470, Training Loss: 9.713e-01, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2471, Training Loss: 9.710e-01, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2472, Training Loss: 9.707e-01, Validation Loss: 1.186e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2473, Training Loss: 9.705e-01, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2474, Training Loss: 9.702e-01, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2475, Training Loss: 9.699e-01, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2476, Training Loss: 9.696e-01, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2477, Training Loss: 9.693e-01, Validation Loss: 1.185e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2478, Training Loss: 9.690e-01, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2479, Training Loss: 9.687e-01, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2480, Training Loss: 9.685e-01, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2481, Training Loss: 9.682e-01, Validation Loss: 1.184e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2482, Training Loss: 9.679e-01, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2483, Training Loss: 9.676e-01, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2484, Training Loss: 9.673e-01, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2485, Training Loss: 9.670e-01, Validation Loss: 1.183e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2486, Training Loss: 9.668e-01, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2487, Training Loss: 9.665e-01, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2488, Training Loss: 9.662e-01, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2489, Training Loss: 9.659e-01, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2490, Training Loss: 9.656e-01, Validation Loss: 1.182e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2491, Training Loss: 9.653e-01, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2492, Training Loss: 9.651e-01, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2493, Training Loss: 9.648e-01, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2494, Training Loss: 9.645e-01, Validation Loss: 1.181e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2495, Training Loss: 9.642e-01, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2496, Training Loss: 9.639e-01, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2497, Training Loss: 9.636e-01, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2498, Training Loss: 9.634e-01, Validation Loss: 1.180e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2499, Training Loss: 9.631e-01, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2500, Training Loss: 9.628e-01, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2501, Training Loss: 9.625e-01, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2502, Training Loss: 9.622e-01, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2503, Training Loss: 9.620e-01, Validation Loss: 1.179e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2504, Training Loss: 9.617e-01, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2505, Training Loss: 9.614e-01, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2506, Training Loss: 9.611e-01, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2507, Training Loss: 9.608e-01, Validation Loss: 1.178e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2508, Training Loss: 9.605e-01, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2509, Training Loss: 9.603e-01, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2510, Training Loss: 9.600e-01, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2511, Training Loss: 9.597e-01, Validation Loss: 1.177e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2512, Training Loss: 9.594e-01, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2513, Training Loss: 9.591e-01, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2514, Training Loss: 9.589e-01, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2515, Training Loss: 9.586e-01, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2516, Training Loss: 9.583e-01, Validation Loss: 1.176e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2517, Training Loss: 9.580e-01, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2518, Training Loss: 9.577e-01, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2519, Training Loss: 9.575e-01, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2520, Training Loss: 9.572e-01, Validation Loss: 1.175e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2521, Training Loss: 9.569e-01, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2522, Training Loss: 9.566e-01, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2523, Training Loss: 9.563e-01, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2524, Training Loss: 9.561e-01, Validation Loss: 1.174e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2525, Training Loss: 9.558e-01, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2526, Training Loss: 9.555e-01, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2527, Training Loss: 9.552e-01, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2528, Training Loss: 9.549e-01, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2529, Training Loss: 9.547e-01, Validation Loss: 1.173e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2530, Training Loss: 9.544e-01, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2531, Training Loss: 9.541e-01, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2532, Training Loss: 9.538e-01, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2533, Training Loss: 9.535e-01, Validation Loss: 1.172e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2534, Training Loss: 9.533e-01, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2535, Training Loss: 9.530e-01, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2536, Training Loss: 9.527e-01, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2537, Training Loss: 9.524e-01, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2538, Training Loss: 9.522e-01, Validation Loss: 1.171e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2539, Training Loss: 9.519e-01, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2540, Training Loss: 9.516e-01, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2541, Training Loss: 9.513e-01, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2542, Training Loss: 9.510e-01, Validation Loss: 1.170e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2543, Training Loss: 9.508e-01, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2544, Training Loss: 9.505e-01, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2545, Training Loss: 9.502e-01, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2546, Training Loss: 9.499e-01, Validation Loss: 1.169e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2547, Training Loss: 9.497e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2548, Training Loss: 9.494e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2549, Training Loss: 9.491e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2550, Training Loss: 9.488e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2551, Training Loss: 9.486e-01, Validation Loss: 1.168e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2552, Training Loss: 9.483e-01, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2553, Training Loss: 9.480e-01, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2554, Training Loss: 9.477e-01, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2555, Training Loss: 9.475e-01, Validation Loss: 1.167e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2556, Training Loss: 9.472e-01, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2557, Training Loss: 9.469e-01, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2558, Training Loss: 9.466e-01, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2559, Training Loss: 9.464e-01, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2560, Training Loss: 9.461e-01, Validation Loss: 1.166e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2561, Training Loss: 9.458e-01, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2562, Training Loss: 9.455e-01, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2563, Training Loss: 9.453e-01, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2564, Training Loss: 9.450e-01, Validation Loss: 1.165e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2565, Training Loss: 9.447e-01, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2566, Training Loss: 9.444e-01, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2567, Training Loss: 9.442e-01, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2568, Training Loss: 9.439e-01, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2569, Training Loss: 9.436e-01, Validation Loss: 1.164e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2570, Training Loss: 9.433e-01, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2571, Training Loss: 9.431e-01, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2572, Training Loss: 9.428e-01, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2573, Training Loss: 9.425e-01, Validation Loss: 1.163e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2574, Training Loss: 9.423e-01, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2575, Training Loss: 9.420e-01, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2576, Training Loss: 9.417e-01, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2577, Training Loss: 9.414e-01, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2578, Training Loss: 9.412e-01, Validation Loss: 1.162e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2579, Training Loss: 9.409e-01, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2580, Training Loss: 9.406e-01, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2581, Training Loss: 9.404e-01, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2582, Training Loss: 9.401e-01, Validation Loss: 1.161e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2583, Training Loss: 9.398e-01, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2584, Training Loss: 9.395e-01, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2585, Training Loss: 9.393e-01, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2586, Training Loss: 9.390e-01, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2587, Training Loss: 9.387e-01, Validation Loss: 1.160e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2588, Training Loss: 9.385e-01, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2589, Training Loss: 9.382e-01, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2590, Training Loss: 9.379e-01, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2591, Training Loss: 9.377e-01, Validation Loss: 1.159e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2592, Training Loss: 9.374e-01, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2593, Training Loss: 9.371e-01, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2594, Training Loss: 9.368e-01, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2595, Training Loss: 9.366e-01, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2596, Training Loss: 9.363e-01, Validation Loss: 1.158e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2597, Training Loss: 9.360e-01, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2598, Training Loss: 9.358e-01, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2599, Training Loss: 9.355e-01, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2600, Training Loss: 9.352e-01, Validation Loss: 1.157e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2601, Training Loss: 9.350e-01, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2602, Training Loss: 9.347e-01, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2603, Training Loss: 9.344e-01, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2604, Training Loss: 9.342e-01, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2605, Training Loss: 9.339e-01, Validation Loss: 1.156e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2606, Training Loss: 9.336e-01, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2607, Training Loss: 9.334e-01, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2608, Training Loss: 9.331e-01, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2609, Training Loss: 9.328e-01, Validation Loss: 1.155e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2610, Training Loss: 9.326e-01, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2611, Training Loss: 9.323e-01, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2612, Training Loss: 9.320e-01, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2613, Training Loss: 9.318e-01, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2614, Training Loss: 9.315e-01, Validation Loss: 1.154e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2615, Training Loss: 9.312e-01, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2616, Training Loss: 9.310e-01, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2617, Training Loss: 9.307e-01, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2618, Training Loss: 9.304e-01, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2619, Training Loss: 9.302e-01, Validation Loss: 1.153e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2620, Training Loss: 9.299e-01, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2621, Training Loss: 9.296e-01, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2622, Training Loss: 9.294e-01, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2623, Training Loss: 9.291e-01, Validation Loss: 1.152e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2624, Training Loss: 9.288e-01, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2625, Training Loss: 9.286e-01, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2626, Training Loss: 9.283e-01, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2627, Training Loss: 9.280e-01, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2628, Training Loss: 9.278e-01, Validation Loss: 1.151e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2629, Training Loss: 9.275e-01, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2630, Training Loss: 9.272e-01, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2631, Training Loss: 9.270e-01, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2632, Training Loss: 9.267e-01, Validation Loss: 1.150e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2633, Training Loss: 9.265e-01, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2634, Training Loss: 9.262e-01, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2635, Training Loss: 9.259e-01, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2636, Training Loss: 9.257e-01, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2637, Training Loss: 9.254e-01, Validation Loss: 1.149e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2638, Training Loss: 9.251e-01, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2639, Training Loss: 9.249e-01, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2640, Training Loss: 9.246e-01, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2641, Training Loss: 9.243e-01, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2642, Training Loss: 9.241e-01, Validation Loss: 1.148e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2643, Training Loss: 9.238e-01, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2644, Training Loss: 9.236e-01, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2645, Training Loss: 9.233e-01, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2646, Training Loss: 9.230e-01, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2647, Training Loss: 9.228e-01, Validation Loss: 1.147e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2648, Training Loss: 9.225e-01, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2649, Training Loss: 9.223e-01, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2650, Training Loss: 9.220e-01, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2651, Training Loss: 9.217e-01, Validation Loss: 1.146e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2652, Training Loss: 9.215e-01, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2653, Training Loss: 9.212e-01, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2654, Training Loss: 9.210e-01, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2655, Training Loss: 9.207e-01, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2656, Training Loss: 9.204e-01, Validation Loss: 1.145e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2657, Training Loss: 9.202e-01, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2658, Training Loss: 9.199e-01, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2659, Training Loss: 9.196e-01, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2660, Training Loss: 9.194e-01, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2661, Training Loss: 9.191e-01, Validation Loss: 1.144e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2662, Training Loss: 9.189e-01, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2663, Training Loss: 9.186e-01, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2664, Training Loss: 9.184e-01, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2665, Training Loss: 9.181e-01, Validation Loss: 1.143e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2666, Training Loss: 9.178e-01, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2667, Training Loss: 9.176e-01, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2668, Training Loss: 9.173e-01, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2669, Training Loss: 9.171e-01, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2670, Training Loss: 9.168e-01, Validation Loss: 1.142e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2671, Training Loss: 9.165e-01, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2672, Training Loss: 9.163e-01, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2673, Training Loss: 9.160e-01, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2674, Training Loss: 9.158e-01, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2675, Training Loss: 9.155e-01, Validation Loss: 1.141e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2676, Training Loss: 9.152e-01, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2677, Training Loss: 9.150e-01, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2678, Training Loss: 9.147e-01, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2679, Training Loss: 9.145e-01, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2680, Training Loss: 9.142e-01, Validation Loss: 1.140e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2681, Training Loss: 9.140e-01, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2682, Training Loss: 9.137e-01, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2683, Training Loss: 9.134e-01, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2684, Training Loss: 9.132e-01, Validation Loss: 1.139e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2685, Training Loss: 9.129e-01, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2686, Training Loss: 9.127e-01, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2687, Training Loss: 9.124e-01, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2688, Training Loss: 9.122e-01, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2689, Training Loss: 9.119e-01, Validation Loss: 1.138e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2690, Training Loss: 9.117e-01, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2691, Training Loss: 9.114e-01, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2692, Training Loss: 9.111e-01, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2693, Training Loss: 9.109e-01, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2694, Training Loss: 9.106e-01, Validation Loss: 1.137e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2695, Training Loss: 9.104e-01, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2696, Training Loss: 9.101e-01, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2697, Training Loss: 9.099e-01, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2698, Training Loss: 9.096e-01, Validation Loss: 1.136e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2699, Training Loss: 9.094e-01, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2700, Training Loss: 9.091e-01, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2701, Training Loss: 9.088e-01, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2702, Training Loss: 9.086e-01, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2703, Training Loss: 9.083e-01, Validation Loss: 1.135e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2704, Training Loss: 9.081e-01, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2705, Training Loss: 9.078e-01, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2706, Training Loss: 9.076e-01, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2707, Training Loss: 9.073e-01, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2708, Training Loss: 9.071e-01, Validation Loss: 1.134e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2709, Training Loss: 9.068e-01, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2710, Training Loss: 9.066e-01, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2711, Training Loss: 9.063e-01, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2712, Training Loss: 9.061e-01, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2713, Training Loss: 9.058e-01, Validation Loss: 1.133e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2714, Training Loss: 9.056e-01, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2715, Training Loss: 9.053e-01, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2716, Training Loss: 9.051e-01, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2717, Training Loss: 9.048e-01, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2718, Training Loss: 9.046e-01, Validation Loss: 1.132e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2719, Training Loss: 9.043e-01, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2720, Training Loss: 9.040e-01, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2721, Training Loss: 9.038e-01, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2722, Training Loss: 9.035e-01, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2723, Training Loss: 9.033e-01, Validation Loss: 1.131e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2724, Training Loss: 9.030e-01, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2725, Training Loss: 9.028e-01, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2726, Training Loss: 9.025e-01, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2727, Training Loss: 9.023e-01, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2728, Training Loss: 9.020e-01, Validation Loss: 1.130e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2729, Training Loss: 9.018e-01, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2730, Training Loss: 9.015e-01, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2731, Training Loss: 9.013e-01, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2732, Training Loss: 9.010e-01, Validation Loss: 1.129e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2733, Training Loss: 9.008e-01, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2734, Training Loss: 9.005e-01, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2735, Training Loss: 9.003e-01, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2736, Training Loss: 9.000e-01, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2737, Training Loss: 8.998e-01, Validation Loss: 1.128e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2738, Training Loss: 8.995e-01, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2739, Training Loss: 8.993e-01, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2740, Training Loss: 8.991e-01, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2741, Training Loss: 8.988e-01, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2742, Training Loss: 8.986e-01, Validation Loss: 1.127e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2743, Training Loss: 8.983e-01, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2744, Training Loss: 8.981e-01, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2745, Training Loss: 8.978e-01, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2746, Training Loss: 8.976e-01, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2747, Training Loss: 8.973e-01, Validation Loss: 1.126e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2748, Training Loss: 8.971e-01, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2749, Training Loss: 8.968e-01, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2750, Training Loss: 8.966e-01, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2751, Training Loss: 8.963e-01, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2752, Training Loss: 8.961e-01, Validation Loss: 1.125e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2753, Training Loss: 8.958e-01, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2754, Training Loss: 8.956e-01, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2755, Training Loss: 8.953e-01, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2756, Training Loss: 8.951e-01, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2757, Training Loss: 8.948e-01, Validation Loss: 1.124e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2758, Training Loss: 8.946e-01, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2759, Training Loss: 8.944e-01, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2760, Training Loss: 8.941e-01, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2761, Training Loss: 8.939e-01, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2762, Training Loss: 8.936e-01, Validation Loss: 1.123e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2763, Training Loss: 8.934e-01, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2764, Training Loss: 8.931e-01, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2765, Training Loss: 8.929e-01, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2766, Training Loss: 8.926e-01, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2767, Training Loss: 8.924e-01, Validation Loss: 1.122e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2768, Training Loss: 8.921e-01, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2769, Training Loss: 8.919e-01, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2770, Training Loss: 8.917e-01, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2771, Training Loss: 8.914e-01, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2772, Training Loss: 8.912e-01, Validation Loss: 1.121e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2773, Training Loss: 8.909e-01, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2774, Training Loss: 8.907e-01, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2775, Training Loss: 8.904e-01, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2776, Training Loss: 8.902e-01, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2777, Training Loss: 8.900e-01, Validation Loss: 1.120e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2778, Training Loss: 8.897e-01, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2779, Training Loss: 8.895e-01, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2780, Training Loss: 8.892e-01, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2781, Training Loss: 8.890e-01, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2782, Training Loss: 8.887e-01, Validation Loss: 1.119e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2783, Training Loss: 8.885e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2784, Training Loss: 8.883e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2785, Training Loss: 8.880e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2786, Training Loss: 8.878e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2787, Training Loss: 8.875e-01, Validation Loss: 1.118e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2788, Training Loss: 8.873e-01, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2789, Training Loss: 8.870e-01, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2790, Training Loss: 8.868e-01, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2791, Training Loss: 8.866e-01, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2792, Training Loss: 8.863e-01, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2793, Training Loss: 8.861e-01, Validation Loss: 1.117e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2794, Training Loss: 8.858e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2795, Training Loss: 8.856e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2796, Training Loss: 8.854e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2797, Training Loss: 8.851e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2798, Training Loss: 8.849e-01, Validation Loss: 1.116e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2799, Training Loss: 8.846e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2800, Training Loss: 8.844e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2801, Training Loss: 8.842e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2802, Training Loss: 8.839e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2803, Training Loss: 8.837e-01, Validation Loss: 1.115e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2804, Training Loss: 8.834e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2805, Training Loss: 8.832e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2806, Training Loss: 8.830e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2807, Training Loss: 8.827e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2808, Training Loss: 8.825e-01, Validation Loss: 1.114e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2809, Training Loss: 8.822e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2810, Training Loss: 8.820e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2811, Training Loss: 8.818e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2812, Training Loss: 8.815e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2813, Training Loss: 8.813e-01, Validation Loss: 1.113e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2814, Training Loss: 8.810e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2815, Training Loss: 8.808e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2816, Training Loss: 8.806e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2817, Training Loss: 8.803e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2818, Training Loss: 8.801e-01, Validation Loss: 1.112e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2819, Training Loss: 8.798e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2820, Training Loss: 8.796e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2821, Training Loss: 8.794e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2822, Training Loss: 8.791e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2823, Training Loss: 8.789e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2824, Training Loss: 8.787e-01, Validation Loss: 1.111e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2825, Training Loss: 8.784e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2826, Training Loss: 8.782e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2827, Training Loss: 8.779e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2828, Training Loss: 8.777e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2829, Training Loss: 8.775e-01, Validation Loss: 1.110e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2830, Training Loss: 8.772e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2831, Training Loss: 8.770e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2832, Training Loss: 8.768e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2833, Training Loss: 8.765e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2834, Training Loss: 8.763e-01, Validation Loss: 1.109e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2835, Training Loss: 8.761e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2836, Training Loss: 8.758e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2837, Training Loss: 8.756e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2838, Training Loss: 8.754e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2839, Training Loss: 8.751e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2840, Training Loss: 8.749e-01, Validation Loss: 1.108e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2841, Training Loss: 8.746e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2842, Training Loss: 8.744e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2843, Training Loss: 8.742e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2844, Training Loss: 8.739e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2845, Training Loss: 8.737e-01, Validation Loss: 1.107e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2846, Training Loss: 8.735e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2847, Training Loss: 8.732e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2848, Training Loss: 8.730e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2849, Training Loss: 8.728e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2850, Training Loss: 8.725e-01, Validation Loss: 1.106e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2851, Training Loss: 8.723e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2852, Training Loss: 8.721e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2853, Training Loss: 8.718e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2854, Training Loss: 8.716e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2855, Training Loss: 8.714e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2856, Training Loss: 8.711e-01, Validation Loss: 1.105e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2857, Training Loss: 8.709e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2858, Training Loss: 8.707e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2859, Training Loss: 8.704e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2860, Training Loss: 8.702e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2861, Training Loss: 8.700e-01, Validation Loss: 1.104e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2862, Training Loss: 8.697e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2863, Training Loss: 8.695e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2864, Training Loss: 8.693e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2865, Training Loss: 8.690e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2866, Training Loss: 8.688e-01, Validation Loss: 1.103e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2867, Training Loss: 8.686e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2868, Training Loss: 8.683e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2869, Training Loss: 8.681e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2870, Training Loss: 8.679e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2871, Training Loss: 8.676e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2872, Training Loss: 8.674e-01, Validation Loss: 1.102e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2873, Training Loss: 8.672e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2874, Training Loss: 8.669e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2875, Training Loss: 8.667e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2876, Training Loss: 8.665e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2877, Training Loss: 8.663e-01, Validation Loss: 1.101e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2878, Training Loss: 8.660e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2879, Training Loss: 8.658e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2880, Training Loss: 8.656e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2881, Training Loss: 8.653e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2882, Training Loss: 8.651e-01, Validation Loss: 1.100e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2883, Training Loss: 8.649e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2884, Training Loss: 8.646e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2885, Training Loss: 8.644e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2886, Training Loss: 8.642e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2887, Training Loss: 8.639e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2888, Training Loss: 8.637e-01, Validation Loss: 1.099e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2889, Training Loss: 8.635e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2890, Training Loss: 8.633e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2891, Training Loss: 8.630e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2892, Training Loss: 8.628e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2893, Training Loss: 8.626e-01, Validation Loss: 1.098e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2894, Training Loss: 8.623e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2895, Training Loss: 8.621e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2896, Training Loss: 8.619e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2897, Training Loss: 8.617e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2898, Training Loss: 8.614e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2899, Training Loss: 8.612e-01, Validation Loss: 1.097e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2900, Training Loss: 8.610e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2901, Training Loss: 8.607e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2902, Training Loss: 8.605e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2903, Training Loss: 8.603e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2904, Training Loss: 8.601e-01, Validation Loss: 1.096e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2905, Training Loss: 8.598e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2906, Training Loss: 8.596e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2907, Training Loss: 8.594e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2908, Training Loss: 8.592e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2909, Training Loss: 8.589e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2910, Training Loss: 8.587e-01, Validation Loss: 1.095e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2911, Training Loss: 8.585e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2912, Training Loss: 8.582e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2913, Training Loss: 8.580e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2914, Training Loss: 8.578e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2915, Training Loss: 8.576e-01, Validation Loss: 1.094e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2916, Training Loss: 8.573e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2917, Training Loss: 8.571e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2918, Training Loss: 8.569e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2919, Training Loss: 8.567e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2920, Training Loss: 8.564e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2921, Training Loss: 8.562e-01, Validation Loss: 1.093e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2922, Training Loss: 8.560e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2923, Training Loss: 8.558e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2924, Training Loss: 8.555e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2925, Training Loss: 8.553e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2926, Training Loss: 8.551e-01, Validation Loss: 1.092e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2927, Training Loss: 8.549e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2928, Training Loss: 8.546e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2929, Training Loss: 8.544e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2930, Training Loss: 8.542e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2931, Training Loss: 8.540e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2932, Training Loss: 8.537e-01, Validation Loss: 1.091e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2933, Training Loss: 8.535e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2934, Training Loss: 8.533e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2935, Training Loss: 8.531e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2936, Training Loss: 8.528e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2937, Training Loss: 8.526e-01, Validation Loss: 1.090e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2938, Training Loss: 8.524e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2939, Training Loss: 8.522e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2940, Training Loss: 8.519e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2941, Training Loss: 8.517e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2942, Training Loss: 8.515e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2943, Training Loss: 8.513e-01, Validation Loss: 1.089e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2944, Training Loss: 8.510e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2945, Training Loss: 8.508e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2946, Training Loss: 8.506e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2947, Training Loss: 8.504e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2948, Training Loss: 8.502e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2949, Training Loss: 8.499e-01, Validation Loss: 1.088e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2950, Training Loss: 8.497e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2951, Training Loss: 8.495e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2952, Training Loss: 8.493e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2953, Training Loss: 8.490e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2954, Training Loss: 8.488e-01, Validation Loss: 1.087e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2955, Training Loss: 8.486e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2956, Training Loss: 8.484e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2957, Training Loss: 8.482e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2958, Training Loss: 8.479e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2959, Training Loss: 8.477e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2960, Training Loss: 8.475e-01, Validation Loss: 1.086e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2961, Training Loss: 8.473e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2962, Training Loss: 8.471e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2963, Training Loss: 8.468e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2964, Training Loss: 8.466e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2965, Training Loss: 8.464e-01, Validation Loss: 1.085e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2966, Training Loss: 8.462e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2967, Training Loss: 8.460e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2968, Training Loss: 8.457e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2969, Training Loss: 8.455e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2970, Training Loss: 8.453e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2971, Training Loss: 8.451e-01, Validation Loss: 1.084e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2972, Training Loss: 8.449e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2973, Training Loss: 8.446e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2974, Training Loss: 8.444e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2975, Training Loss: 8.442e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2976, Training Loss: 8.440e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2977, Training Loss: 8.438e-01, Validation Loss: 1.083e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2978, Training Loss: 8.435e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2979, Training Loss: 8.433e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2980, Training Loss: 8.431e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2981, Training Loss: 8.429e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2982, Training Loss: 8.427e-01, Validation Loss: 1.082e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2983, Training Loss: 8.424e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2984, Training Loss: 8.422e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2985, Training Loss: 8.420e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2986, Training Loss: 8.418e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2987, Training Loss: 8.416e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2988, Training Loss: 8.413e-01, Validation Loss: 1.081e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2989, Training Loss: 8.411e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2990, Training Loss: 8.409e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2991, Training Loss: 8.407e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2992, Training Loss: 8.405e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2993, Training Loss: 8.403e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2994, Training Loss: 8.400e-01, Validation Loss: 1.080e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2995, Training Loss: 8.398e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2996, Training Loss: 8.396e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2997, Training Loss: 8.394e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2998, Training Loss: 8.392e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 2999, Training Loss: 8.390e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3000, Training Loss: 8.387e-01, Validation Loss: 1.079e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3001, Training Loss: 8.385e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3002, Training Loss: 8.383e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3003, Training Loss: 8.381e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3004, Training Loss: 8.379e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3005, Training Loss: 8.377e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3006, Training Loss: 8.374e-01, Validation Loss: 1.078e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3007, Training Loss: 8.372e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3008, Training Loss: 8.370e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3009, Training Loss: 8.368e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3010, Training Loss: 8.366e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3011, Training Loss: 8.364e-01, Validation Loss: 1.077e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3012, Training Loss: 8.361e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3013, Training Loss: 8.359e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3014, Training Loss: 8.357e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3015, Training Loss: 8.355e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3016, Training Loss: 8.353e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3017, Training Loss: 8.351e-01, Validation Loss: 1.076e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3018, Training Loss: 8.348e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3019, Training Loss: 8.346e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3020, Training Loss: 8.344e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3021, Training Loss: 8.342e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3022, Training Loss: 8.340e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3023, Training Loss: 8.338e-01, Validation Loss: 1.075e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3024, Training Loss: 8.336e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3025, Training Loss: 8.333e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3026, Training Loss: 8.331e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3027, Training Loss: 8.329e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3028, Training Loss: 8.327e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3029, Training Loss: 8.325e-01, Validation Loss: 1.074e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3030, Training Loss: 8.323e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3031, Training Loss: 8.321e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3032, Training Loss: 8.318e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3033, Training Loss: 8.316e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3034, Training Loss: 8.314e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3035, Training Loss: 8.312e-01, Validation Loss: 1.073e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3036, Training Loss: 8.310e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3037, Training Loss: 8.308e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3038, Training Loss: 8.306e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3039, Training Loss: 8.304e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3040, Training Loss: 8.301e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3041, Training Loss: 8.299e-01, Validation Loss: 1.072e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3042, Training Loss: 8.297e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3043, Training Loss: 8.295e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3044, Training Loss: 8.293e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3045, Training Loss: 8.291e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3046, Training Loss: 8.289e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3047, Training Loss: 8.286e-01, Validation Loss: 1.071e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3048, Training Loss: 8.284e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3049, Training Loss: 8.282e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3050, Training Loss: 8.280e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3051, Training Loss: 8.278e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3052, Training Loss: 8.276e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3053, Training Loss: 8.274e-01, Validation Loss: 1.070e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3054, Training Loss: 8.272e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3055, Training Loss: 8.270e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3056, Training Loss: 8.267e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3057, Training Loss: 8.265e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3058, Training Loss: 8.263e-01, Validation Loss: 1.069e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3059, Training Loss: 8.261e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3060, Training Loss: 8.259e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3061, Training Loss: 8.257e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3062, Training Loss: 8.255e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3063, Training Loss: 8.253e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3064, Training Loss: 8.251e-01, Validation Loss: 1.068e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3065, Training Loss: 8.248e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3066, Training Loss: 8.246e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3067, Training Loss: 8.244e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3068, Training Loss: 8.242e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3069, Training Loss: 8.240e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3070, Training Loss: 8.238e-01, Validation Loss: 1.067e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3071, Training Loss: 8.236e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3072, Training Loss: 8.234e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3073, Training Loss: 8.232e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3074, Training Loss: 8.230e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3075, Training Loss: 8.227e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3076, Training Loss: 8.225e-01, Validation Loss: 1.066e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3077, Training Loss: 8.223e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3078, Training Loss: 8.221e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3079, Training Loss: 8.219e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3080, Training Loss: 8.217e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3081, Training Loss: 8.215e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3082, Training Loss: 8.213e-01, Validation Loss: 1.065e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3083, Training Loss: 8.211e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3084, Training Loss: 8.209e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3085, Training Loss: 8.207e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3086, Training Loss: 8.204e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3087, Training Loss: 8.202e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3088, Training Loss: 8.200e-01, Validation Loss: 1.064e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3089, Training Loss: 8.198e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3090, Training Loss: 8.196e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3091, Training Loss: 8.194e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3092, Training Loss: 8.192e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3093, Training Loss: 8.190e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3094, Training Loss: 8.188e-01, Validation Loss: 1.063e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3095, Training Loss: 8.186e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3096, Training Loss: 8.184e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3097, Training Loss: 8.182e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3098, Training Loss: 8.180e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3099, Training Loss: 8.177e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3100, Training Loss: 8.175e-01, Validation Loss: 1.062e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3101, Training Loss: 8.173e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3102, Training Loss: 8.171e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3103, Training Loss: 8.169e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3104, Training Loss: 8.167e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3105, Training Loss: 8.165e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3106, Training Loss: 8.163e-01, Validation Loss: 1.061e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3107, Training Loss: 8.161e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3108, Training Loss: 8.159e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3109, Training Loss: 8.157e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3110, Training Loss: 8.155e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3111, Training Loss: 8.153e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3112, Training Loss: 8.151e-01, Validation Loss: 1.060e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3113, Training Loss: 8.149e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3114, Training Loss: 8.147e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3115, Training Loss: 8.144e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3116, Training Loss: 8.142e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3117, Training Loss: 8.140e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3118, Training Loss: 8.138e-01, Validation Loss: 1.059e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3119, Training Loss: 8.136e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3120, Training Loss: 8.134e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3121, Training Loss: 8.132e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3122, Training Loss: 8.130e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3123, Training Loss: 8.128e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3124, Training Loss: 8.126e-01, Validation Loss: 1.058e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3125, Training Loss: 8.124e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3126, Training Loss: 8.122e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3127, Training Loss: 8.120e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3128, Training Loss: 8.118e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3129, Training Loss: 8.116e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3130, Training Loss: 8.114e-01, Validation Loss: 1.057e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3131, Training Loss: 8.112e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3132, Training Loss: 8.110e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3133, Training Loss: 8.108e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3134, Training Loss: 8.106e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3135, Training Loss: 8.104e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3136, Training Loss: 8.102e-01, Validation Loss: 1.056e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3137, Training Loss: 8.099e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3138, Training Loss: 8.097e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3139, Training Loss: 8.095e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3140, Training Loss: 8.093e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3141, Training Loss: 8.091e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3142, Training Loss: 8.089e-01, Validation Loss: 1.055e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3143, Training Loss: 8.087e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3144, Training Loss: 8.085e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3145, Training Loss: 8.083e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3146, Training Loss: 8.081e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3147, Training Loss: 8.079e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3148, Training Loss: 8.077e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3149, Training Loss: 8.075e-01, Validation Loss: 1.054e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3150, Training Loss: 8.073e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3151, Training Loss: 8.071e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3152, Training Loss: 8.069e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3153, Training Loss: 8.067e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3154, Training Loss: 8.065e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3155, Training Loss: 8.063e-01, Validation Loss: 1.053e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3156, Training Loss: 8.061e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3157, Training Loss: 8.059e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3158, Training Loss: 8.057e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3159, Training Loss: 8.055e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3160, Training Loss: 8.053e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3161, Training Loss: 8.051e-01, Validation Loss: 1.052e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3162, Training Loss: 8.049e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3163, Training Loss: 8.047e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3164, Training Loss: 8.045e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3165, Training Loss: 8.043e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3166, Training Loss: 8.041e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3167, Training Loss: 8.039e-01, Validation Loss: 1.051e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3168, Training Loss: 8.037e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3169, Training Loss: 8.035e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3170, Training Loss: 8.033e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3171, Training Loss: 8.031e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3172, Training Loss: 8.029e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3173, Training Loss: 8.027e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3174, Training Loss: 8.025e-01, Validation Loss: 1.050e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3175, Training Loss: 8.023e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3176, Training Loss: 8.021e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3177, Training Loss: 8.019e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3178, Training Loss: 8.017e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3179, Training Loss: 8.015e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3180, Training Loss: 8.013e-01, Validation Loss: 1.049e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3181, Training Loss: 8.011e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3182, Training Loss: 8.009e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3183, Training Loss: 8.007e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3184, Training Loss: 8.005e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3185, Training Loss: 8.003e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3186, Training Loss: 8.001e-01, Validation Loss: 1.048e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3187, Training Loss: 7.999e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3188, Training Loss: 7.997e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3189, Training Loss: 7.995e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3190, Training Loss: 7.993e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3191, Training Loss: 7.991e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3192, Training Loss: 7.989e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3193, Training Loss: 7.987e-01, Validation Loss: 1.047e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3194, Training Loss: 7.985e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3195, Training Loss: 7.983e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3196, Training Loss: 7.981e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3197, Training Loss: 7.979e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3198, Training Loss: 7.977e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3199, Training Loss: 7.975e-01, Validation Loss: 1.046e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3200, Training Loss: 7.973e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3201, Training Loss: 7.971e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3202, Training Loss: 7.969e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3203, Training Loss: 7.967e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3204, Training Loss: 7.965e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3205, Training Loss: 7.963e-01, Validation Loss: 1.045e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3206, Training Loss: 7.961e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3207, Training Loss: 7.959e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3208, Training Loss: 7.958e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3209, Training Loss: 7.956e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3210, Training Loss: 7.954e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3211, Training Loss: 7.952e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3212, Training Loss: 7.950e-01, Validation Loss: 1.044e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3213, Training Loss: 7.948e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3214, Training Loss: 7.946e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3215, Training Loss: 7.944e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3216, Training Loss: 7.942e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3217, Training Loss: 7.940e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3218, Training Loss: 7.938e-01, Validation Loss: 1.043e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3219, Training Loss: 7.936e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3220, Training Loss: 7.934e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3221, Training Loss: 7.932e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3222, Training Loss: 7.930e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3223, Training Loss: 7.928e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3224, Training Loss: 7.926e-01, Validation Loss: 1.042e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3225, Training Loss: 7.924e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3226, Training Loss: 7.922e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3227, Training Loss: 7.920e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3228, Training Loss: 7.918e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3229, Training Loss: 7.916e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3230, Training Loss: 7.914e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3231, Training Loss: 7.913e-01, Validation Loss: 1.041e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3232, Training Loss: 7.911e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3233, Training Loss: 7.909e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3234, Training Loss: 7.907e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3235, Training Loss: 7.905e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3236, Training Loss: 7.903e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3237, Training Loss: 7.901e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3238, Training Loss: 7.899e-01, Validation Loss: 1.040e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3239, Training Loss: 7.897e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3240, Training Loss: 7.895e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3241, Training Loss: 7.893e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3242, Training Loss: 7.891e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3243, Training Loss: 7.889e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3244, Training Loss: 7.887e-01, Validation Loss: 1.039e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3245, Training Loss: 7.885e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3246, Training Loss: 7.883e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3247, Training Loss: 7.882e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3248, Training Loss: 7.880e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3249, Training Loss: 7.878e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3250, Training Loss: 7.876e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3251, Training Loss: 7.874e-01, Validation Loss: 1.038e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3252, Training Loss: 7.872e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3253, Training Loss: 7.870e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3254, Training Loss: 7.868e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3255, Training Loss: 7.866e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3256, Training Loss: 7.864e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3257, Training Loss: 7.862e-01, Validation Loss: 1.037e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3258, Training Loss: 7.860e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3259, Training Loss: 7.858e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3260, Training Loss: 7.857e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3261, Training Loss: 7.855e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3262, Training Loss: 7.853e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3263, Training Loss: 7.851e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3264, Training Loss: 7.849e-01, Validation Loss: 1.036e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3265, Training Loss: 7.847e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3266, Training Loss: 7.845e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3267, Training Loss: 7.843e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3268, Training Loss: 7.841e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3269, Training Loss: 7.839e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3270, Training Loss: 7.837e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3271, Training Loss: 7.835e-01, Validation Loss: 1.035e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3272, Training Loss: 7.834e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3273, Training Loss: 7.832e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3274, Training Loss: 7.830e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3275, Training Loss: 7.828e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3276, Training Loss: 7.826e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3277, Training Loss: 7.824e-01, Validation Loss: 1.034e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3278, Training Loss: 7.822e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3279, Training Loss: 7.820e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3280, Training Loss: 7.818e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3281, Training Loss: 7.816e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3282, Training Loss: 7.815e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3283, Training Loss: 7.813e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3284, Training Loss: 7.811e-01, Validation Loss: 1.033e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3285, Training Loss: 7.809e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3286, Training Loss: 7.807e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3287, Training Loss: 7.805e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3288, Training Loss: 7.803e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3289, Training Loss: 7.801e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3290, Training Loss: 7.799e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3291, Training Loss: 7.797e-01, Validation Loss: 1.032e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3292, Training Loss: 7.796e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3293, Training Loss: 7.794e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3294, Training Loss: 7.792e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3295, Training Loss: 7.790e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3296, Training Loss: 7.788e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3297, Training Loss: 7.786e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3298, Training Loss: 7.784e-01, Validation Loss: 1.031e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3299, Training Loss: 7.782e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3300, Training Loss: 7.780e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3301, Training Loss: 7.779e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3302, Training Loss: 7.777e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3303, Training Loss: 7.775e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3304, Training Loss: 7.773e-01, Validation Loss: 1.030e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3305, Training Loss: 7.771e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3306, Training Loss: 7.769e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3307, Training Loss: 7.767e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3308, Training Loss: 7.765e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3309, Training Loss: 7.764e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3310, Training Loss: 7.762e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3311, Training Loss: 7.760e-01, Validation Loss: 1.029e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3312, Training Loss: 7.758e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3313, Training Loss: 7.756e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3314, Training Loss: 7.754e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3315, Training Loss: 7.752e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3316, Training Loss: 7.750e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3317, Training Loss: 7.749e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3318, Training Loss: 7.747e-01, Validation Loss: 1.028e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3319, Training Loss: 7.745e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3320, Training Loss: 7.743e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3321, Training Loss: 7.741e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3322, Training Loss: 7.739e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3323, Training Loss: 7.737e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3324, Training Loss: 7.736e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3325, Training Loss: 7.734e-01, Validation Loss: 1.027e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3326, Training Loss: 7.732e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3327, Training Loss: 7.730e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3328, Training Loss: 7.728e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3329, Training Loss: 7.726e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3330, Training Loss: 7.724e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3331, Training Loss: 7.723e-01, Validation Loss: 1.026e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3332, Training Loss: 7.721e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3333, Training Loss: 7.719e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3334, Training Loss: 7.717e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3335, Training Loss: 7.715e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3336, Training Loss: 7.713e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3337, Training Loss: 7.711e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3338, Training Loss: 7.710e-01, Validation Loss: 1.025e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3339, Training Loss: 7.708e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3340, Training Loss: 7.706e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3341, Training Loss: 7.704e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3342, Training Loss: 7.702e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3343, Training Loss: 7.700e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3344, Training Loss: 7.698e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3345, Training Loss: 7.697e-01, Validation Loss: 1.024e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3346, Training Loss: 7.695e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3347, Training Loss: 7.693e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3348, Training Loss: 7.691e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3349, Training Loss: 7.689e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3350, Training Loss: 7.687e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3351, Training Loss: 7.686e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3352, Training Loss: 7.684e-01, Validation Loss: 1.023e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3353, Training Loss: 7.682e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3354, Training Loss: 7.680e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3355, Training Loss: 7.678e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3356, Training Loss: 7.676e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3357, Training Loss: 7.675e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3358, Training Loss: 7.673e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3359, Training Loss: 7.671e-01, Validation Loss: 1.022e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3360, Training Loss: 7.669e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3361, Training Loss: 7.667e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3362, Training Loss: 7.665e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3363, Training Loss: 7.664e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3364, Training Loss: 7.662e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3365, Training Loss: 7.660e-01, Validation Loss: 1.021e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3366, Training Loss: 7.658e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3367, Training Loss: 7.656e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3368, Training Loss: 7.654e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3369, Training Loss: 7.653e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3370, Training Loss: 7.651e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3371, Training Loss: 7.649e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3372, Training Loss: 7.647e-01, Validation Loss: 1.020e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3373, Training Loss: 7.645e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3374, Training Loss: 7.643e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3375, Training Loss: 7.642e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3376, Training Loss: 7.640e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3377, Training Loss: 7.638e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3378, Training Loss: 7.636e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3379, Training Loss: 7.634e-01, Validation Loss: 1.019e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3380, Training Loss: 7.633e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3381, Training Loss: 7.631e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3382, Training Loss: 7.629e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3383, Training Loss: 7.627e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3384, Training Loss: 7.625e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3385, Training Loss: 7.623e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3386, Training Loss: 7.622e-01, Validation Loss: 1.018e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3387, Training Loss: 7.620e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3388, Training Loss: 7.618e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3389, Training Loss: 7.616e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3390, Training Loss: 7.614e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3391, Training Loss: 7.613e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3392, Training Loss: 7.611e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3393, Training Loss: 7.609e-01, Validation Loss: 1.017e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3394, Training Loss: 7.607e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3395, Training Loss: 7.605e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3396, Training Loss: 7.604e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3397, Training Loss: 7.602e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3398, Training Loss: 7.600e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3399, Training Loss: 7.598e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3400, Training Loss: 7.596e-01, Validation Loss: 1.016e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3401, Training Loss: 7.595e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3402, Training Loss: 7.593e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3403, Training Loss: 7.591e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3404, Training Loss: 7.589e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3405, Training Loss: 7.587e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3406, Training Loss: 7.586e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3407, Training Loss: 7.584e-01, Validation Loss: 1.015e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3408, Training Loss: 7.582e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3409, Training Loss: 7.580e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3410, Training Loss: 7.578e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3411, Training Loss: 7.577e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3412, Training Loss: 7.575e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3413, Training Loss: 7.573e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3414, Training Loss: 7.571e-01, Validation Loss: 1.014e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3415, Training Loss: 7.569e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3416, Training Loss: 7.568e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3417, Training Loss: 7.566e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3418, Training Loss: 7.564e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3419, Training Loss: 7.562e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3420, Training Loss: 7.561e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3421, Training Loss: 7.559e-01, Validation Loss: 1.013e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3422, Training Loss: 7.557e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3423, Training Loss: 7.555e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3424, Training Loss: 7.553e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3425, Training Loss: 7.552e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3426, Training Loss: 7.550e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3427, Training Loss: 7.548e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3428, Training Loss: 7.546e-01, Validation Loss: 1.012e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3429, Training Loss: 7.544e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3430, Training Loss: 7.543e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3431, Training Loss: 7.541e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3432, Training Loss: 7.539e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3433, Training Loss: 7.537e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3434, Training Loss: 7.536e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3435, Training Loss: 7.534e-01, Validation Loss: 1.011e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3436, Training Loss: 7.532e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3437, Training Loss: 7.530e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3438, Training Loss: 7.528e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3439, Training Loss: 7.527e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3440, Training Loss: 7.525e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3441, Training Loss: 7.523e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3442, Training Loss: 7.521e-01, Validation Loss: 1.010e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3443, Training Loss: 7.520e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3444, Training Loss: 7.518e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3445, Training Loss: 7.516e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3446, Training Loss: 7.514e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3447, Training Loss: 7.513e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3448, Training Loss: 7.511e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3449, Training Loss: 7.509e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3450, Training Loss: 7.507e-01, Validation Loss: 1.009e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3451, Training Loss: 7.506e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3452, Training Loss: 7.504e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3453, Training Loss: 7.502e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3454, Training Loss: 7.500e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3455, Training Loss: 7.498e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3456, Training Loss: 7.497e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3457, Training Loss: 7.495e-01, Validation Loss: 1.008e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3458, Training Loss: 7.493e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3459, Training Loss: 7.491e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3460, Training Loss: 7.490e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3461, Training Loss: 7.488e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3462, Training Loss: 7.486e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3463, Training Loss: 7.484e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3464, Training Loss: 7.483e-01, Validation Loss: 1.007e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3465, Training Loss: 7.481e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3466, Training Loss: 7.479e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3467, Training Loss: 7.477e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3468, Training Loss: 7.476e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3469, Training Loss: 7.474e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3470, Training Loss: 7.472e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3471, Training Loss: 7.470e-01, Validation Loss: 1.006e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3472, Training Loss: 7.469e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3473, Training Loss: 7.467e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3474, Training Loss: 7.465e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3475, Training Loss: 7.463e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3476, Training Loss: 7.462e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3477, Training Loss: 7.460e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3478, Training Loss: 7.458e-01, Validation Loss: 1.005e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3479, Training Loss: 7.456e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3480, Training Loss: 7.455e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3481, Training Loss: 7.453e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3482, Training Loss: 7.451e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3483, Training Loss: 7.450e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3484, Training Loss: 7.448e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3485, Training Loss: 7.446e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3486, Training Loss: 7.444e-01, Validation Loss: 1.004e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3487, Training Loss: 7.443e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3488, Training Loss: 7.441e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3489, Training Loss: 7.439e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3490, Training Loss: 7.437e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3491, Training Loss: 7.436e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3492, Training Loss: 7.434e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3493, Training Loss: 7.432e-01, Validation Loss: 1.003e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3494, Training Loss: 7.430e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3495, Training Loss: 7.429e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3496, Training Loss: 7.427e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3497, Training Loss: 7.425e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3498, Training Loss: 7.423e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3499, Training Loss: 7.422e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3500, Training Loss: 7.420e-01, Validation Loss: 1.002e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3501, Training Loss: 7.418e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3502, Training Loss: 7.417e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3503, Training Loss: 7.415e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3504, Training Loss: 7.413e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3505, Training Loss: 7.411e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3506, Training Loss: 7.410e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3507, Training Loss: 7.408e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3508, Training Loss: 7.406e-01, Validation Loss: 1.001e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3509, Training Loss: 7.405e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3510, Training Loss: 7.403e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3511, Training Loss: 7.401e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3512, Training Loss: 7.399e-01, Validation Loss: 1.000e+00, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3513, Training Loss: 7.398e-01, Validation Loss: 9.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3514, Training Loss: 7.396e-01, Validation Loss: 9.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3515, Training Loss: 7.394e-01, Validation Loss: 9.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3516, Training Loss: 7.393e-01, Validation Loss: 9.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3517, Training Loss: 7.391e-01, Validation Loss: 9.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3518, Training Loss: 7.389e-01, Validation Loss: 9.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3519, Training Loss: 7.387e-01, Validation Loss: 9.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3520, Training Loss: 7.386e-01, Validation Loss: 9.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3521, Training Loss: 7.384e-01, Validation Loss: 9.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3522, Training Loss: 7.382e-01, Validation Loss: 9.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3523, Training Loss: 7.381e-01, Validation Loss: 9.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3524, Training Loss: 7.379e-01, Validation Loss: 9.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3525, Training Loss: 7.377e-01, Validation Loss: 9.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3526, Training Loss: 7.375e-01, Validation Loss: 9.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3527, Training Loss: 7.374e-01, Validation Loss: 9.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3528, Training Loss: 7.372e-01, Validation Loss: 9.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3529, Training Loss: 7.370e-01, Validation Loss: 9.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3530, Training Loss: 7.369e-01, Validation Loss: 9.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3531, Training Loss: 7.367e-01, Validation Loss: 9.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3532, Training Loss: 7.365e-01, Validation Loss: 9.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3533, Training Loss: 7.363e-01, Validation Loss: 9.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3534, Training Loss: 7.362e-01, Validation Loss: 9.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3535, Training Loss: 7.360e-01, Validation Loss: 9.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3536, Training Loss: 7.358e-01, Validation Loss: 9.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3537, Training Loss: 7.357e-01, Validation Loss: 9.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3538, Training Loss: 7.355e-01, Validation Loss: 9.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3539, Training Loss: 7.353e-01, Validation Loss: 9.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3540, Training Loss: 7.352e-01, Validation Loss: 9.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3541, Training Loss: 7.350e-01, Validation Loss: 9.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3542, Training Loss: 7.348e-01, Validation Loss: 9.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3543, Training Loss: 7.346e-01, Validation Loss: 9.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3544, Training Loss: 7.345e-01, Validation Loss: 9.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3545, Training Loss: 7.343e-01, Validation Loss: 9.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3546, Training Loss: 7.341e-01, Validation Loss: 9.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3547, Training Loss: 7.340e-01, Validation Loss: 9.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3548, Training Loss: 7.338e-01, Validation Loss: 9.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3549, Training Loss: 7.336e-01, Validation Loss: 9.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3550, Training Loss: 7.335e-01, Validation Loss: 9.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3551, Training Loss: 7.333e-01, Validation Loss: 9.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3552, Training Loss: 7.331e-01, Validation Loss: 9.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3553, Training Loss: 7.330e-01, Validation Loss: 9.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3554, Training Loss: 7.328e-01, Validation Loss: 9.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3555, Training Loss: 7.326e-01, Validation Loss: 9.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3556, Training Loss: 7.324e-01, Validation Loss: 9.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3557, Training Loss: 7.323e-01, Validation Loss: 9.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3558, Training Loss: 7.321e-01, Validation Loss: 9.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3559, Training Loss: 7.319e-01, Validation Loss: 9.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3560, Training Loss: 7.318e-01, Validation Loss: 9.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3561, Training Loss: 7.316e-01, Validation Loss: 9.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3562, Training Loss: 7.314e-01, Validation Loss: 9.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3563, Training Loss: 7.313e-01, Validation Loss: 9.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3564, Training Loss: 7.311e-01, Validation Loss: 9.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3565, Training Loss: 7.309e-01, Validation Loss: 9.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3566, Training Loss: 7.308e-01, Validation Loss: 9.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3567, Training Loss: 7.306e-01, Validation Loss: 9.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3568, Training Loss: 7.304e-01, Validation Loss: 9.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3569, Training Loss: 7.303e-01, Validation Loss: 9.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3570, Training Loss: 7.301e-01, Validation Loss: 9.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3571, Training Loss: 7.299e-01, Validation Loss: 9.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3572, Training Loss: 7.298e-01, Validation Loss: 9.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3573, Training Loss: 7.296e-01, Validation Loss: 9.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3574, Training Loss: 7.294e-01, Validation Loss: 9.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3575, Training Loss: 7.293e-01, Validation Loss: 9.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3576, Training Loss: 7.291e-01, Validation Loss: 9.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3577, Training Loss: 7.289e-01, Validation Loss: 9.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3578, Training Loss: 7.288e-01, Validation Loss: 9.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3579, Training Loss: 7.286e-01, Validation Loss: 9.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3580, Training Loss: 7.284e-01, Validation Loss: 9.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3581, Training Loss: 7.283e-01, Validation Loss: 9.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3582, Training Loss: 7.281e-01, Validation Loss: 9.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3583, Training Loss: 7.279e-01, Validation Loss: 9.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3584, Training Loss: 7.278e-01, Validation Loss: 9.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3585, Training Loss: 7.276e-01, Validation Loss: 9.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3586, Training Loss: 7.274e-01, Validation Loss: 9.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3587, Training Loss: 7.273e-01, Validation Loss: 9.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3588, Training Loss: 7.271e-01, Validation Loss: 9.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3589, Training Loss: 7.269e-01, Validation Loss: 9.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3590, Training Loss: 7.268e-01, Validation Loss: 9.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3591, Training Loss: 7.266e-01, Validation Loss: 9.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3592, Training Loss: 7.264e-01, Validation Loss: 9.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3593, Training Loss: 7.263e-01, Validation Loss: 9.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3594, Training Loss: 7.261e-01, Validation Loss: 9.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3595, Training Loss: 7.259e-01, Validation Loss: 9.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3596, Training Loss: 7.258e-01, Validation Loss: 9.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3597, Training Loss: 7.256e-01, Validation Loss: 9.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3598, Training Loss: 7.254e-01, Validation Loss: 9.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3599, Training Loss: 7.253e-01, Validation Loss: 9.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3600, Training Loss: 7.251e-01, Validation Loss: 9.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3601, Training Loss: 7.249e-01, Validation Loss: 9.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3602, Training Loss: 7.248e-01, Validation Loss: 9.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3603, Training Loss: 7.246e-01, Validation Loss: 9.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3604, Training Loss: 7.244e-01, Validation Loss: 9.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3605, Training Loss: 7.243e-01, Validation Loss: 9.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3606, Training Loss: 7.241e-01, Validation Loss: 9.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3607, Training Loss: 7.239e-01, Validation Loss: 9.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3608, Training Loss: 7.238e-01, Validation Loss: 9.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3609, Training Loss: 7.236e-01, Validation Loss: 9.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3610, Training Loss: 7.234e-01, Validation Loss: 9.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3611, Training Loss: 7.233e-01, Validation Loss: 9.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3612, Training Loss: 7.231e-01, Validation Loss: 9.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3613, Training Loss: 7.230e-01, Validation Loss: 9.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3614, Training Loss: 7.228e-01, Validation Loss: 9.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3615, Training Loss: 7.226e-01, Validation Loss: 9.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3616, Training Loss: 7.225e-01, Validation Loss: 9.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3617, Training Loss: 7.223e-01, Validation Loss: 9.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3618, Training Loss: 7.221e-01, Validation Loss: 9.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3619, Training Loss: 7.220e-01, Validation Loss: 9.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3620, Training Loss: 7.218e-01, Validation Loss: 9.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3621, Training Loss: 7.216e-01, Validation Loss: 9.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3622, Training Loss: 7.215e-01, Validation Loss: 9.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3623, Training Loss: 7.213e-01, Validation Loss: 9.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3624, Training Loss: 7.211e-01, Validation Loss: 9.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3625, Training Loss: 7.210e-01, Validation Loss: 9.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3626, Training Loss: 7.208e-01, Validation Loss: 9.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3627, Training Loss: 7.207e-01, Validation Loss: 9.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3628, Training Loss: 7.205e-01, Validation Loss: 9.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3629, Training Loss: 7.203e-01, Validation Loss: 9.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3630, Training Loss: 7.202e-01, Validation Loss: 9.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3631, Training Loss: 7.200e-01, Validation Loss: 9.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3632, Training Loss: 7.198e-01, Validation Loss: 9.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3633, Training Loss: 7.197e-01, Validation Loss: 9.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3634, Training Loss: 7.195e-01, Validation Loss: 9.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3635, Training Loss: 7.193e-01, Validation Loss: 9.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3636, Training Loss: 7.192e-01, Validation Loss: 9.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3637, Training Loss: 7.190e-01, Validation Loss: 9.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3638, Training Loss: 7.189e-01, Validation Loss: 9.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3639, Training Loss: 7.187e-01, Validation Loss: 9.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3640, Training Loss: 7.185e-01, Validation Loss: 9.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3641, Training Loss: 7.184e-01, Validation Loss: 9.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3642, Training Loss: 7.182e-01, Validation Loss: 9.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3643, Training Loss: 7.180e-01, Validation Loss: 9.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3644, Training Loss: 7.179e-01, Validation Loss: 9.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3645, Training Loss: 7.177e-01, Validation Loss: 9.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3646, Training Loss: 7.176e-01, Validation Loss: 9.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3647, Training Loss: 7.174e-01, Validation Loss: 9.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3648, Training Loss: 7.172e-01, Validation Loss: 9.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3649, Training Loss: 7.171e-01, Validation Loss: 9.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3650, Training Loss: 7.169e-01, Validation Loss: 9.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3651, Training Loss: 7.168e-01, Validation Loss: 9.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3652, Training Loss: 7.166e-01, Validation Loss: 9.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3653, Training Loss: 7.164e-01, Validation Loss: 9.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3654, Training Loss: 7.163e-01, Validation Loss: 9.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3655, Training Loss: 7.161e-01, Validation Loss: 9.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3656, Training Loss: 7.159e-01, Validation Loss: 9.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3657, Training Loss: 7.158e-01, Validation Loss: 9.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3658, Training Loss: 7.156e-01, Validation Loss: 9.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3659, Training Loss: 7.155e-01, Validation Loss: 9.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3660, Training Loss: 7.153e-01, Validation Loss: 9.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3661, Training Loss: 7.151e-01, Validation Loss: 9.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3662, Training Loss: 7.150e-01, Validation Loss: 9.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3663, Training Loss: 7.148e-01, Validation Loss: 9.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3664, Training Loss: 7.147e-01, Validation Loss: 9.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3665, Training Loss: 7.145e-01, Validation Loss: 9.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3666, Training Loss: 7.143e-01, Validation Loss: 9.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3667, Training Loss: 7.142e-01, Validation Loss: 9.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3668, Training Loss: 7.140e-01, Validation Loss: 9.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3669, Training Loss: 7.138e-01, Validation Loss: 9.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3670, Training Loss: 7.137e-01, Validation Loss: 9.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3671, Training Loss: 7.135e-01, Validation Loss: 9.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3672, Training Loss: 7.134e-01, Validation Loss: 9.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3673, Training Loss: 7.132e-01, Validation Loss: 9.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3674, Training Loss: 7.130e-01, Validation Loss: 9.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3675, Training Loss: 7.129e-01, Validation Loss: 9.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3676, Training Loss: 7.127e-01, Validation Loss: 9.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3677, Training Loss: 7.126e-01, Validation Loss: 9.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3678, Training Loss: 7.124e-01, Validation Loss: 9.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3679, Training Loss: 7.122e-01, Validation Loss: 9.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3680, Training Loss: 7.121e-01, Validation Loss: 9.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3681, Training Loss: 7.119e-01, Validation Loss: 9.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3682, Training Loss: 7.118e-01, Validation Loss: 9.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3683, Training Loss: 7.116e-01, Validation Loss: 9.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3684, Training Loss: 7.114e-01, Validation Loss: 9.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3685, Training Loss: 7.113e-01, Validation Loss: 9.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3686, Training Loss: 7.111e-01, Validation Loss: 9.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3687, Training Loss: 7.110e-01, Validation Loss: 9.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3688, Training Loss: 7.108e-01, Validation Loss: 9.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3689, Training Loss: 7.107e-01, Validation Loss: 9.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3690, Training Loss: 7.105e-01, Validation Loss: 9.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3691, Training Loss: 7.103e-01, Validation Loss: 9.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3692, Training Loss: 7.102e-01, Validation Loss: 9.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3693, Training Loss: 7.100e-01, Validation Loss: 9.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3694, Training Loss: 7.099e-01, Validation Loss: 9.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3695, Training Loss: 7.097e-01, Validation Loss: 9.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3696, Training Loss: 7.095e-01, Validation Loss: 9.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3697, Training Loss: 7.094e-01, Validation Loss: 9.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3698, Training Loss: 7.092e-01, Validation Loss: 9.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3699, Training Loss: 7.091e-01, Validation Loss: 9.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3700, Training Loss: 7.089e-01, Validation Loss: 9.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3701, Training Loss: 7.087e-01, Validation Loss: 9.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3702, Training Loss: 7.086e-01, Validation Loss: 9.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3703, Training Loss: 7.084e-01, Validation Loss: 9.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3704, Training Loss: 7.083e-01, Validation Loss: 9.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3705, Training Loss: 7.081e-01, Validation Loss: 9.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3706, Training Loss: 7.080e-01, Validation Loss: 9.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3707, Training Loss: 7.078e-01, Validation Loss: 9.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3708, Training Loss: 7.076e-01, Validation Loss: 9.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3709, Training Loss: 7.075e-01, Validation Loss: 9.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3710, Training Loss: 7.073e-01, Validation Loss: 9.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3711, Training Loss: 7.072e-01, Validation Loss: 9.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3712, Training Loss: 7.070e-01, Validation Loss: 9.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3713, Training Loss: 7.069e-01, Validation Loss: 9.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3714, Training Loss: 7.067e-01, Validation Loss: 9.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3715, Training Loss: 7.065e-01, Validation Loss: 9.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3716, Training Loss: 7.064e-01, Validation Loss: 9.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3717, Training Loss: 7.062e-01, Validation Loss: 9.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3718, Training Loss: 7.061e-01, Validation Loss: 9.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3719, Training Loss: 7.059e-01, Validation Loss: 9.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3720, Training Loss: 7.057e-01, Validation Loss: 9.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3721, Training Loss: 7.056e-01, Validation Loss: 9.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3722, Training Loss: 7.054e-01, Validation Loss: 9.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3723, Training Loss: 7.053e-01, Validation Loss: 9.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3724, Training Loss: 7.051e-01, Validation Loss: 9.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3725, Training Loss: 7.050e-01, Validation Loss: 9.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3726, Training Loss: 7.048e-01, Validation Loss: 9.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3727, Training Loss: 7.047e-01, Validation Loss: 9.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3728, Training Loss: 7.045e-01, Validation Loss: 9.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3729, Training Loss: 7.043e-01, Validation Loss: 9.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3730, Training Loss: 7.042e-01, Validation Loss: 9.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3731, Training Loss: 7.040e-01, Validation Loss: 9.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3732, Training Loss: 7.039e-01, Validation Loss: 9.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3733, Training Loss: 7.037e-01, Validation Loss: 9.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3734, Training Loss: 7.036e-01, Validation Loss: 9.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3735, Training Loss: 7.034e-01, Validation Loss: 9.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3736, Training Loss: 7.032e-01, Validation Loss: 9.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3737, Training Loss: 7.031e-01, Validation Loss: 9.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3738, Training Loss: 7.029e-01, Validation Loss: 9.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3739, Training Loss: 7.028e-01, Validation Loss: 9.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3740, Training Loss: 7.026e-01, Validation Loss: 9.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3741, Training Loss: 7.025e-01, Validation Loss: 9.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3742, Training Loss: 7.023e-01, Validation Loss: 9.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3743, Training Loss: 7.022e-01, Validation Loss: 9.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3744, Training Loss: 7.020e-01, Validation Loss: 9.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3745, Training Loss: 7.018e-01, Validation Loss: 9.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3746, Training Loss: 7.017e-01, Validation Loss: 9.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3747, Training Loss: 7.015e-01, Validation Loss: 9.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3748, Training Loss: 7.014e-01, Validation Loss: 9.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3749, Training Loss: 7.012e-01, Validation Loss: 9.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3750, Training Loss: 7.011e-01, Validation Loss: 9.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3751, Training Loss: 7.009e-01, Validation Loss: 9.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3752, Training Loss: 7.008e-01, Validation Loss: 9.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3753, Training Loss: 7.006e-01, Validation Loss: 9.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3754, Training Loss: 7.004e-01, Validation Loss: 9.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3755, Training Loss: 7.003e-01, Validation Loss: 9.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3756, Training Loss: 7.001e-01, Validation Loss: 9.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3757, Training Loss: 7.000e-01, Validation Loss: 9.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3758, Training Loss: 6.998e-01, Validation Loss: 9.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3759, Training Loss: 6.997e-01, Validation Loss: 9.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3760, Training Loss: 6.995e-01, Validation Loss: 9.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3761, Training Loss: 6.994e-01, Validation Loss: 9.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3762, Training Loss: 6.992e-01, Validation Loss: 9.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3763, Training Loss: 6.991e-01, Validation Loss: 9.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3764, Training Loss: 6.989e-01, Validation Loss: 9.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3765, Training Loss: 6.987e-01, Validation Loss: 9.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3766, Training Loss: 6.986e-01, Validation Loss: 9.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3767, Training Loss: 6.984e-01, Validation Loss: 9.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3768, Training Loss: 6.983e-01, Validation Loss: 9.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3769, Training Loss: 6.981e-01, Validation Loss: 9.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3770, Training Loss: 6.980e-01, Validation Loss: 9.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3771, Training Loss: 6.978e-01, Validation Loss: 9.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3772, Training Loss: 6.977e-01, Validation Loss: 9.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3773, Training Loss: 6.975e-01, Validation Loss: 9.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3774, Training Loss: 6.974e-01, Validation Loss: 9.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3775, Training Loss: 6.972e-01, Validation Loss: 9.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3776, Training Loss: 6.971e-01, Validation Loss: 9.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3777, Training Loss: 6.969e-01, Validation Loss: 9.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3778, Training Loss: 6.967e-01, Validation Loss: 9.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3779, Training Loss: 6.966e-01, Validation Loss: 9.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3780, Training Loss: 6.964e-01, Validation Loss: 9.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3781, Training Loss: 6.963e-01, Validation Loss: 9.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3782, Training Loss: 6.961e-01, Validation Loss: 9.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3783, Training Loss: 6.960e-01, Validation Loss: 9.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3784, Training Loss: 6.958e-01, Validation Loss: 9.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3785, Training Loss: 6.957e-01, Validation Loss: 9.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3786, Training Loss: 6.955e-01, Validation Loss: 9.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3787, Training Loss: 6.954e-01, Validation Loss: 9.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3788, Training Loss: 6.952e-01, Validation Loss: 9.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3789, Training Loss: 6.951e-01, Validation Loss: 9.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3790, Training Loss: 6.949e-01, Validation Loss: 9.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3791, Training Loss: 6.948e-01, Validation Loss: 9.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3792, Training Loss: 6.946e-01, Validation Loss: 9.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3793, Training Loss: 6.945e-01, Validation Loss: 9.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3794, Training Loss: 6.943e-01, Validation Loss: 9.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3795, Training Loss: 6.941e-01, Validation Loss: 9.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3796, Training Loss: 6.940e-01, Validation Loss: 9.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3797, Training Loss: 6.938e-01, Validation Loss: 9.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3798, Training Loss: 6.937e-01, Validation Loss: 9.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3799, Training Loss: 6.935e-01, Validation Loss: 9.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3800, Training Loss: 6.934e-01, Validation Loss: 9.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3801, Training Loss: 6.932e-01, Validation Loss: 9.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3802, Training Loss: 6.931e-01, Validation Loss: 9.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3803, Training Loss: 6.929e-01, Validation Loss: 9.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3804, Training Loss: 6.928e-01, Validation Loss: 9.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3805, Training Loss: 6.926e-01, Validation Loss: 9.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3806, Training Loss: 6.925e-01, Validation Loss: 9.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3807, Training Loss: 6.923e-01, Validation Loss: 9.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3808, Training Loss: 6.922e-01, Validation Loss: 9.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3809, Training Loss: 6.920e-01, Validation Loss: 9.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3810, Training Loss: 6.919e-01, Validation Loss: 9.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3811, Training Loss: 6.917e-01, Validation Loss: 9.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3812, Training Loss: 6.916e-01, Validation Loss: 9.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3813, Training Loss: 6.914e-01, Validation Loss: 9.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3814, Training Loss: 6.913e-01, Validation Loss: 9.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3815, Training Loss: 6.911e-01, Validation Loss: 9.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3816, Training Loss: 6.910e-01, Validation Loss: 9.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3817, Training Loss: 6.908e-01, Validation Loss: 9.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3818, Training Loss: 6.907e-01, Validation Loss: 9.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3819, Training Loss: 6.905e-01, Validation Loss: 9.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3820, Training Loss: 6.904e-01, Validation Loss: 9.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3821, Training Loss: 6.902e-01, Validation Loss: 9.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3822, Training Loss: 6.901e-01, Validation Loss: 9.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3823, Training Loss: 6.899e-01, Validation Loss: 9.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3824, Training Loss: 6.898e-01, Validation Loss: 9.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3825, Training Loss: 6.896e-01, Validation Loss: 9.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3826, Training Loss: 6.895e-01, Validation Loss: 9.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3827, Training Loss: 6.893e-01, Validation Loss: 9.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3828, Training Loss: 6.892e-01, Validation Loss: 9.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3829, Training Loss: 6.890e-01, Validation Loss: 9.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3830, Training Loss: 6.889e-01, Validation Loss: 9.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3831, Training Loss: 6.887e-01, Validation Loss: 9.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3832, Training Loss: 6.886e-01, Validation Loss: 9.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3833, Training Loss: 6.884e-01, Validation Loss: 9.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3834, Training Loss: 6.883e-01, Validation Loss: 9.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3835, Training Loss: 6.881e-01, Validation Loss: 9.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3836, Training Loss: 6.880e-01, Validation Loss: 9.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3837, Training Loss: 6.878e-01, Validation Loss: 9.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3838, Training Loss: 6.877e-01, Validation Loss: 9.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3839, Training Loss: 6.875e-01, Validation Loss: 9.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3840, Training Loss: 6.874e-01, Validation Loss: 9.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3841, Training Loss: 6.872e-01, Validation Loss: 9.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3842, Training Loss: 6.871e-01, Validation Loss: 9.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3843, Training Loss: 6.869e-01, Validation Loss: 9.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3844, Training Loss: 6.868e-01, Validation Loss: 9.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3845, Training Loss: 6.866e-01, Validation Loss: 9.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3846, Training Loss: 6.865e-01, Validation Loss: 9.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3847, Training Loss: 6.863e-01, Validation Loss: 9.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3848, Training Loss: 6.862e-01, Validation Loss: 9.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3849, Training Loss: 6.860e-01, Validation Loss: 9.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3850, Training Loss: 6.859e-01, Validation Loss: 9.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3851, Training Loss: 6.857e-01, Validation Loss: 9.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3852, Training Loss: 6.856e-01, Validation Loss: 9.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3853, Training Loss: 6.854e-01, Validation Loss: 9.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3854, Training Loss: 6.853e-01, Validation Loss: 9.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3855, Training Loss: 6.851e-01, Validation Loss: 9.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3856, Training Loss: 6.850e-01, Validation Loss: 9.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3857, Training Loss: 6.848e-01, Validation Loss: 9.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3858, Training Loss: 6.847e-01, Validation Loss: 9.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3859, Training Loss: 6.845e-01, Validation Loss: 9.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3860, Training Loss: 6.844e-01, Validation Loss: 9.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3861, Training Loss: 6.842e-01, Validation Loss: 9.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3862, Training Loss: 6.841e-01, Validation Loss: 9.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3863, Training Loss: 6.839e-01, Validation Loss: 9.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3864, Training Loss: 6.838e-01, Validation Loss: 9.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3865, Training Loss: 6.836e-01, Validation Loss: 9.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3866, Training Loss: 6.835e-01, Validation Loss: 9.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3867, Training Loss: 6.833e-01, Validation Loss: 9.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3868, Training Loss: 6.832e-01, Validation Loss: 9.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3869, Training Loss: 6.831e-01, Validation Loss: 9.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3870, Training Loss: 6.829e-01, Validation Loss: 9.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3871, Training Loss: 6.828e-01, Validation Loss: 9.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3872, Training Loss: 6.826e-01, Validation Loss: 9.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3873, Training Loss: 6.825e-01, Validation Loss: 9.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3874, Training Loss: 6.823e-01, Validation Loss: 9.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3875, Training Loss: 6.822e-01, Validation Loss: 9.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3876, Training Loss: 6.820e-01, Validation Loss: 9.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3877, Training Loss: 6.819e-01, Validation Loss: 9.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3878, Training Loss: 6.817e-01, Validation Loss: 9.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3879, Training Loss: 6.816e-01, Validation Loss: 9.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3880, Training Loss: 6.814e-01, Validation Loss: 9.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3881, Training Loss: 6.813e-01, Validation Loss: 9.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3882, Training Loss: 6.811e-01, Validation Loss: 9.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3883, Training Loss: 6.810e-01, Validation Loss: 9.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3884, Training Loss: 6.808e-01, Validation Loss: 9.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3885, Training Loss: 6.807e-01, Validation Loss: 9.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3886, Training Loss: 6.805e-01, Validation Loss: 9.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3887, Training Loss: 6.804e-01, Validation Loss: 9.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3888, Training Loss: 6.803e-01, Validation Loss: 9.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3889, Training Loss: 6.801e-01, Validation Loss: 9.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3890, Training Loss: 6.800e-01, Validation Loss: 9.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3891, Training Loss: 6.798e-01, Validation Loss: 9.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3892, Training Loss: 6.797e-01, Validation Loss: 9.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3893, Training Loss: 6.795e-01, Validation Loss: 9.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3894, Training Loss: 6.794e-01, Validation Loss: 9.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3895, Training Loss: 6.792e-01, Validation Loss: 9.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3896, Training Loss: 6.791e-01, Validation Loss: 9.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3897, Training Loss: 6.789e-01, Validation Loss: 9.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3898, Training Loss: 6.788e-01, Validation Loss: 9.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3899, Training Loss: 6.786e-01, Validation Loss: 9.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3900, Training Loss: 6.785e-01, Validation Loss: 9.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3901, Training Loss: 6.783e-01, Validation Loss: 9.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3902, Training Loss: 6.782e-01, Validation Loss: 9.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3903, Training Loss: 6.781e-01, Validation Loss: 9.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3904, Training Loss: 6.779e-01, Validation Loss: 9.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3905, Training Loss: 6.778e-01, Validation Loss: 9.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3906, Training Loss: 6.776e-01, Validation Loss: 9.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3907, Training Loss: 6.775e-01, Validation Loss: 9.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3908, Training Loss: 6.773e-01, Validation Loss: 9.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3909, Training Loss: 6.772e-01, Validation Loss: 9.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3910, Training Loss: 6.770e-01, Validation Loss: 9.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3911, Training Loss: 6.769e-01, Validation Loss: 9.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3912, Training Loss: 6.767e-01, Validation Loss: 9.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3913, Training Loss: 6.766e-01, Validation Loss: 9.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3914, Training Loss: 6.765e-01, Validation Loss: 9.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3915, Training Loss: 6.763e-01, Validation Loss: 9.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3916, Training Loss: 6.762e-01, Validation Loss: 9.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3917, Training Loss: 6.760e-01, Validation Loss: 9.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3918, Training Loss: 6.759e-01, Validation Loss: 9.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3919, Training Loss: 6.757e-01, Validation Loss: 9.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3920, Training Loss: 6.756e-01, Validation Loss: 9.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3921, Training Loss: 6.754e-01, Validation Loss: 9.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3922, Training Loss: 6.753e-01, Validation Loss: 9.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3923, Training Loss: 6.752e-01, Validation Loss: 9.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3924, Training Loss: 6.750e-01, Validation Loss: 9.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3925, Training Loss: 6.749e-01, Validation Loss: 9.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3926, Training Loss: 6.747e-01, Validation Loss: 9.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3927, Training Loss: 6.746e-01, Validation Loss: 9.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3928, Training Loss: 6.744e-01, Validation Loss: 9.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3929, Training Loss: 6.743e-01, Validation Loss: 9.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3930, Training Loss: 6.741e-01, Validation Loss: 9.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3931, Training Loss: 6.740e-01, Validation Loss: 9.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3932, Training Loss: 6.739e-01, Validation Loss: 9.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3933, Training Loss: 6.737e-01, Validation Loss: 9.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3934, Training Loss: 6.736e-01, Validation Loss: 9.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3935, Training Loss: 6.734e-01, Validation Loss: 9.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3936, Training Loss: 6.733e-01, Validation Loss: 9.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3937, Training Loss: 6.731e-01, Validation Loss: 9.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3938, Training Loss: 6.730e-01, Validation Loss: 9.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3939, Training Loss: 6.728e-01, Validation Loss: 9.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3940, Training Loss: 6.727e-01, Validation Loss: 9.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3941, Training Loss: 6.726e-01, Validation Loss: 9.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3942, Training Loss: 6.724e-01, Validation Loss: 9.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3943, Training Loss: 6.723e-01, Validation Loss: 9.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3944, Training Loss: 6.721e-01, Validation Loss: 9.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3945, Training Loss: 6.720e-01, Validation Loss: 9.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3946, Training Loss: 6.718e-01, Validation Loss: 9.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3947, Training Loss: 6.717e-01, Validation Loss: 9.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3948, Training Loss: 6.716e-01, Validation Loss: 9.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3949, Training Loss: 6.714e-01, Validation Loss: 9.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3950, Training Loss: 6.713e-01, Validation Loss: 9.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3951, Training Loss: 6.711e-01, Validation Loss: 9.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3952, Training Loss: 6.710e-01, Validation Loss: 9.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3953, Training Loss: 6.708e-01, Validation Loss: 9.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3954, Training Loss: 6.707e-01, Validation Loss: 9.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3955, Training Loss: 6.705e-01, Validation Loss: 9.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3956, Training Loss: 6.704e-01, Validation Loss: 9.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3957, Training Loss: 6.703e-01, Validation Loss: 9.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3958, Training Loss: 6.701e-01, Validation Loss: 9.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3959, Training Loss: 6.700e-01, Validation Loss: 9.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3960, Training Loss: 6.698e-01, Validation Loss: 9.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3961, Training Loss: 6.697e-01, Validation Loss: 9.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3962, Training Loss: 6.695e-01, Validation Loss: 9.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3963, Training Loss: 6.694e-01, Validation Loss: 9.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3964, Training Loss: 6.693e-01, Validation Loss: 9.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3965, Training Loss: 6.691e-01, Validation Loss: 9.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3966, Training Loss: 6.690e-01, Validation Loss: 9.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3967, Training Loss: 6.688e-01, Validation Loss: 9.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3968, Training Loss: 6.687e-01, Validation Loss: 9.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3969, Training Loss: 6.686e-01, Validation Loss: 9.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3970, Training Loss: 6.684e-01, Validation Loss: 9.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3971, Training Loss: 6.683e-01, Validation Loss: 9.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3972, Training Loss: 6.681e-01, Validation Loss: 9.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3973, Training Loss: 6.680e-01, Validation Loss: 9.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3974, Training Loss: 6.678e-01, Validation Loss: 9.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3975, Training Loss: 6.677e-01, Validation Loss: 9.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3976, Training Loss: 6.676e-01, Validation Loss: 9.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3977, Training Loss: 6.674e-01, Validation Loss: 9.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3978, Training Loss: 6.673e-01, Validation Loss: 9.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3979, Training Loss: 6.671e-01, Validation Loss: 9.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3980, Training Loss: 6.670e-01, Validation Loss: 9.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3981, Training Loss: 6.668e-01, Validation Loss: 9.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3982, Training Loss: 6.667e-01, Validation Loss: 9.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3983, Training Loss: 6.666e-01, Validation Loss: 9.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3984, Training Loss: 6.664e-01, Validation Loss: 9.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3985, Training Loss: 6.663e-01, Validation Loss: 9.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3986, Training Loss: 6.661e-01, Validation Loss: 9.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3987, Training Loss: 6.660e-01, Validation Loss: 9.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3988, Training Loss: 6.659e-01, Validation Loss: 9.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3989, Training Loss: 6.657e-01, Validation Loss: 9.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3990, Training Loss: 6.656e-01, Validation Loss: 9.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3991, Training Loss: 6.654e-01, Validation Loss: 9.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3992, Training Loss: 6.653e-01, Validation Loss: 9.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3993, Training Loss: 6.652e-01, Validation Loss: 9.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3994, Training Loss: 6.650e-01, Validation Loss: 9.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3995, Training Loss: 6.649e-01, Validation Loss: 9.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3996, Training Loss: 6.647e-01, Validation Loss: 9.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3997, Training Loss: 6.646e-01, Validation Loss: 9.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3998, Training Loss: 6.645e-01, Validation Loss: 9.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 3999, Training Loss: 6.643e-01, Validation Loss: 9.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4000, Training Loss: 6.642e-01, Validation Loss: 9.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4001, Training Loss: 6.640e-01, Validation Loss: 9.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4002, Training Loss: 6.639e-01, Validation Loss: 9.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4003, Training Loss: 6.638e-01, Validation Loss: 9.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4004, Training Loss: 6.636e-01, Validation Loss: 9.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4005, Training Loss: 6.635e-01, Validation Loss: 9.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4006, Training Loss: 6.633e-01, Validation Loss: 9.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4007, Training Loss: 6.632e-01, Validation Loss: 9.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4008, Training Loss: 6.631e-01, Validation Loss: 9.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4009, Training Loss: 6.629e-01, Validation Loss: 9.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4010, Training Loss: 6.628e-01, Validation Loss: 9.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4011, Training Loss: 6.626e-01, Validation Loss: 9.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4012, Training Loss: 6.625e-01, Validation Loss: 9.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4013, Training Loss: 6.624e-01, Validation Loss: 9.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4014, Training Loss: 6.622e-01, Validation Loss: 9.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4015, Training Loss: 6.621e-01, Validation Loss: 9.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4016, Training Loss: 6.619e-01, Validation Loss: 9.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4017, Training Loss: 6.618e-01, Validation Loss: 9.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4018, Training Loss: 6.617e-01, Validation Loss: 9.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4019, Training Loss: 6.615e-01, Validation Loss: 9.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4020, Training Loss: 6.614e-01, Validation Loss: 9.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4021, Training Loss: 6.612e-01, Validation Loss: 9.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4022, Training Loss: 6.611e-01, Validation Loss: 9.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4023, Training Loss: 6.610e-01, Validation Loss: 9.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4024, Training Loss: 6.608e-01, Validation Loss: 9.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4025, Training Loss: 6.607e-01, Validation Loss: 9.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4026, Training Loss: 6.605e-01, Validation Loss: 9.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4027, Training Loss: 6.604e-01, Validation Loss: 9.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4028, Training Loss: 6.603e-01, Validation Loss: 9.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4029, Training Loss: 6.601e-01, Validation Loss: 9.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4030, Training Loss: 6.600e-01, Validation Loss: 9.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4031, Training Loss: 6.599e-01, Validation Loss: 9.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4032, Training Loss: 6.597e-01, Validation Loss: 9.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4033, Training Loss: 6.596e-01, Validation Loss: 9.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4034, Training Loss: 6.594e-01, Validation Loss: 9.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4035, Training Loss: 6.593e-01, Validation Loss: 9.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4036, Training Loss: 6.592e-01, Validation Loss: 9.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4037, Training Loss: 6.590e-01, Validation Loss: 9.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4038, Training Loss: 6.589e-01, Validation Loss: 9.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4039, Training Loss: 6.587e-01, Validation Loss: 9.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4040, Training Loss: 6.586e-01, Validation Loss: 9.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4041, Training Loss: 6.585e-01, Validation Loss: 9.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4042, Training Loss: 6.583e-01, Validation Loss: 9.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4043, Training Loss: 6.582e-01, Validation Loss: 9.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4044, Training Loss: 6.581e-01, Validation Loss: 9.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4045, Training Loss: 6.579e-01, Validation Loss: 9.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4046, Training Loss: 6.578e-01, Validation Loss: 9.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4047, Training Loss: 6.576e-01, Validation Loss: 9.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4048, Training Loss: 6.575e-01, Validation Loss: 9.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4049, Training Loss: 6.574e-01, Validation Loss: 9.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4050, Training Loss: 6.572e-01, Validation Loss: 9.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4051, Training Loss: 6.571e-01, Validation Loss: 9.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4052, Training Loss: 6.570e-01, Validation Loss: 9.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4053, Training Loss: 6.568e-01, Validation Loss: 9.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4054, Training Loss: 6.567e-01, Validation Loss: 9.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4055, Training Loss: 6.565e-01, Validation Loss: 9.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4056, Training Loss: 6.564e-01, Validation Loss: 9.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4057, Training Loss: 6.563e-01, Validation Loss: 9.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4058, Training Loss: 6.561e-01, Validation Loss: 9.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4059, Training Loss: 6.560e-01, Validation Loss: 9.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4060, Training Loss: 6.559e-01, Validation Loss: 9.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4061, Training Loss: 6.557e-01, Validation Loss: 9.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4062, Training Loss: 6.556e-01, Validation Loss: 9.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4063, Training Loss: 6.554e-01, Validation Loss: 9.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4064, Training Loss: 6.553e-01, Validation Loss: 9.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4065, Training Loss: 6.552e-01, Validation Loss: 9.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4066, Training Loss: 6.550e-01, Validation Loss: 9.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4067, Training Loss: 6.549e-01, Validation Loss: 9.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4068, Training Loss: 6.548e-01, Validation Loss: 9.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4069, Training Loss: 6.546e-01, Validation Loss: 9.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4070, Training Loss: 6.545e-01, Validation Loss: 9.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4071, Training Loss: 6.544e-01, Validation Loss: 9.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4072, Training Loss: 6.542e-01, Validation Loss: 9.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4073, Training Loss: 6.541e-01, Validation Loss: 9.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4074, Training Loss: 6.539e-01, Validation Loss: 9.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4075, Training Loss: 6.538e-01, Validation Loss: 9.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4076, Training Loss: 6.537e-01, Validation Loss: 9.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4077, Training Loss: 6.535e-01, Validation Loss: 9.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4078, Training Loss: 6.534e-01, Validation Loss: 9.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4079, Training Loss: 6.533e-01, Validation Loss: 9.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4080, Training Loss: 6.531e-01, Validation Loss: 9.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4081, Training Loss: 6.530e-01, Validation Loss: 9.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4082, Training Loss: 6.529e-01, Validation Loss: 9.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4083, Training Loss: 6.527e-01, Validation Loss: 9.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4084, Training Loss: 6.526e-01, Validation Loss: 9.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4085, Training Loss: 6.525e-01, Validation Loss: 9.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4086, Training Loss: 6.523e-01, Validation Loss: 9.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4087, Training Loss: 6.522e-01, Validation Loss: 9.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4088, Training Loss: 6.520e-01, Validation Loss: 9.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4089, Training Loss: 6.519e-01, Validation Loss: 9.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4090, Training Loss: 6.518e-01, Validation Loss: 9.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4091, Training Loss: 6.516e-01, Validation Loss: 9.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4092, Training Loss: 6.515e-01, Validation Loss: 9.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4093, Training Loss: 6.514e-01, Validation Loss: 9.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4094, Training Loss: 6.512e-01, Validation Loss: 9.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4095, Training Loss: 6.511e-01, Validation Loss: 9.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4096, Training Loss: 6.510e-01, Validation Loss: 9.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4097, Training Loss: 6.508e-01, Validation Loss: 9.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4098, Training Loss: 6.507e-01, Validation Loss: 9.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4099, Training Loss: 6.506e-01, Validation Loss: 9.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4100, Training Loss: 6.504e-01, Validation Loss: 9.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4101, Training Loss: 6.503e-01, Validation Loss: 9.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4102, Training Loss: 6.502e-01, Validation Loss: 9.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4103, Training Loss: 6.500e-01, Validation Loss: 9.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4104, Training Loss: 6.499e-01, Validation Loss: 9.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4105, Training Loss: 6.497e-01, Validation Loss: 9.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4106, Training Loss: 6.496e-01, Validation Loss: 9.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4107, Training Loss: 6.495e-01, Validation Loss: 9.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4108, Training Loss: 6.493e-01, Validation Loss: 9.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4109, Training Loss: 6.492e-01, Validation Loss: 9.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4110, Training Loss: 6.491e-01, Validation Loss: 9.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4111, Training Loss: 6.489e-01, Validation Loss: 9.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4112, Training Loss: 6.488e-01, Validation Loss: 9.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4113, Training Loss: 6.487e-01, Validation Loss: 9.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4114, Training Loss: 6.485e-01, Validation Loss: 9.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4115, Training Loss: 6.484e-01, Validation Loss: 9.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4116, Training Loss: 6.483e-01, Validation Loss: 9.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4117, Training Loss: 6.481e-01, Validation Loss: 9.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4118, Training Loss: 6.480e-01, Validation Loss: 9.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4119, Training Loss: 6.479e-01, Validation Loss: 9.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4120, Training Loss: 6.477e-01, Validation Loss: 9.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4121, Training Loss: 6.476e-01, Validation Loss: 9.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4122, Training Loss: 6.475e-01, Validation Loss: 9.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4123, Training Loss: 6.473e-01, Validation Loss: 9.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4124, Training Loss: 6.472e-01, Validation Loss: 9.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4125, Training Loss: 6.471e-01, Validation Loss: 9.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4126, Training Loss: 6.469e-01, Validation Loss: 9.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4127, Training Loss: 6.468e-01, Validation Loss: 9.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4128, Training Loss: 6.467e-01, Validation Loss: 9.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4129, Training Loss: 6.465e-01, Validation Loss: 9.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4130, Training Loss: 6.464e-01, Validation Loss: 9.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4131, Training Loss: 6.463e-01, Validation Loss: 9.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4132, Training Loss: 6.461e-01, Validation Loss: 9.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4133, Training Loss: 6.460e-01, Validation Loss: 9.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4134, Training Loss: 6.459e-01, Validation Loss: 9.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4135, Training Loss: 6.457e-01, Validation Loss: 9.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4136, Training Loss: 6.456e-01, Validation Loss: 9.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4137, Training Loss: 6.455e-01, Validation Loss: 9.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4138, Training Loss: 6.453e-01, Validation Loss: 9.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4139, Training Loss: 6.452e-01, Validation Loss: 9.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4140, Training Loss: 6.451e-01, Validation Loss: 9.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4141, Training Loss: 6.449e-01, Validation Loss: 9.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4142, Training Loss: 6.448e-01, Validation Loss: 9.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4143, Training Loss: 6.447e-01, Validation Loss: 9.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4144, Training Loss: 6.445e-01, Validation Loss: 9.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4145, Training Loss: 6.444e-01, Validation Loss: 9.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4146, Training Loss: 6.443e-01, Validation Loss: 9.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4147, Training Loss: 6.441e-01, Validation Loss: 9.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4148, Training Loss: 6.440e-01, Validation Loss: 9.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4149, Training Loss: 6.439e-01, Validation Loss: 9.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4150, Training Loss: 6.437e-01, Validation Loss: 9.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4151, Training Loss: 6.436e-01, Validation Loss: 9.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4152, Training Loss: 6.435e-01, Validation Loss: 9.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4153, Training Loss: 6.433e-01, Validation Loss: 9.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4154, Training Loss: 6.432e-01, Validation Loss: 9.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4155, Training Loss: 6.431e-01, Validation Loss: 9.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4156, Training Loss: 6.429e-01, Validation Loss: 9.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4157, Training Loss: 6.428e-01, Validation Loss: 9.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4158, Training Loss: 6.427e-01, Validation Loss: 9.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4159, Training Loss: 6.425e-01, Validation Loss: 9.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4160, Training Loss: 6.424e-01, Validation Loss: 9.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4161, Training Loss: 6.423e-01, Validation Loss: 9.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4162, Training Loss: 6.421e-01, Validation Loss: 9.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4163, Training Loss: 6.420e-01, Validation Loss: 9.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4164, Training Loss: 6.419e-01, Validation Loss: 9.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4165, Training Loss: 6.418e-01, Validation Loss: 9.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4166, Training Loss: 6.416e-01, Validation Loss: 9.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4167, Training Loss: 6.415e-01, Validation Loss: 9.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4168, Training Loss: 6.414e-01, Validation Loss: 9.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4169, Training Loss: 6.412e-01, Validation Loss: 9.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4170, Training Loss: 6.411e-01, Validation Loss: 9.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4171, Training Loss: 6.410e-01, Validation Loss: 9.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4172, Training Loss: 6.408e-01, Validation Loss: 9.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4173, Training Loss: 6.407e-01, Validation Loss: 9.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4174, Training Loss: 6.406e-01, Validation Loss: 9.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4175, Training Loss: 6.404e-01, Validation Loss: 9.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4176, Training Loss: 6.403e-01, Validation Loss: 9.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4177, Training Loss: 6.402e-01, Validation Loss: 9.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4178, Training Loss: 6.400e-01, Validation Loss: 9.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4179, Training Loss: 6.399e-01, Validation Loss: 9.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4180, Training Loss: 6.398e-01, Validation Loss: 9.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4181, Training Loss: 6.396e-01, Validation Loss: 9.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4182, Training Loss: 6.395e-01, Validation Loss: 9.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4183, Training Loss: 6.394e-01, Validation Loss: 9.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4184, Training Loss: 6.393e-01, Validation Loss: 9.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4185, Training Loss: 6.391e-01, Validation Loss: 9.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4186, Training Loss: 6.390e-01, Validation Loss: 9.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4187, Training Loss: 6.389e-01, Validation Loss: 9.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4188, Training Loss: 6.387e-01, Validation Loss: 9.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4189, Training Loss: 6.386e-01, Validation Loss: 9.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4190, Training Loss: 6.385e-01, Validation Loss: 9.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4191, Training Loss: 6.383e-01, Validation Loss: 9.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4192, Training Loss: 6.382e-01, Validation Loss: 9.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4193, Training Loss: 6.381e-01, Validation Loss: 9.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4194, Training Loss: 6.379e-01, Validation Loss: 9.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4195, Training Loss: 6.378e-01, Validation Loss: 9.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4196, Training Loss: 6.377e-01, Validation Loss: 9.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4197, Training Loss: 6.376e-01, Validation Loss: 9.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4198, Training Loss: 6.374e-01, Validation Loss: 9.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4199, Training Loss: 6.373e-01, Validation Loss: 9.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4200, Training Loss: 6.372e-01, Validation Loss: 9.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4201, Training Loss: 6.370e-01, Validation Loss: 9.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4202, Training Loss: 6.369e-01, Validation Loss: 9.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4203, Training Loss: 6.368e-01, Validation Loss: 9.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4204, Training Loss: 6.366e-01, Validation Loss: 9.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4205, Training Loss: 6.365e-01, Validation Loss: 9.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4206, Training Loss: 6.364e-01, Validation Loss: 9.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4207, Training Loss: 6.363e-01, Validation Loss: 9.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4208, Training Loss: 6.361e-01, Validation Loss: 9.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4209, Training Loss: 6.360e-01, Validation Loss: 9.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4210, Training Loss: 6.359e-01, Validation Loss: 9.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4211, Training Loss: 6.357e-01, Validation Loss: 9.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4212, Training Loss: 6.356e-01, Validation Loss: 9.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4213, Training Loss: 6.355e-01, Validation Loss: 9.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4214, Training Loss: 6.354e-01, Validation Loss: 9.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4215, Training Loss: 6.352e-01, Validation Loss: 9.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4216, Training Loss: 6.351e-01, Validation Loss: 9.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4217, Training Loss: 6.350e-01, Validation Loss: 9.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4218, Training Loss: 6.348e-01, Validation Loss: 9.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4219, Training Loss: 6.347e-01, Validation Loss: 9.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4220, Training Loss: 6.346e-01, Validation Loss: 9.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4221, Training Loss: 6.344e-01, Validation Loss: 9.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4222, Training Loss: 6.343e-01, Validation Loss: 9.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4223, Training Loss: 6.342e-01, Validation Loss: 9.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4224, Training Loss: 6.341e-01, Validation Loss: 9.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4225, Training Loss: 6.339e-01, Validation Loss: 9.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4226, Training Loss: 6.338e-01, Validation Loss: 9.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4227, Training Loss: 6.337e-01, Validation Loss: 9.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4228, Training Loss: 6.335e-01, Validation Loss: 9.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4229, Training Loss: 6.334e-01, Validation Loss: 9.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4230, Training Loss: 6.333e-01, Validation Loss: 9.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4231, Training Loss: 6.332e-01, Validation Loss: 9.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4232, Training Loss: 6.330e-01, Validation Loss: 9.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4233, Training Loss: 6.329e-01, Validation Loss: 9.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4234, Training Loss: 6.328e-01, Validation Loss: 9.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4235, Training Loss: 6.326e-01, Validation Loss: 9.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4236, Training Loss: 6.325e-01, Validation Loss: 9.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4237, Training Loss: 6.324e-01, Validation Loss: 9.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4238, Training Loss: 6.323e-01, Validation Loss: 9.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4239, Training Loss: 6.321e-01, Validation Loss: 9.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4240, Training Loss: 6.320e-01, Validation Loss: 9.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4241, Training Loss: 6.319e-01, Validation Loss: 9.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4242, Training Loss: 6.317e-01, Validation Loss: 9.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4243, Training Loss: 6.316e-01, Validation Loss: 9.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4244, Training Loss: 6.315e-01, Validation Loss: 9.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4245, Training Loss: 6.314e-01, Validation Loss: 9.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4246, Training Loss: 6.312e-01, Validation Loss: 9.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4247, Training Loss: 6.311e-01, Validation Loss: 9.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4248, Training Loss: 6.310e-01, Validation Loss: 9.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4249, Training Loss: 6.309e-01, Validation Loss: 9.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4250, Training Loss: 6.307e-01, Validation Loss: 9.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4251, Training Loss: 6.306e-01, Validation Loss: 9.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4252, Training Loss: 6.305e-01, Validation Loss: 9.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4253, Training Loss: 6.303e-01, Validation Loss: 9.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4254, Training Loss: 6.302e-01, Validation Loss: 9.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4255, Training Loss: 6.301e-01, Validation Loss: 9.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4256, Training Loss: 6.300e-01, Validation Loss: 9.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4257, Training Loss: 6.298e-01, Validation Loss: 9.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4258, Training Loss: 6.297e-01, Validation Loss: 9.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4259, Training Loss: 6.296e-01, Validation Loss: 9.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4260, Training Loss: 6.294e-01, Validation Loss: 9.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4261, Training Loss: 6.293e-01, Validation Loss: 9.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4262, Training Loss: 6.292e-01, Validation Loss: 9.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4263, Training Loss: 6.291e-01, Validation Loss: 9.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4264, Training Loss: 6.289e-01, Validation Loss: 9.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4265, Training Loss: 6.288e-01, Validation Loss: 9.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4266, Training Loss: 6.287e-01, Validation Loss: 9.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4267, Training Loss: 6.286e-01, Validation Loss: 9.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4268, Training Loss: 6.284e-01, Validation Loss: 9.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4269, Training Loss: 6.283e-01, Validation Loss: 9.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4270, Training Loss: 6.282e-01, Validation Loss: 9.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4271, Training Loss: 6.281e-01, Validation Loss: 9.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4272, Training Loss: 6.279e-01, Validation Loss: 9.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4273, Training Loss: 6.278e-01, Validation Loss: 9.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4274, Training Loss: 6.277e-01, Validation Loss: 9.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4275, Training Loss: 6.275e-01, Validation Loss: 9.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4276, Training Loss: 6.274e-01, Validation Loss: 9.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4277, Training Loss: 6.273e-01, Validation Loss: 9.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4278, Training Loss: 6.272e-01, Validation Loss: 9.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4279, Training Loss: 6.270e-01, Validation Loss: 9.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4280, Training Loss: 6.269e-01, Validation Loss: 9.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4281, Training Loss: 6.268e-01, Validation Loss: 9.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4282, Training Loss: 6.267e-01, Validation Loss: 9.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4283, Training Loss: 6.265e-01, Validation Loss: 9.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4284, Training Loss: 6.264e-01, Validation Loss: 9.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4285, Training Loss: 6.263e-01, Validation Loss: 9.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4286, Training Loss: 6.262e-01, Validation Loss: 9.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4287, Training Loss: 6.260e-01, Validation Loss: 9.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4288, Training Loss: 6.259e-01, Validation Loss: 9.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4289, Training Loss: 6.258e-01, Validation Loss: 9.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4290, Training Loss: 6.257e-01, Validation Loss: 9.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4291, Training Loss: 6.255e-01, Validation Loss: 9.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4292, Training Loss: 6.254e-01, Validation Loss: 9.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4293, Training Loss: 6.253e-01, Validation Loss: 9.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4294, Training Loss: 6.252e-01, Validation Loss: 9.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4295, Training Loss: 6.250e-01, Validation Loss: 9.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4296, Training Loss: 6.249e-01, Validation Loss: 9.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4297, Training Loss: 6.248e-01, Validation Loss: 9.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4298, Training Loss: 6.246e-01, Validation Loss: 9.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4299, Training Loss: 6.245e-01, Validation Loss: 9.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4300, Training Loss: 6.244e-01, Validation Loss: 9.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4301, Training Loss: 6.243e-01, Validation Loss: 9.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4302, Training Loss: 6.241e-01, Validation Loss: 9.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4303, Training Loss: 6.240e-01, Validation Loss: 9.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4304, Training Loss: 6.239e-01, Validation Loss: 9.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4305, Training Loss: 6.238e-01, Validation Loss: 9.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4306, Training Loss: 6.236e-01, Validation Loss: 9.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4307, Training Loss: 6.235e-01, Validation Loss: 9.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4308, Training Loss: 6.234e-01, Validation Loss: 9.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4309, Training Loss: 6.233e-01, Validation Loss: 9.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4310, Training Loss: 6.231e-01, Validation Loss: 9.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4311, Training Loss: 6.230e-01, Validation Loss: 9.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4312, Training Loss: 6.229e-01, Validation Loss: 9.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4313, Training Loss: 6.228e-01, Validation Loss: 9.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4314, Training Loss: 6.226e-01, Validation Loss: 9.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4315, Training Loss: 6.225e-01, Validation Loss: 9.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4316, Training Loss: 6.224e-01, Validation Loss: 9.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4317, Training Loss: 6.223e-01, Validation Loss: 9.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4318, Training Loss: 6.221e-01, Validation Loss: 9.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4319, Training Loss: 6.220e-01, Validation Loss: 9.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4320, Training Loss: 6.219e-01, Validation Loss: 9.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4321, Training Loss: 6.218e-01, Validation Loss: 9.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4322, Training Loss: 6.216e-01, Validation Loss: 9.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4323, Training Loss: 6.215e-01, Validation Loss: 9.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4324, Training Loss: 6.214e-01, Validation Loss: 9.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4325, Training Loss: 6.213e-01, Validation Loss: 9.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4326, Training Loss: 6.212e-01, Validation Loss: 9.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4327, Training Loss: 6.210e-01, Validation Loss: 9.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4328, Training Loss: 6.209e-01, Validation Loss: 9.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4329, Training Loss: 6.208e-01, Validation Loss: 9.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4330, Training Loss: 6.207e-01, Validation Loss: 9.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4331, Training Loss: 6.205e-01, Validation Loss: 9.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4332, Training Loss: 6.204e-01, Validation Loss: 9.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4333, Training Loss: 6.203e-01, Validation Loss: 9.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4334, Training Loss: 6.202e-01, Validation Loss: 9.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4335, Training Loss: 6.200e-01, Validation Loss: 9.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4336, Training Loss: 6.199e-01, Validation Loss: 9.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4337, Training Loss: 6.198e-01, Validation Loss: 9.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4338, Training Loss: 6.197e-01, Validation Loss: 9.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4339, Training Loss: 6.195e-01, Validation Loss: 9.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4340, Training Loss: 6.194e-01, Validation Loss: 9.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4341, Training Loss: 6.193e-01, Validation Loss: 9.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4342, Training Loss: 6.192e-01, Validation Loss: 9.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4343, Training Loss: 6.190e-01, Validation Loss: 9.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4344, Training Loss: 6.189e-01, Validation Loss: 9.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4345, Training Loss: 6.188e-01, Validation Loss: 9.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4346, Training Loss: 6.187e-01, Validation Loss: 9.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4347, Training Loss: 6.186e-01, Validation Loss: 9.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4348, Training Loss: 6.184e-01, Validation Loss: 9.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4349, Training Loss: 6.183e-01, Validation Loss: 9.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4350, Training Loss: 6.182e-01, Validation Loss: 9.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4351, Training Loss: 6.181e-01, Validation Loss: 9.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4352, Training Loss: 6.179e-01, Validation Loss: 9.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4353, Training Loss: 6.178e-01, Validation Loss: 9.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4354, Training Loss: 6.177e-01, Validation Loss: 9.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4355, Training Loss: 6.176e-01, Validation Loss: 9.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4356, Training Loss: 6.174e-01, Validation Loss: 9.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4357, Training Loss: 6.173e-01, Validation Loss: 9.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4358, Training Loss: 6.172e-01, Validation Loss: 9.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4359, Training Loss: 6.171e-01, Validation Loss: 9.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4360, Training Loss: 6.170e-01, Validation Loss: 9.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4361, Training Loss: 6.168e-01, Validation Loss: 9.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4362, Training Loss: 6.167e-01, Validation Loss: 9.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4363, Training Loss: 6.166e-01, Validation Loss: 9.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4364, Training Loss: 6.165e-01, Validation Loss: 9.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4365, Training Loss: 6.163e-01, Validation Loss: 9.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4366, Training Loss: 6.162e-01, Validation Loss: 9.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4367, Training Loss: 6.161e-01, Validation Loss: 9.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4368, Training Loss: 6.160e-01, Validation Loss: 9.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4369, Training Loss: 6.159e-01, Validation Loss: 9.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4370, Training Loss: 6.157e-01, Validation Loss: 9.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4371, Training Loss: 6.156e-01, Validation Loss: 9.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4372, Training Loss: 6.155e-01, Validation Loss: 9.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4373, Training Loss: 6.154e-01, Validation Loss: 9.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4374, Training Loss: 6.152e-01, Validation Loss: 9.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4375, Training Loss: 6.151e-01, Validation Loss: 9.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4376, Training Loss: 6.150e-01, Validation Loss: 9.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4377, Training Loss: 6.149e-01, Validation Loss: 9.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4378, Training Loss: 6.148e-01, Validation Loss: 9.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4379, Training Loss: 6.146e-01, Validation Loss: 9.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4380, Training Loss: 6.145e-01, Validation Loss: 9.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4381, Training Loss: 6.144e-01, Validation Loss: 9.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4382, Training Loss: 6.143e-01, Validation Loss: 9.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4383, Training Loss: 6.141e-01, Validation Loss: 9.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4384, Training Loss: 6.140e-01, Validation Loss: 9.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4385, Training Loss: 6.139e-01, Validation Loss: 9.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4386, Training Loss: 6.138e-01, Validation Loss: 9.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4387, Training Loss: 6.137e-01, Validation Loss: 9.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4388, Training Loss: 6.135e-01, Validation Loss: 9.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4389, Training Loss: 6.134e-01, Validation Loss: 9.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4390, Training Loss: 6.133e-01, Validation Loss: 9.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4391, Training Loss: 6.132e-01, Validation Loss: 9.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4392, Training Loss: 6.131e-01, Validation Loss: 9.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4393, Training Loss: 6.129e-01, Validation Loss: 9.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4394, Training Loss: 6.128e-01, Validation Loss: 9.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4395, Training Loss: 6.127e-01, Validation Loss: 8.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4396, Training Loss: 6.126e-01, Validation Loss: 8.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4397, Training Loss: 6.125e-01, Validation Loss: 8.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4398, Training Loss: 6.123e-01, Validation Loss: 8.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4399, Training Loss: 6.122e-01, Validation Loss: 8.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4400, Training Loss: 6.121e-01, Validation Loss: 8.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4401, Training Loss: 6.120e-01, Validation Loss: 8.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4402, Training Loss: 6.118e-01, Validation Loss: 8.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4403, Training Loss: 6.117e-01, Validation Loss: 8.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4404, Training Loss: 6.116e-01, Validation Loss: 8.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4405, Training Loss: 6.115e-01, Validation Loss: 8.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4406, Training Loss: 6.114e-01, Validation Loss: 8.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4407, Training Loss: 6.112e-01, Validation Loss: 8.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4408, Training Loss: 6.111e-01, Validation Loss: 8.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4409, Training Loss: 6.110e-01, Validation Loss: 8.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4410, Training Loss: 6.109e-01, Validation Loss: 8.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4411, Training Loss: 6.108e-01, Validation Loss: 8.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4412, Training Loss: 6.106e-01, Validation Loss: 8.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4413, Training Loss: 6.105e-01, Validation Loss: 8.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4414, Training Loss: 6.104e-01, Validation Loss: 8.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4415, Training Loss: 6.103e-01, Validation Loss: 8.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4416, Training Loss: 6.102e-01, Validation Loss: 8.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4417, Training Loss: 6.100e-01, Validation Loss: 8.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4418, Training Loss: 6.099e-01, Validation Loss: 8.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4419, Training Loss: 6.098e-01, Validation Loss: 8.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4420, Training Loss: 6.097e-01, Validation Loss: 8.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4421, Training Loss: 6.096e-01, Validation Loss: 8.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4422, Training Loss: 6.094e-01, Validation Loss: 8.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4423, Training Loss: 6.093e-01, Validation Loss: 8.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4424, Training Loss: 6.092e-01, Validation Loss: 8.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4425, Training Loss: 6.091e-01, Validation Loss: 8.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4426, Training Loss: 6.090e-01, Validation Loss: 8.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4427, Training Loss: 6.088e-01, Validation Loss: 8.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4428, Training Loss: 6.087e-01, Validation Loss: 8.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4429, Training Loss: 6.086e-01, Validation Loss: 8.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4430, Training Loss: 6.085e-01, Validation Loss: 8.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4431, Training Loss: 6.084e-01, Validation Loss: 8.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4432, Training Loss: 6.082e-01, Validation Loss: 8.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4433, Training Loss: 6.081e-01, Validation Loss: 8.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4434, Training Loss: 6.080e-01, Validation Loss: 8.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4435, Training Loss: 6.079e-01, Validation Loss: 8.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4436, Training Loss: 6.078e-01, Validation Loss: 8.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4437, Training Loss: 6.077e-01, Validation Loss: 8.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4438, Training Loss: 6.075e-01, Validation Loss: 8.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4439, Training Loss: 6.074e-01, Validation Loss: 8.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4440, Training Loss: 6.073e-01, Validation Loss: 8.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4441, Training Loss: 6.072e-01, Validation Loss: 8.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4442, Training Loss: 6.071e-01, Validation Loss: 8.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4443, Training Loss: 6.069e-01, Validation Loss: 8.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4444, Training Loss: 6.068e-01, Validation Loss: 8.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4445, Training Loss: 6.067e-01, Validation Loss: 8.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4446, Training Loss: 6.066e-01, Validation Loss: 8.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4447, Training Loss: 6.065e-01, Validation Loss: 8.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4448, Training Loss: 6.063e-01, Validation Loss: 8.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4449, Training Loss: 6.062e-01, Validation Loss: 8.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4450, Training Loss: 6.061e-01, Validation Loss: 8.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4451, Training Loss: 6.060e-01, Validation Loss: 8.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4452, Training Loss: 6.059e-01, Validation Loss: 8.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4453, Training Loss: 6.057e-01, Validation Loss: 8.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4454, Training Loss: 6.056e-01, Validation Loss: 8.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4455, Training Loss: 6.055e-01, Validation Loss: 8.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4456, Training Loss: 6.054e-01, Validation Loss: 8.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4457, Training Loss: 6.053e-01, Validation Loss: 8.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4458, Training Loss: 6.052e-01, Validation Loss: 8.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4459, Training Loss: 6.050e-01, Validation Loss: 8.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4460, Training Loss: 6.049e-01, Validation Loss: 8.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4461, Training Loss: 6.048e-01, Validation Loss: 8.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4462, Training Loss: 6.047e-01, Validation Loss: 8.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4463, Training Loss: 6.046e-01, Validation Loss: 8.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4464, Training Loss: 6.044e-01, Validation Loss: 8.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4465, Training Loss: 6.043e-01, Validation Loss: 8.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4466, Training Loss: 6.042e-01, Validation Loss: 8.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4467, Training Loss: 6.041e-01, Validation Loss: 8.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4468, Training Loss: 6.040e-01, Validation Loss: 8.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4469, Training Loss: 6.039e-01, Validation Loss: 8.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4470, Training Loss: 6.037e-01, Validation Loss: 8.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4471, Training Loss: 6.036e-01, Validation Loss: 8.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4472, Training Loss: 6.035e-01, Validation Loss: 8.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4473, Training Loss: 6.034e-01, Validation Loss: 8.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4474, Training Loss: 6.033e-01, Validation Loss: 8.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4475, Training Loss: 6.032e-01, Validation Loss: 8.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4476, Training Loss: 6.030e-01, Validation Loss: 8.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4477, Training Loss: 6.029e-01, Validation Loss: 8.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4478, Training Loss: 6.028e-01, Validation Loss: 8.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4479, Training Loss: 6.027e-01, Validation Loss: 8.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4480, Training Loss: 6.026e-01, Validation Loss: 8.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4481, Training Loss: 6.024e-01, Validation Loss: 8.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4482, Training Loss: 6.023e-01, Validation Loss: 8.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4483, Training Loss: 6.022e-01, Validation Loss: 8.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4484, Training Loss: 6.021e-01, Validation Loss: 8.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4485, Training Loss: 6.020e-01, Validation Loss: 8.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4486, Training Loss: 6.019e-01, Validation Loss: 8.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4487, Training Loss: 6.017e-01, Validation Loss: 8.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4488, Training Loss: 6.016e-01, Validation Loss: 8.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4489, Training Loss: 6.015e-01, Validation Loss: 8.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4490, Training Loss: 6.014e-01, Validation Loss: 8.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4491, Training Loss: 6.013e-01, Validation Loss: 8.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4492, Training Loss: 6.012e-01, Validation Loss: 8.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4493, Training Loss: 6.010e-01, Validation Loss: 8.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4494, Training Loss: 6.009e-01, Validation Loss: 8.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4495, Training Loss: 6.008e-01, Validation Loss: 8.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4496, Training Loss: 6.007e-01, Validation Loss: 8.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4497, Training Loss: 6.006e-01, Validation Loss: 8.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4498, Training Loss: 6.005e-01, Validation Loss: 8.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4499, Training Loss: 6.003e-01, Validation Loss: 8.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4500, Training Loss: 6.002e-01, Validation Loss: 8.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4501, Training Loss: 6.001e-01, Validation Loss: 8.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4502, Training Loss: 6.000e-01, Validation Loss: 8.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4503, Training Loss: 5.999e-01, Validation Loss: 8.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4504, Training Loss: 5.998e-01, Validation Loss: 8.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4505, Training Loss: 5.996e-01, Validation Loss: 8.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4506, Training Loss: 5.995e-01, Validation Loss: 8.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4507, Training Loss: 5.994e-01, Validation Loss: 8.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4508, Training Loss: 5.993e-01, Validation Loss: 8.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4509, Training Loss: 5.992e-01, Validation Loss: 8.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4510, Training Loss: 5.991e-01, Validation Loss: 8.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4511, Training Loss: 5.989e-01, Validation Loss: 8.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4512, Training Loss: 5.988e-01, Validation Loss: 8.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4513, Training Loss: 5.987e-01, Validation Loss: 8.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4514, Training Loss: 5.986e-01, Validation Loss: 8.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4515, Training Loss: 5.985e-01, Validation Loss: 8.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4516, Training Loss: 5.984e-01, Validation Loss: 8.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4517, Training Loss: 5.983e-01, Validation Loss: 8.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4518, Training Loss: 5.981e-01, Validation Loss: 8.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4519, Training Loss: 5.980e-01, Validation Loss: 8.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4520, Training Loss: 5.979e-01, Validation Loss: 8.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4521, Training Loss: 5.978e-01, Validation Loss: 8.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4522, Training Loss: 5.977e-01, Validation Loss: 8.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4523, Training Loss: 5.976e-01, Validation Loss: 8.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4524, Training Loss: 5.974e-01, Validation Loss: 8.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4525, Training Loss: 5.973e-01, Validation Loss: 8.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4526, Training Loss: 5.972e-01, Validation Loss: 8.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4527, Training Loss: 5.971e-01, Validation Loss: 8.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4528, Training Loss: 5.970e-01, Validation Loss: 8.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4529, Training Loss: 5.969e-01, Validation Loss: 8.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4530, Training Loss: 5.968e-01, Validation Loss: 8.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4531, Training Loss: 5.966e-01, Validation Loss: 8.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4532, Training Loss: 5.965e-01, Validation Loss: 8.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4533, Training Loss: 5.964e-01, Validation Loss: 8.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4534, Training Loss: 5.963e-01, Validation Loss: 8.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4535, Training Loss: 5.962e-01, Validation Loss: 8.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4536, Training Loss: 5.961e-01, Validation Loss: 8.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4537, Training Loss: 5.959e-01, Validation Loss: 8.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4538, Training Loss: 5.958e-01, Validation Loss: 8.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4539, Training Loss: 5.957e-01, Validation Loss: 8.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4540, Training Loss: 5.956e-01, Validation Loss: 8.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4541, Training Loss: 5.955e-01, Validation Loss: 8.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4542, Training Loss: 5.954e-01, Validation Loss: 8.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4543, Training Loss: 5.953e-01, Validation Loss: 8.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4544, Training Loss: 5.951e-01, Validation Loss: 8.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4545, Training Loss: 5.950e-01, Validation Loss: 8.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4546, Training Loss: 5.949e-01, Validation Loss: 8.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4547, Training Loss: 5.948e-01, Validation Loss: 8.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4548, Training Loss: 5.947e-01, Validation Loss: 8.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4549, Training Loss: 5.946e-01, Validation Loss: 8.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4550, Training Loss: 5.945e-01, Validation Loss: 8.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4551, Training Loss: 5.943e-01, Validation Loss: 8.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4552, Training Loss: 5.942e-01, Validation Loss: 8.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4553, Training Loss: 5.941e-01, Validation Loss: 8.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4554, Training Loss: 5.940e-01, Validation Loss: 8.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4555, Training Loss: 5.939e-01, Validation Loss: 8.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4556, Training Loss: 5.938e-01, Validation Loss: 8.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4557, Training Loss: 5.937e-01, Validation Loss: 8.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4558, Training Loss: 5.935e-01, Validation Loss: 8.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4559, Training Loss: 5.934e-01, Validation Loss: 8.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4560, Training Loss: 5.933e-01, Validation Loss: 8.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4561, Training Loss: 5.932e-01, Validation Loss: 8.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4562, Training Loss: 5.931e-01, Validation Loss: 8.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4563, Training Loss: 5.930e-01, Validation Loss: 8.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4564, Training Loss: 5.929e-01, Validation Loss: 8.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4565, Training Loss: 5.927e-01, Validation Loss: 8.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4566, Training Loss: 5.926e-01, Validation Loss: 8.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4567, Training Loss: 5.925e-01, Validation Loss: 8.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4568, Training Loss: 5.924e-01, Validation Loss: 8.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4569, Training Loss: 5.923e-01, Validation Loss: 8.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4570, Training Loss: 5.922e-01, Validation Loss: 8.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4571, Training Loss: 5.921e-01, Validation Loss: 8.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4572, Training Loss: 5.919e-01, Validation Loss: 8.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4573, Training Loss: 5.918e-01, Validation Loss: 8.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4574, Training Loss: 5.917e-01, Validation Loss: 8.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4575, Training Loss: 5.916e-01, Validation Loss: 8.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4576, Training Loss: 5.915e-01, Validation Loss: 8.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4577, Training Loss: 5.914e-01, Validation Loss: 8.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4578, Training Loss: 5.913e-01, Validation Loss: 8.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4579, Training Loss: 5.911e-01, Validation Loss: 8.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4580, Training Loss: 5.910e-01, Validation Loss: 8.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4581, Training Loss: 5.909e-01, Validation Loss: 8.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4582, Training Loss: 5.908e-01, Validation Loss: 8.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4583, Training Loss: 5.907e-01, Validation Loss: 8.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4584, Training Loss: 5.906e-01, Validation Loss: 8.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4585, Training Loss: 5.905e-01, Validation Loss: 8.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4586, Training Loss: 5.903e-01, Validation Loss: 8.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4587, Training Loss: 5.902e-01, Validation Loss: 8.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4588, Training Loss: 5.901e-01, Validation Loss: 8.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4589, Training Loss: 5.900e-01, Validation Loss: 8.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4590, Training Loss: 5.899e-01, Validation Loss: 8.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4591, Training Loss: 5.898e-01, Validation Loss: 8.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4592, Training Loss: 5.897e-01, Validation Loss: 8.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4593, Training Loss: 5.896e-01, Validation Loss: 8.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4594, Training Loss: 5.894e-01, Validation Loss: 8.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4595, Training Loss: 5.893e-01, Validation Loss: 8.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4596, Training Loss: 5.892e-01, Validation Loss: 8.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4597, Training Loss: 5.891e-01, Validation Loss: 8.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4598, Training Loss: 5.890e-01, Validation Loss: 8.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4599, Training Loss: 5.889e-01, Validation Loss: 8.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4600, Training Loss: 5.888e-01, Validation Loss: 8.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4601, Training Loss: 5.886e-01, Validation Loss: 8.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4602, Training Loss: 5.885e-01, Validation Loss: 8.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4603, Training Loss: 5.884e-01, Validation Loss: 8.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4604, Training Loss: 5.883e-01, Validation Loss: 8.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4605, Training Loss: 5.882e-01, Validation Loss: 8.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4606, Training Loss: 5.881e-01, Validation Loss: 8.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4607, Training Loss: 5.880e-01, Validation Loss: 8.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4608, Training Loss: 5.879e-01, Validation Loss: 8.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4609, Training Loss: 5.877e-01, Validation Loss: 8.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4610, Training Loss: 5.876e-01, Validation Loss: 8.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4611, Training Loss: 5.875e-01, Validation Loss: 8.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4612, Training Loss: 5.874e-01, Validation Loss: 8.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4613, Training Loss: 5.873e-01, Validation Loss: 8.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4614, Training Loss: 5.872e-01, Validation Loss: 8.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4615, Training Loss: 5.871e-01, Validation Loss: 8.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4616, Training Loss: 5.870e-01, Validation Loss: 8.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4617, Training Loss: 5.868e-01, Validation Loss: 8.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4618, Training Loss: 5.867e-01, Validation Loss: 8.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4619, Training Loss: 5.866e-01, Validation Loss: 8.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4620, Training Loss: 5.865e-01, Validation Loss: 8.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4621, Training Loss: 5.864e-01, Validation Loss: 8.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4622, Training Loss: 5.863e-01, Validation Loss: 8.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4623, Training Loss: 5.862e-01, Validation Loss: 8.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4624, Training Loss: 5.861e-01, Validation Loss: 8.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4625, Training Loss: 5.860e-01, Validation Loss: 8.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4626, Training Loss: 5.858e-01, Validation Loss: 8.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4627, Training Loss: 5.857e-01, Validation Loss: 8.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4628, Training Loss: 5.856e-01, Validation Loss: 8.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4629, Training Loss: 5.855e-01, Validation Loss: 8.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4630, Training Loss: 5.854e-01, Validation Loss: 8.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4631, Training Loss: 5.853e-01, Validation Loss: 8.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4632, Training Loss: 5.852e-01, Validation Loss: 8.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4633, Training Loss: 5.851e-01, Validation Loss: 8.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4634, Training Loss: 5.849e-01, Validation Loss: 8.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4635, Training Loss: 5.848e-01, Validation Loss: 8.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4636, Training Loss: 5.847e-01, Validation Loss: 8.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4637, Training Loss: 5.846e-01, Validation Loss: 8.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4638, Training Loss: 5.845e-01, Validation Loss: 8.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4639, Training Loss: 5.844e-01, Validation Loss: 8.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4640, Training Loss: 5.843e-01, Validation Loss: 8.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4641, Training Loss: 5.842e-01, Validation Loss: 8.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4642, Training Loss: 5.841e-01, Validation Loss: 8.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4643, Training Loss: 5.839e-01, Validation Loss: 8.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4644, Training Loss: 5.838e-01, Validation Loss: 8.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4645, Training Loss: 5.837e-01, Validation Loss: 8.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4646, Training Loss: 5.836e-01, Validation Loss: 8.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4647, Training Loss: 5.835e-01, Validation Loss: 8.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4648, Training Loss: 5.834e-01, Validation Loss: 8.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4649, Training Loss: 5.833e-01, Validation Loss: 8.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4650, Training Loss: 5.832e-01, Validation Loss: 8.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4651, Training Loss: 5.831e-01, Validation Loss: 8.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4652, Training Loss: 5.829e-01, Validation Loss: 8.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4653, Training Loss: 5.828e-01, Validation Loss: 8.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4654, Training Loss: 5.827e-01, Validation Loss: 8.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4655, Training Loss: 5.826e-01, Validation Loss: 8.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4656, Training Loss: 5.825e-01, Validation Loss: 8.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4657, Training Loss: 5.824e-01, Validation Loss: 8.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4658, Training Loss: 5.823e-01, Validation Loss: 8.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4659, Training Loss: 5.822e-01, Validation Loss: 8.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4660, Training Loss: 5.821e-01, Validation Loss: 8.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4661, Training Loss: 5.819e-01, Validation Loss: 8.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4662, Training Loss: 5.818e-01, Validation Loss: 8.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4663, Training Loss: 5.817e-01, Validation Loss: 8.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4664, Training Loss: 5.816e-01, Validation Loss: 8.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4665, Training Loss: 5.815e-01, Validation Loss: 8.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4666, Training Loss: 5.814e-01, Validation Loss: 8.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4667, Training Loss: 5.813e-01, Validation Loss: 8.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4668, Training Loss: 5.812e-01, Validation Loss: 8.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4669, Training Loss: 5.811e-01, Validation Loss: 8.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4670, Training Loss: 5.810e-01, Validation Loss: 8.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4671, Training Loss: 5.808e-01, Validation Loss: 8.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4672, Training Loss: 5.807e-01, Validation Loss: 8.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4673, Training Loss: 5.806e-01, Validation Loss: 8.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4674, Training Loss: 5.805e-01, Validation Loss: 8.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4675, Training Loss: 5.804e-01, Validation Loss: 8.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4676, Training Loss: 5.803e-01, Validation Loss: 8.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4677, Training Loss: 5.802e-01, Validation Loss: 8.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4678, Training Loss: 5.801e-01, Validation Loss: 8.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4679, Training Loss: 5.800e-01, Validation Loss: 8.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4680, Training Loss: 5.799e-01, Validation Loss: 8.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4681, Training Loss: 5.797e-01, Validation Loss: 8.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4682, Training Loss: 5.796e-01, Validation Loss: 8.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4683, Training Loss: 5.795e-01, Validation Loss: 8.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4684, Training Loss: 5.794e-01, Validation Loss: 8.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4685, Training Loss: 5.793e-01, Validation Loss: 8.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4686, Training Loss: 5.792e-01, Validation Loss: 8.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4687, Training Loss: 5.791e-01, Validation Loss: 8.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4688, Training Loss: 5.790e-01, Validation Loss: 8.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4689, Training Loss: 5.789e-01, Validation Loss: 8.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4690, Training Loss: 5.788e-01, Validation Loss: 8.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4691, Training Loss: 5.787e-01, Validation Loss: 8.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4692, Training Loss: 5.785e-01, Validation Loss: 8.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4693, Training Loss: 5.784e-01, Validation Loss: 8.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4694, Training Loss: 5.783e-01, Validation Loss: 8.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4695, Training Loss: 5.782e-01, Validation Loss: 8.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4696, Training Loss: 5.781e-01, Validation Loss: 8.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4697, Training Loss: 5.780e-01, Validation Loss: 8.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4698, Training Loss: 5.779e-01, Validation Loss: 8.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4699, Training Loss: 5.778e-01, Validation Loss: 8.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4700, Training Loss: 5.777e-01, Validation Loss: 8.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4701, Training Loss: 5.776e-01, Validation Loss: 8.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4702, Training Loss: 5.774e-01, Validation Loss: 8.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4703, Training Loss: 5.773e-01, Validation Loss: 8.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4704, Training Loss: 5.772e-01, Validation Loss: 8.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4705, Training Loss: 5.771e-01, Validation Loss: 8.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4706, Training Loss: 5.770e-01, Validation Loss: 8.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4707, Training Loss: 5.769e-01, Validation Loss: 8.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4708, Training Loss: 5.768e-01, Validation Loss: 8.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4709, Training Loss: 5.767e-01, Validation Loss: 8.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4710, Training Loss: 5.766e-01, Validation Loss: 8.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4711, Training Loss: 5.765e-01, Validation Loss: 8.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4712, Training Loss: 5.764e-01, Validation Loss: 8.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4713, Training Loss: 5.763e-01, Validation Loss: 8.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4714, Training Loss: 5.761e-01, Validation Loss: 8.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4715, Training Loss: 5.760e-01, Validation Loss: 8.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4716, Training Loss: 5.759e-01, Validation Loss: 8.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4717, Training Loss: 5.758e-01, Validation Loss: 8.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4718, Training Loss: 5.757e-01, Validation Loss: 8.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4719, Training Loss: 5.756e-01, Validation Loss: 8.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4720, Training Loss: 5.755e-01, Validation Loss: 8.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4721, Training Loss: 5.754e-01, Validation Loss: 8.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4722, Training Loss: 5.753e-01, Validation Loss: 8.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4723, Training Loss: 5.752e-01, Validation Loss: 8.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4724, Training Loss: 5.751e-01, Validation Loss: 8.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4725, Training Loss: 5.750e-01, Validation Loss: 8.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4726, Training Loss: 5.748e-01, Validation Loss: 8.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4727, Training Loss: 5.747e-01, Validation Loss: 8.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4728, Training Loss: 5.746e-01, Validation Loss: 8.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4729, Training Loss: 5.745e-01, Validation Loss: 8.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4730, Training Loss: 5.744e-01, Validation Loss: 8.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4731, Training Loss: 5.743e-01, Validation Loss: 8.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4732, Training Loss: 5.742e-01, Validation Loss: 8.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4733, Training Loss: 5.741e-01, Validation Loss: 8.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4734, Training Loss: 5.740e-01, Validation Loss: 8.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4735, Training Loss: 5.739e-01, Validation Loss: 8.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4736, Training Loss: 5.738e-01, Validation Loss: 8.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4737, Training Loss: 5.737e-01, Validation Loss: 8.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4738, Training Loss: 5.735e-01, Validation Loss: 8.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4739, Training Loss: 5.734e-01, Validation Loss: 8.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4740, Training Loss: 5.733e-01, Validation Loss: 8.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4741, Training Loss: 5.732e-01, Validation Loss: 8.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4742, Training Loss: 5.731e-01, Validation Loss: 8.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4743, Training Loss: 5.730e-01, Validation Loss: 8.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4744, Training Loss: 5.729e-01, Validation Loss: 8.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4745, Training Loss: 5.728e-01, Validation Loss: 8.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4746, Training Loss: 5.727e-01, Validation Loss: 8.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4747, Training Loss: 5.726e-01, Validation Loss: 8.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4748, Training Loss: 5.725e-01, Validation Loss: 8.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4749, Training Loss: 5.724e-01, Validation Loss: 8.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4750, Training Loss: 5.723e-01, Validation Loss: 8.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4751, Training Loss: 5.722e-01, Validation Loss: 8.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4752, Training Loss: 5.720e-01, Validation Loss: 8.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4753, Training Loss: 5.719e-01, Validation Loss: 8.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4754, Training Loss: 5.718e-01, Validation Loss: 8.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4755, Training Loss: 5.717e-01, Validation Loss: 8.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4756, Training Loss: 5.716e-01, Validation Loss: 8.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4757, Training Loss: 5.715e-01, Validation Loss: 8.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4758, Training Loss: 5.714e-01, Validation Loss: 8.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4759, Training Loss: 5.713e-01, Validation Loss: 8.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4760, Training Loss: 5.712e-01, Validation Loss: 8.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4761, Training Loss: 5.711e-01, Validation Loss: 8.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4762, Training Loss: 5.710e-01, Validation Loss: 8.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4763, Training Loss: 5.709e-01, Validation Loss: 8.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4764, Training Loss: 5.708e-01, Validation Loss: 8.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4765, Training Loss: 5.707e-01, Validation Loss: 8.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4766, Training Loss: 5.705e-01, Validation Loss: 8.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4767, Training Loss: 5.704e-01, Validation Loss: 8.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4768, Training Loss: 5.703e-01, Validation Loss: 8.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4769, Training Loss: 5.702e-01, Validation Loss: 8.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4770, Training Loss: 5.701e-01, Validation Loss: 8.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4771, Training Loss: 5.700e-01, Validation Loss: 8.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4772, Training Loss: 5.699e-01, Validation Loss: 8.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4773, Training Loss: 5.698e-01, Validation Loss: 8.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4774, Training Loss: 5.697e-01, Validation Loss: 8.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4775, Training Loss: 5.696e-01, Validation Loss: 8.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4776, Training Loss: 5.695e-01, Validation Loss: 8.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4777, Training Loss: 5.694e-01, Validation Loss: 8.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4778, Training Loss: 5.693e-01, Validation Loss: 8.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4779, Training Loss: 5.692e-01, Validation Loss: 8.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4780, Training Loss: 5.691e-01, Validation Loss: 8.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4781, Training Loss: 5.690e-01, Validation Loss: 8.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4782, Training Loss: 5.688e-01, Validation Loss: 8.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4783, Training Loss: 5.687e-01, Validation Loss: 8.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4784, Training Loss: 5.686e-01, Validation Loss: 8.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4785, Training Loss: 5.685e-01, Validation Loss: 8.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4786, Training Loss: 5.684e-01, Validation Loss: 8.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4787, Training Loss: 5.683e-01, Validation Loss: 8.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4788, Training Loss: 5.682e-01, Validation Loss: 8.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4789, Training Loss: 5.681e-01, Validation Loss: 8.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4790, Training Loss: 5.680e-01, Validation Loss: 8.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4791, Training Loss: 5.679e-01, Validation Loss: 8.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4792, Training Loss: 5.678e-01, Validation Loss: 8.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4793, Training Loss: 5.677e-01, Validation Loss: 8.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4794, Training Loss: 5.676e-01, Validation Loss: 8.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4795, Training Loss: 5.675e-01, Validation Loss: 8.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4796, Training Loss: 5.674e-01, Validation Loss: 8.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4797, Training Loss: 5.673e-01, Validation Loss: 8.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4798, Training Loss: 5.672e-01, Validation Loss: 8.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4799, Training Loss: 5.670e-01, Validation Loss: 8.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4800, Training Loss: 5.669e-01, Validation Loss: 8.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4801, Training Loss: 5.668e-01, Validation Loss: 8.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4802, Training Loss: 5.667e-01, Validation Loss: 8.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4803, Training Loss: 5.666e-01, Validation Loss: 8.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4804, Training Loss: 5.665e-01, Validation Loss: 8.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4805, Training Loss: 5.664e-01, Validation Loss: 8.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4806, Training Loss: 5.663e-01, Validation Loss: 8.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4807, Training Loss: 5.662e-01, Validation Loss: 8.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4808, Training Loss: 5.661e-01, Validation Loss: 8.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4809, Training Loss: 5.660e-01, Validation Loss: 8.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4810, Training Loss: 5.659e-01, Validation Loss: 8.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4811, Training Loss: 5.658e-01, Validation Loss: 8.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4812, Training Loss: 5.657e-01, Validation Loss: 8.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4813, Training Loss: 5.656e-01, Validation Loss: 8.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4814, Training Loss: 5.655e-01, Validation Loss: 8.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4815, Training Loss: 5.654e-01, Validation Loss: 8.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4816, Training Loss: 5.653e-01, Validation Loss: 8.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4817, Training Loss: 5.652e-01, Validation Loss: 8.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4818, Training Loss: 5.651e-01, Validation Loss: 8.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4819, Training Loss: 5.649e-01, Validation Loss: 8.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4820, Training Loss: 5.648e-01, Validation Loss: 8.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4821, Training Loss: 5.647e-01, Validation Loss: 8.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4822, Training Loss: 5.646e-01, Validation Loss: 8.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4823, Training Loss: 5.645e-01, Validation Loss: 8.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4824, Training Loss: 5.644e-01, Validation Loss: 8.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4825, Training Loss: 5.643e-01, Validation Loss: 8.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4826, Training Loss: 5.642e-01, Validation Loss: 8.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4827, Training Loss: 5.641e-01, Validation Loss: 8.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4828, Training Loss: 5.640e-01, Validation Loss: 8.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4829, Training Loss: 5.639e-01, Validation Loss: 8.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4830, Training Loss: 5.638e-01, Validation Loss: 8.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4831, Training Loss: 5.637e-01, Validation Loss: 8.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4832, Training Loss: 5.636e-01, Validation Loss: 8.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4833, Training Loss: 5.635e-01, Validation Loss: 8.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4834, Training Loss: 5.634e-01, Validation Loss: 8.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4835, Training Loss: 5.633e-01, Validation Loss: 8.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4836, Training Loss: 5.632e-01, Validation Loss: 8.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4837, Training Loss: 5.631e-01, Validation Loss: 8.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4838, Training Loss: 5.630e-01, Validation Loss: 8.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4839, Training Loss: 5.629e-01, Validation Loss: 8.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4840, Training Loss: 5.628e-01, Validation Loss: 8.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4841, Training Loss: 5.627e-01, Validation Loss: 8.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4842, Training Loss: 5.625e-01, Validation Loss: 8.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4843, Training Loss: 5.624e-01, Validation Loss: 8.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4844, Training Loss: 5.623e-01, Validation Loss: 8.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4845, Training Loss: 5.622e-01, Validation Loss: 8.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4846, Training Loss: 5.621e-01, Validation Loss: 8.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4847, Training Loss: 5.620e-01, Validation Loss: 8.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4848, Training Loss: 5.619e-01, Validation Loss: 8.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4849, Training Loss: 5.618e-01, Validation Loss: 8.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4850, Training Loss: 5.617e-01, Validation Loss: 8.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4851, Training Loss: 5.616e-01, Validation Loss: 8.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4852, Training Loss: 5.615e-01, Validation Loss: 8.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4853, Training Loss: 5.614e-01, Validation Loss: 8.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4854, Training Loss: 5.613e-01, Validation Loss: 8.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4855, Training Loss: 5.612e-01, Validation Loss: 8.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4856, Training Loss: 5.611e-01, Validation Loss: 8.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4857, Training Loss: 5.610e-01, Validation Loss: 8.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4858, Training Loss: 5.609e-01, Validation Loss: 8.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4859, Training Loss: 5.608e-01, Validation Loss: 8.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4860, Training Loss: 5.607e-01, Validation Loss: 8.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4861, Training Loss: 5.606e-01, Validation Loss: 8.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4862, Training Loss: 5.605e-01, Validation Loss: 8.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4863, Training Loss: 5.604e-01, Validation Loss: 8.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4864, Training Loss: 5.603e-01, Validation Loss: 8.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4865, Training Loss: 5.602e-01, Validation Loss: 8.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4866, Training Loss: 5.601e-01, Validation Loss: 8.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4867, Training Loss: 5.600e-01, Validation Loss: 8.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4868, Training Loss: 5.599e-01, Validation Loss: 8.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4869, Training Loss: 5.598e-01, Validation Loss: 8.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4870, Training Loss: 5.597e-01, Validation Loss: 8.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4871, Training Loss: 5.595e-01, Validation Loss: 8.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4872, Training Loss: 5.594e-01, Validation Loss: 8.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4873, Training Loss: 5.593e-01, Validation Loss: 8.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4874, Training Loss: 5.592e-01, Validation Loss: 8.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4875, Training Loss: 5.591e-01, Validation Loss: 8.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4876, Training Loss: 5.590e-01, Validation Loss: 8.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4877, Training Loss: 5.589e-01, Validation Loss: 8.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4878, Training Loss: 5.588e-01, Validation Loss: 8.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4879, Training Loss: 5.587e-01, Validation Loss: 8.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4880, Training Loss: 5.586e-01, Validation Loss: 8.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4881, Training Loss: 5.585e-01, Validation Loss: 8.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4882, Training Loss: 5.584e-01, Validation Loss: 8.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4883, Training Loss: 5.583e-01, Validation Loss: 8.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4884, Training Loss: 5.582e-01, Validation Loss: 8.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4885, Training Loss: 5.581e-01, Validation Loss: 8.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4886, Training Loss: 5.580e-01, Validation Loss: 8.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4887, Training Loss: 5.579e-01, Validation Loss: 8.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4888, Training Loss: 5.578e-01, Validation Loss: 8.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4889, Training Loss: 5.577e-01, Validation Loss: 8.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4890, Training Loss: 5.576e-01, Validation Loss: 8.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4891, Training Loss: 5.575e-01, Validation Loss: 8.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4892, Training Loss: 5.574e-01, Validation Loss: 8.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4893, Training Loss: 5.573e-01, Validation Loss: 8.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4894, Training Loss: 5.572e-01, Validation Loss: 8.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4895, Training Loss: 5.571e-01, Validation Loss: 8.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4896, Training Loss: 5.570e-01, Validation Loss: 8.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4897, Training Loss: 5.569e-01, Validation Loss: 8.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4898, Training Loss: 5.568e-01, Validation Loss: 8.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4899, Training Loss: 5.567e-01, Validation Loss: 8.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4900, Training Loss: 5.566e-01, Validation Loss: 8.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4901, Training Loss: 5.565e-01, Validation Loss: 8.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4902, Training Loss: 5.564e-01, Validation Loss: 8.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4903, Training Loss: 5.563e-01, Validation Loss: 8.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4904, Training Loss: 5.562e-01, Validation Loss: 8.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4905, Training Loss: 5.561e-01, Validation Loss: 8.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4906, Training Loss: 5.560e-01, Validation Loss: 8.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4907, Training Loss: 5.559e-01, Validation Loss: 8.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4908, Training Loss: 5.558e-01, Validation Loss: 8.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4909, Training Loss: 5.557e-01, Validation Loss: 8.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4910, Training Loss: 5.556e-01, Validation Loss: 8.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4911, Training Loss: 5.555e-01, Validation Loss: 8.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4912, Training Loss: 5.554e-01, Validation Loss: 8.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4913, Training Loss: 5.553e-01, Validation Loss: 8.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4914, Training Loss: 5.552e-01, Validation Loss: 8.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4915, Training Loss: 5.551e-01, Validation Loss: 8.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4916, Training Loss: 5.550e-01, Validation Loss: 8.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4917, Training Loss: 5.549e-01, Validation Loss: 8.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4918, Training Loss: 5.548e-01, Validation Loss: 8.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4919, Training Loss: 5.547e-01, Validation Loss: 8.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4920, Training Loss: 5.545e-01, Validation Loss: 8.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4921, Training Loss: 5.544e-01, Validation Loss: 8.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4922, Training Loss: 5.543e-01, Validation Loss: 8.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4923, Training Loss: 5.542e-01, Validation Loss: 8.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4924, Training Loss: 5.541e-01, Validation Loss: 8.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4925, Training Loss: 5.540e-01, Validation Loss: 8.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4926, Training Loss: 5.539e-01, Validation Loss: 8.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4927, Training Loss: 5.538e-01, Validation Loss: 8.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4928, Training Loss: 5.537e-01, Validation Loss: 8.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4929, Training Loss: 5.536e-01, Validation Loss: 8.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4930, Training Loss: 5.535e-01, Validation Loss: 8.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4931, Training Loss: 5.534e-01, Validation Loss: 8.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4932, Training Loss: 5.533e-01, Validation Loss: 8.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4933, Training Loss: 5.532e-01, Validation Loss: 8.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4934, Training Loss: 5.531e-01, Validation Loss: 8.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4935, Training Loss: 5.530e-01, Validation Loss: 8.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4936, Training Loss: 5.529e-01, Validation Loss: 8.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4937, Training Loss: 5.528e-01, Validation Loss: 8.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4938, Training Loss: 5.527e-01, Validation Loss: 8.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4939, Training Loss: 5.526e-01, Validation Loss: 8.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4940, Training Loss: 5.525e-01, Validation Loss: 8.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4941, Training Loss: 5.524e-01, Validation Loss: 8.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4942, Training Loss: 5.523e-01, Validation Loss: 8.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4943, Training Loss: 5.522e-01, Validation Loss: 8.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4944, Training Loss: 5.521e-01, Validation Loss: 8.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4945, Training Loss: 5.520e-01, Validation Loss: 8.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4946, Training Loss: 5.519e-01, Validation Loss: 8.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4947, Training Loss: 5.518e-01, Validation Loss: 8.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4948, Training Loss: 5.517e-01, Validation Loss: 8.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4949, Training Loss: 5.516e-01, Validation Loss: 8.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4950, Training Loss: 5.515e-01, Validation Loss: 8.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4951, Training Loss: 5.514e-01, Validation Loss: 8.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4952, Training Loss: 5.513e-01, Validation Loss: 8.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4953, Training Loss: 5.512e-01, Validation Loss: 8.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4954, Training Loss: 5.511e-01, Validation Loss: 8.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4955, Training Loss: 5.510e-01, Validation Loss: 8.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4956, Training Loss: 5.509e-01, Validation Loss: 8.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4957, Training Loss: 5.508e-01, Validation Loss: 8.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4958, Training Loss: 5.507e-01, Validation Loss: 8.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4959, Training Loss: 5.506e-01, Validation Loss: 8.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4960, Training Loss: 5.505e-01, Validation Loss: 8.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4961, Training Loss: 5.504e-01, Validation Loss: 8.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4962, Training Loss: 5.503e-01, Validation Loss: 8.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4963, Training Loss: 5.502e-01, Validation Loss: 8.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4964, Training Loss: 5.501e-01, Validation Loss: 8.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4965, Training Loss: 5.500e-01, Validation Loss: 8.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4966, Training Loss: 5.499e-01, Validation Loss: 8.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4967, Training Loss: 5.498e-01, Validation Loss: 8.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4968, Training Loss: 5.497e-01, Validation Loss: 8.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4969, Training Loss: 5.496e-01, Validation Loss: 8.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4970, Training Loss: 5.495e-01, Validation Loss: 8.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4971, Training Loss: 5.494e-01, Validation Loss: 8.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4972, Training Loss: 5.493e-01, Validation Loss: 8.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4973, Training Loss: 5.492e-01, Validation Loss: 8.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4974, Training Loss: 5.491e-01, Validation Loss: 8.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4975, Training Loss: 5.490e-01, Validation Loss: 8.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4976, Training Loss: 5.489e-01, Validation Loss: 8.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4977, Training Loss: 5.488e-01, Validation Loss: 8.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4978, Training Loss: 5.487e-01, Validation Loss: 8.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4979, Training Loss: 5.486e-01, Validation Loss: 8.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4980, Training Loss: 5.485e-01, Validation Loss: 8.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4981, Training Loss: 5.484e-01, Validation Loss: 8.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4982, Training Loss: 5.483e-01, Validation Loss: 8.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4983, Training Loss: 5.482e-01, Validation Loss: 8.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4984, Training Loss: 5.481e-01, Validation Loss: 8.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4985, Training Loss: 5.480e-01, Validation Loss: 8.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4986, Training Loss: 5.479e-01, Validation Loss: 8.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4987, Training Loss: 5.478e-01, Validation Loss: 8.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4988, Training Loss: 5.477e-01, Validation Loss: 8.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4989, Training Loss: 5.476e-01, Validation Loss: 8.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4990, Training Loss: 5.475e-01, Validation Loss: 8.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4991, Training Loss: 5.474e-01, Validation Loss: 8.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4992, Training Loss: 5.473e-01, Validation Loss: 8.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4993, Training Loss: 5.472e-01, Validation Loss: 8.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4994, Training Loss: 5.471e-01, Validation Loss: 8.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4995, Training Loss: 5.470e-01, Validation Loss: 8.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4996, Training Loss: 5.469e-01, Validation Loss: 8.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4997, Training Loss: 5.468e-01, Validation Loss: 8.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4998, Training Loss: 5.467e-01, Validation Loss: 8.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 4999, Training Loss: 5.466e-01, Validation Loss: 8.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5000, Training Loss: 5.465e-01, Validation Loss: 8.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5001, Training Loss: 5.464e-01, Validation Loss: 8.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5002, Training Loss: 5.463e-01, Validation Loss: 8.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5003, Training Loss: 5.462e-01, Validation Loss: 8.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5004, Training Loss: 5.461e-01, Validation Loss: 8.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5005, Training Loss: 5.460e-01, Validation Loss: 8.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5006, Training Loss: 5.460e-01, Validation Loss: 8.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5007, Training Loss: 5.459e-01, Validation Loss: 8.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5008, Training Loss: 5.458e-01, Validation Loss: 8.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5009, Training Loss: 5.457e-01, Validation Loss: 8.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5010, Training Loss: 5.456e-01, Validation Loss: 8.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5011, Training Loss: 5.455e-01, Validation Loss: 8.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5012, Training Loss: 5.454e-01, Validation Loss: 8.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5013, Training Loss: 5.453e-01, Validation Loss: 8.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5014, Training Loss: 5.452e-01, Validation Loss: 8.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5015, Training Loss: 5.451e-01, Validation Loss: 8.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5016, Training Loss: 5.450e-01, Validation Loss: 8.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5017, Training Loss: 5.449e-01, Validation Loss: 8.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5018, Training Loss: 5.448e-01, Validation Loss: 8.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5019, Training Loss: 5.447e-01, Validation Loss: 8.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5020, Training Loss: 5.446e-01, Validation Loss: 8.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5021, Training Loss: 5.445e-01, Validation Loss: 8.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5022, Training Loss: 5.444e-01, Validation Loss: 8.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5023, Training Loss: 5.443e-01, Validation Loss: 8.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5024, Training Loss: 5.442e-01, Validation Loss: 8.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5025, Training Loss: 5.441e-01, Validation Loss: 8.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5026, Training Loss: 5.440e-01, Validation Loss: 8.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5027, Training Loss: 5.439e-01, Validation Loss: 8.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5028, Training Loss: 5.438e-01, Validation Loss: 8.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5029, Training Loss: 5.437e-01, Validation Loss: 8.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5030, Training Loss: 5.436e-01, Validation Loss: 8.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5031, Training Loss: 5.435e-01, Validation Loss: 8.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5032, Training Loss: 5.434e-01, Validation Loss: 8.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5033, Training Loss: 5.433e-01, Validation Loss: 8.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5034, Training Loss: 5.432e-01, Validation Loss: 8.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5035, Training Loss: 5.431e-01, Validation Loss: 8.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5036, Training Loss: 5.430e-01, Validation Loss: 8.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5037, Training Loss: 5.429e-01, Validation Loss: 8.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5038, Training Loss: 5.428e-01, Validation Loss: 8.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5039, Training Loss: 5.427e-01, Validation Loss: 8.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5040, Training Loss: 5.426e-01, Validation Loss: 8.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5041, Training Loss: 5.425e-01, Validation Loss: 8.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5042, Training Loss: 5.424e-01, Validation Loss: 8.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5043, Training Loss: 5.423e-01, Validation Loss: 8.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5044, Training Loss: 5.422e-01, Validation Loss: 8.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5045, Training Loss: 5.421e-01, Validation Loss: 8.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5046, Training Loss: 5.420e-01, Validation Loss: 8.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5047, Training Loss: 5.419e-01, Validation Loss: 8.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5048, Training Loss: 5.418e-01, Validation Loss: 8.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5049, Training Loss: 5.417e-01, Validation Loss: 8.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5050, Training Loss: 5.416e-01, Validation Loss: 8.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5051, Training Loss: 5.415e-01, Validation Loss: 8.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5052, Training Loss: 5.414e-01, Validation Loss: 8.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5053, Training Loss: 5.413e-01, Validation Loss: 8.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5054, Training Loss: 5.412e-01, Validation Loss: 8.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5055, Training Loss: 5.412e-01, Validation Loss: 8.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5056, Training Loss: 5.411e-01, Validation Loss: 8.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5057, Training Loss: 5.410e-01, Validation Loss: 8.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5058, Training Loss: 5.409e-01, Validation Loss: 8.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5059, Training Loss: 5.408e-01, Validation Loss: 8.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5060, Training Loss: 5.407e-01, Validation Loss: 8.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5061, Training Loss: 5.406e-01, Validation Loss: 8.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5062, Training Loss: 5.405e-01, Validation Loss: 8.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5063, Training Loss: 5.404e-01, Validation Loss: 8.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5064, Training Loss: 5.403e-01, Validation Loss: 8.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5065, Training Loss: 5.402e-01, Validation Loss: 8.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5066, Training Loss: 5.401e-01, Validation Loss: 8.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5067, Training Loss: 5.400e-01, Validation Loss: 8.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5068, Training Loss: 5.399e-01, Validation Loss: 8.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5069, Training Loss: 5.398e-01, Validation Loss: 8.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5070, Training Loss: 5.397e-01, Validation Loss: 8.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5071, Training Loss: 5.396e-01, Validation Loss: 8.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5072, Training Loss: 5.395e-01, Validation Loss: 8.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5073, Training Loss: 5.394e-01, Validation Loss: 8.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5074, Training Loss: 5.393e-01, Validation Loss: 8.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5075, Training Loss: 5.392e-01, Validation Loss: 8.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5076, Training Loss: 5.391e-01, Validation Loss: 8.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5077, Training Loss: 5.390e-01, Validation Loss: 8.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5078, Training Loss: 5.389e-01, Validation Loss: 8.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5079, Training Loss: 5.388e-01, Validation Loss: 8.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5080, Training Loss: 5.387e-01, Validation Loss: 8.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5081, Training Loss: 5.386e-01, Validation Loss: 8.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5082, Training Loss: 5.385e-01, Validation Loss: 8.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5083, Training Loss: 5.384e-01, Validation Loss: 8.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5084, Training Loss: 5.383e-01, Validation Loss: 8.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5085, Training Loss: 5.382e-01, Validation Loss: 8.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5086, Training Loss: 5.382e-01, Validation Loss: 8.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5087, Training Loss: 5.381e-01, Validation Loss: 8.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5088, Training Loss: 5.380e-01, Validation Loss: 8.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5089, Training Loss: 5.379e-01, Validation Loss: 8.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5090, Training Loss: 5.378e-01, Validation Loss: 8.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5091, Training Loss: 5.377e-01, Validation Loss: 8.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5092, Training Loss: 5.376e-01, Validation Loss: 8.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5093, Training Loss: 5.375e-01, Validation Loss: 8.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5094, Training Loss: 5.374e-01, Validation Loss: 8.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5095, Training Loss: 5.373e-01, Validation Loss: 8.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5096, Training Loss: 5.372e-01, Validation Loss: 8.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5097, Training Loss: 5.371e-01, Validation Loss: 8.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5098, Training Loss: 5.370e-01, Validation Loss: 8.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5099, Training Loss: 5.369e-01, Validation Loss: 8.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5100, Training Loss: 5.368e-01, Validation Loss: 8.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5101, Training Loss: 5.367e-01, Validation Loss: 8.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5102, Training Loss: 5.366e-01, Validation Loss: 8.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5103, Training Loss: 5.365e-01, Validation Loss: 8.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5104, Training Loss: 5.364e-01, Validation Loss: 8.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5105, Training Loss: 5.363e-01, Validation Loss: 8.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5106, Training Loss: 5.362e-01, Validation Loss: 8.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5107, Training Loss: 5.361e-01, Validation Loss: 8.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5108, Training Loss: 5.360e-01, Validation Loss: 8.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5109, Training Loss: 5.359e-01, Validation Loss: 8.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5110, Training Loss: 5.359e-01, Validation Loss: 8.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5111, Training Loss: 5.358e-01, Validation Loss: 8.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5112, Training Loss: 5.357e-01, Validation Loss: 8.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5113, Training Loss: 5.356e-01, Validation Loss: 8.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5114, Training Loss: 5.355e-01, Validation Loss: 8.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5115, Training Loss: 5.354e-01, Validation Loss: 8.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5116, Training Loss: 5.353e-01, Validation Loss: 8.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5117, Training Loss: 5.352e-01, Validation Loss: 8.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5118, Training Loss: 5.351e-01, Validation Loss: 8.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5119, Training Loss: 5.350e-01, Validation Loss: 8.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5120, Training Loss: 5.349e-01, Validation Loss: 8.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5121, Training Loss: 5.348e-01, Validation Loss: 8.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5122, Training Loss: 5.347e-01, Validation Loss: 8.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5123, Training Loss: 5.346e-01, Validation Loss: 8.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5124, Training Loss: 5.345e-01, Validation Loss: 8.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5125, Training Loss: 5.344e-01, Validation Loss: 8.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5126, Training Loss: 5.343e-01, Validation Loss: 8.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5127, Training Loss: 5.342e-01, Validation Loss: 8.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5128, Training Loss: 5.341e-01, Validation Loss: 8.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5129, Training Loss: 5.340e-01, Validation Loss: 8.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5130, Training Loss: 5.339e-01, Validation Loss: 8.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5131, Training Loss: 5.339e-01, Validation Loss: 8.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5132, Training Loss: 5.338e-01, Validation Loss: 8.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5133, Training Loss: 5.337e-01, Validation Loss: 8.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5134, Training Loss: 5.336e-01, Validation Loss: 8.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5135, Training Loss: 5.335e-01, Validation Loss: 8.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5136, Training Loss: 5.334e-01, Validation Loss: 8.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5137, Training Loss: 5.333e-01, Validation Loss: 8.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5138, Training Loss: 5.332e-01, Validation Loss: 8.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5139, Training Loss: 5.331e-01, Validation Loss: 8.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5140, Training Loss: 5.330e-01, Validation Loss: 8.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5141, Training Loss: 5.329e-01, Validation Loss: 8.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5142, Training Loss: 5.328e-01, Validation Loss: 8.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5143, Training Loss: 5.327e-01, Validation Loss: 8.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5144, Training Loss: 5.326e-01, Validation Loss: 8.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5145, Training Loss: 5.325e-01, Validation Loss: 8.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5146, Training Loss: 5.324e-01, Validation Loss: 8.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5147, Training Loss: 5.323e-01, Validation Loss: 8.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5148, Training Loss: 5.322e-01, Validation Loss: 8.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5149, Training Loss: 5.321e-01, Validation Loss: 8.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5150, Training Loss: 5.321e-01, Validation Loss: 8.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5151, Training Loss: 5.320e-01, Validation Loss: 8.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5152, Training Loss: 5.319e-01, Validation Loss: 8.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5153, Training Loss: 5.318e-01, Validation Loss: 8.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5154, Training Loss: 5.317e-01, Validation Loss: 8.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5155, Training Loss: 5.316e-01, Validation Loss: 8.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5156, Training Loss: 5.315e-01, Validation Loss: 8.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5157, Training Loss: 5.314e-01, Validation Loss: 8.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5158, Training Loss: 5.313e-01, Validation Loss: 8.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5159, Training Loss: 5.312e-01, Validation Loss: 8.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5160, Training Loss: 5.311e-01, Validation Loss: 8.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5161, Training Loss: 5.310e-01, Validation Loss: 8.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5162, Training Loss: 5.309e-01, Validation Loss: 8.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5163, Training Loss: 5.308e-01, Validation Loss: 8.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5164, Training Loss: 5.307e-01, Validation Loss: 8.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5165, Training Loss: 5.306e-01, Validation Loss: 8.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5166, Training Loss: 5.305e-01, Validation Loss: 8.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5167, Training Loss: 5.305e-01, Validation Loss: 8.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5168, Training Loss: 5.304e-01, Validation Loss: 8.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5169, Training Loss: 5.303e-01, Validation Loss: 8.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5170, Training Loss: 5.302e-01, Validation Loss: 8.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5171, Training Loss: 5.301e-01, Validation Loss: 8.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5172, Training Loss: 5.300e-01, Validation Loss: 8.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5173, Training Loss: 5.299e-01, Validation Loss: 8.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5174, Training Loss: 5.298e-01, Validation Loss: 8.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5175, Training Loss: 5.297e-01, Validation Loss: 8.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5176, Training Loss: 5.296e-01, Validation Loss: 8.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5177, Training Loss: 5.295e-01, Validation Loss: 8.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5178, Training Loss: 5.294e-01, Validation Loss: 8.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5179, Training Loss: 5.293e-01, Validation Loss: 8.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5180, Training Loss: 5.292e-01, Validation Loss: 8.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5181, Training Loss: 5.291e-01, Validation Loss: 8.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5182, Training Loss: 5.290e-01, Validation Loss: 8.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5183, Training Loss: 5.290e-01, Validation Loss: 8.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5184, Training Loss: 5.289e-01, Validation Loss: 8.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5185, Training Loss: 5.288e-01, Validation Loss: 8.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5186, Training Loss: 5.287e-01, Validation Loss: 8.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5187, Training Loss: 5.286e-01, Validation Loss: 8.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5188, Training Loss: 5.285e-01, Validation Loss: 8.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5189, Training Loss: 5.284e-01, Validation Loss: 8.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5190, Training Loss: 5.283e-01, Validation Loss: 8.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5191, Training Loss: 5.282e-01, Validation Loss: 8.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5192, Training Loss: 5.281e-01, Validation Loss: 8.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5193, Training Loss: 5.280e-01, Validation Loss: 8.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5194, Training Loss: 5.279e-01, Validation Loss: 8.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5195, Training Loss: 5.278e-01, Validation Loss: 8.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5196, Training Loss: 5.277e-01, Validation Loss: 8.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5197, Training Loss: 5.277e-01, Validation Loss: 8.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5198, Training Loss: 5.276e-01, Validation Loss: 8.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5199, Training Loss: 5.275e-01, Validation Loss: 8.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5200, Training Loss: 5.274e-01, Validation Loss: 8.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5201, Training Loss: 5.273e-01, Validation Loss: 8.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5202, Training Loss: 5.272e-01, Validation Loss: 8.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5203, Training Loss: 5.271e-01, Validation Loss: 8.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5204, Training Loss: 5.270e-01, Validation Loss: 8.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5205, Training Loss: 5.269e-01, Validation Loss: 8.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5206, Training Loss: 5.268e-01, Validation Loss: 8.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5207, Training Loss: 5.267e-01, Validation Loss: 8.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5208, Training Loss: 5.266e-01, Validation Loss: 8.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5209, Training Loss: 5.265e-01, Validation Loss: 8.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5210, Training Loss: 5.264e-01, Validation Loss: 8.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5211, Training Loss: 5.264e-01, Validation Loss: 8.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5212, Training Loss: 5.263e-01, Validation Loss: 8.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5213, Training Loss: 5.262e-01, Validation Loss: 8.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5214, Training Loss: 5.261e-01, Validation Loss: 8.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5215, Training Loss: 5.260e-01, Validation Loss: 8.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5216, Training Loss: 5.259e-01, Validation Loss: 8.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5217, Training Loss: 5.258e-01, Validation Loss: 8.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5218, Training Loss: 5.257e-01, Validation Loss: 8.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5219, Training Loss: 5.256e-01, Validation Loss: 8.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5220, Training Loss: 5.255e-01, Validation Loss: 8.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5221, Training Loss: 5.254e-01, Validation Loss: 8.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5222, Training Loss: 5.253e-01, Validation Loss: 8.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5223, Training Loss: 5.252e-01, Validation Loss: 8.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5224, Training Loss: 5.252e-01, Validation Loss: 8.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5225, Training Loss: 5.251e-01, Validation Loss: 8.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5226, Training Loss: 5.250e-01, Validation Loss: 8.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5227, Training Loss: 5.249e-01, Validation Loss: 8.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5228, Training Loss: 5.248e-01, Validation Loss: 8.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5229, Training Loss: 5.247e-01, Validation Loss: 8.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5230, Training Loss: 5.246e-01, Validation Loss: 8.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5231, Training Loss: 5.245e-01, Validation Loss: 8.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5232, Training Loss: 5.244e-01, Validation Loss: 8.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5233, Training Loss: 5.243e-01, Validation Loss: 8.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5234, Training Loss: 5.242e-01, Validation Loss: 8.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5235, Training Loss: 5.241e-01, Validation Loss: 8.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5236, Training Loss: 5.240e-01, Validation Loss: 8.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5237, Training Loss: 5.240e-01, Validation Loss: 8.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5238, Training Loss: 5.239e-01, Validation Loss: 8.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5239, Training Loss: 5.238e-01, Validation Loss: 8.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5240, Training Loss: 5.237e-01, Validation Loss: 8.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5241, Training Loss: 5.236e-01, Validation Loss: 8.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5242, Training Loss: 5.235e-01, Validation Loss: 8.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5243, Training Loss: 5.234e-01, Validation Loss: 8.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5244, Training Loss: 5.233e-01, Validation Loss: 8.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5245, Training Loss: 5.232e-01, Validation Loss: 8.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5246, Training Loss: 5.231e-01, Validation Loss: 8.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5247, Training Loss: 5.230e-01, Validation Loss: 8.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5248, Training Loss: 5.229e-01, Validation Loss: 8.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5249, Training Loss: 5.229e-01, Validation Loss: 8.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5250, Training Loss: 5.228e-01, Validation Loss: 8.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5251, Training Loss: 5.227e-01, Validation Loss: 8.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5252, Training Loss: 5.226e-01, Validation Loss: 8.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5253, Training Loss: 5.225e-01, Validation Loss: 8.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5254, Training Loss: 5.224e-01, Validation Loss: 8.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5255, Training Loss: 5.223e-01, Validation Loss: 8.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5256, Training Loss: 5.222e-01, Validation Loss: 8.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5257, Training Loss: 5.221e-01, Validation Loss: 8.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5258, Training Loss: 5.220e-01, Validation Loss: 8.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5259, Training Loss: 5.219e-01, Validation Loss: 8.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5260, Training Loss: 5.219e-01, Validation Loss: 8.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5261, Training Loss: 5.218e-01, Validation Loss: 8.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5262, Training Loss: 5.217e-01, Validation Loss: 8.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5263, Training Loss: 5.216e-01, Validation Loss: 8.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5264, Training Loss: 5.215e-01, Validation Loss: 8.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5265, Training Loss: 5.214e-01, Validation Loss: 8.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5266, Training Loss: 5.213e-01, Validation Loss: 8.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5267, Training Loss: 5.212e-01, Validation Loss: 8.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5268, Training Loss: 5.211e-01, Validation Loss: 8.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5269, Training Loss: 5.210e-01, Validation Loss: 8.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5270, Training Loss: 5.209e-01, Validation Loss: 8.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5271, Training Loss: 5.208e-01, Validation Loss: 8.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5272, Training Loss: 5.208e-01, Validation Loss: 8.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5273, Training Loss: 5.207e-01, Validation Loss: 8.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5274, Training Loss: 5.206e-01, Validation Loss: 8.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5275, Training Loss: 5.205e-01, Validation Loss: 8.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5276, Training Loss: 5.204e-01, Validation Loss: 8.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5277, Training Loss: 5.203e-01, Validation Loss: 8.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5278, Training Loss: 5.202e-01, Validation Loss: 8.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5279, Training Loss: 5.201e-01, Validation Loss: 8.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5280, Training Loss: 5.200e-01, Validation Loss: 8.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5281, Training Loss: 5.199e-01, Validation Loss: 8.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5282, Training Loss: 5.199e-01, Validation Loss: 8.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5283, Training Loss: 5.198e-01, Validation Loss: 8.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5284, Training Loss: 5.197e-01, Validation Loss: 8.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5285, Training Loss: 5.196e-01, Validation Loss: 8.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5286, Training Loss: 5.195e-01, Validation Loss: 8.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5287, Training Loss: 5.194e-01, Validation Loss: 8.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5288, Training Loss: 5.193e-01, Validation Loss: 8.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5289, Training Loss: 5.192e-01, Validation Loss: 8.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5290, Training Loss: 5.191e-01, Validation Loss: 8.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5291, Training Loss: 5.190e-01, Validation Loss: 8.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5292, Training Loss: 5.189e-01, Validation Loss: 8.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5293, Training Loss: 5.189e-01, Validation Loss: 8.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5294, Training Loss: 5.188e-01, Validation Loss: 8.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5295, Training Loss: 5.187e-01, Validation Loss: 8.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5296, Training Loss: 5.186e-01, Validation Loss: 8.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5297, Training Loss: 5.185e-01, Validation Loss: 8.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5298, Training Loss: 5.184e-01, Validation Loss: 8.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5299, Training Loss: 5.183e-01, Validation Loss: 8.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5300, Training Loss: 5.182e-01, Validation Loss: 8.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5301, Training Loss: 5.181e-01, Validation Loss: 8.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5302, Training Loss: 5.180e-01, Validation Loss: 8.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5303, Training Loss: 5.180e-01, Validation Loss: 8.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5304, Training Loss: 5.179e-01, Validation Loss: 8.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5305, Training Loss: 5.178e-01, Validation Loss: 8.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5306, Training Loss: 5.177e-01, Validation Loss: 8.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5307, Training Loss: 5.176e-01, Validation Loss: 8.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5308, Training Loss: 5.175e-01, Validation Loss: 8.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5309, Training Loss: 5.174e-01, Validation Loss: 8.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5310, Training Loss: 5.173e-01, Validation Loss: 8.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5311, Training Loss: 5.172e-01, Validation Loss: 8.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5312, Training Loss: 5.171e-01, Validation Loss: 8.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5313, Training Loss: 5.171e-01, Validation Loss: 8.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5314, Training Loss: 5.170e-01, Validation Loss: 8.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5315, Training Loss: 5.169e-01, Validation Loss: 8.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5316, Training Loss: 5.168e-01, Validation Loss: 8.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5317, Training Loss: 5.167e-01, Validation Loss: 8.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5318, Training Loss: 5.166e-01, Validation Loss: 8.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5319, Training Loss: 5.165e-01, Validation Loss: 8.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5320, Training Loss: 5.164e-01, Validation Loss: 8.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5321, Training Loss: 5.163e-01, Validation Loss: 8.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5322, Training Loss: 5.163e-01, Validation Loss: 8.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5323, Training Loss: 5.162e-01, Validation Loss: 8.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5324, Training Loss: 5.161e-01, Validation Loss: 8.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5325, Training Loss: 5.160e-01, Validation Loss: 8.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5326, Training Loss: 5.159e-01, Validation Loss: 8.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5327, Training Loss: 5.158e-01, Validation Loss: 8.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5328, Training Loss: 5.157e-01, Validation Loss: 8.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5329, Training Loss: 5.156e-01, Validation Loss: 8.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5330, Training Loss: 5.155e-01, Validation Loss: 8.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5331, Training Loss: 5.155e-01, Validation Loss: 8.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5332, Training Loss: 5.154e-01, Validation Loss: 8.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5333, Training Loss: 5.153e-01, Validation Loss: 8.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5334, Training Loss: 5.152e-01, Validation Loss: 8.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5335, Training Loss: 5.151e-01, Validation Loss: 8.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5336, Training Loss: 5.150e-01, Validation Loss: 8.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5337, Training Loss: 5.149e-01, Validation Loss: 8.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5338, Training Loss: 5.148e-01, Validation Loss: 8.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5339, Training Loss: 5.147e-01, Validation Loss: 8.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5340, Training Loss: 5.146e-01, Validation Loss: 8.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5341, Training Loss: 5.146e-01, Validation Loss: 8.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5342, Training Loss: 5.145e-01, Validation Loss: 8.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5343, Training Loss: 5.144e-01, Validation Loss: 8.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5344, Training Loss: 5.143e-01, Validation Loss: 8.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5345, Training Loss: 5.142e-01, Validation Loss: 8.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5346, Training Loss: 5.141e-01, Validation Loss: 8.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5347, Training Loss: 5.140e-01, Validation Loss: 8.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5348, Training Loss: 5.139e-01, Validation Loss: 8.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5349, Training Loss: 5.139e-01, Validation Loss: 8.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5350, Training Loss: 5.138e-01, Validation Loss: 8.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5351, Training Loss: 5.137e-01, Validation Loss: 8.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5352, Training Loss: 5.136e-01, Validation Loss: 8.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5353, Training Loss: 5.135e-01, Validation Loss: 8.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5354, Training Loss: 5.134e-01, Validation Loss: 8.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5355, Training Loss: 5.133e-01, Validation Loss: 8.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5356, Training Loss: 5.132e-01, Validation Loss: 8.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5357, Training Loss: 5.131e-01, Validation Loss: 8.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5358, Training Loss: 5.131e-01, Validation Loss: 8.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5359, Training Loss: 5.130e-01, Validation Loss: 8.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5360, Training Loss: 5.129e-01, Validation Loss: 8.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5361, Training Loss: 5.128e-01, Validation Loss: 8.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5362, Training Loss: 5.127e-01, Validation Loss: 8.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5363, Training Loss: 5.126e-01, Validation Loss: 8.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5364, Training Loss: 5.125e-01, Validation Loss: 8.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5365, Training Loss: 5.124e-01, Validation Loss: 8.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5366, Training Loss: 5.123e-01, Validation Loss: 8.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5367, Training Loss: 5.123e-01, Validation Loss: 8.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5368, Training Loss: 5.122e-01, Validation Loss: 8.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5369, Training Loss: 5.121e-01, Validation Loss: 8.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5370, Training Loss: 5.120e-01, Validation Loss: 8.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5371, Training Loss: 5.119e-01, Validation Loss: 8.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5372, Training Loss: 5.118e-01, Validation Loss: 8.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5373, Training Loss: 5.117e-01, Validation Loss: 8.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5374, Training Loss: 5.116e-01, Validation Loss: 8.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5375, Training Loss: 5.116e-01, Validation Loss: 8.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5376, Training Loss: 5.115e-01, Validation Loss: 8.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5377, Training Loss: 5.114e-01, Validation Loss: 8.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5378, Training Loss: 5.113e-01, Validation Loss: 8.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5379, Training Loss: 5.112e-01, Validation Loss: 8.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5380, Training Loss: 5.111e-01, Validation Loss: 8.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5381, Training Loss: 5.110e-01, Validation Loss: 8.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5382, Training Loss: 5.109e-01, Validation Loss: 8.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5383, Training Loss: 5.109e-01, Validation Loss: 8.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5384, Training Loss: 5.108e-01, Validation Loss: 8.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5385, Training Loss: 5.107e-01, Validation Loss: 8.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5386, Training Loss: 5.106e-01, Validation Loss: 8.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5387, Training Loss: 5.105e-01, Validation Loss: 8.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5388, Training Loss: 5.104e-01, Validation Loss: 8.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5389, Training Loss: 5.103e-01, Validation Loss: 8.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5390, Training Loss: 5.102e-01, Validation Loss: 8.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5391, Training Loss: 5.102e-01, Validation Loss: 8.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5392, Training Loss: 5.101e-01, Validation Loss: 8.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5393, Training Loss: 5.100e-01, Validation Loss: 8.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5394, Training Loss: 5.099e-01, Validation Loss: 8.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5395, Training Loss: 5.098e-01, Validation Loss: 8.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5396, Training Loss: 5.097e-01, Validation Loss: 8.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5397, Training Loss: 5.096e-01, Validation Loss: 8.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5398, Training Loss: 5.095e-01, Validation Loss: 8.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5399, Training Loss: 5.095e-01, Validation Loss: 8.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5400, Training Loss: 5.094e-01, Validation Loss: 8.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5401, Training Loss: 5.093e-01, Validation Loss: 8.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5402, Training Loss: 5.092e-01, Validation Loss: 8.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5403, Training Loss: 5.091e-01, Validation Loss: 8.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5404, Training Loss: 5.090e-01, Validation Loss: 8.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5405, Training Loss: 5.089e-01, Validation Loss: 8.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5406, Training Loss: 5.088e-01, Validation Loss: 8.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5407, Training Loss: 5.088e-01, Validation Loss: 8.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5408, Training Loss: 5.087e-01, Validation Loss: 8.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5409, Training Loss: 5.086e-01, Validation Loss: 8.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5410, Training Loss: 5.085e-01, Validation Loss: 8.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5411, Training Loss: 5.084e-01, Validation Loss: 8.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5412, Training Loss: 5.083e-01, Validation Loss: 8.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5413, Training Loss: 5.082e-01, Validation Loss: 8.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5414, Training Loss: 5.081e-01, Validation Loss: 8.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5415, Training Loss: 5.081e-01, Validation Loss: 8.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5416, Training Loss: 5.080e-01, Validation Loss: 8.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5417, Training Loss: 5.079e-01, Validation Loss: 8.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5418, Training Loss: 5.078e-01, Validation Loss: 8.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5419, Training Loss: 5.077e-01, Validation Loss: 8.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5420, Training Loss: 5.076e-01, Validation Loss: 8.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5421, Training Loss: 5.075e-01, Validation Loss: 8.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5422, Training Loss: 5.075e-01, Validation Loss: 8.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5423, Training Loss: 5.074e-01, Validation Loss: 8.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5424, Training Loss: 5.073e-01, Validation Loss: 8.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5425, Training Loss: 5.072e-01, Validation Loss: 8.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5426, Training Loss: 5.071e-01, Validation Loss: 8.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5427, Training Loss: 5.070e-01, Validation Loss: 8.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5428, Training Loss: 5.069e-01, Validation Loss: 8.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5429, Training Loss: 5.068e-01, Validation Loss: 8.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5430, Training Loss: 5.068e-01, Validation Loss: 8.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5431, Training Loss: 5.067e-01, Validation Loss: 8.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5432, Training Loss: 5.066e-01, Validation Loss: 8.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5433, Training Loss: 5.065e-01, Validation Loss: 8.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5434, Training Loss: 5.064e-01, Validation Loss: 8.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5435, Training Loss: 5.063e-01, Validation Loss: 8.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5436, Training Loss: 5.062e-01, Validation Loss: 8.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5437, Training Loss: 5.062e-01, Validation Loss: 8.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5438, Training Loss: 5.061e-01, Validation Loss: 8.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5439, Training Loss: 5.060e-01, Validation Loss: 8.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5440, Training Loss: 5.059e-01, Validation Loss: 8.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5441, Training Loss: 5.058e-01, Validation Loss: 8.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5442, Training Loss: 5.057e-01, Validation Loss: 8.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5443, Training Loss: 5.056e-01, Validation Loss: 8.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5444, Training Loss: 5.056e-01, Validation Loss: 8.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5445, Training Loss: 5.055e-01, Validation Loss: 8.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5446, Training Loss: 5.054e-01, Validation Loss: 8.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5447, Training Loss: 5.053e-01, Validation Loss: 8.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5448, Training Loss: 5.052e-01, Validation Loss: 8.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5449, Training Loss: 5.051e-01, Validation Loss: 8.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5450, Training Loss: 5.050e-01, Validation Loss: 8.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5451, Training Loss: 5.049e-01, Validation Loss: 8.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5452, Training Loss: 5.049e-01, Validation Loss: 8.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5453, Training Loss: 5.048e-01, Validation Loss: 8.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5454, Training Loss: 5.047e-01, Validation Loss: 8.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5455, Training Loss: 5.046e-01, Validation Loss: 8.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5456, Training Loss: 5.045e-01, Validation Loss: 8.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5457, Training Loss: 5.044e-01, Validation Loss: 8.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5458, Training Loss: 5.043e-01, Validation Loss: 8.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5459, Training Loss: 5.043e-01, Validation Loss: 8.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5460, Training Loss: 5.042e-01, Validation Loss: 8.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5461, Training Loss: 5.041e-01, Validation Loss: 8.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5462, Training Loss: 5.040e-01, Validation Loss: 8.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5463, Training Loss: 5.039e-01, Validation Loss: 8.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5464, Training Loss: 5.038e-01, Validation Loss: 8.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5465, Training Loss: 5.037e-01, Validation Loss: 8.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5466, Training Loss: 5.037e-01, Validation Loss: 8.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5467, Training Loss: 5.036e-01, Validation Loss: 8.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5468, Training Loss: 5.035e-01, Validation Loss: 8.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5469, Training Loss: 5.034e-01, Validation Loss: 8.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5470, Training Loss: 5.033e-01, Validation Loss: 8.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5471, Training Loss: 5.032e-01, Validation Loss: 8.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5472, Training Loss: 5.032e-01, Validation Loss: 8.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5473, Training Loss: 5.031e-01, Validation Loss: 8.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5474, Training Loss: 5.030e-01, Validation Loss: 8.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5475, Training Loss: 5.029e-01, Validation Loss: 8.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5476, Training Loss: 5.028e-01, Validation Loss: 8.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5477, Training Loss: 5.027e-01, Validation Loss: 8.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5478, Training Loss: 5.026e-01, Validation Loss: 8.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5479, Training Loss: 5.026e-01, Validation Loss: 8.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5480, Training Loss: 5.025e-01, Validation Loss: 8.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5481, Training Loss: 5.024e-01, Validation Loss: 8.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5482, Training Loss: 5.023e-01, Validation Loss: 8.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5483, Training Loss: 5.022e-01, Validation Loss: 8.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5484, Training Loss: 5.021e-01, Validation Loss: 8.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5485, Training Loss: 5.020e-01, Validation Loss: 8.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5486, Training Loss: 5.020e-01, Validation Loss: 8.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5487, Training Loss: 5.019e-01, Validation Loss: 8.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5488, Training Loss: 5.018e-01, Validation Loss: 8.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5489, Training Loss: 5.017e-01, Validation Loss: 8.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5490, Training Loss: 5.016e-01, Validation Loss: 8.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5491, Training Loss: 5.015e-01, Validation Loss: 8.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5492, Training Loss: 5.014e-01, Validation Loss: 8.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5493, Training Loss: 5.014e-01, Validation Loss: 8.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5494, Training Loss: 5.013e-01, Validation Loss: 8.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5495, Training Loss: 5.012e-01, Validation Loss: 8.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5496, Training Loss: 5.011e-01, Validation Loss: 8.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5497, Training Loss: 5.010e-01, Validation Loss: 8.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5498, Training Loss: 5.009e-01, Validation Loss: 8.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5499, Training Loss: 5.009e-01, Validation Loss: 8.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5500, Training Loss: 5.008e-01, Validation Loss: 8.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5501, Training Loss: 5.007e-01, Validation Loss: 8.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5502, Training Loss: 5.006e-01, Validation Loss: 8.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5503, Training Loss: 5.005e-01, Validation Loss: 8.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5504, Training Loss: 5.004e-01, Validation Loss: 8.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5505, Training Loss: 5.003e-01, Validation Loss: 8.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5506, Training Loss: 5.003e-01, Validation Loss: 8.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5507, Training Loss: 5.002e-01, Validation Loss: 8.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5508, Training Loss: 5.001e-01, Validation Loss: 8.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5509, Training Loss: 5.000e-01, Validation Loss: 8.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5510, Training Loss: 4.999e-01, Validation Loss: 8.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5511, Training Loss: 4.998e-01, Validation Loss: 8.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5512, Training Loss: 4.998e-01, Validation Loss: 8.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5513, Training Loss: 4.997e-01, Validation Loss: 8.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5514, Training Loss: 4.996e-01, Validation Loss: 8.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5515, Training Loss: 4.995e-01, Validation Loss: 8.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5516, Training Loss: 4.994e-01, Validation Loss: 8.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5517, Training Loss: 4.993e-01, Validation Loss: 8.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5518, Training Loss: 4.992e-01, Validation Loss: 8.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5519, Training Loss: 4.992e-01, Validation Loss: 8.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5520, Training Loss: 4.991e-01, Validation Loss: 8.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5521, Training Loss: 4.990e-01, Validation Loss: 8.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5522, Training Loss: 4.989e-01, Validation Loss: 8.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5523, Training Loss: 4.988e-01, Validation Loss: 8.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5524, Training Loss: 4.987e-01, Validation Loss: 8.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5525, Training Loss: 4.987e-01, Validation Loss: 8.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5526, Training Loss: 4.986e-01, Validation Loss: 8.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5527, Training Loss: 4.985e-01, Validation Loss: 8.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5528, Training Loss: 4.984e-01, Validation Loss: 8.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5529, Training Loss: 4.983e-01, Validation Loss: 8.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5530, Training Loss: 4.982e-01, Validation Loss: 8.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5531, Training Loss: 4.982e-01, Validation Loss: 8.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5532, Training Loss: 4.981e-01, Validation Loss: 8.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5533, Training Loss: 4.980e-01, Validation Loss: 8.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5534, Training Loss: 4.979e-01, Validation Loss: 8.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5535, Training Loss: 4.978e-01, Validation Loss: 8.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5536, Training Loss: 4.977e-01, Validation Loss: 8.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5537, Training Loss: 4.977e-01, Validation Loss: 8.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5538, Training Loss: 4.976e-01, Validation Loss: 8.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5539, Training Loss: 4.975e-01, Validation Loss: 8.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5540, Training Loss: 4.974e-01, Validation Loss: 8.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5541, Training Loss: 4.973e-01, Validation Loss: 8.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5542, Training Loss: 4.972e-01, Validation Loss: 8.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5543, Training Loss: 4.972e-01, Validation Loss: 8.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5544, Training Loss: 4.971e-01, Validation Loss: 8.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5545, Training Loss: 4.970e-01, Validation Loss: 8.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5546, Training Loss: 4.969e-01, Validation Loss: 8.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5547, Training Loss: 4.968e-01, Validation Loss: 8.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5548, Training Loss: 4.967e-01, Validation Loss: 8.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5549, Training Loss: 4.967e-01, Validation Loss: 8.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5550, Training Loss: 4.966e-01, Validation Loss: 8.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5551, Training Loss: 4.965e-01, Validation Loss: 8.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5552, Training Loss: 4.964e-01, Validation Loss: 8.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5553, Training Loss: 4.963e-01, Validation Loss: 8.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5554, Training Loss: 4.962e-01, Validation Loss: 8.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5555, Training Loss: 4.962e-01, Validation Loss: 8.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5556, Training Loss: 4.961e-01, Validation Loss: 8.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5557, Training Loss: 4.960e-01, Validation Loss: 8.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5558, Training Loss: 4.959e-01, Validation Loss: 8.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5559, Training Loss: 4.958e-01, Validation Loss: 8.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5560, Training Loss: 4.957e-01, Validation Loss: 8.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5561, Training Loss: 4.957e-01, Validation Loss: 8.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5562, Training Loss: 4.956e-01, Validation Loss: 8.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5563, Training Loss: 4.955e-01, Validation Loss: 8.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5564, Training Loss: 4.954e-01, Validation Loss: 8.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5565, Training Loss: 4.953e-01, Validation Loss: 8.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5566, Training Loss: 4.952e-01, Validation Loss: 8.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5567, Training Loss: 4.952e-01, Validation Loss: 8.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5568, Training Loss: 4.951e-01, Validation Loss: 8.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5569, Training Loss: 4.950e-01, Validation Loss: 8.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5570, Training Loss: 4.949e-01, Validation Loss: 8.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5571, Training Loss: 4.948e-01, Validation Loss: 8.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5572, Training Loss: 4.947e-01, Validation Loss: 8.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5573, Training Loss: 4.947e-01, Validation Loss: 8.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5574, Training Loss: 4.946e-01, Validation Loss: 8.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5575, Training Loss: 4.945e-01, Validation Loss: 8.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5576, Training Loss: 4.944e-01, Validation Loss: 8.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5577, Training Loss: 4.943e-01, Validation Loss: 8.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5578, Training Loss: 4.942e-01, Validation Loss: 8.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5579, Training Loss: 4.942e-01, Validation Loss: 8.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5580, Training Loss: 4.941e-01, Validation Loss: 8.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5581, Training Loss: 4.940e-01, Validation Loss: 8.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5582, Training Loss: 4.939e-01, Validation Loss: 8.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5583, Training Loss: 4.938e-01, Validation Loss: 8.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5584, Training Loss: 4.937e-01, Validation Loss: 8.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5585, Training Loss: 4.937e-01, Validation Loss: 8.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5586, Training Loss: 4.936e-01, Validation Loss: 8.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5587, Training Loss: 4.935e-01, Validation Loss: 8.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5588, Training Loss: 4.934e-01, Validation Loss: 8.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5589, Training Loss: 4.933e-01, Validation Loss: 8.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5590, Training Loss: 4.932e-01, Validation Loss: 8.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5591, Training Loss: 4.932e-01, Validation Loss: 8.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5592, Training Loss: 4.931e-01, Validation Loss: 8.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5593, Training Loss: 4.930e-01, Validation Loss: 8.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5594, Training Loss: 4.929e-01, Validation Loss: 8.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5595, Training Loss: 4.928e-01, Validation Loss: 8.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5596, Training Loss: 4.928e-01, Validation Loss: 8.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5597, Training Loss: 4.927e-01, Validation Loss: 8.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5598, Training Loss: 4.926e-01, Validation Loss: 8.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5599, Training Loss: 4.925e-01, Validation Loss: 8.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5600, Training Loss: 4.924e-01, Validation Loss: 8.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5601, Training Loss: 4.923e-01, Validation Loss: 8.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5602, Training Loss: 4.923e-01, Validation Loss: 8.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5603, Training Loss: 4.922e-01, Validation Loss: 8.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5604, Training Loss: 4.921e-01, Validation Loss: 8.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5605, Training Loss: 4.920e-01, Validation Loss: 8.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5606, Training Loss: 4.919e-01, Validation Loss: 8.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5607, Training Loss: 4.919e-01, Validation Loss: 8.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5608, Training Loss: 4.918e-01, Validation Loss: 8.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5609, Training Loss: 4.917e-01, Validation Loss: 8.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5610, Training Loss: 4.916e-01, Validation Loss: 8.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5611, Training Loss: 4.915e-01, Validation Loss: 8.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5612, Training Loss: 4.914e-01, Validation Loss: 8.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5613, Training Loss: 4.914e-01, Validation Loss: 8.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5614, Training Loss: 4.913e-01, Validation Loss: 8.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5615, Training Loss: 4.912e-01, Validation Loss: 8.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5616, Training Loss: 4.911e-01, Validation Loss: 8.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5617, Training Loss: 4.910e-01, Validation Loss: 8.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5618, Training Loss: 4.909e-01, Validation Loss: 8.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5619, Training Loss: 4.909e-01, Validation Loss: 8.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5620, Training Loss: 4.908e-01, Validation Loss: 8.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5621, Training Loss: 4.907e-01, Validation Loss: 8.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5622, Training Loss: 4.906e-01, Validation Loss: 8.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5623, Training Loss: 4.905e-01, Validation Loss: 8.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5624, Training Loss: 4.905e-01, Validation Loss: 8.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5625, Training Loss: 4.904e-01, Validation Loss: 8.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5626, Training Loss: 4.903e-01, Validation Loss: 8.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5627, Training Loss: 4.902e-01, Validation Loss: 8.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5628, Training Loss: 4.901e-01, Validation Loss: 8.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5629, Training Loss: 4.901e-01, Validation Loss: 8.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5630, Training Loss: 4.900e-01, Validation Loss: 8.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5631, Training Loss: 4.899e-01, Validation Loss: 8.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5632, Training Loss: 4.898e-01, Validation Loss: 8.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5633, Training Loss: 4.897e-01, Validation Loss: 8.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5634, Training Loss: 4.896e-01, Validation Loss: 8.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5635, Training Loss: 4.896e-01, Validation Loss: 8.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5636, Training Loss: 4.895e-01, Validation Loss: 8.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5637, Training Loss: 4.894e-01, Validation Loss: 8.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5638, Training Loss: 4.893e-01, Validation Loss: 8.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5639, Training Loss: 4.892e-01, Validation Loss: 8.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5640, Training Loss: 4.892e-01, Validation Loss: 8.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5641, Training Loss: 4.891e-01, Validation Loss: 8.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5642, Training Loss: 4.890e-01, Validation Loss: 8.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5643, Training Loss: 4.889e-01, Validation Loss: 8.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5644, Training Loss: 4.888e-01, Validation Loss: 8.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5645, Training Loss: 4.887e-01, Validation Loss: 8.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5646, Training Loss: 4.887e-01, Validation Loss: 8.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5647, Training Loss: 4.886e-01, Validation Loss: 8.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5648, Training Loss: 4.885e-01, Validation Loss: 8.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5649, Training Loss: 4.884e-01, Validation Loss: 8.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5650, Training Loss: 4.883e-01, Validation Loss: 8.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5651, Training Loss: 4.883e-01, Validation Loss: 8.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5652, Training Loss: 4.882e-01, Validation Loss: 8.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5653, Training Loss: 4.881e-01, Validation Loss: 8.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5654, Training Loss: 4.880e-01, Validation Loss: 8.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5655, Training Loss: 4.879e-01, Validation Loss: 8.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5656, Training Loss: 4.879e-01, Validation Loss: 8.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5657, Training Loss: 4.878e-01, Validation Loss: 8.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5658, Training Loss: 4.877e-01, Validation Loss: 8.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5659, Training Loss: 4.876e-01, Validation Loss: 8.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5660, Training Loss: 4.875e-01, Validation Loss: 8.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5661, Training Loss: 4.875e-01, Validation Loss: 8.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5662, Training Loss: 4.874e-01, Validation Loss: 8.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5663, Training Loss: 4.873e-01, Validation Loss: 8.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5664, Training Loss: 4.872e-01, Validation Loss: 8.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5665, Training Loss: 4.871e-01, Validation Loss: 8.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5666, Training Loss: 4.870e-01, Validation Loss: 8.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5667, Training Loss: 4.870e-01, Validation Loss: 8.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5668, Training Loss: 4.869e-01, Validation Loss: 8.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5669, Training Loss: 4.868e-01, Validation Loss: 8.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5670, Training Loss: 4.867e-01, Validation Loss: 8.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5671, Training Loss: 4.866e-01, Validation Loss: 8.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5672, Training Loss: 4.866e-01, Validation Loss: 8.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5673, Training Loss: 4.865e-01, Validation Loss: 8.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5674, Training Loss: 4.864e-01, Validation Loss: 8.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5675, Training Loss: 4.863e-01, Validation Loss: 8.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5676, Training Loss: 4.862e-01, Validation Loss: 8.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5677, Training Loss: 4.862e-01, Validation Loss: 8.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5678, Training Loss: 4.861e-01, Validation Loss: 8.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5679, Training Loss: 4.860e-01, Validation Loss: 8.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5680, Training Loss: 4.859e-01, Validation Loss: 8.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5681, Training Loss: 4.858e-01, Validation Loss: 8.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5682, Training Loss: 4.858e-01, Validation Loss: 8.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5683, Training Loss: 4.857e-01, Validation Loss: 8.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5684, Training Loss: 4.856e-01, Validation Loss: 8.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5685, Training Loss: 4.855e-01, Validation Loss: 8.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5686, Training Loss: 4.854e-01, Validation Loss: 8.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5687, Training Loss: 4.854e-01, Validation Loss: 8.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5688, Training Loss: 4.853e-01, Validation Loss: 8.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5689, Training Loss: 4.852e-01, Validation Loss: 8.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5690, Training Loss: 4.851e-01, Validation Loss: 8.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5691, Training Loss: 4.850e-01, Validation Loss: 8.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5692, Training Loss: 4.850e-01, Validation Loss: 8.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5693, Training Loss: 4.849e-01, Validation Loss: 8.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5694, Training Loss: 4.848e-01, Validation Loss: 8.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5695, Training Loss: 4.847e-01, Validation Loss: 8.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5696, Training Loss: 4.846e-01, Validation Loss: 8.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5697, Training Loss: 4.846e-01, Validation Loss: 8.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5698, Training Loss: 4.845e-01, Validation Loss: 8.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5699, Training Loss: 4.844e-01, Validation Loss: 8.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5700, Training Loss: 4.843e-01, Validation Loss: 8.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5701, Training Loss: 4.842e-01, Validation Loss: 8.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5702, Training Loss: 4.842e-01, Validation Loss: 8.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5703, Training Loss: 4.841e-01, Validation Loss: 8.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5704, Training Loss: 4.840e-01, Validation Loss: 8.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5705, Training Loss: 4.839e-01, Validation Loss: 8.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5706, Training Loss: 4.838e-01, Validation Loss: 8.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5707, Training Loss: 4.838e-01, Validation Loss: 8.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5708, Training Loss: 4.837e-01, Validation Loss: 8.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5709, Training Loss: 4.836e-01, Validation Loss: 8.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5710, Training Loss: 4.835e-01, Validation Loss: 8.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5711, Training Loss: 4.834e-01, Validation Loss: 8.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5712, Training Loss: 4.834e-01, Validation Loss: 8.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5713, Training Loss: 4.833e-01, Validation Loss: 8.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5714, Training Loss: 4.832e-01, Validation Loss: 8.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5715, Training Loss: 4.831e-01, Validation Loss: 8.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5716, Training Loss: 4.830e-01, Validation Loss: 8.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5717, Training Loss: 4.830e-01, Validation Loss: 8.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5718, Training Loss: 4.829e-01, Validation Loss: 8.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5719, Training Loss: 4.828e-01, Validation Loss: 8.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5720, Training Loss: 4.827e-01, Validation Loss: 8.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5721, Training Loss: 4.826e-01, Validation Loss: 8.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5722, Training Loss: 4.826e-01, Validation Loss: 8.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5723, Training Loss: 4.825e-01, Validation Loss: 8.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5724, Training Loss: 4.824e-01, Validation Loss: 8.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5725, Training Loss: 4.823e-01, Validation Loss: 8.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5726, Training Loss: 4.822e-01, Validation Loss: 8.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5727, Training Loss: 4.822e-01, Validation Loss: 8.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5728, Training Loss: 4.821e-01, Validation Loss: 8.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5729, Training Loss: 4.820e-01, Validation Loss: 8.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5730, Training Loss: 4.819e-01, Validation Loss: 8.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5731, Training Loss: 4.819e-01, Validation Loss: 8.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5732, Training Loss: 4.818e-01, Validation Loss: 8.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5733, Training Loss: 4.817e-01, Validation Loss: 7.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5734, Training Loss: 4.816e-01, Validation Loss: 7.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5735, Training Loss: 4.815e-01, Validation Loss: 7.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5736, Training Loss: 4.815e-01, Validation Loss: 7.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5737, Training Loss: 4.814e-01, Validation Loss: 7.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5738, Training Loss: 4.813e-01, Validation Loss: 7.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5739, Training Loss: 4.812e-01, Validation Loss: 7.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5740, Training Loss: 4.811e-01, Validation Loss: 7.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5741, Training Loss: 4.811e-01, Validation Loss: 7.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5742, Training Loss: 4.810e-01, Validation Loss: 7.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5743, Training Loss: 4.809e-01, Validation Loss: 7.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5744, Training Loss: 4.808e-01, Validation Loss: 7.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5745, Training Loss: 4.807e-01, Validation Loss: 7.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5746, Training Loss: 4.807e-01, Validation Loss: 7.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5747, Training Loss: 4.806e-01, Validation Loss: 7.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5748, Training Loss: 4.805e-01, Validation Loss: 7.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5749, Training Loss: 4.804e-01, Validation Loss: 7.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5750, Training Loss: 4.804e-01, Validation Loss: 7.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5751, Training Loss: 4.803e-01, Validation Loss: 7.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5752, Training Loss: 4.802e-01, Validation Loss: 7.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5753, Training Loss: 4.801e-01, Validation Loss: 7.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5754, Training Loss: 4.800e-01, Validation Loss: 7.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5755, Training Loss: 4.800e-01, Validation Loss: 7.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5756, Training Loss: 4.799e-01, Validation Loss: 7.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5757, Training Loss: 4.798e-01, Validation Loss: 7.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5758, Training Loss: 4.797e-01, Validation Loss: 7.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5759, Training Loss: 4.796e-01, Validation Loss: 7.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5760, Training Loss: 4.796e-01, Validation Loss: 7.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5761, Training Loss: 4.795e-01, Validation Loss: 7.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5762, Training Loss: 4.794e-01, Validation Loss: 7.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5763, Training Loss: 4.793e-01, Validation Loss: 7.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5764, Training Loss: 4.793e-01, Validation Loss: 7.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5765, Training Loss: 4.792e-01, Validation Loss: 7.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5766, Training Loss: 4.791e-01, Validation Loss: 7.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5767, Training Loss: 4.790e-01, Validation Loss: 7.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5768, Training Loss: 4.789e-01, Validation Loss: 7.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5769, Training Loss: 4.789e-01, Validation Loss: 7.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5770, Training Loss: 4.788e-01, Validation Loss: 7.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5771, Training Loss: 4.787e-01, Validation Loss: 7.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5772, Training Loss: 4.786e-01, Validation Loss: 7.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5773, Training Loss: 4.785e-01, Validation Loss: 7.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5774, Training Loss: 4.785e-01, Validation Loss: 7.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5775, Training Loss: 4.784e-01, Validation Loss: 7.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5776, Training Loss: 4.783e-01, Validation Loss: 7.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5777, Training Loss: 4.782e-01, Validation Loss: 7.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5778, Training Loss: 4.782e-01, Validation Loss: 7.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5779, Training Loss: 4.781e-01, Validation Loss: 7.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5780, Training Loss: 4.780e-01, Validation Loss: 7.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5781, Training Loss: 4.779e-01, Validation Loss: 7.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5782, Training Loss: 4.778e-01, Validation Loss: 7.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5783, Training Loss: 4.778e-01, Validation Loss: 7.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5784, Training Loss: 4.777e-01, Validation Loss: 7.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5785, Training Loss: 4.776e-01, Validation Loss: 7.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5786, Training Loss: 4.775e-01, Validation Loss: 7.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5787, Training Loss: 4.775e-01, Validation Loss: 7.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5788, Training Loss: 4.774e-01, Validation Loss: 7.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5789, Training Loss: 4.773e-01, Validation Loss: 7.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5790, Training Loss: 4.772e-01, Validation Loss: 7.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5791, Training Loss: 4.771e-01, Validation Loss: 7.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5792, Training Loss: 4.771e-01, Validation Loss: 7.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5793, Training Loss: 4.770e-01, Validation Loss: 7.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5794, Training Loss: 4.769e-01, Validation Loss: 7.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5795, Training Loss: 4.768e-01, Validation Loss: 7.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5796, Training Loss: 4.768e-01, Validation Loss: 7.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5797, Training Loss: 4.767e-01, Validation Loss: 7.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5798, Training Loss: 4.766e-01, Validation Loss: 7.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5799, Training Loss: 4.765e-01, Validation Loss: 7.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5800, Training Loss: 4.764e-01, Validation Loss: 7.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5801, Training Loss: 4.764e-01, Validation Loss: 7.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5802, Training Loss: 4.763e-01, Validation Loss: 7.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5803, Training Loss: 4.762e-01, Validation Loss: 7.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5804, Training Loss: 4.761e-01, Validation Loss: 7.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5805, Training Loss: 4.761e-01, Validation Loss: 7.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5806, Training Loss: 4.760e-01, Validation Loss: 7.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5807, Training Loss: 4.759e-01, Validation Loss: 7.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5808, Training Loss: 4.758e-01, Validation Loss: 7.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5809, Training Loss: 4.757e-01, Validation Loss: 7.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5810, Training Loss: 4.757e-01, Validation Loss: 7.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5811, Training Loss: 4.756e-01, Validation Loss: 7.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5812, Training Loss: 4.755e-01, Validation Loss: 7.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5813, Training Loss: 4.754e-01, Validation Loss: 7.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5814, Training Loss: 4.754e-01, Validation Loss: 7.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5815, Training Loss: 4.753e-01, Validation Loss: 7.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5816, Training Loss: 4.752e-01, Validation Loss: 7.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5817, Training Loss: 4.751e-01, Validation Loss: 7.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5818, Training Loss: 4.750e-01, Validation Loss: 7.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5819, Training Loss: 4.750e-01, Validation Loss: 7.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5820, Training Loss: 4.749e-01, Validation Loss: 7.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5821, Training Loss: 4.748e-01, Validation Loss: 7.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5822, Training Loss: 4.747e-01, Validation Loss: 7.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5823, Training Loss: 4.747e-01, Validation Loss: 7.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5824, Training Loss: 4.746e-01, Validation Loss: 7.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5825, Training Loss: 4.745e-01, Validation Loss: 7.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5826, Training Loss: 4.744e-01, Validation Loss: 7.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5827, Training Loss: 4.744e-01, Validation Loss: 7.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5828, Training Loss: 4.743e-01, Validation Loss: 7.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5829, Training Loss: 4.742e-01, Validation Loss: 7.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5830, Training Loss: 4.741e-01, Validation Loss: 7.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5831, Training Loss: 4.740e-01, Validation Loss: 7.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5832, Training Loss: 4.740e-01, Validation Loss: 7.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5833, Training Loss: 4.739e-01, Validation Loss: 7.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5834, Training Loss: 4.738e-01, Validation Loss: 7.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5835, Training Loss: 4.737e-01, Validation Loss: 7.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5836, Training Loss: 4.737e-01, Validation Loss: 7.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5837, Training Loss: 4.736e-01, Validation Loss: 7.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5838, Training Loss: 4.735e-01, Validation Loss: 7.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5839, Training Loss: 4.734e-01, Validation Loss: 7.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5840, Training Loss: 4.734e-01, Validation Loss: 7.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5841, Training Loss: 4.733e-01, Validation Loss: 7.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5842, Training Loss: 4.732e-01, Validation Loss: 7.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5843, Training Loss: 4.731e-01, Validation Loss: 7.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5844, Training Loss: 4.730e-01, Validation Loss: 7.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5845, Training Loss: 4.730e-01, Validation Loss: 7.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5846, Training Loss: 4.729e-01, Validation Loss: 7.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5847, Training Loss: 4.728e-01, Validation Loss: 7.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5848, Training Loss: 4.727e-01, Validation Loss: 7.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5849, Training Loss: 4.727e-01, Validation Loss: 7.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5850, Training Loss: 4.726e-01, Validation Loss: 7.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5851, Training Loss: 4.725e-01, Validation Loss: 7.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5852, Training Loss: 4.724e-01, Validation Loss: 7.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5853, Training Loss: 4.724e-01, Validation Loss: 7.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5854, Training Loss: 4.723e-01, Validation Loss: 7.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5855, Training Loss: 4.722e-01, Validation Loss: 7.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5856, Training Loss: 4.721e-01, Validation Loss: 7.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5857, Training Loss: 4.720e-01, Validation Loss: 7.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5858, Training Loss: 4.720e-01, Validation Loss: 7.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5859, Training Loss: 4.719e-01, Validation Loss: 7.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5860, Training Loss: 4.718e-01, Validation Loss: 7.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5861, Training Loss: 4.717e-01, Validation Loss: 7.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5862, Training Loss: 4.717e-01, Validation Loss: 7.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5863, Training Loss: 4.716e-01, Validation Loss: 7.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5864, Training Loss: 4.715e-01, Validation Loss: 7.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5865, Training Loss: 4.714e-01, Validation Loss: 7.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5866, Training Loss: 4.714e-01, Validation Loss: 7.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5867, Training Loss: 4.713e-01, Validation Loss: 7.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5868, Training Loss: 4.712e-01, Validation Loss: 7.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5869, Training Loss: 4.711e-01, Validation Loss: 7.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5870, Training Loss: 4.711e-01, Validation Loss: 7.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5871, Training Loss: 4.710e-01, Validation Loss: 7.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5872, Training Loss: 4.709e-01, Validation Loss: 7.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5873, Training Loss: 4.708e-01, Validation Loss: 7.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5874, Training Loss: 4.708e-01, Validation Loss: 7.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5875, Training Loss: 4.707e-01, Validation Loss: 7.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5876, Training Loss: 4.706e-01, Validation Loss: 7.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5877, Training Loss: 4.705e-01, Validation Loss: 7.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5878, Training Loss: 4.704e-01, Validation Loss: 7.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5879, Training Loss: 4.704e-01, Validation Loss: 7.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5880, Training Loss: 4.703e-01, Validation Loss: 7.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5881, Training Loss: 4.702e-01, Validation Loss: 7.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5882, Training Loss: 4.701e-01, Validation Loss: 7.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5883, Training Loss: 4.701e-01, Validation Loss: 7.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5884, Training Loss: 4.700e-01, Validation Loss: 7.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5885, Training Loss: 4.699e-01, Validation Loss: 7.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5886, Training Loss: 4.698e-01, Validation Loss: 7.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5887, Training Loss: 4.698e-01, Validation Loss: 7.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5888, Training Loss: 4.697e-01, Validation Loss: 7.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5889, Training Loss: 4.696e-01, Validation Loss: 7.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5890, Training Loss: 4.695e-01, Validation Loss: 7.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5891, Training Loss: 4.695e-01, Validation Loss: 7.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5892, Training Loss: 4.694e-01, Validation Loss: 7.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5893, Training Loss: 4.693e-01, Validation Loss: 7.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5894, Training Loss: 4.692e-01, Validation Loss: 7.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5895, Training Loss: 4.692e-01, Validation Loss: 7.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5896, Training Loss: 4.691e-01, Validation Loss: 7.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5897, Training Loss: 4.690e-01, Validation Loss: 7.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5898, Training Loss: 4.689e-01, Validation Loss: 7.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5899, Training Loss: 4.689e-01, Validation Loss: 7.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5900, Training Loss: 4.688e-01, Validation Loss: 7.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5901, Training Loss: 4.687e-01, Validation Loss: 7.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5902, Training Loss: 4.686e-01, Validation Loss: 7.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5903, Training Loss: 4.686e-01, Validation Loss: 7.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5904, Training Loss: 4.685e-01, Validation Loss: 7.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5905, Training Loss: 4.684e-01, Validation Loss: 7.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5906, Training Loss: 4.683e-01, Validation Loss: 7.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5907, Training Loss: 4.682e-01, Validation Loss: 7.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5908, Training Loss: 4.682e-01, Validation Loss: 7.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5909, Training Loss: 4.681e-01, Validation Loss: 7.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5910, Training Loss: 4.680e-01, Validation Loss: 7.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5911, Training Loss: 4.679e-01, Validation Loss: 7.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5912, Training Loss: 4.679e-01, Validation Loss: 7.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5913, Training Loss: 4.678e-01, Validation Loss: 7.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5914, Training Loss: 4.677e-01, Validation Loss: 7.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5915, Training Loss: 4.676e-01, Validation Loss: 7.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5916, Training Loss: 4.676e-01, Validation Loss: 7.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5917, Training Loss: 4.675e-01, Validation Loss: 7.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5918, Training Loss: 4.674e-01, Validation Loss: 7.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5919, Training Loss: 4.673e-01, Validation Loss: 7.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5920, Training Loss: 4.673e-01, Validation Loss: 7.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5921, Training Loss: 4.672e-01, Validation Loss: 7.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5922, Training Loss: 4.671e-01, Validation Loss: 7.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5923, Training Loss: 4.670e-01, Validation Loss: 7.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5924, Training Loss: 4.670e-01, Validation Loss: 7.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5925, Training Loss: 4.669e-01, Validation Loss: 7.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5926, Training Loss: 4.668e-01, Validation Loss: 7.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5927, Training Loss: 4.667e-01, Validation Loss: 7.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5928, Training Loss: 4.667e-01, Validation Loss: 7.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5929, Training Loss: 4.666e-01, Validation Loss: 7.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5930, Training Loss: 4.665e-01, Validation Loss: 7.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5931, Training Loss: 4.664e-01, Validation Loss: 7.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5932, Training Loss: 4.664e-01, Validation Loss: 7.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5933, Training Loss: 4.663e-01, Validation Loss: 7.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5934, Training Loss: 4.662e-01, Validation Loss: 7.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5935, Training Loss: 4.661e-01, Validation Loss: 7.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5936, Training Loss: 4.661e-01, Validation Loss: 7.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5937, Training Loss: 4.660e-01, Validation Loss: 7.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5938, Training Loss: 4.659e-01, Validation Loss: 7.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5939, Training Loss: 4.658e-01, Validation Loss: 7.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5940, Training Loss: 4.658e-01, Validation Loss: 7.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5941, Training Loss: 4.657e-01, Validation Loss: 7.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5942, Training Loss: 4.656e-01, Validation Loss: 7.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5943, Training Loss: 4.655e-01, Validation Loss: 7.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5944, Training Loss: 4.655e-01, Validation Loss: 7.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5945, Training Loss: 4.654e-01, Validation Loss: 7.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5946, Training Loss: 4.653e-01, Validation Loss: 7.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5947, Training Loss: 4.652e-01, Validation Loss: 7.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5948, Training Loss: 4.652e-01, Validation Loss: 7.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5949, Training Loss: 4.651e-01, Validation Loss: 7.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5950, Training Loss: 4.650e-01, Validation Loss: 7.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5951, Training Loss: 4.649e-01, Validation Loss: 7.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5952, Training Loss: 4.649e-01, Validation Loss: 7.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5953, Training Loss: 4.648e-01, Validation Loss: 7.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5954, Training Loss: 4.647e-01, Validation Loss: 7.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5955, Training Loss: 4.646e-01, Validation Loss: 7.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5956, Training Loss: 4.646e-01, Validation Loss: 7.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5957, Training Loss: 4.645e-01, Validation Loss: 7.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5958, Training Loss: 4.644e-01, Validation Loss: 7.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5959, Training Loss: 4.643e-01, Validation Loss: 7.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5960, Training Loss: 4.643e-01, Validation Loss: 7.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5961, Training Loss: 4.642e-01, Validation Loss: 7.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5962, Training Loss: 4.641e-01, Validation Loss: 7.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5963, Training Loss: 4.641e-01, Validation Loss: 7.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5964, Training Loss: 4.640e-01, Validation Loss: 7.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5965, Training Loss: 4.639e-01, Validation Loss: 7.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5966, Training Loss: 4.638e-01, Validation Loss: 7.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5967, Training Loss: 4.638e-01, Validation Loss: 7.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5968, Training Loss: 4.637e-01, Validation Loss: 7.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5969, Training Loss: 4.636e-01, Validation Loss: 7.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5970, Training Loss: 4.635e-01, Validation Loss: 7.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5971, Training Loss: 4.635e-01, Validation Loss: 7.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5972, Training Loss: 4.634e-01, Validation Loss: 7.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5973, Training Loss: 4.633e-01, Validation Loss: 7.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5974, Training Loss: 4.632e-01, Validation Loss: 7.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5975, Training Loss: 4.632e-01, Validation Loss: 7.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5976, Training Loss: 4.631e-01, Validation Loss: 7.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5977, Training Loss: 4.630e-01, Validation Loss: 7.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5978, Training Loss: 4.629e-01, Validation Loss: 7.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5979, Training Loss: 4.629e-01, Validation Loss: 7.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5980, Training Loss: 4.628e-01, Validation Loss: 7.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5981, Training Loss: 4.627e-01, Validation Loss: 7.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5982, Training Loss: 4.626e-01, Validation Loss: 7.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5983, Training Loss: 4.626e-01, Validation Loss: 7.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5984, Training Loss: 4.625e-01, Validation Loss: 7.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5985, Training Loss: 4.624e-01, Validation Loss: 7.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5986, Training Loss: 4.623e-01, Validation Loss: 7.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5987, Training Loss: 4.623e-01, Validation Loss: 7.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5988, Training Loss: 4.622e-01, Validation Loss: 7.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5989, Training Loss: 4.621e-01, Validation Loss: 7.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5990, Training Loss: 4.620e-01, Validation Loss: 7.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5991, Training Loss: 4.620e-01, Validation Loss: 7.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5992, Training Loss: 4.619e-01, Validation Loss: 7.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5993, Training Loss: 4.618e-01, Validation Loss: 7.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5994, Training Loss: 4.618e-01, Validation Loss: 7.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5995, Training Loss: 4.617e-01, Validation Loss: 7.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5996, Training Loss: 4.616e-01, Validation Loss: 7.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5997, Training Loss: 4.615e-01, Validation Loss: 7.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5998, Training Loss: 4.615e-01, Validation Loss: 7.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 5999, Training Loss: 4.614e-01, Validation Loss: 7.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6000, Training Loss: 4.613e-01, Validation Loss: 7.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6001, Training Loss: 4.612e-01, Validation Loss: 7.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6002, Training Loss: 4.612e-01, Validation Loss: 7.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6003, Training Loss: 4.611e-01, Validation Loss: 7.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6004, Training Loss: 4.610e-01, Validation Loss: 7.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6005, Training Loss: 4.609e-01, Validation Loss: 7.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6006, Training Loss: 4.609e-01, Validation Loss: 7.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6007, Training Loss: 4.608e-01, Validation Loss: 7.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6008, Training Loss: 4.607e-01, Validation Loss: 7.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6009, Training Loss: 4.607e-01, Validation Loss: 7.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6010, Training Loss: 4.606e-01, Validation Loss: 7.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6011, Training Loss: 4.605e-01, Validation Loss: 7.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6012, Training Loss: 4.604e-01, Validation Loss: 7.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6013, Training Loss: 4.604e-01, Validation Loss: 7.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6014, Training Loss: 4.603e-01, Validation Loss: 7.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6015, Training Loss: 4.602e-01, Validation Loss: 7.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6016, Training Loss: 4.601e-01, Validation Loss: 7.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6017, Training Loss: 4.601e-01, Validation Loss: 7.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6018, Training Loss: 4.600e-01, Validation Loss: 7.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6019, Training Loss: 4.599e-01, Validation Loss: 7.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6020, Training Loss: 4.598e-01, Validation Loss: 7.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6021, Training Loss: 4.598e-01, Validation Loss: 7.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6022, Training Loss: 4.597e-01, Validation Loss: 7.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6023, Training Loss: 4.596e-01, Validation Loss: 7.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6024, Training Loss: 4.596e-01, Validation Loss: 7.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6025, Training Loss: 4.595e-01, Validation Loss: 7.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6026, Training Loss: 4.594e-01, Validation Loss: 7.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6027, Training Loss: 4.593e-01, Validation Loss: 7.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6028, Training Loss: 4.593e-01, Validation Loss: 7.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6029, Training Loss: 4.592e-01, Validation Loss: 7.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6030, Training Loss: 4.591e-01, Validation Loss: 7.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6031, Training Loss: 4.590e-01, Validation Loss: 7.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6032, Training Loss: 4.590e-01, Validation Loss: 7.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6033, Training Loss: 4.589e-01, Validation Loss: 7.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6034, Training Loss: 4.588e-01, Validation Loss: 7.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6035, Training Loss: 4.587e-01, Validation Loss: 7.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6036, Training Loss: 4.587e-01, Validation Loss: 7.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6037, Training Loss: 4.586e-01, Validation Loss: 7.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6038, Training Loss: 4.585e-01, Validation Loss: 7.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6039, Training Loss: 4.585e-01, Validation Loss: 7.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6040, Training Loss: 4.584e-01, Validation Loss: 7.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6041, Training Loss: 4.583e-01, Validation Loss: 7.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6042, Training Loss: 4.582e-01, Validation Loss: 7.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6043, Training Loss: 4.582e-01, Validation Loss: 7.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6044, Training Loss: 4.581e-01, Validation Loss: 7.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6045, Training Loss: 4.580e-01, Validation Loss: 7.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6046, Training Loss: 4.579e-01, Validation Loss: 7.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6047, Training Loss: 4.579e-01, Validation Loss: 7.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6048, Training Loss: 4.578e-01, Validation Loss: 7.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6049, Training Loss: 4.577e-01, Validation Loss: 7.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6050, Training Loss: 4.577e-01, Validation Loss: 7.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6051, Training Loss: 4.576e-01, Validation Loss: 7.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6052, Training Loss: 4.575e-01, Validation Loss: 7.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6053, Training Loss: 4.574e-01, Validation Loss: 7.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6054, Training Loss: 4.574e-01, Validation Loss: 7.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6055, Training Loss: 4.573e-01, Validation Loss: 7.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6056, Training Loss: 4.572e-01, Validation Loss: 7.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6057, Training Loss: 4.571e-01, Validation Loss: 7.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6058, Training Loss: 4.571e-01, Validation Loss: 7.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6059, Training Loss: 4.570e-01, Validation Loss: 7.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6060, Training Loss: 4.569e-01, Validation Loss: 7.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6061, Training Loss: 4.569e-01, Validation Loss: 7.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6062, Training Loss: 4.568e-01, Validation Loss: 7.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6063, Training Loss: 4.567e-01, Validation Loss: 7.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6064, Training Loss: 4.566e-01, Validation Loss: 7.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6065, Training Loss: 4.566e-01, Validation Loss: 7.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6066, Training Loss: 4.565e-01, Validation Loss: 7.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6067, Training Loss: 4.564e-01, Validation Loss: 7.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6068, Training Loss: 4.563e-01, Validation Loss: 7.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6069, Training Loss: 4.563e-01, Validation Loss: 7.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6070, Training Loss: 4.562e-01, Validation Loss: 7.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6071, Training Loss: 4.561e-01, Validation Loss: 7.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6072, Training Loss: 4.561e-01, Validation Loss: 7.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6073, Training Loss: 4.560e-01, Validation Loss: 7.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6074, Training Loss: 4.559e-01, Validation Loss: 7.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6075, Training Loss: 4.558e-01, Validation Loss: 7.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6076, Training Loss: 4.558e-01, Validation Loss: 7.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6077, Training Loss: 4.557e-01, Validation Loss: 7.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6078, Training Loss: 4.556e-01, Validation Loss: 7.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6079, Training Loss: 4.556e-01, Validation Loss: 7.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6080, Training Loss: 4.555e-01, Validation Loss: 7.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6081, Training Loss: 4.554e-01, Validation Loss: 7.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6082, Training Loss: 4.553e-01, Validation Loss: 7.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6083, Training Loss: 4.553e-01, Validation Loss: 7.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6084, Training Loss: 4.552e-01, Validation Loss: 7.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6085, Training Loss: 4.551e-01, Validation Loss: 7.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6086, Training Loss: 4.551e-01, Validation Loss: 7.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6087, Training Loss: 4.550e-01, Validation Loss: 7.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6088, Training Loss: 4.549e-01, Validation Loss: 7.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6089, Training Loss: 4.548e-01, Validation Loss: 7.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6090, Training Loss: 4.548e-01, Validation Loss: 7.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6091, Training Loss: 4.547e-01, Validation Loss: 7.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6092, Training Loss: 4.546e-01, Validation Loss: 7.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6093, Training Loss: 4.545e-01, Validation Loss: 7.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6094, Training Loss: 4.545e-01, Validation Loss: 7.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6095, Training Loss: 4.544e-01, Validation Loss: 7.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6096, Training Loss: 4.543e-01, Validation Loss: 7.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6097, Training Loss: 4.543e-01, Validation Loss: 7.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6098, Training Loss: 4.542e-01, Validation Loss: 7.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6099, Training Loss: 4.541e-01, Validation Loss: 7.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6100, Training Loss: 4.540e-01, Validation Loss: 7.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6101, Training Loss: 4.540e-01, Validation Loss: 7.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6102, Training Loss: 4.539e-01, Validation Loss: 7.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6103, Training Loss: 4.538e-01, Validation Loss: 7.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6104, Training Loss: 4.538e-01, Validation Loss: 7.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6105, Training Loss: 4.537e-01, Validation Loss: 7.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6106, Training Loss: 4.536e-01, Validation Loss: 7.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6107, Training Loss: 4.535e-01, Validation Loss: 7.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6108, Training Loss: 4.535e-01, Validation Loss: 7.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6109, Training Loss: 4.534e-01, Validation Loss: 7.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6110, Training Loss: 4.533e-01, Validation Loss: 7.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6111, Training Loss: 4.533e-01, Validation Loss: 7.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6112, Training Loss: 4.532e-01, Validation Loss: 7.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6113, Training Loss: 4.531e-01, Validation Loss: 7.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6114, Training Loss: 4.530e-01, Validation Loss: 7.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6115, Training Loss: 4.530e-01, Validation Loss: 7.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6116, Training Loss: 4.529e-01, Validation Loss: 7.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6117, Training Loss: 4.528e-01, Validation Loss: 7.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6118, Training Loss: 4.528e-01, Validation Loss: 7.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6119, Training Loss: 4.527e-01, Validation Loss: 7.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6120, Training Loss: 4.526e-01, Validation Loss: 7.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6121, Training Loss: 4.525e-01, Validation Loss: 7.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6122, Training Loss: 4.525e-01, Validation Loss: 7.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6123, Training Loss: 4.524e-01, Validation Loss: 7.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6124, Training Loss: 4.523e-01, Validation Loss: 7.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6125, Training Loss: 4.523e-01, Validation Loss: 7.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6126, Training Loss: 4.522e-01, Validation Loss: 7.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6127, Training Loss: 4.521e-01, Validation Loss: 7.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6128, Training Loss: 4.520e-01, Validation Loss: 7.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6129, Training Loss: 4.520e-01, Validation Loss: 7.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6130, Training Loss: 4.519e-01, Validation Loss: 7.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6131, Training Loss: 4.518e-01, Validation Loss: 7.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6132, Training Loss: 4.518e-01, Validation Loss: 7.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6133, Training Loss: 4.517e-01, Validation Loss: 7.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6134, Training Loss: 4.516e-01, Validation Loss: 7.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6135, Training Loss: 4.515e-01, Validation Loss: 7.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6136, Training Loss: 4.515e-01, Validation Loss: 7.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6137, Training Loss: 4.514e-01, Validation Loss: 7.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6138, Training Loss: 4.513e-01, Validation Loss: 7.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6139, Training Loss: 4.513e-01, Validation Loss: 7.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6140, Training Loss: 4.512e-01, Validation Loss: 7.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6141, Training Loss: 4.511e-01, Validation Loss: 7.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6142, Training Loss: 4.511e-01, Validation Loss: 7.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6143, Training Loss: 4.510e-01, Validation Loss: 7.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6144, Training Loss: 4.509e-01, Validation Loss: 7.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6145, Training Loss: 4.508e-01, Validation Loss: 7.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6146, Training Loss: 4.508e-01, Validation Loss: 7.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6147, Training Loss: 4.507e-01, Validation Loss: 7.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6148, Training Loss: 4.506e-01, Validation Loss: 7.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6149, Training Loss: 4.506e-01, Validation Loss: 7.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6150, Training Loss: 4.505e-01, Validation Loss: 7.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6151, Training Loss: 4.504e-01, Validation Loss: 7.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6152, Training Loss: 4.503e-01, Validation Loss: 7.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6153, Training Loss: 4.503e-01, Validation Loss: 7.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6154, Training Loss: 4.502e-01, Validation Loss: 7.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6155, Training Loss: 4.501e-01, Validation Loss: 7.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6156, Training Loss: 4.501e-01, Validation Loss: 7.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6157, Training Loss: 4.500e-01, Validation Loss: 7.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6158, Training Loss: 4.499e-01, Validation Loss: 7.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6159, Training Loss: 4.499e-01, Validation Loss: 7.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6160, Training Loss: 4.498e-01, Validation Loss: 7.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6161, Training Loss: 4.497e-01, Validation Loss: 7.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6162, Training Loss: 4.496e-01, Validation Loss: 7.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6163, Training Loss: 4.496e-01, Validation Loss: 7.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6164, Training Loss: 4.495e-01, Validation Loss: 7.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6165, Training Loss: 4.494e-01, Validation Loss: 7.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6166, Training Loss: 4.494e-01, Validation Loss: 7.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6167, Training Loss: 4.493e-01, Validation Loss: 7.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6168, Training Loss: 4.492e-01, Validation Loss: 7.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6169, Training Loss: 4.491e-01, Validation Loss: 7.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6170, Training Loss: 4.491e-01, Validation Loss: 7.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6171, Training Loss: 4.490e-01, Validation Loss: 7.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6172, Training Loss: 4.489e-01, Validation Loss: 7.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6173, Training Loss: 4.489e-01, Validation Loss: 7.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6174, Training Loss: 4.488e-01, Validation Loss: 7.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6175, Training Loss: 4.487e-01, Validation Loss: 7.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6176, Training Loss: 4.487e-01, Validation Loss: 7.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6177, Training Loss: 4.486e-01, Validation Loss: 7.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6178, Training Loss: 4.485e-01, Validation Loss: 7.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6179, Training Loss: 4.484e-01, Validation Loss: 7.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6180, Training Loss: 4.484e-01, Validation Loss: 7.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6181, Training Loss: 4.483e-01, Validation Loss: 7.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6182, Training Loss: 4.482e-01, Validation Loss: 7.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6183, Training Loss: 4.482e-01, Validation Loss: 7.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6184, Training Loss: 4.481e-01, Validation Loss: 7.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6185, Training Loss: 4.480e-01, Validation Loss: 7.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6186, Training Loss: 4.480e-01, Validation Loss: 7.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6187, Training Loss: 4.479e-01, Validation Loss: 7.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6188, Training Loss: 4.478e-01, Validation Loss: 7.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6189, Training Loss: 4.477e-01, Validation Loss: 7.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6190, Training Loss: 4.477e-01, Validation Loss: 7.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6191, Training Loss: 4.476e-01, Validation Loss: 7.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6192, Training Loss: 4.475e-01, Validation Loss: 7.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6193, Training Loss: 4.475e-01, Validation Loss: 7.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6194, Training Loss: 4.474e-01, Validation Loss: 7.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6195, Training Loss: 4.473e-01, Validation Loss: 7.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6196, Training Loss: 4.473e-01, Validation Loss: 7.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6197, Training Loss: 4.472e-01, Validation Loss: 7.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6198, Training Loss: 4.471e-01, Validation Loss: 7.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6199, Training Loss: 4.470e-01, Validation Loss: 7.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6200, Training Loss: 4.470e-01, Validation Loss: 7.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6201, Training Loss: 4.469e-01, Validation Loss: 7.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6202, Training Loss: 4.468e-01, Validation Loss: 7.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6203, Training Loss: 4.468e-01, Validation Loss: 7.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6204, Training Loss: 4.467e-01, Validation Loss: 7.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6205, Training Loss: 4.466e-01, Validation Loss: 7.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6206, Training Loss: 4.466e-01, Validation Loss: 7.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6207, Training Loss: 4.465e-01, Validation Loss: 7.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6208, Training Loss: 4.464e-01, Validation Loss: 7.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6209, Training Loss: 4.463e-01, Validation Loss: 7.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6210, Training Loss: 4.463e-01, Validation Loss: 7.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6211, Training Loss: 4.462e-01, Validation Loss: 7.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6212, Training Loss: 4.461e-01, Validation Loss: 7.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6213, Training Loss: 4.461e-01, Validation Loss: 7.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6214, Training Loss: 4.460e-01, Validation Loss: 7.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6215, Training Loss: 4.459e-01, Validation Loss: 7.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6216, Training Loss: 4.459e-01, Validation Loss: 7.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6217, Training Loss: 4.458e-01, Validation Loss: 7.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6218, Training Loss: 4.457e-01, Validation Loss: 7.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6219, Training Loss: 4.457e-01, Validation Loss: 7.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6220, Training Loss: 4.456e-01, Validation Loss: 7.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6221, Training Loss: 4.455e-01, Validation Loss: 7.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6222, Training Loss: 4.454e-01, Validation Loss: 7.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6223, Training Loss: 4.454e-01, Validation Loss: 7.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6224, Training Loss: 4.453e-01, Validation Loss: 7.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6225, Training Loss: 4.452e-01, Validation Loss: 7.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6226, Training Loss: 4.452e-01, Validation Loss: 7.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6227, Training Loss: 4.451e-01, Validation Loss: 7.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6228, Training Loss: 4.450e-01, Validation Loss: 7.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6229, Training Loss: 4.450e-01, Validation Loss: 7.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6230, Training Loss: 4.449e-01, Validation Loss: 7.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6231, Training Loss: 4.448e-01, Validation Loss: 7.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6232, Training Loss: 4.447e-01, Validation Loss: 7.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6233, Training Loss: 4.447e-01, Validation Loss: 7.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6234, Training Loss: 4.446e-01, Validation Loss: 7.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6235, Training Loss: 4.445e-01, Validation Loss: 7.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6236, Training Loss: 4.445e-01, Validation Loss: 7.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6237, Training Loss: 4.444e-01, Validation Loss: 7.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6238, Training Loss: 4.443e-01, Validation Loss: 7.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6239, Training Loss: 4.443e-01, Validation Loss: 7.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6240, Training Loss: 4.442e-01, Validation Loss: 7.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6241, Training Loss: 4.441e-01, Validation Loss: 7.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6242, Training Loss: 4.441e-01, Validation Loss: 7.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6243, Training Loss: 4.440e-01, Validation Loss: 7.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6244, Training Loss: 4.439e-01, Validation Loss: 7.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6245, Training Loss: 4.438e-01, Validation Loss: 7.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6246, Training Loss: 4.438e-01, Validation Loss: 7.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6247, Training Loss: 4.437e-01, Validation Loss: 7.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6248, Training Loss: 4.436e-01, Validation Loss: 7.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6249, Training Loss: 4.436e-01, Validation Loss: 7.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6250, Training Loss: 4.435e-01, Validation Loss: 7.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6251, Training Loss: 4.434e-01, Validation Loss: 7.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6252, Training Loss: 4.434e-01, Validation Loss: 7.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6253, Training Loss: 4.433e-01, Validation Loss: 7.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6254, Training Loss: 4.432e-01, Validation Loss: 7.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6255, Training Loss: 4.432e-01, Validation Loss: 7.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6256, Training Loss: 4.431e-01, Validation Loss: 7.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6257, Training Loss: 4.430e-01, Validation Loss: 7.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6258, Training Loss: 4.430e-01, Validation Loss: 7.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6259, Training Loss: 4.429e-01, Validation Loss: 7.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6260, Training Loss: 4.428e-01, Validation Loss: 7.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6261, Training Loss: 4.427e-01, Validation Loss: 7.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6262, Training Loss: 4.427e-01, Validation Loss: 7.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6263, Training Loss: 4.426e-01, Validation Loss: 7.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6264, Training Loss: 4.425e-01, Validation Loss: 7.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6265, Training Loss: 4.425e-01, Validation Loss: 7.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6266, Training Loss: 4.424e-01, Validation Loss: 7.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6267, Training Loss: 4.423e-01, Validation Loss: 7.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6268, Training Loss: 4.423e-01, Validation Loss: 7.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6269, Training Loss: 4.422e-01, Validation Loss: 7.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6270, Training Loss: 4.421e-01, Validation Loss: 7.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6271, Training Loss: 4.421e-01, Validation Loss: 7.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6272, Training Loss: 4.420e-01, Validation Loss: 7.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6273, Training Loss: 4.419e-01, Validation Loss: 7.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6274, Training Loss: 4.419e-01, Validation Loss: 7.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6275, Training Loss: 4.418e-01, Validation Loss: 7.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6276, Training Loss: 4.417e-01, Validation Loss: 7.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6277, Training Loss: 4.417e-01, Validation Loss: 7.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6278, Training Loss: 4.416e-01, Validation Loss: 7.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6279, Training Loss: 4.415e-01, Validation Loss: 7.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6280, Training Loss: 4.414e-01, Validation Loss: 7.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6281, Training Loss: 4.414e-01, Validation Loss: 7.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6282, Training Loss: 4.413e-01, Validation Loss: 7.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6283, Training Loss: 4.412e-01, Validation Loss: 7.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6284, Training Loss: 4.412e-01, Validation Loss: 7.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6285, Training Loss: 4.411e-01, Validation Loss: 7.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6286, Training Loss: 4.410e-01, Validation Loss: 7.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6287, Training Loss: 4.410e-01, Validation Loss: 7.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6288, Training Loss: 4.409e-01, Validation Loss: 7.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6289, Training Loss: 4.408e-01, Validation Loss: 7.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6290, Training Loss: 4.408e-01, Validation Loss: 7.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6291, Training Loss: 4.407e-01, Validation Loss: 7.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6292, Training Loss: 4.406e-01, Validation Loss: 7.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6293, Training Loss: 4.406e-01, Validation Loss: 7.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6294, Training Loss: 4.405e-01, Validation Loss: 7.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6295, Training Loss: 4.404e-01, Validation Loss: 7.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6296, Training Loss: 4.404e-01, Validation Loss: 7.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6297, Training Loss: 4.403e-01, Validation Loss: 7.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6298, Training Loss: 4.402e-01, Validation Loss: 7.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6299, Training Loss: 4.401e-01, Validation Loss: 7.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6300, Training Loss: 4.401e-01, Validation Loss: 7.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6301, Training Loss: 4.400e-01, Validation Loss: 7.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6302, Training Loss: 4.399e-01, Validation Loss: 7.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6303, Training Loss: 4.399e-01, Validation Loss: 7.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6304, Training Loss: 4.398e-01, Validation Loss: 7.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6305, Training Loss: 4.397e-01, Validation Loss: 7.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6306, Training Loss: 4.397e-01, Validation Loss: 7.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6307, Training Loss: 4.396e-01, Validation Loss: 7.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6308, Training Loss: 4.395e-01, Validation Loss: 7.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6309, Training Loss: 4.395e-01, Validation Loss: 7.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6310, Training Loss: 4.394e-01, Validation Loss: 7.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6311, Training Loss: 4.393e-01, Validation Loss: 7.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6312, Training Loss: 4.393e-01, Validation Loss: 7.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6313, Training Loss: 4.392e-01, Validation Loss: 7.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6314, Training Loss: 4.391e-01, Validation Loss: 7.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6315, Training Loss: 4.391e-01, Validation Loss: 7.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6316, Training Loss: 4.390e-01, Validation Loss: 7.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6317, Training Loss: 4.389e-01, Validation Loss: 7.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6318, Training Loss: 4.389e-01, Validation Loss: 7.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6319, Training Loss: 4.388e-01, Validation Loss: 7.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6320, Training Loss: 4.387e-01, Validation Loss: 7.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6321, Training Loss: 4.387e-01, Validation Loss: 7.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6322, Training Loss: 4.386e-01, Validation Loss: 7.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6323, Training Loss: 4.385e-01, Validation Loss: 7.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6324, Training Loss: 4.385e-01, Validation Loss: 7.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6325, Training Loss: 4.384e-01, Validation Loss: 7.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6326, Training Loss: 4.383e-01, Validation Loss: 7.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6327, Training Loss: 4.383e-01, Validation Loss: 7.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6328, Training Loss: 4.382e-01, Validation Loss: 7.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6329, Training Loss: 4.381e-01, Validation Loss: 7.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6330, Training Loss: 4.380e-01, Validation Loss: 7.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6331, Training Loss: 4.380e-01, Validation Loss: 7.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6332, Training Loss: 4.379e-01, Validation Loss: 7.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6333, Training Loss: 4.378e-01, Validation Loss: 7.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6334, Training Loss: 4.378e-01, Validation Loss: 7.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6335, Training Loss: 4.377e-01, Validation Loss: 7.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6336, Training Loss: 4.376e-01, Validation Loss: 7.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6337, Training Loss: 4.376e-01, Validation Loss: 7.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6338, Training Loss: 4.375e-01, Validation Loss: 7.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6339, Training Loss: 4.374e-01, Validation Loss: 7.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6340, Training Loss: 4.374e-01, Validation Loss: 7.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6341, Training Loss: 4.373e-01, Validation Loss: 7.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6342, Training Loss: 4.372e-01, Validation Loss: 7.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6343, Training Loss: 4.372e-01, Validation Loss: 7.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6344, Training Loss: 4.371e-01, Validation Loss: 7.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6345, Training Loss: 4.370e-01, Validation Loss: 7.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6346, Training Loss: 4.370e-01, Validation Loss: 7.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6347, Training Loss: 4.369e-01, Validation Loss: 7.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6348, Training Loss: 4.368e-01, Validation Loss: 7.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6349, Training Loss: 4.368e-01, Validation Loss: 7.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6350, Training Loss: 4.367e-01, Validation Loss: 7.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6351, Training Loss: 4.366e-01, Validation Loss: 7.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6352, Training Loss: 4.366e-01, Validation Loss: 7.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6353, Training Loss: 4.365e-01, Validation Loss: 7.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6354, Training Loss: 4.364e-01, Validation Loss: 7.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6355, Training Loss: 4.364e-01, Validation Loss: 7.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6356, Training Loss: 4.363e-01, Validation Loss: 7.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6357, Training Loss: 4.362e-01, Validation Loss: 7.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6358, Training Loss: 4.362e-01, Validation Loss: 7.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6359, Training Loss: 4.361e-01, Validation Loss: 7.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6360, Training Loss: 4.360e-01, Validation Loss: 7.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6361, Training Loss: 4.360e-01, Validation Loss: 7.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6362, Training Loss: 4.359e-01, Validation Loss: 7.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6363, Training Loss: 4.358e-01, Validation Loss: 7.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6364, Training Loss: 4.358e-01, Validation Loss: 7.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6365, Training Loss: 4.357e-01, Validation Loss: 7.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6366, Training Loss: 4.356e-01, Validation Loss: 7.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6367, Training Loss: 4.356e-01, Validation Loss: 7.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6368, Training Loss: 4.355e-01, Validation Loss: 7.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6369, Training Loss: 4.354e-01, Validation Loss: 7.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6370, Training Loss: 4.354e-01, Validation Loss: 7.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6371, Training Loss: 4.353e-01, Validation Loss: 7.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6372, Training Loss: 4.352e-01, Validation Loss: 7.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6373, Training Loss: 4.352e-01, Validation Loss: 7.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6374, Training Loss: 4.351e-01, Validation Loss: 7.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6375, Training Loss: 4.350e-01, Validation Loss: 7.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6376, Training Loss: 4.350e-01, Validation Loss: 7.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6377, Training Loss: 4.349e-01, Validation Loss: 7.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6378, Training Loss: 4.348e-01, Validation Loss: 7.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6379, Training Loss: 4.348e-01, Validation Loss: 7.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6380, Training Loss: 4.347e-01, Validation Loss: 7.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6381, Training Loss: 4.346e-01, Validation Loss: 7.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6382, Training Loss: 4.346e-01, Validation Loss: 7.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6383, Training Loss: 4.345e-01, Validation Loss: 7.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6384, Training Loss: 4.344e-01, Validation Loss: 7.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6385, Training Loss: 4.344e-01, Validation Loss: 7.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6386, Training Loss: 4.343e-01, Validation Loss: 7.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6387, Training Loss: 4.342e-01, Validation Loss: 7.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6388, Training Loss: 4.342e-01, Validation Loss: 7.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6389, Training Loss: 4.341e-01, Validation Loss: 7.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6390, Training Loss: 4.340e-01, Validation Loss: 7.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6391, Training Loss: 4.340e-01, Validation Loss: 7.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6392, Training Loss: 4.339e-01, Validation Loss: 7.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6393, Training Loss: 4.338e-01, Validation Loss: 7.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6394, Training Loss: 4.338e-01, Validation Loss: 7.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6395, Training Loss: 4.337e-01, Validation Loss: 7.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6396, Training Loss: 4.336e-01, Validation Loss: 7.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6397, Training Loss: 4.336e-01, Validation Loss: 7.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6398, Training Loss: 4.335e-01, Validation Loss: 7.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6399, Training Loss: 4.334e-01, Validation Loss: 7.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6400, Training Loss: 4.334e-01, Validation Loss: 7.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6401, Training Loss: 4.333e-01, Validation Loss: 7.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6402, Training Loss: 4.332e-01, Validation Loss: 7.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6403, Training Loss: 4.332e-01, Validation Loss: 7.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6404, Training Loss: 4.331e-01, Validation Loss: 7.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6405, Training Loss: 4.330e-01, Validation Loss: 7.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6406, Training Loss: 4.330e-01, Validation Loss: 7.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6407, Training Loss: 4.329e-01, Validation Loss: 7.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6408, Training Loss: 4.328e-01, Validation Loss: 7.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6409, Training Loss: 4.328e-01, Validation Loss: 7.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6410, Training Loss: 4.327e-01, Validation Loss: 7.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6411, Training Loss: 4.326e-01, Validation Loss: 7.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6412, Training Loss: 4.326e-01, Validation Loss: 7.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6413, Training Loss: 4.325e-01, Validation Loss: 7.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6414, Training Loss: 4.324e-01, Validation Loss: 7.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6415, Training Loss: 4.324e-01, Validation Loss: 7.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6416, Training Loss: 4.323e-01, Validation Loss: 7.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6417, Training Loss: 4.322e-01, Validation Loss: 7.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6418, Training Loss: 4.322e-01, Validation Loss: 7.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6419, Training Loss: 4.321e-01, Validation Loss: 7.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6420, Training Loss: 4.320e-01, Validation Loss: 7.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6421, Training Loss: 4.320e-01, Validation Loss: 7.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6422, Training Loss: 4.319e-01, Validation Loss: 7.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6423, Training Loss: 4.318e-01, Validation Loss: 7.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6424, Training Loss: 4.318e-01, Validation Loss: 7.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6425, Training Loss: 4.317e-01, Validation Loss: 7.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6426, Training Loss: 4.316e-01, Validation Loss: 7.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6427, Training Loss: 4.316e-01, Validation Loss: 7.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6428, Training Loss: 4.315e-01, Validation Loss: 7.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6429, Training Loss: 4.314e-01, Validation Loss: 7.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6430, Training Loss: 4.314e-01, Validation Loss: 7.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6431, Training Loss: 4.313e-01, Validation Loss: 7.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6432, Training Loss: 4.312e-01, Validation Loss: 7.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6433, Training Loss: 4.312e-01, Validation Loss: 7.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6434, Training Loss: 4.311e-01, Validation Loss: 7.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6435, Training Loss: 4.310e-01, Validation Loss: 7.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6436, Training Loss: 4.310e-01, Validation Loss: 7.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6437, Training Loss: 4.309e-01, Validation Loss: 7.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6438, Training Loss: 4.309e-01, Validation Loss: 7.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6439, Training Loss: 4.308e-01, Validation Loss: 7.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6440, Training Loss: 4.307e-01, Validation Loss: 7.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6441, Training Loss: 4.307e-01, Validation Loss: 7.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6442, Training Loss: 4.306e-01, Validation Loss: 7.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6443, Training Loss: 4.305e-01, Validation Loss: 7.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6444, Training Loss: 4.305e-01, Validation Loss: 7.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6445, Training Loss: 4.304e-01, Validation Loss: 7.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6446, Training Loss: 4.303e-01, Validation Loss: 7.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6447, Training Loss: 4.303e-01, Validation Loss: 7.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6448, Training Loss: 4.302e-01, Validation Loss: 7.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6449, Training Loss: 4.301e-01, Validation Loss: 7.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6450, Training Loss: 4.301e-01, Validation Loss: 7.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6451, Training Loss: 4.300e-01, Validation Loss: 7.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6452, Training Loss: 4.299e-01, Validation Loss: 7.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6453, Training Loss: 4.299e-01, Validation Loss: 7.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6454, Training Loss: 4.298e-01, Validation Loss: 7.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6455, Training Loss: 4.297e-01, Validation Loss: 7.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6456, Training Loss: 4.297e-01, Validation Loss: 7.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6457, Training Loss: 4.296e-01, Validation Loss: 7.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6458, Training Loss: 4.295e-01, Validation Loss: 7.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6459, Training Loss: 4.295e-01, Validation Loss: 7.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6460, Training Loss: 4.294e-01, Validation Loss: 7.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6461, Training Loss: 4.293e-01, Validation Loss: 7.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6462, Training Loss: 4.293e-01, Validation Loss: 7.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6463, Training Loss: 4.292e-01, Validation Loss: 7.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6464, Training Loss: 4.291e-01, Validation Loss: 7.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6465, Training Loss: 4.291e-01, Validation Loss: 7.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6466, Training Loss: 4.290e-01, Validation Loss: 7.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6467, Training Loss: 4.290e-01, Validation Loss: 7.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6468, Training Loss: 4.289e-01, Validation Loss: 7.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6469, Training Loss: 4.288e-01, Validation Loss: 7.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6470, Training Loss: 4.288e-01, Validation Loss: 7.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6471, Training Loss: 4.287e-01, Validation Loss: 7.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6472, Training Loss: 4.286e-01, Validation Loss: 7.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6473, Training Loss: 4.286e-01, Validation Loss: 7.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6474, Training Loss: 4.285e-01, Validation Loss: 7.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6475, Training Loss: 4.284e-01, Validation Loss: 7.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6476, Training Loss: 4.284e-01, Validation Loss: 7.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6477, Training Loss: 4.283e-01, Validation Loss: 7.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6478, Training Loss: 4.282e-01, Validation Loss: 7.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6479, Training Loss: 4.282e-01, Validation Loss: 7.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6480, Training Loss: 4.281e-01, Validation Loss: 7.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6481, Training Loss: 4.280e-01, Validation Loss: 7.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6482, Training Loss: 4.280e-01, Validation Loss: 7.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6483, Training Loss: 4.279e-01, Validation Loss: 7.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6484, Training Loss: 4.278e-01, Validation Loss: 7.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6485, Training Loss: 4.278e-01, Validation Loss: 7.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6486, Training Loss: 4.277e-01, Validation Loss: 7.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6487, Training Loss: 4.276e-01, Validation Loss: 7.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6488, Training Loss: 4.276e-01, Validation Loss: 7.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6489, Training Loss: 4.275e-01, Validation Loss: 7.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6490, Training Loss: 4.275e-01, Validation Loss: 7.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6491, Training Loss: 4.274e-01, Validation Loss: 7.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6492, Training Loss: 4.273e-01, Validation Loss: 7.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6493, Training Loss: 4.273e-01, Validation Loss: 7.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6494, Training Loss: 4.272e-01, Validation Loss: 7.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6495, Training Loss: 4.271e-01, Validation Loss: 7.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6496, Training Loss: 4.271e-01, Validation Loss: 7.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6497, Training Loss: 4.270e-01, Validation Loss: 7.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6498, Training Loss: 4.269e-01, Validation Loss: 7.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6499, Training Loss: 4.269e-01, Validation Loss: 7.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6500, Training Loss: 4.268e-01, Validation Loss: 7.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6501, Training Loss: 4.267e-01, Validation Loss: 7.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6502, Training Loss: 4.267e-01, Validation Loss: 7.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6503, Training Loss: 4.266e-01, Validation Loss: 7.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6504, Training Loss: 4.265e-01, Validation Loss: 7.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6505, Training Loss: 4.265e-01, Validation Loss: 7.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6506, Training Loss: 4.264e-01, Validation Loss: 7.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6507, Training Loss: 4.264e-01, Validation Loss: 7.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6508, Training Loss: 4.263e-01, Validation Loss: 7.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6509, Training Loss: 4.262e-01, Validation Loss: 7.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6510, Training Loss: 4.262e-01, Validation Loss: 7.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6511, Training Loss: 4.261e-01, Validation Loss: 7.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6512, Training Loss: 4.260e-01, Validation Loss: 7.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6513, Training Loss: 4.260e-01, Validation Loss: 7.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6514, Training Loss: 4.259e-01, Validation Loss: 7.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6515, Training Loss: 4.258e-01, Validation Loss: 7.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6516, Training Loss: 4.258e-01, Validation Loss: 7.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6517, Training Loss: 4.257e-01, Validation Loss: 7.583e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 6518, Training Loss: 4.256e-01, Validation Loss: 7.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6519, Training Loss: 4.256e-01, Validation Loss: 7.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6520, Training Loss: 4.255e-01, Validation Loss: 7.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6521, Training Loss: 4.254e-01, Validation Loss: 7.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6522, Training Loss: 4.254e-01, Validation Loss: 7.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6523, Training Loss: 4.253e-01, Validation Loss: 7.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6524, Training Loss: 4.253e-01, Validation Loss: 7.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6525, Training Loss: 4.252e-01, Validation Loss: 7.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6526, Training Loss: 4.251e-01, Validation Loss: 7.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6527, Training Loss: 4.251e-01, Validation Loss: 7.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6528, Training Loss: 4.250e-01, Validation Loss: 7.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6529, Training Loss: 4.249e-01, Validation Loss: 7.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6530, Training Loss: 4.249e-01, Validation Loss: 7.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6531, Training Loss: 4.248e-01, Validation Loss: 7.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6532, Training Loss: 4.247e-01, Validation Loss: 7.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6533, Training Loss: 4.247e-01, Validation Loss: 7.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6534, Training Loss: 4.246e-01, Validation Loss: 7.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6535, Training Loss: 4.245e-01, Validation Loss: 7.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6536, Training Loss: 4.245e-01, Validation Loss: 7.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6537, Training Loss: 4.244e-01, Validation Loss: 7.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6538, Training Loss: 4.244e-01, Validation Loss: 7.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6539, Training Loss: 4.243e-01, Validation Loss: 7.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6540, Training Loss: 4.242e-01, Validation Loss: 7.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6541, Training Loss: 4.242e-01, Validation Loss: 7.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6542, Training Loss: 4.241e-01, Validation Loss: 7.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6543, Training Loss: 4.240e-01, Validation Loss: 7.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6544, Training Loss: 4.240e-01, Validation Loss: 7.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6545, Training Loss: 4.239e-01, Validation Loss: 7.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6546, Training Loss: 4.238e-01, Validation Loss: 7.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6547, Training Loss: 4.238e-01, Validation Loss: 7.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6548, Training Loss: 4.237e-01, Validation Loss: 7.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6549, Training Loss: 4.237e-01, Validation Loss: 7.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6550, Training Loss: 4.236e-01, Validation Loss: 7.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6551, Training Loss: 4.235e-01, Validation Loss: 7.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6552, Training Loss: 4.235e-01, Validation Loss: 7.567e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 6553, Training Loss: 4.234e-01, Validation Loss: 7.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6554, Training Loss: 4.233e-01, Validation Loss: 7.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6555, Training Loss: 4.233e-01, Validation Loss: 7.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6556, Training Loss: 4.232e-01, Validation Loss: 7.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6557, Training Loss: 4.231e-01, Validation Loss: 7.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6558, Training Loss: 4.231e-01, Validation Loss: 7.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6559, Training Loss: 4.230e-01, Validation Loss: 7.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6560, Training Loss: 4.229e-01, Validation Loss: 7.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6561, Training Loss: 4.229e-01, Validation Loss: 7.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6562, Training Loss: 4.228e-01, Validation Loss: 7.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6563, Training Loss: 4.228e-01, Validation Loss: 7.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6564, Training Loss: 4.227e-01, Validation Loss: 7.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6565, Training Loss: 4.226e-01, Validation Loss: 7.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6566, Training Loss: 4.226e-01, Validation Loss: 7.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6567, Training Loss: 4.225e-01, Validation Loss: 7.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6568, Training Loss: 4.224e-01, Validation Loss: 7.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6569, Training Loss: 4.224e-01, Validation Loss: 7.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6570, Training Loss: 4.223e-01, Validation Loss: 7.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6571, Training Loss: 4.222e-01, Validation Loss: 7.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6572, Training Loss: 4.222e-01, Validation Loss: 7.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6573, Training Loss: 4.221e-01, Validation Loss: 7.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6574, Training Loss: 4.221e-01, Validation Loss: 7.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6575, Training Loss: 4.220e-01, Validation Loss: 7.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6576, Training Loss: 4.219e-01, Validation Loss: 7.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6577, Training Loss: 4.219e-01, Validation Loss: 7.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6578, Training Loss: 4.218e-01, Validation Loss: 7.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6579, Training Loss: 4.217e-01, Validation Loss: 7.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6580, Training Loss: 4.217e-01, Validation Loss: 7.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6581, Training Loss: 4.216e-01, Validation Loss: 7.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6582, Training Loss: 4.215e-01, Validation Loss: 7.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6583, Training Loss: 4.215e-01, Validation Loss: 7.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6584, Training Loss: 4.214e-01, Validation Loss: 7.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6585, Training Loss: 4.214e-01, Validation Loss: 7.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6586, Training Loss: 4.213e-01, Validation Loss: 7.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6587, Training Loss: 4.212e-01, Validation Loss: 7.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6588, Training Loss: 4.212e-01, Validation Loss: 7.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6589, Training Loss: 4.211e-01, Validation Loss: 7.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6590, Training Loss: 4.210e-01, Validation Loss: 7.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6591, Training Loss: 4.210e-01, Validation Loss: 7.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6592, Training Loss: 4.209e-01, Validation Loss: 7.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6593, Training Loss: 4.208e-01, Validation Loss: 7.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6594, Training Loss: 4.208e-01, Validation Loss: 7.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6595, Training Loss: 4.207e-01, Validation Loss: 7.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6596, Training Loss: 4.207e-01, Validation Loss: 7.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6597, Training Loss: 4.206e-01, Validation Loss: 7.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6598, Training Loss: 4.205e-01, Validation Loss: 7.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6599, Training Loss: 4.205e-01, Validation Loss: 7.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6600, Training Loss: 4.204e-01, Validation Loss: 7.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6601, Training Loss: 4.203e-01, Validation Loss: 7.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6602, Training Loss: 4.203e-01, Validation Loss: 7.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6603, Training Loss: 4.202e-01, Validation Loss: 7.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6604, Training Loss: 4.202e-01, Validation Loss: 7.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6605, Training Loss: 4.201e-01, Validation Loss: 7.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6606, Training Loss: 4.200e-01, Validation Loss: 7.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6607, Training Loss: 4.200e-01, Validation Loss: 7.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6608, Training Loss: 4.199e-01, Validation Loss: 7.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6609, Training Loss: 4.198e-01, Validation Loss: 7.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6610, Training Loss: 4.198e-01, Validation Loss: 7.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6611, Training Loss: 4.197e-01, Validation Loss: 7.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6612, Training Loss: 4.196e-01, Validation Loss: 7.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6613, Training Loss: 4.196e-01, Validation Loss: 7.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6614, Training Loss: 4.195e-01, Validation Loss: 7.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6615, Training Loss: 4.195e-01, Validation Loss: 7.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6616, Training Loss: 4.194e-01, Validation Loss: 7.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6617, Training Loss: 4.193e-01, Validation Loss: 7.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6618, Training Loss: 4.193e-01, Validation Loss: 7.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6619, Training Loss: 4.192e-01, Validation Loss: 7.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6620, Training Loss: 4.191e-01, Validation Loss: 7.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6621, Training Loss: 4.191e-01, Validation Loss: 7.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6622, Training Loss: 4.190e-01, Validation Loss: 7.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6623, Training Loss: 4.190e-01, Validation Loss: 7.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6624, Training Loss: 4.189e-01, Validation Loss: 7.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6625, Training Loss: 4.188e-01, Validation Loss: 7.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6626, Training Loss: 4.188e-01, Validation Loss: 7.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6627, Training Loss: 4.187e-01, Validation Loss: 7.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6628, Training Loss: 4.186e-01, Validation Loss: 7.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6629, Training Loss: 4.186e-01, Validation Loss: 7.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6630, Training Loss: 4.185e-01, Validation Loss: 7.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6631, Training Loss: 4.185e-01, Validation Loss: 7.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6632, Training Loss: 4.184e-01, Validation Loss: 7.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6633, Training Loss: 4.183e-01, Validation Loss: 7.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6634, Training Loss: 4.183e-01, Validation Loss: 7.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6635, Training Loss: 4.182e-01, Validation Loss: 7.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6636, Training Loss: 4.181e-01, Validation Loss: 7.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6637, Training Loss: 4.181e-01, Validation Loss: 7.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6638, Training Loss: 4.180e-01, Validation Loss: 7.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6639, Training Loss: 4.180e-01, Validation Loss: 7.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6640, Training Loss: 4.179e-01, Validation Loss: 7.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6641, Training Loss: 4.178e-01, Validation Loss: 7.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6642, Training Loss: 4.178e-01, Validation Loss: 7.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6643, Training Loss: 4.177e-01, Validation Loss: 7.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6644, Training Loss: 4.176e-01, Validation Loss: 7.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6645, Training Loss: 4.176e-01, Validation Loss: 7.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6646, Training Loss: 4.175e-01, Validation Loss: 7.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6647, Training Loss: 4.175e-01, Validation Loss: 7.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6648, Training Loss: 4.174e-01, Validation Loss: 7.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6649, Training Loss: 4.173e-01, Validation Loss: 7.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6650, Training Loss: 4.173e-01, Validation Loss: 7.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6651, Training Loss: 4.172e-01, Validation Loss: 7.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6652, Training Loss: 4.171e-01, Validation Loss: 7.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6653, Training Loss: 4.171e-01, Validation Loss: 7.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6654, Training Loss: 4.170e-01, Validation Loss: 7.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6655, Training Loss: 4.170e-01, Validation Loss: 7.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6656, Training Loss: 4.169e-01, Validation Loss: 7.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6657, Training Loss: 4.168e-01, Validation Loss: 7.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6658, Training Loss: 4.168e-01, Validation Loss: 7.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6659, Training Loss: 4.167e-01, Validation Loss: 7.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6660, Training Loss: 4.166e-01, Validation Loss: 7.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6661, Training Loss: 4.166e-01, Validation Loss: 7.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6662, Training Loss: 4.165e-01, Validation Loss: 7.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6663, Training Loss: 4.165e-01, Validation Loss: 7.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6664, Training Loss: 4.164e-01, Validation Loss: 7.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6665, Training Loss: 4.163e-01, Validation Loss: 7.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6666, Training Loss: 4.163e-01, Validation Loss: 7.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6667, Training Loss: 4.162e-01, Validation Loss: 7.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6668, Training Loss: 4.161e-01, Validation Loss: 7.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6669, Training Loss: 4.161e-01, Validation Loss: 7.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6670, Training Loss: 4.160e-01, Validation Loss: 7.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6671, Training Loss: 4.160e-01, Validation Loss: 7.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6672, Training Loss: 4.159e-01, Validation Loss: 7.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6673, Training Loss: 4.158e-01, Validation Loss: 7.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6674, Training Loss: 4.158e-01, Validation Loss: 7.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6675, Training Loss: 4.157e-01, Validation Loss: 7.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6676, Training Loss: 4.156e-01, Validation Loss: 7.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6677, Training Loss: 4.156e-01, Validation Loss: 7.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6678, Training Loss: 4.155e-01, Validation Loss: 7.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6679, Training Loss: 4.155e-01, Validation Loss: 7.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6680, Training Loss: 4.154e-01, Validation Loss: 7.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6681, Training Loss: 4.153e-01, Validation Loss: 7.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6682, Training Loss: 4.153e-01, Validation Loss: 7.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6683, Training Loss: 4.152e-01, Validation Loss: 7.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6684, Training Loss: 4.151e-01, Validation Loss: 7.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6685, Training Loss: 4.151e-01, Validation Loss: 7.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6686, Training Loss: 4.150e-01, Validation Loss: 7.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6687, Training Loss: 4.150e-01, Validation Loss: 7.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6688, Training Loss: 4.149e-01, Validation Loss: 7.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6689, Training Loss: 4.148e-01, Validation Loss: 7.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6690, Training Loss: 4.148e-01, Validation Loss: 7.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6691, Training Loss: 4.147e-01, Validation Loss: 7.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6692, Training Loss: 4.147e-01, Validation Loss: 7.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6693, Training Loss: 4.146e-01, Validation Loss: 7.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6694, Training Loss: 4.145e-01, Validation Loss: 7.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6695, Training Loss: 4.145e-01, Validation Loss: 7.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6696, Training Loss: 4.144e-01, Validation Loss: 7.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6697, Training Loss: 4.143e-01, Validation Loss: 7.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6698, Training Loss: 4.143e-01, Validation Loss: 7.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6699, Training Loss: 4.142e-01, Validation Loss: 7.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6700, Training Loss: 4.142e-01, Validation Loss: 7.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6701, Training Loss: 4.141e-01, Validation Loss: 7.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6702, Training Loss: 4.140e-01, Validation Loss: 7.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6703, Training Loss: 4.140e-01, Validation Loss: 7.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6704, Training Loss: 4.139e-01, Validation Loss: 7.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6705, Training Loss: 4.138e-01, Validation Loss: 7.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6706, Training Loss: 4.138e-01, Validation Loss: 7.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6707, Training Loss: 4.137e-01, Validation Loss: 7.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6708, Training Loss: 4.137e-01, Validation Loss: 7.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6709, Training Loss: 4.136e-01, Validation Loss: 7.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6710, Training Loss: 4.135e-01, Validation Loss: 7.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6711, Training Loss: 4.135e-01, Validation Loss: 7.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6712, Training Loss: 4.134e-01, Validation Loss: 7.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6713, Training Loss: 4.134e-01, Validation Loss: 7.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6714, Training Loss: 4.133e-01, Validation Loss: 7.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6715, Training Loss: 4.132e-01, Validation Loss: 7.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6716, Training Loss: 4.132e-01, Validation Loss: 7.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6717, Training Loss: 4.131e-01, Validation Loss: 7.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6718, Training Loss: 4.130e-01, Validation Loss: 7.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6719, Training Loss: 4.130e-01, Validation Loss: 7.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6720, Training Loss: 4.129e-01, Validation Loss: 7.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6721, Training Loss: 4.129e-01, Validation Loss: 7.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6722, Training Loss: 4.128e-01, Validation Loss: 7.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6723, Training Loss: 4.127e-01, Validation Loss: 7.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6724, Training Loss: 4.127e-01, Validation Loss: 7.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6725, Training Loss: 4.126e-01, Validation Loss: 7.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6726, Training Loss: 4.126e-01, Validation Loss: 7.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6727, Training Loss: 4.125e-01, Validation Loss: 7.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6728, Training Loss: 4.124e-01, Validation Loss: 7.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6729, Training Loss: 4.124e-01, Validation Loss: 7.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6730, Training Loss: 4.123e-01, Validation Loss: 7.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6731, Training Loss: 4.123e-01, Validation Loss: 7.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6732, Training Loss: 4.122e-01, Validation Loss: 7.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6733, Training Loss: 4.121e-01, Validation Loss: 7.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6734, Training Loss: 4.121e-01, Validation Loss: 7.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6735, Training Loss: 4.120e-01, Validation Loss: 7.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6736, Training Loss: 4.119e-01, Validation Loss: 7.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6737, Training Loss: 4.119e-01, Validation Loss: 7.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6738, Training Loss: 4.118e-01, Validation Loss: 7.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6739, Training Loss: 4.118e-01, Validation Loss: 7.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6740, Training Loss: 4.117e-01, Validation Loss: 7.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6741, Training Loss: 4.116e-01, Validation Loss: 7.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6742, Training Loss: 4.116e-01, Validation Loss: 7.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6743, Training Loss: 4.115e-01, Validation Loss: 7.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6744, Training Loss: 4.115e-01, Validation Loss: 7.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6745, Training Loss: 4.114e-01, Validation Loss: 7.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6746, Training Loss: 4.113e-01, Validation Loss: 7.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6747, Training Loss: 4.113e-01, Validation Loss: 7.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6748, Training Loss: 4.112e-01, Validation Loss: 7.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6749, Training Loss: 4.112e-01, Validation Loss: 7.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6750, Training Loss: 4.111e-01, Validation Loss: 7.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6751, Training Loss: 4.110e-01, Validation Loss: 7.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6752, Training Loss: 4.110e-01, Validation Loss: 7.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6753, Training Loss: 4.109e-01, Validation Loss: 7.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6754, Training Loss: 4.108e-01, Validation Loss: 7.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6755, Training Loss: 4.108e-01, Validation Loss: 7.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6756, Training Loss: 4.107e-01, Validation Loss: 7.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6757, Training Loss: 4.107e-01, Validation Loss: 7.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6758, Training Loss: 4.106e-01, Validation Loss: 7.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6759, Training Loss: 4.105e-01, Validation Loss: 7.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6760, Training Loss: 4.105e-01, Validation Loss: 7.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6761, Training Loss: 4.104e-01, Validation Loss: 7.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6762, Training Loss: 4.104e-01, Validation Loss: 7.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6763, Training Loss: 4.103e-01, Validation Loss: 7.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6764, Training Loss: 4.102e-01, Validation Loss: 7.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6765, Training Loss: 4.102e-01, Validation Loss: 7.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6766, Training Loss: 4.101e-01, Validation Loss: 7.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6767, Training Loss: 4.101e-01, Validation Loss: 7.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6768, Training Loss: 4.100e-01, Validation Loss: 7.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6769, Training Loss: 4.099e-01, Validation Loss: 7.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6770, Training Loss: 4.099e-01, Validation Loss: 7.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6771, Training Loss: 4.098e-01, Validation Loss: 7.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6772, Training Loss: 4.098e-01, Validation Loss: 7.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6773, Training Loss: 4.097e-01, Validation Loss: 7.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6774, Training Loss: 4.096e-01, Validation Loss: 7.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6775, Training Loss: 4.096e-01, Validation Loss: 7.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6776, Training Loss: 4.095e-01, Validation Loss: 7.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6777, Training Loss: 4.094e-01, Validation Loss: 7.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6778, Training Loss: 4.094e-01, Validation Loss: 7.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6779, Training Loss: 4.093e-01, Validation Loss: 7.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6780, Training Loss: 4.093e-01, Validation Loss: 7.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6781, Training Loss: 4.092e-01, Validation Loss: 7.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6782, Training Loss: 4.091e-01, Validation Loss: 7.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6783, Training Loss: 4.091e-01, Validation Loss: 7.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6784, Training Loss: 4.090e-01, Validation Loss: 7.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6785, Training Loss: 4.090e-01, Validation Loss: 7.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6786, Training Loss: 4.089e-01, Validation Loss: 7.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6787, Training Loss: 4.088e-01, Validation Loss: 7.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6788, Training Loss: 4.088e-01, Validation Loss: 7.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6789, Training Loss: 4.087e-01, Validation Loss: 7.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6790, Training Loss: 4.087e-01, Validation Loss: 7.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6791, Training Loss: 4.086e-01, Validation Loss: 7.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6792, Training Loss: 4.085e-01, Validation Loss: 7.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6793, Training Loss: 4.085e-01, Validation Loss: 7.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6794, Training Loss: 4.084e-01, Validation Loss: 7.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6795, Training Loss: 4.084e-01, Validation Loss: 7.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6796, Training Loss: 4.083e-01, Validation Loss: 7.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6797, Training Loss: 4.082e-01, Validation Loss: 7.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6798, Training Loss: 4.082e-01, Validation Loss: 7.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6799, Training Loss: 4.081e-01, Validation Loss: 7.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6800, Training Loss: 4.081e-01, Validation Loss: 7.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6801, Training Loss: 4.080e-01, Validation Loss: 7.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6802, Training Loss: 4.079e-01, Validation Loss: 7.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6803, Training Loss: 4.079e-01, Validation Loss: 7.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6804, Training Loss: 4.078e-01, Validation Loss: 7.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6805, Training Loss: 4.078e-01, Validation Loss: 7.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6806, Training Loss: 4.077e-01, Validation Loss: 7.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6807, Training Loss: 4.076e-01, Validation Loss: 7.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6808, Training Loss: 4.076e-01, Validation Loss: 7.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6809, Training Loss: 4.075e-01, Validation Loss: 7.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6810, Training Loss: 4.075e-01, Validation Loss: 7.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6811, Training Loss: 4.074e-01, Validation Loss: 7.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6812, Training Loss: 4.073e-01, Validation Loss: 7.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6813, Training Loss: 4.073e-01, Validation Loss: 7.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6814, Training Loss: 4.072e-01, Validation Loss: 7.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6815, Training Loss: 4.072e-01, Validation Loss: 7.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6816, Training Loss: 4.071e-01, Validation Loss: 7.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6817, Training Loss: 4.070e-01, Validation Loss: 7.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6818, Training Loss: 4.070e-01, Validation Loss: 7.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6819, Training Loss: 4.069e-01, Validation Loss: 7.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6820, Training Loss: 4.069e-01, Validation Loss: 7.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6821, Training Loss: 4.068e-01, Validation Loss: 7.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6822, Training Loss: 4.067e-01, Validation Loss: 7.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6823, Training Loss: 4.067e-01, Validation Loss: 7.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6824, Training Loss: 4.066e-01, Validation Loss: 7.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6825, Training Loss: 4.066e-01, Validation Loss: 7.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6826, Training Loss: 4.065e-01, Validation Loss: 7.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6827, Training Loss: 4.064e-01, Validation Loss: 7.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6828, Training Loss: 4.064e-01, Validation Loss: 7.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6829, Training Loss: 4.063e-01, Validation Loss: 7.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6830, Training Loss: 4.063e-01, Validation Loss: 7.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6831, Training Loss: 4.062e-01, Validation Loss: 7.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6832, Training Loss: 4.061e-01, Validation Loss: 7.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6833, Training Loss: 4.061e-01, Validation Loss: 7.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6834, Training Loss: 4.060e-01, Validation Loss: 7.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6835, Training Loss: 4.060e-01, Validation Loss: 7.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6836, Training Loss: 4.059e-01, Validation Loss: 7.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6837, Training Loss: 4.058e-01, Validation Loss: 7.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6838, Training Loss: 4.058e-01, Validation Loss: 7.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6839, Training Loss: 4.057e-01, Validation Loss: 7.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6840, Training Loss: 4.057e-01, Validation Loss: 7.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6841, Training Loss: 4.056e-01, Validation Loss: 7.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6842, Training Loss: 4.055e-01, Validation Loss: 7.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6843, Training Loss: 4.055e-01, Validation Loss: 7.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6844, Training Loss: 4.054e-01, Validation Loss: 7.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6845, Training Loss: 4.054e-01, Validation Loss: 7.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6846, Training Loss: 4.053e-01, Validation Loss: 7.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6847, Training Loss: 4.052e-01, Validation Loss: 7.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6848, Training Loss: 4.052e-01, Validation Loss: 7.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6849, Training Loss: 4.051e-01, Validation Loss: 7.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6850, Training Loss: 4.051e-01, Validation Loss: 7.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6851, Training Loss: 4.050e-01, Validation Loss: 7.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6852, Training Loss: 4.049e-01, Validation Loss: 7.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6853, Training Loss: 4.049e-01, Validation Loss: 7.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6854, Training Loss: 4.048e-01, Validation Loss: 7.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6855, Training Loss: 4.048e-01, Validation Loss: 7.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6856, Training Loss: 4.047e-01, Validation Loss: 7.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6857, Training Loss: 4.046e-01, Validation Loss: 7.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6858, Training Loss: 4.046e-01, Validation Loss: 7.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6859, Training Loss: 4.045e-01, Validation Loss: 7.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6860, Training Loss: 4.045e-01, Validation Loss: 7.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6861, Training Loss: 4.044e-01, Validation Loss: 7.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6862, Training Loss: 4.043e-01, Validation Loss: 7.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6863, Training Loss: 4.043e-01, Validation Loss: 7.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6864, Training Loss: 4.042e-01, Validation Loss: 7.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6865, Training Loss: 4.042e-01, Validation Loss: 7.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6866, Training Loss: 4.041e-01, Validation Loss: 7.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6867, Training Loss: 4.041e-01, Validation Loss: 7.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6868, Training Loss: 4.040e-01, Validation Loss: 7.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6869, Training Loss: 4.039e-01, Validation Loss: 7.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6870, Training Loss: 4.039e-01, Validation Loss: 7.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6871, Training Loss: 4.038e-01, Validation Loss: 7.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6872, Training Loss: 4.038e-01, Validation Loss: 7.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6873, Training Loss: 4.037e-01, Validation Loss: 7.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6874, Training Loss: 4.036e-01, Validation Loss: 7.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6875, Training Loss: 4.036e-01, Validation Loss: 7.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6876, Training Loss: 4.035e-01, Validation Loss: 7.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6877, Training Loss: 4.035e-01, Validation Loss: 7.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6878, Training Loss: 4.034e-01, Validation Loss: 7.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6879, Training Loss: 4.033e-01, Validation Loss: 7.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6880, Training Loss: 4.033e-01, Validation Loss: 7.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6881, Training Loss: 4.032e-01, Validation Loss: 7.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6882, Training Loss: 4.032e-01, Validation Loss: 7.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6883, Training Loss: 4.031e-01, Validation Loss: 7.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6884, Training Loss: 4.030e-01, Validation Loss: 7.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6885, Training Loss: 4.030e-01, Validation Loss: 7.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6886, Training Loss: 4.029e-01, Validation Loss: 7.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6887, Training Loss: 4.029e-01, Validation Loss: 7.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6888, Training Loss: 4.028e-01, Validation Loss: 7.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6889, Training Loss: 4.028e-01, Validation Loss: 7.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6890, Training Loss: 4.027e-01, Validation Loss: 7.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6891, Training Loss: 4.026e-01, Validation Loss: 7.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6892, Training Loss: 4.026e-01, Validation Loss: 7.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6893, Training Loss: 4.025e-01, Validation Loss: 7.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6894, Training Loss: 4.025e-01, Validation Loss: 7.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6895, Training Loss: 4.024e-01, Validation Loss: 7.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6896, Training Loss: 4.023e-01, Validation Loss: 7.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6897, Training Loss: 4.023e-01, Validation Loss: 7.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6898, Training Loss: 4.022e-01, Validation Loss: 7.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6899, Training Loss: 4.022e-01, Validation Loss: 7.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6900, Training Loss: 4.021e-01, Validation Loss: 7.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6901, Training Loss: 4.020e-01, Validation Loss: 7.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6902, Training Loss: 4.020e-01, Validation Loss: 7.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6903, Training Loss: 4.019e-01, Validation Loss: 7.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6904, Training Loss: 4.019e-01, Validation Loss: 7.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6905, Training Loss: 4.018e-01, Validation Loss: 7.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6906, Training Loss: 4.017e-01, Validation Loss: 7.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6907, Training Loss: 4.017e-01, Validation Loss: 7.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6908, Training Loss: 4.016e-01, Validation Loss: 7.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6909, Training Loss: 4.016e-01, Validation Loss: 7.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6910, Training Loss: 4.015e-01, Validation Loss: 7.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6911, Training Loss: 4.015e-01, Validation Loss: 7.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6912, Training Loss: 4.014e-01, Validation Loss: 7.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6913, Training Loss: 4.013e-01, Validation Loss: 7.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6914, Training Loss: 4.013e-01, Validation Loss: 7.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6915, Training Loss: 4.012e-01, Validation Loss: 7.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6916, Training Loss: 4.012e-01, Validation Loss: 7.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6917, Training Loss: 4.011e-01, Validation Loss: 7.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6918, Training Loss: 4.010e-01, Validation Loss: 7.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6919, Training Loss: 4.010e-01, Validation Loss: 7.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6920, Training Loss: 4.009e-01, Validation Loss: 7.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6921, Training Loss: 4.009e-01, Validation Loss: 7.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6922, Training Loss: 4.008e-01, Validation Loss: 7.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6923, Training Loss: 4.008e-01, Validation Loss: 7.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6924, Training Loss: 4.007e-01, Validation Loss: 7.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6925, Training Loss: 4.006e-01, Validation Loss: 7.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6926, Training Loss: 4.006e-01, Validation Loss: 7.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6927, Training Loss: 4.005e-01, Validation Loss: 7.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6928, Training Loss: 4.005e-01, Validation Loss: 7.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6929, Training Loss: 4.004e-01, Validation Loss: 7.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6930, Training Loss: 4.003e-01, Validation Loss: 7.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6931, Training Loss: 4.003e-01, Validation Loss: 7.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6932, Training Loss: 4.002e-01, Validation Loss: 7.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6933, Training Loss: 4.002e-01, Validation Loss: 7.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6934, Training Loss: 4.001e-01, Validation Loss: 7.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6935, Training Loss: 4.001e-01, Validation Loss: 7.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6936, Training Loss: 4.000e-01, Validation Loss: 7.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6937, Training Loss: 3.999e-01, Validation Loss: 7.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6938, Training Loss: 3.999e-01, Validation Loss: 7.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6939, Training Loss: 3.998e-01, Validation Loss: 7.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6940, Training Loss: 3.998e-01, Validation Loss: 7.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6941, Training Loss: 3.997e-01, Validation Loss: 7.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6942, Training Loss: 3.996e-01, Validation Loss: 7.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6943, Training Loss: 3.996e-01, Validation Loss: 7.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6944, Training Loss: 3.995e-01, Validation Loss: 7.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6945, Training Loss: 3.995e-01, Validation Loss: 7.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6946, Training Loss: 3.994e-01, Validation Loss: 7.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6947, Training Loss: 3.994e-01, Validation Loss: 7.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6948, Training Loss: 3.993e-01, Validation Loss: 7.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6949, Training Loss: 3.992e-01, Validation Loss: 7.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6950, Training Loss: 3.992e-01, Validation Loss: 7.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6951, Training Loss: 3.991e-01, Validation Loss: 7.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6952, Training Loss: 3.991e-01, Validation Loss: 7.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6953, Training Loss: 3.990e-01, Validation Loss: 7.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6954, Training Loss: 3.989e-01, Validation Loss: 7.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6955, Training Loss: 3.989e-01, Validation Loss: 7.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6956, Training Loss: 3.988e-01, Validation Loss: 7.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6957, Training Loss: 3.988e-01, Validation Loss: 7.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6958, Training Loss: 3.987e-01, Validation Loss: 7.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6959, Training Loss: 3.987e-01, Validation Loss: 7.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6960, Training Loss: 3.986e-01, Validation Loss: 7.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6961, Training Loss: 3.985e-01, Validation Loss: 7.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6962, Training Loss: 3.985e-01, Validation Loss: 7.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6963, Training Loss: 3.984e-01, Validation Loss: 7.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6964, Training Loss: 3.984e-01, Validation Loss: 7.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6965, Training Loss: 3.983e-01, Validation Loss: 7.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6966, Training Loss: 3.982e-01, Validation Loss: 7.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6967, Training Loss: 3.982e-01, Validation Loss: 7.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6968, Training Loss: 3.981e-01, Validation Loss: 7.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6969, Training Loss: 3.981e-01, Validation Loss: 7.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6970, Training Loss: 3.980e-01, Validation Loss: 7.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6971, Training Loss: 3.980e-01, Validation Loss: 7.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6972, Training Loss: 3.979e-01, Validation Loss: 7.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6973, Training Loss: 3.978e-01, Validation Loss: 7.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6974, Training Loss: 3.978e-01, Validation Loss: 7.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6975, Training Loss: 3.977e-01, Validation Loss: 7.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6976, Training Loss: 3.977e-01, Validation Loss: 7.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6977, Training Loss: 3.976e-01, Validation Loss: 7.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6978, Training Loss: 3.976e-01, Validation Loss: 7.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6979, Training Loss: 3.975e-01, Validation Loss: 7.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6980, Training Loss: 3.974e-01, Validation Loss: 7.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6981, Training Loss: 3.974e-01, Validation Loss: 7.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6982, Training Loss: 3.973e-01, Validation Loss: 7.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6983, Training Loss: 3.973e-01, Validation Loss: 7.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6984, Training Loss: 3.972e-01, Validation Loss: 7.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6985, Training Loss: 3.972e-01, Validation Loss: 7.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6986, Training Loss: 3.971e-01, Validation Loss: 7.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6987, Training Loss: 3.970e-01, Validation Loss: 7.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6988, Training Loss: 3.970e-01, Validation Loss: 7.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6989, Training Loss: 3.969e-01, Validation Loss: 7.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6990, Training Loss: 3.969e-01, Validation Loss: 7.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6991, Training Loss: 3.968e-01, Validation Loss: 7.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6992, Training Loss: 3.967e-01, Validation Loss: 7.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6993, Training Loss: 3.967e-01, Validation Loss: 7.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6994, Training Loss: 3.966e-01, Validation Loss: 7.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6995, Training Loss: 3.966e-01, Validation Loss: 7.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6996, Training Loss: 3.965e-01, Validation Loss: 7.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6997, Training Loss: 3.965e-01, Validation Loss: 7.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6998, Training Loss: 3.964e-01, Validation Loss: 7.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 6999, Training Loss: 3.963e-01, Validation Loss: 7.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7000, Training Loss: 3.963e-01, Validation Loss: 7.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7001, Training Loss: 3.962e-01, Validation Loss: 7.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7002, Training Loss: 3.962e-01, Validation Loss: 7.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7003, Training Loss: 3.961e-01, Validation Loss: 7.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7004, Training Loss: 3.961e-01, Validation Loss: 7.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7005, Training Loss: 3.960e-01, Validation Loss: 7.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7006, Training Loss: 3.959e-01, Validation Loss: 7.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7007, Training Loss: 3.959e-01, Validation Loss: 7.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7008, Training Loss: 3.958e-01, Validation Loss: 7.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7009, Training Loss: 3.958e-01, Validation Loss: 7.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7010, Training Loss: 3.957e-01, Validation Loss: 7.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7011, Training Loss: 3.957e-01, Validation Loss: 7.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7012, Training Loss: 3.956e-01, Validation Loss: 7.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7013, Training Loss: 3.955e-01, Validation Loss: 7.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7014, Training Loss: 3.955e-01, Validation Loss: 7.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7015, Training Loss: 3.954e-01, Validation Loss: 7.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7016, Training Loss: 3.954e-01, Validation Loss: 7.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7017, Training Loss: 3.953e-01, Validation Loss: 7.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7018, Training Loss: 3.953e-01, Validation Loss: 7.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7019, Training Loss: 3.952e-01, Validation Loss: 7.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7020, Training Loss: 3.951e-01, Validation Loss: 7.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7021, Training Loss: 3.951e-01, Validation Loss: 7.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7022, Training Loss: 3.950e-01, Validation Loss: 7.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7023, Training Loss: 3.950e-01, Validation Loss: 7.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7024, Training Loss: 3.949e-01, Validation Loss: 7.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7025, Training Loss: 3.949e-01, Validation Loss: 7.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7026, Training Loss: 3.948e-01, Validation Loss: 7.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7027, Training Loss: 3.947e-01, Validation Loss: 7.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7028, Training Loss: 3.947e-01, Validation Loss: 7.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7029, Training Loss: 3.946e-01, Validation Loss: 7.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7030, Training Loss: 3.946e-01, Validation Loss: 7.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7031, Training Loss: 3.945e-01, Validation Loss: 7.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7032, Training Loss: 3.945e-01, Validation Loss: 7.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7033, Training Loss: 3.944e-01, Validation Loss: 7.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7034, Training Loss: 3.943e-01, Validation Loss: 7.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7035, Training Loss: 3.943e-01, Validation Loss: 7.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7036, Training Loss: 3.942e-01, Validation Loss: 7.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7037, Training Loss: 3.942e-01, Validation Loss: 7.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7038, Training Loss: 3.941e-01, Validation Loss: 7.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7039, Training Loss: 3.941e-01, Validation Loss: 7.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7040, Training Loss: 3.940e-01, Validation Loss: 7.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7041, Training Loss: 3.939e-01, Validation Loss: 7.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7042, Training Loss: 3.939e-01, Validation Loss: 7.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7043, Training Loss: 3.938e-01, Validation Loss: 7.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7044, Training Loss: 3.938e-01, Validation Loss: 7.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7045, Training Loss: 3.937e-01, Validation Loss: 7.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7046, Training Loss: 3.937e-01, Validation Loss: 7.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7047, Training Loss: 3.936e-01, Validation Loss: 7.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7048, Training Loss: 3.935e-01, Validation Loss: 7.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7049, Training Loss: 3.935e-01, Validation Loss: 7.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7050, Training Loss: 3.934e-01, Validation Loss: 7.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7051, Training Loss: 3.934e-01, Validation Loss: 7.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7052, Training Loss: 3.933e-01, Validation Loss: 7.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7053, Training Loss: 3.933e-01, Validation Loss: 7.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7054, Training Loss: 3.932e-01, Validation Loss: 7.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7055, Training Loss: 3.931e-01, Validation Loss: 7.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7056, Training Loss: 3.931e-01, Validation Loss: 7.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7057, Training Loss: 3.930e-01, Validation Loss: 7.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7058, Training Loss: 3.930e-01, Validation Loss: 7.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7059, Training Loss: 3.929e-01, Validation Loss: 7.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7060, Training Loss: 3.929e-01, Validation Loss: 7.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7061, Training Loss: 3.928e-01, Validation Loss: 7.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7062, Training Loss: 3.927e-01, Validation Loss: 7.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7063, Training Loss: 3.927e-01, Validation Loss: 7.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7064, Training Loss: 3.926e-01, Validation Loss: 7.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7065, Training Loss: 3.926e-01, Validation Loss: 7.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7066, Training Loss: 3.925e-01, Validation Loss: 7.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7067, Training Loss: 3.925e-01, Validation Loss: 7.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7068, Training Loss: 3.924e-01, Validation Loss: 7.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7069, Training Loss: 3.924e-01, Validation Loss: 7.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7070, Training Loss: 3.923e-01, Validation Loss: 7.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7071, Training Loss: 3.922e-01, Validation Loss: 7.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7072, Training Loss: 3.922e-01, Validation Loss: 7.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7073, Training Loss: 3.921e-01, Validation Loss: 7.340e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 7074, Training Loss: 3.921e-01, Validation Loss: 7.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7075, Training Loss: 3.920e-01, Validation Loss: 7.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7076, Training Loss: 3.920e-01, Validation Loss: 7.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7077, Training Loss: 3.919e-01, Validation Loss: 7.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7078, Training Loss: 3.918e-01, Validation Loss: 7.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7079, Training Loss: 3.918e-01, Validation Loss: 7.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7080, Training Loss: 3.917e-01, Validation Loss: 7.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7081, Training Loss: 3.917e-01, Validation Loss: 7.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7082, Training Loss: 3.916e-01, Validation Loss: 7.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7083, Training Loss: 3.916e-01, Validation Loss: 7.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7084, Training Loss: 3.915e-01, Validation Loss: 7.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7085, Training Loss: 3.915e-01, Validation Loss: 7.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7086, Training Loss: 3.914e-01, Validation Loss: 7.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7087, Training Loss: 3.913e-01, Validation Loss: 7.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7088, Training Loss: 3.913e-01, Validation Loss: 7.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7089, Training Loss: 3.912e-01, Validation Loss: 7.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7090, Training Loss: 3.912e-01, Validation Loss: 7.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7091, Training Loss: 3.911e-01, Validation Loss: 7.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7092, Training Loss: 3.911e-01, Validation Loss: 7.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7093, Training Loss: 3.910e-01, Validation Loss: 7.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7094, Training Loss: 3.909e-01, Validation Loss: 7.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7095, Training Loss: 3.909e-01, Validation Loss: 7.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7096, Training Loss: 3.908e-01, Validation Loss: 7.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7097, Training Loss: 3.908e-01, Validation Loss: 7.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7098, Training Loss: 3.907e-01, Validation Loss: 7.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7099, Training Loss: 3.907e-01, Validation Loss: 7.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7100, Training Loss: 3.906e-01, Validation Loss: 7.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7101, Training Loss: 3.906e-01, Validation Loss: 7.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7102, Training Loss: 3.905e-01, Validation Loss: 7.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7103, Training Loss: 3.904e-01, Validation Loss: 7.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7104, Training Loss: 3.904e-01, Validation Loss: 7.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7105, Training Loss: 3.903e-01, Validation Loss: 7.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7106, Training Loss: 3.903e-01, Validation Loss: 7.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7107, Training Loss: 3.902e-01, Validation Loss: 7.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7108, Training Loss: 3.902e-01, Validation Loss: 7.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7109, Training Loss: 3.901e-01, Validation Loss: 7.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7110, Training Loss: 3.900e-01, Validation Loss: 7.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7111, Training Loss: 3.900e-01, Validation Loss: 7.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7112, Training Loss: 3.899e-01, Validation Loss: 7.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7113, Training Loss: 3.899e-01, Validation Loss: 7.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7114, Training Loss: 3.898e-01, Validation Loss: 7.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7115, Training Loss: 3.898e-01, Validation Loss: 7.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7116, Training Loss: 3.897e-01, Validation Loss: 7.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7117, Training Loss: 3.897e-01, Validation Loss: 7.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7118, Training Loss: 3.896e-01, Validation Loss: 7.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7119, Training Loss: 3.895e-01, Validation Loss: 7.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7120, Training Loss: 3.895e-01, Validation Loss: 7.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7121, Training Loss: 3.894e-01, Validation Loss: 7.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7122, Training Loss: 3.894e-01, Validation Loss: 7.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7123, Training Loss: 3.893e-01, Validation Loss: 7.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7124, Training Loss: 3.893e-01, Validation Loss: 7.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7125, Training Loss: 3.892e-01, Validation Loss: 7.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7126, Training Loss: 3.892e-01, Validation Loss: 7.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7127, Training Loss: 3.891e-01, Validation Loss: 7.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7128, Training Loss: 3.890e-01, Validation Loss: 7.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7129, Training Loss: 3.890e-01, Validation Loss: 7.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7130, Training Loss: 3.889e-01, Validation Loss: 7.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7131, Training Loss: 3.889e-01, Validation Loss: 7.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7132, Training Loss: 3.888e-01, Validation Loss: 7.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7133, Training Loss: 3.888e-01, Validation Loss: 7.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7134, Training Loss: 3.887e-01, Validation Loss: 7.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7135, Training Loss: 3.887e-01, Validation Loss: 7.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7136, Training Loss: 3.886e-01, Validation Loss: 7.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7137, Training Loss: 3.885e-01, Validation Loss: 7.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7138, Training Loss: 3.885e-01, Validation Loss: 7.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7139, Training Loss: 3.884e-01, Validation Loss: 7.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7140, Training Loss: 3.884e-01, Validation Loss: 7.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7141, Training Loss: 3.883e-01, Validation Loss: 7.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7142, Training Loss: 3.883e-01, Validation Loss: 7.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7143, Training Loss: 3.882e-01, Validation Loss: 7.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7144, Training Loss: 3.881e-01, Validation Loss: 7.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7145, Training Loss: 3.881e-01, Validation Loss: 7.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7146, Training Loss: 3.880e-01, Validation Loss: 7.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7147, Training Loss: 3.880e-01, Validation Loss: 7.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7148, Training Loss: 3.879e-01, Validation Loss: 7.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7149, Training Loss: 3.879e-01, Validation Loss: 7.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7150, Training Loss: 3.878e-01, Validation Loss: 7.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7151, Training Loss: 3.878e-01, Validation Loss: 7.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7152, Training Loss: 3.877e-01, Validation Loss: 7.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7153, Training Loss: 3.876e-01, Validation Loss: 7.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7154, Training Loss: 3.876e-01, Validation Loss: 7.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7155, Training Loss: 3.875e-01, Validation Loss: 7.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7156, Training Loss: 3.875e-01, Validation Loss: 7.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7157, Training Loss: 3.874e-01, Validation Loss: 7.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7158, Training Loss: 3.874e-01, Validation Loss: 7.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7159, Training Loss: 3.873e-01, Validation Loss: 7.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7160, Training Loss: 3.873e-01, Validation Loss: 7.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7161, Training Loss: 3.872e-01, Validation Loss: 7.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7162, Training Loss: 3.872e-01, Validation Loss: 7.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7163, Training Loss: 3.871e-01, Validation Loss: 7.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7164, Training Loss: 3.870e-01, Validation Loss: 7.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7165, Training Loss: 3.870e-01, Validation Loss: 7.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7166, Training Loss: 3.869e-01, Validation Loss: 7.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7167, Training Loss: 3.869e-01, Validation Loss: 7.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7168, Training Loss: 3.868e-01, Validation Loss: 7.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7169, Training Loss: 3.868e-01, Validation Loss: 7.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7170, Training Loss: 3.867e-01, Validation Loss: 7.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7171, Training Loss: 3.867e-01, Validation Loss: 7.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7172, Training Loss: 3.866e-01, Validation Loss: 7.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7173, Training Loss: 3.865e-01, Validation Loss: 7.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7174, Training Loss: 3.865e-01, Validation Loss: 7.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7175, Training Loss: 3.864e-01, Validation Loss: 7.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7176, Training Loss: 3.864e-01, Validation Loss: 7.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7177, Training Loss: 3.863e-01, Validation Loss: 7.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7178, Training Loss: 3.863e-01, Validation Loss: 7.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7179, Training Loss: 3.862e-01, Validation Loss: 7.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7180, Training Loss: 3.862e-01, Validation Loss: 7.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7181, Training Loss: 3.861e-01, Validation Loss: 7.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7182, Training Loss: 3.860e-01, Validation Loss: 7.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7183, Training Loss: 3.860e-01, Validation Loss: 7.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7184, Training Loss: 3.859e-01, Validation Loss: 7.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7185, Training Loss: 3.859e-01, Validation Loss: 7.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7186, Training Loss: 3.858e-01, Validation Loss: 7.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7187, Training Loss: 3.858e-01, Validation Loss: 7.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7188, Training Loss: 3.857e-01, Validation Loss: 7.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7189, Training Loss: 3.857e-01, Validation Loss: 7.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7190, Training Loss: 3.856e-01, Validation Loss: 7.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7191, Training Loss: 3.856e-01, Validation Loss: 7.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7192, Training Loss: 3.855e-01, Validation Loss: 7.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7193, Training Loss: 3.854e-01, Validation Loss: 7.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7194, Training Loss: 3.854e-01, Validation Loss: 7.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7195, Training Loss: 3.853e-01, Validation Loss: 7.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7196, Training Loss: 3.853e-01, Validation Loss: 7.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7197, Training Loss: 3.852e-01, Validation Loss: 7.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7198, Training Loss: 3.852e-01, Validation Loss: 7.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7199, Training Loss: 3.851e-01, Validation Loss: 7.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7200, Training Loss: 3.851e-01, Validation Loss: 7.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7201, Training Loss: 3.850e-01, Validation Loss: 7.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7202, Training Loss: 3.849e-01, Validation Loss: 7.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7203, Training Loss: 3.849e-01, Validation Loss: 7.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7204, Training Loss: 3.848e-01, Validation Loss: 7.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7205, Training Loss: 3.848e-01, Validation Loss: 7.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7206, Training Loss: 3.847e-01, Validation Loss: 7.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7207, Training Loss: 3.847e-01, Validation Loss: 7.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7208, Training Loss: 3.846e-01, Validation Loss: 7.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7209, Training Loss: 3.846e-01, Validation Loss: 7.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7210, Training Loss: 3.845e-01, Validation Loss: 7.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7211, Training Loss: 3.845e-01, Validation Loss: 7.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7212, Training Loss: 3.844e-01, Validation Loss: 7.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7213, Training Loss: 3.843e-01, Validation Loss: 7.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7214, Training Loss: 3.843e-01, Validation Loss: 7.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7215, Training Loss: 3.842e-01, Validation Loss: 7.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7216, Training Loss: 3.842e-01, Validation Loss: 7.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7217, Training Loss: 3.841e-01, Validation Loss: 7.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7218, Training Loss: 3.841e-01, Validation Loss: 7.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7219, Training Loss: 3.840e-01, Validation Loss: 7.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7220, Training Loss: 3.840e-01, Validation Loss: 7.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7221, Training Loss: 3.839e-01, Validation Loss: 7.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7222, Training Loss: 3.839e-01, Validation Loss: 7.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7223, Training Loss: 3.838e-01, Validation Loss: 7.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7224, Training Loss: 3.837e-01, Validation Loss: 7.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7225, Training Loss: 3.837e-01, Validation Loss: 7.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7226, Training Loss: 3.836e-01, Validation Loss: 7.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7227, Training Loss: 3.836e-01, Validation Loss: 7.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7228, Training Loss: 3.835e-01, Validation Loss: 7.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7229, Training Loss: 3.835e-01, Validation Loss: 7.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7230, Training Loss: 3.834e-01, Validation Loss: 7.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7231, Training Loss: 3.834e-01, Validation Loss: 7.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7232, Training Loss: 3.833e-01, Validation Loss: 7.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7233, Training Loss: 3.833e-01, Validation Loss: 7.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7234, Training Loss: 3.832e-01, Validation Loss: 7.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7235, Training Loss: 3.831e-01, Validation Loss: 7.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7236, Training Loss: 3.831e-01, Validation Loss: 7.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7237, Training Loss: 3.830e-01, Validation Loss: 7.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7238, Training Loss: 3.830e-01, Validation Loss: 7.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7239, Training Loss: 3.829e-01, Validation Loss: 7.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7240, Training Loss: 3.829e-01, Validation Loss: 7.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7241, Training Loss: 3.828e-01, Validation Loss: 7.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7242, Training Loss: 3.828e-01, Validation Loss: 7.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7243, Training Loss: 3.827e-01, Validation Loss: 7.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7244, Training Loss: 3.827e-01, Validation Loss: 7.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7245, Training Loss: 3.826e-01, Validation Loss: 7.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7246, Training Loss: 3.825e-01, Validation Loss: 7.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7247, Training Loss: 3.825e-01, Validation Loss: 7.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7248, Training Loss: 3.824e-01, Validation Loss: 7.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7249, Training Loss: 3.824e-01, Validation Loss: 7.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7250, Training Loss: 3.823e-01, Validation Loss: 7.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7251, Training Loss: 3.823e-01, Validation Loss: 7.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7252, Training Loss: 3.822e-01, Validation Loss: 7.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7253, Training Loss: 3.822e-01, Validation Loss: 7.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7254, Training Loss: 3.821e-01, Validation Loss: 7.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7255, Training Loss: 3.821e-01, Validation Loss: 7.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7256, Training Loss: 3.820e-01, Validation Loss: 7.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7257, Training Loss: 3.819e-01, Validation Loss: 7.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7258, Training Loss: 3.819e-01, Validation Loss: 7.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7259, Training Loss: 3.818e-01, Validation Loss: 7.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7260, Training Loss: 3.818e-01, Validation Loss: 7.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7261, Training Loss: 3.817e-01, Validation Loss: 7.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7262, Training Loss: 3.817e-01, Validation Loss: 7.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7263, Training Loss: 3.816e-01, Validation Loss: 7.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7264, Training Loss: 3.816e-01, Validation Loss: 7.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7265, Training Loss: 3.815e-01, Validation Loss: 7.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7266, Training Loss: 3.815e-01, Validation Loss: 7.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7267, Training Loss: 3.814e-01, Validation Loss: 7.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7268, Training Loss: 3.814e-01, Validation Loss: 7.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7269, Training Loss: 3.813e-01, Validation Loss: 7.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7270, Training Loss: 3.812e-01, Validation Loss: 7.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7271, Training Loss: 3.812e-01, Validation Loss: 7.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7272, Training Loss: 3.811e-01, Validation Loss: 7.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7273, Training Loss: 3.811e-01, Validation Loss: 7.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7274, Training Loss: 3.810e-01, Validation Loss: 7.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7275, Training Loss: 3.810e-01, Validation Loss: 7.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7276, Training Loss: 3.809e-01, Validation Loss: 7.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7277, Training Loss: 3.809e-01, Validation Loss: 7.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7278, Training Loss: 3.808e-01, Validation Loss: 7.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7279, Training Loss: 3.808e-01, Validation Loss: 7.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7280, Training Loss: 3.807e-01, Validation Loss: 7.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7281, Training Loss: 3.807e-01, Validation Loss: 7.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7282, Training Loss: 3.806e-01, Validation Loss: 7.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7283, Training Loss: 3.805e-01, Validation Loss: 7.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7284, Training Loss: 3.805e-01, Validation Loss: 7.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7285, Training Loss: 3.804e-01, Validation Loss: 7.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7286, Training Loss: 3.804e-01, Validation Loss: 7.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7287, Training Loss: 3.803e-01, Validation Loss: 7.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7288, Training Loss: 3.803e-01, Validation Loss: 7.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7289, Training Loss: 3.802e-01, Validation Loss: 7.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7290, Training Loss: 3.802e-01, Validation Loss: 7.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7291, Training Loss: 3.801e-01, Validation Loss: 7.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7292, Training Loss: 3.801e-01, Validation Loss: 7.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7293, Training Loss: 3.800e-01, Validation Loss: 7.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7294, Training Loss: 3.800e-01, Validation Loss: 7.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7295, Training Loss: 3.799e-01, Validation Loss: 7.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7296, Training Loss: 3.798e-01, Validation Loss: 7.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7297, Training Loss: 3.798e-01, Validation Loss: 7.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7298, Training Loss: 3.797e-01, Validation Loss: 7.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7299, Training Loss: 3.797e-01, Validation Loss: 7.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7300, Training Loss: 3.796e-01, Validation Loss: 7.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7301, Training Loss: 3.796e-01, Validation Loss: 7.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7302, Training Loss: 3.795e-01, Validation Loss: 7.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7303, Training Loss: 3.795e-01, Validation Loss: 7.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7304, Training Loss: 3.794e-01, Validation Loss: 7.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7305, Training Loss: 3.794e-01, Validation Loss: 7.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7306, Training Loss: 3.793e-01, Validation Loss: 7.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7307, Training Loss: 3.793e-01, Validation Loss: 7.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7308, Training Loss: 3.792e-01, Validation Loss: 7.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7309, Training Loss: 3.791e-01, Validation Loss: 7.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7310, Training Loss: 3.791e-01, Validation Loss: 7.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7311, Training Loss: 3.790e-01, Validation Loss: 7.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7312, Training Loss: 3.790e-01, Validation Loss: 7.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7313, Training Loss: 3.789e-01, Validation Loss: 7.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7314, Training Loss: 3.789e-01, Validation Loss: 7.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7315, Training Loss: 3.788e-01, Validation Loss: 7.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7316, Training Loss: 3.788e-01, Validation Loss: 7.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7317, Training Loss: 3.787e-01, Validation Loss: 7.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7318, Training Loss: 3.787e-01, Validation Loss: 7.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7319, Training Loss: 3.786e-01, Validation Loss: 7.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7320, Training Loss: 3.786e-01, Validation Loss: 7.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7321, Training Loss: 3.785e-01, Validation Loss: 7.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7322, Training Loss: 3.785e-01, Validation Loss: 7.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7323, Training Loss: 3.784e-01, Validation Loss: 7.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7324, Training Loss: 3.783e-01, Validation Loss: 7.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7325, Training Loss: 3.783e-01, Validation Loss: 7.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7326, Training Loss: 3.782e-01, Validation Loss: 7.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7327, Training Loss: 3.782e-01, Validation Loss: 7.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7328, Training Loss: 3.781e-01, Validation Loss: 7.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7329, Training Loss: 3.781e-01, Validation Loss: 7.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7330, Training Loss: 3.780e-01, Validation Loss: 7.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7331, Training Loss: 3.780e-01, Validation Loss: 7.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7332, Training Loss: 3.779e-01, Validation Loss: 7.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7333, Training Loss: 3.779e-01, Validation Loss: 7.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7334, Training Loss: 3.778e-01, Validation Loss: 7.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7335, Training Loss: 3.778e-01, Validation Loss: 7.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7336, Training Loss: 3.777e-01, Validation Loss: 7.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7337, Training Loss: 3.777e-01, Validation Loss: 7.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7338, Training Loss: 3.776e-01, Validation Loss: 7.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7339, Training Loss: 3.775e-01, Validation Loss: 7.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7340, Training Loss: 3.775e-01, Validation Loss: 7.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7341, Training Loss: 3.774e-01, Validation Loss: 7.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7342, Training Loss: 3.774e-01, Validation Loss: 7.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7343, Training Loss: 3.773e-01, Validation Loss: 7.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7344, Training Loss: 3.773e-01, Validation Loss: 7.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7345, Training Loss: 3.772e-01, Validation Loss: 7.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7346, Training Loss: 3.772e-01, Validation Loss: 7.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7347, Training Loss: 3.771e-01, Validation Loss: 7.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7348, Training Loss: 3.771e-01, Validation Loss: 7.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7349, Training Loss: 3.770e-01, Validation Loss: 7.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7350, Training Loss: 3.770e-01, Validation Loss: 7.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7351, Training Loss: 3.769e-01, Validation Loss: 7.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7352, Training Loss: 3.769e-01, Validation Loss: 7.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7353, Training Loss: 3.768e-01, Validation Loss: 7.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7354, Training Loss: 3.767e-01, Validation Loss: 7.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7355, Training Loss: 3.767e-01, Validation Loss: 7.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7356, Training Loss: 3.766e-01, Validation Loss: 7.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7357, Training Loss: 3.766e-01, Validation Loss: 7.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7358, Training Loss: 3.765e-01, Validation Loss: 7.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7359, Training Loss: 3.765e-01, Validation Loss: 7.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7360, Training Loss: 3.764e-01, Validation Loss: 7.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7361, Training Loss: 3.764e-01, Validation Loss: 7.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7362, Training Loss: 3.763e-01, Validation Loss: 7.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7363, Training Loss: 3.763e-01, Validation Loss: 7.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7364, Training Loss: 3.762e-01, Validation Loss: 7.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7365, Training Loss: 3.762e-01, Validation Loss: 7.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7366, Training Loss: 3.761e-01, Validation Loss: 7.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7367, Training Loss: 3.761e-01, Validation Loss: 7.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7368, Training Loss: 3.760e-01, Validation Loss: 7.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7369, Training Loss: 3.760e-01, Validation Loss: 7.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7370, Training Loss: 3.759e-01, Validation Loss: 7.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7371, Training Loss: 3.758e-01, Validation Loss: 7.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7372, Training Loss: 3.758e-01, Validation Loss: 7.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7373, Training Loss: 3.757e-01, Validation Loss: 7.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7374, Training Loss: 3.757e-01, Validation Loss: 7.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7375, Training Loss: 3.756e-01, Validation Loss: 7.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7376, Training Loss: 3.756e-01, Validation Loss: 7.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7377, Training Loss: 3.755e-01, Validation Loss: 7.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7378, Training Loss: 3.755e-01, Validation Loss: 7.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7379, Training Loss: 3.754e-01, Validation Loss: 7.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7380, Training Loss: 3.754e-01, Validation Loss: 7.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7381, Training Loss: 3.753e-01, Validation Loss: 7.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7382, Training Loss: 3.753e-01, Validation Loss: 7.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7383, Training Loss: 3.752e-01, Validation Loss: 7.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7384, Training Loss: 3.752e-01, Validation Loss: 7.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7385, Training Loss: 3.751e-01, Validation Loss: 7.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7386, Training Loss: 3.751e-01, Validation Loss: 7.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7387, Training Loss: 3.750e-01, Validation Loss: 7.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7388, Training Loss: 3.750e-01, Validation Loss: 7.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7389, Training Loss: 3.749e-01, Validation Loss: 7.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7390, Training Loss: 3.748e-01, Validation Loss: 7.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7391, Training Loss: 3.748e-01, Validation Loss: 7.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7392, Training Loss: 3.747e-01, Validation Loss: 7.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7393, Training Loss: 3.747e-01, Validation Loss: 7.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7394, Training Loss: 3.746e-01, Validation Loss: 7.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7395, Training Loss: 3.746e-01, Validation Loss: 7.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7396, Training Loss: 3.745e-01, Validation Loss: 7.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7397, Training Loss: 3.745e-01, Validation Loss: 7.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7398, Training Loss: 3.744e-01, Validation Loss: 7.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7399, Training Loss: 3.744e-01, Validation Loss: 7.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7400, Training Loss: 3.743e-01, Validation Loss: 7.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7401, Training Loss: 3.743e-01, Validation Loss: 7.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7402, Training Loss: 3.742e-01, Validation Loss: 7.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7403, Training Loss: 3.742e-01, Validation Loss: 7.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7404, Training Loss: 3.741e-01, Validation Loss: 7.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7405, Training Loss: 3.741e-01, Validation Loss: 7.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7406, Training Loss: 3.740e-01, Validation Loss: 7.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7407, Training Loss: 3.740e-01, Validation Loss: 7.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7408, Training Loss: 3.739e-01, Validation Loss: 7.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7409, Training Loss: 3.738e-01, Validation Loss: 7.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7410, Training Loss: 3.738e-01, Validation Loss: 7.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7411, Training Loss: 3.737e-01, Validation Loss: 7.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7412, Training Loss: 3.737e-01, Validation Loss: 7.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7413, Training Loss: 3.736e-01, Validation Loss: 7.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7414, Training Loss: 3.736e-01, Validation Loss: 7.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7415, Training Loss: 3.735e-01, Validation Loss: 7.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7416, Training Loss: 3.735e-01, Validation Loss: 7.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7417, Training Loss: 3.734e-01, Validation Loss: 7.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7418, Training Loss: 3.734e-01, Validation Loss: 7.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7419, Training Loss: 3.733e-01, Validation Loss: 7.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7420, Training Loss: 3.733e-01, Validation Loss: 7.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7421, Training Loss: 3.732e-01, Validation Loss: 7.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7422, Training Loss: 3.732e-01, Validation Loss: 7.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7423, Training Loss: 3.731e-01, Validation Loss: 7.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7424, Training Loss: 3.731e-01, Validation Loss: 7.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7425, Training Loss: 3.730e-01, Validation Loss: 7.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7426, Training Loss: 3.730e-01, Validation Loss: 7.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7427, Training Loss: 3.729e-01, Validation Loss: 7.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7428, Training Loss: 3.729e-01, Validation Loss: 7.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7429, Training Loss: 3.728e-01, Validation Loss: 7.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7430, Training Loss: 3.728e-01, Validation Loss: 7.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7431, Training Loss: 3.727e-01, Validation Loss: 7.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7432, Training Loss: 3.726e-01, Validation Loss: 7.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7433, Training Loss: 3.726e-01, Validation Loss: 7.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7434, Training Loss: 3.725e-01, Validation Loss: 7.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7435, Training Loss: 3.725e-01, Validation Loss: 7.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7436, Training Loss: 3.724e-01, Validation Loss: 7.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7437, Training Loss: 3.724e-01, Validation Loss: 7.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7438, Training Loss: 3.723e-01, Validation Loss: 7.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7439, Training Loss: 3.723e-01, Validation Loss: 7.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7440, Training Loss: 3.722e-01, Validation Loss: 7.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7441, Training Loss: 3.722e-01, Validation Loss: 7.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7442, Training Loss: 3.721e-01, Validation Loss: 7.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7443, Training Loss: 3.721e-01, Validation Loss: 7.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7444, Training Loss: 3.720e-01, Validation Loss: 7.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7445, Training Loss: 3.720e-01, Validation Loss: 7.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7446, Training Loss: 3.719e-01, Validation Loss: 7.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7447, Training Loss: 3.719e-01, Validation Loss: 7.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7448, Training Loss: 3.718e-01, Validation Loss: 7.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7449, Training Loss: 3.718e-01, Validation Loss: 7.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7450, Training Loss: 3.717e-01, Validation Loss: 7.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7451, Training Loss: 3.717e-01, Validation Loss: 7.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7452, Training Loss: 3.716e-01, Validation Loss: 7.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7453, Training Loss: 3.716e-01, Validation Loss: 7.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7454, Training Loss: 3.715e-01, Validation Loss: 7.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7455, Training Loss: 3.714e-01, Validation Loss: 7.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7456, Training Loss: 3.714e-01, Validation Loss: 7.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7457, Training Loss: 3.713e-01, Validation Loss: 7.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7458, Training Loss: 3.713e-01, Validation Loss: 7.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7459, Training Loss: 3.712e-01, Validation Loss: 7.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7460, Training Loss: 3.712e-01, Validation Loss: 7.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7461, Training Loss: 3.711e-01, Validation Loss: 7.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7462, Training Loss: 3.711e-01, Validation Loss: 7.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7463, Training Loss: 3.710e-01, Validation Loss: 7.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7464, Training Loss: 3.710e-01, Validation Loss: 7.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7465, Training Loss: 3.709e-01, Validation Loss: 7.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7466, Training Loss: 3.709e-01, Validation Loss: 7.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7467, Training Loss: 3.708e-01, Validation Loss: 7.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7468, Training Loss: 3.708e-01, Validation Loss: 7.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7469, Training Loss: 3.707e-01, Validation Loss: 7.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7470, Training Loss: 3.707e-01, Validation Loss: 7.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7471, Training Loss: 3.706e-01, Validation Loss: 7.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7472, Training Loss: 3.706e-01, Validation Loss: 7.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7473, Training Loss: 3.705e-01, Validation Loss: 7.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7474, Training Loss: 3.705e-01, Validation Loss: 7.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7475, Training Loss: 3.704e-01, Validation Loss: 7.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7476, Training Loss: 3.704e-01, Validation Loss: 7.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7477, Training Loss: 3.703e-01, Validation Loss: 7.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7478, Training Loss: 3.703e-01, Validation Loss: 7.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7479, Training Loss: 3.702e-01, Validation Loss: 7.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7480, Training Loss: 3.702e-01, Validation Loss: 7.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7481, Training Loss: 3.701e-01, Validation Loss: 7.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7482, Training Loss: 3.701e-01, Validation Loss: 7.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7483, Training Loss: 3.700e-01, Validation Loss: 7.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7484, Training Loss: 3.699e-01, Validation Loss: 7.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7485, Training Loss: 3.699e-01, Validation Loss: 7.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7486, Training Loss: 3.698e-01, Validation Loss: 7.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7487, Training Loss: 3.698e-01, Validation Loss: 7.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7488, Training Loss: 3.697e-01, Validation Loss: 7.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7489, Training Loss: 3.697e-01, Validation Loss: 7.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7490, Training Loss: 3.696e-01, Validation Loss: 7.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7491, Training Loss: 3.696e-01, Validation Loss: 7.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7492, Training Loss: 3.695e-01, Validation Loss: 7.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7493, Training Loss: 3.695e-01, Validation Loss: 7.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7494, Training Loss: 3.694e-01, Validation Loss: 7.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7495, Training Loss: 3.694e-01, Validation Loss: 7.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7496, Training Loss: 3.693e-01, Validation Loss: 7.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7497, Training Loss: 3.693e-01, Validation Loss: 7.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7498, Training Loss: 3.692e-01, Validation Loss: 7.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7499, Training Loss: 3.692e-01, Validation Loss: 7.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7500, Training Loss: 3.691e-01, Validation Loss: 7.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7501, Training Loss: 3.691e-01, Validation Loss: 7.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7502, Training Loss: 3.690e-01, Validation Loss: 7.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7503, Training Loss: 3.690e-01, Validation Loss: 7.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7504, Training Loss: 3.689e-01, Validation Loss: 7.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7505, Training Loss: 3.689e-01, Validation Loss: 7.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7506, Training Loss: 3.688e-01, Validation Loss: 7.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7507, Training Loss: 3.688e-01, Validation Loss: 7.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7508, Training Loss: 3.687e-01, Validation Loss: 7.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7509, Training Loss: 3.687e-01, Validation Loss: 7.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7510, Training Loss: 3.686e-01, Validation Loss: 7.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7511, Training Loss: 3.686e-01, Validation Loss: 7.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7512, Training Loss: 3.685e-01, Validation Loss: 7.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7513, Training Loss: 3.685e-01, Validation Loss: 7.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7514, Training Loss: 3.684e-01, Validation Loss: 7.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7515, Training Loss: 3.684e-01, Validation Loss: 7.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7516, Training Loss: 3.683e-01, Validation Loss: 7.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7517, Training Loss: 3.683e-01, Validation Loss: 7.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7518, Training Loss: 3.682e-01, Validation Loss: 7.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7519, Training Loss: 3.682e-01, Validation Loss: 7.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7520, Training Loss: 3.681e-01, Validation Loss: 7.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7521, Training Loss: 3.681e-01, Validation Loss: 7.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7522, Training Loss: 3.680e-01, Validation Loss: 7.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7523, Training Loss: 3.679e-01, Validation Loss: 7.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7524, Training Loss: 3.679e-01, Validation Loss: 7.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7525, Training Loss: 3.678e-01, Validation Loss: 7.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7526, Training Loss: 3.678e-01, Validation Loss: 7.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7527, Training Loss: 3.677e-01, Validation Loss: 7.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7528, Training Loss: 3.677e-01, Validation Loss: 7.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7529, Training Loss: 3.676e-01, Validation Loss: 7.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7530, Training Loss: 3.676e-01, Validation Loss: 7.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7531, Training Loss: 3.675e-01, Validation Loss: 7.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7532, Training Loss: 3.675e-01, Validation Loss: 7.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7533, Training Loss: 3.674e-01, Validation Loss: 7.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7534, Training Loss: 3.674e-01, Validation Loss: 7.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7535, Training Loss: 3.673e-01, Validation Loss: 7.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7536, Training Loss: 3.673e-01, Validation Loss: 7.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7537, Training Loss: 3.672e-01, Validation Loss: 7.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7538, Training Loss: 3.672e-01, Validation Loss: 7.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7539, Training Loss: 3.671e-01, Validation Loss: 7.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7540, Training Loss: 3.671e-01, Validation Loss: 7.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7541, Training Loss: 3.670e-01, Validation Loss: 7.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7542, Training Loss: 3.670e-01, Validation Loss: 7.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7543, Training Loss: 3.669e-01, Validation Loss: 7.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7544, Training Loss: 3.669e-01, Validation Loss: 7.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7545, Training Loss: 3.668e-01, Validation Loss: 7.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7546, Training Loss: 3.668e-01, Validation Loss: 7.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7547, Training Loss: 3.667e-01, Validation Loss: 7.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7548, Training Loss: 3.667e-01, Validation Loss: 7.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7549, Training Loss: 3.666e-01, Validation Loss: 7.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7550, Training Loss: 3.666e-01, Validation Loss: 7.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7551, Training Loss: 3.665e-01, Validation Loss: 7.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7552, Training Loss: 3.665e-01, Validation Loss: 7.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7553, Training Loss: 3.664e-01, Validation Loss: 7.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7554, Training Loss: 3.664e-01, Validation Loss: 7.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7555, Training Loss: 3.663e-01, Validation Loss: 7.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7556, Training Loss: 3.663e-01, Validation Loss: 7.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7557, Training Loss: 3.662e-01, Validation Loss: 7.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7558, Training Loss: 3.662e-01, Validation Loss: 7.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7559, Training Loss: 3.661e-01, Validation Loss: 7.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7560, Training Loss: 3.661e-01, Validation Loss: 7.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7561, Training Loss: 3.660e-01, Validation Loss: 7.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7562, Training Loss: 3.660e-01, Validation Loss: 7.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7563, Training Loss: 3.659e-01, Validation Loss: 7.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7564, Training Loss: 3.659e-01, Validation Loss: 7.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7565, Training Loss: 3.658e-01, Validation Loss: 7.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7566, Training Loss: 3.658e-01, Validation Loss: 7.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7567, Training Loss: 3.657e-01, Validation Loss: 7.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7568, Training Loss: 3.657e-01, Validation Loss: 7.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7569, Training Loss: 3.656e-01, Validation Loss: 7.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7570, Training Loss: 3.656e-01, Validation Loss: 7.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7571, Training Loss: 3.655e-01, Validation Loss: 7.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7572, Training Loss: 3.655e-01, Validation Loss: 7.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7573, Training Loss: 3.654e-01, Validation Loss: 7.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7574, Training Loss: 3.654e-01, Validation Loss: 7.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7575, Training Loss: 3.653e-01, Validation Loss: 7.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7576, Training Loss: 3.653e-01, Validation Loss: 7.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7577, Training Loss: 3.652e-01, Validation Loss: 7.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7578, Training Loss: 3.652e-01, Validation Loss: 7.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7579, Training Loss: 3.651e-01, Validation Loss: 7.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7580, Training Loss: 3.651e-01, Validation Loss: 7.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7581, Training Loss: 3.650e-01, Validation Loss: 7.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7582, Training Loss: 3.650e-01, Validation Loss: 7.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7583, Training Loss: 3.649e-01, Validation Loss: 7.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7584, Training Loss: 3.649e-01, Validation Loss: 7.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7585, Training Loss: 3.648e-01, Validation Loss: 7.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7586, Training Loss: 3.648e-01, Validation Loss: 7.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7587, Training Loss: 3.647e-01, Validation Loss: 7.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7588, Training Loss: 3.647e-01, Validation Loss: 7.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7589, Training Loss: 3.646e-01, Validation Loss: 7.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7590, Training Loss: 3.645e-01, Validation Loss: 7.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7591, Training Loss: 3.645e-01, Validation Loss: 7.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7592, Training Loss: 3.644e-01, Validation Loss: 7.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7593, Training Loss: 3.644e-01, Validation Loss: 7.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7594, Training Loss: 3.643e-01, Validation Loss: 7.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7595, Training Loss: 3.643e-01, Validation Loss: 7.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7596, Training Loss: 3.642e-01, Validation Loss: 7.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7597, Training Loss: 3.642e-01, Validation Loss: 7.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7598, Training Loss: 3.641e-01, Validation Loss: 7.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7599, Training Loss: 3.641e-01, Validation Loss: 7.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7600, Training Loss: 3.640e-01, Validation Loss: 7.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7601, Training Loss: 3.640e-01, Validation Loss: 7.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7602, Training Loss: 3.639e-01, Validation Loss: 7.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7603, Training Loss: 3.639e-01, Validation Loss: 7.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7604, Training Loss: 3.638e-01, Validation Loss: 7.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7605, Training Loss: 3.638e-01, Validation Loss: 7.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7606, Training Loss: 3.637e-01, Validation Loss: 7.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7607, Training Loss: 3.637e-01, Validation Loss: 7.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7608, Training Loss: 3.636e-01, Validation Loss: 7.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7609, Training Loss: 3.636e-01, Validation Loss: 7.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7610, Training Loss: 3.635e-01, Validation Loss: 7.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7611, Training Loss: 3.635e-01, Validation Loss: 7.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7612, Training Loss: 3.634e-01, Validation Loss: 7.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7613, Training Loss: 3.634e-01, Validation Loss: 7.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7614, Training Loss: 3.633e-01, Validation Loss: 7.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7615, Training Loss: 3.633e-01, Validation Loss: 7.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7616, Training Loss: 3.632e-01, Validation Loss: 7.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7617, Training Loss: 3.632e-01, Validation Loss: 7.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7618, Training Loss: 3.631e-01, Validation Loss: 7.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7619, Training Loss: 3.631e-01, Validation Loss: 7.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7620, Training Loss: 3.630e-01, Validation Loss: 7.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7621, Training Loss: 3.630e-01, Validation Loss: 7.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7622, Training Loss: 3.629e-01, Validation Loss: 7.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7623, Training Loss: 3.629e-01, Validation Loss: 7.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7624, Training Loss: 3.628e-01, Validation Loss: 7.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7625, Training Loss: 3.628e-01, Validation Loss: 7.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7626, Training Loss: 3.627e-01, Validation Loss: 7.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7627, Training Loss: 3.627e-01, Validation Loss: 7.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7628, Training Loss: 3.626e-01, Validation Loss: 7.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7629, Training Loss: 3.626e-01, Validation Loss: 7.128e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 7630, Training Loss: 3.625e-01, Validation Loss: 7.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7631, Training Loss: 3.625e-01, Validation Loss: 7.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7632, Training Loss: 3.624e-01, Validation Loss: 7.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7633, Training Loss: 3.624e-01, Validation Loss: 7.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7634, Training Loss: 3.623e-01, Validation Loss: 7.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7635, Training Loss: 3.623e-01, Validation Loss: 7.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7636, Training Loss: 3.622e-01, Validation Loss: 7.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7637, Training Loss: 3.622e-01, Validation Loss: 7.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7638, Training Loss: 3.621e-01, Validation Loss: 7.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7639, Training Loss: 3.621e-01, Validation Loss: 7.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7640, Training Loss: 3.620e-01, Validation Loss: 7.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7641, Training Loss: 3.620e-01, Validation Loss: 7.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7642, Training Loss: 3.619e-01, Validation Loss: 7.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7643, Training Loss: 3.619e-01, Validation Loss: 7.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7644, Training Loss: 3.618e-01, Validation Loss: 7.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7645, Training Loss: 3.618e-01, Validation Loss: 7.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7646, Training Loss: 3.617e-01, Validation Loss: 7.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7647, Training Loss: 3.617e-01, Validation Loss: 7.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7648, Training Loss: 3.616e-01, Validation Loss: 7.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7649, Training Loss: 3.616e-01, Validation Loss: 7.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7650, Training Loss: 3.615e-01, Validation Loss: 7.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7651, Training Loss: 3.615e-01, Validation Loss: 7.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7652, Training Loss: 3.614e-01, Validation Loss: 7.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7653, Training Loss: 3.614e-01, Validation Loss: 7.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7654, Training Loss: 3.613e-01, Validation Loss: 7.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7655, Training Loss: 3.613e-01, Validation Loss: 7.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7656, Training Loss: 3.612e-01, Validation Loss: 7.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7657, Training Loss: 3.612e-01, Validation Loss: 7.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7658, Training Loss: 3.611e-01, Validation Loss: 7.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7659, Training Loss: 3.611e-01, Validation Loss: 7.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7660, Training Loss: 3.610e-01, Validation Loss: 7.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7661, Training Loss: 3.610e-01, Validation Loss: 7.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7662, Training Loss: 3.610e-01, Validation Loss: 7.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7663, Training Loss: 3.609e-01, Validation Loss: 7.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7664, Training Loss: 3.609e-01, Validation Loss: 7.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7665, Training Loss: 3.608e-01, Validation Loss: 7.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7666, Training Loss: 3.608e-01, Validation Loss: 7.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7667, Training Loss: 3.607e-01, Validation Loss: 7.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7668, Training Loss: 3.607e-01, Validation Loss: 7.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7669, Training Loss: 3.606e-01, Validation Loss: 7.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7670, Training Loss: 3.606e-01, Validation Loss: 7.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7671, Training Loss: 3.605e-01, Validation Loss: 7.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7672, Training Loss: 3.605e-01, Validation Loss: 7.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7673, Training Loss: 3.604e-01, Validation Loss: 7.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7674, Training Loss: 3.604e-01, Validation Loss: 7.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7675, Training Loss: 3.603e-01, Validation Loss: 7.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7676, Training Loss: 3.603e-01, Validation Loss: 7.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7677, Training Loss: 3.602e-01, Validation Loss: 7.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7678, Training Loss: 3.602e-01, Validation Loss: 7.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7679, Training Loss: 3.601e-01, Validation Loss: 7.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7680, Training Loss: 3.601e-01, Validation Loss: 7.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7681, Training Loss: 3.600e-01, Validation Loss: 7.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7682, Training Loss: 3.600e-01, Validation Loss: 7.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7683, Training Loss: 3.599e-01, Validation Loss: 7.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7684, Training Loss: 3.599e-01, Validation Loss: 7.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7685, Training Loss: 3.598e-01, Validation Loss: 7.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7686, Training Loss: 3.598e-01, Validation Loss: 7.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7687, Training Loss: 3.597e-01, Validation Loss: 7.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7688, Training Loss: 3.597e-01, Validation Loss: 7.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7689, Training Loss: 3.596e-01, Validation Loss: 7.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7690, Training Loss: 3.596e-01, Validation Loss: 7.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7691, Training Loss: 3.595e-01, Validation Loss: 7.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7692, Training Loss: 3.595e-01, Validation Loss: 7.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7693, Training Loss: 3.594e-01, Validation Loss: 7.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7694, Training Loss: 3.594e-01, Validation Loss: 7.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7695, Training Loss: 3.593e-01, Validation Loss: 7.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7696, Training Loss: 3.593e-01, Validation Loss: 7.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7697, Training Loss: 3.592e-01, Validation Loss: 7.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7698, Training Loss: 3.592e-01, Validation Loss: 7.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7699, Training Loss: 3.591e-01, Validation Loss: 7.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7700, Training Loss: 3.591e-01, Validation Loss: 7.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7701, Training Loss: 3.590e-01, Validation Loss: 7.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7702, Training Loss: 3.590e-01, Validation Loss: 7.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7703, Training Loss: 3.589e-01, Validation Loss: 7.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7704, Training Loss: 3.589e-01, Validation Loss: 7.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7705, Training Loss: 3.588e-01, Validation Loss: 7.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7706, Training Loss: 3.588e-01, Validation Loss: 7.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7707, Training Loss: 3.587e-01, Validation Loss: 7.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7708, Training Loss: 3.587e-01, Validation Loss: 7.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7709, Training Loss: 3.586e-01, Validation Loss: 7.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7710, Training Loss: 3.586e-01, Validation Loss: 7.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7711, Training Loss: 3.585e-01, Validation Loss: 7.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7712, Training Loss: 3.585e-01, Validation Loss: 7.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7713, Training Loss: 3.584e-01, Validation Loss: 7.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7714, Training Loss: 3.584e-01, Validation Loss: 7.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7715, Training Loss: 3.583e-01, Validation Loss: 7.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7716, Training Loss: 3.583e-01, Validation Loss: 7.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7717, Training Loss: 3.582e-01, Validation Loss: 7.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7718, Training Loss: 3.582e-01, Validation Loss: 7.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7719, Training Loss: 3.581e-01, Validation Loss: 7.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7720, Training Loss: 3.581e-01, Validation Loss: 7.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7721, Training Loss: 3.580e-01, Validation Loss: 7.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7722, Training Loss: 3.580e-01, Validation Loss: 7.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7723, Training Loss: 3.579e-01, Validation Loss: 7.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7724, Training Loss: 3.579e-01, Validation Loss: 7.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7725, Training Loss: 3.578e-01, Validation Loss: 7.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7726, Training Loss: 3.578e-01, Validation Loss: 7.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7727, Training Loss: 3.577e-01, Validation Loss: 7.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7728, Training Loss: 3.577e-01, Validation Loss: 7.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7729, Training Loss: 3.577e-01, Validation Loss: 7.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7730, Training Loss: 3.576e-01, Validation Loss: 7.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7731, Training Loss: 3.576e-01, Validation Loss: 7.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7732, Training Loss: 3.575e-01, Validation Loss: 7.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7733, Training Loss: 3.575e-01, Validation Loss: 7.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7734, Training Loss: 3.574e-01, Validation Loss: 7.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7735, Training Loss: 3.574e-01, Validation Loss: 7.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7736, Training Loss: 3.573e-01, Validation Loss: 7.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7737, Training Loss: 3.573e-01, Validation Loss: 7.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7738, Training Loss: 3.572e-01, Validation Loss: 7.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7739, Training Loss: 3.572e-01, Validation Loss: 7.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7740, Training Loss: 3.571e-01, Validation Loss: 7.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7741, Training Loss: 3.571e-01, Validation Loss: 7.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7742, Training Loss: 3.570e-01, Validation Loss: 7.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7743, Training Loss: 3.570e-01, Validation Loss: 7.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7744, Training Loss: 3.569e-01, Validation Loss: 7.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7745, Training Loss: 3.569e-01, Validation Loss: 7.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7746, Training Loss: 3.568e-01, Validation Loss: 7.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7747, Training Loss: 3.568e-01, Validation Loss: 7.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7748, Training Loss: 3.567e-01, Validation Loss: 7.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7749, Training Loss: 3.567e-01, Validation Loss: 7.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7750, Training Loss: 3.566e-01, Validation Loss: 7.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7751, Training Loss: 3.566e-01, Validation Loss: 7.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7752, Training Loss: 3.565e-01, Validation Loss: 7.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7753, Training Loss: 3.565e-01, Validation Loss: 7.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7754, Training Loss: 3.564e-01, Validation Loss: 7.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7755, Training Loss: 3.564e-01, Validation Loss: 7.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7756, Training Loss: 3.563e-01, Validation Loss: 7.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7757, Training Loss: 3.563e-01, Validation Loss: 7.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7758, Training Loss: 3.562e-01, Validation Loss: 7.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7759, Training Loss: 3.562e-01, Validation Loss: 7.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7760, Training Loss: 3.561e-01, Validation Loss: 7.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7761, Training Loss: 3.561e-01, Validation Loss: 7.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7762, Training Loss: 3.560e-01, Validation Loss: 7.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7763, Training Loss: 3.560e-01, Validation Loss: 7.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7764, Training Loss: 3.559e-01, Validation Loss: 7.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7765, Training Loss: 3.559e-01, Validation Loss: 7.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7766, Training Loss: 3.558e-01, Validation Loss: 7.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7767, Training Loss: 3.558e-01, Validation Loss: 7.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7768, Training Loss: 3.558e-01, Validation Loss: 7.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7769, Training Loss: 3.557e-01, Validation Loss: 7.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7770, Training Loss: 3.557e-01, Validation Loss: 7.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7771, Training Loss: 3.556e-01, Validation Loss: 7.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7772, Training Loss: 3.556e-01, Validation Loss: 7.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7773, Training Loss: 3.555e-01, Validation Loss: 7.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7774, Training Loss: 3.555e-01, Validation Loss: 7.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7775, Training Loss: 3.554e-01, Validation Loss: 7.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7776, Training Loss: 3.554e-01, Validation Loss: 7.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7777, Training Loss: 3.553e-01, Validation Loss: 7.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7778, Training Loss: 3.553e-01, Validation Loss: 7.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7779, Training Loss: 3.552e-01, Validation Loss: 7.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7780, Training Loss: 3.552e-01, Validation Loss: 7.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7781, Training Loss: 3.551e-01, Validation Loss: 7.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7782, Training Loss: 3.551e-01, Validation Loss: 7.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7783, Training Loss: 3.550e-01, Validation Loss: 7.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7784, Training Loss: 3.550e-01, Validation Loss: 7.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7785, Training Loss: 3.549e-01, Validation Loss: 7.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7786, Training Loss: 3.549e-01, Validation Loss: 7.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7787, Training Loss: 3.548e-01, Validation Loss: 7.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7788, Training Loss: 3.548e-01, Validation Loss: 7.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7789, Training Loss: 3.547e-01, Validation Loss: 7.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7790, Training Loss: 3.547e-01, Validation Loss: 7.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7791, Training Loss: 3.546e-01, Validation Loss: 7.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7792, Training Loss: 3.546e-01, Validation Loss: 7.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7793, Training Loss: 3.545e-01, Validation Loss: 7.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7794, Training Loss: 3.545e-01, Validation Loss: 7.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7795, Training Loss: 3.544e-01, Validation Loss: 7.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7796, Training Loss: 3.544e-01, Validation Loss: 7.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7797, Training Loss: 3.544e-01, Validation Loss: 7.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7798, Training Loss: 3.543e-01, Validation Loss: 7.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7799, Training Loss: 3.543e-01, Validation Loss: 7.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7800, Training Loss: 3.542e-01, Validation Loss: 7.069e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 7801, Training Loss: 3.542e-01, Validation Loss: 7.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7802, Training Loss: 3.541e-01, Validation Loss: 7.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7803, Training Loss: 3.541e-01, Validation Loss: 7.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7804, Training Loss: 3.540e-01, Validation Loss: 7.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7805, Training Loss: 3.540e-01, Validation Loss: 7.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7806, Training Loss: 3.539e-01, Validation Loss: 7.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7807, Training Loss: 3.539e-01, Validation Loss: 7.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7808, Training Loss: 3.538e-01, Validation Loss: 7.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7809, Training Loss: 3.538e-01, Validation Loss: 7.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7810, Training Loss: 3.537e-01, Validation Loss: 7.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7811, Training Loss: 3.537e-01, Validation Loss: 7.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7812, Training Loss: 3.536e-01, Validation Loss: 7.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7813, Training Loss: 3.536e-01, Validation Loss: 7.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7814, Training Loss: 3.535e-01, Validation Loss: 7.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7815, Training Loss: 3.535e-01, Validation Loss: 7.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7816, Training Loss: 3.534e-01, Validation Loss: 7.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7817, Training Loss: 3.534e-01, Validation Loss: 7.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7818, Training Loss: 3.533e-01, Validation Loss: 7.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7819, Training Loss: 3.533e-01, Validation Loss: 7.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7820, Training Loss: 3.532e-01, Validation Loss: 7.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7821, Training Loss: 3.532e-01, Validation Loss: 7.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7822, Training Loss: 3.531e-01, Validation Loss: 7.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7823, Training Loss: 3.531e-01, Validation Loss: 7.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7824, Training Loss: 3.531e-01, Validation Loss: 7.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7825, Training Loss: 3.530e-01, Validation Loss: 7.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7826, Training Loss: 3.530e-01, Validation Loss: 7.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7827, Training Loss: 3.529e-01, Validation Loss: 7.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7828, Training Loss: 3.529e-01, Validation Loss: 7.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7829, Training Loss: 3.528e-01, Validation Loss: 7.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7830, Training Loss: 3.528e-01, Validation Loss: 7.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7831, Training Loss: 3.527e-01, Validation Loss: 7.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7832, Training Loss: 3.527e-01, Validation Loss: 7.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7833, Training Loss: 3.526e-01, Validation Loss: 7.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7834, Training Loss: 3.526e-01, Validation Loss: 7.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7835, Training Loss: 3.525e-01, Validation Loss: 7.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7836, Training Loss: 3.525e-01, Validation Loss: 7.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7837, Training Loss: 3.524e-01, Validation Loss: 7.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7838, Training Loss: 3.524e-01, Validation Loss: 7.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7839, Training Loss: 3.523e-01, Validation Loss: 7.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7840, Training Loss: 3.523e-01, Validation Loss: 7.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7841, Training Loss: 3.522e-01, Validation Loss: 7.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7842, Training Loss: 3.522e-01, Validation Loss: 7.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7843, Training Loss: 3.521e-01, Validation Loss: 7.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7844, Training Loss: 3.521e-01, Validation Loss: 7.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7845, Training Loss: 3.520e-01, Validation Loss: 7.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7846, Training Loss: 3.520e-01, Validation Loss: 7.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7847, Training Loss: 3.520e-01, Validation Loss: 7.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7848, Training Loss: 3.519e-01, Validation Loss: 7.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7849, Training Loss: 3.519e-01, Validation Loss: 7.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7850, Training Loss: 3.518e-01, Validation Loss: 7.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7851, Training Loss: 3.518e-01, Validation Loss: 7.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7852, Training Loss: 3.517e-01, Validation Loss: 7.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7853, Training Loss: 3.517e-01, Validation Loss: 7.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7854, Training Loss: 3.516e-01, Validation Loss: 7.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7855, Training Loss: 3.516e-01, Validation Loss: 7.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7856, Training Loss: 3.515e-01, Validation Loss: 7.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7857, Training Loss: 3.515e-01, Validation Loss: 7.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7858, Training Loss: 3.514e-01, Validation Loss: 7.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7859, Training Loss: 3.514e-01, Validation Loss: 7.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7860, Training Loss: 3.513e-01, Validation Loss: 7.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7861, Training Loss: 3.513e-01, Validation Loss: 7.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7862, Training Loss: 3.512e-01, Validation Loss: 7.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7863, Training Loss: 3.512e-01, Validation Loss: 7.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7864, Training Loss: 3.511e-01, Validation Loss: 7.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7865, Training Loss: 3.511e-01, Validation Loss: 7.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7866, Training Loss: 3.510e-01, Validation Loss: 7.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7867, Training Loss: 3.510e-01, Validation Loss: 7.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7868, Training Loss: 3.510e-01, Validation Loss: 7.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7869, Training Loss: 3.509e-01, Validation Loss: 7.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7870, Training Loss: 3.509e-01, Validation Loss: 7.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7871, Training Loss: 3.508e-01, Validation Loss: 7.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7872, Training Loss: 3.508e-01, Validation Loss: 7.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7873, Training Loss: 3.507e-01, Validation Loss: 7.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7874, Training Loss: 3.507e-01, Validation Loss: 7.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7875, Training Loss: 3.506e-01, Validation Loss: 7.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7876, Training Loss: 3.506e-01, Validation Loss: 7.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7877, Training Loss: 3.505e-01, Validation Loss: 7.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7878, Training Loss: 3.505e-01, Validation Loss: 7.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7879, Training Loss: 3.504e-01, Validation Loss: 7.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7880, Training Loss: 3.504e-01, Validation Loss: 7.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7881, Training Loss: 3.503e-01, Validation Loss: 7.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7882, Training Loss: 3.503e-01, Validation Loss: 7.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7883, Training Loss: 3.502e-01, Validation Loss: 7.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7884, Training Loss: 3.502e-01, Validation Loss: 7.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7885, Training Loss: 3.501e-01, Validation Loss: 7.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7886, Training Loss: 3.501e-01, Validation Loss: 7.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7887, Training Loss: 3.501e-01, Validation Loss: 7.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7888, Training Loss: 3.500e-01, Validation Loss: 7.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7889, Training Loss: 3.500e-01, Validation Loss: 7.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7890, Training Loss: 3.499e-01, Validation Loss: 7.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7891, Training Loss: 3.499e-01, Validation Loss: 7.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7892, Training Loss: 3.498e-01, Validation Loss: 7.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7893, Training Loss: 3.498e-01, Validation Loss: 7.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7894, Training Loss: 3.497e-01, Validation Loss: 7.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7895, Training Loss: 3.497e-01, Validation Loss: 7.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7896, Training Loss: 3.496e-01, Validation Loss: 7.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7897, Training Loss: 3.496e-01, Validation Loss: 7.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7898, Training Loss: 3.495e-01, Validation Loss: 7.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7899, Training Loss: 3.495e-01, Validation Loss: 7.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7900, Training Loss: 3.494e-01, Validation Loss: 7.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7901, Training Loss: 3.494e-01, Validation Loss: 7.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7902, Training Loss: 3.493e-01, Validation Loss: 7.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7903, Training Loss: 3.493e-01, Validation Loss: 7.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7904, Training Loss: 3.493e-01, Validation Loss: 7.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7905, Training Loss: 3.492e-01, Validation Loss: 7.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7906, Training Loss: 3.492e-01, Validation Loss: 7.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7907, Training Loss: 3.491e-01, Validation Loss: 7.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7908, Training Loss: 3.491e-01, Validation Loss: 7.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7909, Training Loss: 3.490e-01, Validation Loss: 7.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7910, Training Loss: 3.490e-01, Validation Loss: 7.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7911, Training Loss: 3.489e-01, Validation Loss: 7.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7912, Training Loss: 3.489e-01, Validation Loss: 7.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7913, Training Loss: 3.488e-01, Validation Loss: 7.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7914, Training Loss: 3.488e-01, Validation Loss: 7.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7915, Training Loss: 3.487e-01, Validation Loss: 7.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7916, Training Loss: 3.487e-01, Validation Loss: 7.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7917, Training Loss: 3.486e-01, Validation Loss: 7.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7918, Training Loss: 3.486e-01, Validation Loss: 7.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7919, Training Loss: 3.485e-01, Validation Loss: 7.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7920, Training Loss: 3.485e-01, Validation Loss: 7.029e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 7921, Training Loss: 3.485e-01, Validation Loss: 7.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7922, Training Loss: 3.484e-01, Validation Loss: 7.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7923, Training Loss: 3.484e-01, Validation Loss: 7.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7924, Training Loss: 3.483e-01, Validation Loss: 7.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7925, Training Loss: 3.483e-01, Validation Loss: 7.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7926, Training Loss: 3.482e-01, Validation Loss: 7.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7927, Training Loss: 3.482e-01, Validation Loss: 7.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7928, Training Loss: 3.481e-01, Validation Loss: 7.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7929, Training Loss: 3.481e-01, Validation Loss: 7.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7930, Training Loss: 3.480e-01, Validation Loss: 7.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7931, Training Loss: 3.480e-01, Validation Loss: 7.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7932, Training Loss: 3.479e-01, Validation Loss: 7.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7933, Training Loss: 3.479e-01, Validation Loss: 7.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7934, Training Loss: 3.478e-01, Validation Loss: 7.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7935, Training Loss: 3.478e-01, Validation Loss: 7.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7936, Training Loss: 3.477e-01, Validation Loss: 7.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7937, Training Loss: 3.477e-01, Validation Loss: 7.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7938, Training Loss: 3.477e-01, Validation Loss: 7.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7939, Training Loss: 3.476e-01, Validation Loss: 7.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7940, Training Loss: 3.476e-01, Validation Loss: 7.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7941, Training Loss: 3.475e-01, Validation Loss: 7.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7942, Training Loss: 3.475e-01, Validation Loss: 7.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7943, Training Loss: 3.474e-01, Validation Loss: 7.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7944, Training Loss: 3.474e-01, Validation Loss: 7.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7945, Training Loss: 3.473e-01, Validation Loss: 7.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7946, Training Loss: 3.473e-01, Validation Loss: 7.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7947, Training Loss: 3.472e-01, Validation Loss: 7.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7948, Training Loss: 3.472e-01, Validation Loss: 7.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7949, Training Loss: 3.471e-01, Validation Loss: 7.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7950, Training Loss: 3.471e-01, Validation Loss: 7.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7951, Training Loss: 3.470e-01, Validation Loss: 7.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7952, Training Loss: 3.470e-01, Validation Loss: 7.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7953, Training Loss: 3.470e-01, Validation Loss: 7.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7954, Training Loss: 3.469e-01, Validation Loss: 7.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7955, Training Loss: 3.469e-01, Validation Loss: 7.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7956, Training Loss: 3.468e-01, Validation Loss: 7.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7957, Training Loss: 3.468e-01, Validation Loss: 7.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7958, Training Loss: 3.467e-01, Validation Loss: 7.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7959, Training Loss: 3.467e-01, Validation Loss: 7.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7960, Training Loss: 3.466e-01, Validation Loss: 7.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7961, Training Loss: 3.466e-01, Validation Loss: 7.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7962, Training Loss: 3.465e-01, Validation Loss: 7.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7963, Training Loss: 3.465e-01, Validation Loss: 7.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7964, Training Loss: 3.464e-01, Validation Loss: 7.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7965, Training Loss: 3.464e-01, Validation Loss: 7.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7966, Training Loss: 3.464e-01, Validation Loss: 7.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7967, Training Loss: 3.463e-01, Validation Loss: 7.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7968, Training Loss: 3.463e-01, Validation Loss: 7.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7969, Training Loss: 3.462e-01, Validation Loss: 7.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7970, Training Loss: 3.462e-01, Validation Loss: 7.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7971, Training Loss: 3.461e-01, Validation Loss: 7.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7972, Training Loss: 3.461e-01, Validation Loss: 7.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7973, Training Loss: 3.460e-01, Validation Loss: 7.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7974, Training Loss: 3.460e-01, Validation Loss: 7.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7975, Training Loss: 3.459e-01, Validation Loss: 7.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7976, Training Loss: 3.459e-01, Validation Loss: 7.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7977, Training Loss: 3.458e-01, Validation Loss: 7.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7978, Training Loss: 3.458e-01, Validation Loss: 7.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7979, Training Loss: 3.457e-01, Validation Loss: 7.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7980, Training Loss: 3.457e-01, Validation Loss: 7.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7981, Training Loss: 3.457e-01, Validation Loss: 7.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7982, Training Loss: 3.456e-01, Validation Loss: 7.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7983, Training Loss: 3.456e-01, Validation Loss: 7.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7984, Training Loss: 3.455e-01, Validation Loss: 7.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7985, Training Loss: 3.455e-01, Validation Loss: 7.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7986, Training Loss: 3.454e-01, Validation Loss: 7.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7987, Training Loss: 3.454e-01, Validation Loss: 7.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7988, Training Loss: 3.453e-01, Validation Loss: 7.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7989, Training Loss: 3.453e-01, Validation Loss: 7.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7990, Training Loss: 3.452e-01, Validation Loss: 7.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7991, Training Loss: 3.452e-01, Validation Loss: 7.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7992, Training Loss: 3.451e-01, Validation Loss: 7.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7993, Training Loss: 3.451e-01, Validation Loss: 7.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7994, Training Loss: 3.451e-01, Validation Loss: 7.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7995, Training Loss: 3.450e-01, Validation Loss: 7.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7996, Training Loss: 3.450e-01, Validation Loss: 7.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7997, Training Loss: 3.449e-01, Validation Loss: 7.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7998, Training Loss: 3.449e-01, Validation Loss: 7.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 7999, Training Loss: 3.448e-01, Validation Loss: 7.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8000, Training Loss: 3.448e-01, Validation Loss: 7.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8001, Training Loss: 3.447e-01, Validation Loss: 7.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8002, Training Loss: 3.447e-01, Validation Loss: 7.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8003, Training Loss: 3.446e-01, Validation Loss: 7.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8004, Training Loss: 3.446e-01, Validation Loss: 7.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8005, Training Loss: 3.445e-01, Validation Loss: 7.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8006, Training Loss: 3.445e-01, Validation Loss: 7.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8007, Training Loss: 3.445e-01, Validation Loss: 7.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8008, Training Loss: 3.444e-01, Validation Loss: 7.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8009, Training Loss: 3.444e-01, Validation Loss: 7.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8010, Training Loss: 3.443e-01, Validation Loss: 6.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8011, Training Loss: 3.443e-01, Validation Loss: 6.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8012, Training Loss: 3.442e-01, Validation Loss: 6.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8013, Training Loss: 3.442e-01, Validation Loss: 6.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8014, Training Loss: 3.441e-01, Validation Loss: 6.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8015, Training Loss: 3.441e-01, Validation Loss: 6.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8016, Training Loss: 3.440e-01, Validation Loss: 6.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8017, Training Loss: 3.440e-01, Validation Loss: 6.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8018, Training Loss: 3.439e-01, Validation Loss: 6.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8019, Training Loss: 3.439e-01, Validation Loss: 6.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8020, Training Loss: 3.439e-01, Validation Loss: 6.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8021, Training Loss: 3.438e-01, Validation Loss: 6.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8022, Training Loss: 3.438e-01, Validation Loss: 6.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8023, Training Loss: 3.437e-01, Validation Loss: 6.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8024, Training Loss: 3.437e-01, Validation Loss: 6.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8025, Training Loss: 3.436e-01, Validation Loss: 6.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8026, Training Loss: 3.436e-01, Validation Loss: 6.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8027, Training Loss: 3.435e-01, Validation Loss: 6.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8028, Training Loss: 3.435e-01, Validation Loss: 6.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8029, Training Loss: 3.434e-01, Validation Loss: 6.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8030, Training Loss: 3.434e-01, Validation Loss: 6.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8031, Training Loss: 3.433e-01, Validation Loss: 6.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8032, Training Loss: 3.433e-01, Validation Loss: 6.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8033, Training Loss: 3.433e-01, Validation Loss: 6.992e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8034, Training Loss: 3.432e-01, Validation Loss: 6.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8035, Training Loss: 3.432e-01, Validation Loss: 6.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8036, Training Loss: 3.431e-01, Validation Loss: 6.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8037, Training Loss: 3.431e-01, Validation Loss: 6.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8038, Training Loss: 3.430e-01, Validation Loss: 6.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8039, Training Loss: 3.430e-01, Validation Loss: 6.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8040, Training Loss: 3.429e-01, Validation Loss: 6.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8041, Training Loss: 3.429e-01, Validation Loss: 6.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8042, Training Loss: 3.428e-01, Validation Loss: 6.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8043, Training Loss: 3.428e-01, Validation Loss: 6.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8044, Training Loss: 3.428e-01, Validation Loss: 6.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8045, Training Loss: 3.427e-01, Validation Loss: 6.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8046, Training Loss: 3.427e-01, Validation Loss: 6.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8047, Training Loss: 3.426e-01, Validation Loss: 6.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8048, Training Loss: 3.426e-01, Validation Loss: 6.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8049, Training Loss: 3.425e-01, Validation Loss: 6.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8050, Training Loss: 3.425e-01, Validation Loss: 6.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8051, Training Loss: 3.424e-01, Validation Loss: 6.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8052, Training Loss: 3.424e-01, Validation Loss: 6.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8053, Training Loss: 3.423e-01, Validation Loss: 6.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8054, Training Loss: 3.423e-01, Validation Loss: 6.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8055, Training Loss: 3.422e-01, Validation Loss: 6.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8056, Training Loss: 3.422e-01, Validation Loss: 6.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8057, Training Loss: 3.422e-01, Validation Loss: 6.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8058, Training Loss: 3.421e-01, Validation Loss: 6.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8059, Training Loss: 3.421e-01, Validation Loss: 6.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8060, Training Loss: 3.420e-01, Validation Loss: 6.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8061, Training Loss: 3.420e-01, Validation Loss: 6.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8062, Training Loss: 3.419e-01, Validation Loss: 6.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8063, Training Loss: 3.419e-01, Validation Loss: 6.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8064, Training Loss: 3.418e-01, Validation Loss: 6.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8065, Training Loss: 3.418e-01, Validation Loss: 6.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8066, Training Loss: 3.417e-01, Validation Loss: 6.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8067, Training Loss: 3.417e-01, Validation Loss: 6.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8068, Training Loss: 3.417e-01, Validation Loss: 6.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8069, Training Loss: 3.416e-01, Validation Loss: 6.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8070, Training Loss: 3.416e-01, Validation Loss: 6.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8071, Training Loss: 3.415e-01, Validation Loss: 6.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8072, Training Loss: 3.415e-01, Validation Loss: 6.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8073, Training Loss: 3.414e-01, Validation Loss: 6.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8074, Training Loss: 3.414e-01, Validation Loss: 6.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8075, Training Loss: 3.413e-01, Validation Loss: 6.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8076, Training Loss: 3.413e-01, Validation Loss: 6.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8077, Training Loss: 3.412e-01, Validation Loss: 6.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8078, Training Loss: 3.412e-01, Validation Loss: 6.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8079, Training Loss: 3.412e-01, Validation Loss: 6.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8080, Training Loss: 3.411e-01, Validation Loss: 6.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8081, Training Loss: 3.411e-01, Validation Loss: 6.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8082, Training Loss: 3.410e-01, Validation Loss: 6.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8083, Training Loss: 3.410e-01, Validation Loss: 6.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8084, Training Loss: 3.409e-01, Validation Loss: 6.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8085, Training Loss: 3.409e-01, Validation Loss: 6.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8086, Training Loss: 3.408e-01, Validation Loss: 6.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8087, Training Loss: 3.408e-01, Validation Loss: 6.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8088, Training Loss: 3.407e-01, Validation Loss: 6.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8089, Training Loss: 3.407e-01, Validation Loss: 6.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8090, Training Loss: 3.407e-01, Validation Loss: 6.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8091, Training Loss: 3.406e-01, Validation Loss: 6.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8092, Training Loss: 3.406e-01, Validation Loss: 6.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8093, Training Loss: 3.405e-01, Validation Loss: 6.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8094, Training Loss: 3.405e-01, Validation Loss: 6.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8095, Training Loss: 3.404e-01, Validation Loss: 6.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8096, Training Loss: 3.404e-01, Validation Loss: 6.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8097, Training Loss: 3.403e-01, Validation Loss: 6.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8098, Training Loss: 3.403e-01, Validation Loss: 6.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8099, Training Loss: 3.402e-01, Validation Loss: 6.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8100, Training Loss: 3.402e-01, Validation Loss: 6.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8101, Training Loss: 3.402e-01, Validation Loss: 6.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8102, Training Loss: 3.401e-01, Validation Loss: 6.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8103, Training Loss: 3.401e-01, Validation Loss: 6.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8104, Training Loss: 3.400e-01, Validation Loss: 6.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8105, Training Loss: 3.400e-01, Validation Loss: 6.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8106, Training Loss: 3.399e-01, Validation Loss: 6.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8107, Training Loss: 3.399e-01, Validation Loss: 6.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8108, Training Loss: 3.398e-01, Validation Loss: 6.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8109, Training Loss: 3.398e-01, Validation Loss: 6.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8110, Training Loss: 3.398e-01, Validation Loss: 6.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8111, Training Loss: 3.397e-01, Validation Loss: 6.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8112, Training Loss: 3.397e-01, Validation Loss: 6.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8113, Training Loss: 3.396e-01, Validation Loss: 6.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8114, Training Loss: 3.396e-01, Validation Loss: 6.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8115, Training Loss: 3.395e-01, Validation Loss: 6.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8116, Training Loss: 3.395e-01, Validation Loss: 6.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8117, Training Loss: 3.394e-01, Validation Loss: 6.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8118, Training Loss: 3.394e-01, Validation Loss: 6.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8119, Training Loss: 3.393e-01, Validation Loss: 6.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8120, Training Loss: 3.393e-01, Validation Loss: 6.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8121, Training Loss: 3.393e-01, Validation Loss: 6.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8122, Training Loss: 3.392e-01, Validation Loss: 6.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8123, Training Loss: 3.392e-01, Validation Loss: 6.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8124, Training Loss: 3.391e-01, Validation Loss: 6.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8125, Training Loss: 3.391e-01, Validation Loss: 6.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8126, Training Loss: 3.390e-01, Validation Loss: 6.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8127, Training Loss: 3.390e-01, Validation Loss: 6.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8128, Training Loss: 3.389e-01, Validation Loss: 6.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8129, Training Loss: 3.389e-01, Validation Loss: 6.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8130, Training Loss: 3.389e-01, Validation Loss: 6.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8131, Training Loss: 3.388e-01, Validation Loss: 6.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8132, Training Loss: 3.388e-01, Validation Loss: 6.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8133, Training Loss: 3.387e-01, Validation Loss: 6.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8134, Training Loss: 3.387e-01, Validation Loss: 6.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8135, Training Loss: 3.386e-01, Validation Loss: 6.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8136, Training Loss: 3.386e-01, Validation Loss: 6.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8137, Training Loss: 3.385e-01, Validation Loss: 6.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8138, Training Loss: 3.385e-01, Validation Loss: 6.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8139, Training Loss: 3.384e-01, Validation Loss: 6.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8140, Training Loss: 3.384e-01, Validation Loss: 6.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8141, Training Loss: 3.384e-01, Validation Loss: 6.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8142, Training Loss: 3.383e-01, Validation Loss: 6.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8143, Training Loss: 3.383e-01, Validation Loss: 6.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8144, Training Loss: 3.382e-01, Validation Loss: 6.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8145, Training Loss: 3.382e-01, Validation Loss: 6.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8146, Training Loss: 3.381e-01, Validation Loss: 6.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8147, Training Loss: 3.381e-01, Validation Loss: 6.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8148, Training Loss: 3.380e-01, Validation Loss: 6.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8149, Training Loss: 3.380e-01, Validation Loss: 6.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8150, Training Loss: 3.380e-01, Validation Loss: 6.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8151, Training Loss: 3.379e-01, Validation Loss: 6.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8152, Training Loss: 3.379e-01, Validation Loss: 6.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8153, Training Loss: 3.378e-01, Validation Loss: 6.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8154, Training Loss: 3.378e-01, Validation Loss: 6.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8155, Training Loss: 3.377e-01, Validation Loss: 6.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8156, Training Loss: 3.377e-01, Validation Loss: 6.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8157, Training Loss: 3.376e-01, Validation Loss: 6.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8158, Training Loss: 3.376e-01, Validation Loss: 6.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8159, Training Loss: 3.376e-01, Validation Loss: 6.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8160, Training Loss: 3.375e-01, Validation Loss: 6.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8161, Training Loss: 3.375e-01, Validation Loss: 6.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8162, Training Loss: 3.374e-01, Validation Loss: 6.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8163, Training Loss: 3.374e-01, Validation Loss: 6.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8164, Training Loss: 3.373e-01, Validation Loss: 6.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8165, Training Loss: 3.373e-01, Validation Loss: 6.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8166, Training Loss: 3.372e-01, Validation Loss: 6.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8167, Training Loss: 3.372e-01, Validation Loss: 6.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8168, Training Loss: 3.371e-01, Validation Loss: 6.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8169, Training Loss: 3.371e-01, Validation Loss: 6.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8170, Training Loss: 3.371e-01, Validation Loss: 6.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8171, Training Loss: 3.370e-01, Validation Loss: 6.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8172, Training Loss: 3.370e-01, Validation Loss: 6.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8173, Training Loss: 3.369e-01, Validation Loss: 6.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8174, Training Loss: 3.369e-01, Validation Loss: 6.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8175, Training Loss: 3.368e-01, Validation Loss: 6.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8176, Training Loss: 3.368e-01, Validation Loss: 6.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8177, Training Loss: 3.367e-01, Validation Loss: 6.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8178, Training Loss: 3.367e-01, Validation Loss: 6.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8179, Training Loss: 3.367e-01, Validation Loss: 6.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8180, Training Loss: 3.366e-01, Validation Loss: 6.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8181, Training Loss: 3.366e-01, Validation Loss: 6.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8182, Training Loss: 3.365e-01, Validation Loss: 6.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8183, Training Loss: 3.365e-01, Validation Loss: 6.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8184, Training Loss: 3.364e-01, Validation Loss: 6.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8185, Training Loss: 3.364e-01, Validation Loss: 6.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8186, Training Loss: 3.363e-01, Validation Loss: 6.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8187, Training Loss: 3.363e-01, Validation Loss: 6.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8188, Training Loss: 3.363e-01, Validation Loss: 6.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8189, Training Loss: 3.362e-01, Validation Loss: 6.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8190, Training Loss: 3.362e-01, Validation Loss: 6.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8191, Training Loss: 3.361e-01, Validation Loss: 6.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8192, Training Loss: 3.361e-01, Validation Loss: 6.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8193, Training Loss: 3.360e-01, Validation Loss: 6.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8194, Training Loss: 3.360e-01, Validation Loss: 6.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8195, Training Loss: 3.359e-01, Validation Loss: 6.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8196, Training Loss: 3.359e-01, Validation Loss: 6.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8197, Training Loss: 3.359e-01, Validation Loss: 6.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8198, Training Loss: 3.358e-01, Validation Loss: 6.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8199, Training Loss: 3.358e-01, Validation Loss: 6.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8200, Training Loss: 3.357e-01, Validation Loss: 6.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8201, Training Loss: 3.357e-01, Validation Loss: 6.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8202, Training Loss: 3.356e-01, Validation Loss: 6.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8203, Training Loss: 3.356e-01, Validation Loss: 6.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8204, Training Loss: 3.355e-01, Validation Loss: 6.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8205, Training Loss: 3.355e-01, Validation Loss: 6.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8206, Training Loss: 3.355e-01, Validation Loss: 6.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8207, Training Loss: 3.354e-01, Validation Loss: 6.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8208, Training Loss: 3.354e-01, Validation Loss: 6.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8209, Training Loss: 3.353e-01, Validation Loss: 6.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8210, Training Loss: 3.353e-01, Validation Loss: 6.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8211, Training Loss: 3.352e-01, Validation Loss: 6.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8212, Training Loss: 3.352e-01, Validation Loss: 6.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8213, Training Loss: 3.351e-01, Validation Loss: 6.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8214, Training Loss: 3.351e-01, Validation Loss: 6.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8215, Training Loss: 3.351e-01, Validation Loss: 6.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8216, Training Loss: 3.350e-01, Validation Loss: 6.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8217, Training Loss: 3.350e-01, Validation Loss: 6.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8218, Training Loss: 3.349e-01, Validation Loss: 6.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8219, Training Loss: 3.349e-01, Validation Loss: 6.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8220, Training Loss: 3.348e-01, Validation Loss: 6.934e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8221, Training Loss: 3.348e-01, Validation Loss: 6.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8222, Training Loss: 3.348e-01, Validation Loss: 6.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8223, Training Loss: 3.347e-01, Validation Loss: 6.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8224, Training Loss: 3.347e-01, Validation Loss: 6.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8225, Training Loss: 3.346e-01, Validation Loss: 6.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8226, Training Loss: 3.346e-01, Validation Loss: 6.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8227, Training Loss: 3.345e-01, Validation Loss: 6.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8228, Training Loss: 3.345e-01, Validation Loss: 6.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8229, Training Loss: 3.344e-01, Validation Loss: 6.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8230, Training Loss: 3.344e-01, Validation Loss: 6.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8231, Training Loss: 3.344e-01, Validation Loss: 6.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8232, Training Loss: 3.343e-01, Validation Loss: 6.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8233, Training Loss: 3.343e-01, Validation Loss: 6.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8234, Training Loss: 3.342e-01, Validation Loss: 6.930e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8235, Training Loss: 3.342e-01, Validation Loss: 6.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8236, Training Loss: 3.341e-01, Validation Loss: 6.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8237, Training Loss: 3.341e-01, Validation Loss: 6.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8238, Training Loss: 3.340e-01, Validation Loss: 6.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8239, Training Loss: 3.340e-01, Validation Loss: 6.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8240, Training Loss: 3.340e-01, Validation Loss: 6.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8241, Training Loss: 3.339e-01, Validation Loss: 6.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8242, Training Loss: 3.339e-01, Validation Loss: 6.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8243, Training Loss: 3.338e-01, Validation Loss: 6.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8244, Training Loss: 3.338e-01, Validation Loss: 6.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8245, Training Loss: 3.337e-01, Validation Loss: 6.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8246, Training Loss: 3.337e-01, Validation Loss: 6.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8247, Training Loss: 3.337e-01, Validation Loss: 6.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8248, Training Loss: 3.336e-01, Validation Loss: 6.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8249, Training Loss: 3.336e-01, Validation Loss: 6.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8250, Training Loss: 3.335e-01, Validation Loss: 6.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8251, Training Loss: 3.335e-01, Validation Loss: 6.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8252, Training Loss: 3.334e-01, Validation Loss: 6.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8253, Training Loss: 3.334e-01, Validation Loss: 6.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8254, Training Loss: 3.333e-01, Validation Loss: 6.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8255, Training Loss: 3.333e-01, Validation Loss: 6.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8256, Training Loss: 3.333e-01, Validation Loss: 6.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8257, Training Loss: 3.332e-01, Validation Loss: 6.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8258, Training Loss: 3.332e-01, Validation Loss: 6.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8259, Training Loss: 3.331e-01, Validation Loss: 6.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8260, Training Loss: 3.331e-01, Validation Loss: 6.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8261, Training Loss: 3.330e-01, Validation Loss: 6.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8262, Training Loss: 3.330e-01, Validation Loss: 6.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8263, Training Loss: 3.330e-01, Validation Loss: 6.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8264, Training Loss: 3.329e-01, Validation Loss: 6.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8265, Training Loss: 3.329e-01, Validation Loss: 6.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8266, Training Loss: 3.328e-01, Validation Loss: 6.920e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8267, Training Loss: 3.328e-01, Validation Loss: 6.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8268, Training Loss: 3.327e-01, Validation Loss: 6.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8269, Training Loss: 3.327e-01, Validation Loss: 6.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8270, Training Loss: 3.326e-01, Validation Loss: 6.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8271, Training Loss: 3.326e-01, Validation Loss: 6.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8272, Training Loss: 3.326e-01, Validation Loss: 6.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8273, Training Loss: 3.325e-01, Validation Loss: 6.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8274, Training Loss: 3.325e-01, Validation Loss: 6.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8275, Training Loss: 3.324e-01, Validation Loss: 6.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8276, Training Loss: 3.324e-01, Validation Loss: 6.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8277, Training Loss: 3.323e-01, Validation Loss: 6.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8278, Training Loss: 3.323e-01, Validation Loss: 6.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8279, Training Loss: 3.323e-01, Validation Loss: 6.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8280, Training Loss: 3.322e-01, Validation Loss: 6.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8281, Training Loss: 3.322e-01, Validation Loss: 6.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8282, Training Loss: 3.321e-01, Validation Loss: 6.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8283, Training Loss: 3.321e-01, Validation Loss: 6.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8284, Training Loss: 3.320e-01, Validation Loss: 6.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8285, Training Loss: 3.320e-01, Validation Loss: 6.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8286, Training Loss: 3.319e-01, Validation Loss: 6.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8287, Training Loss: 3.319e-01, Validation Loss: 6.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8288, Training Loss: 3.319e-01, Validation Loss: 6.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8289, Training Loss: 3.318e-01, Validation Loss: 6.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8290, Training Loss: 3.318e-01, Validation Loss: 6.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8291, Training Loss: 3.317e-01, Validation Loss: 6.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8292, Training Loss: 3.317e-01, Validation Loss: 6.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8293, Training Loss: 3.316e-01, Validation Loss: 6.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8294, Training Loss: 3.316e-01, Validation Loss: 6.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8295, Training Loss: 3.316e-01, Validation Loss: 6.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8296, Training Loss: 3.315e-01, Validation Loss: 6.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8297, Training Loss: 3.315e-01, Validation Loss: 6.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8298, Training Loss: 3.314e-01, Validation Loss: 6.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8299, Training Loss: 3.314e-01, Validation Loss: 6.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8300, Training Loss: 3.313e-01, Validation Loss: 6.909e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8301, Training Loss: 3.313e-01, Validation Loss: 6.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8302, Training Loss: 3.312e-01, Validation Loss: 6.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8303, Training Loss: 3.312e-01, Validation Loss: 6.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8304, Training Loss: 3.312e-01, Validation Loss: 6.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8305, Training Loss: 3.311e-01, Validation Loss: 6.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8306, Training Loss: 3.311e-01, Validation Loss: 6.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8307, Training Loss: 3.310e-01, Validation Loss: 6.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8308, Training Loss: 3.310e-01, Validation Loss: 6.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8309, Training Loss: 3.309e-01, Validation Loss: 6.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8310, Training Loss: 3.309e-01, Validation Loss: 6.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8311, Training Loss: 3.309e-01, Validation Loss: 6.906e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8312, Training Loss: 3.308e-01, Validation Loss: 6.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8313, Training Loss: 3.308e-01, Validation Loss: 6.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8314, Training Loss: 3.307e-01, Validation Loss: 6.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8315, Training Loss: 3.307e-01, Validation Loss: 6.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8316, Training Loss: 3.306e-01, Validation Loss: 6.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8317, Training Loss: 3.306e-01, Validation Loss: 6.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8318, Training Loss: 3.306e-01, Validation Loss: 6.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8319, Training Loss: 3.305e-01, Validation Loss: 6.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8320, Training Loss: 3.305e-01, Validation Loss: 6.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8321, Training Loss: 3.304e-01, Validation Loss: 6.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8322, Training Loss: 3.304e-01, Validation Loss: 6.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8323, Training Loss: 3.303e-01, Validation Loss: 6.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8324, Training Loss: 3.303e-01, Validation Loss: 6.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8325, Training Loss: 3.303e-01, Validation Loss: 6.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8326, Training Loss: 3.302e-01, Validation Loss: 6.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8327, Training Loss: 3.302e-01, Validation Loss: 6.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8328, Training Loss: 3.301e-01, Validation Loss: 6.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8329, Training Loss: 3.301e-01, Validation Loss: 6.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8330, Training Loss: 3.300e-01, Validation Loss: 6.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8331, Training Loss: 3.300e-01, Validation Loss: 6.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8332, Training Loss: 3.300e-01, Validation Loss: 6.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8333, Training Loss: 3.299e-01, Validation Loss: 6.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8334, Training Loss: 3.299e-01, Validation Loss: 6.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8335, Training Loss: 3.298e-01, Validation Loss: 6.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8336, Training Loss: 3.298e-01, Validation Loss: 6.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8337, Training Loss: 3.297e-01, Validation Loss: 6.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8338, Training Loss: 3.297e-01, Validation Loss: 6.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8339, Training Loss: 3.296e-01, Validation Loss: 6.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8340, Training Loss: 3.296e-01, Validation Loss: 6.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8341, Training Loss: 3.296e-01, Validation Loss: 6.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8342, Training Loss: 3.295e-01, Validation Loss: 6.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8343, Training Loss: 3.295e-01, Validation Loss: 6.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8344, Training Loss: 3.294e-01, Validation Loss: 6.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8345, Training Loss: 3.294e-01, Validation Loss: 6.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8346, Training Loss: 3.293e-01, Validation Loss: 6.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8347, Training Loss: 3.293e-01, Validation Loss: 6.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8348, Training Loss: 3.293e-01, Validation Loss: 6.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8349, Training Loss: 3.292e-01, Validation Loss: 6.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8350, Training Loss: 3.292e-01, Validation Loss: 6.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8351, Training Loss: 3.291e-01, Validation Loss: 6.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8352, Training Loss: 3.291e-01, Validation Loss: 6.894e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8353, Training Loss: 3.290e-01, Validation Loss: 6.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8354, Training Loss: 3.290e-01, Validation Loss: 6.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8355, Training Loss: 3.290e-01, Validation Loss: 6.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8356, Training Loss: 3.289e-01, Validation Loss: 6.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8357, Training Loss: 3.289e-01, Validation Loss: 6.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8358, Training Loss: 3.288e-01, Validation Loss: 6.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8359, Training Loss: 3.288e-01, Validation Loss: 6.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8360, Training Loss: 3.287e-01, Validation Loss: 6.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8361, Training Loss: 3.287e-01, Validation Loss: 6.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8362, Training Loss: 3.287e-01, Validation Loss: 6.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8363, Training Loss: 3.286e-01, Validation Loss: 6.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8364, Training Loss: 3.286e-01, Validation Loss: 6.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8365, Training Loss: 3.285e-01, Validation Loss: 6.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8366, Training Loss: 3.285e-01, Validation Loss: 6.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8367, Training Loss: 3.284e-01, Validation Loss: 6.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8368, Training Loss: 3.284e-01, Validation Loss: 6.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8369, Training Loss: 3.284e-01, Validation Loss: 6.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8370, Training Loss: 3.283e-01, Validation Loss: 6.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8371, Training Loss: 3.283e-01, Validation Loss: 6.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8372, Training Loss: 3.282e-01, Validation Loss: 6.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8373, Training Loss: 3.282e-01, Validation Loss: 6.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8374, Training Loss: 3.281e-01, Validation Loss: 6.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8375, Training Loss: 3.281e-01, Validation Loss: 6.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8376, Training Loss: 3.281e-01, Validation Loss: 6.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8377, Training Loss: 3.280e-01, Validation Loss: 6.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8378, Training Loss: 3.280e-01, Validation Loss: 6.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8379, Training Loss: 3.279e-01, Validation Loss: 6.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8380, Training Loss: 3.279e-01, Validation Loss: 6.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8381, Training Loss: 3.278e-01, Validation Loss: 6.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8382, Training Loss: 3.278e-01, Validation Loss: 6.885e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8383, Training Loss: 3.278e-01, Validation Loss: 6.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8384, Training Loss: 3.277e-01, Validation Loss: 6.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8385, Training Loss: 3.277e-01, Validation Loss: 6.884e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8386, Training Loss: 3.276e-01, Validation Loss: 6.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8387, Training Loss: 3.276e-01, Validation Loss: 6.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8388, Training Loss: 3.275e-01, Validation Loss: 6.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8389, Training Loss: 3.275e-01, Validation Loss: 6.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8390, Training Loss: 3.275e-01, Validation Loss: 6.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8391, Training Loss: 3.274e-01, Validation Loss: 6.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8392, Training Loss: 3.274e-01, Validation Loss: 6.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8393, Training Loss: 3.273e-01, Validation Loss: 6.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8394, Training Loss: 3.273e-01, Validation Loss: 6.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8395, Training Loss: 3.272e-01, Validation Loss: 6.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8396, Training Loss: 3.272e-01, Validation Loss: 6.881e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8397, Training Loss: 3.272e-01, Validation Loss: 6.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8398, Training Loss: 3.271e-01, Validation Loss: 6.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8399, Training Loss: 3.271e-01, Validation Loss: 6.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8400, Training Loss: 3.270e-01, Validation Loss: 6.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8401, Training Loss: 3.270e-01, Validation Loss: 6.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8402, Training Loss: 3.269e-01, Validation Loss: 6.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8403, Training Loss: 3.269e-01, Validation Loss: 6.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8404, Training Loss: 3.269e-01, Validation Loss: 6.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8405, Training Loss: 3.268e-01, Validation Loss: 6.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8406, Training Loss: 3.268e-01, Validation Loss: 6.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8407, Training Loss: 3.267e-01, Validation Loss: 6.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8408, Training Loss: 3.267e-01, Validation Loss: 6.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8409, Training Loss: 3.266e-01, Validation Loss: 6.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8410, Training Loss: 3.266e-01, Validation Loss: 6.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8411, Training Loss: 3.266e-01, Validation Loss: 6.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8412, Training Loss: 3.265e-01, Validation Loss: 6.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8413, Training Loss: 3.265e-01, Validation Loss: 6.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8414, Training Loss: 3.264e-01, Validation Loss: 6.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8415, Training Loss: 3.264e-01, Validation Loss: 6.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8416, Training Loss: 3.264e-01, Validation Loss: 6.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8417, Training Loss: 3.263e-01, Validation Loss: 6.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8418, Training Loss: 3.263e-01, Validation Loss: 6.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8419, Training Loss: 3.262e-01, Validation Loss: 6.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8420, Training Loss: 3.262e-01, Validation Loss: 6.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8421, Training Loss: 3.261e-01, Validation Loss: 6.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8422, Training Loss: 3.261e-01, Validation Loss: 6.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8423, Training Loss: 3.261e-01, Validation Loss: 6.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8424, Training Loss: 3.260e-01, Validation Loss: 6.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8425, Training Loss: 3.260e-01, Validation Loss: 6.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8426, Training Loss: 3.259e-01, Validation Loss: 6.872e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8427, Training Loss: 3.259e-01, Validation Loss: 6.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8428, Training Loss: 3.258e-01, Validation Loss: 6.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8429, Training Loss: 3.258e-01, Validation Loss: 6.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8430, Training Loss: 3.258e-01, Validation Loss: 6.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8431, Training Loss: 3.257e-01, Validation Loss: 6.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8432, Training Loss: 3.257e-01, Validation Loss: 6.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8433, Training Loss: 3.256e-01, Validation Loss: 6.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8434, Training Loss: 3.256e-01, Validation Loss: 6.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8435, Training Loss: 3.255e-01, Validation Loss: 6.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8436, Training Loss: 3.255e-01, Validation Loss: 6.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8437, Training Loss: 3.255e-01, Validation Loss: 6.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8438, Training Loss: 3.254e-01, Validation Loss: 6.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8439, Training Loss: 3.254e-01, Validation Loss: 6.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8440, Training Loss: 3.253e-01, Validation Loss: 6.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8441, Training Loss: 3.253e-01, Validation Loss: 6.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8442, Training Loss: 3.252e-01, Validation Loss: 6.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8443, Training Loss: 3.252e-01, Validation Loss: 6.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8444, Training Loss: 3.252e-01, Validation Loss: 6.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8445, Training Loss: 3.251e-01, Validation Loss: 6.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8446, Training Loss: 3.251e-01, Validation Loss: 6.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8447, Training Loss: 3.250e-01, Validation Loss: 6.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8448, Training Loss: 3.250e-01, Validation Loss: 6.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8449, Training Loss: 3.250e-01, Validation Loss: 6.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8450, Training Loss: 3.249e-01, Validation Loss: 6.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8451, Training Loss: 3.249e-01, Validation Loss: 6.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8452, Training Loss: 3.248e-01, Validation Loss: 6.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8453, Training Loss: 3.248e-01, Validation Loss: 6.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8454, Training Loss: 3.247e-01, Validation Loss: 6.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8455, Training Loss: 3.247e-01, Validation Loss: 6.863e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8456, Training Loss: 3.247e-01, Validation Loss: 6.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8457, Training Loss: 3.246e-01, Validation Loss: 6.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8458, Training Loss: 3.246e-01, Validation Loss: 6.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8459, Training Loss: 3.245e-01, Validation Loss: 6.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8460, Training Loss: 3.245e-01, Validation Loss: 6.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8461, Training Loss: 3.244e-01, Validation Loss: 6.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8462, Training Loss: 3.244e-01, Validation Loss: 6.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8463, Training Loss: 3.244e-01, Validation Loss: 6.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8464, Training Loss: 3.243e-01, Validation Loss: 6.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8465, Training Loss: 3.243e-01, Validation Loss: 6.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8466, Training Loss: 3.242e-01, Validation Loss: 6.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8467, Training Loss: 3.242e-01, Validation Loss: 6.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8468, Training Loss: 3.242e-01, Validation Loss: 6.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8469, Training Loss: 3.241e-01, Validation Loss: 6.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8470, Training Loss: 3.241e-01, Validation Loss: 6.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8471, Training Loss: 3.240e-01, Validation Loss: 6.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8472, Training Loss: 3.240e-01, Validation Loss: 6.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8473, Training Loss: 3.239e-01, Validation Loss: 6.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8474, Training Loss: 3.239e-01, Validation Loss: 6.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8475, Training Loss: 3.239e-01, Validation Loss: 6.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8476, Training Loss: 3.238e-01, Validation Loss: 6.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8477, Training Loss: 3.238e-01, Validation Loss: 6.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8478, Training Loss: 3.237e-01, Validation Loss: 6.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8479, Training Loss: 3.237e-01, Validation Loss: 6.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8480, Training Loss: 3.236e-01, Validation Loss: 6.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8481, Training Loss: 3.236e-01, Validation Loss: 6.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8482, Training Loss: 3.236e-01, Validation Loss: 6.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8483, Training Loss: 3.235e-01, Validation Loss: 6.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8484, Training Loss: 3.235e-01, Validation Loss: 6.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8485, Training Loss: 3.234e-01, Validation Loss: 6.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8486, Training Loss: 3.234e-01, Validation Loss: 6.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8487, Training Loss: 3.234e-01, Validation Loss: 6.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8488, Training Loss: 3.233e-01, Validation Loss: 6.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8489, Training Loss: 3.233e-01, Validation Loss: 6.853e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8490, Training Loss: 3.232e-01, Validation Loss: 6.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8491, Training Loss: 3.232e-01, Validation Loss: 6.853e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8492, Training Loss: 3.231e-01, Validation Loss: 6.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8493, Training Loss: 3.231e-01, Validation Loss: 6.852e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8494, Training Loss: 3.231e-01, Validation Loss: 6.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8495, Training Loss: 3.230e-01, Validation Loss: 6.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8496, Training Loss: 3.230e-01, Validation Loss: 6.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8497, Training Loss: 3.229e-01, Validation Loss: 6.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8498, Training Loss: 3.229e-01, Validation Loss: 6.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8499, Training Loss: 3.229e-01, Validation Loss: 6.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8500, Training Loss: 3.228e-01, Validation Loss: 6.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8501, Training Loss: 3.228e-01, Validation Loss: 6.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8502, Training Loss: 3.227e-01, Validation Loss: 6.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8503, Training Loss: 3.227e-01, Validation Loss: 6.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8504, Training Loss: 3.226e-01, Validation Loss: 6.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8505, Training Loss: 3.226e-01, Validation Loss: 6.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8506, Training Loss: 3.226e-01, Validation Loss: 6.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8507, Training Loss: 3.225e-01, Validation Loss: 6.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8508, Training Loss: 3.225e-01, Validation Loss: 6.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8509, Training Loss: 3.224e-01, Validation Loss: 6.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8510, Training Loss: 3.224e-01, Validation Loss: 6.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8511, Training Loss: 3.224e-01, Validation Loss: 6.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8512, Training Loss: 3.223e-01, Validation Loss: 6.846e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8513, Training Loss: 3.223e-01, Validation Loss: 6.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8514, Training Loss: 3.222e-01, Validation Loss: 6.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8515, Training Loss: 3.222e-01, Validation Loss: 6.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8516, Training Loss: 3.221e-01, Validation Loss: 6.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8517, Training Loss: 3.221e-01, Validation Loss: 6.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8518, Training Loss: 3.221e-01, Validation Loss: 6.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8519, Training Loss: 3.220e-01, Validation Loss: 6.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8520, Training Loss: 3.220e-01, Validation Loss: 6.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8521, Training Loss: 3.219e-01, Validation Loss: 6.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8522, Training Loss: 3.219e-01, Validation Loss: 6.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8523, Training Loss: 3.219e-01, Validation Loss: 6.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8524, Training Loss: 3.218e-01, Validation Loss: 6.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8525, Training Loss: 3.218e-01, Validation Loss: 6.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8526, Training Loss: 3.217e-01, Validation Loss: 6.842e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8527, Training Loss: 3.217e-01, Validation Loss: 6.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8528, Training Loss: 3.216e-01, Validation Loss: 6.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8529, Training Loss: 3.216e-01, Validation Loss: 6.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8530, Training Loss: 3.216e-01, Validation Loss: 6.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8531, Training Loss: 3.215e-01, Validation Loss: 6.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8532, Training Loss: 3.215e-01, Validation Loss: 6.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8533, Training Loss: 3.214e-01, Validation Loss: 6.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8534, Training Loss: 3.214e-01, Validation Loss: 6.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8535, Training Loss: 3.214e-01, Validation Loss: 6.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8536, Training Loss: 3.213e-01, Validation Loss: 6.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8537, Training Loss: 3.213e-01, Validation Loss: 6.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8538, Training Loss: 3.212e-01, Validation Loss: 6.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8539, Training Loss: 3.212e-01, Validation Loss: 6.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8540, Training Loss: 3.211e-01, Validation Loss: 6.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8541, Training Loss: 3.211e-01, Validation Loss: 6.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8542, Training Loss: 3.211e-01, Validation Loss: 6.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8543, Training Loss: 3.210e-01, Validation Loss: 6.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8544, Training Loss: 3.210e-01, Validation Loss: 6.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8545, Training Loss: 3.209e-01, Validation Loss: 6.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8546, Training Loss: 3.209e-01, Validation Loss: 6.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8547, Training Loss: 3.209e-01, Validation Loss: 6.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8548, Training Loss: 3.208e-01, Validation Loss: 6.836e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8549, Training Loss: 3.208e-01, Validation Loss: 6.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8550, Training Loss: 3.207e-01, Validation Loss: 6.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8551, Training Loss: 3.207e-01, Validation Loss: 6.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8552, Training Loss: 3.206e-01, Validation Loss: 6.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8553, Training Loss: 3.206e-01, Validation Loss: 6.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8554, Training Loss: 3.206e-01, Validation Loss: 6.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8555, Training Loss: 3.205e-01, Validation Loss: 6.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8556, Training Loss: 3.205e-01, Validation Loss: 6.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8557, Training Loss: 3.204e-01, Validation Loss: 6.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8558, Training Loss: 3.204e-01, Validation Loss: 6.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8559, Training Loss: 3.204e-01, Validation Loss: 6.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8560, Training Loss: 3.203e-01, Validation Loss: 6.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8561, Training Loss: 3.203e-01, Validation Loss: 6.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8562, Training Loss: 3.202e-01, Validation Loss: 6.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8563, Training Loss: 3.202e-01, Validation Loss: 6.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8564, Training Loss: 3.202e-01, Validation Loss: 6.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8565, Training Loss: 3.201e-01, Validation Loss: 6.831e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8566, Training Loss: 3.201e-01, Validation Loss: 6.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8567, Training Loss: 3.200e-01, Validation Loss: 6.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8568, Training Loss: 3.200e-01, Validation Loss: 6.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8569, Training Loss: 3.199e-01, Validation Loss: 6.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8570, Training Loss: 3.199e-01, Validation Loss: 6.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8571, Training Loss: 3.199e-01, Validation Loss: 6.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8572, Training Loss: 3.198e-01, Validation Loss: 6.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8573, Training Loss: 3.198e-01, Validation Loss: 6.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8574, Training Loss: 3.197e-01, Validation Loss: 6.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8575, Training Loss: 3.197e-01, Validation Loss: 6.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8576, Training Loss: 3.197e-01, Validation Loss: 6.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8577, Training Loss: 3.196e-01, Validation Loss: 6.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8578, Training Loss: 3.196e-01, Validation Loss: 6.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8579, Training Loss: 3.195e-01, Validation Loss: 6.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8580, Training Loss: 3.195e-01, Validation Loss: 6.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8581, Training Loss: 3.195e-01, Validation Loss: 6.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8582, Training Loss: 3.194e-01, Validation Loss: 6.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8583, Training Loss: 3.194e-01, Validation Loss: 6.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8584, Training Loss: 3.193e-01, Validation Loss: 6.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8585, Training Loss: 3.193e-01, Validation Loss: 6.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8586, Training Loss: 3.192e-01, Validation Loss: 6.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8587, Training Loss: 3.192e-01, Validation Loss: 6.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8588, Training Loss: 3.192e-01, Validation Loss: 6.824e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8589, Training Loss: 3.191e-01, Validation Loss: 6.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8590, Training Loss: 3.191e-01, Validation Loss: 6.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8591, Training Loss: 3.190e-01, Validation Loss: 6.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8592, Training Loss: 3.190e-01, Validation Loss: 6.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8593, Training Loss: 3.190e-01, Validation Loss: 6.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8594, Training Loss: 3.189e-01, Validation Loss: 6.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8595, Training Loss: 3.189e-01, Validation Loss: 6.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8596, Training Loss: 3.188e-01, Validation Loss: 6.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8597, Training Loss: 3.188e-01, Validation Loss: 6.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8598, Training Loss: 3.188e-01, Validation Loss: 6.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8599, Training Loss: 3.187e-01, Validation Loss: 6.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8600, Training Loss: 3.187e-01, Validation Loss: 6.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8601, Training Loss: 3.186e-01, Validation Loss: 6.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8602, Training Loss: 3.186e-01, Validation Loss: 6.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8603, Training Loss: 3.185e-01, Validation Loss: 6.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8604, Training Loss: 3.185e-01, Validation Loss: 6.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8605, Training Loss: 3.185e-01, Validation Loss: 6.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8606, Training Loss: 3.184e-01, Validation Loss: 6.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8607, Training Loss: 3.184e-01, Validation Loss: 6.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8608, Training Loss: 3.183e-01, Validation Loss: 6.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8609, Training Loss: 3.183e-01, Validation Loss: 6.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8610, Training Loss: 3.183e-01, Validation Loss: 6.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8611, Training Loss: 3.182e-01, Validation Loss: 6.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8612, Training Loss: 3.182e-01, Validation Loss: 6.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8613, Training Loss: 3.181e-01, Validation Loss: 6.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8614, Training Loss: 3.181e-01, Validation Loss: 6.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8615, Training Loss: 3.181e-01, Validation Loss: 6.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8616, Training Loss: 3.180e-01, Validation Loss: 6.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8617, Training Loss: 3.180e-01, Validation Loss: 6.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8618, Training Loss: 3.179e-01, Validation Loss: 6.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8619, Training Loss: 3.179e-01, Validation Loss: 6.816e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8620, Training Loss: 3.179e-01, Validation Loss: 6.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8621, Training Loss: 3.178e-01, Validation Loss: 6.815e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8622, Training Loss: 3.178e-01, Validation Loss: 6.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8623, Training Loss: 3.177e-01, Validation Loss: 6.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8624, Training Loss: 3.177e-01, Validation Loss: 6.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8625, Training Loss: 3.176e-01, Validation Loss: 6.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8626, Training Loss: 3.176e-01, Validation Loss: 6.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8627, Training Loss: 3.176e-01, Validation Loss: 6.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8628, Training Loss: 3.175e-01, Validation Loss: 6.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8629, Training Loss: 3.175e-01, Validation Loss: 6.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8630, Training Loss: 3.174e-01, Validation Loss: 6.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8631, Training Loss: 3.174e-01, Validation Loss: 6.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8632, Training Loss: 3.174e-01, Validation Loss: 6.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8633, Training Loss: 3.173e-01, Validation Loss: 6.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8634, Training Loss: 3.173e-01, Validation Loss: 6.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8635, Training Loss: 3.172e-01, Validation Loss: 6.811e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8636, Training Loss: 3.172e-01, Validation Loss: 6.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8637, Training Loss: 3.172e-01, Validation Loss: 6.811e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8638, Training Loss: 3.171e-01, Validation Loss: 6.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8639, Training Loss: 3.171e-01, Validation Loss: 6.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8640, Training Loss: 3.170e-01, Validation Loss: 6.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8641, Training Loss: 3.170e-01, Validation Loss: 6.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8642, Training Loss: 3.170e-01, Validation Loss: 6.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8643, Training Loss: 3.169e-01, Validation Loss: 6.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8644, Training Loss: 3.169e-01, Validation Loss: 6.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8645, Training Loss: 3.168e-01, Validation Loss: 6.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8646, Training Loss: 3.168e-01, Validation Loss: 6.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8647, Training Loss: 3.168e-01, Validation Loss: 6.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8648, Training Loss: 3.167e-01, Validation Loss: 6.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8649, Training Loss: 3.167e-01, Validation Loss: 6.807e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8650, Training Loss: 3.166e-01, Validation Loss: 6.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8651, Training Loss: 3.166e-01, Validation Loss: 6.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8652, Training Loss: 3.165e-01, Validation Loss: 6.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8653, Training Loss: 3.165e-01, Validation Loss: 6.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8654, Training Loss: 3.165e-01, Validation Loss: 6.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8655, Training Loss: 3.164e-01, Validation Loss: 6.806e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8656, Training Loss: 3.164e-01, Validation Loss: 6.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8657, Training Loss: 3.163e-01, Validation Loss: 6.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8658, Training Loss: 3.163e-01, Validation Loss: 6.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8659, Training Loss: 3.163e-01, Validation Loss: 6.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8660, Training Loss: 3.162e-01, Validation Loss: 6.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8661, Training Loss: 3.162e-01, Validation Loss: 6.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8662, Training Loss: 3.161e-01, Validation Loss: 6.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8663, Training Loss: 3.161e-01, Validation Loss: 6.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8664, Training Loss: 3.161e-01, Validation Loss: 6.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8665, Training Loss: 3.160e-01, Validation Loss: 6.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8666, Training Loss: 3.160e-01, Validation Loss: 6.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8667, Training Loss: 3.159e-01, Validation Loss: 6.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8668, Training Loss: 3.159e-01, Validation Loss: 6.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8669, Training Loss: 3.159e-01, Validation Loss: 6.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8670, Training Loss: 3.158e-01, Validation Loss: 6.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8671, Training Loss: 3.158e-01, Validation Loss: 6.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8672, Training Loss: 3.157e-01, Validation Loss: 6.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8673, Training Loss: 3.157e-01, Validation Loss: 6.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8674, Training Loss: 3.157e-01, Validation Loss: 6.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8675, Training Loss: 3.156e-01, Validation Loss: 6.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8676, Training Loss: 3.156e-01, Validation Loss: 6.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8677, Training Loss: 3.155e-01, Validation Loss: 6.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8678, Training Loss: 3.155e-01, Validation Loss: 6.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8679, Training Loss: 3.155e-01, Validation Loss: 6.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8680, Training Loss: 3.154e-01, Validation Loss: 6.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8681, Training Loss: 3.154e-01, Validation Loss: 6.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8682, Training Loss: 3.153e-01, Validation Loss: 6.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8683, Training Loss: 3.153e-01, Validation Loss: 6.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8684, Training Loss: 3.153e-01, Validation Loss: 6.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8685, Training Loss: 3.152e-01, Validation Loss: 6.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8686, Training Loss: 3.152e-01, Validation Loss: 6.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8687, Training Loss: 3.151e-01, Validation Loss: 6.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8688, Training Loss: 3.151e-01, Validation Loss: 6.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8689, Training Loss: 3.151e-01, Validation Loss: 6.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8690, Training Loss: 3.150e-01, Validation Loss: 6.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8691, Training Loss: 3.150e-01, Validation Loss: 6.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8692, Training Loss: 3.149e-01, Validation Loss: 6.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8693, Training Loss: 3.149e-01, Validation Loss: 6.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8694, Training Loss: 3.149e-01, Validation Loss: 6.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8695, Training Loss: 3.148e-01, Validation Loss: 6.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8696, Training Loss: 3.148e-01, Validation Loss: 6.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8697, Training Loss: 3.147e-01, Validation Loss: 6.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8698, Training Loss: 3.147e-01, Validation Loss: 6.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8699, Training Loss: 3.147e-01, Validation Loss: 6.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8700, Training Loss: 3.146e-01, Validation Loss: 6.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8701, Training Loss: 3.146e-01, Validation Loss: 6.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8702, Training Loss: 3.145e-01, Validation Loss: 6.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8703, Training Loss: 3.145e-01, Validation Loss: 6.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8704, Training Loss: 3.145e-01, Validation Loss: 6.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8705, Training Loss: 3.144e-01, Validation Loss: 6.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8706, Training Loss: 3.144e-01, Validation Loss: 6.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8707, Training Loss: 3.143e-01, Validation Loss: 6.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8708, Training Loss: 3.143e-01, Validation Loss: 6.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8709, Training Loss: 3.142e-01, Validation Loss: 6.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8710, Training Loss: 3.142e-01, Validation Loss: 6.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8711, Training Loss: 3.142e-01, Validation Loss: 6.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8712, Training Loss: 3.141e-01, Validation Loss: 6.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8713, Training Loss: 3.141e-01, Validation Loss: 6.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8714, Training Loss: 3.140e-01, Validation Loss: 6.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8715, Training Loss: 3.140e-01, Validation Loss: 6.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8716, Training Loss: 3.140e-01, Validation Loss: 6.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8717, Training Loss: 3.139e-01, Validation Loss: 6.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8718, Training Loss: 3.139e-01, Validation Loss: 6.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8719, Training Loss: 3.138e-01, Validation Loss: 6.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8720, Training Loss: 3.138e-01, Validation Loss: 6.788e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8721, Training Loss: 3.138e-01, Validation Loss: 6.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8722, Training Loss: 3.137e-01, Validation Loss: 6.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8723, Training Loss: 3.137e-01, Validation Loss: 6.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8724, Training Loss: 3.136e-01, Validation Loss: 6.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8725, Training Loss: 3.136e-01, Validation Loss: 6.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8726, Training Loss: 3.136e-01, Validation Loss: 6.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8727, Training Loss: 3.135e-01, Validation Loss: 6.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8728, Training Loss: 3.135e-01, Validation Loss: 6.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8729, Training Loss: 3.134e-01, Validation Loss: 6.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8730, Training Loss: 3.134e-01, Validation Loss: 6.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8731, Training Loss: 3.134e-01, Validation Loss: 6.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8732, Training Loss: 3.133e-01, Validation Loss: 6.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8733, Training Loss: 3.133e-01, Validation Loss: 6.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8734, Training Loss: 3.132e-01, Validation Loss: 6.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8735, Training Loss: 3.132e-01, Validation Loss: 6.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8736, Training Loss: 3.132e-01, Validation Loss: 6.784e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8737, Training Loss: 3.131e-01, Validation Loss: 6.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8738, Training Loss: 3.131e-01, Validation Loss: 6.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8739, Training Loss: 3.130e-01, Validation Loss: 6.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8740, Training Loss: 3.130e-01, Validation Loss: 6.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8741, Training Loss: 3.130e-01, Validation Loss: 6.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8742, Training Loss: 3.129e-01, Validation Loss: 6.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8743, Training Loss: 3.129e-01, Validation Loss: 6.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8744, Training Loss: 3.129e-01, Validation Loss: 6.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8745, Training Loss: 3.128e-01, Validation Loss: 6.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8746, Training Loss: 3.128e-01, Validation Loss: 6.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8747, Training Loss: 3.127e-01, Validation Loss: 6.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8748, Training Loss: 3.127e-01, Validation Loss: 6.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8749, Training Loss: 3.127e-01, Validation Loss: 6.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8750, Training Loss: 3.126e-01, Validation Loss: 6.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8751, Training Loss: 3.126e-01, Validation Loss: 6.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8752, Training Loss: 3.125e-01, Validation Loss: 6.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8753, Training Loss: 3.125e-01, Validation Loss: 6.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8754, Training Loss: 3.125e-01, Validation Loss: 6.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8755, Training Loss: 3.124e-01, Validation Loss: 6.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8756, Training Loss: 3.124e-01, Validation Loss: 6.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8757, Training Loss: 3.123e-01, Validation Loss: 6.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8758, Training Loss: 3.123e-01, Validation Loss: 6.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8759, Training Loss: 3.123e-01, Validation Loss: 6.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8760, Training Loss: 3.122e-01, Validation Loss: 6.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8761, Training Loss: 3.122e-01, Validation Loss: 6.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8762, Training Loss: 3.121e-01, Validation Loss: 6.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8763, Training Loss: 3.121e-01, Validation Loss: 6.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8764, Training Loss: 3.121e-01, Validation Loss: 6.776e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8765, Training Loss: 3.120e-01, Validation Loss: 6.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8766, Training Loss: 3.120e-01, Validation Loss: 6.775e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8767, Training Loss: 3.119e-01, Validation Loss: 6.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8768, Training Loss: 3.119e-01, Validation Loss: 6.775e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8769, Training Loss: 3.119e-01, Validation Loss: 6.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8770, Training Loss: 3.118e-01, Validation Loss: 6.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8771, Training Loss: 3.118e-01, Validation Loss: 6.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8772, Training Loss: 3.117e-01, Validation Loss: 6.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8773, Training Loss: 3.117e-01, Validation Loss: 6.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8774, Training Loss: 3.117e-01, Validation Loss: 6.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8775, Training Loss: 3.116e-01, Validation Loss: 6.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8776, Training Loss: 3.116e-01, Validation Loss: 6.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8777, Training Loss: 3.115e-01, Validation Loss: 6.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8778, Training Loss: 3.115e-01, Validation Loss: 6.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8779, Training Loss: 3.115e-01, Validation Loss: 6.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8780, Training Loss: 3.114e-01, Validation Loss: 6.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8781, Training Loss: 3.114e-01, Validation Loss: 6.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8782, Training Loss: 3.113e-01, Validation Loss: 6.771e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8783, Training Loss: 3.113e-01, Validation Loss: 6.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8784, Training Loss: 3.113e-01, Validation Loss: 6.771e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8785, Training Loss: 3.112e-01, Validation Loss: 6.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8786, Training Loss: 3.112e-01, Validation Loss: 6.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8787, Training Loss: 3.111e-01, Validation Loss: 6.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8788, Training Loss: 3.111e-01, Validation Loss: 6.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8789, Training Loss: 3.111e-01, Validation Loss: 6.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8790, Training Loss: 3.110e-01, Validation Loss: 6.769e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8791, Training Loss: 3.110e-01, Validation Loss: 6.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8792, Training Loss: 3.109e-01, Validation Loss: 6.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8793, Training Loss: 3.109e-01, Validation Loss: 6.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8794, Training Loss: 3.109e-01, Validation Loss: 6.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8795, Training Loss: 3.108e-01, Validation Loss: 6.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8796, Training Loss: 3.108e-01, Validation Loss: 6.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8797, Training Loss: 3.107e-01, Validation Loss: 6.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8798, Training Loss: 3.107e-01, Validation Loss: 6.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8799, Training Loss: 3.107e-01, Validation Loss: 6.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8800, Training Loss: 3.106e-01, Validation Loss: 6.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8801, Training Loss: 3.106e-01, Validation Loss: 6.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8802, Training Loss: 3.106e-01, Validation Loss: 6.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8803, Training Loss: 3.105e-01, Validation Loss: 6.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8804, Training Loss: 3.105e-01, Validation Loss: 6.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8805, Training Loss: 3.104e-01, Validation Loss: 6.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8806, Training Loss: 3.104e-01, Validation Loss: 6.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8807, Training Loss: 3.104e-01, Validation Loss: 6.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8808, Training Loss: 3.103e-01, Validation Loss: 6.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8809, Training Loss: 3.103e-01, Validation Loss: 6.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8810, Training Loss: 3.102e-01, Validation Loss: 6.763e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8811, Training Loss: 3.102e-01, Validation Loss: 6.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8812, Training Loss: 3.102e-01, Validation Loss: 6.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8813, Training Loss: 3.101e-01, Validation Loss: 6.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8814, Training Loss: 3.101e-01, Validation Loss: 6.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8815, Training Loss: 3.100e-01, Validation Loss: 6.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8816, Training Loss: 3.100e-01, Validation Loss: 6.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8817, Training Loss: 3.100e-01, Validation Loss: 6.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8818, Training Loss: 3.099e-01, Validation Loss: 6.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8819, Training Loss: 3.099e-01, Validation Loss: 6.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8820, Training Loss: 3.098e-01, Validation Loss: 6.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8821, Training Loss: 3.098e-01, Validation Loss: 6.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8822, Training Loss: 3.098e-01, Validation Loss: 6.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8823, Training Loss: 3.097e-01, Validation Loss: 6.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8824, Training Loss: 3.097e-01, Validation Loss: 6.760e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8825, Training Loss: 3.096e-01, Validation Loss: 6.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8826, Training Loss: 3.096e-01, Validation Loss: 6.759e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8827, Training Loss: 3.096e-01, Validation Loss: 6.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8828, Training Loss: 3.095e-01, Validation Loss: 6.759e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8829, Training Loss: 3.095e-01, Validation Loss: 6.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8830, Training Loss: 3.095e-01, Validation Loss: 6.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8831, Training Loss: 3.094e-01, Validation Loss: 6.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8832, Training Loss: 3.094e-01, Validation Loss: 6.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8833, Training Loss: 3.093e-01, Validation Loss: 6.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8834, Training Loss: 3.093e-01, Validation Loss: 6.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8835, Training Loss: 3.093e-01, Validation Loss: 6.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8836, Training Loss: 3.092e-01, Validation Loss: 6.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8837, Training Loss: 3.092e-01, Validation Loss: 6.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8838, Training Loss: 3.091e-01, Validation Loss: 6.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8839, Training Loss: 3.091e-01, Validation Loss: 6.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8840, Training Loss: 3.091e-01, Validation Loss: 6.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8841, Training Loss: 3.090e-01, Validation Loss: 6.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8842, Training Loss: 3.090e-01, Validation Loss: 6.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8843, Training Loss: 3.089e-01, Validation Loss: 6.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8844, Training Loss: 3.089e-01, Validation Loss: 6.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8845, Training Loss: 3.089e-01, Validation Loss: 6.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8846, Training Loss: 3.088e-01, Validation Loss: 6.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8847, Training Loss: 3.088e-01, Validation Loss: 6.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8848, Training Loss: 3.087e-01, Validation Loss: 6.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8849, Training Loss: 3.087e-01, Validation Loss: 6.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8850, Training Loss: 3.087e-01, Validation Loss: 6.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8851, Training Loss: 3.086e-01, Validation Loss: 6.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8852, Training Loss: 3.086e-01, Validation Loss: 6.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8853, Training Loss: 3.086e-01, Validation Loss: 6.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8854, Training Loss: 3.085e-01, Validation Loss: 6.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8855, Training Loss: 3.085e-01, Validation Loss: 6.751e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8856, Training Loss: 3.084e-01, Validation Loss: 6.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8857, Training Loss: 3.084e-01, Validation Loss: 6.751e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8858, Training Loss: 3.084e-01, Validation Loss: 6.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8859, Training Loss: 3.083e-01, Validation Loss: 6.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8860, Training Loss: 3.083e-01, Validation Loss: 6.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8861, Training Loss: 3.082e-01, Validation Loss: 6.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8862, Training Loss: 3.082e-01, Validation Loss: 6.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8863, Training Loss: 3.082e-01, Validation Loss: 6.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8864, Training Loss: 3.081e-01, Validation Loss: 6.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8865, Training Loss: 3.081e-01, Validation Loss: 6.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8866, Training Loss: 3.080e-01, Validation Loss: 6.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8867, Training Loss: 3.080e-01, Validation Loss: 6.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8868, Training Loss: 3.080e-01, Validation Loss: 6.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8869, Training Loss: 3.079e-01, Validation Loss: 6.748e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8870, Training Loss: 3.079e-01, Validation Loss: 6.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8871, Training Loss: 3.079e-01, Validation Loss: 6.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8872, Training Loss: 3.078e-01, Validation Loss: 6.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8873, Training Loss: 3.078e-01, Validation Loss: 6.747e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8874, Training Loss: 3.077e-01, Validation Loss: 6.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8875, Training Loss: 3.077e-01, Validation Loss: 6.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8876, Training Loss: 3.077e-01, Validation Loss: 6.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8877, Training Loss: 3.076e-01, Validation Loss: 6.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8878, Training Loss: 3.076e-01, Validation Loss: 6.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8879, Training Loss: 3.075e-01, Validation Loss: 6.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8880, Training Loss: 3.075e-01, Validation Loss: 6.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8881, Training Loss: 3.075e-01, Validation Loss: 6.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8882, Training Loss: 3.074e-01, Validation Loss: 6.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8883, Training Loss: 3.074e-01, Validation Loss: 6.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8884, Training Loss: 3.073e-01, Validation Loss: 6.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8885, Training Loss: 3.073e-01, Validation Loss: 6.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8886, Training Loss: 3.073e-01, Validation Loss: 6.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8887, Training Loss: 3.072e-01, Validation Loss: 6.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8888, Training Loss: 3.072e-01, Validation Loss: 6.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8889, Training Loss: 3.072e-01, Validation Loss: 6.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8890, Training Loss: 3.071e-01, Validation Loss: 6.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8891, Training Loss: 3.071e-01, Validation Loss: 6.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8892, Training Loss: 3.070e-01, Validation Loss: 6.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8893, Training Loss: 3.070e-01, Validation Loss: 6.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8894, Training Loss: 3.070e-01, Validation Loss: 6.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8895, Training Loss: 3.069e-01, Validation Loss: 6.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8896, Training Loss: 3.069e-01, Validation Loss: 6.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8897, Training Loss: 3.068e-01, Validation Loss: 6.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8898, Training Loss: 3.068e-01, Validation Loss: 6.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8899, Training Loss: 3.068e-01, Validation Loss: 6.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8900, Training Loss: 3.067e-01, Validation Loss: 6.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8901, Training Loss: 3.067e-01, Validation Loss: 6.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8902, Training Loss: 3.067e-01, Validation Loss: 6.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8903, Training Loss: 3.066e-01, Validation Loss: 6.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8904, Training Loss: 3.066e-01, Validation Loss: 6.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8905, Training Loss: 3.065e-01, Validation Loss: 6.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8906, Training Loss: 3.065e-01, Validation Loss: 6.738e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8907, Training Loss: 3.065e-01, Validation Loss: 6.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8908, Training Loss: 3.064e-01, Validation Loss: 6.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8909, Training Loss: 3.064e-01, Validation Loss: 6.737e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8910, Training Loss: 3.063e-01, Validation Loss: 6.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8911, Training Loss: 3.063e-01, Validation Loss: 6.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8912, Training Loss: 3.063e-01, Validation Loss: 6.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8913, Training Loss: 3.062e-01, Validation Loss: 6.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8914, Training Loss: 3.062e-01, Validation Loss: 6.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8915, Training Loss: 3.061e-01, Validation Loss: 6.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8916, Training Loss: 3.061e-01, Validation Loss: 6.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8917, Training Loss: 3.061e-01, Validation Loss: 6.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8918, Training Loss: 3.060e-01, Validation Loss: 6.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8919, Training Loss: 3.060e-01, Validation Loss: 6.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8920, Training Loss: 3.060e-01, Validation Loss: 6.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8921, Training Loss: 3.059e-01, Validation Loss: 6.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8922, Training Loss: 3.059e-01, Validation Loss: 6.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8923, Training Loss: 3.058e-01, Validation Loss: 6.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8924, Training Loss: 3.058e-01, Validation Loss: 6.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8925, Training Loss: 3.058e-01, Validation Loss: 6.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8926, Training Loss: 3.057e-01, Validation Loss: 6.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8927, Training Loss: 3.057e-01, Validation Loss: 6.733e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8928, Training Loss: 3.056e-01, Validation Loss: 6.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8929, Training Loss: 3.056e-01, Validation Loss: 6.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8930, Training Loss: 3.056e-01, Validation Loss: 6.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8931, Training Loss: 3.055e-01, Validation Loss: 6.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8932, Training Loss: 3.055e-01, Validation Loss: 6.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8933, Training Loss: 3.055e-01, Validation Loss: 6.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8934, Training Loss: 3.054e-01, Validation Loss: 6.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8935, Training Loss: 3.054e-01, Validation Loss: 6.731e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8936, Training Loss: 3.053e-01, Validation Loss: 6.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8937, Training Loss: 3.053e-01, Validation Loss: 6.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8938, Training Loss: 3.053e-01, Validation Loss: 6.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8939, Training Loss: 3.052e-01, Validation Loss: 6.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8940, Training Loss: 3.052e-01, Validation Loss: 6.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8941, Training Loss: 3.051e-01, Validation Loss: 6.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8942, Training Loss: 3.051e-01, Validation Loss: 6.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8943, Training Loss: 3.051e-01, Validation Loss: 6.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8944, Training Loss: 3.050e-01, Validation Loss: 6.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8945, Training Loss: 3.050e-01, Validation Loss: 6.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8946, Training Loss: 3.050e-01, Validation Loss: 6.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8947, Training Loss: 3.049e-01, Validation Loss: 6.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8948, Training Loss: 3.049e-01, Validation Loss: 6.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8949, Training Loss: 3.048e-01, Validation Loss: 6.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8950, Training Loss: 3.048e-01, Validation Loss: 6.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8951, Training Loss: 3.048e-01, Validation Loss: 6.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8952, Training Loss: 3.047e-01, Validation Loss: 6.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8953, Training Loss: 3.047e-01, Validation Loss: 6.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8954, Training Loss: 3.047e-01, Validation Loss: 6.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8955, Training Loss: 3.046e-01, Validation Loss: 6.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8956, Training Loss: 3.046e-01, Validation Loss: 6.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8957, Training Loss: 3.045e-01, Validation Loss: 6.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8958, Training Loss: 3.045e-01, Validation Loss: 6.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8959, Training Loss: 3.045e-01, Validation Loss: 6.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8960, Training Loss: 3.044e-01, Validation Loss: 6.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8961, Training Loss: 3.044e-01, Validation Loss: 6.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8962, Training Loss: 3.043e-01, Validation Loss: 6.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8963, Training Loss: 3.043e-01, Validation Loss: 6.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8964, Training Loss: 3.043e-01, Validation Loss: 6.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8965, Training Loss: 3.042e-01, Validation Loss: 6.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8966, Training Loss: 3.042e-01, Validation Loss: 6.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8967, Training Loss: 3.042e-01, Validation Loss: 6.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8968, Training Loss: 3.041e-01, Validation Loss: 6.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8969, Training Loss: 3.041e-01, Validation Loss: 6.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8970, Training Loss: 3.040e-01, Validation Loss: 6.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8971, Training Loss: 3.040e-01, Validation Loss: 6.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8972, Training Loss: 3.040e-01, Validation Loss: 6.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8973, Training Loss: 3.039e-01, Validation Loss: 6.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8974, Training Loss: 3.039e-01, Validation Loss: 6.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8975, Training Loss: 3.038e-01, Validation Loss: 6.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8976, Training Loss: 3.038e-01, Validation Loss: 6.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8977, Training Loss: 3.038e-01, Validation Loss: 6.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8978, Training Loss: 3.037e-01, Validation Loss: 6.720e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8979, Training Loss: 3.037e-01, Validation Loss: 6.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8980, Training Loss: 3.037e-01, Validation Loss: 6.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8981, Training Loss: 3.036e-01, Validation Loss: 6.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8982, Training Loss: 3.036e-01, Validation Loss: 6.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8983, Training Loss: 3.035e-01, Validation Loss: 6.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8984, Training Loss: 3.035e-01, Validation Loss: 6.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8985, Training Loss: 3.035e-01, Validation Loss: 6.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8986, Training Loss: 3.034e-01, Validation Loss: 6.718e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8987, Training Loss: 3.034e-01, Validation Loss: 6.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8988, Training Loss: 3.034e-01, Validation Loss: 6.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8989, Training Loss: 3.033e-01, Validation Loss: 6.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8990, Training Loss: 3.033e-01, Validation Loss: 6.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8991, Training Loss: 3.032e-01, Validation Loss: 6.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8992, Training Loss: 3.032e-01, Validation Loss: 6.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8993, Training Loss: 3.032e-01, Validation Loss: 6.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8994, Training Loss: 3.031e-01, Validation Loss: 6.716e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8995, Training Loss: 3.031e-01, Validation Loss: 6.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8996, Training Loss: 3.031e-01, Validation Loss: 6.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8997, Training Loss: 3.030e-01, Validation Loss: 6.715e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 8998, Training Loss: 3.030e-01, Validation Loss: 6.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 8999, Training Loss: 3.029e-01, Validation Loss: 6.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9000, Training Loss: 3.029e-01, Validation Loss: 6.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9001, Training Loss: 3.029e-01, Validation Loss: 6.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9002, Training Loss: 3.028e-01, Validation Loss: 6.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9003, Training Loss: 3.028e-01, Validation Loss: 6.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9004, Training Loss: 3.027e-01, Validation Loss: 6.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9005, Training Loss: 3.027e-01, Validation Loss: 6.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9006, Training Loss: 3.027e-01, Validation Loss: 6.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9007, Training Loss: 3.026e-01, Validation Loss: 6.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9008, Training Loss: 3.026e-01, Validation Loss: 6.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9009, Training Loss: 3.026e-01, Validation Loss: 6.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9010, Training Loss: 3.025e-01, Validation Loss: 6.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9011, Training Loss: 3.025e-01, Validation Loss: 6.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9012, Training Loss: 3.024e-01, Validation Loss: 6.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9013, Training Loss: 3.024e-01, Validation Loss: 6.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9014, Training Loss: 3.024e-01, Validation Loss: 6.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9015, Training Loss: 3.023e-01, Validation Loss: 6.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9016, Training Loss: 3.023e-01, Validation Loss: 6.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9017, Training Loss: 3.023e-01, Validation Loss: 6.710e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9018, Training Loss: 3.022e-01, Validation Loss: 6.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9019, Training Loss: 3.022e-01, Validation Loss: 6.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9020, Training Loss: 3.021e-01, Validation Loss: 6.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9021, Training Loss: 3.021e-01, Validation Loss: 6.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9022, Training Loss: 3.021e-01, Validation Loss: 6.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9023, Training Loss: 3.020e-01, Validation Loss: 6.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9024, Training Loss: 3.020e-01, Validation Loss: 6.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9025, Training Loss: 3.020e-01, Validation Loss: 6.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9026, Training Loss: 3.019e-01, Validation Loss: 6.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9027, Training Loss: 3.019e-01, Validation Loss: 6.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9028, Training Loss: 3.018e-01, Validation Loss: 6.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9029, Training Loss: 3.018e-01, Validation Loss: 6.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9030, Training Loss: 3.018e-01, Validation Loss: 6.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9031, Training Loss: 3.017e-01, Validation Loss: 6.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9032, Training Loss: 3.017e-01, Validation Loss: 6.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9033, Training Loss: 3.017e-01, Validation Loss: 6.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9034, Training Loss: 3.016e-01, Validation Loss: 6.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9035, Training Loss: 3.016e-01, Validation Loss: 6.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9036, Training Loss: 3.015e-01, Validation Loss: 6.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9037, Training Loss: 3.015e-01, Validation Loss: 6.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9038, Training Loss: 3.015e-01, Validation Loss: 6.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9039, Training Loss: 3.014e-01, Validation Loss: 6.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9040, Training Loss: 3.014e-01, Validation Loss: 6.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9041, Training Loss: 3.014e-01, Validation Loss: 6.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9042, Training Loss: 3.013e-01, Validation Loss: 6.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9043, Training Loss: 3.013e-01, Validation Loss: 6.703e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9044, Training Loss: 3.012e-01, Validation Loss: 6.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9045, Training Loss: 3.012e-01, Validation Loss: 6.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9046, Training Loss: 3.012e-01, Validation Loss: 6.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9047, Training Loss: 3.011e-01, Validation Loss: 6.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9048, Training Loss: 3.011e-01, Validation Loss: 6.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9049, Training Loss: 3.010e-01, Validation Loss: 6.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9050, Training Loss: 3.010e-01, Validation Loss: 6.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9051, Training Loss: 3.010e-01, Validation Loss: 6.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9052, Training Loss: 3.009e-01, Validation Loss: 6.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9053, Training Loss: 3.009e-01, Validation Loss: 6.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9054, Training Loss: 3.009e-01, Validation Loss: 6.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9055, Training Loss: 3.008e-01, Validation Loss: 6.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9056, Training Loss: 3.008e-01, Validation Loss: 6.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9057, Training Loss: 3.007e-01, Validation Loss: 6.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9058, Training Loss: 3.007e-01, Validation Loss: 6.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9059, Training Loss: 3.007e-01, Validation Loss: 6.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9060, Training Loss: 3.006e-01, Validation Loss: 6.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9061, Training Loss: 3.006e-01, Validation Loss: 6.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9062, Training Loss: 3.006e-01, Validation Loss: 6.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9063, Training Loss: 3.005e-01, Validation Loss: 6.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9064, Training Loss: 3.005e-01, Validation Loss: 6.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9065, Training Loss: 3.004e-01, Validation Loss: 6.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9066, Training Loss: 3.004e-01, Validation Loss: 6.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9067, Training Loss: 3.004e-01, Validation Loss: 6.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9068, Training Loss: 3.003e-01, Validation Loss: 6.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9069, Training Loss: 3.003e-01, Validation Loss: 6.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9070, Training Loss: 3.003e-01, Validation Loss: 6.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9071, Training Loss: 3.002e-01, Validation Loss: 6.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9072, Training Loss: 3.002e-01, Validation Loss: 6.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9073, Training Loss: 3.001e-01, Validation Loss: 6.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9074, Training Loss: 3.001e-01, Validation Loss: 6.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9075, Training Loss: 3.001e-01, Validation Loss: 6.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9076, Training Loss: 3.000e-01, Validation Loss: 6.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9077, Training Loss: 3.000e-01, Validation Loss: 6.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9078, Training Loss: 3.000e-01, Validation Loss: 6.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9079, Training Loss: 2.999e-01, Validation Loss: 6.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9080, Training Loss: 2.999e-01, Validation Loss: 6.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9081, Training Loss: 2.998e-01, Validation Loss: 6.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9082, Training Loss: 2.998e-01, Validation Loss: 6.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9083, Training Loss: 2.998e-01, Validation Loss: 6.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9084, Training Loss: 2.997e-01, Validation Loss: 6.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9085, Training Loss: 2.997e-01, Validation Loss: 6.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9086, Training Loss: 2.997e-01, Validation Loss: 6.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9087, Training Loss: 2.996e-01, Validation Loss: 6.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9088, Training Loss: 2.996e-01, Validation Loss: 6.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9089, Training Loss: 2.996e-01, Validation Loss: 6.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9090, Training Loss: 2.995e-01, Validation Loss: 6.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9091, Training Loss: 2.995e-01, Validation Loss: 6.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9092, Training Loss: 2.994e-01, Validation Loss: 6.691e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9093, Training Loss: 2.994e-01, Validation Loss: 6.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9094, Training Loss: 2.994e-01, Validation Loss: 6.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9095, Training Loss: 2.993e-01, Validation Loss: 6.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9096, Training Loss: 2.993e-01, Validation Loss: 6.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9097, Training Loss: 2.993e-01, Validation Loss: 6.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9098, Training Loss: 2.992e-01, Validation Loss: 6.689e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9099, Training Loss: 2.992e-01, Validation Loss: 6.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9100, Training Loss: 2.991e-01, Validation Loss: 6.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9101, Training Loss: 2.991e-01, Validation Loss: 6.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9102, Training Loss: 2.991e-01, Validation Loss: 6.689e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9103, Training Loss: 2.990e-01, Validation Loss: 6.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9104, Training Loss: 2.990e-01, Validation Loss: 6.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9105, Training Loss: 2.990e-01, Validation Loss: 6.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9106, Training Loss: 2.989e-01, Validation Loss: 6.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9107, Training Loss: 2.989e-01, Validation Loss: 6.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9108, Training Loss: 2.988e-01, Validation Loss: 6.687e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9109, Training Loss: 2.988e-01, Validation Loss: 6.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9110, Training Loss: 2.988e-01, Validation Loss: 6.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9111, Training Loss: 2.987e-01, Validation Loss: 6.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9112, Training Loss: 2.987e-01, Validation Loss: 6.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9113, Training Loss: 2.987e-01, Validation Loss: 6.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9114, Training Loss: 2.986e-01, Validation Loss: 6.686e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9115, Training Loss: 2.986e-01, Validation Loss: 6.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9116, Training Loss: 2.985e-01, Validation Loss: 6.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9117, Training Loss: 2.985e-01, Validation Loss: 6.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9118, Training Loss: 2.985e-01, Validation Loss: 6.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9119, Training Loss: 2.984e-01, Validation Loss: 6.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9120, Training Loss: 2.984e-01, Validation Loss: 6.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9121, Training Loss: 2.984e-01, Validation Loss: 6.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9122, Training Loss: 2.983e-01, Validation Loss: 6.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9123, Training Loss: 2.983e-01, Validation Loss: 6.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9124, Training Loss: 2.982e-01, Validation Loss: 6.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9125, Training Loss: 2.982e-01, Validation Loss: 6.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9126, Training Loss: 2.982e-01, Validation Loss: 6.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9127, Training Loss: 2.981e-01, Validation Loss: 6.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9128, Training Loss: 2.981e-01, Validation Loss: 6.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9129, Training Loss: 2.981e-01, Validation Loss: 6.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9130, Training Loss: 2.980e-01, Validation Loss: 6.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9131, Training Loss: 2.980e-01, Validation Loss: 6.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9132, Training Loss: 2.980e-01, Validation Loss: 6.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9133, Training Loss: 2.979e-01, Validation Loss: 6.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9134, Training Loss: 2.979e-01, Validation Loss: 6.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9135, Training Loss: 2.978e-01, Validation Loss: 6.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9136, Training Loss: 2.978e-01, Validation Loss: 6.680e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9137, Training Loss: 2.978e-01, Validation Loss: 6.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9138, Training Loss: 2.977e-01, Validation Loss: 6.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9139, Training Loss: 2.977e-01, Validation Loss: 6.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9140, Training Loss: 2.977e-01, Validation Loss: 6.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9141, Training Loss: 2.976e-01, Validation Loss: 6.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9142, Training Loss: 2.976e-01, Validation Loss: 6.678e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9143, Training Loss: 2.975e-01, Validation Loss: 6.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9144, Training Loss: 2.975e-01, Validation Loss: 6.678e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9145, Training Loss: 2.975e-01, Validation Loss: 6.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9146, Training Loss: 2.974e-01, Validation Loss: 6.678e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9147, Training Loss: 2.974e-01, Validation Loss: 6.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9148, Training Loss: 2.974e-01, Validation Loss: 6.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9149, Training Loss: 2.973e-01, Validation Loss: 6.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9150, Training Loss: 2.973e-01, Validation Loss: 6.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9151, Training Loss: 2.972e-01, Validation Loss: 6.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9152, Training Loss: 2.972e-01, Validation Loss: 6.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9153, Training Loss: 2.972e-01, Validation Loss: 6.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9154, Training Loss: 2.971e-01, Validation Loss: 6.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9155, Training Loss: 2.971e-01, Validation Loss: 6.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9156, Training Loss: 2.971e-01, Validation Loss: 6.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9157, Training Loss: 2.970e-01, Validation Loss: 6.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9158, Training Loss: 2.970e-01, Validation Loss: 6.675e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9159, Training Loss: 2.970e-01, Validation Loss: 6.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9160, Training Loss: 2.969e-01, Validation Loss: 6.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9161, Training Loss: 2.969e-01, Validation Loss: 6.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9162, Training Loss: 2.968e-01, Validation Loss: 6.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9163, Training Loss: 2.968e-01, Validation Loss: 6.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9164, Training Loss: 2.968e-01, Validation Loss: 6.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9165, Training Loss: 2.967e-01, Validation Loss: 6.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9166, Training Loss: 2.967e-01, Validation Loss: 6.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9167, Training Loss: 2.967e-01, Validation Loss: 6.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9168, Training Loss: 2.966e-01, Validation Loss: 6.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9169, Training Loss: 2.966e-01, Validation Loss: 6.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9170, Training Loss: 2.966e-01, Validation Loss: 6.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9171, Training Loss: 2.965e-01, Validation Loss: 6.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9172, Training Loss: 2.965e-01, Validation Loss: 6.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9173, Training Loss: 2.964e-01, Validation Loss: 6.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9174, Training Loss: 2.964e-01, Validation Loss: 6.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9175, Training Loss: 2.964e-01, Validation Loss: 6.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9176, Training Loss: 2.963e-01, Validation Loss: 6.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9177, Training Loss: 2.963e-01, Validation Loss: 6.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9178, Training Loss: 2.963e-01, Validation Loss: 6.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9179, Training Loss: 2.962e-01, Validation Loss: 6.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9180, Training Loss: 2.962e-01, Validation Loss: 6.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9181, Training Loss: 2.961e-01, Validation Loss: 6.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9182, Training Loss: 2.961e-01, Validation Loss: 6.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9183, Training Loss: 2.961e-01, Validation Loss: 6.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9184, Training Loss: 2.960e-01, Validation Loss: 6.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9185, Training Loss: 2.960e-01, Validation Loss: 6.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9186, Training Loss: 2.960e-01, Validation Loss: 6.668e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9187, Training Loss: 2.959e-01, Validation Loss: 6.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9188, Training Loss: 2.959e-01, Validation Loss: 6.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9189, Training Loss: 2.959e-01, Validation Loss: 6.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9190, Training Loss: 2.958e-01, Validation Loss: 6.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9191, Training Loss: 2.958e-01, Validation Loss: 6.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9192, Training Loss: 2.957e-01, Validation Loss: 6.666e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9193, Training Loss: 2.957e-01, Validation Loss: 6.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9194, Training Loss: 2.957e-01, Validation Loss: 6.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9195, Training Loss: 2.956e-01, Validation Loss: 6.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9196, Training Loss: 2.956e-01, Validation Loss: 6.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9197, Training Loss: 2.956e-01, Validation Loss: 6.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9198, Training Loss: 2.955e-01, Validation Loss: 6.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9199, Training Loss: 2.955e-01, Validation Loss: 6.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9200, Training Loss: 2.955e-01, Validation Loss: 6.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9201, Training Loss: 2.954e-01, Validation Loss: 6.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9202, Training Loss: 2.954e-01, Validation Loss: 6.664e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9203, Training Loss: 2.953e-01, Validation Loss: 6.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9204, Training Loss: 2.953e-01, Validation Loss: 6.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9205, Training Loss: 2.953e-01, Validation Loss: 6.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9206, Training Loss: 2.952e-01, Validation Loss: 6.663e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9207, Training Loss: 2.952e-01, Validation Loss: 6.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9208, Training Loss: 2.952e-01, Validation Loss: 6.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9209, Training Loss: 2.951e-01, Validation Loss: 6.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9210, Training Loss: 2.951e-01, Validation Loss: 6.662e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9211, Training Loss: 2.950e-01, Validation Loss: 6.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9212, Training Loss: 2.950e-01, Validation Loss: 6.661e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9213, Training Loss: 2.950e-01, Validation Loss: 6.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9214, Training Loss: 2.949e-01, Validation Loss: 6.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9215, Training Loss: 2.949e-01, Validation Loss: 6.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9216, Training Loss: 2.949e-01, Validation Loss: 6.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9217, Training Loss: 2.948e-01, Validation Loss: 6.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9218, Training Loss: 2.948e-01, Validation Loss: 6.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9219, Training Loss: 2.948e-01, Validation Loss: 6.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9220, Training Loss: 2.947e-01, Validation Loss: 6.660e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9221, Training Loss: 2.947e-01, Validation Loss: 6.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9222, Training Loss: 2.946e-01, Validation Loss: 6.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9223, Training Loss: 2.946e-01, Validation Loss: 6.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9224, Training Loss: 2.946e-01, Validation Loss: 6.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9225, Training Loss: 2.945e-01, Validation Loss: 6.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9226, Training Loss: 2.945e-01, Validation Loss: 6.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9227, Training Loss: 2.945e-01, Validation Loss: 6.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9228, Training Loss: 2.944e-01, Validation Loss: 6.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9229, Training Loss: 2.944e-01, Validation Loss: 6.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9230, Training Loss: 2.944e-01, Validation Loss: 6.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9231, Training Loss: 2.943e-01, Validation Loss: 6.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9232, Training Loss: 2.943e-01, Validation Loss: 6.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9233, Training Loss: 2.942e-01, Validation Loss: 6.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9234, Training Loss: 2.942e-01, Validation Loss: 6.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9235, Training Loss: 2.942e-01, Validation Loss: 6.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9236, Training Loss: 2.941e-01, Validation Loss: 6.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9237, Training Loss: 2.941e-01, Validation Loss: 6.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9238, Training Loss: 2.941e-01, Validation Loss: 6.655e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9239, Training Loss: 2.940e-01, Validation Loss: 6.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9240, Training Loss: 2.940e-01, Validation Loss: 6.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9241, Training Loss: 2.940e-01, Validation Loss: 6.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9242, Training Loss: 2.939e-01, Validation Loss: 6.654e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9243, Training Loss: 2.939e-01, Validation Loss: 6.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9244, Training Loss: 2.938e-01, Validation Loss: 6.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9245, Training Loss: 2.938e-01, Validation Loss: 6.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9246, Training Loss: 2.938e-01, Validation Loss: 6.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9247, Training Loss: 2.937e-01, Validation Loss: 6.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9248, Training Loss: 2.937e-01, Validation Loss: 6.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9249, Training Loss: 2.937e-01, Validation Loss: 6.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9250, Training Loss: 2.936e-01, Validation Loss: 6.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9251, Training Loss: 2.936e-01, Validation Loss: 6.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9252, Training Loss: 2.936e-01, Validation Loss: 6.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9253, Training Loss: 2.935e-01, Validation Loss: 6.652e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9254, Training Loss: 2.935e-01, Validation Loss: 6.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9255, Training Loss: 2.934e-01, Validation Loss: 6.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9256, Training Loss: 2.934e-01, Validation Loss: 6.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9257, Training Loss: 2.934e-01, Validation Loss: 6.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9258, Training Loss: 2.933e-01, Validation Loss: 6.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9259, Training Loss: 2.933e-01, Validation Loss: 6.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9260, Training Loss: 2.933e-01, Validation Loss: 6.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9261, Training Loss: 2.932e-01, Validation Loss: 6.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9262, Training Loss: 2.932e-01, Validation Loss: 6.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9263, Training Loss: 2.932e-01, Validation Loss: 6.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9264, Training Loss: 2.931e-01, Validation Loss: 6.649e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9265, Training Loss: 2.931e-01, Validation Loss: 6.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9266, Training Loss: 2.931e-01, Validation Loss: 6.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9267, Training Loss: 2.930e-01, Validation Loss: 6.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9268, Training Loss: 2.930e-01, Validation Loss: 6.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9269, Training Loss: 2.929e-01, Validation Loss: 6.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9270, Training Loss: 2.929e-01, Validation Loss: 6.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9271, Training Loss: 2.929e-01, Validation Loss: 6.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9272, Training Loss: 2.928e-01, Validation Loss: 6.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9273, Training Loss: 2.928e-01, Validation Loss: 6.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9274, Training Loss: 2.928e-01, Validation Loss: 6.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9275, Training Loss: 2.927e-01, Validation Loss: 6.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9276, Training Loss: 2.927e-01, Validation Loss: 6.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9277, Training Loss: 2.927e-01, Validation Loss: 6.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9278, Training Loss: 2.926e-01, Validation Loss: 6.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9279, Training Loss: 2.926e-01, Validation Loss: 6.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9280, Training Loss: 2.925e-01, Validation Loss: 6.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9281, Training Loss: 2.925e-01, Validation Loss: 6.645e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9282, Training Loss: 2.925e-01, Validation Loss: 6.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9283, Training Loss: 2.924e-01, Validation Loss: 6.645e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9284, Training Loss: 2.924e-01, Validation Loss: 6.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9285, Training Loss: 2.924e-01, Validation Loss: 6.644e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9286, Training Loss: 2.923e-01, Validation Loss: 6.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9287, Training Loss: 2.923e-01, Validation Loss: 6.644e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9288, Training Loss: 2.923e-01, Validation Loss: 6.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9289, Training Loss: 2.922e-01, Validation Loss: 6.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9290, Training Loss: 2.922e-01, Validation Loss: 6.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9291, Training Loss: 2.922e-01, Validation Loss: 6.643e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9292, Training Loss: 2.921e-01, Validation Loss: 6.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9293, Training Loss: 2.921e-01, Validation Loss: 6.642e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9294, Training Loss: 2.920e-01, Validation Loss: 6.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9295, Training Loss: 2.920e-01, Validation Loss: 6.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9296, Training Loss: 2.920e-01, Validation Loss: 6.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9297, Training Loss: 2.919e-01, Validation Loss: 6.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9298, Training Loss: 2.919e-01, Validation Loss: 6.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9299, Training Loss: 2.919e-01, Validation Loss: 6.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9300, Training Loss: 2.918e-01, Validation Loss: 6.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9301, Training Loss: 2.918e-01, Validation Loss: 6.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9302, Training Loss: 2.918e-01, Validation Loss: 6.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9303, Training Loss: 2.917e-01, Validation Loss: 6.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9304, Training Loss: 2.917e-01, Validation Loss: 6.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9305, Training Loss: 2.916e-01, Validation Loss: 6.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9306, Training Loss: 2.916e-01, Validation Loss: 6.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9307, Training Loss: 2.916e-01, Validation Loss: 6.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9308, Training Loss: 2.915e-01, Validation Loss: 6.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9309, Training Loss: 2.915e-01, Validation Loss: 6.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9310, Training Loss: 2.915e-01, Validation Loss: 6.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9311, Training Loss: 2.914e-01, Validation Loss: 6.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9312, Training Loss: 2.914e-01, Validation Loss: 6.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9313, Training Loss: 2.914e-01, Validation Loss: 6.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9314, Training Loss: 2.913e-01, Validation Loss: 6.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9315, Training Loss: 2.913e-01, Validation Loss: 6.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9316, Training Loss: 2.913e-01, Validation Loss: 6.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9317, Training Loss: 2.912e-01, Validation Loss: 6.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9318, Training Loss: 2.912e-01, Validation Loss: 6.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9319, Training Loss: 2.911e-01, Validation Loss: 6.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9320, Training Loss: 2.911e-01, Validation Loss: 6.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9321, Training Loss: 2.911e-01, Validation Loss: 6.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9322, Training Loss: 2.910e-01, Validation Loss: 6.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9323, Training Loss: 2.910e-01, Validation Loss: 6.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9324, Training Loss: 2.910e-01, Validation Loss: 6.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9325, Training Loss: 2.909e-01, Validation Loss: 6.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9326, Training Loss: 2.909e-01, Validation Loss: 6.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9327, Training Loss: 2.909e-01, Validation Loss: 6.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9328, Training Loss: 2.908e-01, Validation Loss: 6.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9329, Training Loss: 2.908e-01, Validation Loss: 6.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9330, Training Loss: 2.908e-01, Validation Loss: 6.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9331, Training Loss: 2.907e-01, Validation Loss: 6.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9332, Training Loss: 2.907e-01, Validation Loss: 6.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9333, Training Loss: 2.906e-01, Validation Loss: 6.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9334, Training Loss: 2.906e-01, Validation Loss: 6.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9335, Training Loss: 2.906e-01, Validation Loss: 6.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9336, Training Loss: 2.905e-01, Validation Loss: 6.632e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9337, Training Loss: 2.905e-01, Validation Loss: 6.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9338, Training Loss: 2.905e-01, Validation Loss: 6.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9339, Training Loss: 2.904e-01, Validation Loss: 6.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9340, Training Loss: 2.904e-01, Validation Loss: 6.631e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9341, Training Loss: 2.904e-01, Validation Loss: 6.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9342, Training Loss: 2.903e-01, Validation Loss: 6.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9343, Training Loss: 2.903e-01, Validation Loss: 6.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9344, Training Loss: 2.903e-01, Validation Loss: 6.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9345, Training Loss: 2.902e-01, Validation Loss: 6.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9346, Training Loss: 2.902e-01, Validation Loss: 6.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9347, Training Loss: 2.901e-01, Validation Loss: 6.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9348, Training Loss: 2.901e-01, Validation Loss: 6.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9349, Training Loss: 2.901e-01, Validation Loss: 6.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9350, Training Loss: 2.900e-01, Validation Loss: 6.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9351, Training Loss: 2.900e-01, Validation Loss: 6.629e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9352, Training Loss: 2.900e-01, Validation Loss: 6.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9353, Training Loss: 2.899e-01, Validation Loss: 6.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9354, Training Loss: 2.899e-01, Validation Loss: 6.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9355, Training Loss: 2.899e-01, Validation Loss: 6.628e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9356, Training Loss: 2.898e-01, Validation Loss: 6.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9357, Training Loss: 2.898e-01, Validation Loss: 6.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9358, Training Loss: 2.898e-01, Validation Loss: 6.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9359, Training Loss: 2.897e-01, Validation Loss: 6.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9360, Training Loss: 2.897e-01, Validation Loss: 6.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9361, Training Loss: 2.897e-01, Validation Loss: 6.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9362, Training Loss: 2.896e-01, Validation Loss: 6.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9363, Training Loss: 2.896e-01, Validation Loss: 6.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9364, Training Loss: 2.895e-01, Validation Loss: 6.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9365, Training Loss: 2.895e-01, Validation Loss: 6.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9366, Training Loss: 2.895e-01, Validation Loss: 6.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9367, Training Loss: 2.894e-01, Validation Loss: 6.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9368, Training Loss: 2.894e-01, Validation Loss: 6.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9369, Training Loss: 2.894e-01, Validation Loss: 6.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9370, Training Loss: 2.893e-01, Validation Loss: 6.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9371, Training Loss: 2.893e-01, Validation Loss: 6.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9372, Training Loss: 2.893e-01, Validation Loss: 6.624e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9373, Training Loss: 2.892e-01, Validation Loss: 6.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9374, Training Loss: 2.892e-01, Validation Loss: 6.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9375, Training Loss: 2.892e-01, Validation Loss: 6.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9376, Training Loss: 2.891e-01, Validation Loss: 6.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9377, Training Loss: 2.891e-01, Validation Loss: 6.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9378, Training Loss: 2.890e-01, Validation Loss: 6.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9379, Training Loss: 2.890e-01, Validation Loss: 6.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9380, Training Loss: 2.890e-01, Validation Loss: 6.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9381, Training Loss: 2.889e-01, Validation Loss: 6.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9382, Training Loss: 2.889e-01, Validation Loss: 6.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9383, Training Loss: 2.889e-01, Validation Loss: 6.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9384, Training Loss: 2.888e-01, Validation Loss: 6.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9385, Training Loss: 2.888e-01, Validation Loss: 6.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9386, Training Loss: 2.888e-01, Validation Loss: 6.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9387, Training Loss: 2.887e-01, Validation Loss: 6.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9388, Training Loss: 2.887e-01, Validation Loss: 6.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9389, Training Loss: 2.887e-01, Validation Loss: 6.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9390, Training Loss: 2.886e-01, Validation Loss: 6.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9391, Training Loss: 2.886e-01, Validation Loss: 6.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9392, Training Loss: 2.886e-01, Validation Loss: 6.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9393, Training Loss: 2.885e-01, Validation Loss: 6.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9394, Training Loss: 2.885e-01, Validation Loss: 6.619e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9395, Training Loss: 2.884e-01, Validation Loss: 6.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9396, Training Loss: 2.884e-01, Validation Loss: 6.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9397, Training Loss: 2.884e-01, Validation Loss: 6.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9398, Training Loss: 2.883e-01, Validation Loss: 6.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9399, Training Loss: 2.883e-01, Validation Loss: 6.617e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9400, Training Loss: 2.883e-01, Validation Loss: 6.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9401, Training Loss: 2.882e-01, Validation Loss: 6.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9402, Training Loss: 2.882e-01, Validation Loss: 6.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9403, Training Loss: 2.882e-01, Validation Loss: 6.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9404, Training Loss: 2.881e-01, Validation Loss: 6.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9405, Training Loss: 2.881e-01, Validation Loss: 6.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9406, Training Loss: 2.881e-01, Validation Loss: 6.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9407, Training Loss: 2.880e-01, Validation Loss: 6.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9408, Training Loss: 2.880e-01, Validation Loss: 6.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9409, Training Loss: 2.880e-01, Validation Loss: 6.615e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9410, Training Loss: 2.879e-01, Validation Loss: 6.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9411, Training Loss: 2.879e-01, Validation Loss: 6.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9412, Training Loss: 2.878e-01, Validation Loss: 6.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9413, Training Loss: 2.878e-01, Validation Loss: 6.614e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9414, Training Loss: 2.878e-01, Validation Loss: 6.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9415, Training Loss: 2.877e-01, Validation Loss: 6.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9416, Training Loss: 2.877e-01, Validation Loss: 6.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9417, Training Loss: 2.877e-01, Validation Loss: 6.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9418, Training Loss: 2.876e-01, Validation Loss: 6.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9419, Training Loss: 2.876e-01, Validation Loss: 6.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9420, Training Loss: 2.876e-01, Validation Loss: 6.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9421, Training Loss: 2.875e-01, Validation Loss: 6.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9422, Training Loss: 2.875e-01, Validation Loss: 6.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9423, Training Loss: 2.875e-01, Validation Loss: 6.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9424, Training Loss: 2.874e-01, Validation Loss: 6.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9425, Training Loss: 2.874e-01, Validation Loss: 6.611e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9426, Training Loss: 2.874e-01, Validation Loss: 6.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9427, Training Loss: 2.873e-01, Validation Loss: 6.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9428, Training Loss: 2.873e-01, Validation Loss: 6.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9429, Training Loss: 2.873e-01, Validation Loss: 6.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9430, Training Loss: 2.872e-01, Validation Loss: 6.610e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9431, Training Loss: 2.872e-01, Validation Loss: 6.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9432, Training Loss: 2.871e-01, Validation Loss: 6.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9433, Training Loss: 2.871e-01, Validation Loss: 6.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9434, Training Loss: 2.871e-01, Validation Loss: 6.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9435, Training Loss: 2.870e-01, Validation Loss: 6.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9436, Training Loss: 2.870e-01, Validation Loss: 6.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9437, Training Loss: 2.870e-01, Validation Loss: 6.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9438, Training Loss: 2.869e-01, Validation Loss: 6.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9439, Training Loss: 2.869e-01, Validation Loss: 6.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9440, Training Loss: 2.869e-01, Validation Loss: 6.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9441, Training Loss: 2.868e-01, Validation Loss: 6.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9442, Training Loss: 2.868e-01, Validation Loss: 6.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9443, Training Loss: 2.868e-01, Validation Loss: 6.607e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9444, Training Loss: 2.867e-01, Validation Loss: 6.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9445, Training Loss: 2.867e-01, Validation Loss: 6.607e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9446, Training Loss: 2.867e-01, Validation Loss: 6.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9447, Training Loss: 2.866e-01, Validation Loss: 6.606e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9448, Training Loss: 2.866e-01, Validation Loss: 6.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9449, Training Loss: 2.866e-01, Validation Loss: 6.606e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9450, Training Loss: 2.865e-01, Validation Loss: 6.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9451, Training Loss: 2.865e-01, Validation Loss: 6.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9452, Training Loss: 2.864e-01, Validation Loss: 6.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9453, Training Loss: 2.864e-01, Validation Loss: 6.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9454, Training Loss: 2.864e-01, Validation Loss: 6.605e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9455, Training Loss: 2.863e-01, Validation Loss: 6.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9456, Training Loss: 2.863e-01, Validation Loss: 6.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9457, Training Loss: 2.863e-01, Validation Loss: 6.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9458, Training Loss: 2.862e-01, Validation Loss: 6.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9459, Training Loss: 2.862e-01, Validation Loss: 6.604e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9460, Training Loss: 2.862e-01, Validation Loss: 6.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9461, Training Loss: 2.861e-01, Validation Loss: 6.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9462, Training Loss: 2.861e-01, Validation Loss: 6.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9463, Training Loss: 2.861e-01, Validation Loss: 6.603e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9464, Training Loss: 2.860e-01, Validation Loss: 6.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9465, Training Loss: 2.860e-01, Validation Loss: 6.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9466, Training Loss: 2.860e-01, Validation Loss: 6.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9467, Training Loss: 2.859e-01, Validation Loss: 6.602e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9468, Training Loss: 2.859e-01, Validation Loss: 6.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9469, Training Loss: 2.859e-01, Validation Loss: 6.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9470, Training Loss: 2.858e-01, Validation Loss: 6.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9471, Training Loss: 2.858e-01, Validation Loss: 6.601e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9472, Training Loss: 2.857e-01, Validation Loss: 6.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9473, Training Loss: 2.857e-01, Validation Loss: 6.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9474, Training Loss: 2.857e-01, Validation Loss: 6.600e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9475, Training Loss: 2.856e-01, Validation Loss: 6.600e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9476, Training Loss: 2.856e-01, Validation Loss: 6.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9477, Training Loss: 2.856e-01, Validation Loss: 6.599e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9478, Training Loss: 2.855e-01, Validation Loss: 6.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9479, Training Loss: 2.855e-01, Validation Loss: 6.599e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9480, Training Loss: 2.855e-01, Validation Loss: 6.599e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9481, Training Loss: 2.854e-01, Validation Loss: 6.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9482, Training Loss: 2.854e-01, Validation Loss: 6.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9483, Training Loss: 2.854e-01, Validation Loss: 6.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9484, Training Loss: 2.853e-01, Validation Loss: 6.598e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9485, Training Loss: 2.853e-01, Validation Loss: 6.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9486, Training Loss: 2.853e-01, Validation Loss: 6.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9487, Training Loss: 2.852e-01, Validation Loss: 6.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9488, Training Loss: 2.852e-01, Validation Loss: 6.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9489, Training Loss: 2.852e-01, Validation Loss: 6.597e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9490, Training Loss: 2.851e-01, Validation Loss: 6.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9491, Training Loss: 2.851e-01, Validation Loss: 6.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9492, Training Loss: 2.851e-01, Validation Loss: 6.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9493, Training Loss: 2.850e-01, Validation Loss: 6.596e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9494, Training Loss: 2.850e-01, Validation Loss: 6.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9495, Training Loss: 2.850e-01, Validation Loss: 6.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9496, Training Loss: 2.849e-01, Validation Loss: 6.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9497, Training Loss: 2.849e-01, Validation Loss: 6.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9498, Training Loss: 2.848e-01, Validation Loss: 6.595e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9499, Training Loss: 2.848e-01, Validation Loss: 6.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9500, Training Loss: 2.848e-01, Validation Loss: 6.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9501, Training Loss: 2.847e-01, Validation Loss: 6.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9502, Training Loss: 2.847e-01, Validation Loss: 6.594e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9503, Training Loss: 2.847e-01, Validation Loss: 6.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9504, Training Loss: 2.846e-01, Validation Loss: 6.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9505, Training Loss: 2.846e-01, Validation Loss: 6.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9506, Training Loss: 2.846e-01, Validation Loss: 6.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9507, Training Loss: 2.845e-01, Validation Loss: 6.593e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9508, Training Loss: 2.845e-01, Validation Loss: 6.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9509, Training Loss: 2.845e-01, Validation Loss: 6.592e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9510, Training Loss: 2.844e-01, Validation Loss: 6.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9511, Training Loss: 2.844e-01, Validation Loss: 6.592e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9512, Training Loss: 2.844e-01, Validation Loss: 6.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9513, Training Loss: 2.843e-01, Validation Loss: 6.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9514, Training Loss: 2.843e-01, Validation Loss: 6.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9515, Training Loss: 2.843e-01, Validation Loss: 6.591e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9516, Training Loss: 2.842e-01, Validation Loss: 6.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9517, Training Loss: 2.842e-01, Validation Loss: 6.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9518, Training Loss: 2.842e-01, Validation Loss: 6.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9519, Training Loss: 2.841e-01, Validation Loss: 6.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9520, Training Loss: 2.841e-01, Validation Loss: 6.590e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9521, Training Loss: 2.841e-01, Validation Loss: 6.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9522, Training Loss: 2.840e-01, Validation Loss: 6.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9523, Training Loss: 2.840e-01, Validation Loss: 6.589e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9524, Training Loss: 2.839e-01, Validation Loss: 6.589e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9525, Training Loss: 2.839e-01, Validation Loss: 6.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9526, Training Loss: 2.839e-01, Validation Loss: 6.588e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9527, Training Loss: 2.838e-01, Validation Loss: 6.588e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9528, Training Loss: 2.838e-01, Validation Loss: 6.588e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9529, Training Loss: 2.838e-01, Validation Loss: 6.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9530, Training Loss: 2.837e-01, Validation Loss: 6.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9531, Training Loss: 2.837e-01, Validation Loss: 6.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9532, Training Loss: 2.837e-01, Validation Loss: 6.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9533, Training Loss: 2.836e-01, Validation Loss: 6.587e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9534, Training Loss: 2.836e-01, Validation Loss: 6.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9535, Training Loss: 2.836e-01, Validation Loss: 6.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9536, Training Loss: 2.835e-01, Validation Loss: 6.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9537, Training Loss: 2.835e-01, Validation Loss: 6.586e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9538, Training Loss: 2.835e-01, Validation Loss: 6.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9539, Training Loss: 2.834e-01, Validation Loss: 6.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9540, Training Loss: 2.834e-01, Validation Loss: 6.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9541, Training Loss: 2.834e-01, Validation Loss: 6.585e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9542, Training Loss: 2.833e-01, Validation Loss: 6.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9543, Training Loss: 2.833e-01, Validation Loss: 6.584e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9544, Training Loss: 2.833e-01, Validation Loss: 6.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9545, Training Loss: 2.832e-01, Validation Loss: 6.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9546, Training Loss: 2.832e-01, Validation Loss: 6.584e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9547, Training Loss: 2.832e-01, Validation Loss: 6.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9548, Training Loss: 2.831e-01, Validation Loss: 6.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9549, Training Loss: 2.831e-01, Validation Loss: 6.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9550, Training Loss: 2.831e-01, Validation Loss: 6.583e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9551, Training Loss: 2.830e-01, Validation Loss: 6.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9552, Training Loss: 2.830e-01, Validation Loss: 6.583e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9553, Training Loss: 2.830e-01, Validation Loss: 6.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9554, Training Loss: 2.829e-01, Validation Loss: 6.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9555, Training Loss: 2.829e-01, Validation Loss: 6.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9556, Training Loss: 2.828e-01, Validation Loss: 6.582e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9557, Training Loss: 2.828e-01, Validation Loss: 6.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9558, Training Loss: 2.828e-01, Validation Loss: 6.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9559, Training Loss: 2.827e-01, Validation Loss: 6.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9560, Training Loss: 2.827e-01, Validation Loss: 6.581e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9561, Training Loss: 2.827e-01, Validation Loss: 6.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9562, Training Loss: 2.826e-01, Validation Loss: 6.580e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9563, Training Loss: 2.826e-01, Validation Loss: 6.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9564, Training Loss: 2.826e-01, Validation Loss: 6.580e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9565, Training Loss: 2.825e-01, Validation Loss: 6.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9566, Training Loss: 2.825e-01, Validation Loss: 6.579e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9567, Training Loss: 2.825e-01, Validation Loss: 6.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9568, Training Loss: 2.824e-01, Validation Loss: 6.579e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9569, Training Loss: 2.824e-01, Validation Loss: 6.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9570, Training Loss: 2.824e-01, Validation Loss: 6.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9571, Training Loss: 2.823e-01, Validation Loss: 6.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9572, Training Loss: 2.823e-01, Validation Loss: 6.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9573, Training Loss: 2.823e-01, Validation Loss: 6.578e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9574, Training Loss: 2.822e-01, Validation Loss: 6.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9575, Training Loss: 2.822e-01, Validation Loss: 6.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9576, Training Loss: 2.822e-01, Validation Loss: 6.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9577, Training Loss: 2.821e-01, Validation Loss: 6.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9578, Training Loss: 2.821e-01, Validation Loss: 6.577e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9579, Training Loss: 2.821e-01, Validation Loss: 6.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9580, Training Loss: 2.820e-01, Validation Loss: 6.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9581, Training Loss: 2.820e-01, Validation Loss: 6.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9582, Training Loss: 2.820e-01, Validation Loss: 6.576e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9583, Training Loss: 2.819e-01, Validation Loss: 6.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9584, Training Loss: 2.819e-01, Validation Loss: 6.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9585, Training Loss: 2.819e-01, Validation Loss: 6.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9586, Training Loss: 2.818e-01, Validation Loss: 6.575e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9587, Training Loss: 2.818e-01, Validation Loss: 6.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9588, Training Loss: 2.818e-01, Validation Loss: 6.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9589, Training Loss: 2.817e-01, Validation Loss: 6.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9590, Training Loss: 2.817e-01, Validation Loss: 6.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9591, Training Loss: 2.817e-01, Validation Loss: 6.574e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9592, Training Loss: 2.816e-01, Validation Loss: 6.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9593, Training Loss: 2.816e-01, Validation Loss: 6.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9594, Training Loss: 2.816e-01, Validation Loss: 6.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9595, Training Loss: 2.815e-01, Validation Loss: 6.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9596, Training Loss: 2.815e-01, Validation Loss: 6.573e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9597, Training Loss: 2.815e-01, Validation Loss: 6.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9598, Training Loss: 2.814e-01, Validation Loss: 6.572e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9599, Training Loss: 2.814e-01, Validation Loss: 6.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9600, Training Loss: 2.813e-01, Validation Loss: 6.572e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9601, Training Loss: 2.813e-01, Validation Loss: 6.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9602, Training Loss: 2.813e-01, Validation Loss: 6.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9603, Training Loss: 2.812e-01, Validation Loss: 6.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9604, Training Loss: 2.812e-01, Validation Loss: 6.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9605, Training Loss: 2.812e-01, Validation Loss: 6.571e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9606, Training Loss: 2.811e-01, Validation Loss: 6.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9607, Training Loss: 2.811e-01, Validation Loss: 6.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9608, Training Loss: 2.811e-01, Validation Loss: 6.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9609, Training Loss: 2.810e-01, Validation Loss: 6.570e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9610, Training Loss: 2.810e-01, Validation Loss: 6.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9611, Training Loss: 2.810e-01, Validation Loss: 6.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9612, Training Loss: 2.809e-01, Validation Loss: 6.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9613, Training Loss: 2.809e-01, Validation Loss: 6.569e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9614, Training Loss: 2.809e-01, Validation Loss: 6.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9615, Training Loss: 2.808e-01, Validation Loss: 6.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9616, Training Loss: 2.808e-01, Validation Loss: 6.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9617, Training Loss: 2.808e-01, Validation Loss: 6.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9618, Training Loss: 2.807e-01, Validation Loss: 6.568e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9619, Training Loss: 2.807e-01, Validation Loss: 6.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9620, Training Loss: 2.807e-01, Validation Loss: 6.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9621, Training Loss: 2.806e-01, Validation Loss: 6.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9622, Training Loss: 2.806e-01, Validation Loss: 6.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9623, Training Loss: 2.806e-01, Validation Loss: 6.567e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9624, Training Loss: 2.805e-01, Validation Loss: 6.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9625, Training Loss: 2.805e-01, Validation Loss: 6.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9626, Training Loss: 2.805e-01, Validation Loss: 6.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9627, Training Loss: 2.804e-01, Validation Loss: 6.566e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9628, Training Loss: 2.804e-01, Validation Loss: 6.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9629, Training Loss: 2.804e-01, Validation Loss: 6.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9630, Training Loss: 2.803e-01, Validation Loss: 6.565e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9631, Training Loss: 2.803e-01, Validation Loss: 6.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9632, Training Loss: 2.803e-01, Validation Loss: 6.565e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9633, Training Loss: 2.802e-01, Validation Loss: 6.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9634, Training Loss: 2.802e-01, Validation Loss: 6.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9635, Training Loss: 2.802e-01, Validation Loss: 6.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9636, Training Loss: 2.801e-01, Validation Loss: 6.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9637, Training Loss: 2.801e-01, Validation Loss: 6.564e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9638, Training Loss: 2.801e-01, Validation Loss: 6.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9639, Training Loss: 2.800e-01, Validation Loss: 6.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9640, Training Loss: 2.800e-01, Validation Loss: 6.563e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9641, Training Loss: 2.800e-01, Validation Loss: 6.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9642, Training Loss: 2.799e-01, Validation Loss: 6.563e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9643, Training Loss: 2.799e-01, Validation Loss: 6.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9644, Training Loss: 2.799e-01, Validation Loss: 6.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9645, Training Loss: 2.798e-01, Validation Loss: 6.562e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9646, Training Loss: 2.798e-01, Validation Loss: 6.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9647, Training Loss: 2.798e-01, Validation Loss: 6.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9648, Training Loss: 2.797e-01, Validation Loss: 6.561e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9649, Training Loss: 2.797e-01, Validation Loss: 6.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9650, Training Loss: 2.797e-01, Validation Loss: 6.561e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9651, Training Loss: 2.796e-01, Validation Loss: 6.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9652, Training Loss: 2.796e-01, Validation Loss: 6.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9653, Training Loss: 2.796e-01, Validation Loss: 6.560e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9654, Training Loss: 2.795e-01, Validation Loss: 6.560e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9655, Training Loss: 2.795e-01, Validation Loss: 6.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9656, Training Loss: 2.795e-01, Validation Loss: 6.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9657, Training Loss: 2.794e-01, Validation Loss: 6.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9658, Training Loss: 2.794e-01, Validation Loss: 6.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9659, Training Loss: 2.794e-01, Validation Loss: 6.559e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9660, Training Loss: 2.793e-01, Validation Loss: 6.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9661, Training Loss: 2.793e-01, Validation Loss: 6.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9662, Training Loss: 2.793e-01, Validation Loss: 6.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9663, Training Loss: 2.792e-01, Validation Loss: 6.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9664, Training Loss: 2.792e-01, Validation Loss: 6.558e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9665, Training Loss: 2.792e-01, Validation Loss: 6.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9666, Training Loss: 2.791e-01, Validation Loss: 6.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9667, Training Loss: 2.791e-01, Validation Loss: 6.557e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9668, Training Loss: 2.791e-01, Validation Loss: 6.557e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9669, Training Loss: 2.790e-01, Validation Loss: 6.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9670, Training Loss: 2.790e-01, Validation Loss: 6.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9671, Training Loss: 2.790e-01, Validation Loss: 6.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9672, Training Loss: 2.789e-01, Validation Loss: 6.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9673, Training Loss: 2.789e-01, Validation Loss: 6.556e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9674, Training Loss: 2.789e-01, Validation Loss: 6.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9675, Training Loss: 2.788e-01, Validation Loss: 6.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9676, Training Loss: 2.788e-01, Validation Loss: 6.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9677, Training Loss: 2.787e-01, Validation Loss: 6.555e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9678, Training Loss: 2.787e-01, Validation Loss: 6.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9679, Training Loss: 2.787e-01, Validation Loss: 6.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9680, Training Loss: 2.786e-01, Validation Loss: 6.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9681, Training Loss: 2.786e-01, Validation Loss: 6.554e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9682, Training Loss: 2.786e-01, Validation Loss: 6.554e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9683, Training Loss: 2.785e-01, Validation Loss: 6.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9684, Training Loss: 2.785e-01, Validation Loss: 6.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9685, Training Loss: 2.785e-01, Validation Loss: 6.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9686, Training Loss: 2.784e-01, Validation Loss: 6.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9687, Training Loss: 2.784e-01, Validation Loss: 6.553e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9688, Training Loss: 2.784e-01, Validation Loss: 6.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9689, Training Loss: 2.783e-01, Validation Loss: 6.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9690, Training Loss: 2.783e-01, Validation Loss: 6.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9691, Training Loss: 2.783e-01, Validation Loss: 6.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9692, Training Loss: 2.782e-01, Validation Loss: 6.552e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9693, Training Loss: 2.782e-01, Validation Loss: 6.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9694, Training Loss: 2.782e-01, Validation Loss: 6.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9695, Training Loss: 2.781e-01, Validation Loss: 6.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9696, Training Loss: 2.781e-01, Validation Loss: 6.551e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9697, Training Loss: 2.781e-01, Validation Loss: 6.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9698, Training Loss: 2.780e-01, Validation Loss: 6.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9699, Training Loss: 2.780e-01, Validation Loss: 6.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9700, Training Loss: 2.780e-01, Validation Loss: 6.550e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9701, Training Loss: 2.779e-01, Validation Loss: 6.550e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9702, Training Loss: 2.779e-01, Validation Loss: 6.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9703, Training Loss: 2.779e-01, Validation Loss: 6.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9704, Training Loss: 2.778e-01, Validation Loss: 6.549e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9705, Training Loss: 2.778e-01, Validation Loss: 6.549e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9706, Training Loss: 2.778e-01, Validation Loss: 6.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9707, Training Loss: 2.777e-01, Validation Loss: 6.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9708, Training Loss: 2.777e-01, Validation Loss: 6.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9709, Training Loss: 2.777e-01, Validation Loss: 6.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9710, Training Loss: 2.776e-01, Validation Loss: 6.548e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9711, Training Loss: 2.776e-01, Validation Loss: 6.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9712, Training Loss: 2.776e-01, Validation Loss: 6.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9713, Training Loss: 2.775e-01, Validation Loss: 6.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9714, Training Loss: 2.775e-01, Validation Loss: 6.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9715, Training Loss: 2.775e-01, Validation Loss: 6.547e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9716, Training Loss: 2.774e-01, Validation Loss: 6.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9717, Training Loss: 2.774e-01, Validation Loss: 6.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9718, Training Loss: 2.774e-01, Validation Loss: 6.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9719, Training Loss: 2.773e-01, Validation Loss: 6.546e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9720, Training Loss: 2.773e-01, Validation Loss: 6.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9721, Training Loss: 2.773e-01, Validation Loss: 6.545e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9722, Training Loss: 2.772e-01, Validation Loss: 6.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9723, Training Loss: 2.772e-01, Validation Loss: 6.545e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9724, Training Loss: 2.772e-01, Validation Loss: 6.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9725, Training Loss: 2.771e-01, Validation Loss: 6.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9726, Training Loss: 2.771e-01, Validation Loss: 6.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9727, Training Loss: 2.771e-01, Validation Loss: 6.544e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9728, Training Loss: 2.770e-01, Validation Loss: 6.544e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9729, Training Loss: 2.770e-01, Validation Loss: 6.544e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9730, Training Loss: 2.770e-01, Validation Loss: 6.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9731, Training Loss: 2.769e-01, Validation Loss: 6.543e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9732, Training Loss: 2.769e-01, Validation Loss: 6.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9733, Training Loss: 2.769e-01, Validation Loss: 6.543e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9734, Training Loss: 2.768e-01, Validation Loss: 6.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9735, Training Loss: 2.768e-01, Validation Loss: 6.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9736, Training Loss: 2.768e-01, Validation Loss: 6.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9737, Training Loss: 2.767e-01, Validation Loss: 6.542e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9738, Training Loss: 2.767e-01, Validation Loss: 6.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9739, Training Loss: 2.767e-01, Validation Loss: 6.542e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9740, Training Loss: 2.767e-01, Validation Loss: 6.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9741, Training Loss: 2.766e-01, Validation Loss: 6.541e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9742, Training Loss: 2.766e-01, Validation Loss: 6.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9743, Training Loss: 2.766e-01, Validation Loss: 6.541e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9744, Training Loss: 2.765e-01, Validation Loss: 6.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9745, Training Loss: 2.765e-01, Validation Loss: 6.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9746, Training Loss: 2.765e-01, Validation Loss: 6.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9747, Training Loss: 2.764e-01, Validation Loss: 6.540e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9748, Training Loss: 2.764e-01, Validation Loss: 6.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9749, Training Loss: 2.764e-01, Validation Loss: 6.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9750, Training Loss: 2.763e-01, Validation Loss: 6.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9751, Training Loss: 2.763e-01, Validation Loss: 6.539e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9752, Training Loss: 2.763e-01, Validation Loss: 6.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9753, Training Loss: 2.762e-01, Validation Loss: 6.539e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9754, Training Loss: 2.762e-01, Validation Loss: 6.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9755, Training Loss: 2.762e-01, Validation Loss: 6.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9756, Training Loss: 2.761e-01, Validation Loss: 6.538e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9757, Training Loss: 2.761e-01, Validation Loss: 6.538e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9758, Training Loss: 2.761e-01, Validation Loss: 6.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9759, Training Loss: 2.760e-01, Validation Loss: 6.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9760, Training Loss: 2.760e-01, Validation Loss: 6.537e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9761, Training Loss: 2.760e-01, Validation Loss: 6.537e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9762, Training Loss: 2.759e-01, Validation Loss: 6.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9763, Training Loss: 2.759e-01, Validation Loss: 6.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9764, Training Loss: 2.759e-01, Validation Loss: 6.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9765, Training Loss: 2.758e-01, Validation Loss: 6.536e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9766, Training Loss: 2.758e-01, Validation Loss: 6.536e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9767, Training Loss: 2.758e-01, Validation Loss: 6.536e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9768, Training Loss: 2.757e-01, Validation Loss: 6.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9769, Training Loss: 2.757e-01, Validation Loss: 6.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9770, Training Loss: 2.757e-01, Validation Loss: 6.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9771, Training Loss: 2.756e-01, Validation Loss: 6.535e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9772, Training Loss: 2.756e-01, Validation Loss: 6.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9773, Training Loss: 2.756e-01, Validation Loss: 6.534e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9774, Training Loss: 2.755e-01, Validation Loss: 6.534e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9775, Training Loss: 2.755e-01, Validation Loss: 6.534e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9776, Training Loss: 2.755e-01, Validation Loss: 6.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9777, Training Loss: 2.754e-01, Validation Loss: 6.533e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9778, Training Loss: 2.754e-01, Validation Loss: 6.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9779, Training Loss: 2.754e-01, Validation Loss: 6.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9780, Training Loss: 2.753e-01, Validation Loss: 6.533e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9781, Training Loss: 2.753e-01, Validation Loss: 6.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9782, Training Loss: 2.753e-01, Validation Loss: 6.532e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9783, Training Loss: 2.752e-01, Validation Loss: 6.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9784, Training Loss: 2.752e-01, Validation Loss: 6.532e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9785, Training Loss: 2.752e-01, Validation Loss: 6.532e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9786, Training Loss: 2.751e-01, Validation Loss: 6.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9787, Training Loss: 2.751e-01, Validation Loss: 6.531e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9788, Training Loss: 2.751e-01, Validation Loss: 6.531e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9789, Training Loss: 2.750e-01, Validation Loss: 6.531e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9790, Training Loss: 2.750e-01, Validation Loss: 6.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9791, Training Loss: 2.750e-01, Validation Loss: 6.530e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9792, Training Loss: 2.749e-01, Validation Loss: 6.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9793, Training Loss: 2.749e-01, Validation Loss: 6.530e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9794, Training Loss: 2.749e-01, Validation Loss: 6.530e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9795, Training Loss: 2.748e-01, Validation Loss: 6.530e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9796, Training Loss: 2.748e-01, Validation Loss: 6.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9797, Training Loss: 2.748e-01, Validation Loss: 6.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9798, Training Loss: 2.747e-01, Validation Loss: 6.529e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9799, Training Loss: 2.747e-01, Validation Loss: 6.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9800, Training Loss: 2.747e-01, Validation Loss: 6.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9801, Training Loss: 2.746e-01, Validation Loss: 6.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9802, Training Loss: 2.746e-01, Validation Loss: 6.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9803, Training Loss: 2.746e-01, Validation Loss: 6.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9804, Training Loss: 2.745e-01, Validation Loss: 6.528e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9805, Training Loss: 2.745e-01, Validation Loss: 6.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9806, Training Loss: 2.745e-01, Validation Loss: 6.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9807, Training Loss: 2.744e-01, Validation Loss: 6.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9808, Training Loss: 2.744e-01, Validation Loss: 6.527e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9809, Training Loss: 2.744e-01, Validation Loss: 6.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9810, Training Loss: 2.743e-01, Validation Loss: 6.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9811, Training Loss: 2.743e-01, Validation Loss: 6.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9812, Training Loss: 2.743e-01, Validation Loss: 6.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9813, Training Loss: 2.742e-01, Validation Loss: 6.526e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9814, Training Loss: 2.742e-01, Validation Loss: 6.526e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9815, Training Loss: 2.742e-01, Validation Loss: 6.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9816, Training Loss: 2.742e-01, Validation Loss: 6.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9817, Training Loss: 2.741e-01, Validation Loss: 6.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9818, Training Loss: 2.741e-01, Validation Loss: 6.525e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9819, Training Loss: 2.741e-01, Validation Loss: 6.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9820, Training Loss: 2.740e-01, Validation Loss: 6.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9821, Training Loss: 2.740e-01, Validation Loss: 6.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9822, Training Loss: 2.740e-01, Validation Loss: 6.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9823, Training Loss: 2.739e-01, Validation Loss: 6.524e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9824, Training Loss: 2.739e-01, Validation Loss: 6.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9825, Training Loss: 2.739e-01, Validation Loss: 6.523e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9826, Training Loss: 2.738e-01, Validation Loss: 6.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9827, Training Loss: 2.738e-01, Validation Loss: 6.523e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9828, Training Loss: 2.738e-01, Validation Loss: 6.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9829, Training Loss: 2.737e-01, Validation Loss: 6.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9830, Training Loss: 2.737e-01, Validation Loss: 6.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9831, Training Loss: 2.737e-01, Validation Loss: 6.522e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9832, Training Loss: 2.736e-01, Validation Loss: 6.522e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9833, Training Loss: 2.736e-01, Validation Loss: 6.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9834, Training Loss: 2.736e-01, Validation Loss: 6.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9835, Training Loss: 2.735e-01, Validation Loss: 6.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9836, Training Loss: 2.735e-01, Validation Loss: 6.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9837, Training Loss: 2.735e-01, Validation Loss: 6.521e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9838, Training Loss: 2.734e-01, Validation Loss: 6.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9839, Training Loss: 2.734e-01, Validation Loss: 6.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9840, Training Loss: 2.734e-01, Validation Loss: 6.520e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9841, Training Loss: 2.733e-01, Validation Loss: 6.520e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9842, Training Loss: 2.733e-01, Validation Loss: 6.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9843, Training Loss: 2.733e-01, Validation Loss: 6.520e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9844, Training Loss: 2.732e-01, Validation Loss: 6.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9845, Training Loss: 2.732e-01, Validation Loss: 6.519e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9846, Training Loss: 2.732e-01, Validation Loss: 6.519e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9847, Training Loss: 2.731e-01, Validation Loss: 6.519e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9848, Training Loss: 2.731e-01, Validation Loss: 6.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9849, Training Loss: 2.731e-01, Validation Loss: 6.518e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9850, Training Loss: 2.730e-01, Validation Loss: 6.518e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9851, Training Loss: 2.730e-01, Validation Loss: 6.518e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9852, Training Loss: 2.730e-01, Validation Loss: 6.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9853, Training Loss: 2.729e-01, Validation Loss: 6.517e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9854, Training Loss: 2.729e-01, Validation Loss: 6.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9855, Training Loss: 2.729e-01, Validation Loss: 6.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9856, Training Loss: 2.728e-01, Validation Loss: 6.517e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9857, Training Loss: 2.728e-01, Validation Loss: 6.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9858, Training Loss: 2.728e-01, Validation Loss: 6.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9859, Training Loss: 2.727e-01, Validation Loss: 6.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9860, Training Loss: 2.727e-01, Validation Loss: 6.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9861, Training Loss: 2.727e-01, Validation Loss: 6.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9862, Training Loss: 2.727e-01, Validation Loss: 6.516e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9863, Training Loss: 2.726e-01, Validation Loss: 6.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9864, Training Loss: 2.726e-01, Validation Loss: 6.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9865, Training Loss: 2.726e-01, Validation Loss: 6.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9866, Training Loss: 2.725e-01, Validation Loss: 6.515e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9867, Training Loss: 2.725e-01, Validation Loss: 6.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9868, Training Loss: 2.725e-01, Validation Loss: 6.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9869, Training Loss: 2.724e-01, Validation Loss: 6.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9870, Training Loss: 2.724e-01, Validation Loss: 6.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9871, Training Loss: 2.724e-01, Validation Loss: 6.514e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9872, Training Loss: 2.723e-01, Validation Loss: 6.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9873, Training Loss: 2.723e-01, Validation Loss: 6.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9874, Training Loss: 2.723e-01, Validation Loss: 6.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9875, Training Loss: 2.722e-01, Validation Loss: 6.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9876, Training Loss: 2.722e-01, Validation Loss: 6.513e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9877, Training Loss: 2.722e-01, Validation Loss: 6.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9878, Training Loss: 2.721e-01, Validation Loss: 6.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9879, Training Loss: 2.721e-01, Validation Loss: 6.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9880, Training Loss: 2.721e-01, Validation Loss: 6.512e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9881, Training Loss: 2.720e-01, Validation Loss: 6.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9882, Training Loss: 2.720e-01, Validation Loss: 6.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9883, Training Loss: 2.720e-01, Validation Loss: 6.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9884, Training Loss: 2.719e-01, Validation Loss: 6.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9885, Training Loss: 2.719e-01, Validation Loss: 6.511e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9886, Training Loss: 2.719e-01, Validation Loss: 6.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9887, Training Loss: 2.718e-01, Validation Loss: 6.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9888, Training Loss: 2.718e-01, Validation Loss: 6.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9889, Training Loss: 2.718e-01, Validation Loss: 6.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9890, Training Loss: 2.717e-01, Validation Loss: 6.510e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9891, Training Loss: 2.717e-01, Validation Loss: 6.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9892, Training Loss: 2.717e-01, Validation Loss: 6.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9893, Training Loss: 2.717e-01, Validation Loss: 6.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9894, Training Loss: 2.716e-01, Validation Loss: 6.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9895, Training Loss: 2.716e-01, Validation Loss: 6.509e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9896, Training Loss: 2.716e-01, Validation Loss: 6.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9897, Training Loss: 2.715e-01, Validation Loss: 6.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9898, Training Loss: 2.715e-01, Validation Loss: 6.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9899, Training Loss: 2.715e-01, Validation Loss: 6.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9900, Training Loss: 2.714e-01, Validation Loss: 6.508e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9901, Training Loss: 2.714e-01, Validation Loss: 6.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9902, Training Loss: 2.714e-01, Validation Loss: 6.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9903, Training Loss: 2.713e-01, Validation Loss: 6.507e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9904, Training Loss: 2.713e-01, Validation Loss: 6.507e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9905, Training Loss: 2.713e-01, Validation Loss: 6.507e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9906, Training Loss: 2.712e-01, Validation Loss: 6.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9907, Training Loss: 2.712e-01, Validation Loss: 6.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9908, Training Loss: 2.712e-01, Validation Loss: 6.506e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9909, Training Loss: 2.711e-01, Validation Loss: 6.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9910, Training Loss: 2.711e-01, Validation Loss: 6.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9911, Training Loss: 2.711e-01, Validation Loss: 6.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9912, Training Loss: 2.710e-01, Validation Loss: 6.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9913, Training Loss: 2.710e-01, Validation Loss: 6.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9914, Training Loss: 2.710e-01, Validation Loss: 6.505e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9915, Training Loss: 2.709e-01, Validation Loss: 6.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9916, Training Loss: 2.709e-01, Validation Loss: 6.504e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9917, Training Loss: 2.709e-01, Validation Loss: 6.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9918, Training Loss: 2.708e-01, Validation Loss: 6.504e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9919, Training Loss: 2.708e-01, Validation Loss: 6.504e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9920, Training Loss: 2.708e-01, Validation Loss: 6.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9921, Training Loss: 2.708e-01, Validation Loss: 6.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9922, Training Loss: 2.707e-01, Validation Loss: 6.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9923, Training Loss: 2.707e-01, Validation Loss: 6.503e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9924, Training Loss: 2.707e-01, Validation Loss: 6.503e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9925, Training Loss: 2.706e-01, Validation Loss: 6.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9926, Training Loss: 2.706e-01, Validation Loss: 6.502e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9927, Training Loss: 2.706e-01, Validation Loss: 6.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9928, Training Loss: 2.705e-01, Validation Loss: 6.502e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9929, Training Loss: 2.705e-01, Validation Loss: 6.502e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9930, Training Loss: 2.705e-01, Validation Loss: 6.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9931, Training Loss: 2.704e-01, Validation Loss: 6.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9932, Training Loss: 2.704e-01, Validation Loss: 6.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9933, Training Loss: 2.704e-01, Validation Loss: 6.501e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9934, Training Loss: 2.703e-01, Validation Loss: 6.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9935, Training Loss: 2.703e-01, Validation Loss: 6.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9936, Training Loss: 2.703e-01, Validation Loss: 6.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9937, Training Loss: 2.702e-01, Validation Loss: 6.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9938, Training Loss: 2.702e-01, Validation Loss: 6.500e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9939, Training Loss: 2.702e-01, Validation Loss: 6.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9940, Training Loss: 2.701e-01, Validation Loss: 6.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9941, Training Loss: 2.701e-01, Validation Loss: 6.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9942, Training Loss: 2.701e-01, Validation Loss: 6.499e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9943, Training Loss: 2.700e-01, Validation Loss: 6.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9944, Training Loss: 2.700e-01, Validation Loss: 6.499e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9945, Training Loss: 2.700e-01, Validation Loss: 6.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9946, Training Loss: 2.700e-01, Validation Loss: 6.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9947, Training Loss: 2.699e-01, Validation Loss: 6.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9948, Training Loss: 2.699e-01, Validation Loss: 6.498e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9949, Training Loss: 2.699e-01, Validation Loss: 6.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9950, Training Loss: 2.698e-01, Validation Loss: 6.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9951, Training Loss: 2.698e-01, Validation Loss: 6.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9952, Training Loss: 2.698e-01, Validation Loss: 6.497e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9953, Training Loss: 2.697e-01, Validation Loss: 6.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9954, Training Loss: 2.697e-01, Validation Loss: 6.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9955, Training Loss: 2.697e-01, Validation Loss: 6.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9956, Training Loss: 2.696e-01, Validation Loss: 6.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9957, Training Loss: 2.696e-01, Validation Loss: 6.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9958, Training Loss: 2.696e-01, Validation Loss: 6.496e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9959, Training Loss: 2.695e-01, Validation Loss: 6.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9960, Training Loss: 2.695e-01, Validation Loss: 6.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9961, Training Loss: 2.695e-01, Validation Loss: 6.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9962, Training Loss: 2.694e-01, Validation Loss: 6.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9963, Training Loss: 2.694e-01, Validation Loss: 6.495e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9964, Training Loss: 2.694e-01, Validation Loss: 6.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9965, Training Loss: 2.693e-01, Validation Loss: 6.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9966, Training Loss: 2.693e-01, Validation Loss: 6.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9967, Training Loss: 2.693e-01, Validation Loss: 6.494e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9968, Training Loss: 2.692e-01, Validation Loss: 6.494e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9969, Training Loss: 2.692e-01, Validation Loss: 6.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9970, Training Loss: 2.692e-01, Validation Loss: 6.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9971, Training Loss: 2.692e-01, Validation Loss: 6.493e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9972, Training Loss: 2.691e-01, Validation Loss: 6.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9973, Training Loss: 2.691e-01, Validation Loss: 6.493e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9974, Training Loss: 2.691e-01, Validation Loss: 6.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9975, Training Loss: 2.690e-01, Validation Loss: 6.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9976, Training Loss: 2.690e-01, Validation Loss: 6.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9977, Training Loss: 2.690e-01, Validation Loss: 6.492e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9978, Training Loss: 2.689e-01, Validation Loss: 6.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9979, Training Loss: 2.689e-01, Validation Loss: 6.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9980, Training Loss: 2.689e-01, Validation Loss: 6.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9981, Training Loss: 2.688e-01, Validation Loss: 6.491e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9982, Training Loss: 2.688e-01, Validation Loss: 6.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9983, Training Loss: 2.688e-01, Validation Loss: 6.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9984, Training Loss: 2.687e-01, Validation Loss: 6.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9985, Training Loss: 2.687e-01, Validation Loss: 6.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9986, Training Loss: 2.687e-01, Validation Loss: 6.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9987, Training Loss: 2.686e-01, Validation Loss: 6.490e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9988, Training Loss: 2.686e-01, Validation Loss: 6.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9989, Training Loss: 2.686e-01, Validation Loss: 6.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9990, Training Loss: 2.686e-01, Validation Loss: 6.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9991, Training Loss: 2.685e-01, Validation Loss: 6.489e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9992, Training Loss: 2.685e-01, Validation Loss: 6.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9993, Training Loss: 2.685e-01, Validation Loss: 6.488e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 9994, Training Loss: 2.684e-01, Validation Loss: 6.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9995, Training Loss: 2.684e-01, Validation Loss: 6.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9996, Training Loss: 2.684e-01, Validation Loss: 6.488e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9997, Training Loss: 2.683e-01, Validation Loss: 6.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9998, Training Loss: 2.683e-01, Validation Loss: 6.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 9999, Training Loss: 2.683e-01, Validation Loss: 6.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10000, Training Loss: 2.682e-01, Validation Loss: 6.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10001, Training Loss: 2.682e-01, Validation Loss: 6.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10002, Training Loss: 2.682e-01, Validation Loss: 6.487e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10003, Training Loss: 2.681e-01, Validation Loss: 6.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10004, Training Loss: 2.681e-01, Validation Loss: 6.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10005, Training Loss: 2.681e-01, Validation Loss: 6.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10006, Training Loss: 2.680e-01, Validation Loss: 6.486e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10007, Training Loss: 2.680e-01, Validation Loss: 6.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10008, Training Loss: 2.680e-01, Validation Loss: 6.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10009, Training Loss: 2.679e-01, Validation Loss: 6.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10010, Training Loss: 2.679e-01, Validation Loss: 6.485e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10011, Training Loss: 2.679e-01, Validation Loss: 6.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10012, Training Loss: 2.679e-01, Validation Loss: 6.485e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10013, Training Loss: 2.678e-01, Validation Loss: 6.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10014, Training Loss: 2.678e-01, Validation Loss: 6.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10015, Training Loss: 2.678e-01, Validation Loss: 6.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10016, Training Loss: 2.677e-01, Validation Loss: 6.484e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10017, Training Loss: 2.677e-01, Validation Loss: 6.484e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10018, Training Loss: 2.677e-01, Validation Loss: 6.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10019, Training Loss: 2.676e-01, Validation Loss: 6.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10020, Training Loss: 2.676e-01, Validation Loss: 6.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10021, Training Loss: 2.676e-01, Validation Loss: 6.483e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10022, Training Loss: 2.675e-01, Validation Loss: 6.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10023, Training Loss: 2.675e-01, Validation Loss: 6.482e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10024, Training Loss: 2.675e-01, Validation Loss: 6.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10025, Training Loss: 2.674e-01, Validation Loss: 6.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10026, Training Loss: 2.674e-01, Validation Loss: 6.482e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10027, Training Loss: 2.674e-01, Validation Loss: 6.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10028, Training Loss: 2.674e-01, Validation Loss: 6.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10029, Training Loss: 2.673e-01, Validation Loss: 6.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10030, Training Loss: 2.673e-01, Validation Loss: 6.481e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10031, Training Loss: 2.673e-01, Validation Loss: 6.481e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10032, Training Loss: 2.672e-01, Validation Loss: 6.481e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10033, Training Loss: 2.672e-01, Validation Loss: 6.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10034, Training Loss: 2.672e-01, Validation Loss: 6.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10035, Training Loss: 2.671e-01, Validation Loss: 6.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10036, Training Loss: 2.671e-01, Validation Loss: 6.480e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10037, Training Loss: 2.671e-01, Validation Loss: 6.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10038, Training Loss: 2.670e-01, Validation Loss: 6.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10039, Training Loss: 2.670e-01, Validation Loss: 6.479e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10040, Training Loss: 2.670e-01, Validation Loss: 6.479e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10041, Training Loss: 2.669e-01, Validation Loss: 6.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10042, Training Loss: 2.669e-01, Validation Loss: 6.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10043, Training Loss: 2.669e-01, Validation Loss: 6.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10044, Training Loss: 2.668e-01, Validation Loss: 6.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10045, Training Loss: 2.668e-01, Validation Loss: 6.478e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10046, Training Loss: 2.668e-01, Validation Loss: 6.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10047, Training Loss: 2.668e-01, Validation Loss: 6.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10048, Training Loss: 2.667e-01, Validation Loss: 6.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10049, Training Loss: 2.667e-01, Validation Loss: 6.477e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10050, Training Loss: 2.667e-01, Validation Loss: 6.477e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10051, Training Loss: 2.666e-01, Validation Loss: 6.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10052, Training Loss: 2.666e-01, Validation Loss: 6.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10053, Training Loss: 2.666e-01, Validation Loss: 6.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10054, Training Loss: 2.665e-01, Validation Loss: 6.476e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10055, Training Loss: 2.665e-01, Validation Loss: 6.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10056, Training Loss: 2.665e-01, Validation Loss: 6.476e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10057, Training Loss: 2.664e-01, Validation Loss: 6.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10058, Training Loss: 2.664e-01, Validation Loss: 6.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10059, Training Loss: 2.664e-01, Validation Loss: 6.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10060, Training Loss: 2.663e-01, Validation Loss: 6.475e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10061, Training Loss: 2.663e-01, Validation Loss: 6.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10062, Training Loss: 2.663e-01, Validation Loss: 6.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10063, Training Loss: 2.663e-01, Validation Loss: 6.474e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10064, Training Loss: 2.662e-01, Validation Loss: 6.474e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10065, Training Loss: 2.662e-01, Validation Loss: 6.474e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10066, Training Loss: 2.662e-01, Validation Loss: 6.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10067, Training Loss: 2.661e-01, Validation Loss: 6.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10068, Training Loss: 2.661e-01, Validation Loss: 6.473e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10069, Training Loss: 2.661e-01, Validation Loss: 6.473e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10070, Training Loss: 2.660e-01, Validation Loss: 6.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10071, Training Loss: 2.660e-01, Validation Loss: 6.473e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10072, Training Loss: 2.660e-01, Validation Loss: 6.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10073, Training Loss: 2.659e-01, Validation Loss: 6.472e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10074, Training Loss: 2.659e-01, Validation Loss: 6.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10075, Training Loss: 2.659e-01, Validation Loss: 6.472e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10076, Training Loss: 2.658e-01, Validation Loss: 6.472e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10077, Training Loss: 2.658e-01, Validation Loss: 6.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10078, Training Loss: 2.658e-01, Validation Loss: 6.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10079, Training Loss: 2.658e-01, Validation Loss: 6.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10080, Training Loss: 2.657e-01, Validation Loss: 6.471e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10081, Training Loss: 2.657e-01, Validation Loss: 6.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10082, Training Loss: 2.657e-01, Validation Loss: 6.470e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10083, Training Loss: 2.656e-01, Validation Loss: 6.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10084, Training Loss: 2.656e-01, Validation Loss: 6.470e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10085, Training Loss: 2.656e-01, Validation Loss: 6.470e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10086, Training Loss: 2.655e-01, Validation Loss: 6.470e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10087, Training Loss: 2.655e-01, Validation Loss: 6.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10088, Training Loss: 2.655e-01, Validation Loss: 6.469e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10089, Training Loss: 2.654e-01, Validation Loss: 6.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10090, Training Loss: 2.654e-01, Validation Loss: 6.469e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10091, Training Loss: 2.654e-01, Validation Loss: 6.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10092, Training Loss: 2.653e-01, Validation Loss: 6.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10093, Training Loss: 2.653e-01, Validation Loss: 6.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10094, Training Loss: 2.653e-01, Validation Loss: 6.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10095, Training Loss: 2.653e-01, Validation Loss: 6.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10096, Training Loss: 2.652e-01, Validation Loss: 6.468e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10097, Training Loss: 2.652e-01, Validation Loss: 6.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10098, Training Loss: 2.652e-01, Validation Loss: 6.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10099, Training Loss: 2.651e-01, Validation Loss: 6.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10100, Training Loss: 2.651e-01, Validation Loss: 6.467e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10101, Training Loss: 2.651e-01, Validation Loss: 6.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10102, Training Loss: 2.650e-01, Validation Loss: 6.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10103, Training Loss: 2.650e-01, Validation Loss: 6.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10104, Training Loss: 2.650e-01, Validation Loss: 6.466e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10105, Training Loss: 2.649e-01, Validation Loss: 6.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10106, Training Loss: 2.649e-01, Validation Loss: 6.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10107, Training Loss: 2.649e-01, Validation Loss: 6.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10108, Training Loss: 2.649e-01, Validation Loss: 6.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10109, Training Loss: 2.648e-01, Validation Loss: 6.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10110, Training Loss: 2.648e-01, Validation Loss: 6.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10111, Training Loss: 2.648e-01, Validation Loss: 6.465e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10112, Training Loss: 2.647e-01, Validation Loss: 6.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10113, Training Loss: 2.647e-01, Validation Loss: 6.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10114, Training Loss: 2.647e-01, Validation Loss: 6.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10115, Training Loss: 2.646e-01, Validation Loss: 6.464e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10116, Training Loss: 2.646e-01, Validation Loss: 6.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10117, Training Loss: 2.646e-01, Validation Loss: 6.463e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10118, Training Loss: 2.645e-01, Validation Loss: 6.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10119, Training Loss: 2.645e-01, Validation Loss: 6.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10120, Training Loss: 2.645e-01, Validation Loss: 6.463e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10121, Training Loss: 2.644e-01, Validation Loss: 6.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10122, Training Loss: 2.644e-01, Validation Loss: 6.462e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10123, Training Loss: 2.644e-01, Validation Loss: 6.462e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10124, Training Loss: 2.644e-01, Validation Loss: 6.462e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10125, Training Loss: 2.643e-01, Validation Loss: 6.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10126, Training Loss: 2.643e-01, Validation Loss: 6.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10127, Training Loss: 2.643e-01, Validation Loss: 6.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10128, Training Loss: 2.642e-01, Validation Loss: 6.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10129, Training Loss: 2.642e-01, Validation Loss: 6.461e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10130, Training Loss: 2.642e-01, Validation Loss: 6.461e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10131, Training Loss: 2.641e-01, Validation Loss: 6.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10132, Training Loss: 2.641e-01, Validation Loss: 6.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10133, Training Loss: 2.641e-01, Validation Loss: 6.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10134, Training Loss: 2.640e-01, Validation Loss: 6.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10135, Training Loss: 2.640e-01, Validation Loss: 6.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10136, Training Loss: 2.640e-01, Validation Loss: 6.460e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10137, Training Loss: 2.640e-01, Validation Loss: 6.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10138, Training Loss: 2.639e-01, Validation Loss: 6.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10139, Training Loss: 2.639e-01, Validation Loss: 6.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10140, Training Loss: 2.639e-01, Validation Loss: 6.459e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10141, Training Loss: 2.638e-01, Validation Loss: 6.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10142, Training Loss: 2.638e-01, Validation Loss: 6.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10143, Training Loss: 2.638e-01, Validation Loss: 6.458e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10144, Training Loss: 2.637e-01, Validation Loss: 6.458e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10145, Training Loss: 2.637e-01, Validation Loss: 6.458e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10146, Training Loss: 2.637e-01, Validation Loss: 6.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10147, Training Loss: 2.636e-01, Validation Loss: 6.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10148, Training Loss: 2.636e-01, Validation Loss: 6.457e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10149, Training Loss: 2.636e-01, Validation Loss: 6.457e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10150, Training Loss: 2.636e-01, Validation Loss: 6.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10151, Training Loss: 2.635e-01, Validation Loss: 6.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10152, Training Loss: 2.635e-01, Validation Loss: 6.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10153, Training Loss: 2.635e-01, Validation Loss: 6.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10154, Training Loss: 2.634e-01, Validation Loss: 6.456e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10155, Training Loss: 2.634e-01, Validation Loss: 6.456e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10156, Training Loss: 2.634e-01, Validation Loss: 6.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10157, Training Loss: 2.633e-01, Validation Loss: 6.455e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10158, Training Loss: 2.633e-01, Validation Loss: 6.455e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10159, Training Loss: 2.633e-01, Validation Loss: 6.455e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10160, Training Loss: 2.632e-01, Validation Loss: 6.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10161, Training Loss: 2.632e-01, Validation Loss: 6.455e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10162, Training Loss: 2.632e-01, Validation Loss: 6.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10163, Training Loss: 2.632e-01, Validation Loss: 6.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10164, Training Loss: 2.631e-01, Validation Loss: 6.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10165, Training Loss: 2.631e-01, Validation Loss: 6.454e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10166, Training Loss: 2.631e-01, Validation Loss: 6.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10167, Training Loss: 2.630e-01, Validation Loss: 6.453e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10168, Training Loss: 2.630e-01, Validation Loss: 6.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10169, Training Loss: 2.630e-01, Validation Loss: 6.453e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10170, Training Loss: 2.629e-01, Validation Loss: 6.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10171, Training Loss: 2.629e-01, Validation Loss: 6.453e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10172, Training Loss: 2.629e-01, Validation Loss: 6.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10173, Training Loss: 2.628e-01, Validation Loss: 6.452e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10174, Training Loss: 2.628e-01, Validation Loss: 6.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10175, Training Loss: 2.628e-01, Validation Loss: 6.452e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10176, Training Loss: 2.628e-01, Validation Loss: 6.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10177, Training Loss: 2.627e-01, Validation Loss: 6.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10178, Training Loss: 2.627e-01, Validation Loss: 6.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10179, Training Loss: 2.627e-01, Validation Loss: 6.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10180, Training Loss: 2.626e-01, Validation Loss: 6.451e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10181, Training Loss: 2.626e-01, Validation Loss: 6.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10182, Training Loss: 2.626e-01, Validation Loss: 6.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10183, Training Loss: 2.625e-01, Validation Loss: 6.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10184, Training Loss: 2.625e-01, Validation Loss: 6.450e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10185, Training Loss: 2.625e-01, Validation Loss: 6.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10186, Training Loss: 2.624e-01, Validation Loss: 6.450e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10187, Training Loss: 2.624e-01, Validation Loss: 6.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10188, Training Loss: 2.624e-01, Validation Loss: 6.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10189, Training Loss: 2.624e-01, Validation Loss: 6.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10190, Training Loss: 2.623e-01, Validation Loss: 6.449e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10191, Training Loss: 2.623e-01, Validation Loss: 6.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10192, Training Loss: 2.623e-01, Validation Loss: 6.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10193, Training Loss: 2.622e-01, Validation Loss: 6.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10194, Training Loss: 2.622e-01, Validation Loss: 6.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10195, Training Loss: 2.622e-01, Validation Loss: 6.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10196, Training Loss: 2.621e-01, Validation Loss: 6.448e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10197, Training Loss: 2.621e-01, Validation Loss: 6.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10198, Training Loss: 2.621e-01, Validation Loss: 6.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10199, Training Loss: 2.620e-01, Validation Loss: 6.447e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10200, Training Loss: 2.620e-01, Validation Loss: 6.447e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10201, Training Loss: 2.620e-01, Validation Loss: 6.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10202, Training Loss: 2.620e-01, Validation Loss: 6.446e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10203, Training Loss: 2.619e-01, Validation Loss: 6.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10204, Training Loss: 2.619e-01, Validation Loss: 6.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10205, Training Loss: 2.619e-01, Validation Loss: 6.446e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10206, Training Loss: 2.618e-01, Validation Loss: 6.446e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10207, Training Loss: 2.618e-01, Validation Loss: 6.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10208, Training Loss: 2.618e-01, Validation Loss: 6.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10209, Training Loss: 2.617e-01, Validation Loss: 6.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10210, Training Loss: 2.617e-01, Validation Loss: 6.445e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10211, Training Loss: 2.617e-01, Validation Loss: 6.445e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10212, Training Loss: 2.617e-01, Validation Loss: 6.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10213, Training Loss: 2.616e-01, Validation Loss: 6.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10214, Training Loss: 2.616e-01, Validation Loss: 6.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10215, Training Loss: 2.616e-01, Validation Loss: 6.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10216, Training Loss: 2.615e-01, Validation Loss: 6.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10217, Training Loss: 2.615e-01, Validation Loss: 6.444e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10218, Training Loss: 2.615e-01, Validation Loss: 6.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10219, Training Loss: 2.614e-01, Validation Loss: 6.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10220, Training Loss: 2.614e-01, Validation Loss: 6.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10221, Training Loss: 2.614e-01, Validation Loss: 6.443e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10222, Training Loss: 2.613e-01, Validation Loss: 6.443e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10223, Training Loss: 2.613e-01, Validation Loss: 6.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10224, Training Loss: 2.613e-01, Validation Loss: 6.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10225, Training Loss: 2.613e-01, Validation Loss: 6.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10226, Training Loss: 2.612e-01, Validation Loss: 6.442e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10227, Training Loss: 2.612e-01, Validation Loss: 6.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10228, Training Loss: 2.612e-01, Validation Loss: 6.441e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10229, Training Loss: 2.611e-01, Validation Loss: 6.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10230, Training Loss: 2.611e-01, Validation Loss: 6.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10231, Training Loss: 2.611e-01, Validation Loss: 6.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10232, Training Loss: 2.610e-01, Validation Loss: 6.441e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10233, Training Loss: 2.610e-01, Validation Loss: 6.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10234, Training Loss: 2.610e-01, Validation Loss: 6.440e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10235, Training Loss: 2.610e-01, Validation Loss: 6.440e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10236, Training Loss: 2.609e-01, Validation Loss: 6.440e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10237, Training Loss: 2.609e-01, Validation Loss: 6.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10238, Training Loss: 2.609e-01, Validation Loss: 6.439e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10239, Training Loss: 2.608e-01, Validation Loss: 6.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10240, Training Loss: 2.608e-01, Validation Loss: 6.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10241, Training Loss: 2.608e-01, Validation Loss: 6.439e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10242, Training Loss: 2.607e-01, Validation Loss: 6.439e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10243, Training Loss: 2.607e-01, Validation Loss: 6.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10244, Training Loss: 2.607e-01, Validation Loss: 6.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10245, Training Loss: 2.606e-01, Validation Loss: 6.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10246, Training Loss: 2.606e-01, Validation Loss: 6.438e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10247, Training Loss: 2.606e-01, Validation Loss: 6.438e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10248, Training Loss: 2.606e-01, Validation Loss: 6.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10249, Training Loss: 2.605e-01, Validation Loss: 6.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10250, Training Loss: 2.605e-01, Validation Loss: 6.437e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10251, Training Loss: 2.605e-01, Validation Loss: 6.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10252, Training Loss: 2.604e-01, Validation Loss: 6.437e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10253, Training Loss: 2.604e-01, Validation Loss: 6.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10254, Training Loss: 2.604e-01, Validation Loss: 6.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10255, Training Loss: 2.603e-01, Validation Loss: 6.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10256, Training Loss: 2.603e-01, Validation Loss: 6.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10257, Training Loss: 2.603e-01, Validation Loss: 6.436e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10258, Training Loss: 2.603e-01, Validation Loss: 6.436e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10259, Training Loss: 2.602e-01, Validation Loss: 6.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10260, Training Loss: 2.602e-01, Validation Loss: 6.435e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10261, Training Loss: 2.602e-01, Validation Loss: 6.435e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10262, Training Loss: 2.601e-01, Validation Loss: 6.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10263, Training Loss: 2.601e-01, Validation Loss: 6.435e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10264, Training Loss: 2.601e-01, Validation Loss: 6.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10265, Training Loss: 2.600e-01, Validation Loss: 6.434e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10266, Training Loss: 2.600e-01, Validation Loss: 6.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10267, Training Loss: 2.600e-01, Validation Loss: 6.434e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10268, Training Loss: 2.600e-01, Validation Loss: 6.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10269, Training Loss: 2.599e-01, Validation Loss: 6.433e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10270, Training Loss: 2.599e-01, Validation Loss: 6.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10271, Training Loss: 2.599e-01, Validation Loss: 6.433e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10272, Training Loss: 2.598e-01, Validation Loss: 6.433e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10273, Training Loss: 2.598e-01, Validation Loss: 6.433e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10274, Training Loss: 2.598e-01, Validation Loss: 6.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10275, Training Loss: 2.597e-01, Validation Loss: 6.432e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10276, Training Loss: 2.597e-01, Validation Loss: 6.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10277, Training Loss: 2.597e-01, Validation Loss: 6.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10278, Training Loss: 2.597e-01, Validation Loss: 6.432e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10279, Training Loss: 2.596e-01, Validation Loss: 6.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10280, Training Loss: 2.596e-01, Validation Loss: 6.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10281, Training Loss: 2.596e-01, Validation Loss: 6.431e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10282, Training Loss: 2.595e-01, Validation Loss: 6.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10283, Training Loss: 2.595e-01, Validation Loss: 6.431e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10284, Training Loss: 2.595e-01, Validation Loss: 6.431e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10285, Training Loss: 2.594e-01, Validation Loss: 6.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10286, Training Loss: 2.594e-01, Validation Loss: 6.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10287, Training Loss: 2.594e-01, Validation Loss: 6.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10288, Training Loss: 2.593e-01, Validation Loss: 6.430e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10289, Training Loss: 2.593e-01, Validation Loss: 6.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10290, Training Loss: 2.593e-01, Validation Loss: 6.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10291, Training Loss: 2.593e-01, Validation Loss: 6.429e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10292, Training Loss: 2.592e-01, Validation Loss: 6.429e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10293, Training Loss: 2.592e-01, Validation Loss: 6.429e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10294, Training Loss: 2.592e-01, Validation Loss: 6.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10295, Training Loss: 2.591e-01, Validation Loss: 6.428e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10296, Training Loss: 2.591e-01, Validation Loss: 6.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10297, Training Loss: 2.591e-01, Validation Loss: 6.428e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10298, Training Loss: 2.590e-01, Validation Loss: 6.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10299, Training Loss: 2.590e-01, Validation Loss: 6.428e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10300, Training Loss: 2.590e-01, Validation Loss: 6.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10301, Training Loss: 2.590e-01, Validation Loss: 6.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10302, Training Loss: 2.589e-01, Validation Loss: 6.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10303, Training Loss: 2.589e-01, Validation Loss: 6.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10304, Training Loss: 2.589e-01, Validation Loss: 6.427e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10305, Training Loss: 2.588e-01, Validation Loss: 6.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10306, Training Loss: 2.588e-01, Validation Loss: 6.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10307, Training Loss: 2.588e-01, Validation Loss: 6.426e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10308, Training Loss: 2.587e-01, Validation Loss: 6.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10309, Training Loss: 2.587e-01, Validation Loss: 6.426e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10310, Training Loss: 2.587e-01, Validation Loss: 6.426e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10311, Training Loss: 2.587e-01, Validation Loss: 6.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10312, Training Loss: 2.586e-01, Validation Loss: 6.425e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10313, Training Loss: 2.586e-01, Validation Loss: 6.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10314, Training Loss: 2.586e-01, Validation Loss: 6.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10315, Training Loss: 2.585e-01, Validation Loss: 6.425e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10316, Training Loss: 2.585e-01, Validation Loss: 6.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10317, Training Loss: 2.585e-01, Validation Loss: 6.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10318, Training Loss: 2.584e-01, Validation Loss: 6.424e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10319, Training Loss: 2.584e-01, Validation Loss: 6.424e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10320, Training Loss: 2.584e-01, Validation Loss: 6.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10321, Training Loss: 2.584e-01, Validation Loss: 6.423e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10322, Training Loss: 2.583e-01, Validation Loss: 6.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10323, Training Loss: 2.583e-01, Validation Loss: 6.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10324, Training Loss: 2.583e-01, Validation Loss: 6.423e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10325, Training Loss: 2.582e-01, Validation Loss: 6.423e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10326, Training Loss: 2.582e-01, Validation Loss: 6.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10327, Training Loss: 2.582e-01, Validation Loss: 6.422e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10328, Training Loss: 2.581e-01, Validation Loss: 6.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10329, Training Loss: 2.581e-01, Validation Loss: 6.422e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10330, Training Loss: 2.581e-01, Validation Loss: 6.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10331, Training Loss: 2.581e-01, Validation Loss: 6.421e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10332, Training Loss: 2.580e-01, Validation Loss: 6.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10333, Training Loss: 2.580e-01, Validation Loss: 6.421e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10334, Training Loss: 2.580e-01, Validation Loss: 6.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10335, Training Loss: 2.579e-01, Validation Loss: 6.421e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10336, Training Loss: 2.579e-01, Validation Loss: 6.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10337, Training Loss: 2.579e-01, Validation Loss: 6.420e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10338, Training Loss: 2.579e-01, Validation Loss: 6.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10339, Training Loss: 2.578e-01, Validation Loss: 6.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10340, Training Loss: 2.578e-01, Validation Loss: 6.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10341, Training Loss: 2.578e-01, Validation Loss: 6.420e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10342, Training Loss: 2.577e-01, Validation Loss: 6.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10343, Training Loss: 2.577e-01, Validation Loss: 6.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10344, Training Loss: 2.577e-01, Validation Loss: 6.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10345, Training Loss: 2.576e-01, Validation Loss: 6.419e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10346, Training Loss: 2.576e-01, Validation Loss: 6.419e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10347, Training Loss: 2.576e-01, Validation Loss: 6.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10348, Training Loss: 2.576e-01, Validation Loss: 6.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10349, Training Loss: 2.575e-01, Validation Loss: 6.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10350, Training Loss: 2.575e-01, Validation Loss: 6.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10351, Training Loss: 2.575e-01, Validation Loss: 6.418e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10352, Training Loss: 2.574e-01, Validation Loss: 6.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10353, Training Loss: 2.574e-01, Validation Loss: 6.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10354, Training Loss: 2.574e-01, Validation Loss: 6.417e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10355, Training Loss: 2.573e-01, Validation Loss: 6.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10356, Training Loss: 2.573e-01, Validation Loss: 6.417e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10357, Training Loss: 2.573e-01, Validation Loss: 6.417e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10358, Training Loss: 2.573e-01, Validation Loss: 6.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10359, Training Loss: 2.572e-01, Validation Loss: 6.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10360, Training Loss: 2.572e-01, Validation Loss: 6.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10361, Training Loss: 2.572e-01, Validation Loss: 6.416e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10362, Training Loss: 2.571e-01, Validation Loss: 6.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10363, Training Loss: 2.571e-01, Validation Loss: 6.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10364, Training Loss: 2.571e-01, Validation Loss: 6.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10365, Training Loss: 2.570e-01, Validation Loss: 6.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10366, Training Loss: 2.570e-01, Validation Loss: 6.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10367, Training Loss: 2.570e-01, Validation Loss: 6.415e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10368, Training Loss: 2.570e-01, Validation Loss: 6.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10369, Training Loss: 2.569e-01, Validation Loss: 6.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10370, Training Loss: 2.569e-01, Validation Loss: 6.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10371, Training Loss: 2.569e-01, Validation Loss: 6.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10372, Training Loss: 2.568e-01, Validation Loss: 6.414e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10373, Training Loss: 2.568e-01, Validation Loss: 6.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10374, Training Loss: 2.568e-01, Validation Loss: 6.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10375, Training Loss: 2.568e-01, Validation Loss: 6.413e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10376, Training Loss: 2.567e-01, Validation Loss: 6.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10377, Training Loss: 2.567e-01, Validation Loss: 6.413e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10378, Training Loss: 2.567e-01, Validation Loss: 6.413e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10379, Training Loss: 2.566e-01, Validation Loss: 6.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10380, Training Loss: 2.566e-01, Validation Loss: 6.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10381, Training Loss: 2.566e-01, Validation Loss: 6.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10382, Training Loss: 2.565e-01, Validation Loss: 6.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10383, Training Loss: 2.565e-01, Validation Loss: 6.412e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10384, Training Loss: 2.565e-01, Validation Loss: 6.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10385, Training Loss: 2.565e-01, Validation Loss: 6.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10386, Training Loss: 2.564e-01, Validation Loss: 6.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10387, Training Loss: 2.564e-01, Validation Loss: 6.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10388, Training Loss: 2.564e-01, Validation Loss: 6.411e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10389, Training Loss: 2.563e-01, Validation Loss: 6.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10390, Training Loss: 2.563e-01, Validation Loss: 6.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10391, Training Loss: 2.563e-01, Validation Loss: 6.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10392, Training Loss: 2.562e-01, Validation Loss: 6.410e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10393, Training Loss: 2.562e-01, Validation Loss: 6.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10394, Training Loss: 2.562e-01, Validation Loss: 6.410e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10395, Training Loss: 2.562e-01, Validation Loss: 6.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10396, Training Loss: 2.561e-01, Validation Loss: 6.409e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10397, Training Loss: 2.561e-01, Validation Loss: 6.409e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10398, Training Loss: 2.561e-01, Validation Loss: 6.409e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10399, Training Loss: 2.560e-01, Validation Loss: 6.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10400, Training Loss: 2.560e-01, Validation Loss: 6.409e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10401, Training Loss: 2.560e-01, Validation Loss: 6.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10402, Training Loss: 2.560e-01, Validation Loss: 6.408e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10403, Training Loss: 2.559e-01, Validation Loss: 6.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10404, Training Loss: 2.559e-01, Validation Loss: 6.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10405, Training Loss: 2.559e-01, Validation Loss: 6.408e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10406, Training Loss: 2.558e-01, Validation Loss: 6.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10407, Training Loss: 2.558e-01, Validation Loss: 6.407e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10408, Training Loss: 2.558e-01, Validation Loss: 6.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10409, Training Loss: 2.557e-01, Validation Loss: 6.407e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10410, Training Loss: 2.557e-01, Validation Loss: 6.407e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10411, Training Loss: 2.557e-01, Validation Loss: 6.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10412, Training Loss: 2.557e-01, Validation Loss: 6.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10413, Training Loss: 2.556e-01, Validation Loss: 6.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10414, Training Loss: 2.556e-01, Validation Loss: 6.406e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10415, Training Loss: 2.556e-01, Validation Loss: 6.406e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10416, Training Loss: 2.555e-01, Validation Loss: 6.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10417, Training Loss: 2.555e-01, Validation Loss: 6.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10418, Training Loss: 2.555e-01, Validation Loss: 6.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10419, Training Loss: 2.555e-01, Validation Loss: 6.405e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10420, Training Loss: 2.554e-01, Validation Loss: 6.405e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10421, Training Loss: 2.554e-01, Validation Loss: 6.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10422, Training Loss: 2.554e-01, Validation Loss: 6.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10423, Training Loss: 2.553e-01, Validation Loss: 6.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10424, Training Loss: 2.553e-01, Validation Loss: 6.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10425, Training Loss: 2.553e-01, Validation Loss: 6.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10426, Training Loss: 2.552e-01, Validation Loss: 6.404e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10427, Training Loss: 2.552e-01, Validation Loss: 6.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10428, Training Loss: 2.552e-01, Validation Loss: 6.403e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10429, Training Loss: 2.552e-01, Validation Loss: 6.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10430, Training Loss: 2.551e-01, Validation Loss: 6.403e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10431, Training Loss: 2.551e-01, Validation Loss: 6.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10432, Training Loss: 2.551e-01, Validation Loss: 6.402e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10433, Training Loss: 2.550e-01, Validation Loss: 6.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10434, Training Loss: 2.550e-01, Validation Loss: 6.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10435, Training Loss: 2.550e-01, Validation Loss: 6.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10436, Training Loss: 2.550e-01, Validation Loss: 6.402e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10437, Training Loss: 2.549e-01, Validation Loss: 6.402e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10438, Training Loss: 2.549e-01, Validation Loss: 6.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10439, Training Loss: 2.549e-01, Validation Loss: 6.401e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10440, Training Loss: 2.548e-01, Validation Loss: 6.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10441, Training Loss: 2.548e-01, Validation Loss: 6.401e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10442, Training Loss: 2.548e-01, Validation Loss: 6.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10443, Training Loss: 2.547e-01, Validation Loss: 6.401e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10444, Training Loss: 2.547e-01, Validation Loss: 6.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10445, Training Loss: 2.547e-01, Validation Loss: 6.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10446, Training Loss: 2.547e-01, Validation Loss: 6.400e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10447, Training Loss: 2.546e-01, Validation Loss: 6.400e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10448, Training Loss: 2.546e-01, Validation Loss: 6.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10449, Training Loss: 2.546e-01, Validation Loss: 6.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10450, Training Loss: 2.545e-01, Validation Loss: 6.399e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10451, Training Loss: 2.545e-01, Validation Loss: 6.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10452, Training Loss: 2.545e-01, Validation Loss: 6.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10453, Training Loss: 2.545e-01, Validation Loss: 6.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10454, Training Loss: 2.544e-01, Validation Loss: 6.399e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10455, Training Loss: 2.544e-01, Validation Loss: 6.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10456, Training Loss: 2.544e-01, Validation Loss: 6.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10457, Training Loss: 2.543e-01, Validation Loss: 6.398e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10458, Training Loss: 2.543e-01, Validation Loss: 6.398e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10459, Training Loss: 2.543e-01, Validation Loss: 6.398e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10460, Training Loss: 2.542e-01, Validation Loss: 6.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10461, Training Loss: 2.542e-01, Validation Loss: 6.397e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10462, Training Loss: 2.542e-01, Validation Loss: 6.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10463, Training Loss: 2.542e-01, Validation Loss: 6.397e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10464, Training Loss: 2.541e-01, Validation Loss: 6.397e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10465, Training Loss: 2.541e-01, Validation Loss: 6.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10466, Training Loss: 2.541e-01, Validation Loss: 6.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10467, Training Loss: 2.540e-01, Validation Loss: 6.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10468, Training Loss: 2.540e-01, Validation Loss: 6.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10469, Training Loss: 2.540e-01, Validation Loss: 6.396e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10470, Training Loss: 2.540e-01, Validation Loss: 6.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10471, Training Loss: 2.539e-01, Validation Loss: 6.395e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10472, Training Loss: 2.539e-01, Validation Loss: 6.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10473, Training Loss: 2.539e-01, Validation Loss: 6.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10474, Training Loss: 2.538e-01, Validation Loss: 6.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10475, Training Loss: 2.538e-01, Validation Loss: 6.395e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10476, Training Loss: 2.538e-01, Validation Loss: 6.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10477, Training Loss: 2.538e-01, Validation Loss: 6.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10478, Training Loss: 2.537e-01, Validation Loss: 6.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10479, Training Loss: 2.537e-01, Validation Loss: 6.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10480, Training Loss: 2.537e-01, Validation Loss: 6.394e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10481, Training Loss: 2.536e-01, Validation Loss: 6.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10482, Training Loss: 2.536e-01, Validation Loss: 6.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10483, Training Loss: 2.536e-01, Validation Loss: 6.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10484, Training Loss: 2.535e-01, Validation Loss: 6.393e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10485, Training Loss: 2.535e-01, Validation Loss: 6.393e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10486, Training Loss: 2.535e-01, Validation Loss: 6.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10487, Training Loss: 2.535e-01, Validation Loss: 6.392e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10488, Training Loss: 2.534e-01, Validation Loss: 6.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10489, Training Loss: 2.534e-01, Validation Loss: 6.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10490, Training Loss: 2.534e-01, Validation Loss: 6.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10491, Training Loss: 2.533e-01, Validation Loss: 6.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10492, Training Loss: 2.533e-01, Validation Loss: 6.392e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10493, Training Loss: 2.533e-01, Validation Loss: 6.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10494, Training Loss: 2.533e-01, Validation Loss: 6.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10495, Training Loss: 2.532e-01, Validation Loss: 6.391e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10496, Training Loss: 2.532e-01, Validation Loss: 6.391e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10497, Training Loss: 2.532e-01, Validation Loss: 6.391e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10498, Training Loss: 2.531e-01, Validation Loss: 6.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10499, Training Loss: 2.531e-01, Validation Loss: 6.390e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10500, Training Loss: 2.531e-01, Validation Loss: 6.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10501, Training Loss: 2.531e-01, Validation Loss: 6.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10502, Training Loss: 2.530e-01, Validation Loss: 6.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10503, Training Loss: 2.530e-01, Validation Loss: 6.390e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10504, Training Loss: 2.530e-01, Validation Loss: 6.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10505, Training Loss: 2.529e-01, Validation Loss: 6.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10506, Training Loss: 2.529e-01, Validation Loss: 6.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10507, Training Loss: 2.529e-01, Validation Loss: 6.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10508, Training Loss: 2.529e-01, Validation Loss: 6.389e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10509, Training Loss: 2.528e-01, Validation Loss: 6.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10510, Training Loss: 2.528e-01, Validation Loss: 6.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10511, Training Loss: 2.528e-01, Validation Loss: 6.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10512, Training Loss: 2.527e-01, Validation Loss: 6.388e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10513, Training Loss: 2.527e-01, Validation Loss: 6.388e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10514, Training Loss: 2.527e-01, Validation Loss: 6.388e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10515, Training Loss: 2.526e-01, Validation Loss: 6.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10516, Training Loss: 2.526e-01, Validation Loss: 6.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10517, Training Loss: 2.526e-01, Validation Loss: 6.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10518, Training Loss: 2.526e-01, Validation Loss: 6.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10519, Training Loss: 2.525e-01, Validation Loss: 6.387e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10520, Training Loss: 2.525e-01, Validation Loss: 6.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10521, Training Loss: 2.525e-01, Validation Loss: 6.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10522, Training Loss: 2.524e-01, Validation Loss: 6.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10523, Training Loss: 2.524e-01, Validation Loss: 6.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10524, Training Loss: 2.524e-01, Validation Loss: 6.386e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10525, Training Loss: 2.524e-01, Validation Loss: 6.386e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10526, Training Loss: 2.523e-01, Validation Loss: 6.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10527, Training Loss: 2.523e-01, Validation Loss: 6.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10528, Training Loss: 2.523e-01, Validation Loss: 6.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10529, Training Loss: 2.522e-01, Validation Loss: 6.385e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10530, Training Loss: 2.522e-01, Validation Loss: 6.385e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10531, Training Loss: 2.522e-01, Validation Loss: 6.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10532, Training Loss: 2.522e-01, Validation Loss: 6.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10533, Training Loss: 2.521e-01, Validation Loss: 6.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10534, Training Loss: 2.521e-01, Validation Loss: 6.384e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10535, Training Loss: 2.521e-01, Validation Loss: 6.384e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10536, Training Loss: 2.520e-01, Validation Loss: 6.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10537, Training Loss: 2.520e-01, Validation Loss: 6.383e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10538, Training Loss: 2.520e-01, Validation Loss: 6.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10539, Training Loss: 2.520e-01, Validation Loss: 6.383e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10540, Training Loss: 2.519e-01, Validation Loss: 6.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10541, Training Loss: 2.519e-01, Validation Loss: 6.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10542, Training Loss: 2.519e-01, Validation Loss: 6.383e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10543, Training Loss: 2.518e-01, Validation Loss: 6.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10544, Training Loss: 2.518e-01, Validation Loss: 6.382e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10545, Training Loss: 2.518e-01, Validation Loss: 6.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10546, Training Loss: 2.518e-01, Validation Loss: 6.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10547, Training Loss: 2.517e-01, Validation Loss: 6.382e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10548, Training Loss: 2.517e-01, Validation Loss: 6.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10549, Training Loss: 2.517e-01, Validation Loss: 6.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10550, Training Loss: 2.516e-01, Validation Loss: 6.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10551, Training Loss: 2.516e-01, Validation Loss: 6.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10552, Training Loss: 2.516e-01, Validation Loss: 6.381e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10553, Training Loss: 2.516e-01, Validation Loss: 6.381e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10554, Training Loss: 2.515e-01, Validation Loss: 6.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10555, Training Loss: 2.515e-01, Validation Loss: 6.380e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10556, Training Loss: 2.515e-01, Validation Loss: 6.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10557, Training Loss: 2.514e-01, Validation Loss: 6.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10558, Training Loss: 2.514e-01, Validation Loss: 6.380e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10559, Training Loss: 2.514e-01, Validation Loss: 6.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10560, Training Loss: 2.514e-01, Validation Loss: 6.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10561, Training Loss: 2.513e-01, Validation Loss: 6.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10562, Training Loss: 2.513e-01, Validation Loss: 6.379e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10563, Training Loss: 2.513e-01, Validation Loss: 6.379e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10564, Training Loss: 2.512e-01, Validation Loss: 6.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10565, Training Loss: 2.512e-01, Validation Loss: 6.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10566, Training Loss: 2.512e-01, Validation Loss: 6.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10567, Training Loss: 2.511e-01, Validation Loss: 6.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10568, Training Loss: 2.511e-01, Validation Loss: 6.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10569, Training Loss: 2.511e-01, Validation Loss: 6.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10570, Training Loss: 2.511e-01, Validation Loss: 6.378e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10571, Training Loss: 2.510e-01, Validation Loss: 6.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10572, Training Loss: 2.510e-01, Validation Loss: 6.377e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10573, Training Loss: 2.510e-01, Validation Loss: 6.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10574, Training Loss: 2.509e-01, Validation Loss: 6.377e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10575, Training Loss: 2.509e-01, Validation Loss: 6.377e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10576, Training Loss: 2.509e-01, Validation Loss: 6.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10577, Training Loss: 2.509e-01, Validation Loss: 6.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10578, Training Loss: 2.508e-01, Validation Loss: 6.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10579, Training Loss: 2.508e-01, Validation Loss: 6.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10580, Training Loss: 2.508e-01, Validation Loss: 6.376e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10581, Training Loss: 2.507e-01, Validation Loss: 6.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10582, Training Loss: 2.507e-01, Validation Loss: 6.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10583, Training Loss: 2.507e-01, Validation Loss: 6.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10584, Training Loss: 2.507e-01, Validation Loss: 6.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10585, Training Loss: 2.506e-01, Validation Loss: 6.375e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10586, Training Loss: 2.506e-01, Validation Loss: 6.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10587, Training Loss: 2.506e-01, Validation Loss: 6.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10588, Training Loss: 2.505e-01, Validation Loss: 6.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10589, Training Loss: 2.505e-01, Validation Loss: 6.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10590, Training Loss: 2.505e-01, Validation Loss: 6.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10591, Training Loss: 2.505e-01, Validation Loss: 6.374e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10592, Training Loss: 2.504e-01, Validation Loss: 6.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10593, Training Loss: 2.504e-01, Validation Loss: 6.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10594, Training Loss: 2.504e-01, Validation Loss: 6.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10595, Training Loss: 2.503e-01, Validation Loss: 6.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10596, Training Loss: 2.503e-01, Validation Loss: 6.373e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10597, Training Loss: 2.503e-01, Validation Loss: 6.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10598, Training Loss: 2.503e-01, Validation Loss: 6.372e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10599, Training Loss: 2.502e-01, Validation Loss: 6.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10600, Training Loss: 2.502e-01, Validation Loss: 6.372e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10601, Training Loss: 2.502e-01, Validation Loss: 6.372e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10602, Training Loss: 2.501e-01, Validation Loss: 6.372e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10603, Training Loss: 2.501e-01, Validation Loss: 6.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10604, Training Loss: 2.501e-01, Validation Loss: 6.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10605, Training Loss: 2.501e-01, Validation Loss: 6.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10606, Training Loss: 2.500e-01, Validation Loss: 6.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10607, Training Loss: 2.500e-01, Validation Loss: 6.371e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10608, Training Loss: 2.500e-01, Validation Loss: 6.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10609, Training Loss: 2.499e-01, Validation Loss: 6.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10610, Training Loss: 2.499e-01, Validation Loss: 6.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10611, Training Loss: 2.499e-01, Validation Loss: 6.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10612, Training Loss: 2.499e-01, Validation Loss: 6.370e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10613, Training Loss: 2.498e-01, Validation Loss: 6.370e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10614, Training Loss: 2.498e-01, Validation Loss: 6.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10615, Training Loss: 2.498e-01, Validation Loss: 6.369e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10616, Training Loss: 2.497e-01, Validation Loss: 6.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10617, Training Loss: 2.497e-01, Validation Loss: 6.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10618, Training Loss: 2.497e-01, Validation Loss: 6.369e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10619, Training Loss: 2.497e-01, Validation Loss: 6.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10620, Training Loss: 2.496e-01, Validation Loss: 6.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10621, Training Loss: 2.496e-01, Validation Loss: 6.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10622, Training Loss: 2.496e-01, Validation Loss: 6.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10623, Training Loss: 2.495e-01, Validation Loss: 6.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10624, Training Loss: 2.495e-01, Validation Loss: 6.368e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10625, Training Loss: 2.495e-01, Validation Loss: 6.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10626, Training Loss: 2.495e-01, Validation Loss: 6.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10627, Training Loss: 2.494e-01, Validation Loss: 6.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10628, Training Loss: 2.494e-01, Validation Loss: 6.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10629, Training Loss: 2.494e-01, Validation Loss: 6.367e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10630, Training Loss: 2.494e-01, Validation Loss: 6.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10631, Training Loss: 2.493e-01, Validation Loss: 6.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10632, Training Loss: 2.493e-01, Validation Loss: 6.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10633, Training Loss: 2.493e-01, Validation Loss: 6.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10634, Training Loss: 2.492e-01, Validation Loss: 6.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10635, Training Loss: 2.492e-01, Validation Loss: 6.366e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10636, Training Loss: 2.492e-01, Validation Loss: 6.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10637, Training Loss: 2.492e-01, Validation Loss: 6.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10638, Training Loss: 2.491e-01, Validation Loss: 6.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10639, Training Loss: 2.491e-01, Validation Loss: 6.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10640, Training Loss: 2.491e-01, Validation Loss: 6.365e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10641, Training Loss: 2.490e-01, Validation Loss: 6.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10642, Training Loss: 2.490e-01, Validation Loss: 6.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10643, Training Loss: 2.490e-01, Validation Loss: 6.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10644, Training Loss: 2.490e-01, Validation Loss: 6.364e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10645, Training Loss: 2.489e-01, Validation Loss: 6.364e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10646, Training Loss: 2.489e-01, Validation Loss: 6.364e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 10647, Training Loss: 2.489e-01, Validation Loss: 6.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10648, Training Loss: 2.488e-01, Validation Loss: 6.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10649, Training Loss: 2.488e-01, Validation Loss: 6.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10650, Training Loss: 2.488e-01, Validation Loss: 6.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10651, Training Loss: 2.488e-01, Validation Loss: 6.363e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10652, Training Loss: 2.487e-01, Validation Loss: 6.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10653, Training Loss: 2.487e-01, Validation Loss: 6.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10654, Training Loss: 2.487e-01, Validation Loss: 6.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10655, Training Loss: 2.486e-01, Validation Loss: 6.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10656, Training Loss: 2.486e-01, Validation Loss: 6.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10657, Training Loss: 2.486e-01, Validation Loss: 6.362e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10658, Training Loss: 2.486e-01, Validation Loss: 6.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10659, Training Loss: 2.485e-01, Validation Loss: 6.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10660, Training Loss: 2.485e-01, Validation Loss: 6.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10661, Training Loss: 2.485e-01, Validation Loss: 6.361e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10662, Training Loss: 2.484e-01, Validation Loss: 6.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10663, Training Loss: 2.484e-01, Validation Loss: 6.361e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10664, Training Loss: 2.484e-01, Validation Loss: 6.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10665, Training Loss: 2.484e-01, Validation Loss: 6.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10666, Training Loss: 2.483e-01, Validation Loss: 6.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10667, Training Loss: 2.483e-01, Validation Loss: 6.360e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10668, Training Loss: 2.483e-01, Validation Loss: 6.360e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10669, Training Loss: 2.482e-01, Validation Loss: 6.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10670, Training Loss: 2.482e-01, Validation Loss: 6.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10671, Training Loss: 2.482e-01, Validation Loss: 6.359e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10672, Training Loss: 2.482e-01, Validation Loss: 6.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10673, Training Loss: 2.481e-01, Validation Loss: 6.359e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10674, Training Loss: 2.481e-01, Validation Loss: 6.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10675, Training Loss: 2.481e-01, Validation Loss: 6.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10676, Training Loss: 2.480e-01, Validation Loss: 6.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10677, Training Loss: 2.480e-01, Validation Loss: 6.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10678, Training Loss: 2.480e-01, Validation Loss: 6.358e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10679, Training Loss: 2.480e-01, Validation Loss: 6.358e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10680, Training Loss: 2.479e-01, Validation Loss: 6.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10681, Training Loss: 2.479e-01, Validation Loss: 6.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10682, Training Loss: 2.479e-01, Validation Loss: 6.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10683, Training Loss: 2.479e-01, Validation Loss: 6.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10684, Training Loss: 2.478e-01, Validation Loss: 6.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10685, Training Loss: 2.478e-01, Validation Loss: 6.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10686, Training Loss: 2.478e-01, Validation Loss: 6.357e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10687, Training Loss: 2.477e-01, Validation Loss: 6.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10688, Training Loss: 2.477e-01, Validation Loss: 6.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10689, Training Loss: 2.477e-01, Validation Loss: 6.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10690, Training Loss: 2.477e-01, Validation Loss: 6.356e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10691, Training Loss: 2.476e-01, Validation Loss: 6.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10692, Training Loss: 2.476e-01, Validation Loss: 6.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10693, Training Loss: 2.476e-01, Validation Loss: 6.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10694, Training Loss: 2.475e-01, Validation Loss: 6.355e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10695, Training Loss: 2.475e-01, Validation Loss: 6.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10696, Training Loss: 2.475e-01, Validation Loss: 6.355e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10697, Training Loss: 2.475e-01, Validation Loss: 6.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10698, Training Loss: 2.474e-01, Validation Loss: 6.354e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10699, Training Loss: 2.474e-01, Validation Loss: 6.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10700, Training Loss: 2.474e-01, Validation Loss: 6.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10701, Training Loss: 2.473e-01, Validation Loss: 6.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10702, Training Loss: 2.473e-01, Validation Loss: 6.354e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10703, Training Loss: 2.473e-01, Validation Loss: 6.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10704, Training Loss: 2.473e-01, Validation Loss: 6.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10705, Training Loss: 2.472e-01, Validation Loss: 6.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10706, Training Loss: 2.472e-01, Validation Loss: 6.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10707, Training Loss: 2.472e-01, Validation Loss: 6.353e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10708, Training Loss: 2.471e-01, Validation Loss: 6.353e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10709, Training Loss: 2.471e-01, Validation Loss: 6.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10710, Training Loss: 2.471e-01, Validation Loss: 6.352e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10711, Training Loss: 2.471e-01, Validation Loss: 6.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10712, Training Loss: 2.470e-01, Validation Loss: 6.352e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10713, Training Loss: 2.470e-01, Validation Loss: 6.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10714, Training Loss: 2.470e-01, Validation Loss: 6.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10715, Training Loss: 2.470e-01, Validation Loss: 6.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10716, Training Loss: 2.469e-01, Validation Loss: 6.351e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10717, Training Loss: 2.469e-01, Validation Loss: 6.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10718, Training Loss: 2.469e-01, Validation Loss: 6.351e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10719, Training Loss: 2.468e-01, Validation Loss: 6.351e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10720, Training Loss: 2.468e-01, Validation Loss: 6.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10721, Training Loss: 2.468e-01, Validation Loss: 6.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10722, Training Loss: 2.468e-01, Validation Loss: 6.350e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10723, Training Loss: 2.467e-01, Validation Loss: 6.350e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10724, Training Loss: 2.467e-01, Validation Loss: 6.350e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 10725, Training Loss: 2.467e-01, Validation Loss: 6.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10726, Training Loss: 2.466e-01, Validation Loss: 6.349e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10727, Training Loss: 2.466e-01, Validation Loss: 6.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10728, Training Loss: 2.466e-01, Validation Loss: 6.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10729, Training Loss: 2.466e-01, Validation Loss: 6.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10730, Training Loss: 2.465e-01, Validation Loss: 6.349e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10731, Training Loss: 2.465e-01, Validation Loss: 6.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10732, Training Loss: 2.465e-01, Validation Loss: 6.348e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10733, Training Loss: 2.465e-01, Validation Loss: 6.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10734, Training Loss: 2.464e-01, Validation Loss: 6.348e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10735, Training Loss: 2.464e-01, Validation Loss: 6.348e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10736, Training Loss: 2.464e-01, Validation Loss: 6.348e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10737, Training Loss: 2.463e-01, Validation Loss: 6.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10738, Training Loss: 2.463e-01, Validation Loss: 6.347e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10739, Training Loss: 2.463e-01, Validation Loss: 6.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10740, Training Loss: 2.463e-01, Validation Loss: 6.347e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10741, Training Loss: 2.462e-01, Validation Loss: 6.347e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10742, Training Loss: 2.462e-01, Validation Loss: 6.347e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10743, Training Loss: 2.462e-01, Validation Loss: 6.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10744, Training Loss: 2.461e-01, Validation Loss: 6.346e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10745, Training Loss: 2.461e-01, Validation Loss: 6.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10746, Training Loss: 2.461e-01, Validation Loss: 6.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10747, Training Loss: 2.461e-01, Validation Loss: 6.346e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10748, Training Loss: 2.460e-01, Validation Loss: 6.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10749, Training Loss: 2.460e-01, Validation Loss: 6.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10750, Training Loss: 2.460e-01, Validation Loss: 6.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10751, Training Loss: 2.459e-01, Validation Loss: 6.345e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10752, Training Loss: 2.459e-01, Validation Loss: 6.345e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10753, Training Loss: 2.459e-01, Validation Loss: 6.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10754, Training Loss: 2.459e-01, Validation Loss: 6.344e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10755, Training Loss: 2.458e-01, Validation Loss: 6.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10756, Training Loss: 2.458e-01, Validation Loss: 6.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10757, Training Loss: 2.458e-01, Validation Loss: 6.344e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10758, Training Loss: 2.458e-01, Validation Loss: 6.344e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10759, Training Loss: 2.457e-01, Validation Loss: 6.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10760, Training Loss: 2.457e-01, Validation Loss: 6.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10761, Training Loss: 2.457e-01, Validation Loss: 6.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10762, Training Loss: 2.456e-01, Validation Loss: 6.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10763, Training Loss: 2.456e-01, Validation Loss: 6.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10764, Training Loss: 2.456e-01, Validation Loss: 6.343e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10765, Training Loss: 2.456e-01, Validation Loss: 6.343e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10766, Training Loss: 2.455e-01, Validation Loss: 6.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10767, Training Loss: 2.455e-01, Validation Loss: 6.342e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10768, Training Loss: 2.455e-01, Validation Loss: 6.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10769, Training Loss: 2.454e-01, Validation Loss: 6.342e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10770, Training Loss: 2.454e-01, Validation Loss: 6.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10771, Training Loss: 2.454e-01, Validation Loss: 6.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10772, Training Loss: 2.454e-01, Validation Loss: 6.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10773, Training Loss: 2.453e-01, Validation Loss: 6.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10774, Training Loss: 2.453e-01, Validation Loss: 6.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10775, Training Loss: 2.453e-01, Validation Loss: 6.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10776, Training Loss: 2.453e-01, Validation Loss: 6.341e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10777, Training Loss: 2.452e-01, Validation Loss: 6.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10778, Training Loss: 2.452e-01, Validation Loss: 6.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10779, Training Loss: 2.452e-01, Validation Loss: 6.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10780, Training Loss: 2.451e-01, Validation Loss: 6.340e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10781, Training Loss: 2.451e-01, Validation Loss: 6.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10782, Training Loss: 2.451e-01, Validation Loss: 6.340e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10783, Training Loss: 2.451e-01, Validation Loss: 6.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10784, Training Loss: 2.450e-01, Validation Loss: 6.339e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10785, Training Loss: 2.450e-01, Validation Loss: 6.339e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10786, Training Loss: 2.450e-01, Validation Loss: 6.339e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10787, Training Loss: 2.450e-01, Validation Loss: 6.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10788, Training Loss: 2.449e-01, Validation Loss: 6.339e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10789, Training Loss: 2.449e-01, Validation Loss: 6.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10790, Training Loss: 2.449e-01, Validation Loss: 6.338e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10791, Training Loss: 2.448e-01, Validation Loss: 6.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10792, Training Loss: 2.448e-01, Validation Loss: 6.338e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10793, Training Loss: 2.448e-01, Validation Loss: 6.338e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10794, Training Loss: 2.448e-01, Validation Loss: 6.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10795, Training Loss: 2.447e-01, Validation Loss: 6.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10796, Training Loss: 2.447e-01, Validation Loss: 6.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10797, Training Loss: 2.447e-01, Validation Loss: 6.337e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10798, Training Loss: 2.446e-01, Validation Loss: 6.337e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10799, Training Loss: 2.446e-01, Validation Loss: 6.337e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10800, Training Loss: 2.446e-01, Validation Loss: 6.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10801, Training Loss: 2.446e-01, Validation Loss: 6.336e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10802, Training Loss: 2.445e-01, Validation Loss: 6.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10803, Training Loss: 2.445e-01, Validation Loss: 6.336e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10804, Training Loss: 2.445e-01, Validation Loss: 6.336e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10805, Training Loss: 2.445e-01, Validation Loss: 6.336e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10806, Training Loss: 2.444e-01, Validation Loss: 6.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10807, Training Loss: 2.444e-01, Validation Loss: 6.335e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10808, Training Loss: 2.444e-01, Validation Loss: 6.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10809, Training Loss: 2.443e-01, Validation Loss: 6.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10810, Training Loss: 2.443e-01, Validation Loss: 6.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10811, Training Loss: 2.443e-01, Validation Loss: 6.335e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10812, Training Loss: 2.443e-01, Validation Loss: 6.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10813, Training Loss: 2.442e-01, Validation Loss: 6.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10814, Training Loss: 2.442e-01, Validation Loss: 6.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10815, Training Loss: 2.442e-01, Validation Loss: 6.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10816, Training Loss: 2.442e-01, Validation Loss: 6.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10817, Training Loss: 2.441e-01, Validation Loss: 6.334e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10818, Training Loss: 2.441e-01, Validation Loss: 6.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10819, Training Loss: 2.441e-01, Validation Loss: 6.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10820, Training Loss: 2.440e-01, Validation Loss: 6.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10821, Training Loss: 2.440e-01, Validation Loss: 6.333e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10822, Training Loss: 2.440e-01, Validation Loss: 6.333e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10823, Training Loss: 2.440e-01, Validation Loss: 6.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10824, Training Loss: 2.439e-01, Validation Loss: 6.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10825, Training Loss: 2.439e-01, Validation Loss: 6.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10826, Training Loss: 2.439e-01, Validation Loss: 6.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10827, Training Loss: 2.438e-01, Validation Loss: 6.332e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10828, Training Loss: 2.438e-01, Validation Loss: 6.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10829, Training Loss: 2.438e-01, Validation Loss: 6.332e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10830, Training Loss: 2.438e-01, Validation Loss: 6.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10831, Training Loss: 2.437e-01, Validation Loss: 6.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10832, Training Loss: 2.437e-01, Validation Loss: 6.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10833, Training Loss: 2.437e-01, Validation Loss: 6.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10834, Training Loss: 2.437e-01, Validation Loss: 6.331e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10835, Training Loss: 2.436e-01, Validation Loss: 6.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10836, Training Loss: 2.436e-01, Validation Loss: 6.330e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10837, Training Loss: 2.436e-01, Validation Loss: 6.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10838, Training Loss: 2.435e-01, Validation Loss: 6.330e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10839, Training Loss: 2.435e-01, Validation Loss: 6.330e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10840, Training Loss: 2.435e-01, Validation Loss: 6.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10841, Training Loss: 2.435e-01, Validation Loss: 6.330e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10842, Training Loss: 2.434e-01, Validation Loss: 6.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10843, Training Loss: 2.434e-01, Validation Loss: 6.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10844, Training Loss: 2.434e-01, Validation Loss: 6.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10845, Training Loss: 2.434e-01, Validation Loss: 6.329e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10846, Training Loss: 2.433e-01, Validation Loss: 6.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10847, Training Loss: 2.433e-01, Validation Loss: 6.329e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10848, Training Loss: 2.433e-01, Validation Loss: 6.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10849, Training Loss: 2.432e-01, Validation Loss: 6.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10850, Training Loss: 2.432e-01, Validation Loss: 6.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10851, Training Loss: 2.432e-01, Validation Loss: 6.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10852, Training Loss: 2.432e-01, Validation Loss: 6.328e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10853, Training Loss: 2.431e-01, Validation Loss: 6.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10854, Training Loss: 2.431e-01, Validation Loss: 6.327e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10855, Training Loss: 2.431e-01, Validation Loss: 6.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10856, Training Loss: 2.431e-01, Validation Loss: 6.327e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10857, Training Loss: 2.430e-01, Validation Loss: 6.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10858, Training Loss: 2.430e-01, Validation Loss: 6.327e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10859, Training Loss: 2.430e-01, Validation Loss: 6.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10860, Training Loss: 2.429e-01, Validation Loss: 6.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10861, Training Loss: 2.429e-01, Validation Loss: 6.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10862, Training Loss: 2.429e-01, Validation Loss: 6.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10863, Training Loss: 2.429e-01, Validation Loss: 6.326e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10864, Training Loss: 2.428e-01, Validation Loss: 6.326e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10865, Training Loss: 2.428e-01, Validation Loss: 6.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10866, Training Loss: 2.428e-01, Validation Loss: 6.325e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10867, Training Loss: 2.428e-01, Validation Loss: 6.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10868, Training Loss: 2.427e-01, Validation Loss: 6.325e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10869, Training Loss: 2.427e-01, Validation Loss: 6.325e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10870, Training Loss: 2.427e-01, Validation Loss: 6.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10871, Training Loss: 2.426e-01, Validation Loss: 6.324e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10872, Training Loss: 2.426e-01, Validation Loss: 6.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10873, Training Loss: 2.426e-01, Validation Loss: 6.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10874, Training Loss: 2.426e-01, Validation Loss: 6.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10875, Training Loss: 2.425e-01, Validation Loss: 6.324e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10876, Training Loss: 2.425e-01, Validation Loss: 6.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10877, Training Loss: 2.425e-01, Validation Loss: 6.323e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10878, Training Loss: 2.425e-01, Validation Loss: 6.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10879, Training Loss: 2.424e-01, Validation Loss: 6.323e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10880, Training Loss: 2.424e-01, Validation Loss: 6.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10881, Training Loss: 2.424e-01, Validation Loss: 6.323e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10882, Training Loss: 2.423e-01, Validation Loss: 6.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10883, Training Loss: 2.423e-01, Validation Loss: 6.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10884, Training Loss: 2.423e-01, Validation Loss: 6.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10885, Training Loss: 2.423e-01, Validation Loss: 6.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10886, Training Loss: 2.422e-01, Validation Loss: 6.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10887, Training Loss: 2.422e-01, Validation Loss: 6.322e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10888, Training Loss: 2.422e-01, Validation Loss: 6.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10889, Training Loss: 2.422e-01, Validation Loss: 6.321e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10890, Training Loss: 2.421e-01, Validation Loss: 6.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10891, Training Loss: 2.421e-01, Validation Loss: 6.321e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10892, Training Loss: 2.421e-01, Validation Loss: 6.321e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10893, Training Loss: 2.420e-01, Validation Loss: 6.321e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10894, Training Loss: 2.420e-01, Validation Loss: 6.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10895, Training Loss: 2.420e-01, Validation Loss: 6.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10896, Training Loss: 2.420e-01, Validation Loss: 6.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10897, Training Loss: 2.419e-01, Validation Loss: 6.320e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10898, Training Loss: 2.419e-01, Validation Loss: 6.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10899, Training Loss: 2.419e-01, Validation Loss: 6.320e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10900, Training Loss: 2.419e-01, Validation Loss: 6.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10901, Training Loss: 2.418e-01, Validation Loss: 6.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10902, Training Loss: 2.418e-01, Validation Loss: 6.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10903, Training Loss: 2.418e-01, Validation Loss: 6.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10904, Training Loss: 2.417e-01, Validation Loss: 6.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10905, Training Loss: 2.417e-01, Validation Loss: 6.319e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10906, Training Loss: 2.417e-01, Validation Loss: 6.319e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10907, Training Loss: 2.417e-01, Validation Loss: 6.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10908, Training Loss: 2.416e-01, Validation Loss: 6.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10909, Training Loss: 2.416e-01, Validation Loss: 6.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10910, Training Loss: 2.416e-01, Validation Loss: 6.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10911, Training Loss: 2.416e-01, Validation Loss: 6.318e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10912, Training Loss: 2.415e-01, Validation Loss: 6.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10913, Training Loss: 2.415e-01, Validation Loss: 6.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10914, Training Loss: 2.415e-01, Validation Loss: 6.317e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10915, Training Loss: 2.414e-01, Validation Loss: 6.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10916, Training Loss: 2.414e-01, Validation Loss: 6.317e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10917, Training Loss: 2.414e-01, Validation Loss: 6.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10918, Training Loss: 2.414e-01, Validation Loss: 6.317e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10919, Training Loss: 2.413e-01, Validation Loss: 6.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10920, Training Loss: 2.413e-01, Validation Loss: 6.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10921, Training Loss: 2.413e-01, Validation Loss: 6.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10922, Training Loss: 2.413e-01, Validation Loss: 6.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10923, Training Loss: 2.412e-01, Validation Loss: 6.316e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10924, Training Loss: 2.412e-01, Validation Loss: 6.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10925, Training Loss: 2.412e-01, Validation Loss: 6.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10926, Training Loss: 2.412e-01, Validation Loss: 6.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10927, Training Loss: 2.411e-01, Validation Loss: 6.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10928, Training Loss: 2.411e-01, Validation Loss: 6.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10929, Training Loss: 2.411e-01, Validation Loss: 6.315e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10930, Training Loss: 2.410e-01, Validation Loss: 6.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10931, Training Loss: 2.410e-01, Validation Loss: 6.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10932, Training Loss: 2.410e-01, Validation Loss: 6.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10933, Training Loss: 2.410e-01, Validation Loss: 6.314e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10934, Training Loss: 2.409e-01, Validation Loss: 6.314e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10935, Training Loss: 2.409e-01, Validation Loss: 6.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10936, Training Loss: 2.409e-01, Validation Loss: 6.314e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10937, Training Loss: 2.409e-01, Validation Loss: 6.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10938, Training Loss: 2.408e-01, Validation Loss: 6.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10939, Training Loss: 2.408e-01, Validation Loss: 6.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10940, Training Loss: 2.408e-01, Validation Loss: 6.313e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10941, Training Loss: 2.407e-01, Validation Loss: 6.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10942, Training Loss: 2.407e-01, Validation Loss: 6.313e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10943, Training Loss: 2.407e-01, Validation Loss: 6.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10944, Training Loss: 2.407e-01, Validation Loss: 6.312e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10945, Training Loss: 2.406e-01, Validation Loss: 6.312e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10946, Training Loss: 2.406e-01, Validation Loss: 6.312e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10947, Training Loss: 2.406e-01, Validation Loss: 6.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10948, Training Loss: 2.406e-01, Validation Loss: 6.312e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10949, Training Loss: 2.405e-01, Validation Loss: 6.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10950, Training Loss: 2.405e-01, Validation Loss: 6.311e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10951, Training Loss: 2.405e-01, Validation Loss: 6.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10952, Training Loss: 2.405e-01, Validation Loss: 6.311e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10953, Training Loss: 2.404e-01, Validation Loss: 6.311e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10954, Training Loss: 2.404e-01, Validation Loss: 6.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10955, Training Loss: 2.404e-01, Validation Loss: 6.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10956, Training Loss: 2.403e-01, Validation Loss: 6.310e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10957, Training Loss: 2.403e-01, Validation Loss: 6.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10958, Training Loss: 2.403e-01, Validation Loss: 6.310e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10959, Training Loss: 2.403e-01, Validation Loss: 6.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10960, Training Loss: 2.402e-01, Validation Loss: 6.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10961, Training Loss: 2.402e-01, Validation Loss: 6.309e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10962, Training Loss: 2.402e-01, Validation Loss: 6.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10963, Training Loss: 2.402e-01, Validation Loss: 6.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10964, Training Loss: 2.401e-01, Validation Loss: 6.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10965, Training Loss: 2.401e-01, Validation Loss: 6.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10966, Training Loss: 2.401e-01, Validation Loss: 6.309e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10967, Training Loss: 2.400e-01, Validation Loss: 6.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10968, Training Loss: 2.400e-01, Validation Loss: 6.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10969, Training Loss: 2.400e-01, Validation Loss: 6.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10970, Training Loss: 2.400e-01, Validation Loss: 6.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10971, Training Loss: 2.399e-01, Validation Loss: 6.308e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10972, Training Loss: 2.399e-01, Validation Loss: 6.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10973, Training Loss: 2.399e-01, Validation Loss: 6.307e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10974, Training Loss: 2.399e-01, Validation Loss: 6.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10975, Training Loss: 2.398e-01, Validation Loss: 6.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10976, Training Loss: 2.398e-01, Validation Loss: 6.307e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10977, Training Loss: 2.398e-01, Validation Loss: 6.307e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10978, Training Loss: 2.398e-01, Validation Loss: 6.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10979, Training Loss: 2.397e-01, Validation Loss: 6.306e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10980, Training Loss: 2.397e-01, Validation Loss: 6.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10981, Training Loss: 2.397e-01, Validation Loss: 6.306e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10982, Training Loss: 2.396e-01, Validation Loss: 6.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10983, Training Loss: 2.396e-01, Validation Loss: 6.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10984, Training Loss: 2.396e-01, Validation Loss: 6.306e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10985, Training Loss: 2.396e-01, Validation Loss: 6.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10986, Training Loss: 2.395e-01, Validation Loss: 6.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10987, Training Loss: 2.395e-01, Validation Loss: 6.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10988, Training Loss: 2.395e-01, Validation Loss: 6.305e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10989, Training Loss: 2.395e-01, Validation Loss: 6.305e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10990, Training Loss: 2.394e-01, Validation Loss: 6.305e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10991, Training Loss: 2.394e-01, Validation Loss: 6.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10992, Training Loss: 2.394e-01, Validation Loss: 6.304e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10993, Training Loss: 2.394e-01, Validation Loss: 6.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10994, Training Loss: 2.393e-01, Validation Loss: 6.304e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10995, Training Loss: 2.393e-01, Validation Loss: 6.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10996, Training Loss: 2.393e-01, Validation Loss: 6.304e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10997, Training Loss: 2.392e-01, Validation Loss: 6.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 10998, Training Loss: 2.392e-01, Validation Loss: 6.303e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 10999, Training Loss: 2.392e-01, Validation Loss: 6.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11000, Training Loss: 2.392e-01, Validation Loss: 6.303e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11001, Training Loss: 2.391e-01, Validation Loss: 6.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11002, Training Loss: 2.391e-01, Validation Loss: 6.303e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11003, Training Loss: 2.391e-01, Validation Loss: 6.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11004, Training Loss: 2.391e-01, Validation Loss: 6.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11005, Training Loss: 2.390e-01, Validation Loss: 6.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11006, Training Loss: 2.390e-01, Validation Loss: 6.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11007, Training Loss: 2.390e-01, Validation Loss: 6.302e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11008, Training Loss: 2.390e-01, Validation Loss: 6.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11009, Training Loss: 2.389e-01, Validation Loss: 6.302e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11010, Training Loss: 2.389e-01, Validation Loss: 6.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11011, Training Loss: 2.389e-01, Validation Loss: 6.301e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11012, Training Loss: 2.388e-01, Validation Loss: 6.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11013, Training Loss: 2.388e-01, Validation Loss: 6.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11014, Training Loss: 2.388e-01, Validation Loss: 6.301e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11015, Training Loss: 2.388e-01, Validation Loss: 6.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11016, Training Loss: 2.387e-01, Validation Loss: 6.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11017, Training Loss: 2.387e-01, Validation Loss: 6.300e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11018, Training Loss: 2.387e-01, Validation Loss: 6.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11019, Training Loss: 2.387e-01, Validation Loss: 6.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11020, Training Loss: 2.386e-01, Validation Loss: 6.300e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11021, Training Loss: 2.386e-01, Validation Loss: 6.300e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11022, Training Loss: 2.386e-01, Validation Loss: 6.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11023, Training Loss: 2.386e-01, Validation Loss: 6.299e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11024, Training Loss: 2.385e-01, Validation Loss: 6.299e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11025, Training Loss: 2.385e-01, Validation Loss: 6.299e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11026, Training Loss: 2.385e-01, Validation Loss: 6.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11027, Training Loss: 2.384e-01, Validation Loss: 6.299e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11028, Training Loss: 2.384e-01, Validation Loss: 6.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11029, Training Loss: 2.384e-01, Validation Loss: 6.298e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11030, Training Loss: 2.384e-01, Validation Loss: 6.298e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11031, Training Loss: 2.383e-01, Validation Loss: 6.298e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11032, Training Loss: 2.383e-01, Validation Loss: 6.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11033, Training Loss: 2.383e-01, Validation Loss: 6.298e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11034, Training Loss: 2.383e-01, Validation Loss: 6.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11035, Training Loss: 2.382e-01, Validation Loss: 6.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11036, Training Loss: 2.382e-01, Validation Loss: 6.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11037, Training Loss: 2.382e-01, Validation Loss: 6.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11038, Training Loss: 2.382e-01, Validation Loss: 6.297e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11039, Training Loss: 2.381e-01, Validation Loss: 6.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11040, Training Loss: 2.381e-01, Validation Loss: 6.296e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11041, Training Loss: 2.381e-01, Validation Loss: 6.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11042, Training Loss: 2.380e-01, Validation Loss: 6.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11043, Training Loss: 2.380e-01, Validation Loss: 6.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11044, Training Loss: 2.380e-01, Validation Loss: 6.296e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11045, Training Loss: 2.380e-01, Validation Loss: 6.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11046, Training Loss: 2.379e-01, Validation Loss: 6.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11047, Training Loss: 2.379e-01, Validation Loss: 6.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11048, Training Loss: 2.379e-01, Validation Loss: 6.295e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11049, Training Loss: 2.379e-01, Validation Loss: 6.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11050, Training Loss: 2.378e-01, Validation Loss: 6.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11051, Training Loss: 2.378e-01, Validation Loss: 6.295e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11052, Training Loss: 2.378e-01, Validation Loss: 6.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11053, Training Loss: 2.378e-01, Validation Loss: 6.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11054, Training Loss: 2.377e-01, Validation Loss: 6.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11055, Training Loss: 2.377e-01, Validation Loss: 6.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11056, Training Loss: 2.377e-01, Validation Loss: 6.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11057, Training Loss: 2.376e-01, Validation Loss: 6.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11058, Training Loss: 2.376e-01, Validation Loss: 6.294e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11059, Training Loss: 2.376e-01, Validation Loss: 6.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11060, Training Loss: 2.376e-01, Validation Loss: 6.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11061, Training Loss: 2.375e-01, Validation Loss: 6.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11062, Training Loss: 2.375e-01, Validation Loss: 6.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11063, Training Loss: 2.375e-01, Validation Loss: 6.293e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11064, Training Loss: 2.375e-01, Validation Loss: 6.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11065, Training Loss: 2.374e-01, Validation Loss: 6.292e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11066, Training Loss: 2.374e-01, Validation Loss: 6.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11067, Training Loss: 2.374e-01, Validation Loss: 6.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11068, Training Loss: 2.374e-01, Validation Loss: 6.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11069, Training Loss: 2.373e-01, Validation Loss: 6.292e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11070, Training Loss: 2.373e-01, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11071, Training Loss: 2.373e-01, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11072, Training Loss: 2.373e-01, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11073, Training Loss: 2.372e-01, Validation Loss: 6.291e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11074, Training Loss: 2.372e-01, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11075, Training Loss: 2.372e-01, Validation Loss: 6.291e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11076, Training Loss: 2.371e-01, Validation Loss: 6.291e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11077, Training Loss: 2.371e-01, Validation Loss: 6.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11078, Training Loss: 2.371e-01, Validation Loss: 6.290e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11079, Training Loss: 2.371e-01, Validation Loss: 6.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11080, Training Loss: 2.370e-01, Validation Loss: 6.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11081, Training Loss: 2.370e-01, Validation Loss: 6.290e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11082, Training Loss: 2.370e-01, Validation Loss: 6.290e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11083, Training Loss: 2.370e-01, Validation Loss: 6.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11084, Training Loss: 2.369e-01, Validation Loss: 6.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11085, Training Loss: 2.369e-01, Validation Loss: 6.289e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11086, Training Loss: 2.369e-01, Validation Loss: 6.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11087, Training Loss: 2.369e-01, Validation Loss: 6.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11088, Training Loss: 2.368e-01, Validation Loss: 6.289e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11089, Training Loss: 2.368e-01, Validation Loss: 6.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11090, Training Loss: 2.368e-01, Validation Loss: 6.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11091, Training Loss: 2.368e-01, Validation Loss: 6.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11092, Training Loss: 2.367e-01, Validation Loss: 6.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11093, Training Loss: 2.367e-01, Validation Loss: 6.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11094, Training Loss: 2.367e-01, Validation Loss: 6.288e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11095, Training Loss: 2.366e-01, Validation Loss: 6.288e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11096, Training Loss: 2.366e-01, Validation Loss: 6.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11097, Training Loss: 2.366e-01, Validation Loss: 6.287e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11098, Training Loss: 2.366e-01, Validation Loss: 6.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11099, Training Loss: 2.365e-01, Validation Loss: 6.287e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11100, Training Loss: 2.365e-01, Validation Loss: 6.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11101, Training Loss: 2.365e-01, Validation Loss: 6.287e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11102, Training Loss: 2.365e-01, Validation Loss: 6.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11103, Training Loss: 2.364e-01, Validation Loss: 6.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11104, Training Loss: 2.364e-01, Validation Loss: 6.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11105, Training Loss: 2.364e-01, Validation Loss: 6.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11106, Training Loss: 2.364e-01, Validation Loss: 6.286e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11107, Training Loss: 2.363e-01, Validation Loss: 6.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11108, Training Loss: 2.363e-01, Validation Loss: 6.285e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11109, Training Loss: 2.363e-01, Validation Loss: 6.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11110, Training Loss: 2.363e-01, Validation Loss: 6.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11111, Training Loss: 2.362e-01, Validation Loss: 6.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11112, Training Loss: 2.362e-01, Validation Loss: 6.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11113, Training Loss: 2.362e-01, Validation Loss: 6.285e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11114, Training Loss: 2.361e-01, Validation Loss: 6.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11115, Training Loss: 2.361e-01, Validation Loss: 6.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11116, Training Loss: 2.361e-01, Validation Loss: 6.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11117, Training Loss: 2.361e-01, Validation Loss: 6.284e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11118, Training Loss: 2.360e-01, Validation Loss: 6.284e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11119, Training Loss: 2.360e-01, Validation Loss: 6.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11120, Training Loss: 2.360e-01, Validation Loss: 6.284e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11121, Training Loss: 2.360e-01, Validation Loss: 6.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11122, Training Loss: 2.359e-01, Validation Loss: 6.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11123, Training Loss: 2.359e-01, Validation Loss: 6.283e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11124, Training Loss: 2.359e-01, Validation Loss: 6.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11125, Training Loss: 2.359e-01, Validation Loss: 6.283e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11126, Training Loss: 2.358e-01, Validation Loss: 6.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11127, Training Loss: 2.358e-01, Validation Loss: 6.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11128, Training Loss: 2.358e-01, Validation Loss: 6.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11129, Training Loss: 2.358e-01, Validation Loss: 6.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11130, Training Loss: 2.357e-01, Validation Loss: 6.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11131, Training Loss: 2.357e-01, Validation Loss: 6.282e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11132, Training Loss: 2.357e-01, Validation Loss: 6.282e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11133, Training Loss: 2.357e-01, Validation Loss: 6.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11134, Training Loss: 2.356e-01, Validation Loss: 6.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11135, Training Loss: 2.356e-01, Validation Loss: 6.281e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11136, Training Loss: 2.356e-01, Validation Loss: 6.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11137, Training Loss: 2.355e-01, Validation Loss: 6.281e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11138, Training Loss: 2.355e-01, Validation Loss: 6.281e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11139, Training Loss: 2.355e-01, Validation Loss: 6.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11140, Training Loss: 2.355e-01, Validation Loss: 6.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11141, Training Loss: 2.354e-01, Validation Loss: 6.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11142, Training Loss: 2.354e-01, Validation Loss: 6.280e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11143, Training Loss: 2.354e-01, Validation Loss: 6.280e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11144, Training Loss: 2.354e-01, Validation Loss: 6.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11145, Training Loss: 2.353e-01, Validation Loss: 6.280e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11146, Training Loss: 2.353e-01, Validation Loss: 6.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11147, Training Loss: 2.353e-01, Validation Loss: 6.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11148, Training Loss: 2.353e-01, Validation Loss: 6.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11149, Training Loss: 2.352e-01, Validation Loss: 6.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11150, Training Loss: 2.352e-01, Validation Loss: 6.279e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11151, Training Loss: 2.352e-01, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11152, Training Loss: 2.352e-01, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11153, Training Loss: 2.351e-01, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11154, Training Loss: 2.351e-01, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11155, Training Loss: 2.351e-01, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11156, Training Loss: 2.351e-01, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11157, Training Loss: 2.350e-01, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11158, Training Loss: 2.350e-01, Validation Loss: 6.278e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11159, Training Loss: 2.350e-01, Validation Loss: 6.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11160, Training Loss: 2.349e-01, Validation Loss: 6.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11161, Training Loss: 2.349e-01, Validation Loss: 6.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11162, Training Loss: 2.349e-01, Validation Loss: 6.277e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11163, Training Loss: 2.349e-01, Validation Loss: 6.277e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11164, Training Loss: 2.348e-01, Validation Loss: 6.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11165, Training Loss: 2.348e-01, Validation Loss: 6.276e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11166, Training Loss: 2.348e-01, Validation Loss: 6.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11167, Training Loss: 2.348e-01, Validation Loss: 6.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11168, Training Loss: 2.347e-01, Validation Loss: 6.276e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11169, Training Loss: 2.347e-01, Validation Loss: 6.276e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11170, Training Loss: 2.347e-01, Validation Loss: 6.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11171, Training Loss: 2.347e-01, Validation Loss: 6.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11172, Training Loss: 2.346e-01, Validation Loss: 6.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11173, Training Loss: 2.346e-01, Validation Loss: 6.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11174, Training Loss: 2.346e-01, Validation Loss: 6.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11175, Training Loss: 2.346e-01, Validation Loss: 6.275e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11176, Training Loss: 2.345e-01, Validation Loss: 6.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11177, Training Loss: 2.345e-01, Validation Loss: 6.274e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11178, Training Loss: 2.345e-01, Validation Loss: 6.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11179, Training Loss: 2.345e-01, Validation Loss: 6.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11180, Training Loss: 2.344e-01, Validation Loss: 6.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11181, Training Loss: 2.344e-01, Validation Loss: 6.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11182, Training Loss: 2.344e-01, Validation Loss: 6.274e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11183, Training Loss: 2.344e-01, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11184, Training Loss: 2.343e-01, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11185, Training Loss: 2.343e-01, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11186, Training Loss: 2.343e-01, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11187, Training Loss: 2.342e-01, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11188, Training Loss: 2.342e-01, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11189, Training Loss: 2.342e-01, Validation Loss: 6.273e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11190, Training Loss: 2.342e-01, Validation Loss: 6.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11191, Training Loss: 2.341e-01, Validation Loss: 6.272e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11192, Training Loss: 2.341e-01, Validation Loss: 6.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11193, Training Loss: 2.341e-01, Validation Loss: 6.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11194, Training Loss: 2.341e-01, Validation Loss: 6.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11195, Training Loss: 2.340e-01, Validation Loss: 6.272e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11196, Training Loss: 2.340e-01, Validation Loss: 6.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11197, Training Loss: 2.340e-01, Validation Loss: 6.271e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11198, Training Loss: 2.340e-01, Validation Loss: 6.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11199, Training Loss: 2.339e-01, Validation Loss: 6.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11200, Training Loss: 2.339e-01, Validation Loss: 6.271e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11201, Training Loss: 2.339e-01, Validation Loss: 6.271e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11202, Training Loss: 2.339e-01, Validation Loss: 6.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11203, Training Loss: 2.338e-01, Validation Loss: 6.270e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11204, Training Loss: 2.338e-01, Validation Loss: 6.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11205, Training Loss: 2.338e-01, Validation Loss: 6.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11206, Training Loss: 2.338e-01, Validation Loss: 6.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11207, Training Loss: 2.337e-01, Validation Loss: 6.270e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11208, Training Loss: 2.337e-01, Validation Loss: 6.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11209, Training Loss: 2.337e-01, Validation Loss: 6.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11210, Training Loss: 2.337e-01, Validation Loss: 6.269e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11211, Training Loss: 2.336e-01, Validation Loss: 6.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11212, Training Loss: 2.336e-01, Validation Loss: 6.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11213, Training Loss: 2.336e-01, Validation Loss: 6.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11214, Training Loss: 2.336e-01, Validation Loss: 6.269e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11215, Training Loss: 2.335e-01, Validation Loss: 6.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11216, Training Loss: 2.335e-01, Validation Loss: 6.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11217, Training Loss: 2.335e-01, Validation Loss: 6.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11218, Training Loss: 2.334e-01, Validation Loss: 6.268e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11219, Training Loss: 2.334e-01, Validation Loss: 6.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11220, Training Loss: 2.334e-01, Validation Loss: 6.268e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11221, Training Loss: 2.334e-01, Validation Loss: 6.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11222, Training Loss: 2.333e-01, Validation Loss: 6.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11223, Training Loss: 2.333e-01, Validation Loss: 6.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11224, Training Loss: 2.333e-01, Validation Loss: 6.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11225, Training Loss: 2.333e-01, Validation Loss: 6.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11226, Training Loss: 2.332e-01, Validation Loss: 6.267e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11227, Training Loss: 2.332e-01, Validation Loss: 6.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11228, Training Loss: 2.332e-01, Validation Loss: 6.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11229, Training Loss: 2.332e-01, Validation Loss: 6.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11230, Training Loss: 2.331e-01, Validation Loss: 6.266e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11231, Training Loss: 2.331e-01, Validation Loss: 6.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11232, Training Loss: 2.331e-01, Validation Loss: 6.266e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11233, Training Loss: 2.331e-01, Validation Loss: 6.266e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11234, Training Loss: 2.330e-01, Validation Loss: 6.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11235, Training Loss: 2.330e-01, Validation Loss: 6.265e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11236, Training Loss: 2.330e-01, Validation Loss: 6.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11237, Training Loss: 2.330e-01, Validation Loss: 6.265e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11238, Training Loss: 2.329e-01, Validation Loss: 6.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11239, Training Loss: 2.329e-01, Validation Loss: 6.265e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11240, Training Loss: 2.329e-01, Validation Loss: 6.265e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11241, Training Loss: 2.329e-01, Validation Loss: 6.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11242, Training Loss: 2.328e-01, Validation Loss: 6.264e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11243, Training Loss: 2.328e-01, Validation Loss: 6.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11244, Training Loss: 2.328e-01, Validation Loss: 6.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11245, Training Loss: 2.328e-01, Validation Loss: 6.264e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11246, Training Loss: 2.327e-01, Validation Loss: 6.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11247, Training Loss: 2.327e-01, Validation Loss: 6.264e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11248, Training Loss: 2.327e-01, Validation Loss: 6.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11249, Training Loss: 2.327e-01, Validation Loss: 6.263e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11250, Training Loss: 2.326e-01, Validation Loss: 6.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11251, Training Loss: 2.326e-01, Validation Loss: 6.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11252, Training Loss: 2.326e-01, Validation Loss: 6.263e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11253, Training Loss: 2.325e-01, Validation Loss: 6.263e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11254, Training Loss: 2.325e-01, Validation Loss: 6.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11255, Training Loss: 2.325e-01, Validation Loss: 6.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11256, Training Loss: 2.325e-01, Validation Loss: 6.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11257, Training Loss: 2.324e-01, Validation Loss: 6.262e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11258, Training Loss: 2.324e-01, Validation Loss: 6.262e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11259, Training Loss: 2.324e-01, Validation Loss: 6.262e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11260, Training Loss: 2.324e-01, Validation Loss: 6.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11261, Training Loss: 2.323e-01, Validation Loss: 6.261e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11262, Training Loss: 2.323e-01, Validation Loss: 6.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11263, Training Loss: 2.323e-01, Validation Loss: 6.261e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11264, Training Loss: 2.323e-01, Validation Loss: 6.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11265, Training Loss: 2.322e-01, Validation Loss: 6.261e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11266, Training Loss: 2.322e-01, Validation Loss: 6.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11267, Training Loss: 2.322e-01, Validation Loss: 6.260e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11268, Training Loss: 2.322e-01, Validation Loss: 6.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11269, Training Loss: 2.321e-01, Validation Loss: 6.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11270, Training Loss: 2.321e-01, Validation Loss: 6.260e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11271, Training Loss: 2.321e-01, Validation Loss: 6.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11272, Training Loss: 2.321e-01, Validation Loss: 6.260e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11273, Training Loss: 2.320e-01, Validation Loss: 6.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11274, Training Loss: 2.320e-01, Validation Loss: 6.259e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11275, Training Loss: 2.320e-01, Validation Loss: 6.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11276, Training Loss: 2.320e-01, Validation Loss: 6.259e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11277, Training Loss: 2.319e-01, Validation Loss: 6.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11278, Training Loss: 2.319e-01, Validation Loss: 6.259e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11279, Training Loss: 2.319e-01, Validation Loss: 6.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11280, Training Loss: 2.319e-01, Validation Loss: 6.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11281, Training Loss: 2.318e-01, Validation Loss: 6.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11282, Training Loss: 2.318e-01, Validation Loss: 6.258e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11283, Training Loss: 2.318e-01, Validation Loss: 6.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11284, Training Loss: 2.318e-01, Validation Loss: 6.258e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11285, Training Loss: 2.317e-01, Validation Loss: 6.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11286, Training Loss: 2.317e-01, Validation Loss: 6.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11287, Training Loss: 2.317e-01, Validation Loss: 6.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11288, Training Loss: 2.317e-01, Validation Loss: 6.257e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11289, Training Loss: 2.316e-01, Validation Loss: 6.257e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11290, Training Loss: 2.316e-01, Validation Loss: 6.257e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11291, Training Loss: 2.316e-01, Validation Loss: 6.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11292, Training Loss: 2.316e-01, Validation Loss: 6.256e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11293, Training Loss: 2.315e-01, Validation Loss: 6.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11294, Training Loss: 2.315e-01, Validation Loss: 6.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11295, Training Loss: 2.315e-01, Validation Loss: 6.256e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11296, Training Loss: 2.315e-01, Validation Loss: 6.256e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11297, Training Loss: 2.314e-01, Validation Loss: 6.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11298, Training Loss: 2.314e-01, Validation Loss: 6.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11299, Training Loss: 2.314e-01, Validation Loss: 6.255e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11300, Training Loss: 2.314e-01, Validation Loss: 6.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11301, Training Loss: 2.313e-01, Validation Loss: 6.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11302, Training Loss: 2.313e-01, Validation Loss: 6.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11303, Training Loss: 2.313e-01, Validation Loss: 6.255e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11304, Training Loss: 2.312e-01, Validation Loss: 6.255e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11305, Training Loss: 2.312e-01, Validation Loss: 6.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11306, Training Loss: 2.312e-01, Validation Loss: 6.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11307, Training Loss: 2.312e-01, Validation Loss: 6.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11308, Training Loss: 2.311e-01, Validation Loss: 6.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11309, Training Loss: 2.311e-01, Validation Loss: 6.254e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11310, Training Loss: 2.311e-01, Validation Loss: 6.254e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11311, Training Loss: 2.311e-01, Validation Loss: 6.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11312, Training Loss: 2.310e-01, Validation Loss: 6.253e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11313, Training Loss: 2.310e-01, Validation Loss: 6.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11314, Training Loss: 2.310e-01, Validation Loss: 6.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11315, Training Loss: 2.310e-01, Validation Loss: 6.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11316, Training Loss: 2.309e-01, Validation Loss: 6.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11317, Training Loss: 2.309e-01, Validation Loss: 6.253e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11318, Training Loss: 2.309e-01, Validation Loss: 6.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11319, Training Loss: 2.309e-01, Validation Loss: 6.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11320, Training Loss: 2.308e-01, Validation Loss: 6.252e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11321, Training Loss: 2.308e-01, Validation Loss: 6.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11322, Training Loss: 2.308e-01, Validation Loss: 6.252e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11323, Training Loss: 2.308e-01, Validation Loss: 6.252e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11324, Training Loss: 2.307e-01, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11325, Training Loss: 2.307e-01, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11326, Training Loss: 2.307e-01, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11327, Training Loss: 2.307e-01, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11328, Training Loss: 2.306e-01, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11329, Training Loss: 2.306e-01, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11330, Training Loss: 2.306e-01, Validation Loss: 6.251e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11331, Training Loss: 2.306e-01, Validation Loss: 6.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11332, Training Loss: 2.305e-01, Validation Loss: 6.250e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11333, Training Loss: 2.305e-01, Validation Loss: 6.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11334, Training Loss: 2.305e-01, Validation Loss: 6.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11335, Training Loss: 2.305e-01, Validation Loss: 6.250e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11336, Training Loss: 2.304e-01, Validation Loss: 6.250e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11337, Training Loss: 2.304e-01, Validation Loss: 6.250e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11338, Training Loss: 2.304e-01, Validation Loss: 6.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11339, Training Loss: 2.304e-01, Validation Loss: 6.249e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11340, Training Loss: 2.303e-01, Validation Loss: 6.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11341, Training Loss: 2.303e-01, Validation Loss: 6.249e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11342, Training Loss: 2.303e-01, Validation Loss: 6.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11343, Training Loss: 2.303e-01, Validation Loss: 6.249e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11344, Training Loss: 2.302e-01, Validation Loss: 6.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11345, Training Loss: 2.302e-01, Validation Loss: 6.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11346, Training Loss: 2.302e-01, Validation Loss: 6.248e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11347, Training Loss: 2.302e-01, Validation Loss: 6.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11348, Training Loss: 2.301e-01, Validation Loss: 6.248e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11349, Training Loss: 2.301e-01, Validation Loss: 6.248e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11350, Training Loss: 2.301e-01, Validation Loss: 6.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11351, Training Loss: 2.301e-01, Validation Loss: 6.247e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11352, Training Loss: 2.300e-01, Validation Loss: 6.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11353, Training Loss: 2.300e-01, Validation Loss: 6.247e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11354, Training Loss: 2.300e-01, Validation Loss: 6.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11355, Training Loss: 2.300e-01, Validation Loss: 6.247e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11356, Training Loss: 2.299e-01, Validation Loss: 6.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11357, Training Loss: 2.299e-01, Validation Loss: 6.246e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11358, Training Loss: 2.299e-01, Validation Loss: 6.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11359, Training Loss: 2.299e-01, Validation Loss: 6.246e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11360, Training Loss: 2.298e-01, Validation Loss: 6.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11361, Training Loss: 2.298e-01, Validation Loss: 6.246e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11362, Training Loss: 2.298e-01, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11363, Training Loss: 2.298e-01, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11364, Training Loss: 2.297e-01, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11365, Training Loss: 2.297e-01, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11366, Training Loss: 2.297e-01, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11367, Training Loss: 2.297e-01, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11368, Training Loss: 2.296e-01, Validation Loss: 6.245e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11369, Training Loss: 2.296e-01, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11370, Training Loss: 2.296e-01, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11371, Training Loss: 2.296e-01, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11372, Training Loss: 2.295e-01, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11373, Training Loss: 2.295e-01, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11374, Training Loss: 2.295e-01, Validation Loss: 6.244e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11375, Training Loss: 2.295e-01, Validation Loss: 6.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11376, Training Loss: 2.294e-01, Validation Loss: 6.243e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11377, Training Loss: 2.294e-01, Validation Loss: 6.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11378, Training Loss: 2.294e-01, Validation Loss: 6.243e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11379, Training Loss: 2.294e-01, Validation Loss: 6.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11380, Training Loss: 2.293e-01, Validation Loss: 6.243e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11381, Training Loss: 2.293e-01, Validation Loss: 6.243e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11382, Training Loss: 2.293e-01, Validation Loss: 6.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11383, Training Loss: 2.293e-01, Validation Loss: 6.242e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11384, Training Loss: 2.292e-01, Validation Loss: 6.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11385, Training Loss: 2.292e-01, Validation Loss: 6.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11386, Training Loss: 2.292e-01, Validation Loss: 6.242e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11387, Training Loss: 2.292e-01, Validation Loss: 6.242e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11388, Training Loss: 2.291e-01, Validation Loss: 6.242e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11389, Training Loss: 2.291e-01, Validation Loss: 6.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11390, Training Loss: 2.291e-01, Validation Loss: 6.241e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11391, Training Loss: 2.291e-01, Validation Loss: 6.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11392, Training Loss: 2.290e-01, Validation Loss: 6.241e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11393, Training Loss: 2.290e-01, Validation Loss: 6.241e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11394, Training Loss: 2.290e-01, Validation Loss: 6.241e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11395, Training Loss: 2.290e-01, Validation Loss: 6.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11396, Training Loss: 2.289e-01, Validation Loss: 6.240e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11397, Training Loss: 2.289e-01, Validation Loss: 6.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11398, Training Loss: 2.289e-01, Validation Loss: 6.240e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11399, Training Loss: 2.289e-01, Validation Loss: 6.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11400, Training Loss: 2.288e-01, Validation Loss: 6.240e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11401, Training Loss: 2.288e-01, Validation Loss: 6.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11402, Training Loss: 2.288e-01, Validation Loss: 6.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11403, Training Loss: 2.288e-01, Validation Loss: 6.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11404, Training Loss: 2.287e-01, Validation Loss: 6.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11405, Training Loss: 2.287e-01, Validation Loss: 6.239e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11406, Training Loss: 2.287e-01, Validation Loss: 6.239e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11407, Training Loss: 2.287e-01, Validation Loss: 6.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11408, Training Loss: 2.286e-01, Validation Loss: 6.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11409, Training Loss: 2.286e-01, Validation Loss: 6.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11410, Training Loss: 2.286e-01, Validation Loss: 6.238e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11411, Training Loss: 2.286e-01, Validation Loss: 6.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11412, Training Loss: 2.285e-01, Validation Loss: 6.238e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11413, Training Loss: 2.285e-01, Validation Loss: 6.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11414, Training Loss: 2.285e-01, Validation Loss: 6.238e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11415, Training Loss: 2.285e-01, Validation Loss: 6.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11416, Training Loss: 2.284e-01, Validation Loss: 6.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11417, Training Loss: 2.284e-01, Validation Loss: 6.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11418, Training Loss: 2.284e-01, Validation Loss: 6.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11419, Training Loss: 2.284e-01, Validation Loss: 6.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11420, Training Loss: 2.283e-01, Validation Loss: 6.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11421, Training Loss: 2.283e-01, Validation Loss: 6.237e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11422, Training Loss: 2.283e-01, Validation Loss: 6.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11423, Training Loss: 2.283e-01, Validation Loss: 6.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11424, Training Loss: 2.282e-01, Validation Loss: 6.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11425, Training Loss: 2.282e-01, Validation Loss: 6.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11426, Training Loss: 2.282e-01, Validation Loss: 6.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11427, Training Loss: 2.282e-01, Validation Loss: 6.236e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11428, Training Loss: 2.281e-01, Validation Loss: 6.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11429, Training Loss: 2.281e-01, Validation Loss: 6.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11430, Training Loss: 2.281e-01, Validation Loss: 6.235e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11431, Training Loss: 2.281e-01, Validation Loss: 6.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11432, Training Loss: 2.280e-01, Validation Loss: 6.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11433, Training Loss: 2.280e-01, Validation Loss: 6.235e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11434, Training Loss: 2.280e-01, Validation Loss: 6.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11435, Training Loss: 2.280e-01, Validation Loss: 6.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11436, Training Loss: 2.279e-01, Validation Loss: 6.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11437, Training Loss: 2.279e-01, Validation Loss: 6.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11438, Training Loss: 2.279e-01, Validation Loss: 6.234e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11439, Training Loss: 2.279e-01, Validation Loss: 6.234e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11440, Training Loss: 2.278e-01, Validation Loss: 6.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11441, Training Loss: 2.278e-01, Validation Loss: 6.234e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11442, Training Loss: 2.278e-01, Validation Loss: 6.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11443, Training Loss: 2.278e-01, Validation Loss: 6.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11444, Training Loss: 2.277e-01, Validation Loss: 6.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11445, Training Loss: 2.277e-01, Validation Loss: 6.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11446, Training Loss: 2.277e-01, Validation Loss: 6.233e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11447, Training Loss: 2.277e-01, Validation Loss: 6.233e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11448, Training Loss: 2.276e-01, Validation Loss: 6.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11449, Training Loss: 2.276e-01, Validation Loss: 6.232e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11450, Training Loss: 2.276e-01, Validation Loss: 6.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11451, Training Loss: 2.276e-01, Validation Loss: 6.232e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11452, Training Loss: 2.275e-01, Validation Loss: 6.232e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11453, Training Loss: 2.275e-01, Validation Loss: 6.232e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11454, Training Loss: 2.275e-01, Validation Loss: 6.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11455, Training Loss: 2.275e-01, Validation Loss: 6.231e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11456, Training Loss: 2.274e-01, Validation Loss: 6.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11457, Training Loss: 2.274e-01, Validation Loss: 6.231e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11458, Training Loss: 2.274e-01, Validation Loss: 6.231e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11459, Training Loss: 2.274e-01, Validation Loss: 6.231e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11460, Training Loss: 2.273e-01, Validation Loss: 6.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11461, Training Loss: 2.273e-01, Validation Loss: 6.230e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11462, Training Loss: 2.273e-01, Validation Loss: 6.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11463, Training Loss: 2.273e-01, Validation Loss: 6.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11464, Training Loss: 2.272e-01, Validation Loss: 6.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11465, Training Loss: 2.272e-01, Validation Loss: 6.230e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11466, Training Loss: 2.272e-01, Validation Loss: 6.230e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11467, Training Loss: 2.272e-01, Validation Loss: 6.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11468, Training Loss: 2.271e-01, Validation Loss: 6.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11469, Training Loss: 2.271e-01, Validation Loss: 6.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11470, Training Loss: 2.271e-01, Validation Loss: 6.229e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11471, Training Loss: 2.271e-01, Validation Loss: 6.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11472, Training Loss: 2.270e-01, Validation Loss: 6.229e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11473, Training Loss: 2.270e-01, Validation Loss: 6.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11474, Training Loss: 2.270e-01, Validation Loss: 6.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11475, Training Loss: 2.270e-01, Validation Loss: 6.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11476, Training Loss: 2.269e-01, Validation Loss: 6.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11477, Training Loss: 2.269e-01, Validation Loss: 6.228e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11478, Training Loss: 2.269e-01, Validation Loss: 6.228e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11479, Training Loss: 2.269e-01, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11480, Training Loss: 2.268e-01, Validation Loss: 6.228e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11481, Training Loss: 2.268e-01, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11482, Training Loss: 2.268e-01, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11483, Training Loss: 2.268e-01, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11484, Training Loss: 2.267e-01, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11485, Training Loss: 2.267e-01, Validation Loss: 6.227e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11486, Training Loss: 2.267e-01, Validation Loss: 6.227e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11487, Training Loss: 2.267e-01, Validation Loss: 6.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11488, Training Loss: 2.266e-01, Validation Loss: 6.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11489, Training Loss: 2.266e-01, Validation Loss: 6.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11490, Training Loss: 2.266e-01, Validation Loss: 6.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11491, Training Loss: 2.266e-01, Validation Loss: 6.226e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11492, Training Loss: 2.266e-01, Validation Loss: 6.226e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11493, Training Loss: 2.265e-01, Validation Loss: 6.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11494, Training Loss: 2.265e-01, Validation Loss: 6.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11495, Training Loss: 2.265e-01, Validation Loss: 6.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11496, Training Loss: 2.265e-01, Validation Loss: 6.225e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11497, Training Loss: 2.264e-01, Validation Loss: 6.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11498, Training Loss: 2.264e-01, Validation Loss: 6.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11499, Training Loss: 2.264e-01, Validation Loss: 6.225e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11500, Training Loss: 2.264e-01, Validation Loss: 6.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11501, Training Loss: 2.263e-01, Validation Loss: 6.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11502, Training Loss: 2.263e-01, Validation Loss: 6.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11503, Training Loss: 2.263e-01, Validation Loss: 6.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11504, Training Loss: 2.263e-01, Validation Loss: 6.224e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11505, Training Loss: 2.262e-01, Validation Loss: 6.224e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11506, Training Loss: 2.262e-01, Validation Loss: 6.224e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11507, Training Loss: 2.262e-01, Validation Loss: 6.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11508, Training Loss: 2.262e-01, Validation Loss: 6.223e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11509, Training Loss: 2.261e-01, Validation Loss: 6.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11510, Training Loss: 2.261e-01, Validation Loss: 6.223e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11511, Training Loss: 2.261e-01, Validation Loss: 6.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11512, Training Loss: 2.261e-01, Validation Loss: 6.223e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11513, Training Loss: 2.260e-01, Validation Loss: 6.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11514, Training Loss: 2.260e-01, Validation Loss: 6.222e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11515, Training Loss: 2.260e-01, Validation Loss: 6.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11516, Training Loss: 2.260e-01, Validation Loss: 6.222e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11517, Training Loss: 2.259e-01, Validation Loss: 6.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11518, Training Loss: 2.259e-01, Validation Loss: 6.222e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11519, Training Loss: 2.259e-01, Validation Loss: 6.222e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11520, Training Loss: 2.259e-01, Validation Loss: 6.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11521, Training Loss: 2.258e-01, Validation Loss: 6.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11522, Training Loss: 2.258e-01, Validation Loss: 6.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11523, Training Loss: 2.258e-01, Validation Loss: 6.221e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11524, Training Loss: 2.258e-01, Validation Loss: 6.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11525, Training Loss: 2.257e-01, Validation Loss: 6.221e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11526, Training Loss: 2.257e-01, Validation Loss: 6.221e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11527, Training Loss: 2.257e-01, Validation Loss: 6.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11528, Training Loss: 2.257e-01, Validation Loss: 6.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11529, Training Loss: 2.256e-01, Validation Loss: 6.220e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11530, Training Loss: 2.256e-01, Validation Loss: 6.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11531, Training Loss: 2.256e-01, Validation Loss: 6.220e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11532, Training Loss: 2.256e-01, Validation Loss: 6.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11533, Training Loss: 2.255e-01, Validation Loss: 6.220e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11534, Training Loss: 2.255e-01, Validation Loss: 6.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11535, Training Loss: 2.255e-01, Validation Loss: 6.219e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11536, Training Loss: 2.255e-01, Validation Loss: 6.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11537, Training Loss: 2.254e-01, Validation Loss: 6.219e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11538, Training Loss: 2.254e-01, Validation Loss: 6.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11539, Training Loss: 2.254e-01, Validation Loss: 6.219e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11540, Training Loss: 2.254e-01, Validation Loss: 6.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11541, Training Loss: 2.253e-01, Validation Loss: 6.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11542, Training Loss: 2.253e-01, Validation Loss: 6.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11543, Training Loss: 2.253e-01, Validation Loss: 6.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11544, Training Loss: 2.253e-01, Validation Loss: 6.218e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11545, Training Loss: 2.253e-01, Validation Loss: 6.218e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11546, Training Loss: 2.252e-01, Validation Loss: 6.218e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11547, Training Loss: 2.252e-01, Validation Loss: 6.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11548, Training Loss: 2.252e-01, Validation Loss: 6.217e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11549, Training Loss: 2.252e-01, Validation Loss: 6.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11550, Training Loss: 2.251e-01, Validation Loss: 6.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11551, Training Loss: 2.251e-01, Validation Loss: 6.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11552, Training Loss: 2.251e-01, Validation Loss: 6.217e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11553, Training Loss: 2.251e-01, Validation Loss: 6.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11554, Training Loss: 2.250e-01, Validation Loss: 6.216e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11555, Training Loss: 2.250e-01, Validation Loss: 6.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11556, Training Loss: 2.250e-01, Validation Loss: 6.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11557, Training Loss: 2.250e-01, Validation Loss: 6.216e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11558, Training Loss: 2.249e-01, Validation Loss: 6.216e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11559, Training Loss: 2.249e-01, Validation Loss: 6.216e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11560, Training Loss: 2.249e-01, Validation Loss: 6.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11561, Training Loss: 2.249e-01, Validation Loss: 6.216e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11562, Training Loss: 2.248e-01, Validation Loss: 6.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11563, Training Loss: 2.248e-01, Validation Loss: 6.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11564, Training Loss: 2.248e-01, Validation Loss: 6.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11565, Training Loss: 2.248e-01, Validation Loss: 6.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11566, Training Loss: 2.247e-01, Validation Loss: 6.215e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11567, Training Loss: 2.247e-01, Validation Loss: 6.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11568, Training Loss: 2.247e-01, Validation Loss: 6.214e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11569, Training Loss: 2.247e-01, Validation Loss: 6.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11570, Training Loss: 2.246e-01, Validation Loss: 6.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11571, Training Loss: 2.246e-01, Validation Loss: 6.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11572, Training Loss: 2.246e-01, Validation Loss: 6.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11573, Training Loss: 2.246e-01, Validation Loss: 6.214e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11574, Training Loss: 2.245e-01, Validation Loss: 6.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11575, Training Loss: 2.245e-01, Validation Loss: 6.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11576, Training Loss: 2.245e-01, Validation Loss: 6.213e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11577, Training Loss: 2.245e-01, Validation Loss: 6.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11578, Training Loss: 2.244e-01, Validation Loss: 6.213e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11579, Training Loss: 2.244e-01, Validation Loss: 6.213e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11580, Training Loss: 2.244e-01, Validation Loss: 6.213e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11581, Training Loss: 2.244e-01, Validation Loss: 6.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11582, Training Loss: 2.243e-01, Validation Loss: 6.212e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11583, Training Loss: 2.243e-01, Validation Loss: 6.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11584, Training Loss: 2.243e-01, Validation Loss: 6.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11585, Training Loss: 2.243e-01, Validation Loss: 6.212e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11586, Training Loss: 2.243e-01, Validation Loss: 6.212e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11587, Training Loss: 2.242e-01, Validation Loss: 6.212e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11588, Training Loss: 2.242e-01, Validation Loss: 6.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11589, Training Loss: 2.242e-01, Validation Loss: 6.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11590, Training Loss: 2.242e-01, Validation Loss: 6.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11591, Training Loss: 2.241e-01, Validation Loss: 6.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11592, Training Loss: 2.241e-01, Validation Loss: 6.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11593, Training Loss: 2.241e-01, Validation Loss: 6.211e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11594, Training Loss: 2.241e-01, Validation Loss: 6.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11595, Training Loss: 2.240e-01, Validation Loss: 6.210e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11596, Training Loss: 2.240e-01, Validation Loss: 6.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11597, Training Loss: 2.240e-01, Validation Loss: 6.210e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11598, Training Loss: 2.240e-01, Validation Loss: 6.210e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11599, Training Loss: 2.239e-01, Validation Loss: 6.210e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11600, Training Loss: 2.239e-01, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11601, Training Loss: 2.239e-01, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11602, Training Loss: 2.239e-01, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11603, Training Loss: 2.238e-01, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11604, Training Loss: 2.238e-01, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11605, Training Loss: 2.238e-01, Validation Loss: 6.209e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11606, Training Loss: 2.238e-01, Validation Loss: 6.209e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11607, Training Loss: 2.237e-01, Validation Loss: 6.209e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11608, Training Loss: 2.237e-01, Validation Loss: 6.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11609, Training Loss: 2.237e-01, Validation Loss: 6.208e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11610, Training Loss: 2.237e-01, Validation Loss: 6.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11611, Training Loss: 2.236e-01, Validation Loss: 6.208e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11612, Training Loss: 2.236e-01, Validation Loss: 6.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11613, Training Loss: 2.236e-01, Validation Loss: 6.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11614, Training Loss: 2.236e-01, Validation Loss: 6.208e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11615, Training Loss: 2.235e-01, Validation Loss: 6.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11616, Training Loss: 2.235e-01, Validation Loss: 6.207e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11617, Training Loss: 2.235e-01, Validation Loss: 6.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11618, Training Loss: 2.235e-01, Validation Loss: 6.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11619, Training Loss: 2.235e-01, Validation Loss: 6.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11620, Training Loss: 2.234e-01, Validation Loss: 6.207e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11621, Training Loss: 2.234e-01, Validation Loss: 6.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11622, Training Loss: 2.234e-01, Validation Loss: 6.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11623, Training Loss: 2.234e-01, Validation Loss: 6.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11624, Training Loss: 2.233e-01, Validation Loss: 6.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11625, Training Loss: 2.233e-01, Validation Loss: 6.206e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11626, Training Loss: 2.233e-01, Validation Loss: 6.206e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11627, Training Loss: 2.233e-01, Validation Loss: 6.206e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11628, Training Loss: 2.232e-01, Validation Loss: 6.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11629, Training Loss: 2.232e-01, Validation Loss: 6.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11630, Training Loss: 2.232e-01, Validation Loss: 6.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11631, Training Loss: 2.232e-01, Validation Loss: 6.205e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11632, Training Loss: 2.231e-01, Validation Loss: 6.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11633, Training Loss: 2.231e-01, Validation Loss: 6.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11634, Training Loss: 2.231e-01, Validation Loss: 6.205e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11635, Training Loss: 2.231e-01, Validation Loss: 6.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11636, Training Loss: 2.230e-01, Validation Loss: 6.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11637, Training Loss: 2.230e-01, Validation Loss: 6.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11638, Training Loss: 2.230e-01, Validation Loss: 6.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11639, Training Loss: 2.230e-01, Validation Loss: 6.204e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11640, Training Loss: 2.229e-01, Validation Loss: 6.204e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11641, Training Loss: 2.229e-01, Validation Loss: 6.204e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11642, Training Loss: 2.229e-01, Validation Loss: 6.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11643, Training Loss: 2.229e-01, Validation Loss: 6.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11644, Training Loss: 2.228e-01, Validation Loss: 6.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11645, Training Loss: 2.228e-01, Validation Loss: 6.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11646, Training Loss: 2.228e-01, Validation Loss: 6.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11647, Training Loss: 2.228e-01, Validation Loss: 6.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11648, Training Loss: 2.228e-01, Validation Loss: 6.203e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11649, Training Loss: 2.227e-01, Validation Loss: 6.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11650, Training Loss: 2.227e-01, Validation Loss: 6.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11651, Training Loss: 2.227e-01, Validation Loss: 6.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11652, Training Loss: 2.227e-01, Validation Loss: 6.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11653, Training Loss: 2.226e-01, Validation Loss: 6.202e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11654, Training Loss: 2.226e-01, Validation Loss: 6.202e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11655, Training Loss: 2.226e-01, Validation Loss: 6.202e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11656, Training Loss: 2.226e-01, Validation Loss: 6.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11657, Training Loss: 2.225e-01, Validation Loss: 6.201e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11658, Training Loss: 2.225e-01, Validation Loss: 6.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11659, Training Loss: 2.225e-01, Validation Loss: 6.201e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11660, Training Loss: 2.225e-01, Validation Loss: 6.201e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11661, Training Loss: 2.224e-01, Validation Loss: 6.201e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11662, Training Loss: 2.224e-01, Validation Loss: 6.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11663, Training Loss: 2.224e-01, Validation Loss: 6.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11664, Training Loss: 2.224e-01, Validation Loss: 6.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11665, Training Loss: 2.223e-01, Validation Loss: 6.200e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11666, Training Loss: 2.223e-01, Validation Loss: 6.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11667, Training Loss: 2.223e-01, Validation Loss: 6.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11668, Training Loss: 2.223e-01, Validation Loss: 6.200e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11669, Training Loss: 2.222e-01, Validation Loss: 6.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11670, Training Loss: 2.222e-01, Validation Loss: 6.199e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11671, Training Loss: 2.222e-01, Validation Loss: 6.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11672, Training Loss: 2.222e-01, Validation Loss: 6.199e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11673, Training Loss: 2.222e-01, Validation Loss: 6.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11674, Training Loss: 2.221e-01, Validation Loss: 6.199e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11675, Training Loss: 2.221e-01, Validation Loss: 6.199e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11676, Training Loss: 2.221e-01, Validation Loss: 6.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11677, Training Loss: 2.221e-01, Validation Loss: 6.198e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11678, Training Loss: 2.220e-01, Validation Loss: 6.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11679, Training Loss: 2.220e-01, Validation Loss: 6.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11680, Training Loss: 2.220e-01, Validation Loss: 6.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11681, Training Loss: 2.220e-01, Validation Loss: 6.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11682, Training Loss: 2.219e-01, Validation Loss: 6.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11683, Training Loss: 2.219e-01, Validation Loss: 6.198e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11684, Training Loss: 2.219e-01, Validation Loss: 6.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11685, Training Loss: 2.219e-01, Validation Loss: 6.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11686, Training Loss: 2.218e-01, Validation Loss: 6.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11687, Training Loss: 2.218e-01, Validation Loss: 6.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11688, Training Loss: 2.218e-01, Validation Loss: 6.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11689, Training Loss: 2.218e-01, Validation Loss: 6.197e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11690, Training Loss: 2.217e-01, Validation Loss: 6.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11691, Training Loss: 2.217e-01, Validation Loss: 6.196e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11692, Training Loss: 2.217e-01, Validation Loss: 6.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11693, Training Loss: 2.217e-01, Validation Loss: 6.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11694, Training Loss: 2.216e-01, Validation Loss: 6.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11695, Training Loss: 2.216e-01, Validation Loss: 6.196e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11696, Training Loss: 2.216e-01, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11697, Training Loss: 2.216e-01, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11698, Training Loss: 2.216e-01, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11699, Training Loss: 2.215e-01, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11700, Training Loss: 2.215e-01, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11701, Training Loss: 2.215e-01, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11702, Training Loss: 2.215e-01, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11703, Training Loss: 2.214e-01, Validation Loss: 6.195e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11704, Training Loss: 2.214e-01, Validation Loss: 6.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11705, Training Loss: 2.214e-01, Validation Loss: 6.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11706, Training Loss: 2.214e-01, Validation Loss: 6.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11707, Training Loss: 2.213e-01, Validation Loss: 6.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11708, Training Loss: 2.213e-01, Validation Loss: 6.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11709, Training Loss: 2.213e-01, Validation Loss: 6.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11710, Training Loss: 2.213e-01, Validation Loss: 6.194e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11711, Training Loss: 2.212e-01, Validation Loss: 6.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11712, Training Loss: 2.212e-01, Validation Loss: 6.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11713, Training Loss: 2.212e-01, Validation Loss: 6.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11714, Training Loss: 2.212e-01, Validation Loss: 6.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11715, Training Loss: 2.211e-01, Validation Loss: 6.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11716, Training Loss: 2.211e-01, Validation Loss: 6.193e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11717, Training Loss: 2.211e-01, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11718, Training Loss: 2.211e-01, Validation Loss: 6.192e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11719, Training Loss: 2.211e-01, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11720, Training Loss: 2.210e-01, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11721, Training Loss: 2.210e-01, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11722, Training Loss: 2.210e-01, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11723, Training Loss: 2.210e-01, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11724, Training Loss: 2.209e-01, Validation Loss: 6.192e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11725, Training Loss: 2.209e-01, Validation Loss: 6.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11726, Training Loss: 2.209e-01, Validation Loss: 6.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11727, Training Loss: 2.209e-01, Validation Loss: 6.191e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11728, Training Loss: 2.208e-01, Validation Loss: 6.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11729, Training Loss: 2.208e-01, Validation Loss: 6.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11730, Training Loss: 2.208e-01, Validation Loss: 6.191e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11731, Training Loss: 2.208e-01, Validation Loss: 6.191e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11732, Training Loss: 2.207e-01, Validation Loss: 6.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11733, Training Loss: 2.207e-01, Validation Loss: 6.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11734, Training Loss: 2.207e-01, Validation Loss: 6.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11735, Training Loss: 2.207e-01, Validation Loss: 6.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11736, Training Loss: 2.206e-01, Validation Loss: 6.190e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11737, Training Loss: 2.206e-01, Validation Loss: 6.190e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11738, Training Loss: 2.206e-01, Validation Loss: 6.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11739, Training Loss: 2.206e-01, Validation Loss: 6.190e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11740, Training Loss: 2.206e-01, Validation Loss: 6.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11741, Training Loss: 2.205e-01, Validation Loss: 6.189e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11742, Training Loss: 2.205e-01, Validation Loss: 6.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11743, Training Loss: 2.205e-01, Validation Loss: 6.189e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11744, Training Loss: 2.205e-01, Validation Loss: 6.189e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11745, Training Loss: 2.204e-01, Validation Loss: 6.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11746, Training Loss: 2.204e-01, Validation Loss: 6.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11747, Training Loss: 2.204e-01, Validation Loss: 6.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11748, Training Loss: 2.204e-01, Validation Loss: 6.188e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11749, Training Loss: 2.203e-01, Validation Loss: 6.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11750, Training Loss: 2.203e-01, Validation Loss: 6.188e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11751, Training Loss: 2.203e-01, Validation Loss: 6.188e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11752, Training Loss: 2.203e-01, Validation Loss: 6.188e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11753, Training Loss: 2.202e-01, Validation Loss: 6.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11754, Training Loss: 2.202e-01, Validation Loss: 6.187e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11755, Training Loss: 2.202e-01, Validation Loss: 6.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11756, Training Loss: 2.202e-01, Validation Loss: 6.187e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11757, Training Loss: 2.201e-01, Validation Loss: 6.187e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11758, Training Loss: 2.201e-01, Validation Loss: 6.187e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11759, Training Loss: 2.201e-01, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11760, Training Loss: 2.201e-01, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11761, Training Loss: 2.201e-01, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11762, Training Loss: 2.200e-01, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11763, Training Loss: 2.200e-01, Validation Loss: 6.186e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11764, Training Loss: 2.200e-01, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11765, Training Loss: 2.200e-01, Validation Loss: 6.186e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11766, Training Loss: 2.199e-01, Validation Loss: 6.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11767, Training Loss: 2.199e-01, Validation Loss: 6.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11768, Training Loss: 2.199e-01, Validation Loss: 6.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11769, Training Loss: 2.199e-01, Validation Loss: 6.185e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11770, Training Loss: 2.198e-01, Validation Loss: 6.185e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 11771, Training Loss: 2.198e-01, Validation Loss: 6.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11772, Training Loss: 2.198e-01, Validation Loss: 6.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11773, Training Loss: 2.198e-01, Validation Loss: 6.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11774, Training Loss: 2.197e-01, Validation Loss: 6.185e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11775, Training Loss: 2.197e-01, Validation Loss: 6.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11776, Training Loss: 2.197e-01, Validation Loss: 6.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11777, Training Loss: 2.197e-01, Validation Loss: 6.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11778, Training Loss: 2.197e-01, Validation Loss: 6.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11779, Training Loss: 2.196e-01, Validation Loss: 6.184e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11780, Training Loss: 2.196e-01, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11781, Training Loss: 2.196e-01, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11782, Training Loss: 2.196e-01, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11783, Training Loss: 2.195e-01, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11784, Training Loss: 2.195e-01, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11785, Training Loss: 2.195e-01, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11786, Training Loss: 2.195e-01, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11787, Training Loss: 2.194e-01, Validation Loss: 6.183e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11788, Training Loss: 2.194e-01, Validation Loss: 6.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11789, Training Loss: 2.194e-01, Validation Loss: 6.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11790, Training Loss: 2.194e-01, Validation Loss: 6.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11791, Training Loss: 2.193e-01, Validation Loss: 6.182e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11792, Training Loss: 2.193e-01, Validation Loss: 6.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11793, Training Loss: 2.193e-01, Validation Loss: 6.182e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11794, Training Loss: 2.193e-01, Validation Loss: 6.182e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11795, Training Loss: 2.193e-01, Validation Loss: 6.182e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11796, Training Loss: 2.192e-01, Validation Loss: 6.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11797, Training Loss: 2.192e-01, Validation Loss: 6.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11798, Training Loss: 2.192e-01, Validation Loss: 6.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11799, Training Loss: 2.192e-01, Validation Loss: 6.181e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11800, Training Loss: 2.191e-01, Validation Loss: 6.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11801, Training Loss: 2.191e-01, Validation Loss: 6.181e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11802, Training Loss: 2.191e-01, Validation Loss: 6.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11803, Training Loss: 2.191e-01, Validation Loss: 6.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11804, Training Loss: 2.190e-01, Validation Loss: 6.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11805, Training Loss: 2.190e-01, Validation Loss: 6.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11806, Training Loss: 2.190e-01, Validation Loss: 6.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11807, Training Loss: 2.190e-01, Validation Loss: 6.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11808, Training Loss: 2.189e-01, Validation Loss: 6.180e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11809, Training Loss: 2.189e-01, Validation Loss: 6.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11810, Training Loss: 2.189e-01, Validation Loss: 6.179e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11811, Training Loss: 2.189e-01, Validation Loss: 6.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11812, Training Loss: 2.189e-01, Validation Loss: 6.179e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11813, Training Loss: 2.188e-01, Validation Loss: 6.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11814, Training Loss: 2.188e-01, Validation Loss: 6.179e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11815, Training Loss: 2.188e-01, Validation Loss: 6.179e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11816, Training Loss: 2.188e-01, Validation Loss: 6.179e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11817, Training Loss: 2.187e-01, Validation Loss: 6.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11818, Training Loss: 2.187e-01, Validation Loss: 6.178e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11819, Training Loss: 2.187e-01, Validation Loss: 6.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11820, Training Loss: 2.187e-01, Validation Loss: 6.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11821, Training Loss: 2.186e-01, Validation Loss: 6.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11822, Training Loss: 2.186e-01, Validation Loss: 6.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11823, Training Loss: 2.186e-01, Validation Loss: 6.178e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11824, Training Loss: 2.186e-01, Validation Loss: 6.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11825, Training Loss: 2.185e-01, Validation Loss: 6.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11826, Training Loss: 2.185e-01, Validation Loss: 6.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11827, Training Loss: 2.185e-01, Validation Loss: 6.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11828, Training Loss: 2.185e-01, Validation Loss: 6.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11829, Training Loss: 2.185e-01, Validation Loss: 6.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11830, Training Loss: 2.184e-01, Validation Loss: 6.177e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11831, Training Loss: 2.184e-01, Validation Loss: 6.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11832, Training Loss: 2.184e-01, Validation Loss: 6.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11833, Training Loss: 2.184e-01, Validation Loss: 6.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11834, Training Loss: 2.183e-01, Validation Loss: 6.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11835, Training Loss: 2.183e-01, Validation Loss: 6.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11836, Training Loss: 2.183e-01, Validation Loss: 6.176e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11837, Training Loss: 2.183e-01, Validation Loss: 6.176e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11838, Training Loss: 2.182e-01, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11839, Training Loss: 2.182e-01, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11840, Training Loss: 2.182e-01, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11841, Training Loss: 2.182e-01, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11842, Training Loss: 2.182e-01, Validation Loss: 6.175e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11843, Training Loss: 2.181e-01, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11844, Training Loss: 2.181e-01, Validation Loss: 6.175e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11845, Training Loss: 2.181e-01, Validation Loss: 6.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11846, Training Loss: 2.181e-01, Validation Loss: 6.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11847, Training Loss: 2.180e-01, Validation Loss: 6.174e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11848, Training Loss: 2.180e-01, Validation Loss: 6.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11849, Training Loss: 2.180e-01, Validation Loss: 6.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11850, Training Loss: 2.180e-01, Validation Loss: 6.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11851, Training Loss: 2.179e-01, Validation Loss: 6.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11852, Training Loss: 2.179e-01, Validation Loss: 6.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11853, Training Loss: 2.179e-01, Validation Loss: 6.174e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11854, Training Loss: 2.179e-01, Validation Loss: 6.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11855, Training Loss: 2.178e-01, Validation Loss: 6.173e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11856, Training Loss: 2.178e-01, Validation Loss: 6.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11857, Training Loss: 2.178e-01, Validation Loss: 6.173e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11858, Training Loss: 2.178e-01, Validation Loss: 6.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11859, Training Loss: 2.178e-01, Validation Loss: 6.173e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11860, Training Loss: 2.177e-01, Validation Loss: 6.173e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11861, Training Loss: 2.177e-01, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11862, Training Loss: 2.177e-01, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11863, Training Loss: 2.177e-01, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11864, Training Loss: 2.176e-01, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11865, Training Loss: 2.176e-01, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11866, Training Loss: 2.176e-01, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11867, Training Loss: 2.176e-01, Validation Loss: 6.172e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11868, Training Loss: 2.175e-01, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11869, Training Loss: 2.175e-01, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11870, Training Loss: 2.175e-01, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11871, Training Loss: 2.175e-01, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11872, Training Loss: 2.175e-01, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11873, Training Loss: 2.174e-01, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11874, Training Loss: 2.174e-01, Validation Loss: 6.171e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11875, Training Loss: 2.174e-01, Validation Loss: 6.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11876, Training Loss: 2.174e-01, Validation Loss: 6.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11877, Training Loss: 2.173e-01, Validation Loss: 6.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11878, Training Loss: 2.173e-01, Validation Loss: 6.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11879, Training Loss: 2.173e-01, Validation Loss: 6.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11880, Training Loss: 2.173e-01, Validation Loss: 6.170e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11881, Training Loss: 2.172e-01, Validation Loss: 6.170e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11882, Training Loss: 2.172e-01, Validation Loss: 6.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11883, Training Loss: 2.172e-01, Validation Loss: 6.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11884, Training Loss: 2.172e-01, Validation Loss: 6.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11885, Training Loss: 2.171e-01, Validation Loss: 6.169e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11886, Training Loss: 2.171e-01, Validation Loss: 6.169e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11887, Training Loss: 2.171e-01, Validation Loss: 6.169e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11888, Training Loss: 2.171e-01, Validation Loss: 6.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11889, Training Loss: 2.171e-01, Validation Loss: 6.169e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11890, Training Loss: 2.170e-01, Validation Loss: 6.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11891, Training Loss: 2.170e-01, Validation Loss: 6.168e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11892, Training Loss: 2.170e-01, Validation Loss: 6.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11893, Training Loss: 2.170e-01, Validation Loss: 6.168e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11894, Training Loss: 2.169e-01, Validation Loss: 6.168e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11895, Training Loss: 2.169e-01, Validation Loss: 6.168e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11896, Training Loss: 2.169e-01, Validation Loss: 6.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11897, Training Loss: 2.169e-01, Validation Loss: 6.167e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11898, Training Loss: 2.168e-01, Validation Loss: 6.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11899, Training Loss: 2.168e-01, Validation Loss: 6.167e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11900, Training Loss: 2.168e-01, Validation Loss: 6.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11901, Training Loss: 2.168e-01, Validation Loss: 6.167e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11902, Training Loss: 2.168e-01, Validation Loss: 6.167e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11903, Training Loss: 2.167e-01, Validation Loss: 6.167e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11904, Training Loss: 2.167e-01, Validation Loss: 6.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11905, Training Loss: 2.167e-01, Validation Loss: 6.167e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11906, Training Loss: 2.167e-01, Validation Loss: 6.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11907, Training Loss: 2.166e-01, Validation Loss: 6.166e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11908, Training Loss: 2.166e-01, Validation Loss: 6.166e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11909, Training Loss: 2.166e-01, Validation Loss: 6.166e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11910, Training Loss: 2.166e-01, Validation Loss: 6.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11911, Training Loss: 2.165e-01, Validation Loss: 6.166e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11912, Training Loss: 2.165e-01, Validation Loss: 6.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11913, Training Loss: 2.165e-01, Validation Loss: 6.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11914, Training Loss: 2.165e-01, Validation Loss: 6.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11915, Training Loss: 2.165e-01, Validation Loss: 6.165e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11916, Training Loss: 2.164e-01, Validation Loss: 6.165e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11917, Training Loss: 2.164e-01, Validation Loss: 6.165e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11918, Training Loss: 2.164e-01, Validation Loss: 6.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11919, Training Loss: 2.164e-01, Validation Loss: 6.165e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11920, Training Loss: 2.163e-01, Validation Loss: 6.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11921, Training Loss: 2.163e-01, Validation Loss: 6.164e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11922, Training Loss: 2.163e-01, Validation Loss: 6.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11923, Training Loss: 2.163e-01, Validation Loss: 6.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11924, Training Loss: 2.162e-01, Validation Loss: 6.164e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11925, Training Loss: 2.162e-01, Validation Loss: 6.164e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11926, Training Loss: 2.162e-01, Validation Loss: 6.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11927, Training Loss: 2.162e-01, Validation Loss: 6.163e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11928, Training Loss: 2.162e-01, Validation Loss: 6.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11929, Training Loss: 2.161e-01, Validation Loss: 6.163e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11930, Training Loss: 2.161e-01, Validation Loss: 6.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11931, Training Loss: 2.161e-01, Validation Loss: 6.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11932, Training Loss: 2.161e-01, Validation Loss: 6.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11933, Training Loss: 2.160e-01, Validation Loss: 6.163e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11934, Training Loss: 2.160e-01, Validation Loss: 6.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11935, Training Loss: 2.160e-01, Validation Loss: 6.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11936, Training Loss: 2.160e-01, Validation Loss: 6.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11937, Training Loss: 2.159e-01, Validation Loss: 6.162e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11938, Training Loss: 2.159e-01, Validation Loss: 6.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11939, Training Loss: 2.159e-01, Validation Loss: 6.162e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11940, Training Loss: 2.159e-01, Validation Loss: 6.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11941, Training Loss: 2.159e-01, Validation Loss: 6.162e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11942, Training Loss: 2.158e-01, Validation Loss: 6.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11943, Training Loss: 2.158e-01, Validation Loss: 6.161e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11944, Training Loss: 2.158e-01, Validation Loss: 6.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11945, Training Loss: 2.158e-01, Validation Loss: 6.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11946, Training Loss: 2.157e-01, Validation Loss: 6.161e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11947, Training Loss: 2.157e-01, Validation Loss: 6.161e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11948, Training Loss: 2.157e-01, Validation Loss: 6.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11949, Training Loss: 2.157e-01, Validation Loss: 6.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11950, Training Loss: 2.156e-01, Validation Loss: 6.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11951, Training Loss: 2.156e-01, Validation Loss: 6.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11952, Training Loss: 2.156e-01, Validation Loss: 6.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11953, Training Loss: 2.156e-01, Validation Loss: 6.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11954, Training Loss: 2.156e-01, Validation Loss: 6.160e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11955, Training Loss: 2.155e-01, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11956, Training Loss: 2.155e-01, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11957, Training Loss: 2.155e-01, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11958, Training Loss: 2.155e-01, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11959, Training Loss: 2.154e-01, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11960, Training Loss: 2.154e-01, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11961, Training Loss: 2.154e-01, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11962, Training Loss: 2.154e-01, Validation Loss: 6.159e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11963, Training Loss: 2.154e-01, Validation Loss: 6.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11964, Training Loss: 2.153e-01, Validation Loss: 6.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11965, Training Loss: 2.153e-01, Validation Loss: 6.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11966, Training Loss: 2.153e-01, Validation Loss: 6.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11967, Training Loss: 2.153e-01, Validation Loss: 6.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11968, Training Loss: 2.152e-01, Validation Loss: 6.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11969, Training Loss: 2.152e-01, Validation Loss: 6.158e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11970, Training Loss: 2.152e-01, Validation Loss: 6.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11971, Training Loss: 2.152e-01, Validation Loss: 6.157e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11972, Training Loss: 2.151e-01, Validation Loss: 6.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11973, Training Loss: 2.151e-01, Validation Loss: 6.157e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11974, Training Loss: 2.151e-01, Validation Loss: 6.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11975, Training Loss: 2.151e-01, Validation Loss: 6.157e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11976, Training Loss: 2.151e-01, Validation Loss: 6.157e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11977, Training Loss: 2.150e-01, Validation Loss: 6.157e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11978, Training Loss: 2.150e-01, Validation Loss: 6.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11979, Training Loss: 2.150e-01, Validation Loss: 6.156e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11980, Training Loss: 2.150e-01, Validation Loss: 6.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11981, Training Loss: 2.149e-01, Validation Loss: 6.156e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11982, Training Loss: 2.149e-01, Validation Loss: 6.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11983, Training Loss: 2.149e-01, Validation Loss: 6.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11984, Training Loss: 2.149e-01, Validation Loss: 6.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11985, Training Loss: 2.148e-01, Validation Loss: 6.156e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11986, Training Loss: 2.148e-01, Validation Loss: 6.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11987, Training Loss: 2.148e-01, Validation Loss: 6.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11988, Training Loss: 2.148e-01, Validation Loss: 6.155e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11989, Training Loss: 2.148e-01, Validation Loss: 6.155e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11990, Training Loss: 2.147e-01, Validation Loss: 6.155e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11991, Training Loss: 2.147e-01, Validation Loss: 6.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11992, Training Loss: 2.147e-01, Validation Loss: 6.154e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11993, Training Loss: 2.147e-01, Validation Loss: 6.155e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 11994, Training Loss: 2.146e-01, Validation Loss: 6.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11995, Training Loss: 2.146e-01, Validation Loss: 6.154e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 11996, Training Loss: 2.146e-01, Validation Loss: 6.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11997, Training Loss: 2.146e-01, Validation Loss: 6.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11998, Training Loss: 2.146e-01, Validation Loss: 6.154e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 11999, Training Loss: 2.145e-01, Validation Loss: 6.154e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12000, Training Loss: 2.145e-01, Validation Loss: 6.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12001, Training Loss: 2.145e-01, Validation Loss: 6.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12002, Training Loss: 2.145e-01, Validation Loss: 6.153e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12003, Training Loss: 2.144e-01, Validation Loss: 6.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12004, Training Loss: 2.144e-01, Validation Loss: 6.153e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12005, Training Loss: 2.144e-01, Validation Loss: 6.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12006, Training Loss: 2.144e-01, Validation Loss: 6.153e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12007, Training Loss: 2.143e-01, Validation Loss: 6.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12008, Training Loss: 2.143e-01, Validation Loss: 6.152e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12009, Training Loss: 2.143e-01, Validation Loss: 6.152e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 12010, Training Loss: 2.143e-01, Validation Loss: 6.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12011, Training Loss: 2.143e-01, Validation Loss: 6.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12012, Training Loss: 2.142e-01, Validation Loss: 6.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12013, Training Loss: 2.142e-01, Validation Loss: 6.152e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12014, Training Loss: 2.142e-01, Validation Loss: 6.152e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12015, Training Loss: 2.142e-01, Validation Loss: 6.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12016, Training Loss: 2.141e-01, Validation Loss: 6.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12017, Training Loss: 2.141e-01, Validation Loss: 6.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12018, Training Loss: 2.141e-01, Validation Loss: 6.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12019, Training Loss: 2.141e-01, Validation Loss: 6.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12020, Training Loss: 2.141e-01, Validation Loss: 6.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12021, Training Loss: 2.140e-01, Validation Loss: 6.151e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12022, Training Loss: 2.140e-01, Validation Loss: 6.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12023, Training Loss: 2.140e-01, Validation Loss: 6.150e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12024, Training Loss: 2.140e-01, Validation Loss: 6.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12025, Training Loss: 2.139e-01, Validation Loss: 6.150e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12026, Training Loss: 2.139e-01, Validation Loss: 6.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12027, Training Loss: 2.139e-01, Validation Loss: 6.150e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12028, Training Loss: 2.139e-01, Validation Loss: 6.150e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12029, Training Loss: 2.138e-01, Validation Loss: 6.150e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12030, Training Loss: 2.138e-01, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12031, Training Loss: 2.138e-01, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12032, Training Loss: 2.138e-01, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12033, Training Loss: 2.138e-01, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12034, Training Loss: 2.137e-01, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12035, Training Loss: 2.137e-01, Validation Loss: 6.149e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12036, Training Loss: 2.137e-01, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12037, Training Loss: 2.137e-01, Validation Loss: 6.149e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12038, Training Loss: 2.136e-01, Validation Loss: 6.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12039, Training Loss: 2.136e-01, Validation Loss: 6.148e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12040, Training Loss: 2.136e-01, Validation Loss: 6.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12041, Training Loss: 2.136e-01, Validation Loss: 6.148e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12042, Training Loss: 2.136e-01, Validation Loss: 6.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12043, Training Loss: 2.135e-01, Validation Loss: 6.148e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12044, Training Loss: 2.135e-01, Validation Loss: 6.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12045, Training Loss: 2.135e-01, Validation Loss: 6.148e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12046, Training Loss: 2.135e-01, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12047, Training Loss: 2.134e-01, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12048, Training Loss: 2.134e-01, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12049, Training Loss: 2.134e-01, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12050, Training Loss: 2.134e-01, Validation Loss: 6.147e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12051, Training Loss: 2.133e-01, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12052, Training Loss: 2.133e-01, Validation Loss: 6.147e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12053, Training Loss: 2.133e-01, Validation Loss: 6.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12054, Training Loss: 2.133e-01, Validation Loss: 6.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12055, Training Loss: 2.133e-01, Validation Loss: 6.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12056, Training Loss: 2.132e-01, Validation Loss: 6.146e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12057, Training Loss: 2.132e-01, Validation Loss: 6.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12058, Training Loss: 2.132e-01, Validation Loss: 6.146e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12059, Training Loss: 2.132e-01, Validation Loss: 6.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12060, Training Loss: 2.131e-01, Validation Loss: 6.146e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12061, Training Loss: 2.131e-01, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12062, Training Loss: 2.131e-01, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12063, Training Loss: 2.131e-01, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12064, Training Loss: 2.131e-01, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12065, Training Loss: 2.130e-01, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12066, Training Loss: 2.130e-01, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12067, Training Loss: 2.130e-01, Validation Loss: 6.145e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12068, Training Loss: 2.130e-01, Validation Loss: 6.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12069, Training Loss: 2.129e-01, Validation Loss: 6.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12070, Training Loss: 2.129e-01, Validation Loss: 6.144e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12071, Training Loss: 2.129e-01, Validation Loss: 6.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12072, Training Loss: 2.129e-01, Validation Loss: 6.144e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12073, Training Loss: 2.129e-01, Validation Loss: 6.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12074, Training Loss: 2.128e-01, Validation Loss: 6.144e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12075, Training Loss: 2.128e-01, Validation Loss: 6.144e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12076, Training Loss: 2.128e-01, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12077, Training Loss: 2.128e-01, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12078, Training Loss: 2.127e-01, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12079, Training Loss: 2.127e-01, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12080, Training Loss: 2.127e-01, Validation Loss: 6.143e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12081, Training Loss: 2.127e-01, Validation Loss: 6.143e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12082, Training Loss: 2.126e-01, Validation Loss: 6.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12083, Training Loss: 2.126e-01, Validation Loss: 6.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12084, Training Loss: 2.126e-01, Validation Loss: 6.142e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12085, Training Loss: 2.126e-01, Validation Loss: 6.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12086, Training Loss: 2.126e-01, Validation Loss: 6.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12087, Training Loss: 2.125e-01, Validation Loss: 6.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12088, Training Loss: 2.125e-01, Validation Loss: 6.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12089, Training Loss: 2.125e-01, Validation Loss: 6.142e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12090, Training Loss: 2.125e-01, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12091, Training Loss: 2.124e-01, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12092, Training Loss: 2.124e-01, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12093, Training Loss: 2.124e-01, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12094, Training Loss: 2.124e-01, Validation Loss: 6.141e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12095, Training Loss: 2.124e-01, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12096, Training Loss: 2.123e-01, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12097, Training Loss: 2.123e-01, Validation Loss: 6.141e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12098, Training Loss: 2.123e-01, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12099, Training Loss: 2.123e-01, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12100, Training Loss: 2.122e-01, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12101, Training Loss: 2.122e-01, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12102, Training Loss: 2.122e-01, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12103, Training Loss: 2.122e-01, Validation Loss: 6.140e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12104, Training Loss: 2.122e-01, Validation Loss: 6.140e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12105, Training Loss: 2.121e-01, Validation Loss: 6.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12106, Training Loss: 2.121e-01, Validation Loss: 6.140e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12107, Training Loss: 2.121e-01, Validation Loss: 6.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12108, Training Loss: 2.121e-01, Validation Loss: 6.139e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12109, Training Loss: 2.120e-01, Validation Loss: 6.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12110, Training Loss: 2.120e-01, Validation Loss: 6.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12111, Training Loss: 2.120e-01, Validation Loss: 6.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12112, Training Loss: 2.120e-01, Validation Loss: 6.139e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12113, Training Loss: 2.120e-01, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12114, Training Loss: 2.119e-01, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12115, Training Loss: 2.119e-01, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12116, Training Loss: 2.119e-01, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12117, Training Loss: 2.119e-01, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12118, Training Loss: 2.118e-01, Validation Loss: 6.138e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12119, Training Loss: 2.118e-01, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12120, Training Loss: 2.118e-01, Validation Loss: 6.138e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12121, Training Loss: 2.118e-01, Validation Loss: 6.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12122, Training Loss: 2.118e-01, Validation Loss: 6.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12123, Training Loss: 2.117e-01, Validation Loss: 6.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12124, Training Loss: 2.117e-01, Validation Loss: 6.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12125, Training Loss: 2.117e-01, Validation Loss: 6.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12126, Training Loss: 2.117e-01, Validation Loss: 6.137e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12127, Training Loss: 2.116e-01, Validation Loss: 6.137e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12128, Training Loss: 2.116e-01, Validation Loss: 6.137e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12129, Training Loss: 2.116e-01, Validation Loss: 6.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12130, Training Loss: 2.116e-01, Validation Loss: 6.136e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12131, Training Loss: 2.116e-01, Validation Loss: 6.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12132, Training Loss: 2.115e-01, Validation Loss: 6.136e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12133, Training Loss: 2.115e-01, Validation Loss: 6.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12134, Training Loss: 2.115e-01, Validation Loss: 6.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12135, Training Loss: 2.115e-01, Validation Loss: 6.136e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12136, Training Loss: 2.114e-01, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12137, Training Loss: 2.114e-01, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12138, Training Loss: 2.114e-01, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12139, Training Loss: 2.114e-01, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12140, Training Loss: 2.114e-01, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12141, Training Loss: 2.113e-01, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12142, Training Loss: 2.113e-01, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12143, Training Loss: 2.113e-01, Validation Loss: 6.135e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12144, Training Loss: 2.113e-01, Validation Loss: 6.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12145, Training Loss: 2.112e-01, Validation Loss: 6.134e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12146, Training Loss: 2.112e-01, Validation Loss: 6.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12147, Training Loss: 2.112e-01, Validation Loss: 6.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12148, Training Loss: 2.112e-01, Validation Loss: 6.134e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12149, Training Loss: 2.111e-01, Validation Loss: 6.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12150, Training Loss: 2.111e-01, Validation Loss: 6.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12151, Training Loss: 2.111e-01, Validation Loss: 6.134e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12152, Training Loss: 2.111e-01, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12153, Training Loss: 2.111e-01, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12154, Training Loss: 2.110e-01, Validation Loss: 6.133e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12155, Training Loss: 2.110e-01, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12156, Training Loss: 2.110e-01, Validation Loss: 6.133e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12157, Training Loss: 2.110e-01, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12158, Training Loss: 2.110e-01, Validation Loss: 6.133e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12159, Training Loss: 2.109e-01, Validation Loss: 6.133e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12160, Training Loss: 2.109e-01, Validation Loss: 6.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12161, Training Loss: 2.109e-01, Validation Loss: 6.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12162, Training Loss: 2.109e-01, Validation Loss: 6.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12163, Training Loss: 2.108e-01, Validation Loss: 6.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12164, Training Loss: 2.108e-01, Validation Loss: 6.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12165, Training Loss: 2.108e-01, Validation Loss: 6.132e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12166, Training Loss: 2.108e-01, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12167, Training Loss: 2.108e-01, Validation Loss: 6.131e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12168, Training Loss: 2.107e-01, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12169, Training Loss: 2.107e-01, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12170, Training Loss: 2.107e-01, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12171, Training Loss: 2.107e-01, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12172, Training Loss: 2.106e-01, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12173, Training Loss: 2.106e-01, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12174, Training Loss: 2.106e-01, Validation Loss: 6.131e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12175, Training Loss: 2.106e-01, Validation Loss: 6.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12176, Training Loss: 2.106e-01, Validation Loss: 6.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12177, Training Loss: 2.105e-01, Validation Loss: 6.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12178, Training Loss: 2.105e-01, Validation Loss: 6.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12179, Training Loss: 2.105e-01, Validation Loss: 6.130e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12180, Training Loss: 2.105e-01, Validation Loss: 6.130e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12181, Training Loss: 2.104e-01, Validation Loss: 6.130e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 12182, Training Loss: 2.104e-01, Validation Loss: 6.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12183, Training Loss: 2.104e-01, Validation Loss: 6.130e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12184, Training Loss: 2.104e-01, Validation Loss: 6.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12185, Training Loss: 2.104e-01, Validation Loss: 6.129e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12186, Training Loss: 2.103e-01, Validation Loss: 6.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12187, Training Loss: 2.103e-01, Validation Loss: 6.129e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12188, Training Loss: 2.103e-01, Validation Loss: 6.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12189, Training Loss: 2.103e-01, Validation Loss: 6.129e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12190, Training Loss: 2.102e-01, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12191, Training Loss: 2.102e-01, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12192, Training Loss: 2.102e-01, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12193, Training Loss: 2.102e-01, Validation Loss: 6.128e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12194, Training Loss: 2.102e-01, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12195, Training Loss: 2.101e-01, Validation Loss: 6.128e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12196, Training Loss: 2.101e-01, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12197, Training Loss: 2.101e-01, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12198, Training Loss: 2.101e-01, Validation Loss: 6.128e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12199, Training Loss: 2.100e-01, Validation Loss: 6.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12200, Training Loss: 2.100e-01, Validation Loss: 6.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12201, Training Loss: 2.100e-01, Validation Loss: 6.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12202, Training Loss: 2.100e-01, Validation Loss: 6.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12203, Training Loss: 2.100e-01, Validation Loss: 6.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12204, Training Loss: 2.099e-01, Validation Loss: 6.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12205, Training Loss: 2.099e-01, Validation Loss: 6.127e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12206, Training Loss: 2.099e-01, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12207, Training Loss: 2.099e-01, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12208, Training Loss: 2.098e-01, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12209, Training Loss: 2.098e-01, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12210, Training Loss: 2.098e-01, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12211, Training Loss: 2.098e-01, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12212, Training Loss: 2.098e-01, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12213, Training Loss: 2.097e-01, Validation Loss: 6.126e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12214, Training Loss: 2.097e-01, Validation Loss: 6.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12215, Training Loss: 2.097e-01, Validation Loss: 6.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12216, Training Loss: 2.097e-01, Validation Loss: 6.125e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12217, Training Loss: 2.096e-01, Validation Loss: 6.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12218, Training Loss: 2.096e-01, Validation Loss: 6.125e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12219, Training Loss: 2.096e-01, Validation Loss: 6.125e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12220, Training Loss: 2.096e-01, Validation Loss: 6.125e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12221, Training Loss: 2.096e-01, Validation Loss: 6.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12222, Training Loss: 2.095e-01, Validation Loss: 6.124e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12223, Training Loss: 2.095e-01, Validation Loss: 6.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12224, Training Loss: 2.095e-01, Validation Loss: 6.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12225, Training Loss: 2.095e-01, Validation Loss: 6.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12226, Training Loss: 2.094e-01, Validation Loss: 6.124e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12227, Training Loss: 2.094e-01, Validation Loss: 6.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12228, Training Loss: 2.094e-01, Validation Loss: 6.124e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12229, Training Loss: 2.094e-01, Validation Loss: 6.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12230, Training Loss: 2.094e-01, Validation Loss: 6.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12231, Training Loss: 2.093e-01, Validation Loss: 6.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12232, Training Loss: 2.093e-01, Validation Loss: 6.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12233, Training Loss: 2.093e-01, Validation Loss: 6.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12234, Training Loss: 2.093e-01, Validation Loss: 6.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12235, Training Loss: 2.092e-01, Validation Loss: 6.123e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12236, Training Loss: 2.092e-01, Validation Loss: 6.123e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12237, Training Loss: 2.092e-01, Validation Loss: 6.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12238, Training Loss: 2.092e-01, Validation Loss: 6.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12239, Training Loss: 2.092e-01, Validation Loss: 6.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12240, Training Loss: 2.091e-01, Validation Loss: 6.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12241, Training Loss: 2.091e-01, Validation Loss: 6.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12242, Training Loss: 2.091e-01, Validation Loss: 6.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12243, Training Loss: 2.091e-01, Validation Loss: 6.122e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12244, Training Loss: 2.091e-01, Validation Loss: 6.122e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12245, Training Loss: 2.090e-01, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12246, Training Loss: 2.090e-01, Validation Loss: 6.121e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12247, Training Loss: 2.090e-01, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12248, Training Loss: 2.090e-01, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12249, Training Loss: 2.089e-01, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12250, Training Loss: 2.089e-01, Validation Loss: 6.121e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12251, Training Loss: 2.089e-01, Validation Loss: 6.121e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12252, Training Loss: 2.089e-01, Validation Loss: 6.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12253, Training Loss: 2.089e-01, Validation Loss: 6.120e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12254, Training Loss: 2.088e-01, Validation Loss: 6.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12255, Training Loss: 2.088e-01, Validation Loss: 6.120e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12256, Training Loss: 2.088e-01, Validation Loss: 6.120e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12257, Training Loss: 2.088e-01, Validation Loss: 6.120e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12258, Training Loss: 2.087e-01, Validation Loss: 6.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12259, Training Loss: 2.087e-01, Validation Loss: 6.120e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12260, Training Loss: 2.087e-01, Validation Loss: 6.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12261, Training Loss: 2.087e-01, Validation Loss: 6.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12262, Training Loss: 2.087e-01, Validation Loss: 6.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12263, Training Loss: 2.086e-01, Validation Loss: 6.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12264, Training Loss: 2.086e-01, Validation Loss: 6.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12265, Training Loss: 2.086e-01, Validation Loss: 6.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12266, Training Loss: 2.086e-01, Validation Loss: 6.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12267, Training Loss: 2.085e-01, Validation Loss: 6.119e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12268, Training Loss: 2.085e-01, Validation Loss: 6.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12269, Training Loss: 2.085e-01, Validation Loss: 6.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12270, Training Loss: 2.085e-01, Validation Loss: 6.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12271, Training Loss: 2.085e-01, Validation Loss: 6.118e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12272, Training Loss: 2.084e-01, Validation Loss: 6.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12273, Training Loss: 2.084e-01, Validation Loss: 6.118e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12274, Training Loss: 2.084e-01, Validation Loss: 6.118e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12275, Training Loss: 2.084e-01, Validation Loss: 6.118e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12276, Training Loss: 2.084e-01, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12277, Training Loss: 2.083e-01, Validation Loss: 6.117e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12278, Training Loss: 2.083e-01, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12279, Training Loss: 2.083e-01, Validation Loss: 6.117e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12280, Training Loss: 2.083e-01, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12281, Training Loss: 2.082e-01, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12282, Training Loss: 2.082e-01, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12283, Training Loss: 2.082e-01, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12284, Training Loss: 2.082e-01, Validation Loss: 6.117e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12285, Training Loss: 2.082e-01, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12286, Training Loss: 2.081e-01, Validation Loss: 6.116e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12287, Training Loss: 2.081e-01, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12288, Training Loss: 2.081e-01, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12289, Training Loss: 2.081e-01, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12290, Training Loss: 2.080e-01, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12291, Training Loss: 2.080e-01, Validation Loss: 6.116e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12292, Training Loss: 2.080e-01, Validation Loss: 6.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12293, Training Loss: 2.080e-01, Validation Loss: 6.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12294, Training Loss: 2.080e-01, Validation Loss: 6.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12295, Training Loss: 2.079e-01, Validation Loss: 6.115e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12296, Training Loss: 2.079e-01, Validation Loss: 6.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12297, Training Loss: 2.079e-01, Validation Loss: 6.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12298, Training Loss: 2.079e-01, Validation Loss: 6.115e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12299, Training Loss: 2.079e-01, Validation Loss: 6.115e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12300, Training Loss: 2.078e-01, Validation Loss: 6.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12301, Training Loss: 2.078e-01, Validation Loss: 6.114e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12302, Training Loss: 2.078e-01, Validation Loss: 6.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12303, Training Loss: 2.078e-01, Validation Loss: 6.114e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12304, Training Loss: 2.077e-01, Validation Loss: 6.114e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12305, Training Loss: 2.077e-01, Validation Loss: 6.114e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12306, Training Loss: 2.077e-01, Validation Loss: 6.114e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 12307, Training Loss: 2.077e-01, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12308, Training Loss: 2.077e-01, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12309, Training Loss: 2.076e-01, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12310, Training Loss: 2.076e-01, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12311, Training Loss: 2.076e-01, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12312, Training Loss: 2.076e-01, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12313, Training Loss: 2.075e-01, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12314, Training Loss: 2.075e-01, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12315, Training Loss: 2.075e-01, Validation Loss: 6.113e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12316, Training Loss: 2.075e-01, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12317, Training Loss: 2.075e-01, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12318, Training Loss: 2.074e-01, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12319, Training Loss: 2.074e-01, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12320, Training Loss: 2.074e-01, Validation Loss: 6.112e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12321, Training Loss: 2.074e-01, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12322, Training Loss: 2.074e-01, Validation Loss: 6.112e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12323, Training Loss: 2.073e-01, Validation Loss: 6.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12324, Training Loss: 2.073e-01, Validation Loss: 6.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12325, Training Loss: 2.073e-01, Validation Loss: 6.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12326, Training Loss: 2.073e-01, Validation Loss: 6.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12327, Training Loss: 2.072e-01, Validation Loss: 6.111e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12328, Training Loss: 2.072e-01, Validation Loss: 6.111e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12329, Training Loss: 2.072e-01, Validation Loss: 6.111e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12330, Training Loss: 2.072e-01, Validation Loss: 6.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12331, Training Loss: 2.072e-01, Validation Loss: 6.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12332, Training Loss: 2.071e-01, Validation Loss: 6.110e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12333, Training Loss: 2.071e-01, Validation Loss: 6.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12334, Training Loss: 2.071e-01, Validation Loss: 6.110e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12335, Training Loss: 2.071e-01, Validation Loss: 6.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12336, Training Loss: 2.070e-01, Validation Loss: 6.110e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12337, Training Loss: 2.070e-01, Validation Loss: 6.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12338, Training Loss: 2.070e-01, Validation Loss: 6.110e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12339, Training Loss: 2.070e-01, Validation Loss: 6.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12340, Training Loss: 2.070e-01, Validation Loss: 6.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12341, Training Loss: 2.069e-01, Validation Loss: 6.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12342, Training Loss: 2.069e-01, Validation Loss: 6.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12343, Training Loss: 2.069e-01, Validation Loss: 6.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12344, Training Loss: 2.069e-01, Validation Loss: 6.109e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12345, Training Loss: 2.069e-01, Validation Loss: 6.109e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12346, Training Loss: 2.068e-01, Validation Loss: 6.109e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12347, Training Loss: 2.068e-01, Validation Loss: 6.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12348, Training Loss: 2.068e-01, Validation Loss: 6.108e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12349, Training Loss: 2.068e-01, Validation Loss: 6.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12350, Training Loss: 2.067e-01, Validation Loss: 6.108e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12351, Training Loss: 2.067e-01, Validation Loss: 6.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12352, Training Loss: 2.067e-01, Validation Loss: 6.108e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12353, Training Loss: 2.067e-01, Validation Loss: 6.108e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12354, Training Loss: 2.067e-01, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12355, Training Loss: 2.066e-01, Validation Loss: 6.107e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12356, Training Loss: 2.066e-01, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12357, Training Loss: 2.066e-01, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12358, Training Loss: 2.066e-01, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12359, Training Loss: 2.066e-01, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12360, Training Loss: 2.065e-01, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12361, Training Loss: 2.065e-01, Validation Loss: 6.107e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12362, Training Loss: 2.065e-01, Validation Loss: 6.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12363, Training Loss: 2.065e-01, Validation Loss: 6.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12364, Training Loss: 2.064e-01, Validation Loss: 6.106e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12365, Training Loss: 2.064e-01, Validation Loss: 6.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12366, Training Loss: 2.064e-01, Validation Loss: 6.106e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12367, Training Loss: 2.064e-01, Validation Loss: 6.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12368, Training Loss: 2.064e-01, Validation Loss: 6.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12369, Training Loss: 2.063e-01, Validation Loss: 6.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12370, Training Loss: 2.063e-01, Validation Loss: 6.106e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12371, Training Loss: 2.063e-01, Validation Loss: 6.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12372, Training Loss: 2.063e-01, Validation Loss: 6.105e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12373, Training Loss: 2.063e-01, Validation Loss: 6.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12374, Training Loss: 2.062e-01, Validation Loss: 6.105e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12375, Training Loss: 2.062e-01, Validation Loss: 6.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12376, Training Loss: 2.062e-01, Validation Loss: 6.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12377, Training Loss: 2.062e-01, Validation Loss: 6.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12378, Training Loss: 2.061e-01, Validation Loss: 6.105e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12379, Training Loss: 2.061e-01, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12380, Training Loss: 2.061e-01, Validation Loss: 6.104e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12381, Training Loss: 2.061e-01, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12382, Training Loss: 2.061e-01, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12383, Training Loss: 2.060e-01, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12384, Training Loss: 2.060e-01, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12385, Training Loss: 2.060e-01, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12386, Training Loss: 2.060e-01, Validation Loss: 6.104e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12387, Training Loss: 2.059e-01, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12388, Training Loss: 2.059e-01, Validation Loss: 6.103e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12389, Training Loss: 2.059e-01, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12390, Training Loss: 2.059e-01, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12391, Training Loss: 2.059e-01, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12392, Training Loss: 2.058e-01, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12393, Training Loss: 2.058e-01, Validation Loss: 6.103e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12394, Training Loss: 2.058e-01, Validation Loss: 6.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12395, Training Loss: 2.058e-01, Validation Loss: 6.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12396, Training Loss: 2.058e-01, Validation Loss: 6.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12397, Training Loss: 2.057e-01, Validation Loss: 6.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12398, Training Loss: 2.057e-01, Validation Loss: 6.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12399, Training Loss: 2.057e-01, Validation Loss: 6.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12400, Training Loss: 2.057e-01, Validation Loss: 6.102e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12401, Training Loss: 2.056e-01, Validation Loss: 6.102e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12402, Training Loss: 2.056e-01, Validation Loss: 6.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12403, Training Loss: 2.056e-01, Validation Loss: 6.101e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12404, Training Loss: 2.056e-01, Validation Loss: 6.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12405, Training Loss: 2.056e-01, Validation Loss: 6.101e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12406, Training Loss: 2.055e-01, Validation Loss: 6.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12407, Training Loss: 2.055e-01, Validation Loss: 6.101e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12408, Training Loss: 2.055e-01, Validation Loss: 6.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12409, Training Loss: 2.055e-01, Validation Loss: 6.101e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12410, Training Loss: 2.055e-01, Validation Loss: 6.101e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12411, Training Loss: 2.054e-01, Validation Loss: 6.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12412, Training Loss: 2.054e-01, Validation Loss: 6.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12413, Training Loss: 2.054e-01, Validation Loss: 6.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12414, Training Loss: 2.054e-01, Validation Loss: 6.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12415, Training Loss: 2.054e-01, Validation Loss: 6.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12416, Training Loss: 2.053e-01, Validation Loss: 6.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12417, Training Loss: 2.053e-01, Validation Loss: 6.100e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12418, Training Loss: 2.053e-01, Validation Loss: 6.100e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12419, Training Loss: 2.053e-01, Validation Loss: 6.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12420, Training Loss: 2.052e-01, Validation Loss: 6.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12421, Training Loss: 2.052e-01, Validation Loss: 6.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12422, Training Loss: 2.052e-01, Validation Loss: 6.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12423, Training Loss: 2.052e-01, Validation Loss: 6.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12424, Training Loss: 2.052e-01, Validation Loss: 6.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12425, Training Loss: 2.051e-01, Validation Loss: 6.099e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12426, Training Loss: 2.051e-01, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12427, Training Loss: 2.051e-01, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12428, Training Loss: 2.051e-01, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12429, Training Loss: 2.051e-01, Validation Loss: 6.098e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12430, Training Loss: 2.050e-01, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12431, Training Loss: 2.050e-01, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12432, Training Loss: 2.050e-01, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12433, Training Loss: 2.050e-01, Validation Loss: 6.098e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12434, Training Loss: 2.049e-01, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12435, Training Loss: 2.049e-01, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12436, Training Loss: 2.049e-01, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12437, Training Loss: 2.049e-01, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12438, Training Loss: 2.049e-01, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12439, Training Loss: 2.048e-01, Validation Loss: 6.097e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12440, Training Loss: 2.048e-01, Validation Loss: 6.097e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12441, Training Loss: 2.048e-01, Validation Loss: 6.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12442, Training Loss: 2.048e-01, Validation Loss: 6.096e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12443, Training Loss: 2.048e-01, Validation Loss: 6.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12444, Training Loss: 2.047e-01, Validation Loss: 6.096e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12445, Training Loss: 2.047e-01, Validation Loss: 6.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12446, Training Loss: 2.047e-01, Validation Loss: 6.096e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12447, Training Loss: 2.047e-01, Validation Loss: 6.096e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12448, Training Loss: 2.046e-01, Validation Loss: 6.096e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12449, Training Loss: 2.046e-01, Validation Loss: 6.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12450, Training Loss: 2.046e-01, Validation Loss: 6.096e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12451, Training Loss: 2.046e-01, Validation Loss: 6.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12452, Training Loss: 2.046e-01, Validation Loss: 6.095e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12453, Training Loss: 2.045e-01, Validation Loss: 6.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12454, Training Loss: 2.045e-01, Validation Loss: 6.095e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12455, Training Loss: 2.045e-01, Validation Loss: 6.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12456, Training Loss: 2.045e-01, Validation Loss: 6.095e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12457, Training Loss: 2.045e-01, Validation Loss: 6.095e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12458, Training Loss: 2.044e-01, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12459, Training Loss: 2.044e-01, Validation Loss: 6.094e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12460, Training Loss: 2.044e-01, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12461, Training Loss: 2.044e-01, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12462, Training Loss: 2.044e-01, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12463, Training Loss: 2.043e-01, Validation Loss: 6.094e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12464, Training Loss: 2.043e-01, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12465, Training Loss: 2.043e-01, Validation Loss: 6.094e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12466, Training Loss: 2.043e-01, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12467, Training Loss: 2.042e-01, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12468, Training Loss: 2.042e-01, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12469, Training Loss: 2.042e-01, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12470, Training Loss: 2.042e-01, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12471, Training Loss: 2.042e-01, Validation Loss: 6.093e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12472, Training Loss: 2.041e-01, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12473, Training Loss: 2.041e-01, Validation Loss: 6.093e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12474, Training Loss: 2.041e-01, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12475, Training Loss: 2.041e-01, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12476, Training Loss: 2.041e-01, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12477, Training Loss: 2.040e-01, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12478, Training Loss: 2.040e-01, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12479, Training Loss: 2.040e-01, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12480, Training Loss: 2.040e-01, Validation Loss: 6.092e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12481, Training Loss: 2.039e-01, Validation Loss: 6.092e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12482, Training Loss: 2.039e-01, Validation Loss: 6.092e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12483, Training Loss: 2.039e-01, Validation Loss: 6.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12484, Training Loss: 2.039e-01, Validation Loss: 6.091e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12485, Training Loss: 2.039e-01, Validation Loss: 6.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12486, Training Loss: 2.038e-01, Validation Loss: 6.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12487, Training Loss: 2.038e-01, Validation Loss: 6.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12488, Training Loss: 2.038e-01, Validation Loss: 6.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12489, Training Loss: 2.038e-01, Validation Loss: 6.091e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12490, Training Loss: 2.038e-01, Validation Loss: 6.091e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12491, Training Loss: 2.037e-01, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12492, Training Loss: 2.037e-01, Validation Loss: 6.090e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12493, Training Loss: 2.037e-01, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12494, Training Loss: 2.037e-01, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12495, Training Loss: 2.037e-01, Validation Loss: 6.090e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12496, Training Loss: 2.036e-01, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12497, Training Loss: 2.036e-01, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12498, Training Loss: 2.036e-01, Validation Loss: 6.090e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12499, Training Loss: 2.036e-01, Validation Loss: 6.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12500, Training Loss: 2.035e-01, Validation Loss: 6.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12501, Training Loss: 2.035e-01, Validation Loss: 6.089e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12502, Training Loss: 2.035e-01, Validation Loss: 6.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12503, Training Loss: 2.035e-01, Validation Loss: 6.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12504, Training Loss: 2.035e-01, Validation Loss: 6.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12505, Training Loss: 2.034e-01, Validation Loss: 6.089e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12506, Training Loss: 2.034e-01, Validation Loss: 6.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12507, Training Loss: 2.034e-01, Validation Loss: 6.089e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12508, Training Loss: 2.034e-01, Validation Loss: 6.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12509, Training Loss: 2.034e-01, Validation Loss: 6.088e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12510, Training Loss: 2.033e-01, Validation Loss: 6.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12511, Training Loss: 2.033e-01, Validation Loss: 6.088e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12512, Training Loss: 2.033e-01, Validation Loss: 6.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12513, Training Loss: 2.033e-01, Validation Loss: 6.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12514, Training Loss: 2.033e-01, Validation Loss: 6.088e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12515, Training Loss: 2.032e-01, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12516, Training Loss: 2.032e-01, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12517, Training Loss: 2.032e-01, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12518, Training Loss: 2.032e-01, Validation Loss: 6.087e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12519, Training Loss: 2.031e-01, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12520, Training Loss: 2.031e-01, Validation Loss: 6.087e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12521, Training Loss: 2.031e-01, Validation Loss: 6.087e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12522, Training Loss: 2.031e-01, Validation Loss: 6.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12523, Training Loss: 2.031e-01, Validation Loss: 6.087e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12524, Training Loss: 2.030e-01, Validation Loss: 6.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12525, Training Loss: 2.030e-01, Validation Loss: 6.086e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12526, Training Loss: 2.030e-01, Validation Loss: 6.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12527, Training Loss: 2.030e-01, Validation Loss: 6.086e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12528, Training Loss: 2.030e-01, Validation Loss: 6.086e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 12529, Training Loss: 2.029e-01, Validation Loss: 6.086e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12530, Training Loss: 2.029e-01, Validation Loss: 6.086e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12531, Training Loss: 2.029e-01, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12532, Training Loss: 2.029e-01, Validation Loss: 6.085e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12533, Training Loss: 2.029e-01, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12534, Training Loss: 2.028e-01, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12535, Training Loss: 2.028e-01, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12536, Training Loss: 2.028e-01, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12537, Training Loss: 2.028e-01, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12538, Training Loss: 2.027e-01, Validation Loss: 6.085e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12539, Training Loss: 2.027e-01, Validation Loss: 6.085e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12540, Training Loss: 2.027e-01, Validation Loss: 6.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12541, Training Loss: 2.027e-01, Validation Loss: 6.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12542, Training Loss: 2.027e-01, Validation Loss: 6.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12543, Training Loss: 2.026e-01, Validation Loss: 6.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12544, Training Loss: 2.026e-01, Validation Loss: 6.084e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12545, Training Loss: 2.026e-01, Validation Loss: 6.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12546, Training Loss: 2.026e-01, Validation Loss: 6.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12547, Training Loss: 2.026e-01, Validation Loss: 6.084e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12548, Training Loss: 2.025e-01, Validation Loss: 6.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12549, Training Loss: 2.025e-01, Validation Loss: 6.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12550, Training Loss: 2.025e-01, Validation Loss: 6.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12551, Training Loss: 2.025e-01, Validation Loss: 6.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12552, Training Loss: 2.025e-01, Validation Loss: 6.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12553, Training Loss: 2.024e-01, Validation Loss: 6.083e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12554, Training Loss: 2.024e-01, Validation Loss: 6.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12555, Training Loss: 2.024e-01, Validation Loss: 6.083e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12556, Training Loss: 2.024e-01, Validation Loss: 6.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12557, Training Loss: 2.024e-01, Validation Loss: 6.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12558, Training Loss: 2.023e-01, Validation Loss: 6.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12559, Training Loss: 2.023e-01, Validation Loss: 6.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12560, Training Loss: 2.023e-01, Validation Loss: 6.082e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12561, Training Loss: 2.023e-01, Validation Loss: 6.082e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12562, Training Loss: 2.022e-01, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12563, Training Loss: 2.022e-01, Validation Loss: 6.082e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12564, Training Loss: 2.022e-01, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12565, Training Loss: 2.022e-01, Validation Loss: 6.081e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12566, Training Loss: 2.022e-01, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12567, Training Loss: 2.021e-01, Validation Loss: 6.081e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12568, Training Loss: 2.021e-01, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12569, Training Loss: 2.021e-01, Validation Loss: 6.081e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12570, Training Loss: 2.021e-01, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12571, Training Loss: 2.021e-01, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12572, Training Loss: 2.020e-01, Validation Loss: 6.081e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12573, Training Loss: 2.020e-01, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12574, Training Loss: 2.020e-01, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12575, Training Loss: 2.020e-01, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12576, Training Loss: 2.020e-01, Validation Loss: 6.080e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12577, Training Loss: 2.019e-01, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12578, Training Loss: 2.019e-01, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12579, Training Loss: 2.019e-01, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12580, Training Loss: 2.019e-01, Validation Loss: 6.080e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12581, Training Loss: 2.019e-01, Validation Loss: 6.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12582, Training Loss: 2.018e-01, Validation Loss: 6.079e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12583, Training Loss: 2.018e-01, Validation Loss: 6.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12584, Training Loss: 2.018e-01, Validation Loss: 6.079e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12585, Training Loss: 2.018e-01, Validation Loss: 6.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12586, Training Loss: 2.017e-01, Validation Loss: 6.079e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12587, Training Loss: 2.017e-01, Validation Loss: 6.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12588, Training Loss: 2.017e-01, Validation Loss: 6.079e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12589, Training Loss: 2.017e-01, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12590, Training Loss: 2.017e-01, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12591, Training Loss: 2.016e-01, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12592, Training Loss: 2.016e-01, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12593, Training Loss: 2.016e-01, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12594, Training Loss: 2.016e-01, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12595, Training Loss: 2.016e-01, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12596, Training Loss: 2.015e-01, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12597, Training Loss: 2.015e-01, Validation Loss: 6.078e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12598, Training Loss: 2.015e-01, Validation Loss: 6.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12599, Training Loss: 2.015e-01, Validation Loss: 6.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12600, Training Loss: 2.015e-01, Validation Loss: 6.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12601, Training Loss: 2.014e-01, Validation Loss: 6.077e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12602, Training Loss: 2.014e-01, Validation Loss: 6.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12603, Training Loss: 2.014e-01, Validation Loss: 6.077e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12604, Training Loss: 2.014e-01, Validation Loss: 6.077e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12605, Training Loss: 2.014e-01, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12606, Training Loss: 2.013e-01, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12607, Training Loss: 2.013e-01, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12608, Training Loss: 2.013e-01, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12609, Training Loss: 2.013e-01, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12610, Training Loss: 2.012e-01, Validation Loss: 6.076e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12611, Training Loss: 2.012e-01, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12612, Training Loss: 2.012e-01, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12613, Training Loss: 2.012e-01, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12614, Training Loss: 2.012e-01, Validation Loss: 6.076e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12615, Training Loss: 2.011e-01, Validation Loss: 6.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12616, Training Loss: 2.011e-01, Validation Loss: 6.075e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12617, Training Loss: 2.011e-01, Validation Loss: 6.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12618, Training Loss: 2.011e-01, Validation Loss: 6.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12619, Training Loss: 2.011e-01, Validation Loss: 6.075e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12620, Training Loss: 2.010e-01, Validation Loss: 6.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12621, Training Loss: 2.010e-01, Validation Loss: 6.075e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12622, Training Loss: 2.010e-01, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12623, Training Loss: 2.010e-01, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12624, Training Loss: 2.010e-01, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12625, Training Loss: 2.009e-01, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12626, Training Loss: 2.009e-01, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12627, Training Loss: 2.009e-01, Validation Loss: 6.074e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12628, Training Loss: 2.009e-01, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12629, Training Loss: 2.009e-01, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12630, Training Loss: 2.008e-01, Validation Loss: 6.074e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12631, Training Loss: 2.008e-01, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12632, Training Loss: 2.008e-01, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12633, Training Loss: 2.008e-01, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12634, Training Loss: 2.008e-01, Validation Loss: 6.073e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12635, Training Loss: 2.007e-01, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12636, Training Loss: 2.007e-01, Validation Loss: 6.073e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12637, Training Loss: 2.007e-01, Validation Loss: 6.073e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12638, Training Loss: 2.007e-01, Validation Loss: 6.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12639, Training Loss: 2.006e-01, Validation Loss: 6.072e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12640, Training Loss: 2.006e-01, Validation Loss: 6.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12641, Training Loss: 2.006e-01, Validation Loss: 6.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12642, Training Loss: 2.006e-01, Validation Loss: 6.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12643, Training Loss: 2.006e-01, Validation Loss: 6.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12644, Training Loss: 2.005e-01, Validation Loss: 6.072e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12645, Training Loss: 2.005e-01, Validation Loss: 6.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12646, Training Loss: 2.005e-01, Validation Loss: 6.072e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12647, Training Loss: 2.005e-01, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12648, Training Loss: 2.005e-01, Validation Loss: 6.071e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12649, Training Loss: 2.004e-01, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12650, Training Loss: 2.004e-01, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12651, Training Loss: 2.004e-01, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12652, Training Loss: 2.004e-01, Validation Loss: 6.071e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12653, Training Loss: 2.004e-01, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12654, Training Loss: 2.003e-01, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12655, Training Loss: 2.003e-01, Validation Loss: 6.071e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12656, Training Loss: 2.003e-01, Validation Loss: 6.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12657, Training Loss: 2.003e-01, Validation Loss: 6.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12658, Training Loss: 2.003e-01, Validation Loss: 6.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12659, Training Loss: 2.002e-01, Validation Loss: 6.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12660, Training Loss: 2.002e-01, Validation Loss: 6.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12661, Training Loss: 2.002e-01, Validation Loss: 6.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12662, Training Loss: 2.002e-01, Validation Loss: 6.070e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12663, Training Loss: 2.002e-01, Validation Loss: 6.070e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12664, Training Loss: 2.001e-01, Validation Loss: 6.070e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12665, Training Loss: 2.001e-01, Validation Loss: 6.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12666, Training Loss: 2.001e-01, Validation Loss: 6.069e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12667, Training Loss: 2.001e-01, Validation Loss: 6.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12668, Training Loss: 2.001e-01, Validation Loss: 6.069e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12669, Training Loss: 2.000e-01, Validation Loss: 6.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12670, Training Loss: 2.000e-01, Validation Loss: 6.069e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12671, Training Loss: 2.000e-01, Validation Loss: 6.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12672, Training Loss: 2.000e-01, Validation Loss: 6.069e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12673, Training Loss: 1.999e-01, Validation Loss: 6.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12674, Training Loss: 1.999e-01, Validation Loss: 6.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12675, Training Loss: 1.999e-01, Validation Loss: 6.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12676, Training Loss: 1.999e-01, Validation Loss: 6.068e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12677, Training Loss: 1.999e-01, Validation Loss: 6.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12678, Training Loss: 1.998e-01, Validation Loss: 6.068e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12679, Training Loss: 1.998e-01, Validation Loss: 6.068e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12680, Training Loss: 1.998e-01, Validation Loss: 6.068e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12681, Training Loss: 1.998e-01, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12682, Training Loss: 1.998e-01, Validation Loss: 6.068e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12683, Training Loss: 1.997e-01, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12684, Training Loss: 1.997e-01, Validation Loss: 6.067e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12685, Training Loss: 1.997e-01, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12686, Training Loss: 1.997e-01, Validation Loss: 6.067e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12687, Training Loss: 1.997e-01, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12688, Training Loss: 1.996e-01, Validation Loss: 6.067e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12689, Training Loss: 1.996e-01, Validation Loss: 6.067e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12690, Training Loss: 1.996e-01, Validation Loss: 6.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12691, Training Loss: 1.996e-01, Validation Loss: 6.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12692, Training Loss: 1.996e-01, Validation Loss: 6.066e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12693, Training Loss: 1.995e-01, Validation Loss: 6.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12694, Training Loss: 1.995e-01, Validation Loss: 6.066e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12695, Training Loss: 1.995e-01, Validation Loss: 6.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12696, Training Loss: 1.995e-01, Validation Loss: 6.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12697, Training Loss: 1.995e-01, Validation Loss: 6.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12698, Training Loss: 1.994e-01, Validation Loss: 6.066e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12699, Training Loss: 1.994e-01, Validation Loss: 6.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12700, Training Loss: 1.994e-01, Validation Loss: 6.065e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12701, Training Loss: 1.994e-01, Validation Loss: 6.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12702, Training Loss: 1.994e-01, Validation Loss: 6.065e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12703, Training Loss: 1.993e-01, Validation Loss: 6.065e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12704, Training Loss: 1.993e-01, Validation Loss: 6.065e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12705, Training Loss: 1.993e-01, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12706, Training Loss: 1.993e-01, Validation Loss: 6.065e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12707, Training Loss: 1.993e-01, Validation Loss: 6.065e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 12708, Training Loss: 1.992e-01, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12709, Training Loss: 1.992e-01, Validation Loss: 6.064e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12710, Training Loss: 1.992e-01, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12711, Training Loss: 1.992e-01, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12712, Training Loss: 1.992e-01, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12713, Training Loss: 1.991e-01, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12714, Training Loss: 1.991e-01, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12715, Training Loss: 1.991e-01, Validation Loss: 6.064e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12716, Training Loss: 1.991e-01, Validation Loss: 6.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12717, Training Loss: 1.990e-01, Validation Loss: 6.063e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12718, Training Loss: 1.990e-01, Validation Loss: 6.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12719, Training Loss: 1.990e-01, Validation Loss: 6.063e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12720, Training Loss: 1.990e-01, Validation Loss: 6.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12721, Training Loss: 1.990e-01, Validation Loss: 6.063e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12722, Training Loss: 1.989e-01, Validation Loss: 6.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12723, Training Loss: 1.989e-01, Validation Loss: 6.063e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12724, Training Loss: 1.989e-01, Validation Loss: 6.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12725, Training Loss: 1.989e-01, Validation Loss: 6.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12726, Training Loss: 1.989e-01, Validation Loss: 6.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12727, Training Loss: 1.988e-01, Validation Loss: 6.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12728, Training Loss: 1.988e-01, Validation Loss: 6.062e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12729, Training Loss: 1.988e-01, Validation Loss: 6.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12730, Training Loss: 1.988e-01, Validation Loss: 6.062e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12731, Training Loss: 1.988e-01, Validation Loss: 6.062e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12732, Training Loss: 1.987e-01, Validation Loss: 6.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12733, Training Loss: 1.987e-01, Validation Loss: 6.061e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12734, Training Loss: 1.987e-01, Validation Loss: 6.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12735, Training Loss: 1.987e-01, Validation Loss: 6.061e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12736, Training Loss: 1.987e-01, Validation Loss: 6.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12737, Training Loss: 1.986e-01, Validation Loss: 6.061e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12738, Training Loss: 1.986e-01, Validation Loss: 6.061e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12739, Training Loss: 1.986e-01, Validation Loss: 6.061e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12740, Training Loss: 1.986e-01, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12741, Training Loss: 1.986e-01, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12742, Training Loss: 1.985e-01, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12743, Training Loss: 1.985e-01, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12744, Training Loss: 1.985e-01, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12745, Training Loss: 1.985e-01, Validation Loss: 6.060e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12746, Training Loss: 1.985e-01, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12747, Training Loss: 1.984e-01, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12748, Training Loss: 1.984e-01, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12749, Training Loss: 1.984e-01, Validation Loss: 6.060e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12750, Training Loss: 1.984e-01, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12751, Training Loss: 1.984e-01, Validation Loss: 6.059e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12752, Training Loss: 1.983e-01, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12753, Training Loss: 1.983e-01, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12754, Training Loss: 1.983e-01, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12755, Training Loss: 1.983e-01, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12756, Training Loss: 1.983e-01, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12757, Training Loss: 1.982e-01, Validation Loss: 6.059e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12758, Training Loss: 1.982e-01, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12759, Training Loss: 1.982e-01, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12760, Training Loss: 1.982e-01, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12761, Training Loss: 1.982e-01, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12762, Training Loss: 1.981e-01, Validation Loss: 6.058e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12763, Training Loss: 1.981e-01, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12764, Training Loss: 1.981e-01, Validation Loss: 6.058e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12765, Training Loss: 1.981e-01, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12766, Training Loss: 1.981e-01, Validation Loss: 6.058e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12767, Training Loss: 1.980e-01, Validation Loss: 6.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12768, Training Loss: 1.980e-01, Validation Loss: 6.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12769, Training Loss: 1.980e-01, Validation Loss: 6.057e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12770, Training Loss: 1.980e-01, Validation Loss: 6.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12771, Training Loss: 1.980e-01, Validation Loss: 6.057e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12772, Training Loss: 1.979e-01, Validation Loss: 6.057e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12773, Training Loss: 1.979e-01, Validation Loss: 6.057e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12774, Training Loss: 1.979e-01, Validation Loss: 6.057e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 12775, Training Loss: 1.979e-01, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12776, Training Loss: 1.979e-01, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12777, Training Loss: 1.978e-01, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12778, Training Loss: 1.978e-01, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12779, Training Loss: 1.978e-01, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12780, Training Loss: 1.978e-01, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12781, Training Loss: 1.978e-01, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12782, Training Loss: 1.977e-01, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12783, Training Loss: 1.977e-01, Validation Loss: 6.056e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12784, Training Loss: 1.977e-01, Validation Loss: 6.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12785, Training Loss: 1.977e-01, Validation Loss: 6.056e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12786, Training Loss: 1.976e-01, Validation Loss: 6.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12787, Training Loss: 1.976e-01, Validation Loss: 6.055e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12788, Training Loss: 1.976e-01, Validation Loss: 6.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12789, Training Loss: 1.976e-01, Validation Loss: 6.055e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12790, Training Loss: 1.976e-01, Validation Loss: 6.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12791, Training Loss: 1.975e-01, Validation Loss: 6.055e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12792, Training Loss: 1.975e-01, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12793, Training Loss: 1.975e-01, Validation Loss: 6.054e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12794, Training Loss: 1.975e-01, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12795, Training Loss: 1.975e-01, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12796, Training Loss: 1.974e-01, Validation Loss: 6.054e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12797, Training Loss: 1.974e-01, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12798, Training Loss: 1.974e-01, Validation Loss: 6.054e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12799, Training Loss: 1.974e-01, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12800, Training Loss: 1.974e-01, Validation Loss: 6.054e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12801, Training Loss: 1.973e-01, Validation Loss: 6.054e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12802, Training Loss: 1.973e-01, Validation Loss: 6.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12803, Training Loss: 1.973e-01, Validation Loss: 6.053e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12804, Training Loss: 1.973e-01, Validation Loss: 6.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12805, Training Loss: 1.973e-01, Validation Loss: 6.053e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12806, Training Loss: 1.972e-01, Validation Loss: 6.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12807, Training Loss: 1.972e-01, Validation Loss: 6.053e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12808, Training Loss: 1.972e-01, Validation Loss: 6.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12809, Training Loss: 1.972e-01, Validation Loss: 6.053e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12810, Training Loss: 1.972e-01, Validation Loss: 6.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12811, Training Loss: 1.971e-01, Validation Loss: 6.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12812, Training Loss: 1.971e-01, Validation Loss: 6.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12813, Training Loss: 1.971e-01, Validation Loss: 6.052e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12814, Training Loss: 1.971e-01, Validation Loss: 6.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12815, Training Loss: 1.971e-01, Validation Loss: 6.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12816, Training Loss: 1.970e-01, Validation Loss: 6.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12817, Training Loss: 1.970e-01, Validation Loss: 6.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12818, Training Loss: 1.970e-01, Validation Loss: 6.052e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12819, Training Loss: 1.970e-01, Validation Loss: 6.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12820, Training Loss: 1.970e-01, Validation Loss: 6.051e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12821, Training Loss: 1.969e-01, Validation Loss: 6.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12822, Training Loss: 1.969e-01, Validation Loss: 6.051e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12823, Training Loss: 1.969e-01, Validation Loss: 6.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12824, Training Loss: 1.969e-01, Validation Loss: 6.051e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12825, Training Loss: 1.969e-01, Validation Loss: 6.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12826, Training Loss: 1.968e-01, Validation Loss: 6.051e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12827, Training Loss: 1.968e-01, Validation Loss: 6.051e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12828, Training Loss: 1.968e-01, Validation Loss: 6.051e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12829, Training Loss: 1.968e-01, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12830, Training Loss: 1.968e-01, Validation Loss: 6.050e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12831, Training Loss: 1.967e-01, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12832, Training Loss: 1.967e-01, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12833, Training Loss: 1.967e-01, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12834, Training Loss: 1.967e-01, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12835, Training Loss: 1.967e-01, Validation Loss: 6.050e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12836, Training Loss: 1.966e-01, Validation Loss: 6.050e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12837, Training Loss: 1.966e-01, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12838, Training Loss: 1.966e-01, Validation Loss: 6.049e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12839, Training Loss: 1.966e-01, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12840, Training Loss: 1.966e-01, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12841, Training Loss: 1.965e-01, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12842, Training Loss: 1.965e-01, Validation Loss: 6.049e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12843, Training Loss: 1.965e-01, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12844, Training Loss: 1.965e-01, Validation Loss: 6.049e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12845, Training Loss: 1.965e-01, Validation Loss: 6.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12846, Training Loss: 1.964e-01, Validation Loss: 6.048e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12847, Training Loss: 1.964e-01, Validation Loss: 6.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12848, Training Loss: 1.964e-01, Validation Loss: 6.048e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12849, Training Loss: 1.964e-01, Validation Loss: 6.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12850, Training Loss: 1.964e-01, Validation Loss: 6.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12851, Training Loss: 1.963e-01, Validation Loss: 6.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12852, Training Loss: 1.963e-01, Validation Loss: 6.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12853, Training Loss: 1.963e-01, Validation Loss: 6.048e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12854, Training Loss: 1.963e-01, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12855, Training Loss: 1.963e-01, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12856, Training Loss: 1.962e-01, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12857, Training Loss: 1.962e-01, Validation Loss: 6.047e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12858, Training Loss: 1.962e-01, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12859, Training Loss: 1.962e-01, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12860, Training Loss: 1.962e-01, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12861, Training Loss: 1.961e-01, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12862, Training Loss: 1.961e-01, Validation Loss: 6.047e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12863, Training Loss: 1.961e-01, Validation Loss: 6.047e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12864, Training Loss: 1.961e-01, Validation Loss: 6.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12865, Training Loss: 1.961e-01, Validation Loss: 6.046e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12866, Training Loss: 1.960e-01, Validation Loss: 6.046e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 12867, Training Loss: 1.960e-01, Validation Loss: 6.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12868, Training Loss: 1.960e-01, Validation Loss: 6.046e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12869, Training Loss: 1.960e-01, Validation Loss: 6.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12870, Training Loss: 1.960e-01, Validation Loss: 6.046e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12871, Training Loss: 1.959e-01, Validation Loss: 6.046e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12872, Training Loss: 1.959e-01, Validation Loss: 6.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12873, Training Loss: 1.959e-01, Validation Loss: 6.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12874, Training Loss: 1.959e-01, Validation Loss: 6.045e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12875, Training Loss: 1.959e-01, Validation Loss: 6.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12876, Training Loss: 1.958e-01, Validation Loss: 6.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12877, Training Loss: 1.958e-01, Validation Loss: 6.045e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12878, Training Loss: 1.958e-01, Validation Loss: 6.045e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12879, Training Loss: 1.958e-01, Validation Loss: 6.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12880, Training Loss: 1.958e-01, Validation Loss: 6.045e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12881, Training Loss: 1.957e-01, Validation Loss: 6.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12882, Training Loss: 1.957e-01, Validation Loss: 6.044e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12883, Training Loss: 1.957e-01, Validation Loss: 6.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12884, Training Loss: 1.957e-01, Validation Loss: 6.044e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12885, Training Loss: 1.957e-01, Validation Loss: 6.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12886, Training Loss: 1.956e-01, Validation Loss: 6.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12887, Training Loss: 1.956e-01, Validation Loss: 6.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12888, Training Loss: 1.956e-01, Validation Loss: 6.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12889, Training Loss: 1.956e-01, Validation Loss: 6.044e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12890, Training Loss: 1.956e-01, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12891, Training Loss: 1.955e-01, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12892, Training Loss: 1.955e-01, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12893, Training Loss: 1.955e-01, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12894, Training Loss: 1.955e-01, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12895, Training Loss: 1.955e-01, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12896, Training Loss: 1.954e-01, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12897, Training Loss: 1.954e-01, Validation Loss: 6.043e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12898, Training Loss: 1.954e-01, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12899, Training Loss: 1.954e-01, Validation Loss: 6.042e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12900, Training Loss: 1.954e-01, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12901, Training Loss: 1.953e-01, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12902, Training Loss: 1.953e-01, Validation Loss: 6.042e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12903, Training Loss: 1.953e-01, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12904, Training Loss: 1.953e-01, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12905, Training Loss: 1.953e-01, Validation Loss: 6.042e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12906, Training Loss: 1.952e-01, Validation Loss: 6.042e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12907, Training Loss: 1.952e-01, Validation Loss: 6.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12908, Training Loss: 1.952e-01, Validation Loss: 6.041e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12909, Training Loss: 1.952e-01, Validation Loss: 6.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12910, Training Loss: 1.952e-01, Validation Loss: 6.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12911, Training Loss: 1.952e-01, Validation Loss: 6.041e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12912, Training Loss: 1.951e-01, Validation Loss: 6.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12913, Training Loss: 1.951e-01, Validation Loss: 6.041e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12914, Training Loss: 1.951e-01, Validation Loss: 6.041e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12915, Training Loss: 1.951e-01, Validation Loss: 6.041e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12916, Training Loss: 1.951e-01, Validation Loss: 6.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12917, Training Loss: 1.950e-01, Validation Loss: 6.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12918, Training Loss: 1.950e-01, Validation Loss: 6.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12919, Training Loss: 1.950e-01, Validation Loss: 6.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12920, Training Loss: 1.950e-01, Validation Loss: 6.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12921, Training Loss: 1.950e-01, Validation Loss: 6.040e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12922, Training Loss: 1.949e-01, Validation Loss: 6.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12923, Training Loss: 1.949e-01, Validation Loss: 6.040e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12924, Training Loss: 1.949e-01, Validation Loss: 6.040e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12925, Training Loss: 1.949e-01, Validation Loss: 6.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12926, Training Loss: 1.949e-01, Validation Loss: 6.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12927, Training Loss: 1.948e-01, Validation Loss: 6.039e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12928, Training Loss: 1.948e-01, Validation Loss: 6.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12929, Training Loss: 1.948e-01, Validation Loss: 6.039e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12930, Training Loss: 1.948e-01, Validation Loss: 6.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12931, Training Loss: 1.948e-01, Validation Loss: 6.039e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12932, Training Loss: 1.947e-01, Validation Loss: 6.039e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12933, Training Loss: 1.947e-01, Validation Loss: 6.039e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12934, Training Loss: 1.947e-01, Validation Loss: 6.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12935, Training Loss: 1.947e-01, Validation Loss: 6.038e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12936, Training Loss: 1.947e-01, Validation Loss: 6.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12937, Training Loss: 1.946e-01, Validation Loss: 6.038e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12938, Training Loss: 1.946e-01, Validation Loss: 6.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12939, Training Loss: 1.946e-01, Validation Loss: 6.038e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12940, Training Loss: 1.946e-01, Validation Loss: 6.038e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12941, Training Loss: 1.946e-01, Validation Loss: 6.038e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12942, Training Loss: 1.945e-01, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12943, Training Loss: 1.945e-01, Validation Loss: 6.037e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12944, Training Loss: 1.945e-01, Validation Loss: 6.037e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 12945, Training Loss: 1.945e-01, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12946, Training Loss: 1.945e-01, Validation Loss: 6.037e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12947, Training Loss: 1.944e-01, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12948, Training Loss: 1.944e-01, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12949, Training Loss: 1.944e-01, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12950, Training Loss: 1.944e-01, Validation Loss: 6.037e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12951, Training Loss: 1.944e-01, Validation Loss: 6.037e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12952, Training Loss: 1.943e-01, Validation Loss: 6.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12953, Training Loss: 1.943e-01, Validation Loss: 6.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12954, Training Loss: 1.943e-01, Validation Loss: 6.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12955, Training Loss: 1.943e-01, Validation Loss: 6.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12956, Training Loss: 1.943e-01, Validation Loss: 6.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12957, Training Loss: 1.942e-01, Validation Loss: 6.036e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12958, Training Loss: 1.942e-01, Validation Loss: 6.036e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12959, Training Loss: 1.942e-01, Validation Loss: 6.036e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12960, Training Loss: 1.942e-01, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12961, Training Loss: 1.942e-01, Validation Loss: 6.036e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12962, Training Loss: 1.941e-01, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12963, Training Loss: 1.941e-01, Validation Loss: 6.035e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12964, Training Loss: 1.941e-01, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12965, Training Loss: 1.941e-01, Validation Loss: 6.035e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12966, Training Loss: 1.941e-01, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12967, Training Loss: 1.940e-01, Validation Loss: 6.035e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12968, Training Loss: 1.940e-01, Validation Loss: 6.035e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12969, Training Loss: 1.940e-01, Validation Loss: 6.035e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12970, Training Loss: 1.940e-01, Validation Loss: 6.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12971, Training Loss: 1.940e-01, Validation Loss: 6.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12972, Training Loss: 1.939e-01, Validation Loss: 6.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12973, Training Loss: 1.939e-01, Validation Loss: 6.034e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12974, Training Loss: 1.939e-01, Validation Loss: 6.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12975, Training Loss: 1.939e-01, Validation Loss: 6.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12976, Training Loss: 1.939e-01, Validation Loss: 6.034e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12977, Training Loss: 1.938e-01, Validation Loss: 6.034e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12978, Training Loss: 1.938e-01, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12979, Training Loss: 1.938e-01, Validation Loss: 6.033e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12980, Training Loss: 1.938e-01, Validation Loss: 6.033e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 12981, Training Loss: 1.938e-01, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12982, Training Loss: 1.938e-01, Validation Loss: 6.033e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12983, Training Loss: 1.937e-01, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12984, Training Loss: 1.937e-01, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12985, Training Loss: 1.937e-01, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12986, Training Loss: 1.937e-01, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12987, Training Loss: 1.937e-01, Validation Loss: 6.033e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12988, Training Loss: 1.936e-01, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12989, Training Loss: 1.936e-01, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12990, Training Loss: 1.936e-01, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12991, Training Loss: 1.936e-01, Validation Loss: 6.032e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12992, Training Loss: 1.936e-01, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12993, Training Loss: 1.935e-01, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12994, Training Loss: 1.935e-01, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12995, Training Loss: 1.935e-01, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12996, Training Loss: 1.935e-01, Validation Loss: 6.032e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12997, Training Loss: 1.935e-01, Validation Loss: 6.032e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 12998, Training Loss: 1.934e-01, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 12999, Training Loss: 1.934e-01, Validation Loss: 6.031e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13000, Training Loss: 1.934e-01, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13001, Training Loss: 1.934e-01, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13002, Training Loss: 1.934e-01, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13003, Training Loss: 1.933e-01, Validation Loss: 6.031e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13004, Training Loss: 1.933e-01, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13005, Training Loss: 1.933e-01, Validation Loss: 6.031e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13006, Training Loss: 1.933e-01, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13007, Training Loss: 1.933e-01, Validation Loss: 6.030e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13008, Training Loss: 1.932e-01, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13009, Training Loss: 1.932e-01, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13010, Training Loss: 1.932e-01, Validation Loss: 6.030e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13011, Training Loss: 1.932e-01, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13012, Training Loss: 1.932e-01, Validation Loss: 6.030e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13013, Training Loss: 1.931e-01, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13014, Training Loss: 1.931e-01, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13015, Training Loss: 1.931e-01, Validation Loss: 6.030e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13016, Training Loss: 1.931e-01, Validation Loss: 6.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13017, Training Loss: 1.931e-01, Validation Loss: 6.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13018, Training Loss: 1.930e-01, Validation Loss: 6.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13019, Training Loss: 1.930e-01, Validation Loss: 6.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13020, Training Loss: 1.930e-01, Validation Loss: 6.029e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13021, Training Loss: 1.930e-01, Validation Loss: 6.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13022, Training Loss: 1.930e-01, Validation Loss: 6.029e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13023, Training Loss: 1.930e-01, Validation Loss: 6.029e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13024, Training Loss: 1.929e-01, Validation Loss: 6.029e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13025, Training Loss: 1.929e-01, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13026, Training Loss: 1.929e-01, Validation Loss: 6.028e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13027, Training Loss: 1.929e-01, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13028, Training Loss: 1.929e-01, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13029, Training Loss: 1.928e-01, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13030, Training Loss: 1.928e-01, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13031, Training Loss: 1.928e-01, Validation Loss: 6.028e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13032, Training Loss: 1.928e-01, Validation Loss: 6.028e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13033, Training Loss: 1.928e-01, Validation Loss: 6.028e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 13034, Training Loss: 1.927e-01, Validation Loss: 6.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13035, Training Loss: 1.927e-01, Validation Loss: 6.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13036, Training Loss: 1.927e-01, Validation Loss: 6.027e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13037, Training Loss: 1.927e-01, Validation Loss: 6.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13038, Training Loss: 1.927e-01, Validation Loss: 6.027e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13039, Training Loss: 1.926e-01, Validation Loss: 6.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13040, Training Loss: 1.926e-01, Validation Loss: 6.027e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13041, Training Loss: 1.926e-01, Validation Loss: 6.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13042, Training Loss: 1.926e-01, Validation Loss: 6.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13043, Training Loss: 1.926e-01, Validation Loss: 6.027e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13044, Training Loss: 1.925e-01, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13045, Training Loss: 1.925e-01, Validation Loss: 6.026e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13046, Training Loss: 1.925e-01, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13047, Training Loss: 1.925e-01, Validation Loss: 6.026e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13048, Training Loss: 1.925e-01, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13049, Training Loss: 1.924e-01, Validation Loss: 6.026e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13050, Training Loss: 1.924e-01, Validation Loss: 6.026e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13051, Training Loss: 1.924e-01, Validation Loss: 6.026e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13052, Training Loss: 1.924e-01, Validation Loss: 6.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13053, Training Loss: 1.924e-01, Validation Loss: 6.025e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13054, Training Loss: 1.923e-01, Validation Loss: 6.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13055, Training Loss: 1.923e-01, Validation Loss: 6.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13056, Training Loss: 1.923e-01, Validation Loss: 6.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13057, Training Loss: 1.923e-01, Validation Loss: 6.025e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13058, Training Loss: 1.923e-01, Validation Loss: 6.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13059, Training Loss: 1.923e-01, Validation Loss: 6.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13060, Training Loss: 1.922e-01, Validation Loss: 6.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13061, Training Loss: 1.922e-01, Validation Loss: 6.025e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13062, Training Loss: 1.922e-01, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13063, Training Loss: 1.922e-01, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13064, Training Loss: 1.922e-01, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13065, Training Loss: 1.921e-01, Validation Loss: 6.024e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13066, Training Loss: 1.921e-01, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13067, Training Loss: 1.921e-01, Validation Loss: 6.024e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13068, Training Loss: 1.921e-01, Validation Loss: 6.024e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13069, Training Loss: 1.921e-01, Validation Loss: 6.024e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13070, Training Loss: 1.920e-01, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13071, Training Loss: 1.920e-01, Validation Loss: 6.024e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13072, Training Loss: 1.920e-01, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13073, Training Loss: 1.920e-01, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13074, Training Loss: 1.920e-01, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13075, Training Loss: 1.919e-01, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13076, Training Loss: 1.919e-01, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13077, Training Loss: 1.919e-01, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13078, Training Loss: 1.919e-01, Validation Loss: 6.023e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13079, Training Loss: 1.919e-01, Validation Loss: 6.023e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13080, Training Loss: 1.918e-01, Validation Loss: 6.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13081, Training Loss: 1.918e-01, Validation Loss: 6.022e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13082, Training Loss: 1.918e-01, Validation Loss: 6.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13083, Training Loss: 1.918e-01, Validation Loss: 6.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13084, Training Loss: 1.918e-01, Validation Loss: 6.022e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13085, Training Loss: 1.917e-01, Validation Loss: 6.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13086, Training Loss: 1.917e-01, Validation Loss: 6.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13087, Training Loss: 1.917e-01, Validation Loss: 6.022e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13088, Training Loss: 1.917e-01, Validation Loss: 6.022e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13089, Training Loss: 1.917e-01, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13090, Training Loss: 1.917e-01, Validation Loss: 6.021e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13091, Training Loss: 1.916e-01, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13092, Training Loss: 1.916e-01, Validation Loss: 6.021e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13093, Training Loss: 1.916e-01, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13094, Training Loss: 1.916e-01, Validation Loss: 6.021e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13095, Training Loss: 1.916e-01, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13096, Training Loss: 1.915e-01, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13097, Training Loss: 1.915e-01, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13098, Training Loss: 1.915e-01, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13099, Training Loss: 1.915e-01, Validation Loss: 6.021e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13100, Training Loss: 1.915e-01, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13101, Training Loss: 1.914e-01, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13102, Training Loss: 1.914e-01, Validation Loss: 6.020e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13103, Training Loss: 1.914e-01, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13104, Training Loss: 1.914e-01, Validation Loss: 6.020e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13105, Training Loss: 1.914e-01, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13106, Training Loss: 1.913e-01, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13107, Training Loss: 1.913e-01, Validation Loss: 6.020e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13108, Training Loss: 1.913e-01, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13109, Training Loss: 1.913e-01, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13110, Training Loss: 1.913e-01, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13111, Training Loss: 1.912e-01, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13112, Training Loss: 1.912e-01, Validation Loss: 6.019e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13113, Training Loss: 1.912e-01, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13114, Training Loss: 1.912e-01, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13115, Training Loss: 1.912e-01, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13116, Training Loss: 1.912e-01, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13117, Training Loss: 1.911e-01, Validation Loss: 6.019e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13118, Training Loss: 1.911e-01, Validation Loss: 6.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13119, Training Loss: 1.911e-01, Validation Loss: 6.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13120, Training Loss: 1.911e-01, Validation Loss: 6.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13121, Training Loss: 1.911e-01, Validation Loss: 6.018e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13122, Training Loss: 1.910e-01, Validation Loss: 6.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13123, Training Loss: 1.910e-01, Validation Loss: 6.018e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13124, Training Loss: 1.910e-01, Validation Loss: 6.018e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13125, Training Loss: 1.910e-01, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13126, Training Loss: 1.910e-01, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13127, Training Loss: 1.909e-01, Validation Loss: 6.018e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13128, Training Loss: 1.909e-01, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13129, Training Loss: 1.909e-01, Validation Loss: 6.017e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13130, Training Loss: 1.909e-01, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13131, Training Loss: 1.909e-01, Validation Loss: 6.017e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13132, Training Loss: 1.908e-01, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13133, Training Loss: 1.908e-01, Validation Loss: 6.017e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13134, Training Loss: 1.908e-01, Validation Loss: 6.017e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13135, Training Loss: 1.908e-01, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13136, Training Loss: 1.908e-01, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13137, Training Loss: 1.907e-01, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13138, Training Loss: 1.907e-01, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13139, Training Loss: 1.907e-01, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13140, Training Loss: 1.907e-01, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13141, Training Loss: 1.907e-01, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13142, Training Loss: 1.907e-01, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13143, Training Loss: 1.906e-01, Validation Loss: 6.016e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13144, Training Loss: 1.906e-01, Validation Loss: 6.016e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13145, Training Loss: 1.906e-01, Validation Loss: 6.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13146, Training Loss: 1.906e-01, Validation Loss: 6.015e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13147, Training Loss: 1.906e-01, Validation Loss: 6.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13148, Training Loss: 1.905e-01, Validation Loss: 6.015e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13149, Training Loss: 1.905e-01, Validation Loss: 6.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13150, Training Loss: 1.905e-01, Validation Loss: 6.015e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13151, Training Loss: 1.905e-01, Validation Loss: 6.015e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13152, Training Loss: 1.905e-01, Validation Loss: 6.015e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13153, Training Loss: 1.904e-01, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13154, Training Loss: 1.904e-01, Validation Loss: 6.015e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13155, Training Loss: 1.904e-01, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13156, Training Loss: 1.904e-01, Validation Loss: 6.014e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13157, Training Loss: 1.904e-01, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13158, Training Loss: 1.903e-01, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13159, Training Loss: 1.903e-01, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13160, Training Loss: 1.903e-01, Validation Loss: 6.014e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13161, Training Loss: 1.903e-01, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13162, Training Loss: 1.903e-01, Validation Loss: 6.014e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13163, Training Loss: 1.903e-01, Validation Loss: 6.014e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13164, Training Loss: 1.902e-01, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13165, Training Loss: 1.902e-01, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13166, Training Loss: 1.902e-01, Validation Loss: 6.013e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13167, Training Loss: 1.902e-01, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13168, Training Loss: 1.902e-01, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13169, Training Loss: 1.901e-01, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13170, Training Loss: 1.901e-01, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13171, Training Loss: 1.901e-01, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13172, Training Loss: 1.901e-01, Validation Loss: 6.013e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13173, Training Loss: 1.901e-01, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13174, Training Loss: 1.900e-01, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13175, Training Loss: 1.900e-01, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13176, Training Loss: 1.900e-01, Validation Loss: 6.012e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13177, Training Loss: 1.900e-01, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13178, Training Loss: 1.900e-01, Validation Loss: 6.012e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13179, Training Loss: 1.899e-01, Validation Loss: 6.012e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13180, Training Loss: 1.899e-01, Validation Loss: 6.012e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13181, Training Loss: 1.899e-01, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13182, Training Loss: 1.899e-01, Validation Loss: 6.012e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13183, Training Loss: 1.899e-01, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13184, Training Loss: 1.899e-01, Validation Loss: 6.011e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13185, Training Loss: 1.898e-01, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13186, Training Loss: 1.898e-01, Validation Loss: 6.011e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13187, Training Loss: 1.898e-01, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13188, Training Loss: 1.898e-01, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13189, Training Loss: 1.898e-01, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13190, Training Loss: 1.897e-01, Validation Loss: 6.011e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13191, Training Loss: 1.897e-01, Validation Loss: 6.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13192, Training Loss: 1.897e-01, Validation Loss: 6.011e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13193, Training Loss: 1.897e-01, Validation Loss: 6.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13194, Training Loss: 1.897e-01, Validation Loss: 6.010e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13195, Training Loss: 1.896e-01, Validation Loss: 6.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13196, Training Loss: 1.896e-01, Validation Loss: 6.010e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13197, Training Loss: 1.896e-01, Validation Loss: 6.010e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13198, Training Loss: 1.896e-01, Validation Loss: 6.010e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13199, Training Loss: 1.896e-01, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13200, Training Loss: 1.895e-01, Validation Loss: 6.010e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13201, Training Loss: 1.895e-01, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13202, Training Loss: 1.895e-01, Validation Loss: 6.009e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13203, Training Loss: 1.895e-01, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13204, Training Loss: 1.895e-01, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13205, Training Loss: 1.895e-01, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13206, Training Loss: 1.894e-01, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13207, Training Loss: 1.894e-01, Validation Loss: 6.009e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13208, Training Loss: 1.894e-01, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13209, Training Loss: 1.894e-01, Validation Loss: 6.009e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13210, Training Loss: 1.894e-01, Validation Loss: 6.009e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13211, Training Loss: 1.893e-01, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13212, Training Loss: 1.893e-01, Validation Loss: 6.008e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13213, Training Loss: 1.893e-01, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13214, Training Loss: 1.893e-01, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13215, Training Loss: 1.893e-01, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13216, Training Loss: 1.892e-01, Validation Loss: 6.008e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13217, Training Loss: 1.892e-01, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13218, Training Loss: 1.892e-01, Validation Loss: 6.008e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13219, Training Loss: 1.892e-01, Validation Loss: 6.008e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13220, Training Loss: 1.892e-01, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13221, Training Loss: 1.892e-01, Validation Loss: 6.007e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13222, Training Loss: 1.891e-01, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13223, Training Loss: 1.891e-01, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13224, Training Loss: 1.891e-01, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13225, Training Loss: 1.891e-01, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13226, Training Loss: 1.891e-01, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13227, Training Loss: 1.890e-01, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13228, Training Loss: 1.890e-01, Validation Loss: 6.007e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13229, Training Loss: 1.890e-01, Validation Loss: 6.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13230, Training Loss: 1.890e-01, Validation Loss: 6.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13231, Training Loss: 1.890e-01, Validation Loss: 6.006e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13232, Training Loss: 1.889e-01, Validation Loss: 6.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13233, Training Loss: 1.889e-01, Validation Loss: 6.006e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13234, Training Loss: 1.889e-01, Validation Loss: 6.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13235, Training Loss: 1.889e-01, Validation Loss: 6.006e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13236, Training Loss: 1.889e-01, Validation Loss: 6.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13237, Training Loss: 1.888e-01, Validation Loss: 6.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13238, Training Loss: 1.888e-01, Validation Loss: 6.006e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13239, Training Loss: 1.888e-01, Validation Loss: 6.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13240, Training Loss: 1.888e-01, Validation Loss: 6.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13241, Training Loss: 1.888e-01, Validation Loss: 6.005e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13242, Training Loss: 1.888e-01, Validation Loss: 6.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13243, Training Loss: 1.887e-01, Validation Loss: 6.005e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13244, Training Loss: 1.887e-01, Validation Loss: 6.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13245, Training Loss: 1.887e-01, Validation Loss: 6.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13246, Training Loss: 1.887e-01, Validation Loss: 6.005e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13247, Training Loss: 1.887e-01, Validation Loss: 6.005e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13248, Training Loss: 1.886e-01, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13249, Training Loss: 1.886e-01, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13250, Training Loss: 1.886e-01, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13251, Training Loss: 1.886e-01, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13252, Training Loss: 1.886e-01, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13253, Training Loss: 1.885e-01, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13254, Training Loss: 1.885e-01, Validation Loss: 6.004e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13255, Training Loss: 1.885e-01, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13256, Training Loss: 1.885e-01, Validation Loss: 6.004e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13257, Training Loss: 1.885e-01, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13258, Training Loss: 1.885e-01, Validation Loss: 6.004e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13259, Training Loss: 1.884e-01, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13260, Training Loss: 1.884e-01, Validation Loss: 6.003e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13261, Training Loss: 1.884e-01, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13262, Training Loss: 1.884e-01, Validation Loss: 6.003e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13263, Training Loss: 1.884e-01, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13264, Training Loss: 1.883e-01, Validation Loss: 6.003e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13265, Training Loss: 1.883e-01, Validation Loss: 6.003e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13266, Training Loss: 1.883e-01, Validation Loss: 6.003e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13267, Training Loss: 1.883e-01, Validation Loss: 6.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13268, Training Loss: 1.883e-01, Validation Loss: 6.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13269, Training Loss: 1.882e-01, Validation Loss: 6.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13270, Training Loss: 1.882e-01, Validation Loss: 6.002e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13271, Training Loss: 1.882e-01, Validation Loss: 6.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13272, Training Loss: 1.882e-01, Validation Loss: 6.002e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13273, Training Loss: 1.882e-01, Validation Loss: 6.002e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13274, Training Loss: 1.882e-01, Validation Loss: 6.002e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13275, Training Loss: 1.881e-01, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13276, Training Loss: 1.881e-01, Validation Loss: 6.002e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13277, Training Loss: 1.881e-01, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13278, Training Loss: 1.881e-01, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13279, Training Loss: 1.881e-01, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13280, Training Loss: 1.880e-01, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13281, Training Loss: 1.880e-01, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13282, Training Loss: 1.880e-01, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13283, Training Loss: 1.880e-01, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13284, Training Loss: 1.880e-01, Validation Loss: 6.001e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13285, Training Loss: 1.879e-01, Validation Loss: 6.001e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13286, Training Loss: 1.879e-01, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13287, Training Loss: 1.879e-01, Validation Loss: 6.000e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13288, Training Loss: 1.879e-01, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13289, Training Loss: 1.879e-01, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13290, Training Loss: 1.879e-01, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13291, Training Loss: 1.878e-01, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13292, Training Loss: 1.878e-01, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13293, Training Loss: 1.878e-01, Validation Loss: 6.000e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13294, Training Loss: 1.878e-01, Validation Loss: 6.000e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13295, Training Loss: 1.878e-01, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13296, Training Loss: 1.877e-01, Validation Loss: 5.999e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13297, Training Loss: 1.877e-01, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13298, Training Loss: 1.877e-01, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13299, Training Loss: 1.877e-01, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13300, Training Loss: 1.877e-01, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13301, Training Loss: 1.876e-01, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13302, Training Loss: 1.876e-01, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13303, Training Loss: 1.876e-01, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13304, Training Loss: 1.876e-01, Validation Loss: 5.999e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13305, Training Loss: 1.876e-01, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13306, Training Loss: 1.876e-01, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13307, Training Loss: 1.875e-01, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13308, Training Loss: 1.875e-01, Validation Loss: 5.998e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13309, Training Loss: 1.875e-01, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13310, Training Loss: 1.875e-01, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13311, Training Loss: 1.875e-01, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13312, Training Loss: 1.874e-01, Validation Loss: 5.998e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13313, Training Loss: 1.874e-01, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13314, Training Loss: 1.874e-01, Validation Loss: 5.998e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13315, Training Loss: 1.874e-01, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13316, Training Loss: 1.874e-01, Validation Loss: 5.997e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13317, Training Loss: 1.873e-01, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13318, Training Loss: 1.873e-01, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13319, Training Loss: 1.873e-01, Validation Loss: 5.997e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13320, Training Loss: 1.873e-01, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13321, Training Loss: 1.873e-01, Validation Loss: 5.997e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13322, Training Loss: 1.873e-01, Validation Loss: 5.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13323, Training Loss: 1.872e-01, Validation Loss: 5.996e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13324, Training Loss: 1.872e-01, Validation Loss: 5.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13325, Training Loss: 1.872e-01, Validation Loss: 5.996e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13326, Training Loss: 1.872e-01, Validation Loss: 5.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13327, Training Loss: 1.872e-01, Validation Loss: 5.996e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13328, Training Loss: 1.871e-01, Validation Loss: 5.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13329, Training Loss: 1.871e-01, Validation Loss: 5.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13330, Training Loss: 1.871e-01, Validation Loss: 5.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13331, Training Loss: 1.871e-01, Validation Loss: 5.996e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13332, Training Loss: 1.871e-01, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13333, Training Loss: 1.870e-01, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13334, Training Loss: 1.870e-01, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13335, Training Loss: 1.870e-01, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13336, Training Loss: 1.870e-01, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13337, Training Loss: 1.870e-01, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13338, Training Loss: 1.870e-01, Validation Loss: 5.995e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13339, Training Loss: 1.869e-01, Validation Loss: 5.995e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13340, Training Loss: 1.869e-01, Validation Loss: 5.995e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13341, Training Loss: 1.869e-01, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13342, Training Loss: 1.869e-01, Validation Loss: 5.994e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13343, Training Loss: 1.869e-01, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13344, Training Loss: 1.868e-01, Validation Loss: 5.994e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13345, Training Loss: 1.868e-01, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13346, Training Loss: 1.868e-01, Validation Loss: 5.994e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13347, Training Loss: 1.868e-01, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13348, Training Loss: 1.868e-01, Validation Loss: 5.994e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13349, Training Loss: 1.867e-01, Validation Loss: 5.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13350, Training Loss: 1.867e-01, Validation Loss: 5.994e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13351, Training Loss: 1.867e-01, Validation Loss: 5.994e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 13352, Training Loss: 1.867e-01, Validation Loss: 5.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13353, Training Loss: 1.867e-01, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13354, Training Loss: 1.867e-01, Validation Loss: 5.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13355, Training Loss: 1.866e-01, Validation Loss: 5.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13356, Training Loss: 1.866e-01, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13357, Training Loss: 1.866e-01, Validation Loss: 5.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13358, Training Loss: 1.866e-01, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13359, Training Loss: 1.866e-01, Validation Loss: 5.993e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13360, Training Loss: 1.865e-01, Validation Loss: 5.993e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13361, Training Loss: 1.865e-01, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13362, Training Loss: 1.865e-01, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13363, Training Loss: 1.865e-01, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13364, Training Loss: 1.865e-01, Validation Loss: 5.992e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13365, Training Loss: 1.865e-01, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13366, Training Loss: 1.864e-01, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13367, Training Loss: 1.864e-01, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13368, Training Loss: 1.864e-01, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13369, Training Loss: 1.864e-01, Validation Loss: 5.992e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13370, Training Loss: 1.864e-01, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13371, Training Loss: 1.863e-01, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13372, Training Loss: 1.863e-01, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13373, Training Loss: 1.863e-01, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13374, Training Loss: 1.863e-01, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13375, Training Loss: 1.863e-01, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13376, Training Loss: 1.862e-01, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13377, Training Loss: 1.862e-01, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13378, Training Loss: 1.862e-01, Validation Loss: 5.991e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13379, Training Loss: 1.862e-01, Validation Loss: 5.991e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13380, Training Loss: 1.862e-01, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13381, Training Loss: 1.862e-01, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13382, Training Loss: 1.861e-01, Validation Loss: 5.990e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13383, Training Loss: 1.861e-01, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13384, Training Loss: 1.861e-01, Validation Loss: 5.990e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13385, Training Loss: 1.861e-01, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13386, Training Loss: 1.861e-01, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13387, Training Loss: 1.860e-01, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13388, Training Loss: 1.860e-01, Validation Loss: 5.990e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13389, Training Loss: 1.860e-01, Validation Loss: 5.990e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13390, Training Loss: 1.860e-01, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13391, Training Loss: 1.860e-01, Validation Loss: 5.989e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13392, Training Loss: 1.860e-01, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13393, Training Loss: 1.859e-01, Validation Loss: 5.989e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13394, Training Loss: 1.859e-01, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13395, Training Loss: 1.859e-01, Validation Loss: 5.989e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13396, Training Loss: 1.859e-01, Validation Loss: 5.989e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13397, Training Loss: 1.859e-01, Validation Loss: 5.989e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13398, Training Loss: 1.858e-01, Validation Loss: 5.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13399, Training Loss: 1.858e-01, Validation Loss: 5.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13400, Training Loss: 1.858e-01, Validation Loss: 5.988e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13401, Training Loss: 1.858e-01, Validation Loss: 5.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13402, Training Loss: 1.858e-01, Validation Loss: 5.988e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13403, Training Loss: 1.858e-01, Validation Loss: 5.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13404, Training Loss: 1.857e-01, Validation Loss: 5.988e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13405, Training Loss: 1.857e-01, Validation Loss: 5.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13406, Training Loss: 1.857e-01, Validation Loss: 5.988e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13407, Training Loss: 1.857e-01, Validation Loss: 5.988e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13408, Training Loss: 1.857e-01, Validation Loss: 5.988e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13409, Training Loss: 1.856e-01, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13410, Training Loss: 1.856e-01, Validation Loss: 5.987e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13411, Training Loss: 1.856e-01, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13412, Training Loss: 1.856e-01, Validation Loss: 5.987e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13413, Training Loss: 1.856e-01, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13414, Training Loss: 1.855e-01, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13415, Training Loss: 1.855e-01, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13416, Training Loss: 1.855e-01, Validation Loss: 5.987e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13417, Training Loss: 1.855e-01, Validation Loss: 5.987e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13418, Training Loss: 1.855e-01, Validation Loss: 5.987e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13419, Training Loss: 1.855e-01, Validation Loss: 5.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13420, Training Loss: 1.854e-01, Validation Loss: 5.986e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13421, Training Loss: 1.854e-01, Validation Loss: 5.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13422, Training Loss: 1.854e-01, Validation Loss: 5.986e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13423, Training Loss: 1.854e-01, Validation Loss: 5.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13424, Training Loss: 1.854e-01, Validation Loss: 5.986e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13425, Training Loss: 1.853e-01, Validation Loss: 5.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13426, Training Loss: 1.853e-01, Validation Loss: 5.986e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13427, Training Loss: 1.853e-01, Validation Loss: 5.986e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13428, Training Loss: 1.853e-01, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13429, Training Loss: 1.853e-01, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13430, Training Loss: 1.853e-01, Validation Loss: 5.985e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13431, Training Loss: 1.852e-01, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13432, Training Loss: 1.852e-01, Validation Loss: 5.985e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13433, Training Loss: 1.852e-01, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13434, Training Loss: 1.852e-01, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13435, Training Loss: 1.852e-01, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13436, Training Loss: 1.851e-01, Validation Loss: 5.985e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13437, Training Loss: 1.851e-01, Validation Loss: 5.985e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13438, Training Loss: 1.851e-01, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13439, Training Loss: 1.851e-01, Validation Loss: 5.984e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13440, Training Loss: 1.851e-01, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13441, Training Loss: 1.851e-01, Validation Loss: 5.984e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13442, Training Loss: 1.850e-01, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13443, Training Loss: 1.850e-01, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13444, Training Loss: 1.850e-01, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13445, Training Loss: 1.850e-01, Validation Loss: 5.984e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13446, Training Loss: 1.850e-01, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13447, Training Loss: 1.849e-01, Validation Loss: 5.984e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13448, Training Loss: 1.849e-01, Validation Loss: 5.984e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13449, Training Loss: 1.849e-01, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13450, Training Loss: 1.849e-01, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13451, Training Loss: 1.849e-01, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13452, Training Loss: 1.849e-01, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13453, Training Loss: 1.848e-01, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13454, Training Loss: 1.848e-01, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13455, Training Loss: 1.848e-01, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13456, Training Loss: 1.848e-01, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13457, Training Loss: 1.848e-01, Validation Loss: 5.983e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13458, Training Loss: 1.847e-01, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13459, Training Loss: 1.847e-01, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13460, Training Loss: 1.847e-01, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13461, Training Loss: 1.847e-01, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13462, Training Loss: 1.847e-01, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13463, Training Loss: 1.846e-01, Validation Loss: 5.982e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13464, Training Loss: 1.846e-01, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13465, Training Loss: 1.846e-01, Validation Loss: 5.982e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13466, Training Loss: 1.846e-01, Validation Loss: 5.982e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13467, Training Loss: 1.846e-01, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13468, Training Loss: 1.846e-01, Validation Loss: 5.982e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13469, Training Loss: 1.845e-01, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13470, Training Loss: 1.845e-01, Validation Loss: 5.981e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13471, Training Loss: 1.845e-01, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13472, Training Loss: 1.845e-01, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13473, Training Loss: 1.845e-01, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13474, Training Loss: 1.844e-01, Validation Loss: 5.981e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13475, Training Loss: 1.844e-01, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13476, Training Loss: 1.844e-01, Validation Loss: 5.981e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13477, Training Loss: 1.844e-01, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13478, Training Loss: 1.844e-01, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13479, Training Loss: 1.844e-01, Validation Loss: 5.980e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13480, Training Loss: 1.843e-01, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13481, Training Loss: 1.843e-01, Validation Loss: 5.980e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13482, Training Loss: 1.843e-01, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13483, Training Loss: 1.843e-01, Validation Loss: 5.980e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13484, Training Loss: 1.843e-01, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13485, Training Loss: 1.842e-01, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13486, Training Loss: 1.842e-01, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13487, Training Loss: 1.842e-01, Validation Loss: 5.980e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13488, Training Loss: 1.842e-01, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13489, Training Loss: 1.842e-01, Validation Loss: 5.979e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13490, Training Loss: 1.842e-01, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13491, Training Loss: 1.841e-01, Validation Loss: 5.979e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13492, Training Loss: 1.841e-01, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13493, Training Loss: 1.841e-01, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13494, Training Loss: 1.841e-01, Validation Loss: 5.979e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13495, Training Loss: 1.841e-01, Validation Loss: 5.979e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13496, Training Loss: 1.840e-01, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13497, Training Loss: 1.840e-01, Validation Loss: 5.979e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13498, Training Loss: 1.840e-01, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13499, Training Loss: 1.840e-01, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13500, Training Loss: 1.840e-01, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13501, Training Loss: 1.840e-01, Validation Loss: 5.978e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13502, Training Loss: 1.839e-01, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13503, Training Loss: 1.839e-01, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13504, Training Loss: 1.839e-01, Validation Loss: 5.978e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13505, Training Loss: 1.839e-01, Validation Loss: 5.978e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13506, Training Loss: 1.839e-01, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13507, Training Loss: 1.838e-01, Validation Loss: 5.978e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13508, Training Loss: 1.838e-01, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13509, Training Loss: 1.838e-01, Validation Loss: 5.977e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13510, Training Loss: 1.838e-01, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13511, Training Loss: 1.838e-01, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13512, Training Loss: 1.838e-01, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13513, Training Loss: 1.837e-01, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13514, Training Loss: 1.837e-01, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13515, Training Loss: 1.837e-01, Validation Loss: 5.977e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13516, Training Loss: 1.837e-01, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13517, Training Loss: 1.837e-01, Validation Loss: 5.977e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13518, Training Loss: 1.836e-01, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13519, Training Loss: 1.836e-01, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13520, Training Loss: 1.836e-01, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13521, Training Loss: 1.836e-01, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13522, Training Loss: 1.836e-01, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13523, Training Loss: 1.836e-01, Validation Loss: 5.976e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13524, Training Loss: 1.835e-01, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13525, Training Loss: 1.835e-01, Validation Loss: 5.976e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13526, Training Loss: 1.835e-01, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13527, Training Loss: 1.835e-01, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13528, Training Loss: 1.835e-01, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13529, Training Loss: 1.834e-01, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13530, Training Loss: 1.834e-01, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13531, Training Loss: 1.834e-01, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13532, Training Loss: 1.834e-01, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13533, Training Loss: 1.834e-01, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13534, Training Loss: 1.834e-01, Validation Loss: 5.975e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13535, Training Loss: 1.833e-01, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13536, Training Loss: 1.833e-01, Validation Loss: 5.975e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13537, Training Loss: 1.833e-01, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13538, Training Loss: 1.833e-01, Validation Loss: 5.974e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13539, Training Loss: 1.833e-01, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13540, Training Loss: 1.833e-01, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13541, Training Loss: 1.832e-01, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13542, Training Loss: 1.832e-01, Validation Loss: 5.974e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13543, Training Loss: 1.832e-01, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13544, Training Loss: 1.832e-01, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13545, Training Loss: 1.832e-01, Validation Loss: 5.974e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13546, Training Loss: 1.831e-01, Validation Loss: 5.974e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13547, Training Loss: 1.831e-01, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13548, Training Loss: 1.831e-01, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13549, Training Loss: 1.831e-01, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13550, Training Loss: 1.831e-01, Validation Loss: 5.973e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13551, Training Loss: 1.831e-01, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13552, Training Loss: 1.830e-01, Validation Loss: 5.973e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13553, Training Loss: 1.830e-01, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13554, Training Loss: 1.830e-01, Validation Loss: 5.973e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13555, Training Loss: 1.830e-01, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13556, Training Loss: 1.830e-01, Validation Loss: 5.973e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13557, Training Loss: 1.829e-01, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13558, Training Loss: 1.829e-01, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13559, Training Loss: 1.829e-01, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13560, Training Loss: 1.829e-01, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13561, Training Loss: 1.829e-01, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13562, Training Loss: 1.829e-01, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13563, Training Loss: 1.828e-01, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13564, Training Loss: 1.828e-01, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13565, Training Loss: 1.828e-01, Validation Loss: 5.972e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13566, Training Loss: 1.828e-01, Validation Loss: 5.972e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13567, Training Loss: 1.828e-01, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13568, Training Loss: 1.827e-01, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13569, Training Loss: 1.827e-01, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13570, Training Loss: 1.827e-01, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13571, Training Loss: 1.827e-01, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13572, Training Loss: 1.827e-01, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13573, Training Loss: 1.827e-01, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13574, Training Loss: 1.826e-01, Validation Loss: 5.971e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13575, Training Loss: 1.826e-01, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13576, Training Loss: 1.826e-01, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13577, Training Loss: 1.826e-01, Validation Loss: 5.971e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13578, Training Loss: 1.826e-01, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13579, Training Loss: 1.825e-01, Validation Loss: 5.970e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13580, Training Loss: 1.825e-01, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13581, Training Loss: 1.825e-01, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13582, Training Loss: 1.825e-01, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13583, Training Loss: 1.825e-01, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13584, Training Loss: 1.825e-01, Validation Loss: 5.970e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13585, Training Loss: 1.824e-01, Validation Loss: 5.970e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13586, Training Loss: 1.824e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13587, Training Loss: 1.824e-01, Validation Loss: 5.970e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13588, Training Loss: 1.824e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13589, Training Loss: 1.824e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13590, Training Loss: 1.824e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13591, Training Loss: 1.823e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13592, Training Loss: 1.823e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13593, Training Loss: 1.823e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13594, Training Loss: 1.823e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13595, Training Loss: 1.823e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13596, Training Loss: 1.822e-01, Validation Loss: 5.969e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13597, Training Loss: 1.822e-01, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13598, Training Loss: 1.822e-01, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13599, Training Loss: 1.822e-01, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13600, Training Loss: 1.822e-01, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13601, Training Loss: 1.822e-01, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13602, Training Loss: 1.821e-01, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13603, Training Loss: 1.821e-01, Validation Loss: 5.968e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13604, Training Loss: 1.821e-01, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13605, Training Loss: 1.821e-01, Validation Loss: 5.968e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13606, Training Loss: 1.821e-01, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13607, Training Loss: 1.820e-01, Validation Loss: 5.968e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13608, Training Loss: 1.820e-01, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13609, Training Loss: 1.820e-01, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13610, Training Loss: 1.820e-01, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13611, Training Loss: 1.820e-01, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13612, Training Loss: 1.820e-01, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13613, Training Loss: 1.819e-01, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13614, Training Loss: 1.819e-01, Validation Loss: 5.967e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13615, Training Loss: 1.819e-01, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13616, Training Loss: 1.819e-01, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13617, Training Loss: 1.819e-01, Validation Loss: 5.967e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13618, Training Loss: 1.818e-01, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13619, Training Loss: 1.818e-01, Validation Loss: 5.966e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13620, Training Loss: 1.818e-01, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13621, Training Loss: 1.818e-01, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13622, Training Loss: 1.818e-01, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13623, Training Loss: 1.818e-01, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13624, Training Loss: 1.817e-01, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13625, Training Loss: 1.817e-01, Validation Loss: 5.966e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13626, Training Loss: 1.817e-01, Validation Loss: 5.966e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13627, Training Loss: 1.817e-01, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13628, Training Loss: 1.817e-01, Validation Loss: 5.965e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13629, Training Loss: 1.817e-01, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13630, Training Loss: 1.816e-01, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13631, Training Loss: 1.816e-01, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13632, Training Loss: 1.816e-01, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13633, Training Loss: 1.816e-01, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13634, Training Loss: 1.816e-01, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13635, Training Loss: 1.815e-01, Validation Loss: 5.965e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13636, Training Loss: 1.815e-01, Validation Loss: 5.965e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13637, Training Loss: 1.815e-01, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13638, Training Loss: 1.815e-01, Validation Loss: 5.965e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13639, Training Loss: 1.815e-01, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13640, Training Loss: 1.815e-01, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13641, Training Loss: 1.814e-01, Validation Loss: 5.964e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13642, Training Loss: 1.814e-01, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13643, Training Loss: 1.814e-01, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13644, Training Loss: 1.814e-01, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13645, Training Loss: 1.814e-01, Validation Loss: 5.964e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13646, Training Loss: 1.814e-01, Validation Loss: 5.964e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13647, Training Loss: 1.813e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13648, Training Loss: 1.813e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13649, Training Loss: 1.813e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13650, Training Loss: 1.813e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13651, Training Loss: 1.813e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13652, Training Loss: 1.812e-01, Validation Loss: 5.963e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13653, Training Loss: 1.812e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13654, Training Loss: 1.812e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13655, Training Loss: 1.812e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13656, Training Loss: 1.812e-01, Validation Loss: 5.963e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13657, Training Loss: 1.812e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13658, Training Loss: 1.811e-01, Validation Loss: 5.963e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13659, Training Loss: 1.811e-01, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13660, Training Loss: 1.811e-01, Validation Loss: 5.962e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13661, Training Loss: 1.811e-01, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13662, Training Loss: 1.811e-01, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13663, Training Loss: 1.810e-01, Validation Loss: 5.962e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13664, Training Loss: 1.810e-01, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13665, Training Loss: 1.810e-01, Validation Loss: 5.962e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13666, Training Loss: 1.810e-01, Validation Loss: 5.962e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13667, Training Loss: 1.810e-01, Validation Loss: 5.962e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13668, Training Loss: 1.810e-01, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13669, Training Loss: 1.809e-01, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13670, Training Loss: 1.809e-01, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13671, Training Loss: 1.809e-01, Validation Loss: 5.961e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13672, Training Loss: 1.809e-01, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13673, Training Loss: 1.809e-01, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13674, Training Loss: 1.809e-01, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13675, Training Loss: 1.808e-01, Validation Loss: 5.961e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13676, Training Loss: 1.808e-01, Validation Loss: 5.961e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13677, Training Loss: 1.808e-01, Validation Loss: 5.961e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13678, Training Loss: 1.808e-01, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13679, Training Loss: 1.808e-01, Validation Loss: 5.961e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13680, Training Loss: 1.807e-01, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13681, Training Loss: 1.807e-01, Validation Loss: 5.960e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13682, Training Loss: 1.807e-01, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13683, Training Loss: 1.807e-01, Validation Loss: 5.960e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13684, Training Loss: 1.807e-01, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13685, Training Loss: 1.807e-01, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13686, Training Loss: 1.806e-01, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13687, Training Loss: 1.806e-01, Validation Loss: 5.960e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13688, Training Loss: 1.806e-01, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13689, Training Loss: 1.806e-01, Validation Loss: 5.959e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13690, Training Loss: 1.806e-01, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13691, Training Loss: 1.806e-01, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13692, Training Loss: 1.805e-01, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13693, Training Loss: 1.805e-01, Validation Loss: 5.959e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13694, Training Loss: 1.805e-01, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13695, Training Loss: 1.805e-01, Validation Loss: 5.959e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13696, Training Loss: 1.805e-01, Validation Loss: 5.959e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13697, Training Loss: 1.804e-01, Validation Loss: 5.959e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13698, Training Loss: 1.804e-01, Validation Loss: 5.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13699, Training Loss: 1.804e-01, Validation Loss: 5.958e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13700, Training Loss: 1.804e-01, Validation Loss: 5.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13701, Training Loss: 1.804e-01, Validation Loss: 5.958e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13702, Training Loss: 1.804e-01, Validation Loss: 5.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13703, Training Loss: 1.803e-01, Validation Loss: 5.958e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13704, Training Loss: 1.803e-01, Validation Loss: 5.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13705, Training Loss: 1.803e-01, Validation Loss: 5.958e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13706, Training Loss: 1.803e-01, Validation Loss: 5.958e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13707, Training Loss: 1.803e-01, Validation Loss: 5.958e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13708, Training Loss: 1.803e-01, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13709, Training Loss: 1.802e-01, Validation Loss: 5.958e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13710, Training Loss: 1.802e-01, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13711, Training Loss: 1.802e-01, Validation Loss: 5.957e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13712, Training Loss: 1.802e-01, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13713, Training Loss: 1.802e-01, Validation Loss: 5.957e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13714, Training Loss: 1.801e-01, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13715, Training Loss: 1.801e-01, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13716, Training Loss: 1.801e-01, Validation Loss: 5.957e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13717, Training Loss: 1.801e-01, Validation Loss: 5.957e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13718, Training Loss: 1.801e-01, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13719, Training Loss: 1.801e-01, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13720, Training Loss: 1.800e-01, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13721, Training Loss: 1.800e-01, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13722, Training Loss: 1.800e-01, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13723, Training Loss: 1.800e-01, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13724, Training Loss: 1.800e-01, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13725, Training Loss: 1.800e-01, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13726, Training Loss: 1.799e-01, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13727, Training Loss: 1.799e-01, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13728, Training Loss: 1.799e-01, Validation Loss: 5.956e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13729, Training Loss: 1.799e-01, Validation Loss: 5.956e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13730, Training Loss: 1.799e-01, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13731, Training Loss: 1.798e-01, Validation Loss: 5.955e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13732, Training Loss: 1.798e-01, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13733, Training Loss: 1.798e-01, Validation Loss: 5.955e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13734, Training Loss: 1.798e-01, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13735, Training Loss: 1.798e-01, Validation Loss: 5.955e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13736, Training Loss: 1.798e-01, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13737, Training Loss: 1.797e-01, Validation Loss: 5.955e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13738, Training Loss: 1.797e-01, Validation Loss: 5.955e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13739, Training Loss: 1.797e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13740, Training Loss: 1.797e-01, Validation Loss: 5.954e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13741, Training Loss: 1.797e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13742, Training Loss: 1.797e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13743, Training Loss: 1.796e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13744, Training Loss: 1.796e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13745, Training Loss: 1.796e-01, Validation Loss: 5.954e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13746, Training Loss: 1.796e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13747, Training Loss: 1.796e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13748, Training Loss: 1.796e-01, Validation Loss: 5.954e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13749, Training Loss: 1.795e-01, Validation Loss: 5.954e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13750, Training Loss: 1.795e-01, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13751, Training Loss: 1.795e-01, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13752, Training Loss: 1.795e-01, Validation Loss: 5.953e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 13753, Training Loss: 1.795e-01, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13754, Training Loss: 1.794e-01, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13755, Training Loss: 1.794e-01, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13756, Training Loss: 1.794e-01, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13757, Training Loss: 1.794e-01, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13758, Training Loss: 1.794e-01, Validation Loss: 5.953e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13759, Training Loss: 1.794e-01, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13760, Training Loss: 1.793e-01, Validation Loss: 5.953e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13761, Training Loss: 1.793e-01, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13762, Training Loss: 1.793e-01, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13763, Training Loss: 1.793e-01, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13764, Training Loss: 1.793e-01, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13765, Training Loss: 1.793e-01, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13766, Training Loss: 1.792e-01, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13767, Training Loss: 1.792e-01, Validation Loss: 5.952e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13768, Training Loss: 1.792e-01, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13769, Training Loss: 1.792e-01, Validation Loss: 5.952e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13770, Training Loss: 1.792e-01, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13771, Training Loss: 1.791e-01, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13772, Training Loss: 1.791e-01, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13773, Training Loss: 1.791e-01, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13774, Training Loss: 1.791e-01, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13775, Training Loss: 1.791e-01, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13776, Training Loss: 1.791e-01, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13777, Training Loss: 1.790e-01, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13778, Training Loss: 1.790e-01, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13779, Training Loss: 1.790e-01, Validation Loss: 5.951e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13780, Training Loss: 1.790e-01, Validation Loss: 5.951e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13781, Training Loss: 1.790e-01, Validation Loss: 5.951e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 13782, Training Loss: 1.790e-01, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13783, Training Loss: 1.789e-01, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13784, Training Loss: 1.789e-01, Validation Loss: 5.950e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13785, Training Loss: 1.789e-01, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13786, Training Loss: 1.789e-01, Validation Loss: 5.950e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13787, Training Loss: 1.789e-01, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13788, Training Loss: 1.789e-01, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13789, Training Loss: 1.788e-01, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13790, Training Loss: 1.788e-01, Validation Loss: 5.950e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13791, Training Loss: 1.788e-01, Validation Loss: 5.950e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13792, Training Loss: 1.788e-01, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13793, Training Loss: 1.788e-01, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13794, Training Loss: 1.787e-01, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13795, Training Loss: 1.787e-01, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13796, Training Loss: 1.787e-01, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13797, Training Loss: 1.787e-01, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13798, Training Loss: 1.787e-01, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13799, Training Loss: 1.787e-01, Validation Loss: 5.949e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13800, Training Loss: 1.786e-01, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13801, Training Loss: 1.786e-01, Validation Loss: 5.949e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13802, Training Loss: 1.786e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13803, Training Loss: 1.786e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13804, Training Loss: 1.786e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13805, Training Loss: 1.786e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13806, Training Loss: 1.785e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13807, Training Loss: 1.785e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13808, Training Loss: 1.785e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13809, Training Loss: 1.785e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13810, Training Loss: 1.785e-01, Validation Loss: 5.948e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13811, Training Loss: 1.785e-01, Validation Loss: 5.948e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13812, Training Loss: 1.784e-01, Validation Loss: 5.948e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13813, Training Loss: 1.784e-01, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13814, Training Loss: 1.784e-01, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13815, Training Loss: 1.784e-01, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13816, Training Loss: 1.784e-01, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13817, Training Loss: 1.783e-01, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13818, Training Loss: 1.783e-01, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13819, Training Loss: 1.783e-01, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13820, Training Loss: 1.783e-01, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13821, Training Loss: 1.783e-01, Validation Loss: 5.947e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13822, Training Loss: 1.783e-01, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13823, Training Loss: 1.782e-01, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13824, Training Loss: 1.782e-01, Validation Loss: 5.947e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13825, Training Loss: 1.782e-01, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13826, Training Loss: 1.782e-01, Validation Loss: 5.946e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13827, Training Loss: 1.782e-01, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13828, Training Loss: 1.782e-01, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13829, Training Loss: 1.781e-01, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13830, Training Loss: 1.781e-01, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13831, Training Loss: 1.781e-01, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13832, Training Loss: 1.781e-01, Validation Loss: 5.946e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13833, Training Loss: 1.781e-01, Validation Loss: 5.946e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13834, Training Loss: 1.781e-01, Validation Loss: 5.946e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13835, Training Loss: 1.780e-01, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13836, Training Loss: 1.780e-01, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13837, Training Loss: 1.780e-01, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13838, Training Loss: 1.780e-01, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13839, Training Loss: 1.780e-01, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13840, Training Loss: 1.779e-01, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13841, Training Loss: 1.779e-01, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13842, Training Loss: 1.779e-01, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13843, Training Loss: 1.779e-01, Validation Loss: 5.945e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13844, Training Loss: 1.779e-01, Validation Loss: 5.945e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13845, Training Loss: 1.779e-01, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13846, Training Loss: 1.778e-01, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13847, Training Loss: 1.778e-01, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13848, Training Loss: 1.778e-01, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13849, Training Loss: 1.778e-01, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13850, Training Loss: 1.778e-01, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13851, Training Loss: 1.778e-01, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13852, Training Loss: 1.777e-01, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13853, Training Loss: 1.777e-01, Validation Loss: 5.944e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13854, Training Loss: 1.777e-01, Validation Loss: 5.944e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13855, Training Loss: 1.777e-01, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13856, Training Loss: 1.777e-01, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13857, Training Loss: 1.777e-01, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13858, Training Loss: 1.776e-01, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13859, Training Loss: 1.776e-01, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13860, Training Loss: 1.776e-01, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13861, Training Loss: 1.776e-01, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13862, Training Loss: 1.776e-01, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13863, Training Loss: 1.776e-01, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13864, Training Loss: 1.775e-01, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13865, Training Loss: 1.775e-01, Validation Loss: 5.943e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13866, Training Loss: 1.775e-01, Validation Loss: 5.943e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13867, Training Loss: 1.775e-01, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13868, Training Loss: 1.775e-01, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13869, Training Loss: 1.774e-01, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13870, Training Loss: 1.774e-01, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13871, Training Loss: 1.774e-01, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13872, Training Loss: 1.774e-01, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13873, Training Loss: 1.774e-01, Validation Loss: 5.942e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13874, Training Loss: 1.774e-01, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13875, Training Loss: 1.773e-01, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13876, Training Loss: 1.773e-01, Validation Loss: 5.942e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13877, Training Loss: 1.773e-01, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13878, Training Loss: 1.773e-01, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13879, Training Loss: 1.773e-01, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13880, Training Loss: 1.773e-01, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13881, Training Loss: 1.772e-01, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13882, Training Loss: 1.772e-01, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13883, Training Loss: 1.772e-01, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13884, Training Loss: 1.772e-01, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13885, Training Loss: 1.772e-01, Validation Loss: 5.941e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13886, Training Loss: 1.772e-01, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13887, Training Loss: 1.771e-01, Validation Loss: 5.941e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13888, Training Loss: 1.771e-01, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13889, Training Loss: 1.771e-01, Validation Loss: 5.940e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13890, Training Loss: 1.771e-01, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13891, Training Loss: 1.771e-01, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13892, Training Loss: 1.771e-01, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13893, Training Loss: 1.770e-01, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13894, Training Loss: 1.770e-01, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13895, Training Loss: 1.770e-01, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13896, Training Loss: 1.770e-01, Validation Loss: 5.940e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13897, Training Loss: 1.770e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13898, Training Loss: 1.770e-01, Validation Loss: 5.940e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13899, Training Loss: 1.769e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13900, Training Loss: 1.769e-01, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13901, Training Loss: 1.769e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13902, Training Loss: 1.769e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13903, Training Loss: 1.769e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13904, Training Loss: 1.768e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13905, Training Loss: 1.768e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13906, Training Loss: 1.768e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13907, Training Loss: 1.768e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13908, Training Loss: 1.768e-01, Validation Loss: 5.939e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13909, Training Loss: 1.768e-01, Validation Loss: 5.939e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13910, Training Loss: 1.767e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13911, Training Loss: 1.767e-01, Validation Loss: 5.938e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13912, Training Loss: 1.767e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13913, Training Loss: 1.767e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13914, Training Loss: 1.767e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13915, Training Loss: 1.767e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13916, Training Loss: 1.766e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13917, Training Loss: 1.766e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13918, Training Loss: 1.766e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13919, Training Loss: 1.766e-01, Validation Loss: 5.938e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13920, Training Loss: 1.766e-01, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13921, Training Loss: 1.766e-01, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13922, Training Loss: 1.765e-01, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13923, Training Loss: 1.765e-01, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13924, Training Loss: 1.765e-01, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13925, Training Loss: 1.765e-01, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13926, Training Loss: 1.765e-01, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13927, Training Loss: 1.765e-01, Validation Loss: 5.937e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13928, Training Loss: 1.764e-01, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13929, Training Loss: 1.764e-01, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13930, Training Loss: 1.764e-01, Validation Loss: 5.937e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13931, Training Loss: 1.764e-01, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13932, Training Loss: 1.764e-01, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13933, Training Loss: 1.764e-01, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13934, Training Loss: 1.763e-01, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13935, Training Loss: 1.763e-01, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13936, Training Loss: 1.763e-01, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13937, Training Loss: 1.763e-01, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13938, Training Loss: 1.763e-01, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13939, Training Loss: 1.763e-01, Validation Loss: 5.936e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13940, Training Loss: 1.762e-01, Validation Loss: 5.936e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13941, Training Loss: 1.762e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13942, Training Loss: 1.762e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13943, Training Loss: 1.762e-01, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13944, Training Loss: 1.762e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13945, Training Loss: 1.761e-01, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13946, Training Loss: 1.761e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13947, Training Loss: 1.761e-01, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13948, Training Loss: 1.761e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13949, Training Loss: 1.761e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13950, Training Loss: 1.761e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13951, Training Loss: 1.760e-01, Validation Loss: 5.935e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13952, Training Loss: 1.760e-01, Validation Loss: 5.935e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13953, Training Loss: 1.760e-01, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13954, Training Loss: 1.760e-01, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13955, Training Loss: 1.760e-01, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13956, Training Loss: 1.760e-01, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13957, Training Loss: 1.759e-01, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13958, Training Loss: 1.759e-01, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13959, Training Loss: 1.759e-01, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13960, Training Loss: 1.759e-01, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13961, Training Loss: 1.759e-01, Validation Loss: 5.934e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13962, Training Loss: 1.759e-01, Validation Loss: 5.934e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13963, Training Loss: 1.758e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13964, Training Loss: 1.758e-01, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13965, Training Loss: 1.758e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13966, Training Loss: 1.758e-01, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13967, Training Loss: 1.758e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13968, Training Loss: 1.758e-01, Validation Loss: 5.933e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13969, Training Loss: 1.757e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13970, Training Loss: 1.757e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13971, Training Loss: 1.757e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13972, Training Loss: 1.757e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13973, Training Loss: 1.757e-01, Validation Loss: 5.933e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13974, Training Loss: 1.757e-01, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13975, Training Loss: 1.756e-01, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13976, Training Loss: 1.756e-01, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13977, Training Loss: 1.756e-01, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13978, Training Loss: 1.756e-01, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13979, Training Loss: 1.756e-01, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13980, Training Loss: 1.756e-01, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13981, Training Loss: 1.755e-01, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13982, Training Loss: 1.755e-01, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13983, Training Loss: 1.755e-01, Validation Loss: 5.932e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13984, Training Loss: 1.755e-01, Validation Loss: 5.932e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13985, Training Loss: 1.755e-01, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13986, Training Loss: 1.755e-01, Validation Loss: 5.931e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 13987, Training Loss: 1.754e-01, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13988, Training Loss: 1.754e-01, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13989, Training Loss: 1.754e-01, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13990, Training Loss: 1.754e-01, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13991, Training Loss: 1.754e-01, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13992, Training Loss: 1.754e-01, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13993, Training Loss: 1.753e-01, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13994, Training Loss: 1.753e-01, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13995, Training Loss: 1.753e-01, Validation Loss: 5.931e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13996, Training Loss: 1.753e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13997, Training Loss: 1.753e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13998, Training Loss: 1.752e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 13999, Training Loss: 1.752e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14000, Training Loss: 1.752e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14001, Training Loss: 1.752e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14002, Training Loss: 1.752e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14003, Training Loss: 1.752e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14004, Training Loss: 1.751e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14005, Training Loss: 1.751e-01, Validation Loss: 5.930e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14006, Training Loss: 1.751e-01, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14007, Training Loss: 1.751e-01, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14008, Training Loss: 1.751e-01, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14009, Training Loss: 1.751e-01, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14010, Training Loss: 1.750e-01, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14011, Training Loss: 1.750e-01, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14012, Training Loss: 1.750e-01, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14013, Training Loss: 1.750e-01, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14014, Training Loss: 1.750e-01, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14015, Training Loss: 1.750e-01, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14016, Training Loss: 1.749e-01, Validation Loss: 5.929e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14017, Training Loss: 1.749e-01, Validation Loss: 5.929e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14018, Training Loss: 1.749e-01, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14019, Training Loss: 1.749e-01, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14020, Training Loss: 1.749e-01, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14021, Training Loss: 1.749e-01, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14022, Training Loss: 1.748e-01, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14023, Training Loss: 1.748e-01, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14024, Training Loss: 1.748e-01, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14025, Training Loss: 1.748e-01, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14026, Training Loss: 1.748e-01, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14027, Training Loss: 1.748e-01, Validation Loss: 5.928e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14028, Training Loss: 1.747e-01, Validation Loss: 5.928e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14029, Training Loss: 1.747e-01, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14030, Training Loss: 1.747e-01, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14031, Training Loss: 1.747e-01, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14032, Training Loss: 1.747e-01, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14033, Training Loss: 1.747e-01, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14034, Training Loss: 1.746e-01, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14035, Training Loss: 1.746e-01, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14036, Training Loss: 1.746e-01, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14037, Training Loss: 1.746e-01, Validation Loss: 5.927e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14038, Training Loss: 1.746e-01, Validation Loss: 5.927e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14039, Training Loss: 1.746e-01, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14040, Training Loss: 1.745e-01, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14041, Training Loss: 1.745e-01, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14042, Training Loss: 1.745e-01, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14043, Training Loss: 1.745e-01, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14044, Training Loss: 1.745e-01, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14045, Training Loss: 1.745e-01, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14046, Training Loss: 1.744e-01, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14047, Training Loss: 1.744e-01, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14048, Training Loss: 1.744e-01, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14049, Training Loss: 1.744e-01, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14050, Training Loss: 1.744e-01, Validation Loss: 5.926e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14051, Training Loss: 1.744e-01, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14052, Training Loss: 1.743e-01, Validation Loss: 5.926e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14053, Training Loss: 1.743e-01, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14054, Training Loss: 1.743e-01, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14055, Training Loss: 1.743e-01, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14056, Training Loss: 1.743e-01, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14057, Training Loss: 1.743e-01, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14058, Training Loss: 1.742e-01, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14059, Training Loss: 1.742e-01, Validation Loss: 5.925e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14060, Training Loss: 1.742e-01, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14061, Training Loss: 1.742e-01, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14062, Training Loss: 1.742e-01, Validation Loss: 5.925e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14063, Training Loss: 1.742e-01, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14064, Training Loss: 1.741e-01, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14065, Training Loss: 1.741e-01, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14066, Training Loss: 1.741e-01, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14067, Training Loss: 1.741e-01, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14068, Training Loss: 1.741e-01, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14069, Training Loss: 1.741e-01, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14070, Training Loss: 1.740e-01, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14071, Training Loss: 1.740e-01, Validation Loss: 5.924e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14072, Training Loss: 1.740e-01, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14073, Training Loss: 1.740e-01, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14074, Training Loss: 1.740e-01, Validation Loss: 5.924e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14075, Training Loss: 1.740e-01, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14076, Training Loss: 1.739e-01, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14077, Training Loss: 1.739e-01, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14078, Training Loss: 1.739e-01, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14079, Training Loss: 1.739e-01, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14080, Training Loss: 1.739e-01, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14081, Training Loss: 1.739e-01, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14082, Training Loss: 1.738e-01, Validation Loss: 5.923e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14083, Training Loss: 1.738e-01, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14084, Training Loss: 1.738e-01, Validation Loss: 5.923e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14085, Training Loss: 1.738e-01, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14086, Training Loss: 1.738e-01, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14087, Training Loss: 1.738e-01, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14088, Training Loss: 1.737e-01, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14089, Training Loss: 1.737e-01, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14090, Training Loss: 1.737e-01, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14091, Training Loss: 1.737e-01, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14092, Training Loss: 1.737e-01, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14093, Training Loss: 1.737e-01, Validation Loss: 5.922e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14094, Training Loss: 1.736e-01, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14095, Training Loss: 1.736e-01, Validation Loss: 5.922e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14096, Training Loss: 1.736e-01, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14097, Training Loss: 1.736e-01, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14098, Training Loss: 1.736e-01, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14099, Training Loss: 1.736e-01, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14100, Training Loss: 1.735e-01, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14101, Training Loss: 1.735e-01, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14102, Training Loss: 1.735e-01, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14103, Training Loss: 1.735e-01, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14104, Training Loss: 1.735e-01, Validation Loss: 5.921e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14105, Training Loss: 1.735e-01, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14106, Training Loss: 1.734e-01, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14107, Training Loss: 1.734e-01, Validation Loss: 5.921e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14108, Training Loss: 1.734e-01, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14109, Training Loss: 1.734e-01, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14110, Training Loss: 1.734e-01, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14111, Training Loss: 1.734e-01, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14112, Training Loss: 1.733e-01, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14113, Training Loss: 1.733e-01, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14114, Training Loss: 1.733e-01, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14115, Training Loss: 1.733e-01, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14116, Training Loss: 1.733e-01, Validation Loss: 5.920e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14117, Training Loss: 1.733e-01, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14118, Training Loss: 1.732e-01, Validation Loss: 5.920e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14119, Training Loss: 1.732e-01, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14120, Training Loss: 1.732e-01, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14121, Training Loss: 1.732e-01, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14122, Training Loss: 1.732e-01, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14123, Training Loss: 1.732e-01, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14124, Training Loss: 1.731e-01, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14125, Training Loss: 1.731e-01, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14126, Training Loss: 1.731e-01, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14127, Training Loss: 1.731e-01, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14128, Training Loss: 1.731e-01, Validation Loss: 5.919e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14129, Training Loss: 1.731e-01, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14130, Training Loss: 1.730e-01, Validation Loss: 5.919e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14131, Training Loss: 1.730e-01, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14132, Training Loss: 1.730e-01, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14133, Training Loss: 1.730e-01, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14134, Training Loss: 1.730e-01, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14135, Training Loss: 1.730e-01, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14136, Training Loss: 1.729e-01, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14137, Training Loss: 1.729e-01, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14138, Training Loss: 1.729e-01, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14139, Training Loss: 1.729e-01, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14140, Training Loss: 1.729e-01, Validation Loss: 5.918e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14141, Training Loss: 1.729e-01, Validation Loss: 5.918e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14142, Training Loss: 1.728e-01, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14143, Training Loss: 1.728e-01, Validation Loss: 5.917e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14144, Training Loss: 1.728e-01, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14145, Training Loss: 1.728e-01, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14146, Training Loss: 1.728e-01, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14147, Training Loss: 1.728e-01, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14148, Training Loss: 1.727e-01, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14149, Training Loss: 1.727e-01, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14150, Training Loss: 1.727e-01, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14151, Training Loss: 1.727e-01, Validation Loss: 5.917e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14152, Training Loss: 1.727e-01, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14153, Training Loss: 1.727e-01, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14154, Training Loss: 1.726e-01, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14155, Training Loss: 1.726e-01, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14156, Training Loss: 1.726e-01, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14157, Training Loss: 1.726e-01, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14158, Training Loss: 1.726e-01, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14159, Training Loss: 1.726e-01, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14160, Training Loss: 1.725e-01, Validation Loss: 5.916e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14161, Training Loss: 1.725e-01, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14162, Training Loss: 1.725e-01, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14163, Training Loss: 1.725e-01, Validation Loss: 5.916e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14164, Training Loss: 1.725e-01, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14165, Training Loss: 1.725e-01, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14166, Training Loss: 1.724e-01, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14167, Training Loss: 1.724e-01, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14168, Training Loss: 1.724e-01, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14169, Training Loss: 1.724e-01, Validation Loss: 5.915e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14170, Training Loss: 1.724e-01, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14171, Training Loss: 1.724e-01, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14172, Training Loss: 1.723e-01, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14173, Training Loss: 1.723e-01, Validation Loss: 5.915e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14174, Training Loss: 1.723e-01, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14175, Training Loss: 1.723e-01, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14176, Training Loss: 1.723e-01, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14177, Training Loss: 1.723e-01, Validation Loss: 5.914e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14178, Training Loss: 1.722e-01, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14179, Training Loss: 1.722e-01, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14180, Training Loss: 1.722e-01, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14181, Training Loss: 1.722e-01, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14182, Training Loss: 1.722e-01, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14183, Training Loss: 1.722e-01, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14184, Training Loss: 1.721e-01, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14185, Training Loss: 1.721e-01, Validation Loss: 5.914e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14186, Training Loss: 1.721e-01, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14187, Training Loss: 1.721e-01, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14188, Training Loss: 1.721e-01, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14189, Training Loss: 1.721e-01, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14190, Training Loss: 1.720e-01, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14191, Training Loss: 1.720e-01, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14192, Training Loss: 1.720e-01, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14193, Training Loss: 1.720e-01, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14194, Training Loss: 1.720e-01, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14195, Training Loss: 1.720e-01, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14196, Training Loss: 1.720e-01, Validation Loss: 5.913e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14197, Training Loss: 1.719e-01, Validation Loss: 5.913e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14198, Training Loss: 1.719e-01, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14199, Training Loss: 1.719e-01, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14200, Training Loss: 1.719e-01, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14201, Training Loss: 1.719e-01, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14202, Training Loss: 1.719e-01, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14203, Training Loss: 1.718e-01, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14204, Training Loss: 1.718e-01, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14205, Training Loss: 1.718e-01, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14206, Training Loss: 1.718e-01, Validation Loss: 5.912e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14207, Training Loss: 1.718e-01, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14208, Training Loss: 1.718e-01, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14209, Training Loss: 1.717e-01, Validation Loss: 5.912e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14210, Training Loss: 1.717e-01, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14211, Training Loss: 1.717e-01, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14212, Training Loss: 1.717e-01, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14213, Training Loss: 1.717e-01, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14214, Training Loss: 1.717e-01, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14215, Training Loss: 1.716e-01, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14216, Training Loss: 1.716e-01, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14217, Training Loss: 1.716e-01, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14218, Training Loss: 1.716e-01, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14219, Training Loss: 1.716e-01, Validation Loss: 5.911e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14220, Training Loss: 1.716e-01, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14221, Training Loss: 1.715e-01, Validation Loss: 5.911e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14222, Training Loss: 1.715e-01, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14223, Training Loss: 1.715e-01, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14224, Training Loss: 1.715e-01, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14225, Training Loss: 1.715e-01, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14226, Training Loss: 1.715e-01, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14227, Training Loss: 1.714e-01, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14228, Training Loss: 1.714e-01, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14229, Training Loss: 1.714e-01, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14230, Training Loss: 1.714e-01, Validation Loss: 5.910e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14231, Training Loss: 1.714e-01, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14232, Training Loss: 1.714e-01, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14233, Training Loss: 1.713e-01, Validation Loss: 5.910e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14234, Training Loss: 1.713e-01, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14235, Training Loss: 1.713e-01, Validation Loss: 5.909e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14236, Training Loss: 1.713e-01, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14237, Training Loss: 1.713e-01, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14238, Training Loss: 1.713e-01, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14239, Training Loss: 1.712e-01, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14240, Training Loss: 1.712e-01, Validation Loss: 5.909e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14241, Training Loss: 1.712e-01, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14242, Training Loss: 1.712e-01, Validation Loss: 5.909e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14243, Training Loss: 1.712e-01, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14244, Training Loss: 1.712e-01, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14245, Training Loss: 1.711e-01, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14246, Training Loss: 1.711e-01, Validation Loss: 5.908e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14247, Training Loss: 1.711e-01, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14248, Training Loss: 1.711e-01, Validation Loss: 5.908e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14249, Training Loss: 1.711e-01, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14250, Training Loss: 1.711e-01, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14251, Training Loss: 1.711e-01, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14252, Training Loss: 1.710e-01, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14253, Training Loss: 1.710e-01, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14254, Training Loss: 1.710e-01, Validation Loss: 5.908e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14255, Training Loss: 1.710e-01, Validation Loss: 5.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14256, Training Loss: 1.710e-01, Validation Loss: 5.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14257, Training Loss: 1.710e-01, Validation Loss: 5.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14258, Training Loss: 1.709e-01, Validation Loss: 5.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14259, Training Loss: 1.709e-01, Validation Loss: 5.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14260, Training Loss: 1.709e-01, Validation Loss: 5.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14261, Training Loss: 1.709e-01, Validation Loss: 5.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14262, Training Loss: 1.709e-01, Validation Loss: 5.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14263, Training Loss: 1.709e-01, Validation Loss: 5.907e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14264, Training Loss: 1.708e-01, Validation Loss: 5.907e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14265, Training Loss: 1.708e-01, Validation Loss: 5.907e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14266, Training Loss: 1.708e-01, Validation Loss: 5.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14267, Training Loss: 1.708e-01, Validation Loss: 5.907e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14268, Training Loss: 1.708e-01, Validation Loss: 5.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14269, Training Loss: 1.708e-01, Validation Loss: 5.906e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14270, Training Loss: 1.707e-01, Validation Loss: 5.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14271, Training Loss: 1.707e-01, Validation Loss: 5.906e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14272, Training Loss: 1.707e-01, Validation Loss: 5.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14273, Training Loss: 1.707e-01, Validation Loss: 5.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14274, Training Loss: 1.707e-01, Validation Loss: 5.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14275, Training Loss: 1.707e-01, Validation Loss: 5.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14276, Training Loss: 1.706e-01, Validation Loss: 5.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14277, Training Loss: 1.706e-01, Validation Loss: 5.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14278, Training Loss: 1.706e-01, Validation Loss: 5.906e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14279, Training Loss: 1.706e-01, Validation Loss: 5.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14280, Training Loss: 1.706e-01, Validation Loss: 5.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14281, Training Loss: 1.706e-01, Validation Loss: 5.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14282, Training Loss: 1.705e-01, Validation Loss: 5.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14283, Training Loss: 1.705e-01, Validation Loss: 5.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14284, Training Loss: 1.705e-01, Validation Loss: 5.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14285, Training Loss: 1.705e-01, Validation Loss: 5.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14286, Training Loss: 1.705e-01, Validation Loss: 5.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14287, Training Loss: 1.705e-01, Validation Loss: 5.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14288, Training Loss: 1.704e-01, Validation Loss: 5.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14289, Training Loss: 1.704e-01, Validation Loss: 5.905e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14290, Training Loss: 1.704e-01, Validation Loss: 5.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14291, Training Loss: 1.704e-01, Validation Loss: 5.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14292, Training Loss: 1.704e-01, Validation Loss: 5.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14293, Training Loss: 1.704e-01, Validation Loss: 5.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14294, Training Loss: 1.704e-01, Validation Loss: 5.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14295, Training Loss: 1.703e-01, Validation Loss: 5.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14296, Training Loss: 1.703e-01, Validation Loss: 5.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14297, Training Loss: 1.703e-01, Validation Loss: 5.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14298, Training Loss: 1.703e-01, Validation Loss: 5.904e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14299, Training Loss: 1.703e-01, Validation Loss: 5.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14300, Training Loss: 1.703e-01, Validation Loss: 5.904e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14301, Training Loss: 1.702e-01, Validation Loss: 5.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14302, Training Loss: 1.702e-01, Validation Loss: 5.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14303, Training Loss: 1.702e-01, Validation Loss: 5.903e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14304, Training Loss: 1.702e-01, Validation Loss: 5.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14305, Training Loss: 1.702e-01, Validation Loss: 5.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14306, Training Loss: 1.702e-01, Validation Loss: 5.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14307, Training Loss: 1.701e-01, Validation Loss: 5.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14308, Training Loss: 1.701e-01, Validation Loss: 5.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14309, Training Loss: 1.701e-01, Validation Loss: 5.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14310, Training Loss: 1.701e-01, Validation Loss: 5.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14311, Training Loss: 1.701e-01, Validation Loss: 5.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14312, Training Loss: 1.701e-01, Validation Loss: 5.903e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14313, Training Loss: 1.700e-01, Validation Loss: 5.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14314, Training Loss: 1.700e-01, Validation Loss: 5.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14315, Training Loss: 1.700e-01, Validation Loss: 5.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14316, Training Loss: 1.700e-01, Validation Loss: 5.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14317, Training Loss: 1.700e-01, Validation Loss: 5.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14318, Training Loss: 1.700e-01, Validation Loss: 5.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14319, Training Loss: 1.699e-01, Validation Loss: 5.902e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14320, Training Loss: 1.699e-01, Validation Loss: 5.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14321, Training Loss: 1.699e-01, Validation Loss: 5.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14322, Training Loss: 1.699e-01, Validation Loss: 5.902e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14323, Training Loss: 1.699e-01, Validation Loss: 5.902e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14324, Training Loss: 1.699e-01, Validation Loss: 5.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14325, Training Loss: 1.699e-01, Validation Loss: 5.902e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14326, Training Loss: 1.698e-01, Validation Loss: 5.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14327, Training Loss: 1.698e-01, Validation Loss: 5.901e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14328, Training Loss: 1.698e-01, Validation Loss: 5.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14329, Training Loss: 1.698e-01, Validation Loss: 5.901e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14330, Training Loss: 1.698e-01, Validation Loss: 5.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14331, Training Loss: 1.698e-01, Validation Loss: 5.901e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14332, Training Loss: 1.697e-01, Validation Loss: 5.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14333, Training Loss: 1.697e-01, Validation Loss: 5.901e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14334, Training Loss: 1.697e-01, Validation Loss: 5.901e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14335, Training Loss: 1.697e-01, Validation Loss: 5.901e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14336, Training Loss: 1.697e-01, Validation Loss: 5.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14337, Training Loss: 1.697e-01, Validation Loss: 5.901e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14338, Training Loss: 1.696e-01, Validation Loss: 5.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14339, Training Loss: 1.696e-01, Validation Loss: 5.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14340, Training Loss: 1.696e-01, Validation Loss: 5.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14341, Training Loss: 1.696e-01, Validation Loss: 5.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14342, Training Loss: 1.696e-01, Validation Loss: 5.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14343, Training Loss: 1.696e-01, Validation Loss: 5.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14344, Training Loss: 1.695e-01, Validation Loss: 5.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14345, Training Loss: 1.695e-01, Validation Loss: 5.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14346, Training Loss: 1.695e-01, Validation Loss: 5.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14347, Training Loss: 1.695e-01, Validation Loss: 5.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14348, Training Loss: 1.695e-01, Validation Loss: 5.900e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14349, Training Loss: 1.695e-01, Validation Loss: 5.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14350, Training Loss: 1.694e-01, Validation Loss: 5.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14351, Training Loss: 1.694e-01, Validation Loss: 5.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14352, Training Loss: 1.694e-01, Validation Loss: 5.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14353, Training Loss: 1.694e-01, Validation Loss: 5.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14354, Training Loss: 1.694e-01, Validation Loss: 5.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14355, Training Loss: 1.694e-01, Validation Loss: 5.899e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14356, Training Loss: 1.694e-01, Validation Loss: 5.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14357, Training Loss: 1.693e-01, Validation Loss: 5.899e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14358, Training Loss: 1.693e-01, Validation Loss: 5.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14359, Training Loss: 1.693e-01, Validation Loss: 5.899e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14360, Training Loss: 1.693e-01, Validation Loss: 5.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14361, Training Loss: 1.693e-01, Validation Loss: 5.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14362, Training Loss: 1.693e-01, Validation Loss: 5.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14363, Training Loss: 1.692e-01, Validation Loss: 5.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14364, Training Loss: 1.692e-01, Validation Loss: 5.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14365, Training Loss: 1.692e-01, Validation Loss: 5.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14366, Training Loss: 1.692e-01, Validation Loss: 5.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14367, Training Loss: 1.692e-01, Validation Loss: 5.898e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14368, Training Loss: 1.692e-01, Validation Loss: 5.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14369, Training Loss: 1.691e-01, Validation Loss: 5.898e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14370, Training Loss: 1.691e-01, Validation Loss: 5.898e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14371, Training Loss: 1.691e-01, Validation Loss: 5.898e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14372, Training Loss: 1.691e-01, Validation Loss: 5.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14373, Training Loss: 1.691e-01, Validation Loss: 5.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14374, Training Loss: 1.691e-01, Validation Loss: 5.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14375, Training Loss: 1.690e-01, Validation Loss: 5.897e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14376, Training Loss: 1.690e-01, Validation Loss: 5.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14377, Training Loss: 1.690e-01, Validation Loss: 5.897e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14378, Training Loss: 1.690e-01, Validation Loss: 5.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14379, Training Loss: 1.690e-01, Validation Loss: 5.897e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14380, Training Loss: 1.690e-01, Validation Loss: 5.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14381, Training Loss: 1.690e-01, Validation Loss: 5.897e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14382, Training Loss: 1.689e-01, Validation Loss: 5.897e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14383, Training Loss: 1.689e-01, Validation Loss: 5.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14384, Training Loss: 1.689e-01, Validation Loss: 5.896e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14385, Training Loss: 1.689e-01, Validation Loss: 5.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14386, Training Loss: 1.689e-01, Validation Loss: 5.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14387, Training Loss: 1.689e-01, Validation Loss: 5.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14388, Training Loss: 1.688e-01, Validation Loss: 5.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14389, Training Loss: 1.688e-01, Validation Loss: 5.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14390, Training Loss: 1.688e-01, Validation Loss: 5.896e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14391, Training Loss: 1.688e-01, Validation Loss: 5.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14392, Training Loss: 1.688e-01, Validation Loss: 5.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14393, Training Loss: 1.688e-01, Validation Loss: 5.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14394, Training Loss: 1.687e-01, Validation Loss: 5.896e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14395, Training Loss: 1.687e-01, Validation Loss: 5.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14396, Training Loss: 1.687e-01, Validation Loss: 5.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14397, Training Loss: 1.687e-01, Validation Loss: 5.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14398, Training Loss: 1.687e-01, Validation Loss: 5.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14399, Training Loss: 1.687e-01, Validation Loss: 5.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14400, Training Loss: 1.686e-01, Validation Loss: 5.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14401, Training Loss: 1.686e-01, Validation Loss: 5.895e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14402, Training Loss: 1.686e-01, Validation Loss: 5.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14403, Training Loss: 1.686e-01, Validation Loss: 5.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14404, Training Loss: 1.686e-01, Validation Loss: 5.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14405, Training Loss: 1.686e-01, Validation Loss: 5.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14406, Training Loss: 1.686e-01, Validation Loss: 5.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14407, Training Loss: 1.685e-01, Validation Loss: 5.895e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14408, Training Loss: 1.685e-01, Validation Loss: 5.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14409, Training Loss: 1.685e-01, Validation Loss: 5.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14410, Training Loss: 1.685e-01, Validation Loss: 5.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14411, Training Loss: 1.685e-01, Validation Loss: 5.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14412, Training Loss: 1.685e-01, Validation Loss: 5.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14413, Training Loss: 1.684e-01, Validation Loss: 5.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14414, Training Loss: 1.684e-01, Validation Loss: 5.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14415, Training Loss: 1.684e-01, Validation Loss: 5.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14416, Training Loss: 1.684e-01, Validation Loss: 5.894e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14417, Training Loss: 1.684e-01, Validation Loss: 5.894e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14418, Training Loss: 1.684e-01, Validation Loss: 5.894e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 14419, Training Loss: 1.683e-01, Validation Loss: 5.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14420, Training Loss: 1.683e-01, Validation Loss: 5.893e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14421, Training Loss: 1.683e-01, Validation Loss: 5.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14422, Training Loss: 1.683e-01, Validation Loss: 5.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14423, Training Loss: 1.683e-01, Validation Loss: 5.893e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14424, Training Loss: 1.683e-01, Validation Loss: 5.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14425, Training Loss: 1.682e-01, Validation Loss: 5.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14426, Training Loss: 1.682e-01, Validation Loss: 5.893e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14427, Training Loss: 1.682e-01, Validation Loss: 5.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14428, Training Loss: 1.682e-01, Validation Loss: 5.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14429, Training Loss: 1.682e-01, Validation Loss: 5.893e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14430, Training Loss: 1.682e-01, Validation Loss: 5.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14431, Training Loss: 1.682e-01, Validation Loss: 5.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14432, Training Loss: 1.681e-01, Validation Loss: 5.892e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14433, Training Loss: 1.681e-01, Validation Loss: 5.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14434, Training Loss: 1.681e-01, Validation Loss: 5.892e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14435, Training Loss: 1.681e-01, Validation Loss: 5.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14436, Training Loss: 1.681e-01, Validation Loss: 5.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14437, Training Loss: 1.681e-01, Validation Loss: 5.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14438, Training Loss: 1.680e-01, Validation Loss: 5.892e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14439, Training Loss: 1.680e-01, Validation Loss: 5.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14440, Training Loss: 1.680e-01, Validation Loss: 5.892e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14441, Training Loss: 1.680e-01, Validation Loss: 5.892e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14442, Training Loss: 1.680e-01, Validation Loss: 5.892e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 14443, Training Loss: 1.680e-01, Validation Loss: 5.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14444, Training Loss: 1.679e-01, Validation Loss: 5.891e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14445, Training Loss: 1.679e-01, Validation Loss: 5.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14446, Training Loss: 1.679e-01, Validation Loss: 5.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14447, Training Loss: 1.679e-01, Validation Loss: 5.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14448, Training Loss: 1.679e-01, Validation Loss: 5.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14449, Training Loss: 1.679e-01, Validation Loss: 5.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14450, Training Loss: 1.679e-01, Validation Loss: 5.891e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14451, Training Loss: 1.678e-01, Validation Loss: 5.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14452, Training Loss: 1.678e-01, Validation Loss: 5.891e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14453, Training Loss: 1.678e-01, Validation Loss: 5.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14454, Training Loss: 1.678e-01, Validation Loss: 5.891e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14455, Training Loss: 1.678e-01, Validation Loss: 5.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14456, Training Loss: 1.678e-01, Validation Loss: 5.890e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14457, Training Loss: 1.677e-01, Validation Loss: 5.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14458, Training Loss: 1.677e-01, Validation Loss: 5.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14459, Training Loss: 1.677e-01, Validation Loss: 5.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14460, Training Loss: 1.677e-01, Validation Loss: 5.890e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14461, Training Loss: 1.677e-01, Validation Loss: 5.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14462, Training Loss: 1.677e-01, Validation Loss: 5.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14463, Training Loss: 1.676e-01, Validation Loss: 5.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14464, Training Loss: 1.676e-01, Validation Loss: 5.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14465, Training Loss: 1.676e-01, Validation Loss: 5.890e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14466, Training Loss: 1.676e-01, Validation Loss: 5.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14467, Training Loss: 1.676e-01, Validation Loss: 5.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14468, Training Loss: 1.676e-01, Validation Loss: 5.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14469, Training Loss: 1.676e-01, Validation Loss: 5.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14470, Training Loss: 1.675e-01, Validation Loss: 5.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14471, Training Loss: 1.675e-01, Validation Loss: 5.889e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14472, Training Loss: 1.675e-01, Validation Loss: 5.889e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 14473, Training Loss: 1.675e-01, Validation Loss: 5.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14474, Training Loss: 1.675e-01, Validation Loss: 5.889e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14475, Training Loss: 1.675e-01, Validation Loss: 5.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14476, Training Loss: 1.674e-01, Validation Loss: 5.889e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14477, Training Loss: 1.674e-01, Validation Loss: 5.889e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14478, Training Loss: 1.674e-01, Validation Loss: 5.889e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14479, Training Loss: 1.674e-01, Validation Loss: 5.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14480, Training Loss: 1.674e-01, Validation Loss: 5.888e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14481, Training Loss: 1.674e-01, Validation Loss: 5.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14482, Training Loss: 1.673e-01, Validation Loss: 5.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14483, Training Loss: 1.673e-01, Validation Loss: 5.888e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14484, Training Loss: 1.673e-01, Validation Loss: 5.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14485, Training Loss: 1.673e-01, Validation Loss: 5.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14486, Training Loss: 1.673e-01, Validation Loss: 5.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14487, Training Loss: 1.673e-01, Validation Loss: 5.888e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14488, Training Loss: 1.673e-01, Validation Loss: 5.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14489, Training Loss: 1.672e-01, Validation Loss: 5.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14490, Training Loss: 1.672e-01, Validation Loss: 5.888e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14491, Training Loss: 1.672e-01, Validation Loss: 5.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14492, Training Loss: 1.672e-01, Validation Loss: 5.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14493, Training Loss: 1.672e-01, Validation Loss: 5.887e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14494, Training Loss: 1.672e-01, Validation Loss: 5.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14495, Training Loss: 1.671e-01, Validation Loss: 5.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14496, Training Loss: 1.671e-01, Validation Loss: 5.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14497, Training Loss: 1.671e-01, Validation Loss: 5.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14498, Training Loss: 1.671e-01, Validation Loss: 5.887e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14499, Training Loss: 1.671e-01, Validation Loss: 5.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14500, Training Loss: 1.671e-01, Validation Loss: 5.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14501, Training Loss: 1.670e-01, Validation Loss: 5.887e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14502, Training Loss: 1.670e-01, Validation Loss: 5.887e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14503, Training Loss: 1.670e-01, Validation Loss: 5.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14504, Training Loss: 1.670e-01, Validation Loss: 5.886e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14505, Training Loss: 1.670e-01, Validation Loss: 5.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14506, Training Loss: 1.670e-01, Validation Loss: 5.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14507, Training Loss: 1.670e-01, Validation Loss: 5.886e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14508, Training Loss: 1.669e-01, Validation Loss: 5.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14509, Training Loss: 1.669e-01, Validation Loss: 5.886e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14510, Training Loss: 1.669e-01, Validation Loss: 5.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14511, Training Loss: 1.669e-01, Validation Loss: 5.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14512, Training Loss: 1.669e-01, Validation Loss: 5.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14513, Training Loss: 1.669e-01, Validation Loss: 5.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14514, Training Loss: 1.668e-01, Validation Loss: 5.886e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14515, Training Loss: 1.668e-01, Validation Loss: 5.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14516, Training Loss: 1.668e-01, Validation Loss: 5.885e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14517, Training Loss: 1.668e-01, Validation Loss: 5.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14518, Training Loss: 1.668e-01, Validation Loss: 5.885e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14519, Training Loss: 1.668e-01, Validation Loss: 5.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14520, Training Loss: 1.667e-01, Validation Loss: 5.885e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14521, Training Loss: 1.667e-01, Validation Loss: 5.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14522, Training Loss: 1.667e-01, Validation Loss: 5.885e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14523, Training Loss: 1.667e-01, Validation Loss: 5.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14524, Training Loss: 1.667e-01, Validation Loss: 5.885e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14525, Training Loss: 1.667e-01, Validation Loss: 5.885e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14526, Training Loss: 1.667e-01, Validation Loss: 5.885e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14527, Training Loss: 1.666e-01, Validation Loss: 5.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14528, Training Loss: 1.666e-01, Validation Loss: 5.884e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14529, Training Loss: 1.666e-01, Validation Loss: 5.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14530, Training Loss: 1.666e-01, Validation Loss: 5.884e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14531, Training Loss: 1.666e-01, Validation Loss: 5.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14532, Training Loss: 1.666e-01, Validation Loss: 5.884e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14533, Training Loss: 1.665e-01, Validation Loss: 5.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14534, Training Loss: 1.665e-01, Validation Loss: 5.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14535, Training Loss: 1.665e-01, Validation Loss: 5.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14536, Training Loss: 1.665e-01, Validation Loss: 5.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14537, Training Loss: 1.665e-01, Validation Loss: 5.884e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14538, Training Loss: 1.665e-01, Validation Loss: 5.884e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14539, Training Loss: 1.664e-01, Validation Loss: 5.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14540, Training Loss: 1.664e-01, Validation Loss: 5.883e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14541, Training Loss: 1.664e-01, Validation Loss: 5.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14542, Training Loss: 1.664e-01, Validation Loss: 5.883e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14543, Training Loss: 1.664e-01, Validation Loss: 5.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14544, Training Loss: 1.664e-01, Validation Loss: 5.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14545, Training Loss: 1.664e-01, Validation Loss: 5.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14546, Training Loss: 1.663e-01, Validation Loss: 5.883e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14547, Training Loss: 1.663e-01, Validation Loss: 5.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14548, Training Loss: 1.663e-01, Validation Loss: 5.883e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14549, Training Loss: 1.663e-01, Validation Loss: 5.883e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14550, Training Loss: 1.663e-01, Validation Loss: 5.883e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14551, Training Loss: 1.663e-01, Validation Loss: 5.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14552, Training Loss: 1.662e-01, Validation Loss: 5.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14553, Training Loss: 1.662e-01, Validation Loss: 5.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14554, Training Loss: 1.662e-01, Validation Loss: 5.882e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14555, Training Loss: 1.662e-01, Validation Loss: 5.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14556, Training Loss: 1.662e-01, Validation Loss: 5.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14557, Training Loss: 1.662e-01, Validation Loss: 5.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14558, Training Loss: 1.662e-01, Validation Loss: 5.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14559, Training Loss: 1.661e-01, Validation Loss: 5.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14560, Training Loss: 1.661e-01, Validation Loss: 5.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14561, Training Loss: 1.661e-01, Validation Loss: 5.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14562, Training Loss: 1.661e-01, Validation Loss: 5.882e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14563, Training Loss: 1.661e-01, Validation Loss: 5.882e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14564, Training Loss: 1.661e-01, Validation Loss: 5.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14565, Training Loss: 1.660e-01, Validation Loss: 5.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14566, Training Loss: 1.660e-01, Validation Loss: 5.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14567, Training Loss: 1.660e-01, Validation Loss: 5.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14568, Training Loss: 1.660e-01, Validation Loss: 5.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14569, Training Loss: 1.660e-01, Validation Loss: 5.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14570, Training Loss: 1.660e-01, Validation Loss: 5.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14571, Training Loss: 1.659e-01, Validation Loss: 5.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14572, Training Loss: 1.659e-01, Validation Loss: 5.881e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14573, Training Loss: 1.659e-01, Validation Loss: 5.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14574, Training Loss: 1.659e-01, Validation Loss: 5.881e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14575, Training Loss: 1.659e-01, Validation Loss: 5.881e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14576, Training Loss: 1.659e-01, Validation Loss: 5.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14577, Training Loss: 1.659e-01, Validation Loss: 5.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14578, Training Loss: 1.658e-01, Validation Loss: 5.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14579, Training Loss: 1.658e-01, Validation Loss: 5.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14580, Training Loss: 1.658e-01, Validation Loss: 5.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14581, Training Loss: 1.658e-01, Validation Loss: 5.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14582, Training Loss: 1.658e-01, Validation Loss: 5.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14583, Training Loss: 1.658e-01, Validation Loss: 5.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14584, Training Loss: 1.657e-01, Validation Loss: 5.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14585, Training Loss: 1.657e-01, Validation Loss: 5.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14586, Training Loss: 1.657e-01, Validation Loss: 5.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14587, Training Loss: 1.657e-01, Validation Loss: 5.880e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14588, Training Loss: 1.657e-01, Validation Loss: 5.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14589, Training Loss: 1.657e-01, Validation Loss: 5.880e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14590, Training Loss: 1.657e-01, Validation Loss: 5.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14591, Training Loss: 1.656e-01, Validation Loss: 5.879e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14592, Training Loss: 1.656e-01, Validation Loss: 5.879e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 14593, Training Loss: 1.656e-01, Validation Loss: 5.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14594, Training Loss: 1.656e-01, Validation Loss: 5.879e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14595, Training Loss: 1.656e-01, Validation Loss: 5.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14596, Training Loss: 1.656e-01, Validation Loss: 5.879e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14597, Training Loss: 1.655e-01, Validation Loss: 5.879e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14598, Training Loss: 1.655e-01, Validation Loss: 5.879e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14599, Training Loss: 1.655e-01, Validation Loss: 5.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14600, Training Loss: 1.655e-01, Validation Loss: 5.879e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14601, Training Loss: 1.655e-01, Validation Loss: 5.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14602, Training Loss: 1.655e-01, Validation Loss: 5.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14603, Training Loss: 1.655e-01, Validation Loss: 5.878e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14604, Training Loss: 1.654e-01, Validation Loss: 5.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14605, Training Loss: 1.654e-01, Validation Loss: 5.878e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14606, Training Loss: 1.654e-01, Validation Loss: 5.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14607, Training Loss: 1.654e-01, Validation Loss: 5.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14608, Training Loss: 1.654e-01, Validation Loss: 5.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14609, Training Loss: 1.654e-01, Validation Loss: 5.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14610, Training Loss: 1.653e-01, Validation Loss: 5.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14611, Training Loss: 1.653e-01, Validation Loss: 5.878e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14612, Training Loss: 1.653e-01, Validation Loss: 5.878e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14613, Training Loss: 1.653e-01, Validation Loss: 5.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14614, Training Loss: 1.653e-01, Validation Loss: 5.877e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14615, Training Loss: 1.653e-01, Validation Loss: 5.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14616, Training Loss: 1.652e-01, Validation Loss: 5.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14617, Training Loss: 1.652e-01, Validation Loss: 5.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14618, Training Loss: 1.652e-01, Validation Loss: 5.877e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14619, Training Loss: 1.652e-01, Validation Loss: 5.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14620, Training Loss: 1.652e-01, Validation Loss: 5.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14621, Training Loss: 1.652e-01, Validation Loss: 5.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14622, Training Loss: 1.652e-01, Validation Loss: 5.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14623, Training Loss: 1.651e-01, Validation Loss: 5.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14624, Training Loss: 1.651e-01, Validation Loss: 5.877e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14625, Training Loss: 1.651e-01, Validation Loss: 5.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14626, Training Loss: 1.651e-01, Validation Loss: 5.876e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14627, Training Loss: 1.651e-01, Validation Loss: 5.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14628, Training Loss: 1.651e-01, Validation Loss: 5.876e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14629, Training Loss: 1.650e-01, Validation Loss: 5.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14630, Training Loss: 1.650e-01, Validation Loss: 5.876e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14631, Training Loss: 1.650e-01, Validation Loss: 5.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14632, Training Loss: 1.650e-01, Validation Loss: 5.876e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14633, Training Loss: 1.650e-01, Validation Loss: 5.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14634, Training Loss: 1.650e-01, Validation Loss: 5.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14635, Training Loss: 1.650e-01, Validation Loss: 5.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14636, Training Loss: 1.649e-01, Validation Loss: 5.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14637, Training Loss: 1.649e-01, Validation Loss: 5.876e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14638, Training Loss: 1.649e-01, Validation Loss: 5.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14639, Training Loss: 1.649e-01, Validation Loss: 5.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14640, Training Loss: 1.649e-01, Validation Loss: 5.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14641, Training Loss: 1.649e-01, Validation Loss: 5.875e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14642, Training Loss: 1.648e-01, Validation Loss: 5.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14643, Training Loss: 1.648e-01, Validation Loss: 5.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14644, Training Loss: 1.648e-01, Validation Loss: 5.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14645, Training Loss: 1.648e-01, Validation Loss: 5.875e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14646, Training Loss: 1.648e-01, Validation Loss: 5.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14647, Training Loss: 1.648e-01, Validation Loss: 5.875e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14648, Training Loss: 1.648e-01, Validation Loss: 5.875e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14649, Training Loss: 1.647e-01, Validation Loss: 5.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14650, Training Loss: 1.647e-01, Validation Loss: 5.875e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14651, Training Loss: 1.647e-01, Validation Loss: 5.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14652, Training Loss: 1.647e-01, Validation Loss: 5.874e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14653, Training Loss: 1.647e-01, Validation Loss: 5.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14654, Training Loss: 1.647e-01, Validation Loss: 5.874e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14655, Training Loss: 1.646e-01, Validation Loss: 5.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14656, Training Loss: 1.646e-01, Validation Loss: 5.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14657, Training Loss: 1.646e-01, Validation Loss: 5.874e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14658, Training Loss: 1.646e-01, Validation Loss: 5.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14659, Training Loss: 1.646e-01, Validation Loss: 5.874e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14660, Training Loss: 1.646e-01, Validation Loss: 5.874e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14661, Training Loss: 1.646e-01, Validation Loss: 5.874e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14662, Training Loss: 1.645e-01, Validation Loss: 5.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14663, Training Loss: 1.645e-01, Validation Loss: 5.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14664, Training Loss: 1.645e-01, Validation Loss: 5.873e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14665, Training Loss: 1.645e-01, Validation Loss: 5.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14666, Training Loss: 1.645e-01, Validation Loss: 5.873e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14667, Training Loss: 1.645e-01, Validation Loss: 5.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14668, Training Loss: 1.644e-01, Validation Loss: 5.873e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14669, Training Loss: 1.644e-01, Validation Loss: 5.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14670, Training Loss: 1.644e-01, Validation Loss: 5.873e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14671, Training Loss: 1.644e-01, Validation Loss: 5.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14672, Training Loss: 1.644e-01, Validation Loss: 5.873e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14673, Training Loss: 1.644e-01, Validation Loss: 5.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14674, Training Loss: 1.644e-01, Validation Loss: 5.873e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14675, Training Loss: 1.643e-01, Validation Loss: 5.873e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14676, Training Loss: 1.643e-01, Validation Loss: 5.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14677, Training Loss: 1.643e-01, Validation Loss: 5.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14678, Training Loss: 1.643e-01, Validation Loss: 5.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14679, Training Loss: 1.643e-01, Validation Loss: 5.872e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14680, Training Loss: 1.643e-01, Validation Loss: 5.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14681, Training Loss: 1.642e-01, Validation Loss: 5.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14682, Training Loss: 1.642e-01, Validation Loss: 5.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14683, Training Loss: 1.642e-01, Validation Loss: 5.872e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14684, Training Loss: 1.642e-01, Validation Loss: 5.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14685, Training Loss: 1.642e-01, Validation Loss: 5.872e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14686, Training Loss: 1.642e-01, Validation Loss: 5.872e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14687, Training Loss: 1.642e-01, Validation Loss: 5.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14688, Training Loss: 1.641e-01, Validation Loss: 5.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14689, Training Loss: 1.641e-01, Validation Loss: 5.871e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14690, Training Loss: 1.641e-01, Validation Loss: 5.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14691, Training Loss: 1.641e-01, Validation Loss: 5.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14692, Training Loss: 1.641e-01, Validation Loss: 5.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14693, Training Loss: 1.641e-01, Validation Loss: 5.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14694, Training Loss: 1.640e-01, Validation Loss: 5.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14695, Training Loss: 1.640e-01, Validation Loss: 5.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14696, Training Loss: 1.640e-01, Validation Loss: 5.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14697, Training Loss: 1.640e-01, Validation Loss: 5.871e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14698, Training Loss: 1.640e-01, Validation Loss: 5.871e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14699, Training Loss: 1.640e-01, Validation Loss: 5.871e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14700, Training Loss: 1.640e-01, Validation Loss: 5.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14701, Training Loss: 1.639e-01, Validation Loss: 5.871e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14702, Training Loss: 1.639e-01, Validation Loss: 5.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14703, Training Loss: 1.639e-01, Validation Loss: 5.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14704, Training Loss: 1.639e-01, Validation Loss: 5.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14705, Training Loss: 1.639e-01, Validation Loss: 5.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14706, Training Loss: 1.639e-01, Validation Loss: 5.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14707, Training Loss: 1.638e-01, Validation Loss: 5.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14708, Training Loss: 1.638e-01, Validation Loss: 5.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14709, Training Loss: 1.638e-01, Validation Loss: 5.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14710, Training Loss: 1.638e-01, Validation Loss: 5.870e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14711, Training Loss: 1.638e-01, Validation Loss: 5.870e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14712, Training Loss: 1.638e-01, Validation Loss: 5.870e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14713, Training Loss: 1.638e-01, Validation Loss: 5.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14714, Training Loss: 1.637e-01, Validation Loss: 5.869e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14715, Training Loss: 1.637e-01, Validation Loss: 5.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14716, Training Loss: 1.637e-01, Validation Loss: 5.869e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14717, Training Loss: 1.637e-01, Validation Loss: 5.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14718, Training Loss: 1.637e-01, Validation Loss: 5.869e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14719, Training Loss: 1.637e-01, Validation Loss: 5.869e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 14720, Training Loss: 1.636e-01, Validation Loss: 5.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14721, Training Loss: 1.636e-01, Validation Loss: 5.869e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14722, Training Loss: 1.636e-01, Validation Loss: 5.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14723, Training Loss: 1.636e-01, Validation Loss: 5.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14724, Training Loss: 1.636e-01, Validation Loss: 5.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14725, Training Loss: 1.636e-01, Validation Loss: 5.869e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14726, Training Loss: 1.636e-01, Validation Loss: 5.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14727, Training Loss: 1.635e-01, Validation Loss: 5.868e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14728, Training Loss: 1.635e-01, Validation Loss: 5.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14729, Training Loss: 1.635e-01, Validation Loss: 5.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14730, Training Loss: 1.635e-01, Validation Loss: 5.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14731, Training Loss: 1.635e-01, Validation Loss: 5.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14732, Training Loss: 1.635e-01, Validation Loss: 5.868e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14733, Training Loss: 1.635e-01, Validation Loss: 5.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14734, Training Loss: 1.634e-01, Validation Loss: 5.868e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14735, Training Loss: 1.634e-01, Validation Loss: 5.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14736, Training Loss: 1.634e-01, Validation Loss: 5.868e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14737, Training Loss: 1.634e-01, Validation Loss: 5.868e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14738, Training Loss: 1.634e-01, Validation Loss: 5.868e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14739, Training Loss: 1.634e-01, Validation Loss: 5.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14740, Training Loss: 1.633e-01, Validation Loss: 5.867e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14741, Training Loss: 1.633e-01, Validation Loss: 5.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14742, Training Loss: 1.633e-01, Validation Loss: 5.867e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14743, Training Loss: 1.633e-01, Validation Loss: 5.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14744, Training Loss: 1.633e-01, Validation Loss: 5.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14745, Training Loss: 1.633e-01, Validation Loss: 5.867e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14746, Training Loss: 1.633e-01, Validation Loss: 5.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14747, Training Loss: 1.632e-01, Validation Loss: 5.867e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14748, Training Loss: 1.632e-01, Validation Loss: 5.867e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 14749, Training Loss: 1.632e-01, Validation Loss: 5.867e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14750, Training Loss: 1.632e-01, Validation Loss: 5.867e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14751, Training Loss: 1.632e-01, Validation Loss: 5.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14752, Training Loss: 1.632e-01, Validation Loss: 5.866e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14753, Training Loss: 1.631e-01, Validation Loss: 5.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14754, Training Loss: 1.631e-01, Validation Loss: 5.866e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14755, Training Loss: 1.631e-01, Validation Loss: 5.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14756, Training Loss: 1.631e-01, Validation Loss: 5.866e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14757, Training Loss: 1.631e-01, Validation Loss: 5.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14758, Training Loss: 1.631e-01, Validation Loss: 5.866e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14759, Training Loss: 1.631e-01, Validation Loss: 5.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14760, Training Loss: 1.630e-01, Validation Loss: 5.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14761, Training Loss: 1.630e-01, Validation Loss: 5.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14762, Training Loss: 1.630e-01, Validation Loss: 5.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14763, Training Loss: 1.630e-01, Validation Loss: 5.866e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14764, Training Loss: 1.630e-01, Validation Loss: 5.866e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14765, Training Loss: 1.630e-01, Validation Loss: 5.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14766, Training Loss: 1.629e-01, Validation Loss: 5.865e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14767, Training Loss: 1.629e-01, Validation Loss: 5.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14768, Training Loss: 1.629e-01, Validation Loss: 5.865e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14769, Training Loss: 1.629e-01, Validation Loss: 5.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14770, Training Loss: 1.629e-01, Validation Loss: 5.865e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14771, Training Loss: 1.629e-01, Validation Loss: 5.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14772, Training Loss: 1.629e-01, Validation Loss: 5.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14773, Training Loss: 1.628e-01, Validation Loss: 5.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14774, Training Loss: 1.628e-01, Validation Loss: 5.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14775, Training Loss: 1.628e-01, Validation Loss: 5.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14776, Training Loss: 1.628e-01, Validation Loss: 5.865e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14777, Training Loss: 1.628e-01, Validation Loss: 5.865e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14778, Training Loss: 1.628e-01, Validation Loss: 5.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14779, Training Loss: 1.628e-01, Validation Loss: 5.865e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14780, Training Loss: 1.627e-01, Validation Loss: 5.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14781, Training Loss: 1.627e-01, Validation Loss: 5.864e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14782, Training Loss: 1.627e-01, Validation Loss: 5.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14783, Training Loss: 1.627e-01, Validation Loss: 5.864e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14784, Training Loss: 1.627e-01, Validation Loss: 5.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14785, Training Loss: 1.627e-01, Validation Loss: 5.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14786, Training Loss: 1.626e-01, Validation Loss: 5.864e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14787, Training Loss: 1.626e-01, Validation Loss: 5.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14788, Training Loss: 1.626e-01, Validation Loss: 5.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14789, Training Loss: 1.626e-01, Validation Loss: 5.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14790, Training Loss: 1.626e-01, Validation Loss: 5.864e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14791, Training Loss: 1.626e-01, Validation Loss: 5.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14792, Training Loss: 1.626e-01, Validation Loss: 5.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14793, Training Loss: 1.625e-01, Validation Loss: 5.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14794, Training Loss: 1.625e-01, Validation Loss: 5.863e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14795, Training Loss: 1.625e-01, Validation Loss: 5.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14796, Training Loss: 1.625e-01, Validation Loss: 5.863e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14797, Training Loss: 1.625e-01, Validation Loss: 5.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14798, Training Loss: 1.625e-01, Validation Loss: 5.863e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14799, Training Loss: 1.625e-01, Validation Loss: 5.863e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14800, Training Loss: 1.624e-01, Validation Loss: 5.863e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14801, Training Loss: 1.624e-01, Validation Loss: 5.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14802, Training Loss: 1.624e-01, Validation Loss: 5.863e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14803, Training Loss: 1.624e-01, Validation Loss: 5.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14804, Training Loss: 1.624e-01, Validation Loss: 5.863e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14805, Training Loss: 1.624e-01, Validation Loss: 5.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14806, Training Loss: 1.623e-01, Validation Loss: 5.862e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14807, Training Loss: 1.623e-01, Validation Loss: 5.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14808, Training Loss: 1.623e-01, Validation Loss: 5.862e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14809, Training Loss: 1.623e-01, Validation Loss: 5.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14810, Training Loss: 1.623e-01, Validation Loss: 5.862e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14811, Training Loss: 1.623e-01, Validation Loss: 5.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14812, Training Loss: 1.623e-01, Validation Loss: 5.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14813, Training Loss: 1.622e-01, Validation Loss: 5.862e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14814, Training Loss: 1.622e-01, Validation Loss: 5.862e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14815, Training Loss: 1.622e-01, Validation Loss: 5.862e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14816, Training Loss: 1.622e-01, Validation Loss: 5.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14817, Training Loss: 1.622e-01, Validation Loss: 5.862e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14818, Training Loss: 1.622e-01, Validation Loss: 5.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14819, Training Loss: 1.621e-01, Validation Loss: 5.861e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14820, Training Loss: 1.621e-01, Validation Loss: 5.861e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 14821, Training Loss: 1.621e-01, Validation Loss: 5.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14822, Training Loss: 1.621e-01, Validation Loss: 5.861e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14823, Training Loss: 1.621e-01, Validation Loss: 5.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14824, Training Loss: 1.621e-01, Validation Loss: 5.861e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14825, Training Loss: 1.621e-01, Validation Loss: 5.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14826, Training Loss: 1.620e-01, Validation Loss: 5.861e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14827, Training Loss: 1.620e-01, Validation Loss: 5.861e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14828, Training Loss: 1.620e-01, Validation Loss: 5.861e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14829, Training Loss: 1.620e-01, Validation Loss: 5.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14830, Training Loss: 1.620e-01, Validation Loss: 5.861e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14831, Training Loss: 1.620e-01, Validation Loss: 5.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14832, Training Loss: 1.620e-01, Validation Loss: 5.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14833, Training Loss: 1.619e-01, Validation Loss: 5.860e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14834, Training Loss: 1.619e-01, Validation Loss: 5.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14835, Training Loss: 1.619e-01, Validation Loss: 5.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14836, Training Loss: 1.619e-01, Validation Loss: 5.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14837, Training Loss: 1.619e-01, Validation Loss: 5.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14838, Training Loss: 1.619e-01, Validation Loss: 5.860e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14839, Training Loss: 1.618e-01, Validation Loss: 5.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14840, Training Loss: 1.618e-01, Validation Loss: 5.860e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14841, Training Loss: 1.618e-01, Validation Loss: 5.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14842, Training Loss: 1.618e-01, Validation Loss: 5.860e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14843, Training Loss: 1.618e-01, Validation Loss: 5.860e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14844, Training Loss: 1.618e-01, Validation Loss: 5.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14845, Training Loss: 1.618e-01, Validation Loss: 5.859e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14846, Training Loss: 1.617e-01, Validation Loss: 5.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14847, Training Loss: 1.617e-01, Validation Loss: 5.859e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14848, Training Loss: 1.617e-01, Validation Loss: 5.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14849, Training Loss: 1.617e-01, Validation Loss: 5.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14850, Training Loss: 1.617e-01, Validation Loss: 5.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14851, Training Loss: 1.617e-01, Validation Loss: 5.859e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14852, Training Loss: 1.617e-01, Validation Loss: 5.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14853, Training Loss: 1.616e-01, Validation Loss: 5.859e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14854, Training Loss: 1.616e-01, Validation Loss: 5.859e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14855, Training Loss: 1.616e-01, Validation Loss: 5.859e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14856, Training Loss: 1.616e-01, Validation Loss: 5.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14857, Training Loss: 1.616e-01, Validation Loss: 5.858e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14858, Training Loss: 1.616e-01, Validation Loss: 5.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14859, Training Loss: 1.615e-01, Validation Loss: 5.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14860, Training Loss: 1.615e-01, Validation Loss: 5.858e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14861, Training Loss: 1.615e-01, Validation Loss: 5.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14862, Training Loss: 1.615e-01, Validation Loss: 5.858e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14863, Training Loss: 1.615e-01, Validation Loss: 5.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14864, Training Loss: 1.615e-01, Validation Loss: 5.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14865, Training Loss: 1.615e-01, Validation Loss: 5.858e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14866, Training Loss: 1.614e-01, Validation Loss: 5.858e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14867, Training Loss: 1.614e-01, Validation Loss: 5.858e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14868, Training Loss: 1.614e-01, Validation Loss: 5.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14869, Training Loss: 1.614e-01, Validation Loss: 5.858e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14870, Training Loss: 1.614e-01, Validation Loss: 5.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14871, Training Loss: 1.614e-01, Validation Loss: 5.857e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14872, Training Loss: 1.614e-01, Validation Loss: 5.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14873, Training Loss: 1.613e-01, Validation Loss: 5.857e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14874, Training Loss: 1.613e-01, Validation Loss: 5.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14875, Training Loss: 1.613e-01, Validation Loss: 5.857e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14876, Training Loss: 1.613e-01, Validation Loss: 5.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14877, Training Loss: 1.613e-01, Validation Loss: 5.857e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14878, Training Loss: 1.613e-01, Validation Loss: 5.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14879, Training Loss: 1.612e-01, Validation Loss: 5.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14880, Training Loss: 1.612e-01, Validation Loss: 5.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14881, Training Loss: 1.612e-01, Validation Loss: 5.857e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14882, Training Loss: 1.612e-01, Validation Loss: 5.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14883, Training Loss: 1.612e-01, Validation Loss: 5.856e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14884, Training Loss: 1.612e-01, Validation Loss: 5.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14885, Training Loss: 1.612e-01, Validation Loss: 5.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14886, Training Loss: 1.611e-01, Validation Loss: 5.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14887, Training Loss: 1.611e-01, Validation Loss: 5.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14888, Training Loss: 1.611e-01, Validation Loss: 5.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14889, Training Loss: 1.611e-01, Validation Loss: 5.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14890, Training Loss: 1.611e-01, Validation Loss: 5.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14891, Training Loss: 1.611e-01, Validation Loss: 5.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14892, Training Loss: 1.611e-01, Validation Loss: 5.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14893, Training Loss: 1.610e-01, Validation Loss: 5.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14894, Training Loss: 1.610e-01, Validation Loss: 5.856e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14895, Training Loss: 1.610e-01, Validation Loss: 5.856e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14896, Training Loss: 1.610e-01, Validation Loss: 5.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14897, Training Loss: 1.610e-01, Validation Loss: 5.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14898, Training Loss: 1.610e-01, Validation Loss: 5.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14899, Training Loss: 1.610e-01, Validation Loss: 5.855e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14900, Training Loss: 1.609e-01, Validation Loss: 5.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14901, Training Loss: 1.609e-01, Validation Loss: 5.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14902, Training Loss: 1.609e-01, Validation Loss: 5.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14903, Training Loss: 1.609e-01, Validation Loss: 5.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14904, Training Loss: 1.609e-01, Validation Loss: 5.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14905, Training Loss: 1.609e-01, Validation Loss: 5.855e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14906, Training Loss: 1.608e-01, Validation Loss: 5.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14907, Training Loss: 1.608e-01, Validation Loss: 5.855e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14908, Training Loss: 1.608e-01, Validation Loss: 5.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14909, Training Loss: 1.608e-01, Validation Loss: 5.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14910, Training Loss: 1.608e-01, Validation Loss: 5.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14911, Training Loss: 1.608e-01, Validation Loss: 5.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14912, Training Loss: 1.608e-01, Validation Loss: 5.854e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14913, Training Loss: 1.607e-01, Validation Loss: 5.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14914, Training Loss: 1.607e-01, Validation Loss: 5.854e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14915, Training Loss: 1.607e-01, Validation Loss: 5.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14916, Training Loss: 1.607e-01, Validation Loss: 5.854e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14917, Training Loss: 1.607e-01, Validation Loss: 5.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14918, Training Loss: 1.607e-01, Validation Loss: 5.854e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14919, Training Loss: 1.607e-01, Validation Loss: 5.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14920, Training Loss: 1.606e-01, Validation Loss: 5.854e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14921, Training Loss: 1.606e-01, Validation Loss: 5.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14922, Training Loss: 1.606e-01, Validation Loss: 5.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14923, Training Loss: 1.606e-01, Validation Loss: 5.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14924, Training Loss: 1.606e-01, Validation Loss: 5.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14925, Training Loss: 1.606e-01, Validation Loss: 5.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14926, Training Loss: 1.605e-01, Validation Loss: 5.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14927, Training Loss: 1.605e-01, Validation Loss: 5.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14928, Training Loss: 1.605e-01, Validation Loss: 5.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14929, Training Loss: 1.605e-01, Validation Loss: 5.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14930, Training Loss: 1.605e-01, Validation Loss: 5.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14931, Training Loss: 1.605e-01, Validation Loss: 5.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14932, Training Loss: 1.605e-01, Validation Loss: 5.853e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14933, Training Loss: 1.604e-01, Validation Loss: 5.853e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14934, Training Loss: 1.604e-01, Validation Loss: 5.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14935, Training Loss: 1.604e-01, Validation Loss: 5.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14936, Training Loss: 1.604e-01, Validation Loss: 5.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14937, Training Loss: 1.604e-01, Validation Loss: 5.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14938, Training Loss: 1.604e-01, Validation Loss: 5.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14939, Training Loss: 1.604e-01, Validation Loss: 5.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14940, Training Loss: 1.603e-01, Validation Loss: 5.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14941, Training Loss: 1.603e-01, Validation Loss: 5.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14942, Training Loss: 1.603e-01, Validation Loss: 5.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14943, Training Loss: 1.603e-01, Validation Loss: 5.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14944, Training Loss: 1.603e-01, Validation Loss: 5.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14945, Training Loss: 1.603e-01, Validation Loss: 5.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14946, Training Loss: 1.603e-01, Validation Loss: 5.852e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14947, Training Loss: 1.602e-01, Validation Loss: 5.852e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14948, Training Loss: 1.602e-01, Validation Loss: 5.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14949, Training Loss: 1.602e-01, Validation Loss: 5.851e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14950, Training Loss: 1.602e-01, Validation Loss: 5.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14951, Training Loss: 1.602e-01, Validation Loss: 5.851e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14952, Training Loss: 1.602e-01, Validation Loss: 5.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14953, Training Loss: 1.602e-01, Validation Loss: 5.851e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14954, Training Loss: 1.601e-01, Validation Loss: 5.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14955, Training Loss: 1.601e-01, Validation Loss: 5.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14956, Training Loss: 1.601e-01, Validation Loss: 5.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14957, Training Loss: 1.601e-01, Validation Loss: 5.851e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14958, Training Loss: 1.601e-01, Validation Loss: 5.851e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14959, Training Loss: 1.601e-01, Validation Loss: 5.851e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14960, Training Loss: 1.600e-01, Validation Loss: 5.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14961, Training Loss: 1.600e-01, Validation Loss: 5.851e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14962, Training Loss: 1.600e-01, Validation Loss: 5.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14963, Training Loss: 1.600e-01, Validation Loss: 5.850e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14964, Training Loss: 1.600e-01, Validation Loss: 5.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14965, Training Loss: 1.600e-01, Validation Loss: 5.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14966, Training Loss: 1.600e-01, Validation Loss: 5.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14967, Training Loss: 1.599e-01, Validation Loss: 5.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14968, Training Loss: 1.599e-01, Validation Loss: 5.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14969, Training Loss: 1.599e-01, Validation Loss: 5.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14970, Training Loss: 1.599e-01, Validation Loss: 5.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14971, Training Loss: 1.599e-01, Validation Loss: 5.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14972, Training Loss: 1.599e-01, Validation Loss: 5.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14973, Training Loss: 1.599e-01, Validation Loss: 5.850e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14974, Training Loss: 1.598e-01, Validation Loss: 5.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14975, Training Loss: 1.598e-01, Validation Loss: 5.849e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14976, Training Loss: 1.598e-01, Validation Loss: 5.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14977, Training Loss: 1.598e-01, Validation Loss: 5.849e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14978, Training Loss: 1.598e-01, Validation Loss: 5.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14979, Training Loss: 1.598e-01, Validation Loss: 5.849e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14980, Training Loss: 1.598e-01, Validation Loss: 5.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14981, Training Loss: 1.597e-01, Validation Loss: 5.849e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14982, Training Loss: 1.597e-01, Validation Loss: 5.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14983, Training Loss: 1.597e-01, Validation Loss: 5.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14984, Training Loss: 1.597e-01, Validation Loss: 5.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14985, Training Loss: 1.597e-01, Validation Loss: 5.849e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14986, Training Loss: 1.597e-01, Validation Loss: 5.849e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14987, Training Loss: 1.596e-01, Validation Loss: 5.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14988, Training Loss: 1.596e-01, Validation Loss: 5.848e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14989, Training Loss: 1.596e-01, Validation Loss: 5.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14990, Training Loss: 1.596e-01, Validation Loss: 5.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14991, Training Loss: 1.596e-01, Validation Loss: 5.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14992, Training Loss: 1.596e-01, Validation Loss: 5.848e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14993, Training Loss: 1.596e-01, Validation Loss: 5.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14994, Training Loss: 1.595e-01, Validation Loss: 5.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14995, Training Loss: 1.595e-01, Validation Loss: 5.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14996, Training Loss: 1.595e-01, Validation Loss: 5.848e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 14997, Training Loss: 1.595e-01, Validation Loss: 5.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14998, Training Loss: 1.595e-01, Validation Loss: 5.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 14999, Training Loss: 1.595e-01, Validation Loss: 5.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15000, Training Loss: 1.595e-01, Validation Loss: 5.848e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15001, Training Loss: 1.594e-01, Validation Loss: 5.848e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15002, Training Loss: 1.594e-01, Validation Loss: 5.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15003, Training Loss: 1.594e-01, Validation Loss: 5.847e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15004, Training Loss: 1.594e-01, Validation Loss: 5.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15005, Training Loss: 1.594e-01, Validation Loss: 5.847e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15006, Training Loss: 1.594e-01, Validation Loss: 5.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15007, Training Loss: 1.594e-01, Validation Loss: 5.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15008, Training Loss: 1.593e-01, Validation Loss: 5.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15009, Training Loss: 1.593e-01, Validation Loss: 5.847e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15010, Training Loss: 1.593e-01, Validation Loss: 5.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15011, Training Loss: 1.593e-01, Validation Loss: 5.847e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15012, Training Loss: 1.593e-01, Validation Loss: 5.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15013, Training Loss: 1.593e-01, Validation Loss: 5.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15014, Training Loss: 1.593e-01, Validation Loss: 5.847e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15015, Training Loss: 1.592e-01, Validation Loss: 5.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15016, Training Loss: 1.592e-01, Validation Loss: 5.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15017, Training Loss: 1.592e-01, Validation Loss: 5.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15018, Training Loss: 1.592e-01, Validation Loss: 5.846e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15019, Training Loss: 1.592e-01, Validation Loss: 5.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15020, Training Loss: 1.592e-01, Validation Loss: 5.846e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15021, Training Loss: 1.592e-01, Validation Loss: 5.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15022, Training Loss: 1.591e-01, Validation Loss: 5.846e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15023, Training Loss: 1.591e-01, Validation Loss: 5.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15024, Training Loss: 1.591e-01, Validation Loss: 5.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15025, Training Loss: 1.591e-01, Validation Loss: 5.846e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15026, Training Loss: 1.591e-01, Validation Loss: 5.846e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15027, Training Loss: 1.591e-01, Validation Loss: 5.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15028, Training Loss: 1.590e-01, Validation Loss: 5.845e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15029, Training Loss: 1.590e-01, Validation Loss: 5.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15030, Training Loss: 1.590e-01, Validation Loss: 5.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15031, Training Loss: 1.590e-01, Validation Loss: 5.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15032, Training Loss: 1.590e-01, Validation Loss: 5.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15033, Training Loss: 1.590e-01, Validation Loss: 5.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15034, Training Loss: 1.590e-01, Validation Loss: 5.845e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15035, Training Loss: 1.589e-01, Validation Loss: 5.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15036, Training Loss: 1.589e-01, Validation Loss: 5.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15037, Training Loss: 1.589e-01, Validation Loss: 5.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15038, Training Loss: 1.589e-01, Validation Loss: 5.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15039, Training Loss: 1.589e-01, Validation Loss: 5.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15040, Training Loss: 1.589e-01, Validation Loss: 5.845e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15041, Training Loss: 1.589e-01, Validation Loss: 5.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15042, Training Loss: 1.588e-01, Validation Loss: 5.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15043, Training Loss: 1.588e-01, Validation Loss: 5.844e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15044, Training Loss: 1.588e-01, Validation Loss: 5.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15045, Training Loss: 1.588e-01, Validation Loss: 5.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15046, Training Loss: 1.588e-01, Validation Loss: 5.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15047, Training Loss: 1.588e-01, Validation Loss: 5.844e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15048, Training Loss: 1.588e-01, Validation Loss: 5.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15049, Training Loss: 1.587e-01, Validation Loss: 5.844e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15050, Training Loss: 1.587e-01, Validation Loss: 5.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15051, Training Loss: 1.587e-01, Validation Loss: 5.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15052, Training Loss: 1.587e-01, Validation Loss: 5.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15053, Training Loss: 1.587e-01, Validation Loss: 5.844e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15054, Training Loss: 1.587e-01, Validation Loss: 5.844e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15055, Training Loss: 1.587e-01, Validation Loss: 5.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15056, Training Loss: 1.586e-01, Validation Loss: 5.843e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15057, Training Loss: 1.586e-01, Validation Loss: 5.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15058, Training Loss: 1.586e-01, Validation Loss: 5.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15059, Training Loss: 1.586e-01, Validation Loss: 5.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15060, Training Loss: 1.586e-01, Validation Loss: 5.843e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15061, Training Loss: 1.586e-01, Validation Loss: 5.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15062, Training Loss: 1.586e-01, Validation Loss: 5.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15063, Training Loss: 1.585e-01, Validation Loss: 5.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15064, Training Loss: 1.585e-01, Validation Loss: 5.843e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15065, Training Loss: 1.585e-01, Validation Loss: 5.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15066, Training Loss: 1.585e-01, Validation Loss: 5.843e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15067, Training Loss: 1.585e-01, Validation Loss: 5.843e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15068, Training Loss: 1.585e-01, Validation Loss: 5.843e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15069, Training Loss: 1.584e-01, Validation Loss: 5.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15070, Training Loss: 1.584e-01, Validation Loss: 5.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15071, Training Loss: 1.584e-01, Validation Loss: 5.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15072, Training Loss: 1.584e-01, Validation Loss: 5.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15073, Training Loss: 1.584e-01, Validation Loss: 5.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15074, Training Loss: 1.584e-01, Validation Loss: 5.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15075, Training Loss: 1.584e-01, Validation Loss: 5.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15076, Training Loss: 1.583e-01, Validation Loss: 5.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15077, Training Loss: 1.583e-01, Validation Loss: 5.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15078, Training Loss: 1.583e-01, Validation Loss: 5.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15079, Training Loss: 1.583e-01, Validation Loss: 5.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15080, Training Loss: 1.583e-01, Validation Loss: 5.842e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15081, Training Loss: 1.583e-01, Validation Loss: 5.842e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15082, Training Loss: 1.583e-01, Validation Loss: 5.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15083, Training Loss: 1.582e-01, Validation Loss: 5.841e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15084, Training Loss: 1.582e-01, Validation Loss: 5.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15085, Training Loss: 1.582e-01, Validation Loss: 5.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15086, Training Loss: 1.582e-01, Validation Loss: 5.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15087, Training Loss: 1.582e-01, Validation Loss: 5.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15088, Training Loss: 1.582e-01, Validation Loss: 5.841e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15089, Training Loss: 1.582e-01, Validation Loss: 5.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15090, Training Loss: 1.581e-01, Validation Loss: 5.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15091, Training Loss: 1.581e-01, Validation Loss: 5.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15092, Training Loss: 1.581e-01, Validation Loss: 5.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15093, Training Loss: 1.581e-01, Validation Loss: 5.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15094, Training Loss: 1.581e-01, Validation Loss: 5.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15095, Training Loss: 1.581e-01, Validation Loss: 5.841e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15096, Training Loss: 1.581e-01, Validation Loss: 5.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15097, Training Loss: 1.580e-01, Validation Loss: 5.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15098, Training Loss: 1.580e-01, Validation Loss: 5.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15099, Training Loss: 1.580e-01, Validation Loss: 5.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15100, Training Loss: 1.580e-01, Validation Loss: 5.840e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15101, Training Loss: 1.580e-01, Validation Loss: 5.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15102, Training Loss: 1.580e-01, Validation Loss: 5.840e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15103, Training Loss: 1.580e-01, Validation Loss: 5.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15104, Training Loss: 1.579e-01, Validation Loss: 5.840e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15105, Training Loss: 1.579e-01, Validation Loss: 5.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15106, Training Loss: 1.579e-01, Validation Loss: 5.840e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15107, Training Loss: 1.579e-01, Validation Loss: 5.840e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15108, Training Loss: 1.579e-01, Validation Loss: 5.840e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15109, Training Loss: 1.579e-01, Validation Loss: 5.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15110, Training Loss: 1.579e-01, Validation Loss: 5.840e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15111, Training Loss: 1.578e-01, Validation Loss: 5.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15112, Training Loss: 1.578e-01, Validation Loss: 5.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15113, Training Loss: 1.578e-01, Validation Loss: 5.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15114, Training Loss: 1.578e-01, Validation Loss: 5.839e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15115, Training Loss: 1.578e-01, Validation Loss: 5.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15116, Training Loss: 1.578e-01, Validation Loss: 5.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15117, Training Loss: 1.578e-01, Validation Loss: 5.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15118, Training Loss: 1.577e-01, Validation Loss: 5.839e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15119, Training Loss: 1.577e-01, Validation Loss: 5.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15120, Training Loss: 1.577e-01, Validation Loss: 5.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15121, Training Loss: 1.577e-01, Validation Loss: 5.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15122, Training Loss: 1.577e-01, Validation Loss: 5.839e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15123, Training Loss: 1.577e-01, Validation Loss: 5.839e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15124, Training Loss: 1.577e-01, Validation Loss: 5.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15125, Training Loss: 1.576e-01, Validation Loss: 5.838e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15126, Training Loss: 1.576e-01, Validation Loss: 5.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15127, Training Loss: 1.576e-01, Validation Loss: 5.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15128, Training Loss: 1.576e-01, Validation Loss: 5.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15129, Training Loss: 1.576e-01, Validation Loss: 5.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15130, Training Loss: 1.576e-01, Validation Loss: 5.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15131, Training Loss: 1.576e-01, Validation Loss: 5.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15132, Training Loss: 1.575e-01, Validation Loss: 5.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15133, Training Loss: 1.575e-01, Validation Loss: 5.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15134, Training Loss: 1.575e-01, Validation Loss: 5.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15135, Training Loss: 1.575e-01, Validation Loss: 5.838e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15136, Training Loss: 1.575e-01, Validation Loss: 5.838e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15137, Training Loss: 1.575e-01, Validation Loss: 5.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15138, Training Loss: 1.575e-01, Validation Loss: 5.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15139, Training Loss: 1.574e-01, Validation Loss: 5.837e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15140, Training Loss: 1.574e-01, Validation Loss: 5.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15141, Training Loss: 1.574e-01, Validation Loss: 5.837e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15142, Training Loss: 1.574e-01, Validation Loss: 5.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15143, Training Loss: 1.574e-01, Validation Loss: 5.837e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15144, Training Loss: 1.574e-01, Validation Loss: 5.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15145, Training Loss: 1.574e-01, Validation Loss: 5.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15146, Training Loss: 1.573e-01, Validation Loss: 5.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15147, Training Loss: 1.573e-01, Validation Loss: 5.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15148, Training Loss: 1.573e-01, Validation Loss: 5.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15149, Training Loss: 1.573e-01, Validation Loss: 5.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15150, Training Loss: 1.573e-01, Validation Loss: 5.837e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15151, Training Loss: 1.573e-01, Validation Loss: 5.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15152, Training Loss: 1.572e-01, Validation Loss: 5.837e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15153, Training Loss: 1.572e-01, Validation Loss: 5.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15154, Training Loss: 1.572e-01, Validation Loss: 5.836e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15155, Training Loss: 1.572e-01, Validation Loss: 5.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15156, Training Loss: 1.572e-01, Validation Loss: 5.836e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15157, Training Loss: 1.572e-01, Validation Loss: 5.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15158, Training Loss: 1.572e-01, Validation Loss: 5.836e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15159, Training Loss: 1.571e-01, Validation Loss: 5.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15160, Training Loss: 1.571e-01, Validation Loss: 5.836e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15161, Training Loss: 1.571e-01, Validation Loss: 5.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15162, Training Loss: 1.571e-01, Validation Loss: 5.836e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15163, Training Loss: 1.571e-01, Validation Loss: 5.836e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15164, Training Loss: 1.571e-01, Validation Loss: 5.836e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15165, Training Loss: 1.571e-01, Validation Loss: 5.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15166, Training Loss: 1.570e-01, Validation Loss: 5.836e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15167, Training Loss: 1.570e-01, Validation Loss: 5.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15168, Training Loss: 1.570e-01, Validation Loss: 5.835e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15169, Training Loss: 1.570e-01, Validation Loss: 5.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15170, Training Loss: 1.570e-01, Validation Loss: 5.835e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15171, Training Loss: 1.570e-01, Validation Loss: 5.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15172, Training Loss: 1.570e-01, Validation Loss: 5.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15173, Training Loss: 1.569e-01, Validation Loss: 5.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15174, Training Loss: 1.569e-01, Validation Loss: 5.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15175, Training Loss: 1.569e-01, Validation Loss: 5.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15176, Training Loss: 1.569e-01, Validation Loss: 5.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15177, Training Loss: 1.569e-01, Validation Loss: 5.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15178, Training Loss: 1.569e-01, Validation Loss: 5.835e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15179, Training Loss: 1.569e-01, Validation Loss: 5.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15180, Training Loss: 1.568e-01, Validation Loss: 5.834e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15181, Training Loss: 1.568e-01, Validation Loss: 5.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15182, Training Loss: 1.568e-01, Validation Loss: 5.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15183, Training Loss: 1.568e-01, Validation Loss: 5.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15184, Training Loss: 1.568e-01, Validation Loss: 5.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15185, Training Loss: 1.568e-01, Validation Loss: 5.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15186, Training Loss: 1.568e-01, Validation Loss: 5.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15187, Training Loss: 1.567e-01, Validation Loss: 5.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15188, Training Loss: 1.567e-01, Validation Loss: 5.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15189, Training Loss: 1.567e-01, Validation Loss: 5.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15190, Training Loss: 1.567e-01, Validation Loss: 5.834e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15191, Training Loss: 1.567e-01, Validation Loss: 5.834e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15192, Training Loss: 1.567e-01, Validation Loss: 5.834e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15193, Training Loss: 1.567e-01, Validation Loss: 5.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15194, Training Loss: 1.566e-01, Validation Loss: 5.833e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15195, Training Loss: 1.566e-01, Validation Loss: 5.833e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 15196, Training Loss: 1.566e-01, Validation Loss: 5.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15197, Training Loss: 1.566e-01, Validation Loss: 5.833e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15198, Training Loss: 1.566e-01, Validation Loss: 5.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15199, Training Loss: 1.566e-01, Validation Loss: 5.833e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15200, Training Loss: 1.566e-01, Validation Loss: 5.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15201, Training Loss: 1.565e-01, Validation Loss: 5.833e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15202, Training Loss: 1.565e-01, Validation Loss: 5.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15203, Training Loss: 1.565e-01, Validation Loss: 5.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15204, Training Loss: 1.565e-01, Validation Loss: 5.833e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15205, Training Loss: 1.565e-01, Validation Loss: 5.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15206, Training Loss: 1.565e-01, Validation Loss: 5.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15207, Training Loss: 1.565e-01, Validation Loss: 5.833e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15208, Training Loss: 1.564e-01, Validation Loss: 5.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15209, Training Loss: 1.564e-01, Validation Loss: 5.833e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15210, Training Loss: 1.564e-01, Validation Loss: 5.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15211, Training Loss: 1.564e-01, Validation Loss: 5.832e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15212, Training Loss: 1.564e-01, Validation Loss: 5.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15213, Training Loss: 1.564e-01, Validation Loss: 5.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15214, Training Loss: 1.564e-01, Validation Loss: 5.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15215, Training Loss: 1.563e-01, Validation Loss: 5.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15216, Training Loss: 1.563e-01, Validation Loss: 5.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15217, Training Loss: 1.563e-01, Validation Loss: 5.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15218, Training Loss: 1.563e-01, Validation Loss: 5.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15219, Training Loss: 1.563e-01, Validation Loss: 5.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15220, Training Loss: 1.563e-01, Validation Loss: 5.832e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15221, Training Loss: 1.563e-01, Validation Loss: 5.832e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15222, Training Loss: 1.562e-01, Validation Loss: 5.832e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15223, Training Loss: 1.562e-01, Validation Loss: 5.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15224, Training Loss: 1.562e-01, Validation Loss: 5.831e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15225, Training Loss: 1.562e-01, Validation Loss: 5.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15226, Training Loss: 1.562e-01, Validation Loss: 5.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15227, Training Loss: 1.562e-01, Validation Loss: 5.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15228, Training Loss: 1.562e-01, Validation Loss: 5.831e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15229, Training Loss: 1.561e-01, Validation Loss: 5.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15230, Training Loss: 1.561e-01, Validation Loss: 5.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15231, Training Loss: 1.561e-01, Validation Loss: 5.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15232, Training Loss: 1.561e-01, Validation Loss: 5.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15233, Training Loss: 1.561e-01, Validation Loss: 5.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15234, Training Loss: 1.561e-01, Validation Loss: 5.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15235, Training Loss: 1.561e-01, Validation Loss: 5.831e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15236, Training Loss: 1.560e-01, Validation Loss: 5.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15237, Training Loss: 1.560e-01, Validation Loss: 5.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15238, Training Loss: 1.560e-01, Validation Loss: 5.830e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15239, Training Loss: 1.560e-01, Validation Loss: 5.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15240, Training Loss: 1.560e-01, Validation Loss: 5.830e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15241, Training Loss: 1.560e-01, Validation Loss: 5.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15242, Training Loss: 1.560e-01, Validation Loss: 5.830e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15243, Training Loss: 1.560e-01, Validation Loss: 5.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15244, Training Loss: 1.559e-01, Validation Loss: 5.830e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15245, Training Loss: 1.559e-01, Validation Loss: 5.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15246, Training Loss: 1.559e-01, Validation Loss: 5.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15247, Training Loss: 1.559e-01, Validation Loss: 5.830e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15248, Training Loss: 1.559e-01, Validation Loss: 5.830e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15249, Training Loss: 1.559e-01, Validation Loss: 5.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15250, Training Loss: 1.559e-01, Validation Loss: 5.830e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15251, Training Loss: 1.558e-01, Validation Loss: 5.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15252, Training Loss: 1.558e-01, Validation Loss: 5.829e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15253, Training Loss: 1.558e-01, Validation Loss: 5.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15254, Training Loss: 1.558e-01, Validation Loss: 5.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15255, Training Loss: 1.558e-01, Validation Loss: 5.829e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15256, Training Loss: 1.558e-01, Validation Loss: 5.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15257, Training Loss: 1.558e-01, Validation Loss: 5.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15258, Training Loss: 1.557e-01, Validation Loss: 5.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15259, Training Loss: 1.557e-01, Validation Loss: 5.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15260, Training Loss: 1.557e-01, Validation Loss: 5.829e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15261, Training Loss: 1.557e-01, Validation Loss: 5.829e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15262, Training Loss: 1.557e-01, Validation Loss: 5.829e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15263, Training Loss: 1.557e-01, Validation Loss: 5.829e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 15264, Training Loss: 1.557e-01, Validation Loss: 5.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15265, Training Loss: 1.556e-01, Validation Loss: 5.828e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15266, Training Loss: 1.556e-01, Validation Loss: 5.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15267, Training Loss: 1.556e-01, Validation Loss: 5.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15268, Training Loss: 1.556e-01, Validation Loss: 5.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15269, Training Loss: 1.556e-01, Validation Loss: 5.828e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15270, Training Loss: 1.556e-01, Validation Loss: 5.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15271, Training Loss: 1.556e-01, Validation Loss: 5.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15272, Training Loss: 1.555e-01, Validation Loss: 5.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15273, Training Loss: 1.555e-01, Validation Loss: 5.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15274, Training Loss: 1.555e-01, Validation Loss: 5.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15275, Training Loss: 1.555e-01, Validation Loss: 5.828e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15276, Training Loss: 1.555e-01, Validation Loss: 5.828e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15277, Training Loss: 1.555e-01, Validation Loss: 5.828e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15278, Training Loss: 1.555e-01, Validation Loss: 5.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15279, Training Loss: 1.554e-01, Validation Loss: 5.828e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15280, Training Loss: 1.554e-01, Validation Loss: 5.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15281, Training Loss: 1.554e-01, Validation Loss: 5.827e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15282, Training Loss: 1.554e-01, Validation Loss: 5.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15283, Training Loss: 1.554e-01, Validation Loss: 5.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15284, Training Loss: 1.554e-01, Validation Loss: 5.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15285, Training Loss: 1.554e-01, Validation Loss: 5.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15286, Training Loss: 1.553e-01, Validation Loss: 5.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15287, Training Loss: 1.553e-01, Validation Loss: 5.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15288, Training Loss: 1.553e-01, Validation Loss: 5.827e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15289, Training Loss: 1.553e-01, Validation Loss: 5.827e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15290, Training Loss: 1.553e-01, Validation Loss: 5.827e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15291, Training Loss: 1.553e-01, Validation Loss: 5.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15292, Training Loss: 1.553e-01, Validation Loss: 5.827e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15293, Training Loss: 1.552e-01, Validation Loss: 5.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15294, Training Loss: 1.552e-01, Validation Loss: 5.826e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15295, Training Loss: 1.552e-01, Validation Loss: 5.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15296, Training Loss: 1.552e-01, Validation Loss: 5.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15297, Training Loss: 1.552e-01, Validation Loss: 5.826e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15298, Training Loss: 1.552e-01, Validation Loss: 5.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15299, Training Loss: 1.552e-01, Validation Loss: 5.826e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15300, Training Loss: 1.551e-01, Validation Loss: 5.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15301, Training Loss: 1.551e-01, Validation Loss: 5.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15302, Training Loss: 1.551e-01, Validation Loss: 5.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15303, Training Loss: 1.551e-01, Validation Loss: 5.826e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15304, Training Loss: 1.551e-01, Validation Loss: 5.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15305, Training Loss: 1.551e-01, Validation Loss: 5.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15306, Training Loss: 1.551e-01, Validation Loss: 5.826e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15307, Training Loss: 1.550e-01, Validation Loss: 5.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15308, Training Loss: 1.550e-01, Validation Loss: 5.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15309, Training Loss: 1.550e-01, Validation Loss: 5.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15310, Training Loss: 1.550e-01, Validation Loss: 5.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15311, Training Loss: 1.550e-01, Validation Loss: 5.825e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15312, Training Loss: 1.550e-01, Validation Loss: 5.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15313, Training Loss: 1.550e-01, Validation Loss: 5.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15314, Training Loss: 1.549e-01, Validation Loss: 5.825e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15315, Training Loss: 1.549e-01, Validation Loss: 5.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15316, Training Loss: 1.549e-01, Validation Loss: 5.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15317, Training Loss: 1.549e-01, Validation Loss: 5.825e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15318, Training Loss: 1.549e-01, Validation Loss: 5.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15319, Training Loss: 1.549e-01, Validation Loss: 5.825e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15320, Training Loss: 1.549e-01, Validation Loss: 5.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15321, Training Loss: 1.548e-01, Validation Loss: 5.825e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15322, Training Loss: 1.548e-01, Validation Loss: 5.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15323, Training Loss: 1.548e-01, Validation Loss: 5.824e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15324, Training Loss: 1.548e-01, Validation Loss: 5.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15325, Training Loss: 1.548e-01, Validation Loss: 5.824e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15326, Training Loss: 1.548e-01, Validation Loss: 5.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15327, Training Loss: 1.548e-01, Validation Loss: 5.824e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15328, Training Loss: 1.548e-01, Validation Loss: 5.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15329, Training Loss: 1.547e-01, Validation Loss: 5.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15330, Training Loss: 1.547e-01, Validation Loss: 5.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15331, Training Loss: 1.547e-01, Validation Loss: 5.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15332, Training Loss: 1.547e-01, Validation Loss: 5.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15333, Training Loss: 1.547e-01, Validation Loss: 5.824e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15334, Training Loss: 1.547e-01, Validation Loss: 5.824e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15335, Training Loss: 1.547e-01, Validation Loss: 5.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15336, Training Loss: 1.546e-01, Validation Loss: 5.823e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15337, Training Loss: 1.546e-01, Validation Loss: 5.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15338, Training Loss: 1.546e-01, Validation Loss: 5.823e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15339, Training Loss: 1.546e-01, Validation Loss: 5.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15340, Training Loss: 1.546e-01, Validation Loss: 5.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15341, Training Loss: 1.546e-01, Validation Loss: 5.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15342, Training Loss: 1.546e-01, Validation Loss: 5.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15343, Training Loss: 1.545e-01, Validation Loss: 5.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15344, Training Loss: 1.545e-01, Validation Loss: 5.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15345, Training Loss: 1.545e-01, Validation Loss: 5.823e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15346, Training Loss: 1.545e-01, Validation Loss: 5.823e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15347, Training Loss: 1.545e-01, Validation Loss: 5.823e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15348, Training Loss: 1.545e-01, Validation Loss: 5.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15349, Training Loss: 1.545e-01, Validation Loss: 5.823e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15350, Training Loss: 1.544e-01, Validation Loss: 5.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15351, Training Loss: 1.544e-01, Validation Loss: 5.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15352, Training Loss: 1.544e-01, Validation Loss: 5.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15353, Training Loss: 1.544e-01, Validation Loss: 5.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15354, Training Loss: 1.544e-01, Validation Loss: 5.822e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15355, Training Loss: 1.544e-01, Validation Loss: 5.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15356, Training Loss: 1.544e-01, Validation Loss: 5.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15357, Training Loss: 1.543e-01, Validation Loss: 5.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15358, Training Loss: 1.543e-01, Validation Loss: 5.822e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15359, Training Loss: 1.543e-01, Validation Loss: 5.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15360, Training Loss: 1.543e-01, Validation Loss: 5.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15361, Training Loss: 1.543e-01, Validation Loss: 5.822e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15362, Training Loss: 1.543e-01, Validation Loss: 5.822e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15363, Training Loss: 1.543e-01, Validation Loss: 5.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15364, Training Loss: 1.542e-01, Validation Loss: 5.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15365, Training Loss: 1.542e-01, Validation Loss: 5.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15366, Training Loss: 1.542e-01, Validation Loss: 5.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15367, Training Loss: 1.542e-01, Validation Loss: 5.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15368, Training Loss: 1.542e-01, Validation Loss: 5.821e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15369, Training Loss: 1.542e-01, Validation Loss: 5.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15370, Training Loss: 1.542e-01, Validation Loss: 5.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15371, Training Loss: 1.541e-01, Validation Loss: 5.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15372, Training Loss: 1.541e-01, Validation Loss: 5.821e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15373, Training Loss: 1.541e-01, Validation Loss: 5.821e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 15374, Training Loss: 1.541e-01, Validation Loss: 5.821e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15375, Training Loss: 1.541e-01, Validation Loss: 5.821e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15376, Training Loss: 1.541e-01, Validation Loss: 5.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15377, Training Loss: 1.541e-01, Validation Loss: 5.821e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15378, Training Loss: 1.541e-01, Validation Loss: 5.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15379, Training Loss: 1.540e-01, Validation Loss: 5.820e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15380, Training Loss: 1.540e-01, Validation Loss: 5.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15381, Training Loss: 1.540e-01, Validation Loss: 5.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15382, Training Loss: 1.540e-01, Validation Loss: 5.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15383, Training Loss: 1.540e-01, Validation Loss: 5.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15384, Training Loss: 1.540e-01, Validation Loss: 5.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15385, Training Loss: 1.540e-01, Validation Loss: 5.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15386, Training Loss: 1.539e-01, Validation Loss: 5.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15387, Training Loss: 1.539e-01, Validation Loss: 5.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15388, Training Loss: 1.539e-01, Validation Loss: 5.820e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15389, Training Loss: 1.539e-01, Validation Loss: 5.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15390, Training Loss: 1.539e-01, Validation Loss: 5.820e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15391, Training Loss: 1.539e-01, Validation Loss: 5.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15392, Training Loss: 1.539e-01, Validation Loss: 5.820e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15393, Training Loss: 1.538e-01, Validation Loss: 5.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15394, Training Loss: 1.538e-01, Validation Loss: 5.819e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15395, Training Loss: 1.538e-01, Validation Loss: 5.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15396, Training Loss: 1.538e-01, Validation Loss: 5.819e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15397, Training Loss: 1.538e-01, Validation Loss: 5.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15398, Training Loss: 1.538e-01, Validation Loss: 5.819e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15399, Training Loss: 1.538e-01, Validation Loss: 5.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15400, Training Loss: 1.537e-01, Validation Loss: 5.819e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15401, Training Loss: 1.537e-01, Validation Loss: 5.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15402, Training Loss: 1.537e-01, Validation Loss: 5.819e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15403, Training Loss: 1.537e-01, Validation Loss: 5.819e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15404, Training Loss: 1.537e-01, Validation Loss: 5.819e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 15405, Training Loss: 1.537e-01, Validation Loss: 5.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15406, Training Loss: 1.537e-01, Validation Loss: 5.818e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15407, Training Loss: 1.536e-01, Validation Loss: 5.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15408, Training Loss: 1.536e-01, Validation Loss: 5.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15409, Training Loss: 1.536e-01, Validation Loss: 5.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15410, Training Loss: 1.536e-01, Validation Loss: 5.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15411, Training Loss: 1.536e-01, Validation Loss: 5.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15412, Training Loss: 1.536e-01, Validation Loss: 5.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15413, Training Loss: 1.536e-01, Validation Loss: 5.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15414, Training Loss: 1.536e-01, Validation Loss: 5.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15415, Training Loss: 1.535e-01, Validation Loss: 5.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15416, Training Loss: 1.535e-01, Validation Loss: 5.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15417, Training Loss: 1.535e-01, Validation Loss: 5.818e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15418, Training Loss: 1.535e-01, Validation Loss: 5.818e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15419, Training Loss: 1.535e-01, Validation Loss: 5.818e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15420, Training Loss: 1.535e-01, Validation Loss: 5.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15421, Training Loss: 1.535e-01, Validation Loss: 5.818e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15422, Training Loss: 1.534e-01, Validation Loss: 5.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15423, Training Loss: 1.534e-01, Validation Loss: 5.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15424, Training Loss: 1.534e-01, Validation Loss: 5.817e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15425, Training Loss: 1.534e-01, Validation Loss: 5.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15426, Training Loss: 1.534e-01, Validation Loss: 5.817e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15427, Training Loss: 1.534e-01, Validation Loss: 5.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15428, Training Loss: 1.534e-01, Validation Loss: 5.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15429, Training Loss: 1.533e-01, Validation Loss: 5.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15430, Training Loss: 1.533e-01, Validation Loss: 5.817e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15431, Training Loss: 1.533e-01, Validation Loss: 5.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15432, Training Loss: 1.533e-01, Validation Loss: 5.817e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15433, Training Loss: 1.533e-01, Validation Loss: 5.817e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15434, Training Loss: 1.533e-01, Validation Loss: 5.817e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15435, Training Loss: 1.533e-01, Validation Loss: 5.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15436, Training Loss: 1.532e-01, Validation Loss: 5.816e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15437, Training Loss: 1.532e-01, Validation Loss: 5.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15438, Training Loss: 1.532e-01, Validation Loss: 5.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15439, Training Loss: 1.532e-01, Validation Loss: 5.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15440, Training Loss: 1.532e-01, Validation Loss: 5.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15441, Training Loss: 1.532e-01, Validation Loss: 5.816e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15442, Training Loss: 1.532e-01, Validation Loss: 5.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15443, Training Loss: 1.532e-01, Validation Loss: 5.816e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15444, Training Loss: 1.531e-01, Validation Loss: 5.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15445, Training Loss: 1.531e-01, Validation Loss: 5.816e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15446, Training Loss: 1.531e-01, Validation Loss: 5.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15447, Training Loss: 1.531e-01, Validation Loss: 5.816e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15448, Training Loss: 1.531e-01, Validation Loss: 5.816e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15449, Training Loss: 1.531e-01, Validation Loss: 5.816e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15450, Training Loss: 1.531e-01, Validation Loss: 5.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15451, Training Loss: 1.530e-01, Validation Loss: 5.815e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15452, Training Loss: 1.530e-01, Validation Loss: 5.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15453, Training Loss: 1.530e-01, Validation Loss: 5.815e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15454, Training Loss: 1.530e-01, Validation Loss: 5.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15455, Training Loss: 1.530e-01, Validation Loss: 5.815e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15456, Training Loss: 1.530e-01, Validation Loss: 5.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15457, Training Loss: 1.530e-01, Validation Loss: 5.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15458, Training Loss: 1.529e-01, Validation Loss: 5.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15459, Training Loss: 1.529e-01, Validation Loss: 5.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15460, Training Loss: 1.529e-01, Validation Loss: 5.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15461, Training Loss: 1.529e-01, Validation Loss: 5.815e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15462, Training Loss: 1.529e-01, Validation Loss: 5.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15463, Training Loss: 1.529e-01, Validation Loss: 5.815e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15464, Training Loss: 1.529e-01, Validation Loss: 5.815e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 15465, Training Loss: 1.528e-01, Validation Loss: 5.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15466, Training Loss: 1.528e-01, Validation Loss: 5.814e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15467, Training Loss: 1.528e-01, Validation Loss: 5.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15468, Training Loss: 1.528e-01, Validation Loss: 5.814e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15469, Training Loss: 1.528e-01, Validation Loss: 5.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15470, Training Loss: 1.528e-01, Validation Loss: 5.814e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15471, Training Loss: 1.528e-01, Validation Loss: 5.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15472, Training Loss: 1.528e-01, Validation Loss: 5.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15473, Training Loss: 1.527e-01, Validation Loss: 5.814e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15474, Training Loss: 1.527e-01, Validation Loss: 5.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15475, Training Loss: 1.527e-01, Validation Loss: 5.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15476, Training Loss: 1.527e-01, Validation Loss: 5.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15477, Training Loss: 1.527e-01, Validation Loss: 5.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15478, Training Loss: 1.527e-01, Validation Loss: 5.814e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15479, Training Loss: 1.527e-01, Validation Loss: 5.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15480, Training Loss: 1.526e-01, Validation Loss: 5.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15481, Training Loss: 1.526e-01, Validation Loss: 5.813e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15482, Training Loss: 1.526e-01, Validation Loss: 5.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15483, Training Loss: 1.526e-01, Validation Loss: 5.813e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15484, Training Loss: 1.526e-01, Validation Loss: 5.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15485, Training Loss: 1.526e-01, Validation Loss: 5.813e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15486, Training Loss: 1.526e-01, Validation Loss: 5.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15487, Training Loss: 1.525e-01, Validation Loss: 5.813e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15488, Training Loss: 1.525e-01, Validation Loss: 5.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15489, Training Loss: 1.525e-01, Validation Loss: 5.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15490, Training Loss: 1.525e-01, Validation Loss: 5.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15491, Training Loss: 1.525e-01, Validation Loss: 5.813e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15492, Training Loss: 1.525e-01, Validation Loss: 5.813e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15493, Training Loss: 1.525e-01, Validation Loss: 5.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15494, Training Loss: 1.524e-01, Validation Loss: 5.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15495, Training Loss: 1.524e-01, Validation Loss: 5.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15496, Training Loss: 1.524e-01, Validation Loss: 5.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15497, Training Loss: 1.524e-01, Validation Loss: 5.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15498, Training Loss: 1.524e-01, Validation Loss: 5.812e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15499, Training Loss: 1.524e-01, Validation Loss: 5.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15500, Training Loss: 1.524e-01, Validation Loss: 5.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15501, Training Loss: 1.524e-01, Validation Loss: 5.812e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15502, Training Loss: 1.523e-01, Validation Loss: 5.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15503, Training Loss: 1.523e-01, Validation Loss: 5.812e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15504, Training Loss: 1.523e-01, Validation Loss: 5.812e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15505, Training Loss: 1.523e-01, Validation Loss: 5.812e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15506, Training Loss: 1.523e-01, Validation Loss: 5.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15507, Training Loss: 1.523e-01, Validation Loss: 5.811e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15508, Training Loss: 1.523e-01, Validation Loss: 5.812e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 15509, Training Loss: 1.522e-01, Validation Loss: 5.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15510, Training Loss: 1.522e-01, Validation Loss: 5.811e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15511, Training Loss: 1.522e-01, Validation Loss: 5.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15512, Training Loss: 1.522e-01, Validation Loss: 5.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15513, Training Loss: 1.522e-01, Validation Loss: 5.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15514, Training Loss: 1.522e-01, Validation Loss: 5.811e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15515, Training Loss: 1.522e-01, Validation Loss: 5.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15516, Training Loss: 1.521e-01, Validation Loss: 5.811e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15517, Training Loss: 1.521e-01, Validation Loss: 5.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15518, Training Loss: 1.521e-01, Validation Loss: 5.811e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15519, Training Loss: 1.521e-01, Validation Loss: 5.811e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15520, Training Loss: 1.521e-01, Validation Loss: 5.811e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15521, Training Loss: 1.521e-01, Validation Loss: 5.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15522, Training Loss: 1.521e-01, Validation Loss: 5.811e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15523, Training Loss: 1.521e-01, Validation Loss: 5.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15524, Training Loss: 1.520e-01, Validation Loss: 5.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15525, Training Loss: 1.520e-01, Validation Loss: 5.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15526, Training Loss: 1.520e-01, Validation Loss: 5.810e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15527, Training Loss: 1.520e-01, Validation Loss: 5.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15528, Training Loss: 1.520e-01, Validation Loss: 5.810e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15529, Training Loss: 1.520e-01, Validation Loss: 5.810e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 15530, Training Loss: 1.520e-01, Validation Loss: 5.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15531, Training Loss: 1.519e-01, Validation Loss: 5.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15532, Training Loss: 1.519e-01, Validation Loss: 5.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15533, Training Loss: 1.519e-01, Validation Loss: 5.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15534, Training Loss: 1.519e-01, Validation Loss: 5.810e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15535, Training Loss: 1.519e-01, Validation Loss: 5.810e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15536, Training Loss: 1.519e-01, Validation Loss: 5.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15537, Training Loss: 1.519e-01, Validation Loss: 5.810e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15538, Training Loss: 1.518e-01, Validation Loss: 5.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15539, Training Loss: 1.518e-01, Validation Loss: 5.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15540, Training Loss: 1.518e-01, Validation Loss: 5.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15541, Training Loss: 1.518e-01, Validation Loss: 5.809e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15542, Training Loss: 1.518e-01, Validation Loss: 5.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15543, Training Loss: 1.518e-01, Validation Loss: 5.809e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15544, Training Loss: 1.518e-01, Validation Loss: 5.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15545, Training Loss: 1.518e-01, Validation Loss: 5.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15546, Training Loss: 1.517e-01, Validation Loss: 5.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15547, Training Loss: 1.517e-01, Validation Loss: 5.809e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15548, Training Loss: 1.517e-01, Validation Loss: 5.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15549, Training Loss: 1.517e-01, Validation Loss: 5.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15550, Training Loss: 1.517e-01, Validation Loss: 5.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15551, Training Loss: 1.517e-01, Validation Loss: 5.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15552, Training Loss: 1.517e-01, Validation Loss: 5.809e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15553, Training Loss: 1.516e-01, Validation Loss: 5.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15554, Training Loss: 1.516e-01, Validation Loss: 5.808e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15555, Training Loss: 1.516e-01, Validation Loss: 5.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15556, Training Loss: 1.516e-01, Validation Loss: 5.808e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15557, Training Loss: 1.516e-01, Validation Loss: 5.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15558, Training Loss: 1.516e-01, Validation Loss: 5.808e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15559, Training Loss: 1.516e-01, Validation Loss: 5.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15560, Training Loss: 1.515e-01, Validation Loss: 5.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15561, Training Loss: 1.515e-01, Validation Loss: 5.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15562, Training Loss: 1.515e-01, Validation Loss: 5.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15563, Training Loss: 1.515e-01, Validation Loss: 5.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15564, Training Loss: 1.515e-01, Validation Loss: 5.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15565, Training Loss: 1.515e-01, Validation Loss: 5.808e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15566, Training Loss: 1.515e-01, Validation Loss: 5.808e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15567, Training Loss: 1.515e-01, Validation Loss: 5.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15568, Training Loss: 1.514e-01, Validation Loss: 5.807e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15569, Training Loss: 1.514e-01, Validation Loss: 5.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15570, Training Loss: 1.514e-01, Validation Loss: 5.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15571, Training Loss: 1.514e-01, Validation Loss: 5.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15572, Training Loss: 1.514e-01, Validation Loss: 5.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15573, Training Loss: 1.514e-01, Validation Loss: 5.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15574, Training Loss: 1.514e-01, Validation Loss: 5.807e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15575, Training Loss: 1.513e-01, Validation Loss: 5.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15576, Training Loss: 1.513e-01, Validation Loss: 5.807e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15577, Training Loss: 1.513e-01, Validation Loss: 5.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15578, Training Loss: 1.513e-01, Validation Loss: 5.807e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15579, Training Loss: 1.513e-01, Validation Loss: 5.807e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15580, Training Loss: 1.513e-01, Validation Loss: 5.807e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15581, Training Loss: 1.513e-01, Validation Loss: 5.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15582, Training Loss: 1.512e-01, Validation Loss: 5.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15583, Training Loss: 1.512e-01, Validation Loss: 5.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15584, Training Loss: 1.512e-01, Validation Loss: 5.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15585, Training Loss: 1.512e-01, Validation Loss: 5.806e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15586, Training Loss: 1.512e-01, Validation Loss: 5.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15587, Training Loss: 1.512e-01, Validation Loss: 5.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15588, Training Loss: 1.512e-01, Validation Loss: 5.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15589, Training Loss: 1.512e-01, Validation Loss: 5.806e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15590, Training Loss: 1.511e-01, Validation Loss: 5.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15591, Training Loss: 1.511e-01, Validation Loss: 5.806e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15592, Training Loss: 1.511e-01, Validation Loss: 5.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15593, Training Loss: 1.511e-01, Validation Loss: 5.806e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15594, Training Loss: 1.511e-01, Validation Loss: 5.806e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15595, Training Loss: 1.511e-01, Validation Loss: 5.806e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15596, Training Loss: 1.511e-01, Validation Loss: 5.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15597, Training Loss: 1.510e-01, Validation Loss: 5.805e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15598, Training Loss: 1.510e-01, Validation Loss: 5.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15599, Training Loss: 1.510e-01, Validation Loss: 5.805e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15600, Training Loss: 1.510e-01, Validation Loss: 5.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15601, Training Loss: 1.510e-01, Validation Loss: 5.805e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15602, Training Loss: 1.510e-01, Validation Loss: 5.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15603, Training Loss: 1.510e-01, Validation Loss: 5.805e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15604, Training Loss: 1.510e-01, Validation Loss: 5.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15605, Training Loss: 1.509e-01, Validation Loss: 5.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15606, Training Loss: 1.509e-01, Validation Loss: 5.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15607, Training Loss: 1.509e-01, Validation Loss: 5.805e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15608, Training Loss: 1.509e-01, Validation Loss: 5.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15609, Training Loss: 1.509e-01, Validation Loss: 5.805e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15610, Training Loss: 1.509e-01, Validation Loss: 5.805e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15611, Training Loss: 1.509e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15612, Training Loss: 1.508e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15613, Training Loss: 1.508e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15614, Training Loss: 1.508e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15615, Training Loss: 1.508e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15616, Training Loss: 1.508e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15617, Training Loss: 1.508e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15618, Training Loss: 1.508e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15619, Training Loss: 1.507e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15620, Training Loss: 1.507e-01, Validation Loss: 5.804e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15621, Training Loss: 1.507e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15622, Training Loss: 1.507e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15623, Training Loss: 1.507e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15624, Training Loss: 1.507e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15625, Training Loss: 1.507e-01, Validation Loss: 5.804e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15626, Training Loss: 1.507e-01, Validation Loss: 5.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15627, Training Loss: 1.506e-01, Validation Loss: 5.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15628, Training Loss: 1.506e-01, Validation Loss: 5.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15629, Training Loss: 1.506e-01, Validation Loss: 5.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15630, Training Loss: 1.506e-01, Validation Loss: 5.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15631, Training Loss: 1.506e-01, Validation Loss: 5.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15632, Training Loss: 1.506e-01, Validation Loss: 5.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15633, Training Loss: 1.506e-01, Validation Loss: 5.803e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15634, Training Loss: 1.505e-01, Validation Loss: 5.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15635, Training Loss: 1.505e-01, Validation Loss: 5.803e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15636, Training Loss: 1.505e-01, Validation Loss: 5.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15637, Training Loss: 1.505e-01, Validation Loss: 5.803e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15638, Training Loss: 1.505e-01, Validation Loss: 5.803e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15639, Training Loss: 1.505e-01, Validation Loss: 5.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15640, Training Loss: 1.505e-01, Validation Loss: 5.803e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15641, Training Loss: 1.505e-01, Validation Loss: 5.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15642, Training Loss: 1.504e-01, Validation Loss: 5.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15643, Training Loss: 1.504e-01, Validation Loss: 5.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15644, Training Loss: 1.504e-01, Validation Loss: 5.802e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15645, Training Loss: 1.504e-01, Validation Loss: 5.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15646, Training Loss: 1.504e-01, Validation Loss: 5.802e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15647, Training Loss: 1.504e-01, Validation Loss: 5.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15648, Training Loss: 1.504e-01, Validation Loss: 5.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15649, Training Loss: 1.503e-01, Validation Loss: 5.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15650, Training Loss: 1.503e-01, Validation Loss: 5.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15651, Training Loss: 1.503e-01, Validation Loss: 5.802e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15652, Training Loss: 1.503e-01, Validation Loss: 5.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15653, Training Loss: 1.503e-01, Validation Loss: 5.802e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15654, Training Loss: 1.503e-01, Validation Loss: 5.802e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15655, Training Loss: 1.503e-01, Validation Loss: 5.802e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15656, Training Loss: 1.503e-01, Validation Loss: 5.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15657, Training Loss: 1.502e-01, Validation Loss: 5.801e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15658, Training Loss: 1.502e-01, Validation Loss: 5.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15659, Training Loss: 1.502e-01, Validation Loss: 5.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15660, Training Loss: 1.502e-01, Validation Loss: 5.801e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15661, Training Loss: 1.502e-01, Validation Loss: 5.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15662, Training Loss: 1.502e-01, Validation Loss: 5.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15663, Training Loss: 1.502e-01, Validation Loss: 5.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15664, Training Loss: 1.501e-01, Validation Loss: 5.801e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15665, Training Loss: 1.501e-01, Validation Loss: 5.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15666, Training Loss: 1.501e-01, Validation Loss: 5.801e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15667, Training Loss: 1.501e-01, Validation Loss: 5.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15668, Training Loss: 1.501e-01, Validation Loss: 5.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15669, Training Loss: 1.501e-01, Validation Loss: 5.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15670, Training Loss: 1.501e-01, Validation Loss: 5.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15671, Training Loss: 1.501e-01, Validation Loss: 5.801e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15672, Training Loss: 1.500e-01, Validation Loss: 5.801e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15673, Training Loss: 1.500e-01, Validation Loss: 5.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15674, Training Loss: 1.500e-01, Validation Loss: 5.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15675, Training Loss: 1.500e-01, Validation Loss: 5.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15676, Training Loss: 1.500e-01, Validation Loss: 5.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15677, Training Loss: 1.500e-01, Validation Loss: 5.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15678, Training Loss: 1.500e-01, Validation Loss: 5.800e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15679, Training Loss: 1.499e-01, Validation Loss: 5.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15680, Training Loss: 1.499e-01, Validation Loss: 5.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15681, Training Loss: 1.499e-01, Validation Loss: 5.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15682, Training Loss: 1.499e-01, Validation Loss: 5.800e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15683, Training Loss: 1.499e-01, Validation Loss: 5.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15684, Training Loss: 1.499e-01, Validation Loss: 5.800e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15685, Training Loss: 1.499e-01, Validation Loss: 5.800e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15686, Training Loss: 1.499e-01, Validation Loss: 5.800e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15687, Training Loss: 1.498e-01, Validation Loss: 5.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15688, Training Loss: 1.498e-01, Validation Loss: 5.799e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15689, Training Loss: 1.498e-01, Validation Loss: 5.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15690, Training Loss: 1.498e-01, Validation Loss: 5.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15691, Training Loss: 1.498e-01, Validation Loss: 5.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15692, Training Loss: 1.498e-01, Validation Loss: 5.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15693, Training Loss: 1.498e-01, Validation Loss: 5.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15694, Training Loss: 1.497e-01, Validation Loss: 5.799e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15695, Training Loss: 1.497e-01, Validation Loss: 5.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15696, Training Loss: 1.497e-01, Validation Loss: 5.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15697, Training Loss: 1.497e-01, Validation Loss: 5.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15698, Training Loss: 1.497e-01, Validation Loss: 5.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15699, Training Loss: 1.497e-01, Validation Loss: 5.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15700, Training Loss: 1.497e-01, Validation Loss: 5.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15701, Training Loss: 1.497e-01, Validation Loss: 5.799e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15702, Training Loss: 1.496e-01, Validation Loss: 5.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15703, Training Loss: 1.496e-01, Validation Loss: 5.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15704, Training Loss: 1.496e-01, Validation Loss: 5.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15705, Training Loss: 1.496e-01, Validation Loss: 5.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15706, Training Loss: 1.496e-01, Validation Loss: 5.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15707, Training Loss: 1.496e-01, Validation Loss: 5.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15708, Training Loss: 1.496e-01, Validation Loss: 5.798e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15709, Training Loss: 1.495e-01, Validation Loss: 5.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15710, Training Loss: 1.495e-01, Validation Loss: 5.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15711, Training Loss: 1.495e-01, Validation Loss: 5.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15712, Training Loss: 1.495e-01, Validation Loss: 5.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15713, Training Loss: 1.495e-01, Validation Loss: 5.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15714, Training Loss: 1.495e-01, Validation Loss: 5.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15715, Training Loss: 1.495e-01, Validation Loss: 5.798e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15716, Training Loss: 1.494e-01, Validation Loss: 5.798e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15717, Training Loss: 1.494e-01, Validation Loss: 5.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15718, Training Loss: 1.494e-01, Validation Loss: 5.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15719, Training Loss: 1.494e-01, Validation Loss: 5.797e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15720, Training Loss: 1.494e-01, Validation Loss: 5.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15721, Training Loss: 1.494e-01, Validation Loss: 5.797e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15722, Training Loss: 1.494e-01, Validation Loss: 5.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15723, Training Loss: 1.494e-01, Validation Loss: 5.797e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15724, Training Loss: 1.493e-01, Validation Loss: 5.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15725, Training Loss: 1.493e-01, Validation Loss: 5.797e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15726, Training Loss: 1.493e-01, Validation Loss: 5.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15727, Training Loss: 1.493e-01, Validation Loss: 5.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15728, Training Loss: 1.493e-01, Validation Loss: 5.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15729, Training Loss: 1.493e-01, Validation Loss: 5.797e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15730, Training Loss: 1.493e-01, Validation Loss: 5.797e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15731, Training Loss: 1.493e-01, Validation Loss: 5.797e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15732, Training Loss: 1.492e-01, Validation Loss: 5.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15733, Training Loss: 1.492e-01, Validation Loss: 5.796e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15734, Training Loss: 1.492e-01, Validation Loss: 5.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15735, Training Loss: 1.492e-01, Validation Loss: 5.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15736, Training Loss: 1.492e-01, Validation Loss: 5.796e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15737, Training Loss: 1.492e-01, Validation Loss: 5.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15738, Training Loss: 1.492e-01, Validation Loss: 5.796e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15739, Training Loss: 1.491e-01, Validation Loss: 5.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15740, Training Loss: 1.491e-01, Validation Loss: 5.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15741, Training Loss: 1.491e-01, Validation Loss: 5.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15742, Training Loss: 1.491e-01, Validation Loss: 5.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15743, Training Loss: 1.491e-01, Validation Loss: 5.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15744, Training Loss: 1.491e-01, Validation Loss: 5.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15745, Training Loss: 1.491e-01, Validation Loss: 5.796e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15746, Training Loss: 1.491e-01, Validation Loss: 5.796e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15747, Training Loss: 1.490e-01, Validation Loss: 5.796e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15748, Training Loss: 1.490e-01, Validation Loss: 5.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15749, Training Loss: 1.490e-01, Validation Loss: 5.795e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15750, Training Loss: 1.490e-01, Validation Loss: 5.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15751, Training Loss: 1.490e-01, Validation Loss: 5.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15752, Training Loss: 1.490e-01, Validation Loss: 5.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15753, Training Loss: 1.490e-01, Validation Loss: 5.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15754, Training Loss: 1.489e-01, Validation Loss: 5.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15755, Training Loss: 1.489e-01, Validation Loss: 5.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15756, Training Loss: 1.489e-01, Validation Loss: 5.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15757, Training Loss: 1.489e-01, Validation Loss: 5.795e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15758, Training Loss: 1.489e-01, Validation Loss: 5.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15759, Training Loss: 1.489e-01, Validation Loss: 5.795e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15760, Training Loss: 1.489e-01, Validation Loss: 5.795e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15761, Training Loss: 1.489e-01, Validation Loss: 5.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15762, Training Loss: 1.488e-01, Validation Loss: 5.795e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15763, Training Loss: 1.488e-01, Validation Loss: 5.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15764, Training Loss: 1.488e-01, Validation Loss: 5.794e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15765, Training Loss: 1.488e-01, Validation Loss: 5.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15766, Training Loss: 1.488e-01, Validation Loss: 5.794e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15767, Training Loss: 1.488e-01, Validation Loss: 5.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15768, Training Loss: 1.488e-01, Validation Loss: 5.794e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15769, Training Loss: 1.487e-01, Validation Loss: 5.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15770, Training Loss: 1.487e-01, Validation Loss: 5.794e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15771, Training Loss: 1.487e-01, Validation Loss: 5.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15772, Training Loss: 1.487e-01, Validation Loss: 5.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15773, Training Loss: 1.487e-01, Validation Loss: 5.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15774, Training Loss: 1.487e-01, Validation Loss: 5.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15775, Training Loss: 1.487e-01, Validation Loss: 5.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15776, Training Loss: 1.487e-01, Validation Loss: 5.794e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15777, Training Loss: 1.486e-01, Validation Loss: 5.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15778, Training Loss: 1.486e-01, Validation Loss: 5.794e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15779, Training Loss: 1.486e-01, Validation Loss: 5.794e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15780, Training Loss: 1.486e-01, Validation Loss: 5.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15781, Training Loss: 1.486e-01, Validation Loss: 5.793e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15782, Training Loss: 1.486e-01, Validation Loss: 5.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15783, Training Loss: 1.486e-01, Validation Loss: 5.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15784, Training Loss: 1.485e-01, Validation Loss: 5.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15785, Training Loss: 1.485e-01, Validation Loss: 5.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15786, Training Loss: 1.485e-01, Validation Loss: 5.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15787, Training Loss: 1.485e-01, Validation Loss: 5.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15788, Training Loss: 1.485e-01, Validation Loss: 5.793e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15789, Training Loss: 1.485e-01, Validation Loss: 5.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15790, Training Loss: 1.485e-01, Validation Loss: 5.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15791, Training Loss: 1.485e-01, Validation Loss: 5.793e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15792, Training Loss: 1.484e-01, Validation Loss: 5.793e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15793, Training Loss: 1.484e-01, Validation Loss: 5.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15794, Training Loss: 1.484e-01, Validation Loss: 5.793e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15795, Training Loss: 1.484e-01, Validation Loss: 5.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15796, Training Loss: 1.484e-01, Validation Loss: 5.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15797, Training Loss: 1.484e-01, Validation Loss: 5.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15798, Training Loss: 1.484e-01, Validation Loss: 5.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15799, Training Loss: 1.484e-01, Validation Loss: 5.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15800, Training Loss: 1.483e-01, Validation Loss: 5.792e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15801, Training Loss: 1.483e-01, Validation Loss: 5.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15802, Training Loss: 1.483e-01, Validation Loss: 5.792e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15803, Training Loss: 1.483e-01, Validation Loss: 5.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15804, Training Loss: 1.483e-01, Validation Loss: 5.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15805, Training Loss: 1.483e-01, Validation Loss: 5.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15806, Training Loss: 1.483e-01, Validation Loss: 5.792e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15807, Training Loss: 1.482e-01, Validation Loss: 5.792e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15808, Training Loss: 1.482e-01, Validation Loss: 5.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15809, Training Loss: 1.482e-01, Validation Loss: 5.792e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15810, Training Loss: 1.482e-01, Validation Loss: 5.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15811, Training Loss: 1.482e-01, Validation Loss: 5.791e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15812, Training Loss: 1.482e-01, Validation Loss: 5.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15813, Training Loss: 1.482e-01, Validation Loss: 5.791e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15814, Training Loss: 1.482e-01, Validation Loss: 5.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15815, Training Loss: 1.481e-01, Validation Loss: 5.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15816, Training Loss: 1.481e-01, Validation Loss: 5.791e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15817, Training Loss: 1.481e-01, Validation Loss: 5.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15818, Training Loss: 1.481e-01, Validation Loss: 5.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15819, Training Loss: 1.481e-01, Validation Loss: 5.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15820, Training Loss: 1.481e-01, Validation Loss: 5.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15821, Training Loss: 1.481e-01, Validation Loss: 5.791e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15822, Training Loss: 1.481e-01, Validation Loss: 5.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15823, Training Loss: 1.480e-01, Validation Loss: 5.791e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15824, Training Loss: 1.480e-01, Validation Loss: 5.791e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15825, Training Loss: 1.480e-01, Validation Loss: 5.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15826, Training Loss: 1.480e-01, Validation Loss: 5.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15827, Training Loss: 1.480e-01, Validation Loss: 5.790e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15828, Training Loss: 1.480e-01, Validation Loss: 5.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15829, Training Loss: 1.480e-01, Validation Loss: 5.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15830, Training Loss: 1.479e-01, Validation Loss: 5.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15831, Training Loss: 1.479e-01, Validation Loss: 5.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15832, Training Loss: 1.479e-01, Validation Loss: 5.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15833, Training Loss: 1.479e-01, Validation Loss: 5.790e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15834, Training Loss: 1.479e-01, Validation Loss: 5.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15835, Training Loss: 1.479e-01, Validation Loss: 5.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15836, Training Loss: 1.479e-01, Validation Loss: 5.790e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15837, Training Loss: 1.479e-01, Validation Loss: 5.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15838, Training Loss: 1.478e-01, Validation Loss: 5.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15839, Training Loss: 1.478e-01, Validation Loss: 5.790e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15840, Training Loss: 1.478e-01, Validation Loss: 5.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15841, Training Loss: 1.478e-01, Validation Loss: 5.790e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15842, Training Loss: 1.478e-01, Validation Loss: 5.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15843, Training Loss: 1.478e-01, Validation Loss: 5.790e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15844, Training Loss: 1.478e-01, Validation Loss: 5.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15845, Training Loss: 1.477e-01, Validation Loss: 5.789e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15846, Training Loss: 1.477e-01, Validation Loss: 5.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15847, Training Loss: 1.477e-01, Validation Loss: 5.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15848, Training Loss: 1.477e-01, Validation Loss: 5.789e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15849, Training Loss: 1.477e-01, Validation Loss: 5.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15850, Training Loss: 1.477e-01, Validation Loss: 5.789e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15851, Training Loss: 1.477e-01, Validation Loss: 5.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15852, Training Loss: 1.477e-01, Validation Loss: 5.789e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15853, Training Loss: 1.476e-01, Validation Loss: 5.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15854, Training Loss: 1.476e-01, Validation Loss: 5.789e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15855, Training Loss: 1.476e-01, Validation Loss: 5.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15856, Training Loss: 1.476e-01, Validation Loss: 5.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15857, Training Loss: 1.476e-01, Validation Loss: 5.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15858, Training Loss: 1.476e-01, Validation Loss: 5.789e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15859, Training Loss: 1.476e-01, Validation Loss: 5.789e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15860, Training Loss: 1.476e-01, Validation Loss: 5.789e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15861, Training Loss: 1.475e-01, Validation Loss: 5.789e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 15862, Training Loss: 1.475e-01, Validation Loss: 5.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15863, Training Loss: 1.475e-01, Validation Loss: 5.788e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15864, Training Loss: 1.475e-01, Validation Loss: 5.788e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 15865, Training Loss: 1.475e-01, Validation Loss: 5.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15866, Training Loss: 1.475e-01, Validation Loss: 5.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15867, Training Loss: 1.475e-01, Validation Loss: 5.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15868, Training Loss: 1.474e-01, Validation Loss: 5.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15869, Training Loss: 1.474e-01, Validation Loss: 5.788e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15870, Training Loss: 1.474e-01, Validation Loss: 5.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15871, Training Loss: 1.474e-01, Validation Loss: 5.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15872, Training Loss: 1.474e-01, Validation Loss: 5.788e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15873, Training Loss: 1.474e-01, Validation Loss: 5.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15874, Training Loss: 1.474e-01, Validation Loss: 5.788e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15875, Training Loss: 1.474e-01, Validation Loss: 5.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15876, Training Loss: 1.473e-01, Validation Loss: 5.788e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15877, Training Loss: 1.473e-01, Validation Loss: 5.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15878, Training Loss: 1.473e-01, Validation Loss: 5.788e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15879, Training Loss: 1.473e-01, Validation Loss: 5.788e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15880, Training Loss: 1.473e-01, Validation Loss: 5.788e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15881, Training Loss: 1.473e-01, Validation Loss: 5.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15882, Training Loss: 1.473e-01, Validation Loss: 5.788e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15883, Training Loss: 1.473e-01, Validation Loss: 5.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15884, Training Loss: 1.472e-01, Validation Loss: 5.787e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15885, Training Loss: 1.472e-01, Validation Loss: 5.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15886, Training Loss: 1.472e-01, Validation Loss: 5.787e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15887, Training Loss: 1.472e-01, Validation Loss: 5.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15888, Training Loss: 1.472e-01, Validation Loss: 5.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15889, Training Loss: 1.472e-01, Validation Loss: 5.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15890, Training Loss: 1.472e-01, Validation Loss: 5.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15891, Training Loss: 1.471e-01, Validation Loss: 5.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15892, Training Loss: 1.471e-01, Validation Loss: 5.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15893, Training Loss: 1.471e-01, Validation Loss: 5.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15894, Training Loss: 1.471e-01, Validation Loss: 5.787e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15895, Training Loss: 1.471e-01, Validation Loss: 5.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15896, Training Loss: 1.471e-01, Validation Loss: 5.787e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15897, Training Loss: 1.471e-01, Validation Loss: 5.787e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15898, Training Loss: 1.471e-01, Validation Loss: 5.787e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15899, Training Loss: 1.470e-01, Validation Loss: 5.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15900, Training Loss: 1.470e-01, Validation Loss: 5.787e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15901, Training Loss: 1.470e-01, Validation Loss: 5.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15902, Training Loss: 1.470e-01, Validation Loss: 5.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15903, Training Loss: 1.470e-01, Validation Loss: 5.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15904, Training Loss: 1.470e-01, Validation Loss: 5.786e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15905, Training Loss: 1.470e-01, Validation Loss: 5.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15906, Training Loss: 1.470e-01, Validation Loss: 5.786e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15907, Training Loss: 1.469e-01, Validation Loss: 5.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15908, Training Loss: 1.469e-01, Validation Loss: 5.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15909, Training Loss: 1.469e-01, Validation Loss: 5.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15910, Training Loss: 1.469e-01, Validation Loss: 5.786e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15911, Training Loss: 1.469e-01, Validation Loss: 5.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15912, Training Loss: 1.469e-01, Validation Loss: 5.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15913, Training Loss: 1.469e-01, Validation Loss: 5.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15914, Training Loss: 1.468e-01, Validation Loss: 5.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15915, Training Loss: 1.468e-01, Validation Loss: 5.786e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15916, Training Loss: 1.468e-01, Validation Loss: 5.786e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15917, Training Loss: 1.468e-01, Validation Loss: 5.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15918, Training Loss: 1.468e-01, Validation Loss: 5.785e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15919, Training Loss: 1.468e-01, Validation Loss: 5.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15920, Training Loss: 1.468e-01, Validation Loss: 5.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15921, Training Loss: 1.468e-01, Validation Loss: 5.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15922, Training Loss: 1.467e-01, Validation Loss: 5.785e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15923, Training Loss: 1.467e-01, Validation Loss: 5.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15924, Training Loss: 1.467e-01, Validation Loss: 5.785e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15925, Training Loss: 1.467e-01, Validation Loss: 5.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15926, Training Loss: 1.467e-01, Validation Loss: 5.785e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15927, Training Loss: 1.467e-01, Validation Loss: 5.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15928, Training Loss: 1.467e-01, Validation Loss: 5.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15929, Training Loss: 1.467e-01, Validation Loss: 5.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15930, Training Loss: 1.466e-01, Validation Loss: 5.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15931, Training Loss: 1.466e-01, Validation Loss: 5.785e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15932, Training Loss: 1.466e-01, Validation Loss: 5.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15933, Training Loss: 1.466e-01, Validation Loss: 5.785e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15934, Training Loss: 1.466e-01, Validation Loss: 5.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15935, Training Loss: 1.466e-01, Validation Loss: 5.785e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15936, Training Loss: 1.466e-01, Validation Loss: 5.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15937, Training Loss: 1.466e-01, Validation Loss: 5.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15938, Training Loss: 1.465e-01, Validation Loss: 5.784e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15939, Training Loss: 1.465e-01, Validation Loss: 5.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15940, Training Loss: 1.465e-01, Validation Loss: 5.784e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15941, Training Loss: 1.465e-01, Validation Loss: 5.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15942, Training Loss: 1.465e-01, Validation Loss: 5.784e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15943, Training Loss: 1.465e-01, Validation Loss: 5.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15944, Training Loss: 1.465e-01, Validation Loss: 5.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15945, Training Loss: 1.464e-01, Validation Loss: 5.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15946, Training Loss: 1.464e-01, Validation Loss: 5.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15947, Training Loss: 1.464e-01, Validation Loss: 5.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15948, Training Loss: 1.464e-01, Validation Loss: 5.784e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15949, Training Loss: 1.464e-01, Validation Loss: 5.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15950, Training Loss: 1.464e-01, Validation Loss: 5.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15951, Training Loss: 1.464e-01, Validation Loss: 5.784e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15952, Training Loss: 1.464e-01, Validation Loss: 5.784e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15953, Training Loss: 1.463e-01, Validation Loss: 5.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15954, Training Loss: 1.463e-01, Validation Loss: 5.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15955, Training Loss: 1.463e-01, Validation Loss: 5.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15956, Training Loss: 1.463e-01, Validation Loss: 5.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15957, Training Loss: 1.463e-01, Validation Loss: 5.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15958, Training Loss: 1.463e-01, Validation Loss: 5.783e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15959, Training Loss: 1.463e-01, Validation Loss: 5.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15960, Training Loss: 1.463e-01, Validation Loss: 5.783e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15961, Training Loss: 1.462e-01, Validation Loss: 5.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15962, Training Loss: 1.462e-01, Validation Loss: 5.783e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15963, Training Loss: 1.462e-01, Validation Loss: 5.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15964, Training Loss: 1.462e-01, Validation Loss: 5.783e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15965, Training Loss: 1.462e-01, Validation Loss: 5.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15966, Training Loss: 1.462e-01, Validation Loss: 5.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15967, Training Loss: 1.462e-01, Validation Loss: 5.783e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15968, Training Loss: 1.462e-01, Validation Loss: 5.783e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15969, Training Loss: 1.461e-01, Validation Loss: 5.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15970, Training Loss: 1.461e-01, Validation Loss: 5.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15971, Training Loss: 1.461e-01, Validation Loss: 5.782e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15972, Training Loss: 1.461e-01, Validation Loss: 5.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15973, Training Loss: 1.461e-01, Validation Loss: 5.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15974, Training Loss: 1.461e-01, Validation Loss: 5.782e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15975, Training Loss: 1.461e-01, Validation Loss: 5.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15976, Training Loss: 1.460e-01, Validation Loss: 5.782e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15977, Training Loss: 1.460e-01, Validation Loss: 5.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15978, Training Loss: 1.460e-01, Validation Loss: 5.782e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15979, Training Loss: 1.460e-01, Validation Loss: 5.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15980, Training Loss: 1.460e-01, Validation Loss: 5.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15981, Training Loss: 1.460e-01, Validation Loss: 5.782e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15982, Training Loss: 1.460e-01, Validation Loss: 5.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15983, Training Loss: 1.460e-01, Validation Loss: 5.782e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15984, Training Loss: 1.459e-01, Validation Loss: 5.782e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15985, Training Loss: 1.459e-01, Validation Loss: 5.782e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15986, Training Loss: 1.459e-01, Validation Loss: 5.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15987, Training Loss: 1.459e-01, Validation Loss: 5.781e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15988, Training Loss: 1.459e-01, Validation Loss: 5.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15989, Training Loss: 1.459e-01, Validation Loss: 5.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15990, Training Loss: 1.459e-01, Validation Loss: 5.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15991, Training Loss: 1.459e-01, Validation Loss: 5.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15992, Training Loss: 1.458e-01, Validation Loss: 5.781e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15993, Training Loss: 1.458e-01, Validation Loss: 5.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15994, Training Loss: 1.458e-01, Validation Loss: 5.781e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 15995, Training Loss: 1.458e-01, Validation Loss: 5.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15996, Training Loss: 1.458e-01, Validation Loss: 5.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15997, Training Loss: 1.458e-01, Validation Loss: 5.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15998, Training Loss: 1.458e-01, Validation Loss: 5.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 15999, Training Loss: 1.458e-01, Validation Loss: 5.781e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16000, Training Loss: 1.457e-01, Validation Loss: 5.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16001, Training Loss: 1.457e-01, Validation Loss: 5.781e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16002, Training Loss: 1.457e-01, Validation Loss: 5.781e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16003, Training Loss: 1.457e-01, Validation Loss: 5.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16004, Training Loss: 1.457e-01, Validation Loss: 5.780e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16005, Training Loss: 1.457e-01, Validation Loss: 5.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16006, Training Loss: 1.457e-01, Validation Loss: 5.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16007, Training Loss: 1.457e-01, Validation Loss: 5.780e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16008, Training Loss: 1.456e-01, Validation Loss: 5.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16009, Training Loss: 1.456e-01, Validation Loss: 5.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16010, Training Loss: 1.456e-01, Validation Loss: 5.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16011, Training Loss: 1.456e-01, Validation Loss: 5.780e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16012, Training Loss: 1.456e-01, Validation Loss: 5.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16013, Training Loss: 1.456e-01, Validation Loss: 5.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16014, Training Loss: 1.456e-01, Validation Loss: 5.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16015, Training Loss: 1.455e-01, Validation Loss: 5.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16016, Training Loss: 1.455e-01, Validation Loss: 5.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16017, Training Loss: 1.455e-01, Validation Loss: 5.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16018, Training Loss: 1.455e-01, Validation Loss: 5.780e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16019, Training Loss: 1.455e-01, Validation Loss: 5.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16020, Training Loss: 1.455e-01, Validation Loss: 5.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16021, Training Loss: 1.455e-01, Validation Loss: 5.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16022, Training Loss: 1.455e-01, Validation Loss: 5.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16023, Training Loss: 1.454e-01, Validation Loss: 5.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16024, Training Loss: 1.454e-01, Validation Loss: 5.779e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16025, Training Loss: 1.454e-01, Validation Loss: 5.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16026, Training Loss: 1.454e-01, Validation Loss: 5.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16027, Training Loss: 1.454e-01, Validation Loss: 5.779e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16028, Training Loss: 1.454e-01, Validation Loss: 5.779e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16029, Training Loss: 1.454e-01, Validation Loss: 5.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16030, Training Loss: 1.454e-01, Validation Loss: 5.779e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16031, Training Loss: 1.453e-01, Validation Loss: 5.779e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16032, Training Loss: 1.453e-01, Validation Loss: 5.779e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16033, Training Loss: 1.453e-01, Validation Loss: 5.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16034, Training Loss: 1.453e-01, Validation Loss: 5.779e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16035, Training Loss: 1.453e-01, Validation Loss: 5.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16036, Training Loss: 1.453e-01, Validation Loss: 5.778e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16037, Training Loss: 1.453e-01, Validation Loss: 5.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16038, Training Loss: 1.453e-01, Validation Loss: 5.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16039, Training Loss: 1.452e-01, Validation Loss: 5.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16040, Training Loss: 1.452e-01, Validation Loss: 5.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16041, Training Loss: 1.452e-01, Validation Loss: 5.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16042, Training Loss: 1.452e-01, Validation Loss: 5.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16043, Training Loss: 1.452e-01, Validation Loss: 5.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16044, Training Loss: 1.452e-01, Validation Loss: 5.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16045, Training Loss: 1.452e-01, Validation Loss: 5.778e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16046, Training Loss: 1.452e-01, Validation Loss: 5.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16047, Training Loss: 1.451e-01, Validation Loss: 5.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16048, Training Loss: 1.451e-01, Validation Loss: 5.778e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16049, Training Loss: 1.451e-01, Validation Loss: 5.778e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16050, Training Loss: 1.451e-01, Validation Loss: 5.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16051, Training Loss: 1.451e-01, Validation Loss: 5.778e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16052, Training Loss: 1.451e-01, Validation Loss: 5.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16053, Training Loss: 1.451e-01, Validation Loss: 5.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16054, Training Loss: 1.451e-01, Validation Loss: 5.777e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16055, Training Loss: 1.450e-01, Validation Loss: 5.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16056, Training Loss: 1.450e-01, Validation Loss: 5.777e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16057, Training Loss: 1.450e-01, Validation Loss: 5.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16058, Training Loss: 1.450e-01, Validation Loss: 5.777e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16059, Training Loss: 1.450e-01, Validation Loss: 5.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16060, Training Loss: 1.450e-01, Validation Loss: 5.777e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16061, Training Loss: 1.450e-01, Validation Loss: 5.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16062, Training Loss: 1.450e-01, Validation Loss: 5.777e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16063, Training Loss: 1.449e-01, Validation Loss: 5.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16064, Training Loss: 1.449e-01, Validation Loss: 5.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16065, Training Loss: 1.449e-01, Validation Loss: 5.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16066, Training Loss: 1.449e-01, Validation Loss: 5.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16067, Training Loss: 1.449e-01, Validation Loss: 5.777e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16068, Training Loss: 1.449e-01, Validation Loss: 5.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16069, Training Loss: 1.449e-01, Validation Loss: 5.776e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16070, Training Loss: 1.448e-01, Validation Loss: 5.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16071, Training Loss: 1.448e-01, Validation Loss: 5.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16072, Training Loss: 1.448e-01, Validation Loss: 5.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16073, Training Loss: 1.448e-01, Validation Loss: 5.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16074, Training Loss: 1.448e-01, Validation Loss: 5.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16075, Training Loss: 1.448e-01, Validation Loss: 5.776e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16076, Training Loss: 1.448e-01, Validation Loss: 5.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16077, Training Loss: 1.448e-01, Validation Loss: 5.776e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16078, Training Loss: 1.447e-01, Validation Loss: 5.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16079, Training Loss: 1.447e-01, Validation Loss: 5.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16080, Training Loss: 1.447e-01, Validation Loss: 5.776e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16081, Training Loss: 1.447e-01, Validation Loss: 5.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16082, Training Loss: 1.447e-01, Validation Loss: 5.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16083, Training Loss: 1.447e-01, Validation Loss: 5.776e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16084, Training Loss: 1.447e-01, Validation Loss: 5.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16085, Training Loss: 1.447e-01, Validation Loss: 5.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16086, Training Loss: 1.446e-01, Validation Loss: 5.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16087, Training Loss: 1.446e-01, Validation Loss: 5.775e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16088, Training Loss: 1.446e-01, Validation Loss: 5.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16089, Training Loss: 1.446e-01, Validation Loss: 5.775e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16090, Training Loss: 1.446e-01, Validation Loss: 5.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16091, Training Loss: 1.446e-01, Validation Loss: 5.775e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16092, Training Loss: 1.446e-01, Validation Loss: 5.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16093, Training Loss: 1.446e-01, Validation Loss: 5.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16094, Training Loss: 1.445e-01, Validation Loss: 5.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16095, Training Loss: 1.445e-01, Validation Loss: 5.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16096, Training Loss: 1.445e-01, Validation Loss: 5.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16097, Training Loss: 1.445e-01, Validation Loss: 5.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16098, Training Loss: 1.445e-01, Validation Loss: 5.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16099, Training Loss: 1.445e-01, Validation Loss: 5.775e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16100, Training Loss: 1.445e-01, Validation Loss: 5.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16101, Training Loss: 1.445e-01, Validation Loss: 5.774e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16102, Training Loss: 1.444e-01, Validation Loss: 5.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16103, Training Loss: 1.444e-01, Validation Loss: 5.774e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16104, Training Loss: 1.444e-01, Validation Loss: 5.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16105, Training Loss: 1.444e-01, Validation Loss: 5.774e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16106, Training Loss: 1.444e-01, Validation Loss: 5.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16107, Training Loss: 1.444e-01, Validation Loss: 5.774e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16108, Training Loss: 1.444e-01, Validation Loss: 5.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16109, Training Loss: 1.444e-01, Validation Loss: 5.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16110, Training Loss: 1.443e-01, Validation Loss: 5.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16111, Training Loss: 1.443e-01, Validation Loss: 5.774e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16112, Training Loss: 1.443e-01, Validation Loss: 5.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16113, Training Loss: 1.443e-01, Validation Loss: 5.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16114, Training Loss: 1.443e-01, Validation Loss: 5.774e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16115, Training Loss: 1.443e-01, Validation Loss: 5.774e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16116, Training Loss: 1.443e-01, Validation Loss: 5.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16117, Training Loss: 1.443e-01, Validation Loss: 5.773e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16118, Training Loss: 1.442e-01, Validation Loss: 5.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16119, Training Loss: 1.442e-01, Validation Loss: 5.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16120, Training Loss: 1.442e-01, Validation Loss: 5.773e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16121, Training Loss: 1.442e-01, Validation Loss: 5.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16122, Training Loss: 1.442e-01, Validation Loss: 5.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16123, Training Loss: 1.442e-01, Validation Loss: 5.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16124, Training Loss: 1.442e-01, Validation Loss: 5.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16125, Training Loss: 1.442e-01, Validation Loss: 5.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16126, Training Loss: 1.441e-01, Validation Loss: 5.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16127, Training Loss: 1.441e-01, Validation Loss: 5.773e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16128, Training Loss: 1.441e-01, Validation Loss: 5.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16129, Training Loss: 1.441e-01, Validation Loss: 5.773e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16130, Training Loss: 1.441e-01, Validation Loss: 5.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16131, Training Loss: 1.441e-01, Validation Loss: 5.773e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16132, Training Loss: 1.441e-01, Validation Loss: 5.773e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16133, Training Loss: 1.441e-01, Validation Loss: 5.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16134, Training Loss: 1.440e-01, Validation Loss: 5.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16135, Training Loss: 1.440e-01, Validation Loss: 5.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16136, Training Loss: 1.440e-01, Validation Loss: 5.772e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16137, Training Loss: 1.440e-01, Validation Loss: 5.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16138, Training Loss: 1.440e-01, Validation Loss: 5.772e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16139, Training Loss: 1.440e-01, Validation Loss: 5.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16140, Training Loss: 1.440e-01, Validation Loss: 5.772e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16141, Training Loss: 1.440e-01, Validation Loss: 5.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16142, Training Loss: 1.439e-01, Validation Loss: 5.772e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16143, Training Loss: 1.439e-01, Validation Loss: 5.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16144, Training Loss: 1.439e-01, Validation Loss: 5.772e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16145, Training Loss: 1.439e-01, Validation Loss: 5.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16146, Training Loss: 1.439e-01, Validation Loss: 5.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16147, Training Loss: 1.439e-01, Validation Loss: 5.772e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16148, Training Loss: 1.439e-01, Validation Loss: 5.772e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16149, Training Loss: 1.439e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16150, Training Loss: 1.438e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16151, Training Loss: 1.438e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16152, Training Loss: 1.438e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16153, Training Loss: 1.438e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16154, Training Loss: 1.438e-01, Validation Loss: 5.771e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16155, Training Loss: 1.438e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16156, Training Loss: 1.438e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16157, Training Loss: 1.438e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16158, Training Loss: 1.437e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16159, Training Loss: 1.437e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16160, Training Loss: 1.437e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16161, Training Loss: 1.437e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16162, Training Loss: 1.437e-01, Validation Loss: 5.771e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16163, Training Loss: 1.437e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16164, Training Loss: 1.437e-01, Validation Loss: 5.771e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16165, Training Loss: 1.437e-01, Validation Loss: 5.771e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16166, Training Loss: 1.436e-01, Validation Loss: 5.771e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16167, Training Loss: 1.436e-01, Validation Loss: 5.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16168, Training Loss: 1.436e-01, Validation Loss: 5.770e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16169, Training Loss: 1.436e-01, Validation Loss: 5.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16170, Training Loss: 1.436e-01, Validation Loss: 5.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16171, Training Loss: 1.436e-01, Validation Loss: 5.770e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16172, Training Loss: 1.436e-01, Validation Loss: 5.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16173, Training Loss: 1.436e-01, Validation Loss: 5.770e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16174, Training Loss: 1.435e-01, Validation Loss: 5.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16175, Training Loss: 1.435e-01, Validation Loss: 5.770e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16176, Training Loss: 1.435e-01, Validation Loss: 5.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16177, Training Loss: 1.435e-01, Validation Loss: 5.770e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16178, Training Loss: 1.435e-01, Validation Loss: 5.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16179, Training Loss: 1.435e-01, Validation Loss: 5.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16180, Training Loss: 1.435e-01, Validation Loss: 5.770e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16181, Training Loss: 1.435e-01, Validation Loss: 5.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16182, Training Loss: 1.434e-01, Validation Loss: 5.770e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16183, Training Loss: 1.434e-01, Validation Loss: 5.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16184, Training Loss: 1.434e-01, Validation Loss: 5.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16185, Training Loss: 1.434e-01, Validation Loss: 5.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16186, Training Loss: 1.434e-01, Validation Loss: 5.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16187, Training Loss: 1.434e-01, Validation Loss: 5.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16188, Training Loss: 1.434e-01, Validation Loss: 5.769e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16189, Training Loss: 1.434e-01, Validation Loss: 5.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16190, Training Loss: 1.433e-01, Validation Loss: 5.769e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16191, Training Loss: 1.433e-01, Validation Loss: 5.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16192, Training Loss: 1.433e-01, Validation Loss: 5.769e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16193, Training Loss: 1.433e-01, Validation Loss: 5.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16194, Training Loss: 1.433e-01, Validation Loss: 5.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16195, Training Loss: 1.433e-01, Validation Loss: 5.769e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16196, Training Loss: 1.433e-01, Validation Loss: 5.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16197, Training Loss: 1.433e-01, Validation Loss: 5.769e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16198, Training Loss: 1.432e-01, Validation Loss: 5.769e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16199, Training Loss: 1.432e-01, Validation Loss: 5.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16200, Training Loss: 1.432e-01, Validation Loss: 5.768e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16201, Training Loss: 1.432e-01, Validation Loss: 5.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16202, Training Loss: 1.432e-01, Validation Loss: 5.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16203, Training Loss: 1.432e-01, Validation Loss: 5.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16204, Training Loss: 1.432e-01, Validation Loss: 5.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16205, Training Loss: 1.432e-01, Validation Loss: 5.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16206, Training Loss: 1.431e-01, Validation Loss: 5.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16207, Training Loss: 1.431e-01, Validation Loss: 5.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16208, Training Loss: 1.431e-01, Validation Loss: 5.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16209, Training Loss: 1.431e-01, Validation Loss: 5.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16210, Training Loss: 1.431e-01, Validation Loss: 5.768e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16211, Training Loss: 1.431e-01, Validation Loss: 5.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16212, Training Loss: 1.431e-01, Validation Loss: 5.768e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16213, Training Loss: 1.431e-01, Validation Loss: 5.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16214, Training Loss: 1.430e-01, Validation Loss: 5.768e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16215, Training Loss: 1.430e-01, Validation Loss: 5.768e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16216, Training Loss: 1.430e-01, Validation Loss: 5.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16217, Training Loss: 1.430e-01, Validation Loss: 5.767e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16218, Training Loss: 1.430e-01, Validation Loss: 5.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16219, Training Loss: 1.430e-01, Validation Loss: 5.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16220, Training Loss: 1.430e-01, Validation Loss: 5.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16221, Training Loss: 1.430e-01, Validation Loss: 5.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16222, Training Loss: 1.429e-01, Validation Loss: 5.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16223, Training Loss: 1.429e-01, Validation Loss: 5.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16224, Training Loss: 1.429e-01, Validation Loss: 5.767e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16225, Training Loss: 1.429e-01, Validation Loss: 5.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16226, Training Loss: 1.429e-01, Validation Loss: 5.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16227, Training Loss: 1.429e-01, Validation Loss: 5.767e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16228, Training Loss: 1.429e-01, Validation Loss: 5.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16229, Training Loss: 1.429e-01, Validation Loss: 5.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16230, Training Loss: 1.428e-01, Validation Loss: 5.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16231, Training Loss: 1.428e-01, Validation Loss: 5.767e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16232, Training Loss: 1.428e-01, Validation Loss: 5.767e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16233, Training Loss: 1.428e-01, Validation Loss: 5.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16234, Training Loss: 1.428e-01, Validation Loss: 5.766e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16235, Training Loss: 1.428e-01, Validation Loss: 5.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16236, Training Loss: 1.428e-01, Validation Loss: 5.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16237, Training Loss: 1.428e-01, Validation Loss: 5.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16238, Training Loss: 1.427e-01, Validation Loss: 5.766e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16239, Training Loss: 1.427e-01, Validation Loss: 5.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16240, Training Loss: 1.427e-01, Validation Loss: 5.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16241, Training Loss: 1.427e-01, Validation Loss: 5.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16242, Training Loss: 1.427e-01, Validation Loss: 5.766e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16243, Training Loss: 1.427e-01, Validation Loss: 5.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16244, Training Loss: 1.427e-01, Validation Loss: 5.766e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16245, Training Loss: 1.427e-01, Validation Loss: 5.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16246, Training Loss: 1.426e-01, Validation Loss: 5.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16247, Training Loss: 1.426e-01, Validation Loss: 5.766e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16248, Training Loss: 1.426e-01, Validation Loss: 5.766e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16249, Training Loss: 1.426e-01, Validation Loss: 5.766e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16250, Training Loss: 1.426e-01, Validation Loss: 5.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16251, Training Loss: 1.426e-01, Validation Loss: 5.765e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16252, Training Loss: 1.426e-01, Validation Loss: 5.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16253, Training Loss: 1.426e-01, Validation Loss: 5.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16254, Training Loss: 1.425e-01, Validation Loss: 5.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16255, Training Loss: 1.425e-01, Validation Loss: 5.765e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16256, Training Loss: 1.425e-01, Validation Loss: 5.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16257, Training Loss: 1.425e-01, Validation Loss: 5.765e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16258, Training Loss: 1.425e-01, Validation Loss: 5.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16259, Training Loss: 1.425e-01, Validation Loss: 5.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16260, Training Loss: 1.425e-01, Validation Loss: 5.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16261, Training Loss: 1.425e-01, Validation Loss: 5.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16262, Training Loss: 1.424e-01, Validation Loss: 5.765e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16263, Training Loss: 1.424e-01, Validation Loss: 5.765e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16264, Training Loss: 1.424e-01, Validation Loss: 5.765e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16265, Training Loss: 1.424e-01, Validation Loss: 5.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16266, Training Loss: 1.424e-01, Validation Loss: 5.765e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16267, Training Loss: 1.424e-01, Validation Loss: 5.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16268, Training Loss: 1.424e-01, Validation Loss: 5.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16269, Training Loss: 1.424e-01, Validation Loss: 5.764e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16270, Training Loss: 1.423e-01, Validation Loss: 5.764e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16271, Training Loss: 1.423e-01, Validation Loss: 5.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16272, Training Loss: 1.423e-01, Validation Loss: 5.764e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16273, Training Loss: 1.423e-01, Validation Loss: 5.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16274, Training Loss: 1.423e-01, Validation Loss: 5.764e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16275, Training Loss: 1.423e-01, Validation Loss: 5.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16276, Training Loss: 1.423e-01, Validation Loss: 5.764e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16277, Training Loss: 1.423e-01, Validation Loss: 5.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16278, Training Loss: 1.422e-01, Validation Loss: 5.764e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16279, Training Loss: 1.422e-01, Validation Loss: 5.764e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16280, Training Loss: 1.422e-01, Validation Loss: 5.764e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16281, Training Loss: 1.422e-01, Validation Loss: 5.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16282, Training Loss: 1.422e-01, Validation Loss: 5.764e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16283, Training Loss: 1.422e-01, Validation Loss: 5.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16284, Training Loss: 1.422e-01, Validation Loss: 5.763e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16285, Training Loss: 1.422e-01, Validation Loss: 5.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16286, Training Loss: 1.421e-01, Validation Loss: 5.763e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16287, Training Loss: 1.421e-01, Validation Loss: 5.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16288, Training Loss: 1.421e-01, Validation Loss: 5.763e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16289, Training Loss: 1.421e-01, Validation Loss: 5.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16290, Training Loss: 1.421e-01, Validation Loss: 5.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16291, Training Loss: 1.421e-01, Validation Loss: 5.763e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16292, Training Loss: 1.421e-01, Validation Loss: 5.763e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16293, Training Loss: 1.421e-01, Validation Loss: 5.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16294, Training Loss: 1.420e-01, Validation Loss: 5.763e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16295, Training Loss: 1.420e-01, Validation Loss: 5.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16296, Training Loss: 1.420e-01, Validation Loss: 5.763e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16297, Training Loss: 1.420e-01, Validation Loss: 5.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16298, Training Loss: 1.420e-01, Validation Loss: 5.763e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16299, Training Loss: 1.420e-01, Validation Loss: 5.763e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16300, Training Loss: 1.420e-01, Validation Loss: 5.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16301, Training Loss: 1.420e-01, Validation Loss: 5.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16302, Training Loss: 1.419e-01, Validation Loss: 5.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16303, Training Loss: 1.419e-01, Validation Loss: 5.762e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16304, Training Loss: 1.419e-01, Validation Loss: 5.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16305, Training Loss: 1.419e-01, Validation Loss: 5.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16306, Training Loss: 1.419e-01, Validation Loss: 5.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16307, Training Loss: 1.419e-01, Validation Loss: 5.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16308, Training Loss: 1.419e-01, Validation Loss: 5.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16309, Training Loss: 1.419e-01, Validation Loss: 5.762e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16310, Training Loss: 1.419e-01, Validation Loss: 5.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16311, Training Loss: 1.418e-01, Validation Loss: 5.762e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16312, Training Loss: 1.418e-01, Validation Loss: 5.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16313, Training Loss: 1.418e-01, Validation Loss: 5.762e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16314, Training Loss: 1.418e-01, Validation Loss: 5.762e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16315, Training Loss: 1.418e-01, Validation Loss: 5.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16316, Training Loss: 1.418e-01, Validation Loss: 5.762e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16317, Training Loss: 1.418e-01, Validation Loss: 5.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16318, Training Loss: 1.418e-01, Validation Loss: 5.761e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16319, Training Loss: 1.417e-01, Validation Loss: 5.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16320, Training Loss: 1.417e-01, Validation Loss: 5.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16321, Training Loss: 1.417e-01, Validation Loss: 5.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16322, Training Loss: 1.417e-01, Validation Loss: 5.761e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16323, Training Loss: 1.417e-01, Validation Loss: 5.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16324, Training Loss: 1.417e-01, Validation Loss: 5.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16325, Training Loss: 1.417e-01, Validation Loss: 5.761e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16326, Training Loss: 1.417e-01, Validation Loss: 5.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16327, Training Loss: 1.416e-01, Validation Loss: 5.761e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16328, Training Loss: 1.416e-01, Validation Loss: 5.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16329, Training Loss: 1.416e-01, Validation Loss: 5.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16330, Training Loss: 1.416e-01, Validation Loss: 5.761e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16331, Training Loss: 1.416e-01, Validation Loss: 5.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16332, Training Loss: 1.416e-01, Validation Loss: 5.761e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16333, Training Loss: 1.416e-01, Validation Loss: 5.761e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16334, Training Loss: 1.416e-01, Validation Loss: 5.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16335, Training Loss: 1.415e-01, Validation Loss: 5.760e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16336, Training Loss: 1.415e-01, Validation Loss: 5.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16337, Training Loss: 1.415e-01, Validation Loss: 5.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16338, Training Loss: 1.415e-01, Validation Loss: 5.760e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16339, Training Loss: 1.415e-01, Validation Loss: 5.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16340, Training Loss: 1.415e-01, Validation Loss: 5.760e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16341, Training Loss: 1.415e-01, Validation Loss: 5.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16342, Training Loss: 1.415e-01, Validation Loss: 5.760e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16343, Training Loss: 1.414e-01, Validation Loss: 5.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16344, Training Loss: 1.414e-01, Validation Loss: 5.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16345, Training Loss: 1.414e-01, Validation Loss: 5.760e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16346, Training Loss: 1.414e-01, Validation Loss: 5.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16347, Training Loss: 1.414e-01, Validation Loss: 5.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16348, Training Loss: 1.414e-01, Validation Loss: 5.760e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16349, Training Loss: 1.414e-01, Validation Loss: 5.760e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16350, Training Loss: 1.414e-01, Validation Loss: 5.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16351, Training Loss: 1.413e-01, Validation Loss: 5.759e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16352, Training Loss: 1.413e-01, Validation Loss: 5.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16353, Training Loss: 1.413e-01, Validation Loss: 5.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16354, Training Loss: 1.413e-01, Validation Loss: 5.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16355, Training Loss: 1.413e-01, Validation Loss: 5.759e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16356, Training Loss: 1.413e-01, Validation Loss: 5.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16357, Training Loss: 1.413e-01, Validation Loss: 5.759e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16358, Training Loss: 1.413e-01, Validation Loss: 5.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16359, Training Loss: 1.412e-01, Validation Loss: 5.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16360, Training Loss: 1.412e-01, Validation Loss: 5.759e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16361, Training Loss: 1.412e-01, Validation Loss: 5.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16362, Training Loss: 1.412e-01, Validation Loss: 5.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16363, Training Loss: 1.412e-01, Validation Loss: 5.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16364, Training Loss: 1.412e-01, Validation Loss: 5.759e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16365, Training Loss: 1.412e-01, Validation Loss: 5.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16366, Training Loss: 1.412e-01, Validation Loss: 5.759e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16367, Training Loss: 1.412e-01, Validation Loss: 5.759e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16368, Training Loss: 1.411e-01, Validation Loss: 5.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16369, Training Loss: 1.411e-01, Validation Loss: 5.758e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16370, Training Loss: 1.411e-01, Validation Loss: 5.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16371, Training Loss: 1.411e-01, Validation Loss: 5.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16372, Training Loss: 1.411e-01, Validation Loss: 5.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16373, Training Loss: 1.411e-01, Validation Loss: 5.758e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16374, Training Loss: 1.411e-01, Validation Loss: 5.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16375, Training Loss: 1.411e-01, Validation Loss: 5.758e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16376, Training Loss: 1.410e-01, Validation Loss: 5.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16377, Training Loss: 1.410e-01, Validation Loss: 5.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16378, Training Loss: 1.410e-01, Validation Loss: 5.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16379, Training Loss: 1.410e-01, Validation Loss: 5.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16380, Training Loss: 1.410e-01, Validation Loss: 5.758e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16381, Training Loss: 1.410e-01, Validation Loss: 5.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16382, Training Loss: 1.410e-01, Validation Loss: 5.758e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16383, Training Loss: 1.410e-01, Validation Loss: 5.758e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16384, Training Loss: 1.409e-01, Validation Loss: 5.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16385, Training Loss: 1.409e-01, Validation Loss: 5.757e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16386, Training Loss: 1.409e-01, Validation Loss: 5.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16387, Training Loss: 1.409e-01, Validation Loss: 5.757e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16388, Training Loss: 1.409e-01, Validation Loss: 5.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16389, Training Loss: 1.409e-01, Validation Loss: 5.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16390, Training Loss: 1.409e-01, Validation Loss: 5.757e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16391, Training Loss: 1.409e-01, Validation Loss: 5.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16392, Training Loss: 1.408e-01, Validation Loss: 5.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16393, Training Loss: 1.408e-01, Validation Loss: 5.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16394, Training Loss: 1.408e-01, Validation Loss: 5.757e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16395, Training Loss: 1.408e-01, Validation Loss: 5.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16396, Training Loss: 1.408e-01, Validation Loss: 5.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16397, Training Loss: 1.408e-01, Validation Loss: 5.757e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16398, Training Loss: 1.408e-01, Validation Loss: 5.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16399, Training Loss: 1.408e-01, Validation Loss: 5.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16400, Training Loss: 1.408e-01, Validation Loss: 5.757e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16401, Training Loss: 1.407e-01, Validation Loss: 5.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16402, Training Loss: 1.407e-01, Validation Loss: 5.756e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16403, Training Loss: 1.407e-01, Validation Loss: 5.756e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16404, Training Loss: 1.407e-01, Validation Loss: 5.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16405, Training Loss: 1.407e-01, Validation Loss: 5.756e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16406, Training Loss: 1.407e-01, Validation Loss: 5.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16407, Training Loss: 1.407e-01, Validation Loss: 5.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16408, Training Loss: 1.407e-01, Validation Loss: 5.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16409, Training Loss: 1.406e-01, Validation Loss: 5.756e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16410, Training Loss: 1.406e-01, Validation Loss: 5.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16411, Training Loss: 1.406e-01, Validation Loss: 5.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16412, Training Loss: 1.406e-01, Validation Loss: 5.756e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16413, Training Loss: 1.406e-01, Validation Loss: 5.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16414, Training Loss: 1.406e-01, Validation Loss: 5.756e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16415, Training Loss: 1.406e-01, Validation Loss: 5.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16416, Training Loss: 1.406e-01, Validation Loss: 5.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16417, Training Loss: 1.405e-01, Validation Loss: 5.756e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16418, Training Loss: 1.405e-01, Validation Loss: 5.756e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16419, Training Loss: 1.405e-01, Validation Loss: 5.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16420, Training Loss: 1.405e-01, Validation Loss: 5.755e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16421, Training Loss: 1.405e-01, Validation Loss: 5.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16422, Training Loss: 1.405e-01, Validation Loss: 5.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16423, Training Loss: 1.405e-01, Validation Loss: 5.755e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16424, Training Loss: 1.405e-01, Validation Loss: 5.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16425, Training Loss: 1.404e-01, Validation Loss: 5.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16426, Training Loss: 1.404e-01, Validation Loss: 5.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16427, Training Loss: 1.404e-01, Validation Loss: 5.755e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16428, Training Loss: 1.404e-01, Validation Loss: 5.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16429, Training Loss: 1.404e-01, Validation Loss: 5.755e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16430, Training Loss: 1.404e-01, Validation Loss: 5.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16431, Training Loss: 1.404e-01, Validation Loss: 5.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16432, Training Loss: 1.404e-01, Validation Loss: 5.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16433, Training Loss: 1.404e-01, Validation Loss: 5.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16434, Training Loss: 1.403e-01, Validation Loss: 5.755e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16435, Training Loss: 1.403e-01, Validation Loss: 5.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16436, Training Loss: 1.403e-01, Validation Loss: 5.755e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16437, Training Loss: 1.403e-01, Validation Loss: 5.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16438, Training Loss: 1.403e-01, Validation Loss: 5.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16439, Training Loss: 1.403e-01, Validation Loss: 5.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16440, Training Loss: 1.403e-01, Validation Loss: 5.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16441, Training Loss: 1.403e-01, Validation Loss: 5.754e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16442, Training Loss: 1.402e-01, Validation Loss: 5.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16443, Training Loss: 1.402e-01, Validation Loss: 5.754e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16444, Training Loss: 1.402e-01, Validation Loss: 5.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16445, Training Loss: 1.402e-01, Validation Loss: 5.754e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16446, Training Loss: 1.402e-01, Validation Loss: 5.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16447, Training Loss: 1.402e-01, Validation Loss: 5.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16448, Training Loss: 1.402e-01, Validation Loss: 5.754e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16449, Training Loss: 1.402e-01, Validation Loss: 5.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16450, Training Loss: 1.401e-01, Validation Loss: 5.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16451, Training Loss: 1.401e-01, Validation Loss: 5.754e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16452, Training Loss: 1.401e-01, Validation Loss: 5.754e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16453, Training Loss: 1.401e-01, Validation Loss: 5.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16454, Training Loss: 1.401e-01, Validation Loss: 5.753e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16455, Training Loss: 1.401e-01, Validation Loss: 5.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16456, Training Loss: 1.401e-01, Validation Loss: 5.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16457, Training Loss: 1.401e-01, Validation Loss: 5.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16458, Training Loss: 1.400e-01, Validation Loss: 5.753e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16459, Training Loss: 1.400e-01, Validation Loss: 5.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16460, Training Loss: 1.400e-01, Validation Loss: 5.753e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16461, Training Loss: 1.400e-01, Validation Loss: 5.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16462, Training Loss: 1.400e-01, Validation Loss: 5.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16463, Training Loss: 1.400e-01, Validation Loss: 5.753e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16464, Training Loss: 1.400e-01, Validation Loss: 5.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16465, Training Loss: 1.400e-01, Validation Loss: 5.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16466, Training Loss: 1.400e-01, Validation Loss: 5.753e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16467, Training Loss: 1.399e-01, Validation Loss: 5.753e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16468, Training Loss: 1.399e-01, Validation Loss: 5.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16469, Training Loss: 1.399e-01, Validation Loss: 5.753e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16470, Training Loss: 1.399e-01, Validation Loss: 5.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16471, Training Loss: 1.399e-01, Validation Loss: 5.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16472, Training Loss: 1.399e-01, Validation Loss: 5.752e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16473, Training Loss: 1.399e-01, Validation Loss: 5.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16474, Training Loss: 1.399e-01, Validation Loss: 5.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16475, Training Loss: 1.398e-01, Validation Loss: 5.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16476, Training Loss: 1.398e-01, Validation Loss: 5.752e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16477, Training Loss: 1.398e-01, Validation Loss: 5.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16478, Training Loss: 1.398e-01, Validation Loss: 5.752e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16479, Training Loss: 1.398e-01, Validation Loss: 5.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16480, Training Loss: 1.398e-01, Validation Loss: 5.752e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16481, Training Loss: 1.398e-01, Validation Loss: 5.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16482, Training Loss: 1.398e-01, Validation Loss: 5.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16483, Training Loss: 1.397e-01, Validation Loss: 5.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16484, Training Loss: 1.397e-01, Validation Loss: 5.752e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16485, Training Loss: 1.397e-01, Validation Loss: 5.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16486, Training Loss: 1.397e-01, Validation Loss: 5.752e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16487, Training Loss: 1.397e-01, Validation Loss: 5.752e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16488, Training Loss: 1.397e-01, Validation Loss: 5.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16489, Training Loss: 1.397e-01, Validation Loss: 5.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16490, Training Loss: 1.397e-01, Validation Loss: 5.751e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16491, Training Loss: 1.397e-01, Validation Loss: 5.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16492, Training Loss: 1.396e-01, Validation Loss: 5.751e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16493, Training Loss: 1.396e-01, Validation Loss: 5.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16494, Training Loss: 1.396e-01, Validation Loss: 5.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16495, Training Loss: 1.396e-01, Validation Loss: 5.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16496, Training Loss: 1.396e-01, Validation Loss: 5.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16497, Training Loss: 1.396e-01, Validation Loss: 5.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16498, Training Loss: 1.396e-01, Validation Loss: 5.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16499, Training Loss: 1.396e-01, Validation Loss: 5.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16500, Training Loss: 1.395e-01, Validation Loss: 5.751e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16501, Training Loss: 1.395e-01, Validation Loss: 5.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16502, Training Loss: 1.395e-01, Validation Loss: 5.751e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16503, Training Loss: 1.395e-01, Validation Loss: 5.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16504, Training Loss: 1.395e-01, Validation Loss: 5.751e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16505, Training Loss: 1.395e-01, Validation Loss: 5.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16506, Training Loss: 1.395e-01, Validation Loss: 5.751e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16507, Training Loss: 1.395e-01, Validation Loss: 5.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16508, Training Loss: 1.394e-01, Validation Loss: 5.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16509, Training Loss: 1.394e-01, Validation Loss: 5.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16510, Training Loss: 1.394e-01, Validation Loss: 5.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16511, Training Loss: 1.394e-01, Validation Loss: 5.750e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16512, Training Loss: 1.394e-01, Validation Loss: 5.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16513, Training Loss: 1.394e-01, Validation Loss: 5.750e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16514, Training Loss: 1.394e-01, Validation Loss: 5.750e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16515, Training Loss: 1.394e-01, Validation Loss: 5.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16516, Training Loss: 1.394e-01, Validation Loss: 5.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16517, Training Loss: 1.393e-01, Validation Loss: 5.750e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16518, Training Loss: 1.393e-01, Validation Loss: 5.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16519, Training Loss: 1.393e-01, Validation Loss: 5.750e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16520, Training Loss: 1.393e-01, Validation Loss: 5.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16521, Training Loss: 1.393e-01, Validation Loss: 5.750e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16522, Training Loss: 1.393e-01, Validation Loss: 5.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16523, Training Loss: 1.393e-01, Validation Loss: 5.750e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16524, Training Loss: 1.393e-01, Validation Loss: 5.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16525, Training Loss: 1.392e-01, Validation Loss: 5.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16526, Training Loss: 1.392e-01, Validation Loss: 5.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16527, Training Loss: 1.392e-01, Validation Loss: 5.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16528, Training Loss: 1.392e-01, Validation Loss: 5.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16529, Training Loss: 1.392e-01, Validation Loss: 5.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16530, Training Loss: 1.392e-01, Validation Loss: 5.749e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16531, Training Loss: 1.392e-01, Validation Loss: 5.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16532, Training Loss: 1.392e-01, Validation Loss: 5.749e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16533, Training Loss: 1.391e-01, Validation Loss: 5.749e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16534, Training Loss: 1.391e-01, Validation Loss: 5.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16535, Training Loss: 1.391e-01, Validation Loss: 5.749e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16536, Training Loss: 1.391e-01, Validation Loss: 5.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16537, Training Loss: 1.391e-01, Validation Loss: 5.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16538, Training Loss: 1.391e-01, Validation Loss: 5.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16539, Training Loss: 1.391e-01, Validation Loss: 5.749e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16540, Training Loss: 1.391e-01, Validation Loss: 5.749e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16541, Training Loss: 1.391e-01, Validation Loss: 5.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16542, Training Loss: 1.390e-01, Validation Loss: 5.749e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16543, Training Loss: 1.390e-01, Validation Loss: 5.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16544, Training Loss: 1.390e-01, Validation Loss: 5.748e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16545, Training Loss: 1.390e-01, Validation Loss: 5.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16546, Training Loss: 1.390e-01, Validation Loss: 5.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16547, Training Loss: 1.390e-01, Validation Loss: 5.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16548, Training Loss: 1.390e-01, Validation Loss: 5.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16549, Training Loss: 1.390e-01, Validation Loss: 5.748e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16550, Training Loss: 1.389e-01, Validation Loss: 5.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16551, Training Loss: 1.389e-01, Validation Loss: 5.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16552, Training Loss: 1.389e-01, Validation Loss: 5.748e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16553, Training Loss: 1.389e-01, Validation Loss: 5.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16554, Training Loss: 1.389e-01, Validation Loss: 5.748e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16555, Training Loss: 1.389e-01, Validation Loss: 5.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16556, Training Loss: 1.389e-01, Validation Loss: 5.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16557, Training Loss: 1.389e-01, Validation Loss: 5.748e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16558, Training Loss: 1.388e-01, Validation Loss: 5.748e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16559, Training Loss: 1.388e-01, Validation Loss: 5.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16560, Training Loss: 1.388e-01, Validation Loss: 5.747e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16561, Training Loss: 1.388e-01, Validation Loss: 5.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16562, Training Loss: 1.388e-01, Validation Loss: 5.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16563, Training Loss: 1.388e-01, Validation Loss: 5.747e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16564, Training Loss: 1.388e-01, Validation Loss: 5.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16565, Training Loss: 1.388e-01, Validation Loss: 5.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16566, Training Loss: 1.388e-01, Validation Loss: 5.747e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16567, Training Loss: 1.387e-01, Validation Loss: 5.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16568, Training Loss: 1.387e-01, Validation Loss: 5.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16569, Training Loss: 1.387e-01, Validation Loss: 5.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16570, Training Loss: 1.387e-01, Validation Loss: 5.747e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16571, Training Loss: 1.387e-01, Validation Loss: 5.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16572, Training Loss: 1.387e-01, Validation Loss: 5.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16573, Training Loss: 1.387e-01, Validation Loss: 5.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16574, Training Loss: 1.387e-01, Validation Loss: 5.747e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16575, Training Loss: 1.386e-01, Validation Loss: 5.747e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16576, Training Loss: 1.386e-01, Validation Loss: 5.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16577, Training Loss: 1.386e-01, Validation Loss: 5.747e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16578, Training Loss: 1.386e-01, Validation Loss: 5.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16579, Training Loss: 1.386e-01, Validation Loss: 5.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16580, Training Loss: 1.386e-01, Validation Loss: 5.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16581, Training Loss: 1.386e-01, Validation Loss: 5.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16582, Training Loss: 1.386e-01, Validation Loss: 5.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16583, Training Loss: 1.386e-01, Validation Loss: 5.746e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16584, Training Loss: 1.385e-01, Validation Loss: 5.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16585, Training Loss: 1.385e-01, Validation Loss: 5.746e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16586, Training Loss: 1.385e-01, Validation Loss: 5.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16587, Training Loss: 1.385e-01, Validation Loss: 5.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16588, Training Loss: 1.385e-01, Validation Loss: 5.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16589, Training Loss: 1.385e-01, Validation Loss: 5.746e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16590, Training Loss: 1.385e-01, Validation Loss: 5.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16591, Training Loss: 1.385e-01, Validation Loss: 5.746e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16592, Training Loss: 1.384e-01, Validation Loss: 5.746e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16593, Training Loss: 1.384e-01, Validation Loss: 5.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16594, Training Loss: 1.384e-01, Validation Loss: 5.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16595, Training Loss: 1.384e-01, Validation Loss: 5.746e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16596, Training Loss: 1.384e-01, Validation Loss: 5.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16597, Training Loss: 1.384e-01, Validation Loss: 5.745e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16598, Training Loss: 1.384e-01, Validation Loss: 5.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16599, Training Loss: 1.384e-01, Validation Loss: 5.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16600, Training Loss: 1.384e-01, Validation Loss: 5.745e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16601, Training Loss: 1.383e-01, Validation Loss: 5.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16602, Training Loss: 1.383e-01, Validation Loss: 5.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16603, Training Loss: 1.383e-01, Validation Loss: 5.745e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16604, Training Loss: 1.383e-01, Validation Loss: 5.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16605, Training Loss: 1.383e-01, Validation Loss: 5.745e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16606, Training Loss: 1.383e-01, Validation Loss: 5.745e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16607, Training Loss: 1.383e-01, Validation Loss: 5.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16608, Training Loss: 1.383e-01, Validation Loss: 5.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16609, Training Loss: 1.382e-01, Validation Loss: 5.745e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16610, Training Loss: 1.382e-01, Validation Loss: 5.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16611, Training Loss: 1.382e-01, Validation Loss: 5.745e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16612, Training Loss: 1.382e-01, Validation Loss: 5.745e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16613, Training Loss: 1.382e-01, Validation Loss: 5.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16614, Training Loss: 1.382e-01, Validation Loss: 5.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16615, Training Loss: 1.382e-01, Validation Loss: 5.744e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16616, Training Loss: 1.382e-01, Validation Loss: 5.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16617, Training Loss: 1.382e-01, Validation Loss: 5.744e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16618, Training Loss: 1.381e-01, Validation Loss: 5.744e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16619, Training Loss: 1.381e-01, Validation Loss: 5.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16620, Training Loss: 1.381e-01, Validation Loss: 5.744e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16621, Training Loss: 1.381e-01, Validation Loss: 5.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16622, Training Loss: 1.381e-01, Validation Loss: 5.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16623, Training Loss: 1.381e-01, Validation Loss: 5.744e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16624, Training Loss: 1.381e-01, Validation Loss: 5.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16625, Training Loss: 1.381e-01, Validation Loss: 5.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16626, Training Loss: 1.380e-01, Validation Loss: 5.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16627, Training Loss: 1.380e-01, Validation Loss: 5.744e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16628, Training Loss: 1.380e-01, Validation Loss: 5.744e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16629, Training Loss: 1.380e-01, Validation Loss: 5.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16630, Training Loss: 1.380e-01, Validation Loss: 5.744e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16631, Training Loss: 1.380e-01, Validation Loss: 5.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16632, Training Loss: 1.380e-01, Validation Loss: 5.743e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16633, Training Loss: 1.380e-01, Validation Loss: 5.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16634, Training Loss: 1.380e-01, Validation Loss: 5.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16635, Training Loss: 1.379e-01, Validation Loss: 5.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16636, Training Loss: 1.379e-01, Validation Loss: 5.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16637, Training Loss: 1.379e-01, Validation Loss: 5.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16638, Training Loss: 1.379e-01, Validation Loss: 5.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16639, Training Loss: 1.379e-01, Validation Loss: 5.743e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16640, Training Loss: 1.379e-01, Validation Loss: 5.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16641, Training Loss: 1.379e-01, Validation Loss: 5.743e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16642, Training Loss: 1.379e-01, Validation Loss: 5.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16643, Training Loss: 1.378e-01, Validation Loss: 5.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16644, Training Loss: 1.378e-01, Validation Loss: 5.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16645, Training Loss: 1.378e-01, Validation Loss: 5.743e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16646, Training Loss: 1.378e-01, Validation Loss: 5.743e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16647, Training Loss: 1.378e-01, Validation Loss: 5.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16648, Training Loss: 1.378e-01, Validation Loss: 5.743e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16649, Training Loss: 1.378e-01, Validation Loss: 5.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16650, Training Loss: 1.378e-01, Validation Loss: 5.743e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16651, Training Loss: 1.378e-01, Validation Loss: 5.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16652, Training Loss: 1.377e-01, Validation Loss: 5.742e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16653, Training Loss: 1.377e-01, Validation Loss: 5.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16654, Training Loss: 1.377e-01, Validation Loss: 5.742e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16655, Training Loss: 1.377e-01, Validation Loss: 5.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16656, Training Loss: 1.377e-01, Validation Loss: 5.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16657, Training Loss: 1.377e-01, Validation Loss: 5.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16658, Training Loss: 1.377e-01, Validation Loss: 5.742e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16659, Training Loss: 1.377e-01, Validation Loss: 5.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16660, Training Loss: 1.376e-01, Validation Loss: 5.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16661, Training Loss: 1.376e-01, Validation Loss: 5.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16662, Training Loss: 1.376e-01, Validation Loss: 5.742e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16663, Training Loss: 1.376e-01, Validation Loss: 5.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16664, Training Loss: 1.376e-01, Validation Loss: 5.742e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16665, Training Loss: 1.376e-01, Validation Loss: 5.742e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16666, Training Loss: 1.376e-01, Validation Loss: 5.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16667, Training Loss: 1.376e-01, Validation Loss: 5.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16668, Training Loss: 1.376e-01, Validation Loss: 5.741e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16669, Training Loss: 1.375e-01, Validation Loss: 5.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16670, Training Loss: 1.375e-01, Validation Loss: 5.741e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16671, Training Loss: 1.375e-01, Validation Loss: 5.741e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16672, Training Loss: 1.375e-01, Validation Loss: 5.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16673, Training Loss: 1.375e-01, Validation Loss: 5.741e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16674, Training Loss: 1.375e-01, Validation Loss: 5.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16675, Training Loss: 1.375e-01, Validation Loss: 5.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16676, Training Loss: 1.375e-01, Validation Loss: 5.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16677, Training Loss: 1.374e-01, Validation Loss: 5.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16678, Training Loss: 1.374e-01, Validation Loss: 5.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16679, Training Loss: 1.374e-01, Validation Loss: 5.741e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16680, Training Loss: 1.374e-01, Validation Loss: 5.741e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16681, Training Loss: 1.374e-01, Validation Loss: 5.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16682, Training Loss: 1.374e-01, Validation Loss: 5.741e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16683, Training Loss: 1.374e-01, Validation Loss: 5.741e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16684, Training Loss: 1.374e-01, Validation Loss: 5.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16685, Training Loss: 1.374e-01, Validation Loss: 5.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16686, Training Loss: 1.373e-01, Validation Loss: 5.740e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16687, Training Loss: 1.373e-01, Validation Loss: 5.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16688, Training Loss: 1.373e-01, Validation Loss: 5.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16689, Training Loss: 1.373e-01, Validation Loss: 5.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16690, Training Loss: 1.373e-01, Validation Loss: 5.740e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16691, Training Loss: 1.373e-01, Validation Loss: 5.740e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16692, Training Loss: 1.373e-01, Validation Loss: 5.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16693, Training Loss: 1.373e-01, Validation Loss: 5.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16694, Training Loss: 1.372e-01, Validation Loss: 5.740e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16695, Training Loss: 1.372e-01, Validation Loss: 5.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16696, Training Loss: 1.372e-01, Validation Loss: 5.740e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16697, Training Loss: 1.372e-01, Validation Loss: 5.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16698, Training Loss: 1.372e-01, Validation Loss: 5.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16699, Training Loss: 1.372e-01, Validation Loss: 5.740e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16700, Training Loss: 1.372e-01, Validation Loss: 5.740e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16701, Training Loss: 1.372e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16702, Training Loss: 1.372e-01, Validation Loss: 5.740e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16703, Training Loss: 1.371e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16704, Training Loss: 1.371e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16705, Training Loss: 1.371e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16706, Training Loss: 1.371e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16707, Training Loss: 1.371e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16708, Training Loss: 1.371e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16709, Training Loss: 1.371e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16710, Training Loss: 1.371e-01, Validation Loss: 5.739e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16711, Training Loss: 1.370e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16712, Training Loss: 1.370e-01, Validation Loss: 5.739e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16713, Training Loss: 1.370e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16714, Training Loss: 1.370e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16715, Training Loss: 1.370e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16716, Training Loss: 1.370e-01, Validation Loss: 5.739e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16717, Training Loss: 1.370e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16718, Training Loss: 1.370e-01, Validation Loss: 5.739e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16719, Training Loss: 1.370e-01, Validation Loss: 5.739e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16720, Training Loss: 1.369e-01, Validation Loss: 5.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16721, Training Loss: 1.369e-01, Validation Loss: 5.738e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16722, Training Loss: 1.369e-01, Validation Loss: 5.738e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16723, Training Loss: 1.369e-01, Validation Loss: 5.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16724, Training Loss: 1.369e-01, Validation Loss: 5.738e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16725, Training Loss: 1.369e-01, Validation Loss: 5.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16726, Training Loss: 1.369e-01, Validation Loss: 5.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16727, Training Loss: 1.369e-01, Validation Loss: 5.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16728, Training Loss: 1.368e-01, Validation Loss: 5.738e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16729, Training Loss: 1.368e-01, Validation Loss: 5.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16730, Training Loss: 1.368e-01, Validation Loss: 5.738e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16731, Training Loss: 1.368e-01, Validation Loss: 5.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16732, Training Loss: 1.368e-01, Validation Loss: 5.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16733, Training Loss: 1.368e-01, Validation Loss: 5.738e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16734, Training Loss: 1.368e-01, Validation Loss: 5.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16735, Training Loss: 1.368e-01, Validation Loss: 5.738e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16736, Training Loss: 1.368e-01, Validation Loss: 5.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16737, Training Loss: 1.367e-01, Validation Loss: 5.738e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16738, Training Loss: 1.367e-01, Validation Loss: 5.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16739, Training Loss: 1.367e-01, Validation Loss: 5.737e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16740, Training Loss: 1.367e-01, Validation Loss: 5.737e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16741, Training Loss: 1.367e-01, Validation Loss: 5.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16742, Training Loss: 1.367e-01, Validation Loss: 5.737e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16743, Training Loss: 1.367e-01, Validation Loss: 5.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16744, Training Loss: 1.367e-01, Validation Loss: 5.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16745, Training Loss: 1.367e-01, Validation Loss: 5.737e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16746, Training Loss: 1.366e-01, Validation Loss: 5.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16747, Training Loss: 1.366e-01, Validation Loss: 5.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16748, Training Loss: 1.366e-01, Validation Loss: 5.737e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16749, Training Loss: 1.366e-01, Validation Loss: 5.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16750, Training Loss: 1.366e-01, Validation Loss: 5.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16751, Training Loss: 1.366e-01, Validation Loss: 5.737e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16752, Training Loss: 1.366e-01, Validation Loss: 5.737e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16753, Training Loss: 1.366e-01, Validation Loss: 5.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16754, Training Loss: 1.365e-01, Validation Loss: 5.737e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16755, Training Loss: 1.365e-01, Validation Loss: 5.737e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16756, Training Loss: 1.365e-01, Validation Loss: 5.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16757, Training Loss: 1.365e-01, Validation Loss: 5.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16758, Training Loss: 1.365e-01, Validation Loss: 5.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16759, Training Loss: 1.365e-01, Validation Loss: 5.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16760, Training Loss: 1.365e-01, Validation Loss: 5.736e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16761, Training Loss: 1.365e-01, Validation Loss: 5.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16762, Training Loss: 1.365e-01, Validation Loss: 5.736e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16763, Training Loss: 1.364e-01, Validation Loss: 5.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16764, Training Loss: 1.364e-01, Validation Loss: 5.736e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16765, Training Loss: 1.364e-01, Validation Loss: 5.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16766, Training Loss: 1.364e-01, Validation Loss: 5.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16767, Training Loss: 1.364e-01, Validation Loss: 5.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16768, Training Loss: 1.364e-01, Validation Loss: 5.736e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16769, Training Loss: 1.364e-01, Validation Loss: 5.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16770, Training Loss: 1.364e-01, Validation Loss: 5.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16771, Training Loss: 1.364e-01, Validation Loss: 5.736e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16772, Training Loss: 1.363e-01, Validation Loss: 5.736e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16773, Training Loss: 1.363e-01, Validation Loss: 5.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16774, Training Loss: 1.363e-01, Validation Loss: 5.736e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16775, Training Loss: 1.363e-01, Validation Loss: 5.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16776, Training Loss: 1.363e-01, Validation Loss: 5.735e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16777, Training Loss: 1.363e-01, Validation Loss: 5.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16778, Training Loss: 1.363e-01, Validation Loss: 5.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16779, Training Loss: 1.363e-01, Validation Loss: 5.735e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16780, Training Loss: 1.362e-01, Validation Loss: 5.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16781, Training Loss: 1.362e-01, Validation Loss: 5.735e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16782, Training Loss: 1.362e-01, Validation Loss: 5.735e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16783, Training Loss: 1.362e-01, Validation Loss: 5.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16784, Training Loss: 1.362e-01, Validation Loss: 5.735e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16785, Training Loss: 1.362e-01, Validation Loss: 5.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16786, Training Loss: 1.362e-01, Validation Loss: 5.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16787, Training Loss: 1.362e-01, Validation Loss: 5.735e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16788, Training Loss: 1.362e-01, Validation Loss: 5.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16789, Training Loss: 1.361e-01, Validation Loss: 5.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16790, Training Loss: 1.361e-01, Validation Loss: 5.735e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16791, Training Loss: 1.361e-01, Validation Loss: 5.735e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16792, Training Loss: 1.361e-01, Validation Loss: 5.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16793, Training Loss: 1.361e-01, Validation Loss: 5.734e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16794, Training Loss: 1.361e-01, Validation Loss: 5.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16795, Training Loss: 1.361e-01, Validation Loss: 5.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16796, Training Loss: 1.361e-01, Validation Loss: 5.734e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16797, Training Loss: 1.360e-01, Validation Loss: 5.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16798, Training Loss: 1.360e-01, Validation Loss: 5.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16799, Training Loss: 1.360e-01, Validation Loss: 5.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16800, Training Loss: 1.360e-01, Validation Loss: 5.734e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16801, Training Loss: 1.360e-01, Validation Loss: 5.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16802, Training Loss: 1.360e-01, Validation Loss: 5.734e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16803, Training Loss: 1.360e-01, Validation Loss: 5.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16804, Training Loss: 1.360e-01, Validation Loss: 5.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16805, Training Loss: 1.360e-01, Validation Loss: 5.734e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16806, Training Loss: 1.359e-01, Validation Loss: 5.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16807, Training Loss: 1.359e-01, Validation Loss: 5.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16808, Training Loss: 1.359e-01, Validation Loss: 5.734e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16809, Training Loss: 1.359e-01, Validation Loss: 5.734e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16810, Training Loss: 1.359e-01, Validation Loss: 5.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16811, Training Loss: 1.359e-01, Validation Loss: 5.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16812, Training Loss: 1.359e-01, Validation Loss: 5.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16813, Training Loss: 1.359e-01, Validation Loss: 5.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16814, Training Loss: 1.359e-01, Validation Loss: 5.733e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16815, Training Loss: 1.358e-01, Validation Loss: 5.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16816, Training Loss: 1.358e-01, Validation Loss: 5.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16817, Training Loss: 1.358e-01, Validation Loss: 5.733e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16818, Training Loss: 1.358e-01, Validation Loss: 5.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16819, Training Loss: 1.358e-01, Validation Loss: 5.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16820, Training Loss: 1.358e-01, Validation Loss: 5.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16821, Training Loss: 1.358e-01, Validation Loss: 5.733e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16822, Training Loss: 1.358e-01, Validation Loss: 5.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16823, Training Loss: 1.358e-01, Validation Loss: 5.733e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16824, Training Loss: 1.357e-01, Validation Loss: 5.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16825, Training Loss: 1.357e-01, Validation Loss: 5.733e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16826, Training Loss: 1.357e-01, Validation Loss: 5.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16827, Training Loss: 1.357e-01, Validation Loss: 5.733e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16828, Training Loss: 1.357e-01, Validation Loss: 5.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16829, Training Loss: 1.357e-01, Validation Loss: 5.733e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16830, Training Loss: 1.357e-01, Validation Loss: 5.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16831, Training Loss: 1.357e-01, Validation Loss: 5.732e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16832, Training Loss: 1.356e-01, Validation Loss: 5.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16833, Training Loss: 1.356e-01, Validation Loss: 5.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16834, Training Loss: 1.356e-01, Validation Loss: 5.732e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16835, Training Loss: 1.356e-01, Validation Loss: 5.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16836, Training Loss: 1.356e-01, Validation Loss: 5.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16837, Training Loss: 1.356e-01, Validation Loss: 5.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16838, Training Loss: 1.356e-01, Validation Loss: 5.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16839, Training Loss: 1.356e-01, Validation Loss: 5.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16840, Training Loss: 1.356e-01, Validation Loss: 5.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16841, Training Loss: 1.355e-01, Validation Loss: 5.732e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16842, Training Loss: 1.355e-01, Validation Loss: 5.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16843, Training Loss: 1.355e-01, Validation Loss: 5.732e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16844, Training Loss: 1.355e-01, Validation Loss: 5.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16845, Training Loss: 1.355e-01, Validation Loss: 5.732e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16846, Training Loss: 1.355e-01, Validation Loss: 5.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16847, Training Loss: 1.355e-01, Validation Loss: 5.732e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16848, Training Loss: 1.355e-01, Validation Loss: 5.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16849, Training Loss: 1.355e-01, Validation Loss: 5.731e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16850, Training Loss: 1.354e-01, Validation Loss: 5.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16851, Training Loss: 1.354e-01, Validation Loss: 5.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16852, Training Loss: 1.354e-01, Validation Loss: 5.731e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16853, Training Loss: 1.354e-01, Validation Loss: 5.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16854, Training Loss: 1.354e-01, Validation Loss: 5.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16855, Training Loss: 1.354e-01, Validation Loss: 5.731e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16856, Training Loss: 1.354e-01, Validation Loss: 5.731e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16857, Training Loss: 1.354e-01, Validation Loss: 5.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16858, Training Loss: 1.353e-01, Validation Loss: 5.731e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16859, Training Loss: 1.353e-01, Validation Loss: 5.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16860, Training Loss: 1.353e-01, Validation Loss: 5.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16861, Training Loss: 1.353e-01, Validation Loss: 5.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16862, Training Loss: 1.353e-01, Validation Loss: 5.731e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16863, Training Loss: 1.353e-01, Validation Loss: 5.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16864, Training Loss: 1.353e-01, Validation Loss: 5.731e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16865, Training Loss: 1.353e-01, Validation Loss: 5.731e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16866, Training Loss: 1.353e-01, Validation Loss: 5.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16867, Training Loss: 1.352e-01, Validation Loss: 5.730e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16868, Training Loss: 1.352e-01, Validation Loss: 5.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16869, Training Loss: 1.352e-01, Validation Loss: 5.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16870, Training Loss: 1.352e-01, Validation Loss: 5.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16871, Training Loss: 1.352e-01, Validation Loss: 5.730e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16872, Training Loss: 1.352e-01, Validation Loss: 5.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16873, Training Loss: 1.352e-01, Validation Loss: 5.730e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16874, Training Loss: 1.352e-01, Validation Loss: 5.730e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16875, Training Loss: 1.352e-01, Validation Loss: 5.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16876, Training Loss: 1.351e-01, Validation Loss: 5.730e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16877, Training Loss: 1.351e-01, Validation Loss: 5.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16878, Training Loss: 1.351e-01, Validation Loss: 5.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16879, Training Loss: 1.351e-01, Validation Loss: 5.730e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16880, Training Loss: 1.351e-01, Validation Loss: 5.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16881, Training Loss: 1.351e-01, Validation Loss: 5.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16882, Training Loss: 1.351e-01, Validation Loss: 5.730e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16883, Training Loss: 1.351e-01, Validation Loss: 5.730e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16884, Training Loss: 1.351e-01, Validation Loss: 5.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16885, Training Loss: 1.350e-01, Validation Loss: 5.729e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16886, Training Loss: 1.350e-01, Validation Loss: 5.729e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16887, Training Loss: 1.350e-01, Validation Loss: 5.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16888, Training Loss: 1.350e-01, Validation Loss: 5.729e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16889, Training Loss: 1.350e-01, Validation Loss: 5.729e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16890, Training Loss: 1.350e-01, Validation Loss: 5.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16891, Training Loss: 1.350e-01, Validation Loss: 5.729e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16892, Training Loss: 1.350e-01, Validation Loss: 5.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16893, Training Loss: 1.349e-01, Validation Loss: 5.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16894, Training Loss: 1.349e-01, Validation Loss: 5.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16895, Training Loss: 1.349e-01, Validation Loss: 5.729e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16896, Training Loss: 1.349e-01, Validation Loss: 5.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16897, Training Loss: 1.349e-01, Validation Loss: 5.729e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16898, Training Loss: 1.349e-01, Validation Loss: 5.729e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16899, Training Loss: 1.349e-01, Validation Loss: 5.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16900, Training Loss: 1.349e-01, Validation Loss: 5.729e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16901, Training Loss: 1.349e-01, Validation Loss: 5.729e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16902, Training Loss: 1.348e-01, Validation Loss: 5.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16903, Training Loss: 1.348e-01, Validation Loss: 5.728e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16904, Training Loss: 1.348e-01, Validation Loss: 5.728e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16905, Training Loss: 1.348e-01, Validation Loss: 5.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16906, Training Loss: 1.348e-01, Validation Loss: 5.728e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16907, Training Loss: 1.348e-01, Validation Loss: 5.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16908, Training Loss: 1.348e-01, Validation Loss: 5.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16909, Training Loss: 1.348e-01, Validation Loss: 5.728e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16910, Training Loss: 1.348e-01, Validation Loss: 5.728e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16911, Training Loss: 1.347e-01, Validation Loss: 5.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16912, Training Loss: 1.347e-01, Validation Loss: 5.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16913, Training Loss: 1.347e-01, Validation Loss: 5.728e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16914, Training Loss: 1.347e-01, Validation Loss: 5.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16915, Training Loss: 1.347e-01, Validation Loss: 5.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16916, Training Loss: 1.347e-01, Validation Loss: 5.728e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16917, Training Loss: 1.347e-01, Validation Loss: 5.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16918, Training Loss: 1.347e-01, Validation Loss: 5.728e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16919, Training Loss: 1.347e-01, Validation Loss: 5.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16920, Training Loss: 1.346e-01, Validation Loss: 5.728e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16921, Training Loss: 1.346e-01, Validation Loss: 5.728e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16922, Training Loss: 1.346e-01, Validation Loss: 5.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16923, Training Loss: 1.346e-01, Validation Loss: 5.727e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16924, Training Loss: 1.346e-01, Validation Loss: 5.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16925, Training Loss: 1.346e-01, Validation Loss: 5.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16926, Training Loss: 1.346e-01, Validation Loss: 5.727e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16927, Training Loss: 1.346e-01, Validation Loss: 5.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16928, Training Loss: 1.346e-01, Validation Loss: 5.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16929, Training Loss: 1.345e-01, Validation Loss: 5.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16930, Training Loss: 1.345e-01, Validation Loss: 5.727e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16931, Training Loss: 1.345e-01, Validation Loss: 5.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16932, Training Loss: 1.345e-01, Validation Loss: 5.727e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16933, Training Loss: 1.345e-01, Validation Loss: 5.727e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16934, Training Loss: 1.345e-01, Validation Loss: 5.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16935, Training Loss: 1.345e-01, Validation Loss: 5.727e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16936, Training Loss: 1.345e-01, Validation Loss: 5.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16937, Training Loss: 1.344e-01, Validation Loss: 5.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16938, Training Loss: 1.344e-01, Validation Loss: 5.727e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16939, Training Loss: 1.344e-01, Validation Loss: 5.727e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16940, Training Loss: 1.344e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16941, Training Loss: 1.344e-01, Validation Loss: 5.726e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16942, Training Loss: 1.344e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16943, Training Loss: 1.344e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16944, Training Loss: 1.344e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16945, Training Loss: 1.344e-01, Validation Loss: 5.726e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16946, Training Loss: 1.343e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16947, Training Loss: 1.343e-01, Validation Loss: 5.726e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16948, Training Loss: 1.343e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16949, Training Loss: 1.343e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16950, Training Loss: 1.343e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16951, Training Loss: 1.343e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16952, Training Loss: 1.343e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16953, Training Loss: 1.343e-01, Validation Loss: 5.726e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16954, Training Loss: 1.343e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16955, Training Loss: 1.342e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16956, Training Loss: 1.342e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16957, Training Loss: 1.342e-01, Validation Loss: 5.726e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16958, Training Loss: 1.342e-01, Validation Loss: 5.726e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16959, Training Loss: 1.342e-01, Validation Loss: 5.726e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16960, Training Loss: 1.342e-01, Validation Loss: 5.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16961, Training Loss: 1.342e-01, Validation Loss: 5.725e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16962, Training Loss: 1.342e-01, Validation Loss: 5.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16963, Training Loss: 1.342e-01, Validation Loss: 5.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16964, Training Loss: 1.341e-01, Validation Loss: 5.725e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16965, Training Loss: 1.341e-01, Validation Loss: 5.725e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16966, Training Loss: 1.341e-01, Validation Loss: 5.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16967, Training Loss: 1.341e-01, Validation Loss: 5.725e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16968, Training Loss: 1.341e-01, Validation Loss: 5.725e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 16969, Training Loss: 1.341e-01, Validation Loss: 5.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16970, Training Loss: 1.341e-01, Validation Loss: 5.725e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16971, Training Loss: 1.341e-01, Validation Loss: 5.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16972, Training Loss: 1.341e-01, Validation Loss: 5.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16973, Training Loss: 1.340e-01, Validation Loss: 5.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16974, Training Loss: 1.340e-01, Validation Loss: 5.725e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16975, Training Loss: 1.340e-01, Validation Loss: 5.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16976, Training Loss: 1.340e-01, Validation Loss: 5.725e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16977, Training Loss: 1.340e-01, Validation Loss: 5.725e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16978, Training Loss: 1.340e-01, Validation Loss: 5.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16979, Training Loss: 1.340e-01, Validation Loss: 5.724e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16980, Training Loss: 1.340e-01, Validation Loss: 5.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16981, Training Loss: 1.340e-01, Validation Loss: 5.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16982, Training Loss: 1.339e-01, Validation Loss: 5.724e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16983, Training Loss: 1.339e-01, Validation Loss: 5.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16984, Training Loss: 1.339e-01, Validation Loss: 5.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16985, Training Loss: 1.339e-01, Validation Loss: 5.724e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16986, Training Loss: 1.339e-01, Validation Loss: 5.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16987, Training Loss: 1.339e-01, Validation Loss: 5.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16988, Training Loss: 1.339e-01, Validation Loss: 5.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16989, Training Loss: 1.339e-01, Validation Loss: 5.724e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16990, Training Loss: 1.339e-01, Validation Loss: 5.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16991, Training Loss: 1.338e-01, Validation Loss: 5.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16992, Training Loss: 1.338e-01, Validation Loss: 5.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16993, Training Loss: 1.338e-01, Validation Loss: 5.724e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16994, Training Loss: 1.338e-01, Validation Loss: 5.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16995, Training Loss: 1.338e-01, Validation Loss: 5.724e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 16996, Training Loss: 1.338e-01, Validation Loss: 5.724e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16997, Training Loss: 1.338e-01, Validation Loss: 5.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16998, Training Loss: 1.338e-01, Validation Loss: 5.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 16999, Training Loss: 1.338e-01, Validation Loss: 5.724e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17000, Training Loss: 1.337e-01, Validation Loss: 5.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17001, Training Loss: 1.337e-01, Validation Loss: 5.723e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17002, Training Loss: 1.337e-01, Validation Loss: 5.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17003, Training Loss: 1.337e-01, Validation Loss: 5.723e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17004, Training Loss: 1.337e-01, Validation Loss: 5.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17005, Training Loss: 1.337e-01, Validation Loss: 5.723e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17006, Training Loss: 1.337e-01, Validation Loss: 5.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17007, Training Loss: 1.337e-01, Validation Loss: 5.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17008, Training Loss: 1.336e-01, Validation Loss: 5.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17009, Training Loss: 1.336e-01, Validation Loss: 5.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17010, Training Loss: 1.336e-01, Validation Loss: 5.723e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17011, Training Loss: 1.336e-01, Validation Loss: 5.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17012, Training Loss: 1.336e-01, Validation Loss: 5.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17013, Training Loss: 1.336e-01, Validation Loss: 5.723e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17014, Training Loss: 1.336e-01, Validation Loss: 5.723e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17015, Training Loss: 1.336e-01, Validation Loss: 5.723e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17016, Training Loss: 1.336e-01, Validation Loss: 5.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17017, Training Loss: 1.335e-01, Validation Loss: 5.723e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17018, Training Loss: 1.335e-01, Validation Loss: 5.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17019, Training Loss: 1.335e-01, Validation Loss: 5.722e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17020, Training Loss: 1.335e-01, Validation Loss: 5.722e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17021, Training Loss: 1.335e-01, Validation Loss: 5.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17022, Training Loss: 1.335e-01, Validation Loss: 5.722e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17023, Training Loss: 1.335e-01, Validation Loss: 5.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17024, Training Loss: 1.335e-01, Validation Loss: 5.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17025, Training Loss: 1.335e-01, Validation Loss: 5.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17026, Training Loss: 1.334e-01, Validation Loss: 5.722e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17027, Training Loss: 1.334e-01, Validation Loss: 5.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17028, Training Loss: 1.334e-01, Validation Loss: 5.722e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17029, Training Loss: 1.334e-01, Validation Loss: 5.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17030, Training Loss: 1.334e-01, Validation Loss: 5.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17031, Training Loss: 1.334e-01, Validation Loss: 5.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17032, Training Loss: 1.334e-01, Validation Loss: 5.722e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17033, Training Loss: 1.334e-01, Validation Loss: 5.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17034, Training Loss: 1.334e-01, Validation Loss: 5.722e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17035, Training Loss: 1.333e-01, Validation Loss: 5.722e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17036, Training Loss: 1.333e-01, Validation Loss: 5.722e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17037, Training Loss: 1.333e-01, Validation Loss: 5.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17038, Training Loss: 1.333e-01, Validation Loss: 5.721e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17039, Training Loss: 1.333e-01, Validation Loss: 5.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17040, Training Loss: 1.333e-01, Validation Loss: 5.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17041, Training Loss: 1.333e-01, Validation Loss: 5.721e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17042, Training Loss: 1.333e-01, Validation Loss: 5.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17043, Training Loss: 1.333e-01, Validation Loss: 5.721e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17044, Training Loss: 1.332e-01, Validation Loss: 5.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17045, Training Loss: 1.332e-01, Validation Loss: 5.721e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17046, Training Loss: 1.332e-01, Validation Loss: 5.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17047, Training Loss: 1.332e-01, Validation Loss: 5.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17048, Training Loss: 1.332e-01, Validation Loss: 5.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17049, Training Loss: 1.332e-01, Validation Loss: 5.721e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17050, Training Loss: 1.332e-01, Validation Loss: 5.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17051, Training Loss: 1.332e-01, Validation Loss: 5.721e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17052, Training Loss: 1.332e-01, Validation Loss: 5.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17053, Training Loss: 1.331e-01, Validation Loss: 5.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17054, Training Loss: 1.331e-01, Validation Loss: 5.721e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17055, Training Loss: 1.331e-01, Validation Loss: 5.721e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17056, Training Loss: 1.331e-01, Validation Loss: 5.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17057, Training Loss: 1.331e-01, Validation Loss: 5.720e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17058, Training Loss: 1.331e-01, Validation Loss: 5.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17059, Training Loss: 1.331e-01, Validation Loss: 5.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17060, Training Loss: 1.331e-01, Validation Loss: 5.720e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17061, Training Loss: 1.331e-01, Validation Loss: 5.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17062, Training Loss: 1.330e-01, Validation Loss: 5.720e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17063, Training Loss: 1.330e-01, Validation Loss: 5.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17064, Training Loss: 1.330e-01, Validation Loss: 5.720e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17065, Training Loss: 1.330e-01, Validation Loss: 5.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17066, Training Loss: 1.330e-01, Validation Loss: 5.720e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17067, Training Loss: 1.330e-01, Validation Loss: 5.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17068, Training Loss: 1.330e-01, Validation Loss: 5.720e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17069, Training Loss: 1.330e-01, Validation Loss: 5.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17070, Training Loss: 1.330e-01, Validation Loss: 5.720e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17071, Training Loss: 1.329e-01, Validation Loss: 5.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17072, Training Loss: 1.329e-01, Validation Loss: 5.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17073, Training Loss: 1.329e-01, Validation Loss: 5.720e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17074, Training Loss: 1.329e-01, Validation Loss: 5.720e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17075, Training Loss: 1.329e-01, Validation Loss: 5.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17076, Training Loss: 1.329e-01, Validation Loss: 5.719e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17077, Training Loss: 1.329e-01, Validation Loss: 5.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17078, Training Loss: 1.329e-01, Validation Loss: 5.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17079, Training Loss: 1.329e-01, Validation Loss: 5.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17080, Training Loss: 1.328e-01, Validation Loss: 5.719e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17081, Training Loss: 1.328e-01, Validation Loss: 5.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17082, Training Loss: 1.328e-01, Validation Loss: 5.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17083, Training Loss: 1.328e-01, Validation Loss: 5.719e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17084, Training Loss: 1.328e-01, Validation Loss: 5.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17085, Training Loss: 1.328e-01, Validation Loss: 5.719e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17086, Training Loss: 1.328e-01, Validation Loss: 5.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17087, Training Loss: 1.328e-01, Validation Loss: 5.719e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17088, Training Loss: 1.328e-01, Validation Loss: 5.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17089, Training Loss: 1.327e-01, Validation Loss: 5.719e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17090, Training Loss: 1.327e-01, Validation Loss: 5.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17091, Training Loss: 1.327e-01, Validation Loss: 5.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17092, Training Loss: 1.327e-01, Validation Loss: 5.719e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17093, Training Loss: 1.327e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17094, Training Loss: 1.327e-01, Validation Loss: 5.719e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17095, Training Loss: 1.327e-01, Validation Loss: 5.719e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17096, Training Loss: 1.327e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17097, Training Loss: 1.327e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17098, Training Loss: 1.326e-01, Validation Loss: 5.718e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17099, Training Loss: 1.326e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17100, Training Loss: 1.326e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17101, Training Loss: 1.326e-01, Validation Loss: 5.718e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17102, Training Loss: 1.326e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17103, Training Loss: 1.326e-01, Validation Loss: 5.718e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17104, Training Loss: 1.326e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17105, Training Loss: 1.326e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17106, Training Loss: 1.326e-01, Validation Loss: 5.718e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17107, Training Loss: 1.325e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17108, Training Loss: 1.325e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17109, Training Loss: 1.325e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17110, Training Loss: 1.325e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17111, Training Loss: 1.325e-01, Validation Loss: 5.718e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17112, Training Loss: 1.325e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17113, Training Loss: 1.325e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17114, Training Loss: 1.325e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17115, Training Loss: 1.325e-01, Validation Loss: 5.718e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17116, Training Loss: 1.324e-01, Validation Loss: 5.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17117, Training Loss: 1.324e-01, Validation Loss: 5.717e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17118, Training Loss: 1.324e-01, Validation Loss: 5.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17119, Training Loss: 1.324e-01, Validation Loss: 5.717e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17120, Training Loss: 1.324e-01, Validation Loss: 5.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17121, Training Loss: 1.324e-01, Validation Loss: 5.717e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17122, Training Loss: 1.324e-01, Validation Loss: 5.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17123, Training Loss: 1.324e-01, Validation Loss: 5.717e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17124, Training Loss: 1.324e-01, Validation Loss: 5.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17125, Training Loss: 1.323e-01, Validation Loss: 5.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17126, Training Loss: 1.323e-01, Validation Loss: 5.717e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17127, Training Loss: 1.323e-01, Validation Loss: 5.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17128, Training Loss: 1.323e-01, Validation Loss: 5.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17129, Training Loss: 1.323e-01, Validation Loss: 5.717e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17130, Training Loss: 1.323e-01, Validation Loss: 5.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17131, Training Loss: 1.323e-01, Validation Loss: 5.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17132, Training Loss: 1.323e-01, Validation Loss: 5.717e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17133, Training Loss: 1.323e-01, Validation Loss: 5.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17134, Training Loss: 1.322e-01, Validation Loss: 5.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17135, Training Loss: 1.322e-01, Validation Loss: 5.717e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17136, Training Loss: 1.322e-01, Validation Loss: 5.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17137, Training Loss: 1.322e-01, Validation Loss: 5.716e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17138, Training Loss: 1.322e-01, Validation Loss: 5.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17139, Training Loss: 1.322e-01, Validation Loss: 5.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17140, Training Loss: 1.322e-01, Validation Loss: 5.716e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17141, Training Loss: 1.322e-01, Validation Loss: 5.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17142, Training Loss: 1.322e-01, Validation Loss: 5.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17143, Training Loss: 1.321e-01, Validation Loss: 5.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17144, Training Loss: 1.321e-01, Validation Loss: 5.716e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17145, Training Loss: 1.321e-01, Validation Loss: 5.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17146, Training Loss: 1.321e-01, Validation Loss: 5.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17147, Training Loss: 1.321e-01, Validation Loss: 5.716e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17148, Training Loss: 1.321e-01, Validation Loss: 5.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17149, Training Loss: 1.321e-01, Validation Loss: 5.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17150, Training Loss: 1.321e-01, Validation Loss: 5.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17151, Training Loss: 1.321e-01, Validation Loss: 5.716e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17152, Training Loss: 1.320e-01, Validation Loss: 5.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17153, Training Loss: 1.320e-01, Validation Loss: 5.716e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17154, Training Loss: 1.320e-01, Validation Loss: 5.716e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17155, Training Loss: 1.320e-01, Validation Loss: 5.716e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17156, Training Loss: 1.320e-01, Validation Loss: 5.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17157, Training Loss: 1.320e-01, Validation Loss: 5.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17158, Training Loss: 1.320e-01, Validation Loss: 5.715e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17159, Training Loss: 1.320e-01, Validation Loss: 5.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17160, Training Loss: 1.320e-01, Validation Loss: 5.715e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17161, Training Loss: 1.319e-01, Validation Loss: 5.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17162, Training Loss: 1.319e-01, Validation Loss: 5.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17163, Training Loss: 1.319e-01, Validation Loss: 5.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17164, Training Loss: 1.319e-01, Validation Loss: 5.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17165, Training Loss: 1.319e-01, Validation Loss: 5.715e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17166, Training Loss: 1.319e-01, Validation Loss: 5.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17167, Training Loss: 1.319e-01, Validation Loss: 5.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17168, Training Loss: 1.319e-01, Validation Loss: 5.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17169, Training Loss: 1.319e-01, Validation Loss: 5.715e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17170, Training Loss: 1.318e-01, Validation Loss: 5.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17171, Training Loss: 1.318e-01, Validation Loss: 5.715e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17172, Training Loss: 1.318e-01, Validation Loss: 5.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17173, Training Loss: 1.318e-01, Validation Loss: 5.715e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17174, Training Loss: 1.318e-01, Validation Loss: 5.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17175, Training Loss: 1.318e-01, Validation Loss: 5.715e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17176, Training Loss: 1.318e-01, Validation Loss: 5.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17177, Training Loss: 1.318e-01, Validation Loss: 5.714e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17178, Training Loss: 1.318e-01, Validation Loss: 5.715e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17179, Training Loss: 1.318e-01, Validation Loss: 5.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17180, Training Loss: 1.317e-01, Validation Loss: 5.714e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17181, Training Loss: 1.317e-01, Validation Loss: 5.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17182, Training Loss: 1.317e-01, Validation Loss: 5.714e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17183, Training Loss: 1.317e-01, Validation Loss: 5.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17184, Training Loss: 1.317e-01, Validation Loss: 5.714e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17185, Training Loss: 1.317e-01, Validation Loss: 5.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17186, Training Loss: 1.317e-01, Validation Loss: 5.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17187, Training Loss: 1.317e-01, Validation Loss: 5.714e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17188, Training Loss: 1.317e-01, Validation Loss: 5.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17189, Training Loss: 1.316e-01, Validation Loss: 5.714e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17190, Training Loss: 1.316e-01, Validation Loss: 5.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17191, Training Loss: 1.316e-01, Validation Loss: 5.714e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17192, Training Loss: 1.316e-01, Validation Loss: 5.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17193, Training Loss: 1.316e-01, Validation Loss: 5.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17194, Training Loss: 1.316e-01, Validation Loss: 5.714e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17195, Training Loss: 1.316e-01, Validation Loss: 5.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17196, Training Loss: 1.316e-01, Validation Loss: 5.714e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17197, Training Loss: 1.316e-01, Validation Loss: 5.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17198, Training Loss: 1.315e-01, Validation Loss: 5.714e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17199, Training Loss: 1.315e-01, Validation Loss: 5.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17200, Training Loss: 1.315e-01, Validation Loss: 5.713e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17201, Training Loss: 1.315e-01, Validation Loss: 5.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17202, Training Loss: 1.315e-01, Validation Loss: 5.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17203, Training Loss: 1.315e-01, Validation Loss: 5.713e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17204, Training Loss: 1.315e-01, Validation Loss: 5.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17205, Training Loss: 1.315e-01, Validation Loss: 5.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17206, Training Loss: 1.315e-01, Validation Loss: 5.713e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17207, Training Loss: 1.314e-01, Validation Loss: 5.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17208, Training Loss: 1.314e-01, Validation Loss: 5.713e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17209, Training Loss: 1.314e-01, Validation Loss: 5.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17210, Training Loss: 1.314e-01, Validation Loss: 5.713e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17211, Training Loss: 1.314e-01, Validation Loss: 5.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17212, Training Loss: 1.314e-01, Validation Loss: 5.713e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17213, Training Loss: 1.314e-01, Validation Loss: 5.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17214, Training Loss: 1.314e-01, Validation Loss: 5.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17215, Training Loss: 1.314e-01, Validation Loss: 5.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17216, Training Loss: 1.313e-01, Validation Loss: 5.713e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17217, Training Loss: 1.313e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17218, Training Loss: 1.313e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17219, Training Loss: 1.313e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17220, Training Loss: 1.313e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17221, Training Loss: 1.313e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17222, Training Loss: 1.313e-01, Validation Loss: 5.712e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17223, Training Loss: 1.313e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17224, Training Loss: 1.313e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17225, Training Loss: 1.312e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17226, Training Loss: 1.312e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17227, Training Loss: 1.312e-01, Validation Loss: 5.712e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17228, Training Loss: 1.312e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17229, Training Loss: 1.312e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17230, Training Loss: 1.312e-01, Validation Loss: 5.712e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17231, Training Loss: 1.312e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17232, Training Loss: 1.312e-01, Validation Loss: 5.712e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17233, Training Loss: 1.312e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17234, Training Loss: 1.311e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17235, Training Loss: 1.311e-01, Validation Loss: 5.712e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17236, Training Loss: 1.311e-01, Validation Loss: 5.712e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17237, Training Loss: 1.311e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17238, Training Loss: 1.311e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17239, Training Loss: 1.311e-01, Validation Loss: 5.711e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17240, Training Loss: 1.311e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17241, Training Loss: 1.311e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17242, Training Loss: 1.311e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17243, Training Loss: 1.311e-01, Validation Loss: 5.711e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17244, Training Loss: 1.310e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17245, Training Loss: 1.310e-01, Validation Loss: 5.711e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17246, Training Loss: 1.310e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17247, Training Loss: 1.310e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17248, Training Loss: 1.310e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17249, Training Loss: 1.310e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17250, Training Loss: 1.310e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17251, Training Loss: 1.310e-01, Validation Loss: 5.711e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17252, Training Loss: 1.310e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17253, Training Loss: 1.309e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17254, Training Loss: 1.309e-01, Validation Loss: 5.711e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17255, Training Loss: 1.309e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17256, Training Loss: 1.309e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17257, Training Loss: 1.309e-01, Validation Loss: 5.711e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17258, Training Loss: 1.309e-01, Validation Loss: 5.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17259, Training Loss: 1.309e-01, Validation Loss: 5.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17260, Training Loss: 1.309e-01, Validation Loss: 5.710e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17261, Training Loss: 1.309e-01, Validation Loss: 5.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17262, Training Loss: 1.308e-01, Validation Loss: 5.710e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17263, Training Loss: 1.308e-01, Validation Loss: 5.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17264, Training Loss: 1.308e-01, Validation Loss: 5.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17265, Training Loss: 1.308e-01, Validation Loss: 5.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17266, Training Loss: 1.308e-01, Validation Loss: 5.710e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17267, Training Loss: 1.308e-01, Validation Loss: 5.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17268, Training Loss: 1.308e-01, Validation Loss: 5.710e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17269, Training Loss: 1.308e-01, Validation Loss: 5.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17270, Training Loss: 1.308e-01, Validation Loss: 5.710e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17271, Training Loss: 1.307e-01, Validation Loss: 5.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17272, Training Loss: 1.307e-01, Validation Loss: 5.710e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17273, Training Loss: 1.307e-01, Validation Loss: 5.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17274, Training Loss: 1.307e-01, Validation Loss: 5.710e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17275, Training Loss: 1.307e-01, Validation Loss: 5.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17276, Training Loss: 1.307e-01, Validation Loss: 5.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17277, Training Loss: 1.307e-01, Validation Loss: 5.710e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17278, Training Loss: 1.307e-01, Validation Loss: 5.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17279, Training Loss: 1.307e-01, Validation Loss: 5.710e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17280, Training Loss: 1.306e-01, Validation Loss: 5.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17281, Training Loss: 1.306e-01, Validation Loss: 5.709e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17282, Training Loss: 1.306e-01, Validation Loss: 5.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17283, Training Loss: 1.306e-01, Validation Loss: 5.709e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17284, Training Loss: 1.306e-01, Validation Loss: 5.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17285, Training Loss: 1.306e-01, Validation Loss: 5.709e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17286, Training Loss: 1.306e-01, Validation Loss: 5.709e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17287, Training Loss: 1.306e-01, Validation Loss: 5.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17288, Training Loss: 1.306e-01, Validation Loss: 5.709e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17289, Training Loss: 1.306e-01, Validation Loss: 5.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17290, Training Loss: 1.305e-01, Validation Loss: 5.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17291, Training Loss: 1.305e-01, Validation Loss: 5.709e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17292, Training Loss: 1.305e-01, Validation Loss: 5.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17293, Training Loss: 1.305e-01, Validation Loss: 5.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17294, Training Loss: 1.305e-01, Validation Loss: 5.709e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17295, Training Loss: 1.305e-01, Validation Loss: 5.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17296, Training Loss: 1.305e-01, Validation Loss: 5.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17297, Training Loss: 1.305e-01, Validation Loss: 5.709e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17298, Training Loss: 1.305e-01, Validation Loss: 5.709e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17299, Training Loss: 1.304e-01, Validation Loss: 5.709e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17300, Training Loss: 1.304e-01, Validation Loss: 5.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17301, Training Loss: 1.304e-01, Validation Loss: 5.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17302, Training Loss: 1.304e-01, Validation Loss: 5.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17303, Training Loss: 1.304e-01, Validation Loss: 5.708e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17304, Training Loss: 1.304e-01, Validation Loss: 5.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17305, Training Loss: 1.304e-01, Validation Loss: 5.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17306, Training Loss: 1.304e-01, Validation Loss: 5.708e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17307, Training Loss: 1.304e-01, Validation Loss: 5.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17308, Training Loss: 1.303e-01, Validation Loss: 5.708e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17309, Training Loss: 1.303e-01, Validation Loss: 5.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17310, Training Loss: 1.303e-01, Validation Loss: 5.708e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17311, Training Loss: 1.303e-01, Validation Loss: 5.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17312, Training Loss: 1.303e-01, Validation Loss: 5.708e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17313, Training Loss: 1.303e-01, Validation Loss: 5.708e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17314, Training Loss: 1.303e-01, Validation Loss: 5.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17315, Training Loss: 1.303e-01, Validation Loss: 5.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17316, Training Loss: 1.303e-01, Validation Loss: 5.708e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17317, Training Loss: 1.302e-01, Validation Loss: 5.708e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17318, Training Loss: 1.302e-01, Validation Loss: 5.708e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17319, Training Loss: 1.302e-01, Validation Loss: 5.708e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17320, Training Loss: 1.302e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17321, Training Loss: 1.302e-01, Validation Loss: 5.708e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17322, Training Loss: 1.302e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17323, Training Loss: 1.302e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17324, Training Loss: 1.302e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17325, Training Loss: 1.302e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17326, Training Loss: 1.302e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17327, Training Loss: 1.301e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17328, Training Loss: 1.301e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17329, Training Loss: 1.301e-01, Validation Loss: 5.707e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17330, Training Loss: 1.301e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17331, Training Loss: 1.301e-01, Validation Loss: 5.707e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17332, Training Loss: 1.301e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17333, Training Loss: 1.301e-01, Validation Loss: 5.707e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17334, Training Loss: 1.301e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17335, Training Loss: 1.301e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17336, Training Loss: 1.300e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17337, Training Loss: 1.300e-01, Validation Loss: 5.707e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17338, Training Loss: 1.300e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17339, Training Loss: 1.300e-01, Validation Loss: 5.707e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17340, Training Loss: 1.300e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17341, Training Loss: 1.300e-01, Validation Loss: 5.707e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17342, Training Loss: 1.300e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17343, Training Loss: 1.300e-01, Validation Loss: 5.706e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17344, Training Loss: 1.300e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17345, Training Loss: 1.299e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17346, Training Loss: 1.299e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17347, Training Loss: 1.299e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17348, Training Loss: 1.299e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17349, Training Loss: 1.299e-01, Validation Loss: 5.706e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17350, Training Loss: 1.299e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17351, Training Loss: 1.299e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17352, Training Loss: 1.299e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17353, Training Loss: 1.299e-01, Validation Loss: 5.706e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17354, Training Loss: 1.298e-01, Validation Loss: 5.706e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17355, Training Loss: 1.298e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17356, Training Loss: 1.298e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17357, Training Loss: 1.298e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17358, Training Loss: 1.298e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17359, Training Loss: 1.298e-01, Validation Loss: 5.706e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17360, Training Loss: 1.298e-01, Validation Loss: 5.706e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17361, Training Loss: 1.298e-01, Validation Loss: 5.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17362, Training Loss: 1.298e-01, Validation Loss: 5.706e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17363, Training Loss: 1.298e-01, Validation Loss: 5.706e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17364, Training Loss: 1.297e-01, Validation Loss: 5.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17365, Training Loss: 1.297e-01, Validation Loss: 5.705e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17366, Training Loss: 1.297e-01, Validation Loss: 5.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17367, Training Loss: 1.297e-01, Validation Loss: 5.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17368, Training Loss: 1.297e-01, Validation Loss: 5.705e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17369, Training Loss: 1.297e-01, Validation Loss: 5.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17370, Training Loss: 1.297e-01, Validation Loss: 5.705e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17371, Training Loss: 1.297e-01, Validation Loss: 5.705e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17372, Training Loss: 1.297e-01, Validation Loss: 5.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17373, Training Loss: 1.296e-01, Validation Loss: 5.705e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17374, Training Loss: 1.296e-01, Validation Loss: 5.705e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17375, Training Loss: 1.296e-01, Validation Loss: 5.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17376, Training Loss: 1.296e-01, Validation Loss: 5.705e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17377, Training Loss: 1.296e-01, Validation Loss: 5.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17378, Training Loss: 1.296e-01, Validation Loss: 5.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17379, Training Loss: 1.296e-01, Validation Loss: 5.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17380, Training Loss: 1.296e-01, Validation Loss: 5.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17381, Training Loss: 1.296e-01, Validation Loss: 5.705e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17382, Training Loss: 1.295e-01, Validation Loss: 5.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17383, Training Loss: 1.295e-01, Validation Loss: 5.705e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17384, Training Loss: 1.295e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17385, Training Loss: 1.295e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17386, Training Loss: 1.295e-01, Validation Loss: 5.704e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17387, Training Loss: 1.295e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17388, Training Loss: 1.295e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17389, Training Loss: 1.295e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17390, Training Loss: 1.295e-01, Validation Loss: 5.704e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17391, Training Loss: 1.295e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17392, Training Loss: 1.294e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17393, Training Loss: 1.294e-01, Validation Loss: 5.704e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17394, Training Loss: 1.294e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17395, Training Loss: 1.294e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17396, Training Loss: 1.294e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17397, Training Loss: 1.294e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17398, Training Loss: 1.294e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17399, Training Loss: 1.294e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17400, Training Loss: 1.294e-01, Validation Loss: 5.704e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17401, Training Loss: 1.293e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17402, Training Loss: 1.293e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17403, Training Loss: 1.293e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17404, Training Loss: 1.293e-01, Validation Loss: 5.704e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17405, Training Loss: 1.293e-01, Validation Loss: 5.704e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17406, Training Loss: 1.293e-01, Validation Loss: 5.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17407, Training Loss: 1.293e-01, Validation Loss: 5.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17408, Training Loss: 1.293e-01, Validation Loss: 5.703e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17409, Training Loss: 1.293e-01, Validation Loss: 5.703e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17410, Training Loss: 1.293e-01, Validation Loss: 5.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17411, Training Loss: 1.292e-01, Validation Loss: 5.703e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17412, Training Loss: 1.292e-01, Validation Loss: 5.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17413, Training Loss: 1.292e-01, Validation Loss: 5.703e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17414, Training Loss: 1.292e-01, Validation Loss: 5.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17415, Training Loss: 1.292e-01, Validation Loss: 5.703e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17416, Training Loss: 1.292e-01, Validation Loss: 5.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17417, Training Loss: 1.292e-01, Validation Loss: 5.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17418, Training Loss: 1.292e-01, Validation Loss: 5.703e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17419, Training Loss: 1.292e-01, Validation Loss: 5.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17420, Training Loss: 1.291e-01, Validation Loss: 5.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17421, Training Loss: 1.291e-01, Validation Loss: 5.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17422, Training Loss: 1.291e-01, Validation Loss: 5.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17423, Training Loss: 1.291e-01, Validation Loss: 5.703e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17424, Training Loss: 1.291e-01, Validation Loss: 5.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17425, Training Loss: 1.291e-01, Validation Loss: 5.703e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17426, Training Loss: 1.291e-01, Validation Loss: 5.703e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17427, Training Loss: 1.291e-01, Validation Loss: 5.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17428, Training Loss: 1.291e-01, Validation Loss: 5.702e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17429, Training Loss: 1.290e-01, Validation Loss: 5.702e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17430, Training Loss: 1.290e-01, Validation Loss: 5.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17431, Training Loss: 1.290e-01, Validation Loss: 5.702e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17432, Training Loss: 1.290e-01, Validation Loss: 5.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17433, Training Loss: 1.290e-01, Validation Loss: 5.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17434, Training Loss: 1.290e-01, Validation Loss: 5.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17435, Training Loss: 1.290e-01, Validation Loss: 5.702e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17436, Training Loss: 1.290e-01, Validation Loss: 5.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17437, Training Loss: 1.290e-01, Validation Loss: 5.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17438, Training Loss: 1.290e-01, Validation Loss: 5.702e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17439, Training Loss: 1.289e-01, Validation Loss: 5.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17440, Training Loss: 1.289e-01, Validation Loss: 5.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17441, Training Loss: 1.289e-01, Validation Loss: 5.702e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17442, Training Loss: 1.289e-01, Validation Loss: 5.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17443, Training Loss: 1.289e-01, Validation Loss: 5.702e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17444, Training Loss: 1.289e-01, Validation Loss: 5.702e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17445, Training Loss: 1.289e-01, Validation Loss: 5.702e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17446, Training Loss: 1.289e-01, Validation Loss: 5.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17447, Training Loss: 1.289e-01, Validation Loss: 5.702e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17448, Training Loss: 1.288e-01, Validation Loss: 5.702e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17449, Training Loss: 1.288e-01, Validation Loss: 5.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17450, Training Loss: 1.288e-01, Validation Loss: 5.701e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17451, Training Loss: 1.288e-01, Validation Loss: 5.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17452, Training Loss: 1.288e-01, Validation Loss: 5.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17453, Training Loss: 1.288e-01, Validation Loss: 5.701e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17454, Training Loss: 1.288e-01, Validation Loss: 5.701e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17455, Training Loss: 1.288e-01, Validation Loss: 5.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17456, Training Loss: 1.288e-01, Validation Loss: 5.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17457, Training Loss: 1.288e-01, Validation Loss: 5.701e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17458, Training Loss: 1.287e-01, Validation Loss: 5.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17459, Training Loss: 1.287e-01, Validation Loss: 5.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17460, Training Loss: 1.287e-01, Validation Loss: 5.701e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17461, Training Loss: 1.287e-01, Validation Loss: 5.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17462, Training Loss: 1.287e-01, Validation Loss: 5.701e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17463, Training Loss: 1.287e-01, Validation Loss: 5.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17464, Training Loss: 1.287e-01, Validation Loss: 5.701e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17465, Training Loss: 1.287e-01, Validation Loss: 5.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17466, Training Loss: 1.287e-01, Validation Loss: 5.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17467, Training Loss: 1.286e-01, Validation Loss: 5.701e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17468, Training Loss: 1.286e-01, Validation Loss: 5.701e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17469, Training Loss: 1.286e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17470, Training Loss: 1.286e-01, Validation Loss: 5.701e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17471, Training Loss: 1.286e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17472, Training Loss: 1.286e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17473, Training Loss: 1.286e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17474, Training Loss: 1.286e-01, Validation Loss: 5.700e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17475, Training Loss: 1.286e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17476, Training Loss: 1.285e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17477, Training Loss: 1.285e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17478, Training Loss: 1.285e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17479, Training Loss: 1.285e-01, Validation Loss: 5.700e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17480, Training Loss: 1.285e-01, Validation Loss: 5.700e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17481, Training Loss: 1.285e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17482, Training Loss: 1.285e-01, Validation Loss: 5.700e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17483, Training Loss: 1.285e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17484, Training Loss: 1.285e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17485, Training Loss: 1.285e-01, Validation Loss: 5.700e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17486, Training Loss: 1.284e-01, Validation Loss: 5.700e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17487, Training Loss: 1.284e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17488, Training Loss: 1.284e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17489, Training Loss: 1.284e-01, Validation Loss: 5.700e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17490, Training Loss: 1.284e-01, Validation Loss: 5.700e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17491, Training Loss: 1.284e-01, Validation Loss: 5.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17492, Training Loss: 1.284e-01, Validation Loss: 5.699e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17493, Training Loss: 1.284e-01, Validation Loss: 5.699e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17494, Training Loss: 1.284e-01, Validation Loss: 5.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17495, Training Loss: 1.283e-01, Validation Loss: 5.699e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17496, Training Loss: 1.283e-01, Validation Loss: 5.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17497, Training Loss: 1.283e-01, Validation Loss: 5.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17498, Training Loss: 1.283e-01, Validation Loss: 5.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17499, Training Loss: 1.283e-01, Validation Loss: 5.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17500, Training Loss: 1.283e-01, Validation Loss: 5.699e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17501, Training Loss: 1.283e-01, Validation Loss: 5.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17502, Training Loss: 1.283e-01, Validation Loss: 5.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17503, Training Loss: 1.283e-01, Validation Loss: 5.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17504, Training Loss: 1.283e-01, Validation Loss: 5.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17505, Training Loss: 1.282e-01, Validation Loss: 5.699e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17506, Training Loss: 1.282e-01, Validation Loss: 5.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17507, Training Loss: 1.282e-01, Validation Loss: 5.699e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17508, Training Loss: 1.282e-01, Validation Loss: 5.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17509, Training Loss: 1.282e-01, Validation Loss: 5.699e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17510, Training Loss: 1.282e-01, Validation Loss: 5.699e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17511, Training Loss: 1.282e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17512, Training Loss: 1.282e-01, Validation Loss: 5.699e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17513, Training Loss: 1.282e-01, Validation Loss: 5.699e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17514, Training Loss: 1.281e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17515, Training Loss: 1.281e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17516, Training Loss: 1.281e-01, Validation Loss: 5.698e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17517, Training Loss: 1.281e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17518, Training Loss: 1.281e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17519, Training Loss: 1.281e-01, Validation Loss: 5.698e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17520, Training Loss: 1.281e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17521, Training Loss: 1.281e-01, Validation Loss: 5.698e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17522, Training Loss: 1.281e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17523, Training Loss: 1.281e-01, Validation Loss: 5.698e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17524, Training Loss: 1.280e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17525, Training Loss: 1.280e-01, Validation Loss: 5.698e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17526, Training Loss: 1.280e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17527, Training Loss: 1.280e-01, Validation Loss: 5.698e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17528, Training Loss: 1.280e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17529, Training Loss: 1.280e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17530, Training Loss: 1.280e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17531, Training Loss: 1.280e-01, Validation Loss: 5.698e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17532, Training Loss: 1.280e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17533, Training Loss: 1.279e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17534, Training Loss: 1.279e-01, Validation Loss: 5.698e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17535, Training Loss: 1.279e-01, Validation Loss: 5.698e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17536, Training Loss: 1.279e-01, Validation Loss: 5.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17537, Training Loss: 1.279e-01, Validation Loss: 5.697e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17538, Training Loss: 1.279e-01, Validation Loss: 5.697e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17539, Training Loss: 1.279e-01, Validation Loss: 5.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17540, Training Loss: 1.279e-01, Validation Loss: 5.697e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17541, Training Loss: 1.279e-01, Validation Loss: 5.697e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17542, Training Loss: 1.279e-01, Validation Loss: 5.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17543, Training Loss: 1.278e-01, Validation Loss: 5.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17544, Training Loss: 1.278e-01, Validation Loss: 5.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17545, Training Loss: 1.278e-01, Validation Loss: 5.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17546, Training Loss: 1.278e-01, Validation Loss: 5.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17547, Training Loss: 1.278e-01, Validation Loss: 5.697e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17548, Training Loss: 1.278e-01, Validation Loss: 5.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17549, Training Loss: 1.278e-01, Validation Loss: 5.697e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17550, Training Loss: 1.278e-01, Validation Loss: 5.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17551, Training Loss: 1.278e-01, Validation Loss: 5.697e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17552, Training Loss: 1.277e-01, Validation Loss: 5.697e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17553, Training Loss: 1.277e-01, Validation Loss: 5.697e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17554, Training Loss: 1.277e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17555, Training Loss: 1.277e-01, Validation Loss: 5.697e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17556, Training Loss: 1.277e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17557, Training Loss: 1.277e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17558, Training Loss: 1.277e-01, Validation Loss: 5.696e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17559, Training Loss: 1.277e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17560, Training Loss: 1.277e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17561, Training Loss: 1.277e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17562, Training Loss: 1.276e-01, Validation Loss: 5.696e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17563, Training Loss: 1.276e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17564, Training Loss: 1.276e-01, Validation Loss: 5.696e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17565, Training Loss: 1.276e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17566, Training Loss: 1.276e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17567, Training Loss: 1.276e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17568, Training Loss: 1.276e-01, Validation Loss: 5.696e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17569, Training Loss: 1.276e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17570, Training Loss: 1.276e-01, Validation Loss: 5.696e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17571, Training Loss: 1.276e-01, Validation Loss: 5.696e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17572, Training Loss: 1.275e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17573, Training Loss: 1.275e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17574, Training Loss: 1.275e-01, Validation Loss: 5.696e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17575, Training Loss: 1.275e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17576, Training Loss: 1.275e-01, Validation Loss: 5.696e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17577, Training Loss: 1.275e-01, Validation Loss: 5.696e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17578, Training Loss: 1.275e-01, Validation Loss: 5.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17579, Training Loss: 1.275e-01, Validation Loss: 5.695e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17580, Training Loss: 1.275e-01, Validation Loss: 5.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17581, Training Loss: 1.274e-01, Validation Loss: 5.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17582, Training Loss: 1.274e-01, Validation Loss: 5.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17583, Training Loss: 1.274e-01, Validation Loss: 5.695e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17584, Training Loss: 1.274e-01, Validation Loss: 5.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17585, Training Loss: 1.274e-01, Validation Loss: 5.695e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17586, Training Loss: 1.274e-01, Validation Loss: 5.695e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17587, Training Loss: 1.274e-01, Validation Loss: 5.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17588, Training Loss: 1.274e-01, Validation Loss: 5.695e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17589, Training Loss: 1.274e-01, Validation Loss: 5.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17590, Training Loss: 1.274e-01, Validation Loss: 5.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17591, Training Loss: 1.273e-01, Validation Loss: 5.695e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17592, Training Loss: 1.273e-01, Validation Loss: 5.695e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17593, Training Loss: 1.273e-01, Validation Loss: 5.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17594, Training Loss: 1.273e-01, Validation Loss: 5.695e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17595, Training Loss: 1.273e-01, Validation Loss: 5.695e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17596, Training Loss: 1.273e-01, Validation Loss: 5.695e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17597, Training Loss: 1.273e-01, Validation Loss: 5.695e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17598, Training Loss: 1.273e-01, Validation Loss: 5.695e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17599, Training Loss: 1.273e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17600, Training Loss: 1.272e-01, Validation Loss: 5.695e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17601, Training Loss: 1.272e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17602, Training Loss: 1.272e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17603, Training Loss: 1.272e-01, Validation Loss: 5.694e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17604, Training Loss: 1.272e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17605, Training Loss: 1.272e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17606, Training Loss: 1.272e-01, Validation Loss: 5.694e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17607, Training Loss: 1.272e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17608, Training Loss: 1.272e-01, Validation Loss: 5.694e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17609, Training Loss: 1.272e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17610, Training Loss: 1.271e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17611, Training Loss: 1.271e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17612, Training Loss: 1.271e-01, Validation Loss: 5.694e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17613, Training Loss: 1.271e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17614, Training Loss: 1.271e-01, Validation Loss: 5.694e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17615, Training Loss: 1.271e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17616, Training Loss: 1.271e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17617, Training Loss: 1.271e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17618, Training Loss: 1.271e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17619, Training Loss: 1.271e-01, Validation Loss: 5.694e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17620, Training Loss: 1.270e-01, Validation Loss: 5.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17621, Training Loss: 1.270e-01, Validation Loss: 5.694e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17622, Training Loss: 1.270e-01, Validation Loss: 5.694e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17623, Training Loss: 1.270e-01, Validation Loss: 5.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17624, Training Loss: 1.270e-01, Validation Loss: 5.693e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17625, Training Loss: 1.270e-01, Validation Loss: 5.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17626, Training Loss: 1.270e-01, Validation Loss: 5.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17627, Training Loss: 1.270e-01, Validation Loss: 5.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17628, Training Loss: 1.270e-01, Validation Loss: 5.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17629, Training Loss: 1.269e-01, Validation Loss: 5.693e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17630, Training Loss: 1.269e-01, Validation Loss: 5.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17631, Training Loss: 1.269e-01, Validation Loss: 5.693e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17632, Training Loss: 1.269e-01, Validation Loss: 5.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17633, Training Loss: 1.269e-01, Validation Loss: 5.693e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17634, Training Loss: 1.269e-01, Validation Loss: 5.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17635, Training Loss: 1.269e-01, Validation Loss: 5.693e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17636, Training Loss: 1.269e-01, Validation Loss: 5.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17637, Training Loss: 1.269e-01, Validation Loss: 5.693e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17638, Training Loss: 1.269e-01, Validation Loss: 5.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17639, Training Loss: 1.268e-01, Validation Loss: 5.693e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17640, Training Loss: 1.268e-01, Validation Loss: 5.693e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17641, Training Loss: 1.268e-01, Validation Loss: 5.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17642, Training Loss: 1.268e-01, Validation Loss: 5.693e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17643, Training Loss: 1.268e-01, Validation Loss: 5.693e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17644, Training Loss: 1.268e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17645, Training Loss: 1.268e-01, Validation Loss: 5.692e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17646, Training Loss: 1.268e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17647, Training Loss: 1.268e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17648, Training Loss: 1.268e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17649, Training Loss: 1.267e-01, Validation Loss: 5.692e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17650, Training Loss: 1.267e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17651, Training Loss: 1.267e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17652, Training Loss: 1.267e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17653, Training Loss: 1.267e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17654, Training Loss: 1.267e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17655, Training Loss: 1.267e-01, Validation Loss: 5.692e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17656, Training Loss: 1.267e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17657, Training Loss: 1.267e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17658, Training Loss: 1.266e-01, Validation Loss: 5.692e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17659, Training Loss: 1.266e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17660, Training Loss: 1.266e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17661, Training Loss: 1.266e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17662, Training Loss: 1.266e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17663, Training Loss: 1.266e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17664, Training Loss: 1.266e-01, Validation Loss: 5.692e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17665, Training Loss: 1.266e-01, Validation Loss: 5.692e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17666, Training Loss: 1.266e-01, Validation Loss: 5.692e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17667, Training Loss: 1.266e-01, Validation Loss: 5.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17668, Training Loss: 1.265e-01, Validation Loss: 5.691e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17669, Training Loss: 1.265e-01, Validation Loss: 5.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17670, Training Loss: 1.265e-01, Validation Loss: 5.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17671, Training Loss: 1.265e-01, Validation Loss: 5.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17672, Training Loss: 1.265e-01, Validation Loss: 5.691e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17673, Training Loss: 1.265e-01, Validation Loss: 5.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17674, Training Loss: 1.265e-01, Validation Loss: 5.691e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17675, Training Loss: 1.265e-01, Validation Loss: 5.691e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17676, Training Loss: 1.265e-01, Validation Loss: 5.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17677, Training Loss: 1.265e-01, Validation Loss: 5.691e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17678, Training Loss: 1.264e-01, Validation Loss: 5.691e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17679, Training Loss: 1.264e-01, Validation Loss: 5.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17680, Training Loss: 1.264e-01, Validation Loss: 5.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17681, Training Loss: 1.264e-01, Validation Loss: 5.691e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17682, Training Loss: 1.264e-01, Validation Loss: 5.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17683, Training Loss: 1.264e-01, Validation Loss: 5.691e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17684, Training Loss: 1.264e-01, Validation Loss: 5.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17685, Training Loss: 1.264e-01, Validation Loss: 5.691e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17686, Training Loss: 1.264e-01, Validation Loss: 5.691e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17687, Training Loss: 1.263e-01, Validation Loss: 5.691e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17688, Training Loss: 1.263e-01, Validation Loss: 5.691e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17689, Training Loss: 1.263e-01, Validation Loss: 5.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17690, Training Loss: 1.263e-01, Validation Loss: 5.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17691, Training Loss: 1.263e-01, Validation Loss: 5.690e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17692, Training Loss: 1.263e-01, Validation Loss: 5.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17693, Training Loss: 1.263e-01, Validation Loss: 5.690e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17694, Training Loss: 1.263e-01, Validation Loss: 5.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17695, Training Loss: 1.263e-01, Validation Loss: 5.690e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17696, Training Loss: 1.263e-01, Validation Loss: 5.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17697, Training Loss: 1.262e-01, Validation Loss: 5.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17698, Training Loss: 1.262e-01, Validation Loss: 5.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17699, Training Loss: 1.262e-01, Validation Loss: 5.690e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17700, Training Loss: 1.262e-01, Validation Loss: 5.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17701, Training Loss: 1.262e-01, Validation Loss: 5.690e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17702, Training Loss: 1.262e-01, Validation Loss: 5.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17703, Training Loss: 1.262e-01, Validation Loss: 5.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17704, Training Loss: 1.262e-01, Validation Loss: 5.690e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17705, Training Loss: 1.262e-01, Validation Loss: 5.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17706, Training Loss: 1.262e-01, Validation Loss: 5.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17707, Training Loss: 1.261e-01, Validation Loss: 5.690e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17708, Training Loss: 1.261e-01, Validation Loss: 5.690e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17709, Training Loss: 1.261e-01, Validation Loss: 5.690e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17710, Training Loss: 1.261e-01, Validation Loss: 5.690e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17711, Training Loss: 1.261e-01, Validation Loss: 5.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17712, Training Loss: 1.261e-01, Validation Loss: 5.690e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17713, Training Loss: 1.261e-01, Validation Loss: 5.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17714, Training Loss: 1.261e-01, Validation Loss: 5.689e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17715, Training Loss: 1.261e-01, Validation Loss: 5.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17716, Training Loss: 1.260e-01, Validation Loss: 5.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17717, Training Loss: 1.260e-01, Validation Loss: 5.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17718, Training Loss: 1.260e-01, Validation Loss: 5.689e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17719, Training Loss: 1.260e-01, Validation Loss: 5.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17720, Training Loss: 1.260e-01, Validation Loss: 5.689e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17721, Training Loss: 1.260e-01, Validation Loss: 5.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17722, Training Loss: 1.260e-01, Validation Loss: 5.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17723, Training Loss: 1.260e-01, Validation Loss: 5.689e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17724, Training Loss: 1.260e-01, Validation Loss: 5.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17725, Training Loss: 1.260e-01, Validation Loss: 5.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17726, Training Loss: 1.259e-01, Validation Loss: 5.689e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17727, Training Loss: 1.259e-01, Validation Loss: 5.689e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17728, Training Loss: 1.259e-01, Validation Loss: 5.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17729, Training Loss: 1.259e-01, Validation Loss: 5.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17730, Training Loss: 1.259e-01, Validation Loss: 5.689e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17731, Training Loss: 1.259e-01, Validation Loss: 5.689e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17732, Training Loss: 1.259e-01, Validation Loss: 5.689e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17733, Training Loss: 1.259e-01, Validation Loss: 5.689e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17734, Training Loss: 1.259e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17735, Training Loss: 1.259e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17736, Training Loss: 1.258e-01, Validation Loss: 5.688e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17737, Training Loss: 1.258e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17738, Training Loss: 1.258e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17739, Training Loss: 1.258e-01, Validation Loss: 5.688e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17740, Training Loss: 1.258e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17741, Training Loss: 1.258e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17742, Training Loss: 1.258e-01, Validation Loss: 5.688e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17743, Training Loss: 1.258e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17744, Training Loss: 1.258e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17745, Training Loss: 1.258e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17746, Training Loss: 1.257e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17747, Training Loss: 1.257e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17748, Training Loss: 1.257e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17749, Training Loss: 1.257e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17750, Training Loss: 1.257e-01, Validation Loss: 5.688e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17751, Training Loss: 1.257e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17752, Training Loss: 1.257e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17753, Training Loss: 1.257e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17754, Training Loss: 1.257e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17755, Training Loss: 1.257e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17756, Training Loss: 1.256e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17757, Training Loss: 1.256e-01, Validation Loss: 5.688e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17758, Training Loss: 1.256e-01, Validation Loss: 5.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17759, Training Loss: 1.256e-01, Validation Loss: 5.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17760, Training Loss: 1.256e-01, Validation Loss: 5.687e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17761, Training Loss: 1.256e-01, Validation Loss: 5.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17762, Training Loss: 1.256e-01, Validation Loss: 5.687e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17763, Training Loss: 1.256e-01, Validation Loss: 5.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17764, Training Loss: 1.256e-01, Validation Loss: 5.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17765, Training Loss: 1.255e-01, Validation Loss: 5.687e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17766, Training Loss: 1.255e-01, Validation Loss: 5.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17767, Training Loss: 1.255e-01, Validation Loss: 5.687e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17768, Training Loss: 1.255e-01, Validation Loss: 5.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17769, Training Loss: 1.255e-01, Validation Loss: 5.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17770, Training Loss: 1.255e-01, Validation Loss: 5.687e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17771, Training Loss: 1.255e-01, Validation Loss: 5.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17772, Training Loss: 1.255e-01, Validation Loss: 5.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17773, Training Loss: 1.255e-01, Validation Loss: 5.687e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17774, Training Loss: 1.255e-01, Validation Loss: 5.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17775, Training Loss: 1.254e-01, Validation Loss: 5.687e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17776, Training Loss: 1.254e-01, Validation Loss: 5.687e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17777, Training Loss: 1.254e-01, Validation Loss: 5.687e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17778, Training Loss: 1.254e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17779, Training Loss: 1.254e-01, Validation Loss: 5.686e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17780, Training Loss: 1.254e-01, Validation Loss: 5.687e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17781, Training Loss: 1.254e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17782, Training Loss: 1.254e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17783, Training Loss: 1.254e-01, Validation Loss: 5.686e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17784, Training Loss: 1.254e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17785, Training Loss: 1.253e-01, Validation Loss: 5.686e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17786, Training Loss: 1.253e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17787, Training Loss: 1.253e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17788, Training Loss: 1.253e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17789, Training Loss: 1.253e-01, Validation Loss: 5.686e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17790, Training Loss: 1.253e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17791, Training Loss: 1.253e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17792, Training Loss: 1.253e-01, Validation Loss: 5.686e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17793, Training Loss: 1.253e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17794, Training Loss: 1.253e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17795, Training Loss: 1.252e-01, Validation Loss: 5.686e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17796, Training Loss: 1.252e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17797, Training Loss: 1.252e-01, Validation Loss: 5.686e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17798, Training Loss: 1.252e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17799, Training Loss: 1.252e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17800, Training Loss: 1.252e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17801, Training Loss: 1.252e-01, Validation Loss: 5.686e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17802, Training Loss: 1.252e-01, Validation Loss: 5.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17803, Training Loss: 1.252e-01, Validation Loss: 5.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17804, Training Loss: 1.252e-01, Validation Loss: 5.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17805, Training Loss: 1.251e-01, Validation Loss: 5.685e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17806, Training Loss: 1.251e-01, Validation Loss: 5.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17807, Training Loss: 1.251e-01, Validation Loss: 5.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17808, Training Loss: 1.251e-01, Validation Loss: 5.685e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17809, Training Loss: 1.251e-01, Validation Loss: 5.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17810, Training Loss: 1.251e-01, Validation Loss: 5.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17811, Training Loss: 1.251e-01, Validation Loss: 5.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17812, Training Loss: 1.251e-01, Validation Loss: 5.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17813, Training Loss: 1.251e-01, Validation Loss: 5.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17814, Training Loss: 1.250e-01, Validation Loss: 5.685e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17815, Training Loss: 1.250e-01, Validation Loss: 5.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17816, Training Loss: 1.250e-01, Validation Loss: 5.685e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17817, Training Loss: 1.250e-01, Validation Loss: 5.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17818, Training Loss: 1.250e-01, Validation Loss: 5.685e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17819, Training Loss: 1.250e-01, Validation Loss: 5.685e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17820, Training Loss: 1.250e-01, Validation Loss: 5.685e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17821, Training Loss: 1.250e-01, Validation Loss: 5.685e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17822, Training Loss: 1.250e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17823, Training Loss: 1.250e-01, Validation Loss: 5.685e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17824, Training Loss: 1.249e-01, Validation Loss: 5.685e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17825, Training Loss: 1.249e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17826, Training Loss: 1.249e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17827, Training Loss: 1.249e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17828, Training Loss: 1.249e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17829, Training Loss: 1.249e-01, Validation Loss: 5.684e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17830, Training Loss: 1.249e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17831, Training Loss: 1.249e-01, Validation Loss: 5.684e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17832, Training Loss: 1.249e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17833, Training Loss: 1.249e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17834, Training Loss: 1.248e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17835, Training Loss: 1.248e-01, Validation Loss: 5.684e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17836, Training Loss: 1.248e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17837, Training Loss: 1.248e-01, Validation Loss: 5.684e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17838, Training Loss: 1.248e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17839, Training Loss: 1.248e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17840, Training Loss: 1.248e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17841, Training Loss: 1.248e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17842, Training Loss: 1.248e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17843, Training Loss: 1.248e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17844, Training Loss: 1.247e-01, Validation Loss: 5.684e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17845, Training Loss: 1.247e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17846, Training Loss: 1.247e-01, Validation Loss: 5.684e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17847, Training Loss: 1.247e-01, Validation Loss: 5.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17848, Training Loss: 1.247e-01, Validation Loss: 5.684e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17849, Training Loss: 1.247e-01, Validation Loss: 5.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17850, Training Loss: 1.247e-01, Validation Loss: 5.683e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17851, Training Loss: 1.247e-01, Validation Loss: 5.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17852, Training Loss: 1.247e-01, Validation Loss: 5.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17853, Training Loss: 1.247e-01, Validation Loss: 5.683e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17854, Training Loss: 1.246e-01, Validation Loss: 5.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17855, Training Loss: 1.246e-01, Validation Loss: 5.683e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17856, Training Loss: 1.246e-01, Validation Loss: 5.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17857, Training Loss: 1.246e-01, Validation Loss: 5.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17858, Training Loss: 1.246e-01, Validation Loss: 5.683e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17859, Training Loss: 1.246e-01, Validation Loss: 5.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17860, Training Loss: 1.246e-01, Validation Loss: 5.683e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17861, Training Loss: 1.246e-01, Validation Loss: 5.683e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17862, Training Loss: 1.246e-01, Validation Loss: 5.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17863, Training Loss: 1.246e-01, Validation Loss: 5.683e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17864, Training Loss: 1.245e-01, Validation Loss: 5.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17865, Training Loss: 1.245e-01, Validation Loss: 5.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17866, Training Loss: 1.245e-01, Validation Loss: 5.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17867, Training Loss: 1.245e-01, Validation Loss: 5.683e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17868, Training Loss: 1.245e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17869, Training Loss: 1.245e-01, Validation Loss: 5.683e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17870, Training Loss: 1.245e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17871, Training Loss: 1.245e-01, Validation Loss: 5.682e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17872, Training Loss: 1.245e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17873, Training Loss: 1.245e-01, Validation Loss: 5.682e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17874, Training Loss: 1.244e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17875, Training Loss: 1.244e-01, Validation Loss: 5.682e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17876, Training Loss: 1.244e-01, Validation Loss: 5.682e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17877, Training Loss: 1.244e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17878, Training Loss: 1.244e-01, Validation Loss: 5.682e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17879, Training Loss: 1.244e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17880, Training Loss: 1.244e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17881, Training Loss: 1.244e-01, Validation Loss: 5.682e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17882, Training Loss: 1.244e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17883, Training Loss: 1.244e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17884, Training Loss: 1.243e-01, Validation Loss: 5.682e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17885, Training Loss: 1.243e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17886, Training Loss: 1.243e-01, Validation Loss: 5.682e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17887, Training Loss: 1.243e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17888, Training Loss: 1.243e-01, Validation Loss: 5.682e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17889, Training Loss: 1.243e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17890, Training Loss: 1.243e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17891, Training Loss: 1.243e-01, Validation Loss: 5.682e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17892, Training Loss: 1.243e-01, Validation Loss: 5.682e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17893, Training Loss: 1.243e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17894, Training Loss: 1.242e-01, Validation Loss: 5.681e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17895, Training Loss: 1.242e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17896, Training Loss: 1.242e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17897, Training Loss: 1.242e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17898, Training Loss: 1.242e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17899, Training Loss: 1.242e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17900, Training Loss: 1.242e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17901, Training Loss: 1.242e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17902, Training Loss: 1.242e-01, Validation Loss: 5.681e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17903, Training Loss: 1.242e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17904, Training Loss: 1.241e-01, Validation Loss: 5.681e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17905, Training Loss: 1.241e-01, Validation Loss: 5.681e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17906, Training Loss: 1.241e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17907, Training Loss: 1.241e-01, Validation Loss: 5.681e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17908, Training Loss: 1.241e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17909, Training Loss: 1.241e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17910, Training Loss: 1.241e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17911, Training Loss: 1.241e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17912, Training Loss: 1.241e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17913, Training Loss: 1.241e-01, Validation Loss: 5.681e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17914, Training Loss: 1.240e-01, Validation Loss: 5.681e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17915, Training Loss: 1.240e-01, Validation Loss: 5.681e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17916, Training Loss: 1.240e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17917, Training Loss: 1.240e-01, Validation Loss: 5.680e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17918, Training Loss: 1.240e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17919, Training Loss: 1.240e-01, Validation Loss: 5.680e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17920, Training Loss: 1.240e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17921, Training Loss: 1.240e-01, Validation Loss: 5.680e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17922, Training Loss: 1.240e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17923, Training Loss: 1.240e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17924, Training Loss: 1.239e-01, Validation Loss: 5.680e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17925, Training Loss: 1.239e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17926, Training Loss: 1.239e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17927, Training Loss: 1.239e-01, Validation Loss: 5.680e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17928, Training Loss: 1.239e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17929, Training Loss: 1.239e-01, Validation Loss: 5.680e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17930, Training Loss: 1.239e-01, Validation Loss: 5.680e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17931, Training Loss: 1.239e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17932, Training Loss: 1.239e-01, Validation Loss: 5.680e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17933, Training Loss: 1.239e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17934, Training Loss: 1.238e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17935, Training Loss: 1.238e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17936, Training Loss: 1.238e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17937, Training Loss: 1.238e-01, Validation Loss: 5.680e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17938, Training Loss: 1.238e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17939, Training Loss: 1.238e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17940, Training Loss: 1.238e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17941, Training Loss: 1.238e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17942, Training Loss: 1.238e-01, Validation Loss: 5.679e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17943, Training Loss: 1.238e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17944, Training Loss: 1.237e-01, Validation Loss: 5.679e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17945, Training Loss: 1.237e-01, Validation Loss: 5.679e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17946, Training Loss: 1.237e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17947, Training Loss: 1.237e-01, Validation Loss: 5.679e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17948, Training Loss: 1.237e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17949, Training Loss: 1.237e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17950, Training Loss: 1.237e-01, Validation Loss: 5.679e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17951, Training Loss: 1.237e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17952, Training Loss: 1.237e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17953, Training Loss: 1.237e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17954, Training Loss: 1.236e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17955, Training Loss: 1.236e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17956, Training Loss: 1.236e-01, Validation Loss: 5.679e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17957, Training Loss: 1.236e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17958, Training Loss: 1.236e-01, Validation Loss: 5.679e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17959, Training Loss: 1.236e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17960, Training Loss: 1.236e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17961, Training Loss: 1.236e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17962, Training Loss: 1.236e-01, Validation Loss: 5.679e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17963, Training Loss: 1.236e-01, Validation Loss: 5.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17964, Training Loss: 1.235e-01, Validation Loss: 5.678e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17965, Training Loss: 1.235e-01, Validation Loss: 5.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17966, Training Loss: 1.235e-01, Validation Loss: 5.678e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17967, Training Loss: 1.235e-01, Validation Loss: 5.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17968, Training Loss: 1.235e-01, Validation Loss: 5.678e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17969, Training Loss: 1.235e-01, Validation Loss: 5.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17970, Training Loss: 1.235e-01, Validation Loss: 5.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17971, Training Loss: 1.235e-01, Validation Loss: 5.678e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17972, Training Loss: 1.235e-01, Validation Loss: 5.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17973, Training Loss: 1.235e-01, Validation Loss: 5.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17974, Training Loss: 1.234e-01, Validation Loss: 5.678e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17975, Training Loss: 1.234e-01, Validation Loss: 5.678e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17976, Training Loss: 1.234e-01, Validation Loss: 5.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17977, Training Loss: 1.234e-01, Validation Loss: 5.678e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17978, Training Loss: 1.234e-01, Validation Loss: 5.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17979, Training Loss: 1.234e-01, Validation Loss: 5.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17980, Training Loss: 1.234e-01, Validation Loss: 5.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17981, Training Loss: 1.234e-01, Validation Loss: 5.678e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17982, Training Loss: 1.234e-01, Validation Loss: 5.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17983, Training Loss: 1.234e-01, Validation Loss: 5.678e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17984, Training Loss: 1.233e-01, Validation Loss: 5.678e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17985, Training Loss: 1.233e-01, Validation Loss: 5.678e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 17986, Training Loss: 1.233e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17987, Training Loss: 1.233e-01, Validation Loss: 5.677e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17988, Training Loss: 1.233e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17989, Training Loss: 1.233e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17990, Training Loss: 1.233e-01, Validation Loss: 5.677e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17991, Training Loss: 1.233e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17992, Training Loss: 1.233e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17993, Training Loss: 1.233e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17994, Training Loss: 1.232e-01, Validation Loss: 5.677e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17995, Training Loss: 1.232e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17996, Training Loss: 1.232e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17997, Training Loss: 1.232e-01, Validation Loss: 5.677e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 17998, Training Loss: 1.232e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 17999, Training Loss: 1.232e-01, Validation Loss: 5.677e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18000, Training Loss: 1.232e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18001, Training Loss: 1.232e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18002, Training Loss: 1.232e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18003, Training Loss: 1.232e-01, Validation Loss: 5.677e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18004, Training Loss: 1.231e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18005, Training Loss: 1.231e-01, Validation Loss: 5.677e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18006, Training Loss: 1.231e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18007, Training Loss: 1.231e-01, Validation Loss: 5.677e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18008, Training Loss: 1.231e-01, Validation Loss: 5.677e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18009, Training Loss: 1.231e-01, Validation Loss: 5.677e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18010, Training Loss: 1.231e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18011, Training Loss: 1.231e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18012, Training Loss: 1.231e-01, Validation Loss: 5.676e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18013, Training Loss: 1.231e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18014, Training Loss: 1.230e-01, Validation Loss: 5.676e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18015, Training Loss: 1.230e-01, Validation Loss: 5.676e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18016, Training Loss: 1.230e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18017, Training Loss: 1.230e-01, Validation Loss: 5.676e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18018, Training Loss: 1.230e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18019, Training Loss: 1.230e-01, Validation Loss: 5.676e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18020, Training Loss: 1.230e-01, Validation Loss: 5.676e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18021, Training Loss: 1.230e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18022, Training Loss: 1.230e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18023, Training Loss: 1.230e-01, Validation Loss: 5.676e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18024, Training Loss: 1.229e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18025, Training Loss: 1.229e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18026, Training Loss: 1.229e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18027, Training Loss: 1.229e-01, Validation Loss: 5.676e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18028, Training Loss: 1.229e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18029, Training Loss: 1.229e-01, Validation Loss: 5.676e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18030, Training Loss: 1.229e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18031, Training Loss: 1.229e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18032, Training Loss: 1.229e-01, Validation Loss: 5.676e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18033, Training Loss: 1.229e-01, Validation Loss: 5.676e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18034, Training Loss: 1.228e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18035, Training Loss: 1.228e-01, Validation Loss: 5.675e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18036, Training Loss: 1.228e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18037, Training Loss: 1.228e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18038, Training Loss: 1.228e-01, Validation Loss: 5.675e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18039, Training Loss: 1.228e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18040, Training Loss: 1.228e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18041, Training Loss: 1.228e-01, Validation Loss: 5.675e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18042, Training Loss: 1.228e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18043, Training Loss: 1.228e-01, Validation Loss: 5.675e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18044, Training Loss: 1.228e-01, Validation Loss: 5.675e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18045, Training Loss: 1.227e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18046, Training Loss: 1.227e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18047, Training Loss: 1.227e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18048, Training Loss: 1.227e-01, Validation Loss: 5.675e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18049, Training Loss: 1.227e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18050, Training Loss: 1.227e-01, Validation Loss: 5.675e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18051, Training Loss: 1.227e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18052, Training Loss: 1.227e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18053, Training Loss: 1.227e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18054, Training Loss: 1.227e-01, Validation Loss: 5.675e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18055, Training Loss: 1.226e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18056, Training Loss: 1.226e-01, Validation Loss: 5.675e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18057, Training Loss: 1.226e-01, Validation Loss: 5.675e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18058, Training Loss: 1.226e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18059, Training Loss: 1.226e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18060, Training Loss: 1.226e-01, Validation Loss: 5.674e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18061, Training Loss: 1.226e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18062, Training Loss: 1.226e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18063, Training Loss: 1.226e-01, Validation Loss: 5.674e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18064, Training Loss: 1.226e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18065, Training Loss: 1.225e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18066, Training Loss: 1.225e-01, Validation Loss: 5.674e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18067, Training Loss: 1.225e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18068, Training Loss: 1.225e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18069, Training Loss: 1.225e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18070, Training Loss: 1.225e-01, Validation Loss: 5.674e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18071, Training Loss: 1.225e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18072, Training Loss: 1.225e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18073, Training Loss: 1.225e-01, Validation Loss: 5.674e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18074, Training Loss: 1.225e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18075, Training Loss: 1.224e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18076, Training Loss: 1.224e-01, Validation Loss: 5.674e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18077, Training Loss: 1.224e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18078, Training Loss: 1.224e-01, Validation Loss: 5.674e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18079, Training Loss: 1.224e-01, Validation Loss: 5.674e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18080, Training Loss: 1.224e-01, Validation Loss: 5.674e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18081, Training Loss: 1.224e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18082, Training Loss: 1.224e-01, Validation Loss: 5.674e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18083, Training Loss: 1.224e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18084, Training Loss: 1.224e-01, Validation Loss: 5.673e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18085, Training Loss: 1.223e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18086, Training Loss: 1.223e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18087, Training Loss: 1.223e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18088, Training Loss: 1.223e-01, Validation Loss: 5.673e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18089, Training Loss: 1.223e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18090, Training Loss: 1.223e-01, Validation Loss: 5.673e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18091, Training Loss: 1.223e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18092, Training Loss: 1.223e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18093, Training Loss: 1.223e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18094, Training Loss: 1.223e-01, Validation Loss: 5.673e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18095, Training Loss: 1.223e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18096, Training Loss: 1.222e-01, Validation Loss: 5.673e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18097, Training Loss: 1.222e-01, Validation Loss: 5.673e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18098, Training Loss: 1.222e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18099, Training Loss: 1.222e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18100, Training Loss: 1.222e-01, Validation Loss: 5.673e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18101, Training Loss: 1.222e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18102, Training Loss: 1.222e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18103, Training Loss: 1.222e-01, Validation Loss: 5.673e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18104, Training Loss: 1.222e-01, Validation Loss: 5.673e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18105, Training Loss: 1.222e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18106, Training Loss: 1.221e-01, Validation Loss: 5.673e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18107, Training Loss: 1.221e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18108, Training Loss: 1.221e-01, Validation Loss: 5.672e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18109, Training Loss: 1.221e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18110, Training Loss: 1.221e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18111, Training Loss: 1.221e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18112, Training Loss: 1.221e-01, Validation Loss: 5.672e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18113, Training Loss: 1.221e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18114, Training Loss: 1.221e-01, Validation Loss: 5.672e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18115, Training Loss: 1.221e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18116, Training Loss: 1.220e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18117, Training Loss: 1.220e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18118, Training Loss: 1.220e-01, Validation Loss: 5.672e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18119, Training Loss: 1.220e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18120, Training Loss: 1.220e-01, Validation Loss: 5.672e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18121, Training Loss: 1.220e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18122, Training Loss: 1.220e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18123, Training Loss: 1.220e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18124, Training Loss: 1.220e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18125, Training Loss: 1.220e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18126, Training Loss: 1.219e-01, Validation Loss: 5.672e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18127, Training Loss: 1.219e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18128, Training Loss: 1.219e-01, Validation Loss: 5.672e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18129, Training Loss: 1.219e-01, Validation Loss: 5.672e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18130, Training Loss: 1.219e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18131, Training Loss: 1.219e-01, Validation Loss: 5.671e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18132, Training Loss: 1.219e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18133, Training Loss: 1.219e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18134, Training Loss: 1.219e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18135, Training Loss: 1.219e-01, Validation Loss: 5.671e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18136, Training Loss: 1.219e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18137, Training Loss: 1.218e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18138, Training Loss: 1.218e-01, Validation Loss: 5.671e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18139, Training Loss: 1.218e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18140, Training Loss: 1.218e-01, Validation Loss: 5.671e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18141, Training Loss: 1.218e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18142, Training Loss: 1.218e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18143, Training Loss: 1.218e-01, Validation Loss: 5.671e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18144, Training Loss: 1.218e-01, Validation Loss: 5.671e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18145, Training Loss: 1.218e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18146, Training Loss: 1.218e-01, Validation Loss: 5.671e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18147, Training Loss: 1.217e-01, Validation Loss: 5.671e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18148, Training Loss: 1.217e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18149, Training Loss: 1.217e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18150, Training Loss: 1.217e-01, Validation Loss: 5.671e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18151, Training Loss: 1.217e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18152, Training Loss: 1.217e-01, Validation Loss: 5.671e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18153, Training Loss: 1.217e-01, Validation Loss: 5.671e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18154, Training Loss: 1.217e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18155, Training Loss: 1.217e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18156, Training Loss: 1.217e-01, Validation Loss: 5.670e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18157, Training Loss: 1.216e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18158, Training Loss: 1.216e-01, Validation Loss: 5.670e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18159, Training Loss: 1.216e-01, Validation Loss: 5.670e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18160, Training Loss: 1.216e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18161, Training Loss: 1.216e-01, Validation Loss: 5.670e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18162, Training Loss: 1.216e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18163, Training Loss: 1.216e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18164, Training Loss: 1.216e-01, Validation Loss: 5.670e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18165, Training Loss: 1.216e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18166, Training Loss: 1.216e-01, Validation Loss: 5.670e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18167, Training Loss: 1.215e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18168, Training Loss: 1.215e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18169, Training Loss: 1.215e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18170, Training Loss: 1.215e-01, Validation Loss: 5.670e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18171, Training Loss: 1.215e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18172, Training Loss: 1.215e-01, Validation Loss: 5.670e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18173, Training Loss: 1.215e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18174, Training Loss: 1.215e-01, Validation Loss: 5.670e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18175, Training Loss: 1.215e-01, Validation Loss: 5.670e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18176, Training Loss: 1.215e-01, Validation Loss: 5.670e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18177, Training Loss: 1.215e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18178, Training Loss: 1.214e-01, Validation Loss: 5.670e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18179, Training Loss: 1.214e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18180, Training Loss: 1.214e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18181, Training Loss: 1.214e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18182, Training Loss: 1.214e-01, Validation Loss: 5.669e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18183, Training Loss: 1.214e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18184, Training Loss: 1.214e-01, Validation Loss: 5.669e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18185, Training Loss: 1.214e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18186, Training Loss: 1.214e-01, Validation Loss: 5.669e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18187, Training Loss: 1.214e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18188, Training Loss: 1.213e-01, Validation Loss: 5.669e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18189, Training Loss: 1.213e-01, Validation Loss: 5.669e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18190, Training Loss: 1.213e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18191, Training Loss: 1.213e-01, Validation Loss: 5.669e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18192, Training Loss: 1.213e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18193, Training Loss: 1.213e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18194, Training Loss: 1.213e-01, Validation Loss: 5.669e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18195, Training Loss: 1.213e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18196, Training Loss: 1.213e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18197, Training Loss: 1.213e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18198, Training Loss: 1.212e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18199, Training Loss: 1.212e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18200, Training Loss: 1.212e-01, Validation Loss: 5.669e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18201, Training Loss: 1.212e-01, Validation Loss: 5.669e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18202, Training Loss: 1.212e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18203, Training Loss: 1.212e-01, Validation Loss: 5.668e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18204, Training Loss: 1.212e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18205, Training Loss: 1.212e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18206, Training Loss: 1.212e-01, Validation Loss: 5.668e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18207, Training Loss: 1.212e-01, Validation Loss: 5.668e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18208, Training Loss: 1.212e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18209, Training Loss: 1.211e-01, Validation Loss: 5.668e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18210, Training Loss: 1.211e-01, Validation Loss: 5.668e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18211, Training Loss: 1.211e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18212, Training Loss: 1.211e-01, Validation Loss: 5.668e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18213, Training Loss: 1.211e-01, Validation Loss: 5.668e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18214, Training Loss: 1.211e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18215, Training Loss: 1.211e-01, Validation Loss: 5.668e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18216, Training Loss: 1.211e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18217, Training Loss: 1.211e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18218, Training Loss: 1.211e-01, Validation Loss: 5.668e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18219, Training Loss: 1.210e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18220, Training Loss: 1.210e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18221, Training Loss: 1.210e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18222, Training Loss: 1.210e-01, Validation Loss: 5.668e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18223, Training Loss: 1.210e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18224, Training Loss: 1.210e-01, Validation Loss: 5.668e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18225, Training Loss: 1.210e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18226, Training Loss: 1.210e-01, Validation Loss: 5.668e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18227, Training Loss: 1.210e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18228, Training Loss: 1.210e-01, Validation Loss: 5.668e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18229, Training Loss: 1.209e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18230, Training Loss: 1.209e-01, Validation Loss: 5.667e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18231, Training Loss: 1.209e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18232, Training Loss: 1.209e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18233, Training Loss: 1.209e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18234, Training Loss: 1.209e-01, Validation Loss: 5.667e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18235, Training Loss: 1.209e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18236, Training Loss: 1.209e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18237, Training Loss: 1.209e-01, Validation Loss: 5.667e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18238, Training Loss: 1.209e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18239, Training Loss: 1.209e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18240, Training Loss: 1.208e-01, Validation Loss: 5.667e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18241, Training Loss: 1.208e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18242, Training Loss: 1.208e-01, Validation Loss: 5.667e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18243, Training Loss: 1.208e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18244, Training Loss: 1.208e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18245, Training Loss: 1.208e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18246, Training Loss: 1.208e-01, Validation Loss: 5.667e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18247, Training Loss: 1.208e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18248, Training Loss: 1.208e-01, Validation Loss: 5.667e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18249, Training Loss: 1.208e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18250, Training Loss: 1.207e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18251, Training Loss: 1.207e-01, Validation Loss: 5.667e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18252, Training Loss: 1.207e-01, Validation Loss: 5.667e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18253, Training Loss: 1.207e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18254, Training Loss: 1.207e-01, Validation Loss: 5.666e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18255, Training Loss: 1.207e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18256, Training Loss: 1.207e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18257, Training Loss: 1.207e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18258, Training Loss: 1.207e-01, Validation Loss: 5.666e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18259, Training Loss: 1.207e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18260, Training Loss: 1.207e-01, Validation Loss: 5.666e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18261, Training Loss: 1.206e-01, Validation Loss: 5.666e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18262, Training Loss: 1.206e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18263, Training Loss: 1.206e-01, Validation Loss: 5.666e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18264, Training Loss: 1.206e-01, Validation Loss: 5.666e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18265, Training Loss: 1.206e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18266, Training Loss: 1.206e-01, Validation Loss: 5.666e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18267, Training Loss: 1.206e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18268, Training Loss: 1.206e-01, Validation Loss: 5.666e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18269, Training Loss: 1.206e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18270, Training Loss: 1.206e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18271, Training Loss: 1.205e-01, Validation Loss: 5.666e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18272, Training Loss: 1.205e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18273, Training Loss: 1.205e-01, Validation Loss: 5.666e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18274, Training Loss: 1.205e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18275, Training Loss: 1.205e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18276, Training Loss: 1.205e-01, Validation Loss: 5.666e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18277, Training Loss: 1.205e-01, Validation Loss: 5.666e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18278, Training Loss: 1.205e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18279, Training Loss: 1.205e-01, Validation Loss: 5.666e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18280, Training Loss: 1.205e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18281, Training Loss: 1.205e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18282, Training Loss: 1.204e-01, Validation Loss: 5.665e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18283, Training Loss: 1.204e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18284, Training Loss: 1.204e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18285, Training Loss: 1.204e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18286, Training Loss: 1.204e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18287, Training Loss: 1.204e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18288, Training Loss: 1.204e-01, Validation Loss: 5.665e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18289, Training Loss: 1.204e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18290, Training Loss: 1.204e-01, Validation Loss: 5.665e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18291, Training Loss: 1.204e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18292, Training Loss: 1.203e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18293, Training Loss: 1.203e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18294, Training Loss: 1.203e-01, Validation Loss: 5.665e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18295, Training Loss: 1.203e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18296, Training Loss: 1.203e-01, Validation Loss: 5.665e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18297, Training Loss: 1.203e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18298, Training Loss: 1.203e-01, Validation Loss: 5.665e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18299, Training Loss: 1.203e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18300, Training Loss: 1.203e-01, Validation Loss: 5.665e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18301, Training Loss: 1.203e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18302, Training Loss: 1.203e-01, Validation Loss: 5.665e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18303, Training Loss: 1.202e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18304, Training Loss: 1.202e-01, Validation Loss: 5.665e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18305, Training Loss: 1.202e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18306, Training Loss: 1.202e-01, Validation Loss: 5.664e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18307, Training Loss: 1.202e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18308, Training Loss: 1.202e-01, Validation Loss: 5.664e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18309, Training Loss: 1.202e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18310, Training Loss: 1.202e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18311, Training Loss: 1.202e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18312, Training Loss: 1.202e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18313, Training Loss: 1.201e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18314, Training Loss: 1.201e-01, Validation Loss: 5.664e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18315, Training Loss: 1.201e-01, Validation Loss: 5.664e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18316, Training Loss: 1.201e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18317, Training Loss: 1.201e-01, Validation Loss: 5.664e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18318, Training Loss: 1.201e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18319, Training Loss: 1.201e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18320, Training Loss: 1.201e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18321, Training Loss: 1.201e-01, Validation Loss: 5.664e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18322, Training Loss: 1.201e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18323, Training Loss: 1.201e-01, Validation Loss: 5.664e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18324, Training Loss: 1.200e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18325, Training Loss: 1.200e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18326, Training Loss: 1.200e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18327, Training Loss: 1.200e-01, Validation Loss: 5.664e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18328, Training Loss: 1.200e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18329, Training Loss: 1.200e-01, Validation Loss: 5.664e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18330, Training Loss: 1.200e-01, Validation Loss: 5.664e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18331, Training Loss: 1.200e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18332, Training Loss: 1.200e-01, Validation Loss: 5.663e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18333, Training Loss: 1.200e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18334, Training Loss: 1.199e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18335, Training Loss: 1.199e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18336, Training Loss: 1.199e-01, Validation Loss: 5.663e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18337, Training Loss: 1.199e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18338, Training Loss: 1.199e-01, Validation Loss: 5.663e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18339, Training Loss: 1.199e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18340, Training Loss: 1.199e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18341, Training Loss: 1.199e-01, Validation Loss: 5.663e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18342, Training Loss: 1.199e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18343, Training Loss: 1.199e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18344, Training Loss: 1.199e-01, Validation Loss: 5.663e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18345, Training Loss: 1.198e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18346, Training Loss: 1.198e-01, Validation Loss: 5.663e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18347, Training Loss: 1.198e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18348, Training Loss: 1.198e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18349, Training Loss: 1.198e-01, Validation Loss: 5.663e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18350, Training Loss: 1.198e-01, Validation Loss: 5.663e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18351, Training Loss: 1.198e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18352, Training Loss: 1.198e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18353, Training Loss: 1.198e-01, Validation Loss: 5.663e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18354, Training Loss: 1.198e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18355, Training Loss: 1.197e-01, Validation Loss: 5.663e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18356, Training Loss: 1.197e-01, Validation Loss: 5.663e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18357, Training Loss: 1.197e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18358, Training Loss: 1.197e-01, Validation Loss: 5.662e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18359, Training Loss: 1.197e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18360, Training Loss: 1.197e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18361, Training Loss: 1.197e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18362, Training Loss: 1.197e-01, Validation Loss: 5.662e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18363, Training Loss: 1.197e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18364, Training Loss: 1.197e-01, Validation Loss: 5.662e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18365, Training Loss: 1.197e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18366, Training Loss: 1.196e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18367, Training Loss: 1.196e-01, Validation Loss: 5.662e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18368, Training Loss: 1.196e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18369, Training Loss: 1.196e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18370, Training Loss: 1.196e-01, Validation Loss: 5.662e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18371, Training Loss: 1.196e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18372, Training Loss: 1.196e-01, Validation Loss: 5.662e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18373, Training Loss: 1.196e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18374, Training Loss: 1.196e-01, Validation Loss: 5.662e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18375, Training Loss: 1.196e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18376, Training Loss: 1.195e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18377, Training Loss: 1.195e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18378, Training Loss: 1.195e-01, Validation Loss: 5.662e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18379, Training Loss: 1.195e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18380, Training Loss: 1.195e-01, Validation Loss: 5.662e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18381, Training Loss: 1.195e-01, Validation Loss: 5.662e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18382, Training Loss: 1.195e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18383, Training Loss: 1.195e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18384, Training Loss: 1.195e-01, Validation Loss: 5.661e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18385, Training Loss: 1.195e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18386, Training Loss: 1.195e-01, Validation Loss: 5.661e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18387, Training Loss: 1.194e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18388, Training Loss: 1.194e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18389, Training Loss: 1.194e-01, Validation Loss: 5.661e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18390, Training Loss: 1.194e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18391, Training Loss: 1.194e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18392, Training Loss: 1.194e-01, Validation Loss: 5.661e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18393, Training Loss: 1.194e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18394, Training Loss: 1.194e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18395, Training Loss: 1.194e-01, Validation Loss: 5.661e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18396, Training Loss: 1.194e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18397, Training Loss: 1.193e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18398, Training Loss: 1.193e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18399, Training Loss: 1.193e-01, Validation Loss: 5.661e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18400, Training Loss: 1.193e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18401, Training Loss: 1.193e-01, Validation Loss: 5.661e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18402, Training Loss: 1.193e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18403, Training Loss: 1.193e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18404, Training Loss: 1.193e-01, Validation Loss: 5.661e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18405, Training Loss: 1.193e-01, Validation Loss: 5.661e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18406, Training Loss: 1.193e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18407, Training Loss: 1.193e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18408, Training Loss: 1.192e-01, Validation Loss: 5.661e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18409, Training Loss: 1.192e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18410, Training Loss: 1.192e-01, Validation Loss: 5.660e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18411, Training Loss: 1.192e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18412, Training Loss: 1.192e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18413, Training Loss: 1.192e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18414, Training Loss: 1.192e-01, Validation Loss: 5.660e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18415, Training Loss: 1.192e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18416, Training Loss: 1.192e-01, Validation Loss: 5.660e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18417, Training Loss: 1.192e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18418, Training Loss: 1.192e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18419, Training Loss: 1.191e-01, Validation Loss: 5.660e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18420, Training Loss: 1.191e-01, Validation Loss: 5.660e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18421, Training Loss: 1.191e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18422, Training Loss: 1.191e-01, Validation Loss: 5.660e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18423, Training Loss: 1.191e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18424, Training Loss: 1.191e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18425, Training Loss: 1.191e-01, Validation Loss: 5.660e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18426, Training Loss: 1.191e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18427, Training Loss: 1.191e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18428, Training Loss: 1.191e-01, Validation Loss: 5.660e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18429, Training Loss: 1.190e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18430, Training Loss: 1.190e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18431, Training Loss: 1.190e-01, Validation Loss: 5.660e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18432, Training Loss: 1.190e-01, Validation Loss: 5.660e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18433, Training Loss: 1.190e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18434, Training Loss: 1.190e-01, Validation Loss: 5.660e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18435, Training Loss: 1.190e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18436, Training Loss: 1.190e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18437, Training Loss: 1.190e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18438, Training Loss: 1.190e-01, Validation Loss: 5.659e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18439, Training Loss: 1.190e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18440, Training Loss: 1.189e-01, Validation Loss: 5.659e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18441, Training Loss: 1.189e-01, Validation Loss: 5.659e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18442, Training Loss: 1.189e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18443, Training Loss: 1.189e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18444, Training Loss: 1.189e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18445, Training Loss: 1.189e-01, Validation Loss: 5.659e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18446, Training Loss: 1.189e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18447, Training Loss: 1.189e-01, Validation Loss: 5.659e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18448, Training Loss: 1.189e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18449, Training Loss: 1.189e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18450, Training Loss: 1.189e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18451, Training Loss: 1.188e-01, Validation Loss: 5.659e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18452, Training Loss: 1.188e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18453, Training Loss: 1.188e-01, Validation Loss: 5.659e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18454, Training Loss: 1.188e-01, Validation Loss: 5.659e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18455, Training Loss: 1.188e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18456, Training Loss: 1.188e-01, Validation Loss: 5.659e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18457, Training Loss: 1.188e-01, Validation Loss: 5.659e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18458, Training Loss: 1.188e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18459, Training Loss: 1.188e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18460, Training Loss: 1.188e-01, Validation Loss: 5.659e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18461, Training Loss: 1.187e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18462, Training Loss: 1.187e-01, Validation Loss: 5.658e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18463, Training Loss: 1.187e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18464, Training Loss: 1.187e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18465, Training Loss: 1.187e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18466, Training Loss: 1.187e-01, Validation Loss: 5.658e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18467, Training Loss: 1.187e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18468, Training Loss: 1.187e-01, Validation Loss: 5.658e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18469, Training Loss: 1.187e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18470, Training Loss: 1.187e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18471, Training Loss: 1.187e-01, Validation Loss: 5.658e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18472, Training Loss: 1.186e-01, Validation Loss: 5.658e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18473, Training Loss: 1.186e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18474, Training Loss: 1.186e-01, Validation Loss: 5.658e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18475, Training Loss: 1.186e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18476, Training Loss: 1.186e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18477, Training Loss: 1.186e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18478, Training Loss: 1.186e-01, Validation Loss: 5.658e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18479, Training Loss: 1.186e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18480, Training Loss: 1.186e-01, Validation Loss: 5.658e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18481, Training Loss: 1.186e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18482, Training Loss: 1.186e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18483, Training Loss: 1.185e-01, Validation Loss: 5.658e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18484, Training Loss: 1.185e-01, Validation Loss: 5.658e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18485, Training Loss: 1.185e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18486, Training Loss: 1.185e-01, Validation Loss: 5.658e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18487, Training Loss: 1.185e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18488, Training Loss: 1.185e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18489, Training Loss: 1.185e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18490, Training Loss: 1.185e-01, Validation Loss: 5.657e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18491, Training Loss: 1.185e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18492, Training Loss: 1.185e-01, Validation Loss: 5.657e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18493, Training Loss: 1.184e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18494, Training Loss: 1.184e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18495, Training Loss: 1.184e-01, Validation Loss: 5.657e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18496, Training Loss: 1.184e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18497, Training Loss: 1.184e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18498, Training Loss: 1.184e-01, Validation Loss: 5.657e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18499, Training Loss: 1.184e-01, Validation Loss: 5.657e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18500, Training Loss: 1.184e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18501, Training Loss: 1.184e-01, Validation Loss: 5.657e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18502, Training Loss: 1.184e-01, Validation Loss: 5.657e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18503, Training Loss: 1.184e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18504, Training Loss: 1.183e-01, Validation Loss: 5.657e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18505, Training Loss: 1.183e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18506, Training Loss: 1.183e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18507, Training Loss: 1.183e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18508, Training Loss: 1.183e-01, Validation Loss: 5.657e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18509, Training Loss: 1.183e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18510, Training Loss: 1.183e-01, Validation Loss: 5.657e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18511, Training Loss: 1.183e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18512, Training Loss: 1.183e-01, Validation Loss: 5.657e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18513, Training Loss: 1.183e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18514, Training Loss: 1.183e-01, Validation Loss: 5.656e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18515, Training Loss: 1.182e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18516, Training Loss: 1.182e-01, Validation Loss: 5.656e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18517, Training Loss: 1.182e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18518, Training Loss: 1.182e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18519, Training Loss: 1.182e-01, Validation Loss: 5.656e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18520, Training Loss: 1.182e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18521, Training Loss: 1.182e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18522, Training Loss: 1.182e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18523, Training Loss: 1.182e-01, Validation Loss: 5.656e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18524, Training Loss: 1.182e-01, Validation Loss: 5.656e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18525, Training Loss: 1.182e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18526, Training Loss: 1.181e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18527, Training Loss: 1.181e-01, Validation Loss: 5.656e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18528, Training Loss: 1.181e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18529, Training Loss: 1.181e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18530, Training Loss: 1.181e-01, Validation Loss: 5.656e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18531, Training Loss: 1.181e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18532, Training Loss: 1.181e-01, Validation Loss: 5.656e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18533, Training Loss: 1.181e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18534, Training Loss: 1.181e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18535, Training Loss: 1.181e-01, Validation Loss: 5.656e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18536, Training Loss: 1.180e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18537, Training Loss: 1.180e-01, Validation Loss: 5.656e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18538, Training Loss: 1.180e-01, Validation Loss: 5.656e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18539, Training Loss: 1.180e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18540, Training Loss: 1.180e-01, Validation Loss: 5.655e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18541, Training Loss: 1.180e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18542, Training Loss: 1.180e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18543, Training Loss: 1.180e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18544, Training Loss: 1.180e-01, Validation Loss: 5.655e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18545, Training Loss: 1.180e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18546, Training Loss: 1.180e-01, Validation Loss: 5.655e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18547, Training Loss: 1.179e-01, Validation Loss: 5.655e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18548, Training Loss: 1.179e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18549, Training Loss: 1.179e-01, Validation Loss: 5.655e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18550, Training Loss: 1.179e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18551, Training Loss: 1.179e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18552, Training Loss: 1.179e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18553, Training Loss: 1.179e-01, Validation Loss: 5.655e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18554, Training Loss: 1.179e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18555, Training Loss: 1.179e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18556, Training Loss: 1.179e-01, Validation Loss: 5.655e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18557, Training Loss: 1.179e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18558, Training Loss: 1.178e-01, Validation Loss: 5.655e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18559, Training Loss: 1.178e-01, Validation Loss: 5.655e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18560, Training Loss: 1.178e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18561, Training Loss: 1.178e-01, Validation Loss: 5.655e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18562, Training Loss: 1.178e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18563, Training Loss: 1.178e-01, Validation Loss: 5.655e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18564, Training Loss: 1.178e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18565, Training Loss: 1.178e-01, Validation Loss: 5.655e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18566, Training Loss: 1.178e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18567, Training Loss: 1.178e-01, Validation Loss: 5.654e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18568, Training Loss: 1.178e-01, Validation Loss: 5.654e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18569, Training Loss: 1.177e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18570, Training Loss: 1.177e-01, Validation Loss: 5.654e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18571, Training Loss: 1.177e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18572, Training Loss: 1.177e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18573, Training Loss: 1.177e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18574, Training Loss: 1.177e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18575, Training Loss: 1.177e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18576, Training Loss: 1.177e-01, Validation Loss: 5.654e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18577, Training Loss: 1.177e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18578, Training Loss: 1.177e-01, Validation Loss: 5.654e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18579, Training Loss: 1.177e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18580, Training Loss: 1.176e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18581, Training Loss: 1.176e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18582, Training Loss: 1.176e-01, Validation Loss: 5.654e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18583, Training Loss: 1.176e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18584, Training Loss: 1.176e-01, Validation Loss: 5.654e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18585, Training Loss: 1.176e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18586, Training Loss: 1.176e-01, Validation Loss: 5.654e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18587, Training Loss: 1.176e-01, Validation Loss: 5.654e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18588, Training Loss: 1.176e-01, Validation Loss: 5.654e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18589, Training Loss: 1.176e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18590, Training Loss: 1.176e-01, Validation Loss: 5.654e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18591, Training Loss: 1.175e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18592, Training Loss: 1.175e-01, Validation Loss: 5.654e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18593, Training Loss: 1.175e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18594, Training Loss: 1.175e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18595, Training Loss: 1.175e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18596, Training Loss: 1.175e-01, Validation Loss: 5.653e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18597, Training Loss: 1.175e-01, Validation Loss: 5.653e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18598, Training Loss: 1.175e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18599, Training Loss: 1.175e-01, Validation Loss: 5.653e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18600, Training Loss: 1.175e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18601, Training Loss: 1.174e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18602, Training Loss: 1.174e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18603, Training Loss: 1.174e-01, Validation Loss: 5.653e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18604, Training Loss: 1.174e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18605, Training Loss: 1.174e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18606, Training Loss: 1.174e-01, Validation Loss: 5.653e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18607, Training Loss: 1.174e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18608, Training Loss: 1.174e-01, Validation Loss: 5.653e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18609, Training Loss: 1.174e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18610, Training Loss: 1.174e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18611, Training Loss: 1.174e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18612, Training Loss: 1.173e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18613, Training Loss: 1.173e-01, Validation Loss: 5.653e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18614, Training Loss: 1.173e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18615, Training Loss: 1.173e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18616, Training Loss: 1.173e-01, Validation Loss: 5.653e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18617, Training Loss: 1.173e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18618, Training Loss: 1.173e-01, Validation Loss: 5.653e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18619, Training Loss: 1.173e-01, Validation Loss: 5.653e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18620, Training Loss: 1.173e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18621, Training Loss: 1.173e-01, Validation Loss: 5.652e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18622, Training Loss: 1.173e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18623, Training Loss: 1.172e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18624, Training Loss: 1.172e-01, Validation Loss: 5.652e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18625, Training Loss: 1.172e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18626, Training Loss: 1.172e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18627, Training Loss: 1.172e-01, Validation Loss: 5.652e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18628, Training Loss: 1.172e-01, Validation Loss: 5.652e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18629, Training Loss: 1.172e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18630, Training Loss: 1.172e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18631, Training Loss: 1.172e-01, Validation Loss: 5.652e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18632, Training Loss: 1.172e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18633, Training Loss: 1.172e-01, Validation Loss: 5.652e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18634, Training Loss: 1.171e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18635, Training Loss: 1.171e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18636, Training Loss: 1.171e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18637, Training Loss: 1.171e-01, Validation Loss: 5.652e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18638, Training Loss: 1.171e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18639, Training Loss: 1.171e-01, Validation Loss: 5.652e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18640, Training Loss: 1.171e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18641, Training Loss: 1.171e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18642, Training Loss: 1.171e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18643, Training Loss: 1.171e-01, Validation Loss: 5.652e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18644, Training Loss: 1.171e-01, Validation Loss: 5.652e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18645, Training Loss: 1.170e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18646, Training Loss: 1.170e-01, Validation Loss: 5.652e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18647, Training Loss: 1.170e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18648, Training Loss: 1.170e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18649, Training Loss: 1.170e-01, Validation Loss: 5.651e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18650, Training Loss: 1.170e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18651, Training Loss: 1.170e-01, Validation Loss: 5.651e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18652, Training Loss: 1.170e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18653, Training Loss: 1.170e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18654, Training Loss: 1.170e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18655, Training Loss: 1.170e-01, Validation Loss: 5.651e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18656, Training Loss: 1.169e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18657, Training Loss: 1.169e-01, Validation Loss: 5.651e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18658, Training Loss: 1.169e-01, Validation Loss: 5.651e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18659, Training Loss: 1.169e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18660, Training Loss: 1.169e-01, Validation Loss: 5.651e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18661, Training Loss: 1.169e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18662, Training Loss: 1.169e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18663, Training Loss: 1.169e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18664, Training Loss: 1.169e-01, Validation Loss: 5.651e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18665, Training Loss: 1.169e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18666, Training Loss: 1.169e-01, Validation Loss: 5.651e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18667, Training Loss: 1.168e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18668, Training Loss: 1.168e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18669, Training Loss: 1.168e-01, Validation Loss: 5.651e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18670, Training Loss: 1.168e-01, Validation Loss: 5.651e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18671, Training Loss: 1.168e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18672, Training Loss: 1.168e-01, Validation Loss: 5.651e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18673, Training Loss: 1.168e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18674, Training Loss: 1.168e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18675, Training Loss: 1.168e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18676, Training Loss: 1.168e-01, Validation Loss: 5.650e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18677, Training Loss: 1.168e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18678, Training Loss: 1.167e-01, Validation Loss: 5.650e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18679, Training Loss: 1.167e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18680, Training Loss: 1.167e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18681, Training Loss: 1.167e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18682, Training Loss: 1.167e-01, Validation Loss: 5.650e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18683, Training Loss: 1.167e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18684, Training Loss: 1.167e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18685, Training Loss: 1.167e-01, Validation Loss: 5.650e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18686, Training Loss: 1.167e-01, Validation Loss: 5.650e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18687, Training Loss: 1.167e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18688, Training Loss: 1.167e-01, Validation Loss: 5.650e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18689, Training Loss: 1.166e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18690, Training Loss: 1.166e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18691, Training Loss: 1.166e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18692, Training Loss: 1.166e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18693, Training Loss: 1.166e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18694, Training Loss: 1.166e-01, Validation Loss: 5.650e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18695, Training Loss: 1.166e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18696, Training Loss: 1.166e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18697, Training Loss: 1.166e-01, Validation Loss: 5.650e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18698, Training Loss: 1.166e-01, Validation Loss: 5.650e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18699, Training Loss: 1.166e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18700, Training Loss: 1.165e-01, Validation Loss: 5.650e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18701, Training Loss: 1.165e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18702, Training Loss: 1.165e-01, Validation Loss: 5.649e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18703, Training Loss: 1.165e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18704, Training Loss: 1.165e-01, Validation Loss: 5.649e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18705, Training Loss: 1.165e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18706, Training Loss: 1.165e-01, Validation Loss: 5.649e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18707, Training Loss: 1.165e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18708, Training Loss: 1.165e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18709, Training Loss: 1.165e-01, Validation Loss: 5.649e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18710, Training Loss: 1.165e-01, Validation Loss: 5.649e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18711, Training Loss: 1.164e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18712, Training Loss: 1.164e-01, Validation Loss: 5.649e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18713, Training Loss: 1.164e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18714, Training Loss: 1.164e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18715, Training Loss: 1.164e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18716, Training Loss: 1.164e-01, Validation Loss: 5.649e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18717, Training Loss: 1.164e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18718, Training Loss: 1.164e-01, Validation Loss: 5.649e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18719, Training Loss: 1.164e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18720, Training Loss: 1.164e-01, Validation Loss: 5.649e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18721, Training Loss: 1.164e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18722, Training Loss: 1.163e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18723, Training Loss: 1.163e-01, Validation Loss: 5.649e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18724, Training Loss: 1.163e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18725, Training Loss: 1.163e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18726, Training Loss: 1.163e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18727, Training Loss: 1.163e-01, Validation Loss: 5.649e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18728, Training Loss: 1.163e-01, Validation Loss: 5.649e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18729, Training Loss: 1.163e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18730, Training Loss: 1.163e-01, Validation Loss: 5.648e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18731, Training Loss: 1.163e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18732, Training Loss: 1.163e-01, Validation Loss: 5.648e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18733, Training Loss: 1.162e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18734, Training Loss: 1.162e-01, Validation Loss: 5.648e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18735, Training Loss: 1.162e-01, Validation Loss: 5.648e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18736, Training Loss: 1.162e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18737, Training Loss: 1.162e-01, Validation Loss: 5.648e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18738, Training Loss: 1.162e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18739, Training Loss: 1.162e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18740, Training Loss: 1.162e-01, Validation Loss: 5.648e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18741, Training Loss: 1.162e-01, Validation Loss: 5.648e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18742, Training Loss: 1.162e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18743, Training Loss: 1.162e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18744, Training Loss: 1.161e-01, Validation Loss: 5.648e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18745, Training Loss: 1.161e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18746, Training Loss: 1.161e-01, Validation Loss: 5.648e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18747, Training Loss: 1.161e-01, Validation Loss: 5.648e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18748, Training Loss: 1.161e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18749, Training Loss: 1.161e-01, Validation Loss: 5.648e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18750, Training Loss: 1.161e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18751, Training Loss: 1.161e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18752, Training Loss: 1.161e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18753, Training Loss: 1.161e-01, Validation Loss: 5.648e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18754, Training Loss: 1.161e-01, Validation Loss: 5.648e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18755, Training Loss: 1.160e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18756, Training Loss: 1.160e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18757, Training Loss: 1.160e-01, Validation Loss: 5.647e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18758, Training Loss: 1.160e-01, Validation Loss: 5.647e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18759, Training Loss: 1.160e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18760, Training Loss: 1.160e-01, Validation Loss: 5.647e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18761, Training Loss: 1.160e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18762, Training Loss: 1.160e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18763, Training Loss: 1.160e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18764, Training Loss: 1.160e-01, Validation Loss: 5.647e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18765, Training Loss: 1.160e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18766, Training Loss: 1.159e-01, Validation Loss: 5.647e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18767, Training Loss: 1.159e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18768, Training Loss: 1.159e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18769, Training Loss: 1.159e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18770, Training Loss: 1.159e-01, Validation Loss: 5.647e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18771, Training Loss: 1.159e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18772, Training Loss: 1.159e-01, Validation Loss: 5.647e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18773, Training Loss: 1.159e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18774, Training Loss: 1.159e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18775, Training Loss: 1.159e-01, Validation Loss: 5.647e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18776, Training Loss: 1.159e-01, Validation Loss: 5.647e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18777, Training Loss: 1.158e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18778, Training Loss: 1.158e-01, Validation Loss: 5.647e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18779, Training Loss: 1.158e-01, Validation Loss: 5.647e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18780, Training Loss: 1.158e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18781, Training Loss: 1.158e-01, Validation Loss: 5.647e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18782, Training Loss: 1.158e-01, Validation Loss: 5.647e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18783, Training Loss: 1.158e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18784, Training Loss: 1.158e-01, Validation Loss: 5.647e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18785, Training Loss: 1.158e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18786, Training Loss: 1.158e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18787, Training Loss: 1.158e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18788, Training Loss: 1.157e-01, Validation Loss: 5.646e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18789, Training Loss: 1.157e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18790, Training Loss: 1.157e-01, Validation Loss: 5.646e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18791, Training Loss: 1.157e-01, Validation Loss: 5.646e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18792, Training Loss: 1.157e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18793, Training Loss: 1.157e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18794, Training Loss: 1.157e-01, Validation Loss: 5.646e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18795, Training Loss: 1.157e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18796, Training Loss: 1.157e-01, Validation Loss: 5.646e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18797, Training Loss: 1.157e-01, Validation Loss: 5.646e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18798, Training Loss: 1.157e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18799, Training Loss: 1.156e-01, Validation Loss: 5.646e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18800, Training Loss: 1.156e-01, Validation Loss: 5.646e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18801, Training Loss: 1.156e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18802, Training Loss: 1.156e-01, Validation Loss: 5.646e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18803, Training Loss: 1.156e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18804, Training Loss: 1.156e-01, Validation Loss: 5.646e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18805, Training Loss: 1.156e-01, Validation Loss: 5.646e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18806, Training Loss: 1.156e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18807, Training Loss: 1.156e-01, Validation Loss: 5.646e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18808, Training Loss: 1.156e-01, Validation Loss: 5.646e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18809, Training Loss: 1.156e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18810, Training Loss: 1.155e-01, Validation Loss: 5.646e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18811, Training Loss: 1.155e-01, Validation Loss: 5.646e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18812, Training Loss: 1.155e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18813, Training Loss: 1.155e-01, Validation Loss: 5.645e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18814, Training Loss: 1.155e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18815, Training Loss: 1.155e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18816, Training Loss: 1.155e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18817, Training Loss: 1.155e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18818, Training Loss: 1.155e-01, Validation Loss: 5.645e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18819, Training Loss: 1.155e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18820, Training Loss: 1.155e-01, Validation Loss: 5.645e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18821, Training Loss: 1.155e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18822, Training Loss: 1.154e-01, Validation Loss: 5.645e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18823, Training Loss: 1.154e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18824, Training Loss: 1.154e-01, Validation Loss: 5.645e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18825, Training Loss: 1.154e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18826, Training Loss: 1.154e-01, Validation Loss: 5.645e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18827, Training Loss: 1.154e-01, Validation Loss: 5.645e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18828, Training Loss: 1.154e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18829, Training Loss: 1.154e-01, Validation Loss: 5.645e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18830, Training Loss: 1.154e-01, Validation Loss: 5.645e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18831, Training Loss: 1.154e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18832, Training Loss: 1.154e-01, Validation Loss: 5.645e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18833, Training Loss: 1.153e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18834, Training Loss: 1.153e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18835, Training Loss: 1.153e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18836, Training Loss: 1.153e-01, Validation Loss: 5.645e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18837, Training Loss: 1.153e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18838, Training Loss: 1.153e-01, Validation Loss: 5.645e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18839, Training Loss: 1.153e-01, Validation Loss: 5.645e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18840, Training Loss: 1.153e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18841, Training Loss: 1.153e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18842, Training Loss: 1.153e-01, Validation Loss: 5.644e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18843, Training Loss: 1.153e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18844, Training Loss: 1.152e-01, Validation Loss: 5.644e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18845, Training Loss: 1.152e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18846, Training Loss: 1.152e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18847, Training Loss: 1.152e-01, Validation Loss: 5.644e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18848, Training Loss: 1.152e-01, Validation Loss: 5.644e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18849, Training Loss: 1.152e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18850, Training Loss: 1.152e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18851, Training Loss: 1.152e-01, Validation Loss: 5.644e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18852, Training Loss: 1.152e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18853, Training Loss: 1.152e-01, Validation Loss: 5.644e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18854, Training Loss: 1.152e-01, Validation Loss: 5.644e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18855, Training Loss: 1.151e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18856, Training Loss: 1.151e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18857, Training Loss: 1.151e-01, Validation Loss: 5.644e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18858, Training Loss: 1.151e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18859, Training Loss: 1.151e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18860, Training Loss: 1.151e-01, Validation Loss: 5.644e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18861, Training Loss: 1.151e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18862, Training Loss: 1.151e-01, Validation Loss: 5.644e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18863, Training Loss: 1.151e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18864, Training Loss: 1.151e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18865, Training Loss: 1.151e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18866, Training Loss: 1.150e-01, Validation Loss: 5.644e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18867, Training Loss: 1.150e-01, Validation Loss: 5.644e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18868, Training Loss: 1.150e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18869, Training Loss: 1.150e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18870, Training Loss: 1.150e-01, Validation Loss: 5.643e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18871, Training Loss: 1.150e-01, Validation Loss: 5.643e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18872, Training Loss: 1.150e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18873, Training Loss: 1.150e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18874, Training Loss: 1.150e-01, Validation Loss: 5.643e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18875, Training Loss: 1.150e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18876, Training Loss: 1.150e-01, Validation Loss: 5.643e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18877, Training Loss: 1.150e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18878, Training Loss: 1.149e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18879, Training Loss: 1.149e-01, Validation Loss: 5.643e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18880, Training Loss: 1.149e-01, Validation Loss: 5.643e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18881, Training Loss: 1.149e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18882, Training Loss: 1.149e-01, Validation Loss: 5.643e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18883, Training Loss: 1.149e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18884, Training Loss: 1.149e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18885, Training Loss: 1.149e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18886, Training Loss: 1.149e-01, Validation Loss: 5.643e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18887, Training Loss: 1.149e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18888, Training Loss: 1.149e-01, Validation Loss: 5.643e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18889, Training Loss: 1.148e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18890, Training Loss: 1.148e-01, Validation Loss: 5.643e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18891, Training Loss: 1.148e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18892, Training Loss: 1.148e-01, Validation Loss: 5.643e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18893, Training Loss: 1.148e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18894, Training Loss: 1.148e-01, Validation Loss: 5.643e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18895, Training Loss: 1.148e-01, Validation Loss: 5.643e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18896, Training Loss: 1.148e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18897, Training Loss: 1.148e-01, Validation Loss: 5.642e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18898, Training Loss: 1.148e-01, Validation Loss: 5.642e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18899, Training Loss: 1.148e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18900, Training Loss: 1.147e-01, Validation Loss: 5.642e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18901, Training Loss: 1.147e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18902, Training Loss: 1.147e-01, Validation Loss: 5.642e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18903, Training Loss: 1.147e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18904, Training Loss: 1.147e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18905, Training Loss: 1.147e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18906, Training Loss: 1.147e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18907, Training Loss: 1.147e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18908, Training Loss: 1.147e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18909, Training Loss: 1.147e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18910, Training Loss: 1.147e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18911, Training Loss: 1.146e-01, Validation Loss: 5.642e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18912, Training Loss: 1.146e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18913, Training Loss: 1.146e-01, Validation Loss: 5.642e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18914, Training Loss: 1.146e-01, Validation Loss: 5.642e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18915, Training Loss: 1.146e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18916, Training Loss: 1.146e-01, Validation Loss: 5.642e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18917, Training Loss: 1.146e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18918, Training Loss: 1.146e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18919, Training Loss: 1.146e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18920, Training Loss: 1.146e-01, Validation Loss: 5.642e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18921, Training Loss: 1.146e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18922, Training Loss: 1.146e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18923, Training Loss: 1.145e-01, Validation Loss: 5.642e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18924, Training Loss: 1.145e-01, Validation Loss: 5.642e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18925, Training Loss: 1.145e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18926, Training Loss: 1.145e-01, Validation Loss: 5.642e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18927, Training Loss: 1.145e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18928, Training Loss: 1.145e-01, Validation Loss: 5.641e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18929, Training Loss: 1.145e-01, Validation Loss: 5.641e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18930, Training Loss: 1.145e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18931, Training Loss: 1.145e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18932, Training Loss: 1.145e-01, Validation Loss: 5.641e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18933, Training Loss: 1.145e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18934, Training Loss: 1.144e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18935, Training Loss: 1.144e-01, Validation Loss: 5.641e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18936, Training Loss: 1.144e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18937, Training Loss: 1.144e-01, Validation Loss: 5.641e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18938, Training Loss: 1.144e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18939, Training Loss: 1.144e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18940, Training Loss: 1.144e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18941, Training Loss: 1.144e-01, Validation Loss: 5.641e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18942, Training Loss: 1.144e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18943, Training Loss: 1.144e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18944, Training Loss: 1.144e-01, Validation Loss: 5.641e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18945, Training Loss: 1.143e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18946, Training Loss: 1.143e-01, Validation Loss: 5.641e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18947, Training Loss: 1.143e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18948, Training Loss: 1.143e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18949, Training Loss: 1.143e-01, Validation Loss: 5.641e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18950, Training Loss: 1.143e-01, Validation Loss: 5.641e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18951, Training Loss: 1.143e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18952, Training Loss: 1.143e-01, Validation Loss: 5.641e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18953, Training Loss: 1.143e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18954, Training Loss: 1.143e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18955, Training Loss: 1.143e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18956, Training Loss: 1.143e-01, Validation Loss: 5.640e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18957, Training Loss: 1.142e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18958, Training Loss: 1.142e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18959, Training Loss: 1.142e-01, Validation Loss: 5.640e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18960, Training Loss: 1.142e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18961, Training Loss: 1.142e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18962, Training Loss: 1.142e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18963, Training Loss: 1.142e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18964, Training Loss: 1.142e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18965, Training Loss: 1.142e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18966, Training Loss: 1.142e-01, Validation Loss: 5.640e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18967, Training Loss: 1.142e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18968, Training Loss: 1.141e-01, Validation Loss: 5.640e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18969, Training Loss: 1.141e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18970, Training Loss: 1.141e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18971, Training Loss: 1.141e-01, Validation Loss: 5.640e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18972, Training Loss: 1.141e-01, Validation Loss: 5.640e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18973, Training Loss: 1.141e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18974, Training Loss: 1.141e-01, Validation Loss: 5.640e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18975, Training Loss: 1.141e-01, Validation Loss: 5.640e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18976, Training Loss: 1.141e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18977, Training Loss: 1.141e-01, Validation Loss: 5.640e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18978, Training Loss: 1.141e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18979, Training Loss: 1.140e-01, Validation Loss: 5.640e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18980, Training Loss: 1.140e-01, Validation Loss: 5.640e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18981, Training Loss: 1.140e-01, Validation Loss: 5.640e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 18982, Training Loss: 1.140e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18983, Training Loss: 1.140e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18984, Training Loss: 1.140e-01, Validation Loss: 5.639e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18985, Training Loss: 1.140e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18986, Training Loss: 1.140e-01, Validation Loss: 5.639e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18987, Training Loss: 1.140e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18988, Training Loss: 1.140e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18989, Training Loss: 1.140e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18990, Training Loss: 1.140e-01, Validation Loss: 5.639e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18991, Training Loss: 1.139e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18992, Training Loss: 1.139e-01, Validation Loss: 5.639e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18993, Training Loss: 1.139e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18994, Training Loss: 1.139e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18995, Training Loss: 1.139e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18996, Training Loss: 1.139e-01, Validation Loss: 5.639e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18997, Training Loss: 1.139e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 18998, Training Loss: 1.139e-01, Validation Loss: 5.639e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 18999, Training Loss: 1.139e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19000, Training Loss: 1.139e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19001, Training Loss: 1.139e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19002, Training Loss: 1.138e-01, Validation Loss: 5.639e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19003, Training Loss: 1.138e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19004, Training Loss: 1.138e-01, Validation Loss: 5.639e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19005, Training Loss: 1.138e-01, Validation Loss: 5.639e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19006, Training Loss: 1.138e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19007, Training Loss: 1.138e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19008, Training Loss: 1.138e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19009, Training Loss: 1.138e-01, Validation Loss: 5.639e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19010, Training Loss: 1.138e-01, Validation Loss: 5.639e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19011, Training Loss: 1.138e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19012, Training Loss: 1.138e-01, Validation Loss: 5.639e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19013, Training Loss: 1.138e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19014, Training Loss: 1.137e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19015, Training Loss: 1.137e-01, Validation Loss: 5.638e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19016, Training Loss: 1.137e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19017, Training Loss: 1.137e-01, Validation Loss: 5.638e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19018, Training Loss: 1.137e-01, Validation Loss: 5.638e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19019, Training Loss: 1.137e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19020, Training Loss: 1.137e-01, Validation Loss: 5.638e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19021, Training Loss: 1.137e-01, Validation Loss: 5.638e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19022, Training Loss: 1.137e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19023, Training Loss: 1.137e-01, Validation Loss: 5.638e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19024, Training Loss: 1.137e-01, Validation Loss: 5.638e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19025, Training Loss: 1.136e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19026, Training Loss: 1.136e-01, Validation Loss: 5.638e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19027, Training Loss: 1.136e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19028, Training Loss: 1.136e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19029, Training Loss: 1.136e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19030, Training Loss: 1.136e-01, Validation Loss: 5.638e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19031, Training Loss: 1.136e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19032, Training Loss: 1.136e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19033, Training Loss: 1.136e-01, Validation Loss: 5.638e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19034, Training Loss: 1.136e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19035, Training Loss: 1.136e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19036, Training Loss: 1.135e-01, Validation Loss: 5.638e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19037, Training Loss: 1.135e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19038, Training Loss: 1.135e-01, Validation Loss: 5.638e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19039, Training Loss: 1.135e-01, Validation Loss: 5.638e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19040, Training Loss: 1.135e-01, Validation Loss: 5.638e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19041, Training Loss: 1.135e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19042, Training Loss: 1.135e-01, Validation Loss: 5.637e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19043, Training Loss: 1.135e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19044, Training Loss: 1.135e-01, Validation Loss: 5.637e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19045, Training Loss: 1.135e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19046, Training Loss: 1.135e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19047, Training Loss: 1.135e-01, Validation Loss: 5.637e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19048, Training Loss: 1.134e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19049, Training Loss: 1.134e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19050, Training Loss: 1.134e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19051, Training Loss: 1.134e-01, Validation Loss: 5.637e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19052, Training Loss: 1.134e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19053, Training Loss: 1.134e-01, Validation Loss: 5.637e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19054, Training Loss: 1.134e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19055, Training Loss: 1.134e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19056, Training Loss: 1.134e-01, Validation Loss: 5.637e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19057, Training Loss: 1.134e-01, Validation Loss: 5.637e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19058, Training Loss: 1.134e-01, Validation Loss: 5.637e-01, Patience: 3, Learning Rate: 0.001\n",
      "Epoch 19059, Training Loss: 1.133e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19060, Training Loss: 1.133e-01, Validation Loss: 5.637e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19061, Training Loss: 1.133e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19062, Training Loss: 1.133e-01, Validation Loss: 5.637e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19063, Training Loss: 1.133e-01, Validation Loss: 5.637e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19064, Training Loss: 1.133e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19065, Training Loss: 1.133e-01, Validation Loss: 5.637e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19066, Training Loss: 1.133e-01, Validation Loss: 5.637e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19067, Training Loss: 1.133e-01, Validation Loss: 5.637e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19068, Training Loss: 1.133e-01, Validation Loss: 5.637e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19069, Training Loss: 1.133e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19070, Training Loss: 1.133e-01, Validation Loss: 5.636e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19071, Training Loss: 1.132e-01, Validation Loss: 5.636e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19072, Training Loss: 1.132e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19073, Training Loss: 1.132e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19074, Training Loss: 1.132e-01, Validation Loss: 5.636e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19075, Training Loss: 1.132e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19076, Training Loss: 1.132e-01, Validation Loss: 5.636e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19077, Training Loss: 1.132e-01, Validation Loss: 5.636e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19078, Training Loss: 1.132e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19079, Training Loss: 1.132e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19080, Training Loss: 1.132e-01, Validation Loss: 5.636e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19081, Training Loss: 1.132e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19082, Training Loss: 1.131e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19083, Training Loss: 1.131e-01, Validation Loss: 5.636e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19084, Training Loss: 1.131e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19085, Training Loss: 1.131e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19086, Training Loss: 1.131e-01, Validation Loss: 5.636e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19087, Training Loss: 1.131e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19088, Training Loss: 1.131e-01, Validation Loss: 5.636e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19089, Training Loss: 1.131e-01, Validation Loss: 5.636e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19090, Training Loss: 1.131e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19091, Training Loss: 1.131e-01, Validation Loss: 5.636e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19092, Training Loss: 1.131e-01, Validation Loss: 5.636e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19093, Training Loss: 1.131e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19094, Training Loss: 1.130e-01, Validation Loss: 5.636e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19095, Training Loss: 1.130e-01, Validation Loss: 5.636e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19096, Training Loss: 1.130e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19097, Training Loss: 1.130e-01, Validation Loss: 5.636e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19098, Training Loss: 1.130e-01, Validation Loss: 5.636e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19099, Training Loss: 1.130e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19100, Training Loss: 1.130e-01, Validation Loss: 5.635e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19101, Training Loss: 1.130e-01, Validation Loss: 5.635e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19102, Training Loss: 1.130e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19103, Training Loss: 1.130e-01, Validation Loss: 5.635e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19104, Training Loss: 1.130e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19105, Training Loss: 1.129e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19106, Training Loss: 1.129e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19107, Training Loss: 1.129e-01, Validation Loss: 5.635e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19108, Training Loss: 1.129e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19109, Training Loss: 1.129e-01, Validation Loss: 5.635e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19110, Training Loss: 1.129e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19111, Training Loss: 1.129e-01, Validation Loss: 5.635e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19112, Training Loss: 1.129e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19113, Training Loss: 1.129e-01, Validation Loss: 5.635e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19114, Training Loss: 1.129e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19115, Training Loss: 1.129e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19116, Training Loss: 1.129e-01, Validation Loss: 5.635e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19117, Training Loss: 1.128e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19118, Training Loss: 1.128e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19119, Training Loss: 1.128e-01, Validation Loss: 5.635e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19120, Training Loss: 1.128e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19121, Training Loss: 1.128e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19122, Training Loss: 1.128e-01, Validation Loss: 5.635e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19123, Training Loss: 1.128e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19124, Training Loss: 1.128e-01, Validation Loss: 5.635e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19125, Training Loss: 1.128e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19126, Training Loss: 1.128e-01, Validation Loss: 5.635e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19127, Training Loss: 1.128e-01, Validation Loss: 5.635e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19128, Training Loss: 1.127e-01, Validation Loss: 5.635e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19129, Training Loss: 1.127e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19130, Training Loss: 1.127e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19131, Training Loss: 1.127e-01, Validation Loss: 5.634e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19132, Training Loss: 1.127e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19133, Training Loss: 1.127e-01, Validation Loss: 5.634e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19134, Training Loss: 1.127e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19135, Training Loss: 1.127e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19136, Training Loss: 1.127e-01, Validation Loss: 5.634e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19137, Training Loss: 1.127e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19138, Training Loss: 1.127e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19139, Training Loss: 1.127e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19140, Training Loss: 1.126e-01, Validation Loss: 5.634e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19141, Training Loss: 1.126e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19142, Training Loss: 1.126e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19143, Training Loss: 1.126e-01, Validation Loss: 5.634e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19144, Training Loss: 1.126e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19145, Training Loss: 1.126e-01, Validation Loss: 5.634e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19146, Training Loss: 1.126e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19147, Training Loss: 1.126e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19148, Training Loss: 1.126e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19149, Training Loss: 1.126e-01, Validation Loss: 5.634e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19150, Training Loss: 1.126e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19151, Training Loss: 1.126e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19152, Training Loss: 1.125e-01, Validation Loss: 5.634e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19153, Training Loss: 1.125e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19154, Training Loss: 1.125e-01, Validation Loss: 5.634e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19155, Training Loss: 1.125e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19156, Training Loss: 1.125e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19157, Training Loss: 1.125e-01, Validation Loss: 5.634e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19158, Training Loss: 1.125e-01, Validation Loss: 5.634e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19159, Training Loss: 1.125e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19160, Training Loss: 1.125e-01, Validation Loss: 5.633e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19161, Training Loss: 1.125e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19162, Training Loss: 1.125e-01, Validation Loss: 5.633e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19163, Training Loss: 1.124e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19164, Training Loss: 1.124e-01, Validation Loss: 5.633e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19165, Training Loss: 1.124e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19166, Training Loss: 1.124e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19167, Training Loss: 1.124e-01, Validation Loss: 5.633e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19168, Training Loss: 1.124e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19169, Training Loss: 1.124e-01, Validation Loss: 5.633e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19170, Training Loss: 1.124e-01, Validation Loss: 5.633e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19171, Training Loss: 1.124e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19172, Training Loss: 1.124e-01, Validation Loss: 5.633e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19173, Training Loss: 1.124e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19174, Training Loss: 1.124e-01, Validation Loss: 5.633e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19175, Training Loss: 1.123e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19176, Training Loss: 1.123e-01, Validation Loss: 5.633e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19177, Training Loss: 1.123e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19178, Training Loss: 1.123e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19179, Training Loss: 1.123e-01, Validation Loss: 5.633e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19180, Training Loss: 1.123e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19181, Training Loss: 1.123e-01, Validation Loss: 5.633e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19182, Training Loss: 1.123e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19183, Training Loss: 1.123e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19184, Training Loss: 1.123e-01, Validation Loss: 5.633e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19185, Training Loss: 1.123e-01, Validation Loss: 5.633e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19186, Training Loss: 1.123e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19187, Training Loss: 1.122e-01, Validation Loss: 5.633e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19188, Training Loss: 1.122e-01, Validation Loss: 5.633e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19189, Training Loss: 1.122e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19190, Training Loss: 1.122e-01, Validation Loss: 5.632e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19191, Training Loss: 1.122e-01, Validation Loss: 5.632e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19192, Training Loss: 1.122e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19193, Training Loss: 1.122e-01, Validation Loss: 5.632e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19194, Training Loss: 1.122e-01, Validation Loss: 5.632e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19195, Training Loss: 1.122e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19196, Training Loss: 1.122e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19197, Training Loss: 1.122e-01, Validation Loss: 5.632e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19198, Training Loss: 1.121e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19199, Training Loss: 1.121e-01, Validation Loss: 5.632e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19200, Training Loss: 1.121e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19201, Training Loss: 1.121e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19202, Training Loss: 1.121e-01, Validation Loss: 5.632e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19203, Training Loss: 1.121e-01, Validation Loss: 5.632e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19204, Training Loss: 1.121e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19205, Training Loss: 1.121e-01, Validation Loss: 5.632e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19206, Training Loss: 1.121e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19207, Training Loss: 1.121e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19208, Training Loss: 1.121e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19209, Training Loss: 1.121e-01, Validation Loss: 5.632e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19210, Training Loss: 1.120e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19211, Training Loss: 1.120e-01, Validation Loss: 5.632e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19212, Training Loss: 1.120e-01, Validation Loss: 5.632e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19213, Training Loss: 1.120e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19214, Training Loss: 1.120e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19215, Training Loss: 1.120e-01, Validation Loss: 5.632e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19216, Training Loss: 1.120e-01, Validation Loss: 5.632e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19217, Training Loss: 1.120e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19218, Training Loss: 1.120e-01, Validation Loss: 5.632e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19219, Training Loss: 1.120e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19220, Training Loss: 1.120e-01, Validation Loss: 5.631e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19221, Training Loss: 1.120e-01, Validation Loss: 5.631e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19222, Training Loss: 1.119e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19223, Training Loss: 1.119e-01, Validation Loss: 5.631e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19224, Training Loss: 1.119e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19225, Training Loss: 1.119e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19226, Training Loss: 1.119e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19227, Training Loss: 1.119e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19228, Training Loss: 1.119e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19229, Training Loss: 1.119e-01, Validation Loss: 5.631e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19230, Training Loss: 1.119e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19231, Training Loss: 1.119e-01, Validation Loss: 5.631e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19232, Training Loss: 1.119e-01, Validation Loss: 5.631e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19233, Training Loss: 1.118e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19234, Training Loss: 1.118e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19235, Training Loss: 1.118e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19236, Training Loss: 1.118e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19237, Training Loss: 1.118e-01, Validation Loss: 5.631e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19238, Training Loss: 1.118e-01, Validation Loss: 5.631e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19239, Training Loss: 1.118e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19240, Training Loss: 1.118e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19241, Training Loss: 1.118e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19242, Training Loss: 1.118e-01, Validation Loss: 5.631e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19243, Training Loss: 1.118e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19244, Training Loss: 1.118e-01, Validation Loss: 5.631e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19245, Training Loss: 1.117e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19246, Training Loss: 1.117e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19247, Training Loss: 1.117e-01, Validation Loss: 5.631e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19248, Training Loss: 1.117e-01, Validation Loss: 5.631e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19249, Training Loss: 1.117e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19250, Training Loss: 1.117e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19251, Training Loss: 1.117e-01, Validation Loss: 5.631e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19252, Training Loss: 1.117e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19253, Training Loss: 1.117e-01, Validation Loss: 5.630e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19254, Training Loss: 1.117e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19255, Training Loss: 1.117e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19256, Training Loss: 1.117e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19257, Training Loss: 1.116e-01, Validation Loss: 5.630e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19258, Training Loss: 1.116e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19259, Training Loss: 1.116e-01, Validation Loss: 5.630e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19260, Training Loss: 1.116e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19261, Training Loss: 1.116e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19262, Training Loss: 1.116e-01, Validation Loss: 5.630e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19263, Training Loss: 1.116e-01, Validation Loss: 5.630e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19264, Training Loss: 1.116e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19265, Training Loss: 1.116e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19266, Training Loss: 1.116e-01, Validation Loss: 5.630e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19267, Training Loss: 1.116e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19268, Training Loss: 1.116e-01, Validation Loss: 5.630e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19269, Training Loss: 1.115e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19270, Training Loss: 1.115e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19271, Training Loss: 1.115e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19272, Training Loss: 1.115e-01, Validation Loss: 5.630e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19273, Training Loss: 1.115e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19274, Training Loss: 1.115e-01, Validation Loss: 5.630e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19275, Training Loss: 1.115e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19276, Training Loss: 1.115e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19277, Training Loss: 1.115e-01, Validation Loss: 5.630e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19278, Training Loss: 1.115e-01, Validation Loss: 5.630e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19279, Training Loss: 1.115e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19280, Training Loss: 1.114e-01, Validation Loss: 5.630e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19281, Training Loss: 1.114e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19282, Training Loss: 1.114e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19283, Training Loss: 1.114e-01, Validation Loss: 5.629e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19284, Training Loss: 1.114e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19285, Training Loss: 1.114e-01, Validation Loss: 5.629e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19286, Training Loss: 1.114e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19287, Training Loss: 1.114e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19288, Training Loss: 1.114e-01, Validation Loss: 5.629e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19289, Training Loss: 1.114e-01, Validation Loss: 5.629e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19290, Training Loss: 1.114e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19291, Training Loss: 1.114e-01, Validation Loss: 5.629e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19292, Training Loss: 1.113e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19293, Training Loss: 1.113e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19294, Training Loss: 1.113e-01, Validation Loss: 5.629e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19295, Training Loss: 1.113e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19296, Training Loss: 1.113e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19297, Training Loss: 1.113e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19298, Training Loss: 1.113e-01, Validation Loss: 5.629e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19299, Training Loss: 1.113e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19300, Training Loss: 1.113e-01, Validation Loss: 5.629e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19301, Training Loss: 1.113e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19302, Training Loss: 1.113e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19303, Training Loss: 1.113e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19304, Training Loss: 1.112e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19305, Training Loss: 1.112e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19306, Training Loss: 1.112e-01, Validation Loss: 5.629e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19307, Training Loss: 1.112e-01, Validation Loss: 5.629e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19308, Training Loss: 1.112e-01, Validation Loss: 5.629e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19309, Training Loss: 1.112e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19310, Training Loss: 1.112e-01, Validation Loss: 5.629e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19311, Training Loss: 1.112e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19312, Training Loss: 1.112e-01, Validation Loss: 5.629e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19313, Training Loss: 1.112e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19314, Training Loss: 1.112e-01, Validation Loss: 5.628e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19315, Training Loss: 1.112e-01, Validation Loss: 5.628e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19316, Training Loss: 1.111e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19317, Training Loss: 1.111e-01, Validation Loss: 5.628e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19318, Training Loss: 1.111e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19319, Training Loss: 1.111e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19320, Training Loss: 1.111e-01, Validation Loss: 5.628e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19321, Training Loss: 1.111e-01, Validation Loss: 5.628e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19322, Training Loss: 1.111e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19323, Training Loss: 1.111e-01, Validation Loss: 5.628e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19324, Training Loss: 1.111e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19325, Training Loss: 1.111e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19326, Training Loss: 1.111e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19327, Training Loss: 1.111e-01, Validation Loss: 5.628e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19328, Training Loss: 1.110e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19329, Training Loss: 1.110e-01, Validation Loss: 5.628e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19330, Training Loss: 1.110e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19331, Training Loss: 1.110e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19332, Training Loss: 1.110e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19333, Training Loss: 1.110e-01, Validation Loss: 5.628e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19334, Training Loss: 1.110e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19335, Training Loss: 1.110e-01, Validation Loss: 5.628e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19336, Training Loss: 1.110e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19337, Training Loss: 1.110e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19338, Training Loss: 1.110e-01, Validation Loss: 5.628e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19339, Training Loss: 1.109e-01, Validation Loss: 5.628e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19340, Training Loss: 1.109e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19341, Training Loss: 1.109e-01, Validation Loss: 5.628e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19342, Training Loss: 1.109e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19343, Training Loss: 1.109e-01, Validation Loss: 5.628e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19344, Training Loss: 1.109e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19345, Training Loss: 1.109e-01, Validation Loss: 5.627e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19346, Training Loss: 1.109e-01, Validation Loss: 5.627e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19347, Training Loss: 1.109e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19348, Training Loss: 1.109e-01, Validation Loss: 5.627e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19349, Training Loss: 1.109e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19350, Training Loss: 1.109e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19351, Training Loss: 1.108e-01, Validation Loss: 5.627e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19352, Training Loss: 1.108e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19353, Training Loss: 1.108e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19354, Training Loss: 1.108e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19355, Training Loss: 1.108e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19356, Training Loss: 1.108e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19357, Training Loss: 1.108e-01, Validation Loss: 5.627e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19358, Training Loss: 1.108e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19359, Training Loss: 1.108e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19360, Training Loss: 1.108e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19361, Training Loss: 1.108e-01, Validation Loss: 5.627e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19362, Training Loss: 1.108e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19363, Training Loss: 1.107e-01, Validation Loss: 5.627e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19364, Training Loss: 1.107e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19365, Training Loss: 1.107e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19366, Training Loss: 1.107e-01, Validation Loss: 5.627e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19367, Training Loss: 1.107e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19368, Training Loss: 1.107e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19369, Training Loss: 1.107e-01, Validation Loss: 5.627e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19370, Training Loss: 1.107e-01, Validation Loss: 5.627e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19371, Training Loss: 1.107e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19372, Training Loss: 1.107e-01, Validation Loss: 5.627e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19373, Training Loss: 1.107e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19374, Training Loss: 1.107e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19375, Training Loss: 1.106e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19376, Training Loss: 1.106e-01, Validation Loss: 5.626e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19377, Training Loss: 1.106e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19378, Training Loss: 1.106e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19379, Training Loss: 1.106e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19380, Training Loss: 1.106e-01, Validation Loss: 5.626e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19381, Training Loss: 1.106e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19382, Training Loss: 1.106e-01, Validation Loss: 5.626e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19383, Training Loss: 1.106e-01, Validation Loss: 5.626e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19384, Training Loss: 1.106e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19385, Training Loss: 1.106e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19386, Training Loss: 1.106e-01, Validation Loss: 5.626e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19387, Training Loss: 1.105e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19388, Training Loss: 1.105e-01, Validation Loss: 5.626e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19389, Training Loss: 1.105e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19390, Training Loss: 1.105e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19391, Training Loss: 1.105e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19392, Training Loss: 1.105e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19393, Training Loss: 1.105e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19394, Training Loss: 1.105e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19395, Training Loss: 1.105e-01, Validation Loss: 5.626e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19396, Training Loss: 1.105e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19397, Training Loss: 1.105e-01, Validation Loss: 5.626e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19398, Training Loss: 1.105e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19399, Training Loss: 1.104e-01, Validation Loss: 5.626e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19400, Training Loss: 1.104e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19401, Training Loss: 1.104e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19402, Training Loss: 1.104e-01, Validation Loss: 5.626e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19403, Training Loss: 1.104e-01, Validation Loss: 5.626e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19404, Training Loss: 1.104e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19405, Training Loss: 1.104e-01, Validation Loss: 5.626e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19406, Training Loss: 1.104e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19407, Training Loss: 1.104e-01, Validation Loss: 5.625e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19408, Training Loss: 1.104e-01, Validation Loss: 5.625e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19409, Training Loss: 1.104e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19410, Training Loss: 1.104e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19411, Training Loss: 1.103e-01, Validation Loss: 5.625e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19412, Training Loss: 1.103e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19413, Training Loss: 1.103e-01, Validation Loss: 5.625e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19414, Training Loss: 1.103e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19415, Training Loss: 1.103e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19416, Training Loss: 1.103e-01, Validation Loss: 5.625e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19417, Training Loss: 1.103e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19418, Training Loss: 1.103e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19419, Training Loss: 1.103e-01, Validation Loss: 5.625e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19420, Training Loss: 1.103e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19421, Training Loss: 1.103e-01, Validation Loss: 5.625e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19422, Training Loss: 1.103e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19423, Training Loss: 1.102e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19424, Training Loss: 1.102e-01, Validation Loss: 5.625e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19425, Training Loss: 1.102e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19426, Training Loss: 1.102e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19427, Training Loss: 1.102e-01, Validation Loss: 5.625e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19428, Training Loss: 1.102e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19429, Training Loss: 1.102e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19430, Training Loss: 1.102e-01, Validation Loss: 5.625e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19431, Training Loss: 1.102e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19432, Training Loss: 1.102e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19433, Training Loss: 1.102e-01, Validation Loss: 5.625e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19434, Training Loss: 1.102e-01, Validation Loss: 5.625e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19435, Training Loss: 1.101e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19436, Training Loss: 1.101e-01, Validation Loss: 5.625e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19437, Training Loss: 1.101e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19438, Training Loss: 1.101e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19439, Training Loss: 1.101e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19440, Training Loss: 1.101e-01, Validation Loss: 5.624e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19441, Training Loss: 1.101e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19442, Training Loss: 1.101e-01, Validation Loss: 5.624e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19443, Training Loss: 1.101e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19444, Training Loss: 1.101e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19445, Training Loss: 1.101e-01, Validation Loss: 5.624e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19446, Training Loss: 1.101e-01, Validation Loss: 5.624e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19447, Training Loss: 1.100e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19448, Training Loss: 1.100e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19449, Training Loss: 1.100e-01, Validation Loss: 5.624e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19450, Training Loss: 1.100e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19451, Training Loss: 1.100e-01, Validation Loss: 5.624e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19452, Training Loss: 1.100e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19453, Training Loss: 1.100e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19454, Training Loss: 1.100e-01, Validation Loss: 5.624e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19455, Training Loss: 1.100e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19456, Training Loss: 1.100e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19457, Training Loss: 1.100e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19458, Training Loss: 1.100e-01, Validation Loss: 5.624e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19459, Training Loss: 1.099e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19460, Training Loss: 1.099e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19461, Training Loss: 1.099e-01, Validation Loss: 5.624e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19462, Training Loss: 1.099e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19463, Training Loss: 1.099e-01, Validation Loss: 5.624e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19464, Training Loss: 1.099e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19465, Training Loss: 1.099e-01, Validation Loss: 5.624e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19466, Training Loss: 1.099e-01, Validation Loss: 5.624e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19467, Training Loss: 1.099e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19468, Training Loss: 1.099e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19469, Training Loss: 1.099e-01, Validation Loss: 5.623e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19470, Training Loss: 1.099e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19471, Training Loss: 1.098e-01, Validation Loss: 5.623e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19472, Training Loss: 1.098e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19473, Training Loss: 1.098e-01, Validation Loss: 5.623e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19474, Training Loss: 1.098e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19475, Training Loss: 1.098e-01, Validation Loss: 5.623e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19476, Training Loss: 1.098e-01, Validation Loss: 5.623e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19477, Training Loss: 1.098e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19478, Training Loss: 1.098e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19479, Training Loss: 1.098e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19480, Training Loss: 1.098e-01, Validation Loss: 5.623e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19481, Training Loss: 1.098e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19482, Training Loss: 1.098e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19483, Training Loss: 1.097e-01, Validation Loss: 5.623e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19484, Training Loss: 1.097e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19485, Training Loss: 1.097e-01, Validation Loss: 5.623e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19486, Training Loss: 1.097e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19487, Training Loss: 1.097e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19488, Training Loss: 1.097e-01, Validation Loss: 5.623e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19489, Training Loss: 1.097e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19490, Training Loss: 1.097e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19491, Training Loss: 1.097e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19492, Training Loss: 1.097e-01, Validation Loss: 5.623e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19493, Training Loss: 1.097e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19494, Training Loss: 1.097e-01, Validation Loss: 5.623e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19495, Training Loss: 1.096e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19496, Training Loss: 1.096e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19497, Training Loss: 1.096e-01, Validation Loss: 5.623e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19498, Training Loss: 1.096e-01, Validation Loss: 5.623e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19499, Training Loss: 1.096e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19500, Training Loss: 1.096e-01, Validation Loss: 5.622e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19501, Training Loss: 1.096e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19502, Training Loss: 1.096e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19503, Training Loss: 1.096e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19504, Training Loss: 1.096e-01, Validation Loss: 5.622e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19505, Training Loss: 1.096e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19506, Training Loss: 1.096e-01, Validation Loss: 5.622e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19507, Training Loss: 1.095e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19508, Training Loss: 1.095e-01, Validation Loss: 5.622e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19509, Training Loss: 1.095e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19510, Training Loss: 1.095e-01, Validation Loss: 5.622e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19511, Training Loss: 1.095e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19512, Training Loss: 1.095e-01, Validation Loss: 5.622e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19513, Training Loss: 1.095e-01, Validation Loss: 5.622e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19514, Training Loss: 1.095e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19515, Training Loss: 1.095e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19516, Training Loss: 1.095e-01, Validation Loss: 5.622e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19517, Training Loss: 1.095e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19518, Training Loss: 1.095e-01, Validation Loss: 5.622e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19519, Training Loss: 1.094e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19520, Training Loss: 1.094e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19521, Training Loss: 1.094e-01, Validation Loss: 5.622e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19522, Training Loss: 1.094e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19523, Training Loss: 1.094e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19524, Training Loss: 1.094e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19525, Training Loss: 1.094e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19526, Training Loss: 1.094e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19527, Training Loss: 1.094e-01, Validation Loss: 5.622e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19528, Training Loss: 1.094e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19529, Training Loss: 1.094e-01, Validation Loss: 5.622e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19530, Training Loss: 1.094e-01, Validation Loss: 5.622e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19531, Training Loss: 1.093e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19532, Training Loss: 1.093e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19533, Training Loss: 1.093e-01, Validation Loss: 5.622e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19534, Training Loss: 1.093e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19535, Training Loss: 1.093e-01, Validation Loss: 5.621e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19536, Training Loss: 1.093e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19537, Training Loss: 1.093e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19538, Training Loss: 1.093e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19539, Training Loss: 1.093e-01, Validation Loss: 5.621e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19540, Training Loss: 1.093e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19541, Training Loss: 1.093e-01, Validation Loss: 5.621e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19542, Training Loss: 1.093e-01, Validation Loss: 5.621e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19543, Training Loss: 1.093e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19544, Training Loss: 1.092e-01, Validation Loss: 5.621e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19545, Training Loss: 1.092e-01, Validation Loss: 5.621e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19546, Training Loss: 1.092e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19547, Training Loss: 1.092e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19548, Training Loss: 1.092e-01, Validation Loss: 5.621e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19549, Training Loss: 1.092e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19550, Training Loss: 1.092e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19551, Training Loss: 1.092e-01, Validation Loss: 5.621e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19552, Training Loss: 1.092e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19553, Training Loss: 1.092e-01, Validation Loss: 5.621e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19554, Training Loss: 1.092e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19555, Training Loss: 1.092e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19556, Training Loss: 1.091e-01, Validation Loss: 5.621e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19557, Training Loss: 1.091e-01, Validation Loss: 5.621e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19558, Training Loss: 1.091e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19559, Training Loss: 1.091e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19560, Training Loss: 1.091e-01, Validation Loss: 5.621e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19561, Training Loss: 1.091e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19562, Training Loss: 1.091e-01, Validation Loss: 5.621e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19563, Training Loss: 1.091e-01, Validation Loss: 5.621e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19564, Training Loss: 1.091e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19565, Training Loss: 1.091e-01, Validation Loss: 5.620e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19566, Training Loss: 1.091e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19567, Training Loss: 1.091e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19568, Training Loss: 1.090e-01, Validation Loss: 5.620e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19569, Training Loss: 1.090e-01, Validation Loss: 5.620e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19570, Training Loss: 1.090e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19571, Training Loss: 1.090e-01, Validation Loss: 5.620e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19572, Training Loss: 1.090e-01, Validation Loss: 5.620e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19573, Training Loss: 1.090e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19574, Training Loss: 1.090e-01, Validation Loss: 5.620e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19575, Training Loss: 1.090e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19576, Training Loss: 1.090e-01, Validation Loss: 5.620e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19577, Training Loss: 1.090e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19578, Training Loss: 1.090e-01, Validation Loss: 5.620e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19579, Training Loss: 1.090e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19580, Training Loss: 1.089e-01, Validation Loss: 5.620e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19581, Training Loss: 1.089e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19582, Training Loss: 1.089e-01, Validation Loss: 5.620e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19583, Training Loss: 1.089e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19584, Training Loss: 1.089e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19585, Training Loss: 1.089e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19586, Training Loss: 1.089e-01, Validation Loss: 5.620e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19587, Training Loss: 1.089e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19588, Training Loss: 1.089e-01, Validation Loss: 5.620e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19589, Training Loss: 1.089e-01, Validation Loss: 5.620e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19590, Training Loss: 1.089e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19591, Training Loss: 1.089e-01, Validation Loss: 5.620e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19592, Training Loss: 1.088e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19593, Training Loss: 1.088e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19594, Training Loss: 1.088e-01, Validation Loss: 5.620e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19595, Training Loss: 1.088e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19596, Training Loss: 1.088e-01, Validation Loss: 5.620e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19597, Training Loss: 1.088e-01, Validation Loss: 5.620e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19598, Training Loss: 1.088e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19599, Training Loss: 1.088e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19600, Training Loss: 1.088e-01, Validation Loss: 5.619e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19601, Training Loss: 1.088e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19602, Training Loss: 1.088e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19603, Training Loss: 1.088e-01, Validation Loss: 5.619e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19604, Training Loss: 1.087e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19605, Training Loss: 1.087e-01, Validation Loss: 5.619e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19606, Training Loss: 1.087e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19607, Training Loss: 1.087e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19608, Training Loss: 1.087e-01, Validation Loss: 5.619e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19609, Training Loss: 1.087e-01, Validation Loss: 5.619e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19610, Training Loss: 1.087e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19611, Training Loss: 1.087e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19612, Training Loss: 1.087e-01, Validation Loss: 5.619e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19613, Training Loss: 1.087e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19614, Training Loss: 1.087e-01, Validation Loss: 5.619e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19615, Training Loss: 1.087e-01, Validation Loss: 5.619e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19616, Training Loss: 1.087e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19617, Training Loss: 1.086e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19618, Training Loss: 1.086e-01, Validation Loss: 5.619e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19619, Training Loss: 1.086e-01, Validation Loss: 5.619e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19620, Training Loss: 1.086e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19621, Training Loss: 1.086e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19622, Training Loss: 1.086e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19623, Training Loss: 1.086e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19624, Training Loss: 1.086e-01, Validation Loss: 5.619e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19625, Training Loss: 1.086e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19626, Training Loss: 1.086e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19627, Training Loss: 1.086e-01, Validation Loss: 5.619e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19628, Training Loss: 1.086e-01, Validation Loss: 5.619e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19629, Training Loss: 1.085e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19630, Training Loss: 1.085e-01, Validation Loss: 5.618e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19631, Training Loss: 1.085e-01, Validation Loss: 5.618e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19632, Training Loss: 1.085e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19633, Training Loss: 1.085e-01, Validation Loss: 5.618e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19634, Training Loss: 1.085e-01, Validation Loss: 5.618e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19635, Training Loss: 1.085e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19636, Training Loss: 1.085e-01, Validation Loss: 5.618e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19637, Training Loss: 1.085e-01, Validation Loss: 5.618e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19638, Training Loss: 1.085e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19639, Training Loss: 1.085e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19640, Training Loss: 1.085e-01, Validation Loss: 5.618e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19641, Training Loss: 1.084e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19642, Training Loss: 1.084e-01, Validation Loss: 5.618e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19643, Training Loss: 1.084e-01, Validation Loss: 5.618e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19644, Training Loss: 1.084e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19645, Training Loss: 1.084e-01, Validation Loss: 5.618e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19646, Training Loss: 1.084e-01, Validation Loss: 5.618e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19647, Training Loss: 1.084e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19648, Training Loss: 1.084e-01, Validation Loss: 5.618e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19649, Training Loss: 1.084e-01, Validation Loss: 5.618e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19650, Training Loss: 1.084e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19651, Training Loss: 1.084e-01, Validation Loss: 5.618e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19652, Training Loss: 1.084e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19653, Training Loss: 1.084e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19654, Training Loss: 1.083e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19655, Training Loss: 1.083e-01, Validation Loss: 5.618e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19656, Training Loss: 1.083e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19657, Training Loss: 1.083e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19658, Training Loss: 1.083e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19659, Training Loss: 1.083e-01, Validation Loss: 5.618e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19660, Training Loss: 1.083e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19661, Training Loss: 1.083e-01, Validation Loss: 5.618e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19662, Training Loss: 1.083e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19663, Training Loss: 1.083e-01, Validation Loss: 5.617e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19664, Training Loss: 1.083e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19665, Training Loss: 1.083e-01, Validation Loss: 5.618e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19666, Training Loss: 1.082e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19667, Training Loss: 1.082e-01, Validation Loss: 5.617e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19668, Training Loss: 1.082e-01, Validation Loss: 5.617e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19669, Training Loss: 1.082e-01, Validation Loss: 5.617e-01, Patience: 3, Learning Rate: 0.001\n",
      "Epoch 19670, Training Loss: 1.082e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19671, Training Loss: 1.082e-01, Validation Loss: 5.617e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19672, Training Loss: 1.082e-01, Validation Loss: 5.617e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19673, Training Loss: 1.082e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19674, Training Loss: 1.082e-01, Validation Loss: 5.617e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19675, Training Loss: 1.082e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19676, Training Loss: 1.082e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19677, Training Loss: 1.082e-01, Validation Loss: 5.617e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19678, Training Loss: 1.081e-01, Validation Loss: 5.617e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19679, Training Loss: 1.081e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19680, Training Loss: 1.081e-01, Validation Loss: 5.617e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19681, Training Loss: 1.081e-01, Validation Loss: 5.617e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19682, Training Loss: 1.081e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19683, Training Loss: 1.081e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19684, Training Loss: 1.081e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19685, Training Loss: 1.081e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19686, Training Loss: 1.081e-01, Validation Loss: 5.617e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19687, Training Loss: 1.081e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19688, Training Loss: 1.081e-01, Validation Loss: 5.617e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19689, Training Loss: 1.081e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19690, Training Loss: 1.081e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19691, Training Loss: 1.080e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19692, Training Loss: 1.080e-01, Validation Loss: 5.617e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19693, Training Loss: 1.080e-01, Validation Loss: 5.617e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19694, Training Loss: 1.080e-01, Validation Loss: 5.617e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19695, Training Loss: 1.080e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19696, Training Loss: 1.080e-01, Validation Loss: 5.617e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19697, Training Loss: 1.080e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19698, Training Loss: 1.080e-01, Validation Loss: 5.617e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19699, Training Loss: 1.080e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19700, Training Loss: 1.080e-01, Validation Loss: 5.616e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19701, Training Loss: 1.080e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19702, Training Loss: 1.080e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19703, Training Loss: 1.079e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19704, Training Loss: 1.079e-01, Validation Loss: 5.616e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19705, Training Loss: 1.079e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19706, Training Loss: 1.079e-01, Validation Loss: 5.616e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19707, Training Loss: 1.079e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19708, Training Loss: 1.079e-01, Validation Loss: 5.616e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19709, Training Loss: 1.079e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19710, Training Loss: 1.079e-01, Validation Loss: 5.616e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19711, Training Loss: 1.079e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19712, Training Loss: 1.079e-01, Validation Loss: 5.616e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19713, Training Loss: 1.079e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19714, Training Loss: 1.079e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19715, Training Loss: 1.078e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19716, Training Loss: 1.078e-01, Validation Loss: 5.616e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19717, Training Loss: 1.078e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19718, Training Loss: 1.078e-01, Validation Loss: 5.616e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19719, Training Loss: 1.078e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19720, Training Loss: 1.078e-01, Validation Loss: 5.616e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19721, Training Loss: 1.078e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19722, Training Loss: 1.078e-01, Validation Loss: 5.616e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19723, Training Loss: 1.078e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19724, Training Loss: 1.078e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19725, Training Loss: 1.078e-01, Validation Loss: 5.616e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19726, Training Loss: 1.078e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19727, Training Loss: 1.078e-01, Validation Loss: 5.616e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19728, Training Loss: 1.077e-01, Validation Loss: 5.616e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19729, Training Loss: 1.077e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19730, Training Loss: 1.077e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19731, Training Loss: 1.077e-01, Validation Loss: 5.615e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19732, Training Loss: 1.077e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19733, Training Loss: 1.077e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19734, Training Loss: 1.077e-01, Validation Loss: 5.615e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19735, Training Loss: 1.077e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19736, Training Loss: 1.077e-01, Validation Loss: 5.615e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19737, Training Loss: 1.077e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19738, Training Loss: 1.077e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19739, Training Loss: 1.077e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19740, Training Loss: 1.076e-01, Validation Loss: 5.615e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19741, Training Loss: 1.076e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19742, Training Loss: 1.076e-01, Validation Loss: 5.615e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19743, Training Loss: 1.076e-01, Validation Loss: 5.615e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19744, Training Loss: 1.076e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19745, Training Loss: 1.076e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19746, Training Loss: 1.076e-01, Validation Loss: 5.615e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19747, Training Loss: 1.076e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19748, Training Loss: 1.076e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19749, Training Loss: 1.076e-01, Validation Loss: 5.615e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19750, Training Loss: 1.076e-01, Validation Loss: 5.615e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19751, Training Loss: 1.076e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19752, Training Loss: 1.076e-01, Validation Loss: 5.615e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19753, Training Loss: 1.075e-01, Validation Loss: 5.615e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19754, Training Loss: 1.075e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19755, Training Loss: 1.075e-01, Validation Loss: 5.615e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19756, Training Loss: 1.075e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19757, Training Loss: 1.075e-01, Validation Loss: 5.615e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19758, Training Loss: 1.075e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19759, Training Loss: 1.075e-01, Validation Loss: 5.615e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19760, Training Loss: 1.075e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19761, Training Loss: 1.075e-01, Validation Loss: 5.615e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19762, Training Loss: 1.075e-01, Validation Loss: 5.615e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19763, Training Loss: 1.075e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19764, Training Loss: 1.075e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19765, Training Loss: 1.074e-01, Validation Loss: 5.614e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19766, Training Loss: 1.074e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19767, Training Loss: 1.074e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19768, Training Loss: 1.074e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19769, Training Loss: 1.074e-01, Validation Loss: 5.614e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19770, Training Loss: 1.074e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19771, Training Loss: 1.074e-01, Validation Loss: 5.614e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19772, Training Loss: 1.074e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19773, Training Loss: 1.074e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19774, Training Loss: 1.074e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19775, Training Loss: 1.074e-01, Validation Loss: 5.614e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19776, Training Loss: 1.074e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19777, Training Loss: 1.074e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19778, Training Loss: 1.073e-01, Validation Loss: 5.614e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19779, Training Loss: 1.073e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19780, Training Loss: 1.073e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19781, Training Loss: 1.073e-01, Validation Loss: 5.614e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19782, Training Loss: 1.073e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19783, Training Loss: 1.073e-01, Validation Loss: 5.614e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19784, Training Loss: 1.073e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19785, Training Loss: 1.073e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19786, Training Loss: 1.073e-01, Validation Loss: 5.614e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19787, Training Loss: 1.073e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19788, Training Loss: 1.073e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19789, Training Loss: 1.073e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19790, Training Loss: 1.072e-01, Validation Loss: 5.614e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19791, Training Loss: 1.072e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19792, Training Loss: 1.072e-01, Validation Loss: 5.614e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19793, Training Loss: 1.072e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19794, Training Loss: 1.072e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19795, Training Loss: 1.072e-01, Validation Loss: 5.614e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19796, Training Loss: 1.072e-01, Validation Loss: 5.614e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19797, Training Loss: 1.072e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19798, Training Loss: 1.072e-01, Validation Loss: 5.613e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19799, Training Loss: 1.072e-01, Validation Loss: 5.613e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19800, Training Loss: 1.072e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19801, Training Loss: 1.072e-01, Validation Loss: 5.613e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19802, Training Loss: 1.071e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19803, Training Loss: 1.071e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19804, Training Loss: 1.071e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19805, Training Loss: 1.071e-01, Validation Loss: 5.613e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19806, Training Loss: 1.071e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19807, Training Loss: 1.071e-01, Validation Loss: 5.613e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19808, Training Loss: 1.071e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19809, Training Loss: 1.071e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19810, Training Loss: 1.071e-01, Validation Loss: 5.613e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19811, Training Loss: 1.071e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19812, Training Loss: 1.071e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19813, Training Loss: 1.071e-01, Validation Loss: 5.613e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19814, Training Loss: 1.071e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19815, Training Loss: 1.070e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19816, Training Loss: 1.070e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19817, Training Loss: 1.070e-01, Validation Loss: 5.613e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19818, Training Loss: 1.070e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19819, Training Loss: 1.070e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19820, Training Loss: 1.070e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19821, Training Loss: 1.070e-01, Validation Loss: 5.613e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19822, Training Loss: 1.070e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19823, Training Loss: 1.070e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19824, Training Loss: 1.070e-01, Validation Loss: 5.613e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19825, Training Loss: 1.070e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19826, Training Loss: 1.070e-01, Validation Loss: 5.613e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19827, Training Loss: 1.070e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19828, Training Loss: 1.069e-01, Validation Loss: 5.613e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19829, Training Loss: 1.069e-01, Validation Loss: 5.613e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19830, Training Loss: 1.069e-01, Validation Loss: 5.613e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19831, Training Loss: 1.069e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19832, Training Loss: 1.069e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19833, Training Loss: 1.069e-01, Validation Loss: 5.613e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19834, Training Loss: 1.069e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19835, Training Loss: 1.069e-01, Validation Loss: 5.612e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19836, Training Loss: 1.069e-01, Validation Loss: 5.612e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19837, Training Loss: 1.069e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19838, Training Loss: 1.069e-01, Validation Loss: 5.612e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19839, Training Loss: 1.069e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19840, Training Loss: 1.068e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19841, Training Loss: 1.068e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19842, Training Loss: 1.068e-01, Validation Loss: 5.612e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19843, Training Loss: 1.068e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19844, Training Loss: 1.068e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19845, Training Loss: 1.068e-01, Validation Loss: 5.612e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19846, Training Loss: 1.068e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19847, Training Loss: 1.068e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19848, Training Loss: 1.068e-01, Validation Loss: 5.612e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19849, Training Loss: 1.068e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19850, Training Loss: 1.068e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19851, Training Loss: 1.068e-01, Validation Loss: 5.612e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19852, Training Loss: 1.068e-01, Validation Loss: 5.612e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19853, Training Loss: 1.067e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19854, Training Loss: 1.067e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19855, Training Loss: 1.067e-01, Validation Loss: 5.612e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19856, Training Loss: 1.067e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19857, Training Loss: 1.067e-01, Validation Loss: 5.612e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19858, Training Loss: 1.067e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19859, Training Loss: 1.067e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19860, Training Loss: 1.067e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19861, Training Loss: 1.067e-01, Validation Loss: 5.612e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19862, Training Loss: 1.067e-01, Validation Loss: 5.612e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19863, Training Loss: 1.067e-01, Validation Loss: 5.612e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19864, Training Loss: 1.067e-01, Validation Loss: 5.612e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19865, Training Loss: 1.066e-01, Validation Loss: 5.612e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19866, Training Loss: 1.066e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19867, Training Loss: 1.066e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19868, Training Loss: 1.066e-01, Validation Loss: 5.612e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19869, Training Loss: 1.066e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19870, Training Loss: 1.066e-01, Validation Loss: 5.611e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19871, Training Loss: 1.066e-01, Validation Loss: 5.611e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19872, Training Loss: 1.066e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19873, Training Loss: 1.066e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19874, Training Loss: 1.066e-01, Validation Loss: 5.611e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19875, Training Loss: 1.066e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19876, Training Loss: 1.066e-01, Validation Loss: 5.611e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19877, Training Loss: 1.066e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19878, Training Loss: 1.065e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19879, Training Loss: 1.065e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19880, Training Loss: 1.065e-01, Validation Loss: 5.611e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19881, Training Loss: 1.065e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19882, Training Loss: 1.065e-01, Validation Loss: 5.611e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19883, Training Loss: 1.065e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19884, Training Loss: 1.065e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19885, Training Loss: 1.065e-01, Validation Loss: 5.611e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19886, Training Loss: 1.065e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19887, Training Loss: 1.065e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19888, Training Loss: 1.065e-01, Validation Loss: 5.611e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19889, Training Loss: 1.065e-01, Validation Loss: 5.611e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19890, Training Loss: 1.065e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19891, Training Loss: 1.064e-01, Validation Loss: 5.611e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19892, Training Loss: 1.064e-01, Validation Loss: 5.611e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19893, Training Loss: 1.064e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19894, Training Loss: 1.064e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19895, Training Loss: 1.064e-01, Validation Loss: 5.611e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19896, Training Loss: 1.064e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19897, Training Loss: 1.064e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19898, Training Loss: 1.064e-01, Validation Loss: 5.611e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19899, Training Loss: 1.064e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19900, Training Loss: 1.064e-01, Validation Loss: 5.611e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19901, Training Loss: 1.064e-01, Validation Loss: 5.611e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19902, Training Loss: 1.064e-01, Validation Loss: 5.611e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19903, Training Loss: 1.063e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19904, Training Loss: 1.063e-01, Validation Loss: 5.610e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19905, Training Loss: 1.063e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19906, Training Loss: 1.063e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19907, Training Loss: 1.063e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19908, Training Loss: 1.063e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19909, Training Loss: 1.063e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19910, Training Loss: 1.063e-01, Validation Loss: 5.610e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19911, Training Loss: 1.063e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19912, Training Loss: 1.063e-01, Validation Loss: 5.610e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19913, Training Loss: 1.063e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19914, Training Loss: 1.063e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19915, Training Loss: 1.063e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19916, Training Loss: 1.062e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19917, Training Loss: 1.062e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19918, Training Loss: 1.062e-01, Validation Loss: 5.610e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19919, Training Loss: 1.062e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19920, Training Loss: 1.062e-01, Validation Loss: 5.610e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19921, Training Loss: 1.062e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19922, Training Loss: 1.062e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19923, Training Loss: 1.062e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19924, Training Loss: 1.062e-01, Validation Loss: 5.610e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19925, Training Loss: 1.062e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19926, Training Loss: 1.062e-01, Validation Loss: 5.610e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19927, Training Loss: 1.062e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19928, Training Loss: 1.062e-01, Validation Loss: 5.610e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19929, Training Loss: 1.061e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19930, Training Loss: 1.061e-01, Validation Loss: 5.610e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19931, Training Loss: 1.061e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19932, Training Loss: 1.061e-01, Validation Loss: 5.610e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19933, Training Loss: 1.061e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19934, Training Loss: 1.061e-01, Validation Loss: 5.610e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19935, Training Loss: 1.061e-01, Validation Loss: 5.610e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19936, Training Loss: 1.061e-01, Validation Loss: 5.610e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19937, Training Loss: 1.061e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19938, Training Loss: 1.061e-01, Validation Loss: 5.609e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19939, Training Loss: 1.061e-01, Validation Loss: 5.609e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19940, Training Loss: 1.061e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19941, Training Loss: 1.060e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19942, Training Loss: 1.060e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19943, Training Loss: 1.060e-01, Validation Loss: 5.609e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19944, Training Loss: 1.060e-01, Validation Loss: 5.609e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19945, Training Loss: 1.060e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19946, Training Loss: 1.060e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19947, Training Loss: 1.060e-01, Validation Loss: 5.609e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19948, Training Loss: 1.060e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19949, Training Loss: 1.060e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19950, Training Loss: 1.060e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19951, Training Loss: 1.060e-01, Validation Loss: 5.609e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19952, Training Loss: 1.060e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19953, Training Loss: 1.060e-01, Validation Loss: 5.609e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19954, Training Loss: 1.059e-01, Validation Loss: 5.609e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19955, Training Loss: 1.059e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19956, Training Loss: 1.059e-01, Validation Loss: 5.609e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19957, Training Loss: 1.059e-01, Validation Loss: 5.609e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19958, Training Loss: 1.059e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19959, Training Loss: 1.059e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19960, Training Loss: 1.059e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19961, Training Loss: 1.059e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19962, Training Loss: 1.059e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19963, Training Loss: 1.059e-01, Validation Loss: 5.609e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19964, Training Loss: 1.059e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19965, Training Loss: 1.059e-01, Validation Loss: 5.609e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19966, Training Loss: 1.059e-01, Validation Loss: 5.609e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19967, Training Loss: 1.058e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19968, Training Loss: 1.058e-01, Validation Loss: 5.609e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19969, Training Loss: 1.058e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19970, Training Loss: 1.058e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19971, Training Loss: 1.058e-01, Validation Loss: 5.609e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19972, Training Loss: 1.058e-01, Validation Loss: 5.609e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19973, Training Loss: 1.058e-01, Validation Loss: 5.609e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19974, Training Loss: 1.058e-01, Validation Loss: 5.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19975, Training Loss: 1.058e-01, Validation Loss: 5.609e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19976, Training Loss: 1.058e-01, Validation Loss: 5.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19977, Training Loss: 1.058e-01, Validation Loss: 5.608e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19978, Training Loss: 1.058e-01, Validation Loss: 5.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19979, Training Loss: 1.058e-01, Validation Loss: 5.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19980, Training Loss: 1.057e-01, Validation Loss: 5.608e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19981, Training Loss: 1.057e-01, Validation Loss: 5.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19982, Training Loss: 1.057e-01, Validation Loss: 5.608e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19983, Training Loss: 1.057e-01, Validation Loss: 5.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19984, Training Loss: 1.057e-01, Validation Loss: 5.608e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19985, Training Loss: 1.057e-01, Validation Loss: 5.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19986, Training Loss: 1.057e-01, Validation Loss: 5.608e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19987, Training Loss: 1.057e-01, Validation Loss: 5.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19988, Training Loss: 1.057e-01, Validation Loss: 5.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19989, Training Loss: 1.057e-01, Validation Loss: 5.608e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19990, Training Loss: 1.057e-01, Validation Loss: 5.608e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19991, Training Loss: 1.057e-01, Validation Loss: 5.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19992, Training Loss: 1.056e-01, Validation Loss: 5.608e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19993, Training Loss: 1.056e-01, Validation Loss: 5.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19994, Training Loss: 1.056e-01, Validation Loss: 5.608e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19995, Training Loss: 1.056e-01, Validation Loss: 5.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19996, Training Loss: 1.056e-01, Validation Loss: 5.608e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19997, Training Loss: 1.056e-01, Validation Loss: 5.608e-01, Patience: 0, Learning Rate: 0.001\n",
      "Epoch 19998, Training Loss: 1.056e-01, Validation Loss: 5.608e-01, Patience: 1, Learning Rate: 0.001\n",
      "Epoch 19999, Training Loss: 1.056e-01, Validation Loss: 5.608e-01, Patience: 2, Learning Rate: 0.001\n",
      "Epoch 19999, Training Loss: 1.056e-01, Validation Loss: 5.608e-01, Patience: 2\n"
     ]
    }
   ],
   "source": [
    "error_train, error_val = model_50.train(X_train, y_train, X_val, y_val, epochs=20000, learning_rate=1e-3, optimizer='sgd', generate_new_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_50.plot_training_error(error_train, error_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error : 0.44680560683100573\n",
      "(208, 4900) (208, 15) (208, 15)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_50.test(X_test, y_test)\n",
    "print(X_test.shape, y_test.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8894230769230769\n",
      "Azmira - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "David - Precision: 0.8421052631578947, Recall: 1.0, F1 Score: 0.9142857142857143\n",
      "Dimas - Precision: 0.9, Recall: 1.0, F1 Score: 0.9473684210526316\n",
      "Fadhli - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Fadlin - Precision: 0.75, Recall: 1.0, F1 Score: 0.8571428571428571\n",
      "Hafidz - Precision: 0.9090909090909091, Recall: 0.7142857142857143, F1 Score: 0.8\n",
      "Haidar - Precision: 1.0, Recall: 0.7142857142857143, F1 Score: 0.8333333333333333\n",
      "Hanna - Precision: 0.8571428571428571, Recall: 1.0, F1 Score: 0.923076923076923\n",
      "Keiko - Precision: 0.8095238095238095, Recall: 0.9444444444444444, F1 Score: 0.8717948717948718\n",
      "Khansa - Precision: 0.8, Recall: 0.3076923076923077, F1 Score: 0.4444444444444444\n",
      "Mikhael - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Puti - Precision: 0.8461538461538461, Recall: 0.9166666666666666, F1 Score: 0.8799999999999999\n",
      "Raesa - Precision: 0.7692307692307693, Recall: 0.7142857142857143, F1 Score: 0.7407407407407408\n",
      "Satwika - Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Toni - Precision: 0.9545454545454546, Recall: 1.0, F1 Score: 0.9767441860465117\n",
      "Mean Precision: 0.8958528605897028\n",
      "Mean Recall: 0.8874440374440374\n",
      "Mean F1 Score: 0.8792620994612019\n"
     ]
    }
   ],
   "source": [
    "model_50.add_labels_from_folders(input_directory)\n",
    "model_50.evaluate_metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_50.plot_confusion_matrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_50.save_weights(\"./My_Model_50/08_Ishmael_Rotate.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
